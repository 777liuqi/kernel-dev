 Percent |	Source code & Disassembly of vmlinux for cycles (133734 samples, percent: local period)
-------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010780cc0 <cmpwait_special>:
         : 6                cmpwait_special():
    0.00 :   ffff800010780cc0:       paciasp
    0.00 :   ffff800010780cc4:       sevl
    0.00 :   ffff800010780cc8:       wfe
    0.30 :   ffff800010780ccc:       mov     x4, #0x7fffffff                 // #2147483647
    0.26 :   ffff800010780cd0:       dmb     ish
    0.51 :   ffff800010780cd4:       ldxr    x2, [x0]
    0.00 :   ffff800010780cd8:       and     x4, x4, x2
    0.00 :   ffff800010780cdc:       eor     x4, x4, x1
    0.00 :   ffff800010780ce0:       cbz     x4, ffff800010780cec <cmpwait_special+0x2c>
   81.87 :   ffff800010780ce4:       wfe
    7.45 :   ffff800010780ce8:       b       ffff800010780ccc <cmpwait_special+0xc>
    9.61 :   ffff800010780cec:       mov     w0, w2
    0.00 :   ffff800010780cf0:       autiasp
    0.01 :   ffff800010780cf4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (65248 samples, percent: local period)
------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077c908 <arm_smmu_cmdq_issue_cmdlist>:
         : 6                arm_smmu_cmdq_issue_cmdlist():
         : 795              prod = atomic_fetch_andnot_relaxed(CMDQ_PROD_OWNED_FLAG,
         : 796              &cmdq->q.llq.atomic.prod);
         : 797              prod &= ~CMDQ_PROD_OWNED_FLAG;
         :
         : 799              /*
         : 800              * c. Wait for any gathered work to be written to the queue.
    0.01 :   ffff80001077c908:       paciasp
    0.00 :   ffff80001077c90c:       sub     sp, sp, #0x230
    0.00 :   ffff80001077c910:       stp     x29, x30, [sp]
    0.00 :   ffff80001077c914:       mov     x29, sp
    0.01 :   ffff80001077c918:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001077c91c:       add     x23, sp, #0x11f
    0.00 :   ffff80001077c920:       and     x23, x23, #0xffffffffffffffc0
         : 800              * Note that we read our own entries so that we have the control
         : 801              * dependency required by (d).
         : 802              */
         : 803              arm_smmu_cmdq_poll_valid_map(cmdq, llq.prod, prod);
         :
    0.00 :   ffff80001077c924:       add     x24, x0, #0x40
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.01 :   ffff80001077c928:       stp     x21, x22, [sp, #32]
         : 801              /*
    0.00 :   ffff80001077c92c:       add     x21, x23, #0x80
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.00 :   ffff80001077c930:       stp     x19, x20, [sp, #16]
    0.02 :   ffff80001077c934:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001077c938:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001077c93c:       mov     x28, x0
    0.00 :   ffff80001077c940:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
         : 802              * d. Advance the hardware prod pointer
    0.01 :   ffff80001077c944:       ldr     w19, [x24, #68]
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.00 :   ffff80001077c948:       add     x4, x0, #0x948
         : 801              /*
    0.44 :   ffff80001077c94c:       stp     xzr, xzr, [x21, #16]
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.00 :   ffff80001077c950:       and     w0, w3, #0xff
         : 801              /*
    0.00 :   ffff80001077c954:       stp     xzr, xzr, [x21, #32]
    0.00 :   ffff80001077c958:       stp     xzr, xzr, [x21, #48]
    0.01 :   ffff80001077c95c:       stp     xzr, xzr, [x21, #64]
         : 803              * Control dependency ordering from the entries becoming valid.
    0.01 :   ffff80001077c960:       str     w19, [x23, #196]
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.01 :   ffff80001077c964:       str     w2, [sp, #160]
    0.00 :   ffff80001077c968:       ldr     x2, [x4]
    0.00 :   ffff80001077c96c:       str     x2, [sp, #552]
    0.00 :   ffff80001077c970:       mov     x2, #0x0                        // #0
         : 803              * Control dependency ordering from the entries becoming valid.
    0.00 :   ffff80001077c974:       mov     x2, #0x80                       // #128
         : 801              /*
    0.01 :   ffff80001077c978:       stp     xzr, xzr, [x21, #80]
    0.01 :   ffff80001077c97c:       stp     xzr, xzr, [x21, #96]
    0.01 :   ffff80001077c980:       stp     xzr, xzr, [x21, #112]
    0.01 :   ffff80001077c984:       stp     xzr, xzr, [x23, #128]
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.00 :   ffff80001077c988:       str     w0, [sp, #148]
         : 803              * Control dependency ordering from the entries becoming valid.
    0.00 :   ffff80001077c98c:       mov     x0, x23
         : 795              * c. Wait for any gathered work to be written to the queue.
    0.01 :   ffff80001077c990:       stp     x4, x1, [sp, #168]
         : 803              * Control dependency ordering from the entries becoming valid.
    0.00 :   ffff80001077c994:       mov     x1, x21
    0.00 :   ffff80001077c998:       bl      ffff8000104a5b40 <__memcpy>
         : 806              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077c99c:       mrs     x5, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077c9a0:       and     w0, w5, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff80001077c9a4:       cbz     w0, ffff80001077d2d4 <arm_smmu_cmdq_issue_cmdlist+0x9cc>
         : 118              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.03 :   ffff80001077c9a8:       mrs     x1, tpidr_el1
         : 46               arm_smmu_cmdq_issue_cmdlist():
         : 823              ret = arm_smmu_cmdq_poll_until_sync(smmu, &llq);
         : 824              if (ret) {
         : 825              dev_err_ratelimited(smmu->dev,
         : 826              "CMD_SYNC timeout at 0x%08x [hwprod 0x%08x, hwcons 0x%08x]\n",
         : 827              llq.prod,
         : 828              readl_relaxed(cmdq->q.prod_reg),
    0.07 :   ffff80001077c9ac:       adrp    x0, ffff80001176d000 <cpu_number>
    0.00 :   ffff80001077c9b0:       add     x0, x0, #0x0
    0.00 :   ffff80001077c9b4:       ldr     w0, [x0, x1]
    0.11 :   ffff80001077c9b8:       str     x5, [sp, #96]
    0.00 :   ffff80001077c9bc:       str     w0, [sp, #164]
         : 824              readl_relaxed(cmdq->q.cons_reg));
    0.00 :   ffff80001077c9c0:       bl      ffff800010110e30 <ktime_get>
    0.00 :   ffff80001077c9c4:       str     x0, [sp, #152]
         : 825              }
    0.00 :   ffff80001077c9c8:       ldr     x0, [x28, #64]
   14.79 :   ffff80001077c9cc:       str     x0, [x23, #128]
         : 828              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001077c9d0:       ldr     x5, [sp, #96]
    0.00 :   ffff80001077c9d4:       b       ffff80001077cb54 <arm_smmu_cmdq_issue_cmdlist+0x24c>
    0.00 :   ffff80001077c9d8:       b       ffff80001077cb54 <arm_smmu_cmdq_issue_cmdlist+0x24c>
         : 47               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff80001077c9dc:       adrp    x0, ffff800011f80000 <tpm_dev+0x358>
    0.00 :   ffff80001077c9e0:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001077c9e4:       add     x26, x0, #0x1d8
    0.01 :   ffff80001077c9e8:       stadd   x1, [x26]
         : 189              arm_smmu_cmdq_issue_cmdlist():
         :
         : 828              /*
    0.00 :   ffff80001077c9ec:       ldr     w1, [sp, #160]
    0.00 :   ffff80001077c9f0:       ldr     w0, [sp, #148]
    0.00 :   ffff80001077c9f4:       add     w25, w0, w1
    0.00 :   ffff80001077c9f8:       add     x1, x24, #0x40
         : 833              arch_static_branch_jump():
    0.00 :   ffff80001077c9fc:       b       ffff80001077cb48 <arm_smmu_cmdq_issue_cmdlist+0x240>
    0.00 :   ffff80001077ca00:       b       ffff80001077cb48 <arm_smmu_cmdq_issue_cmdlist+0x240>
         : 40               __lse_atomic_fetch_add_relaxed():
         : 52               ATOMIC_FETCH_OPS(add, ldadd)
    0.01 :   ffff80001077ca04:       mov     w0, w25
    0.00 :   ffff80001077ca08:       ldadd   w0, w0, [x1]
         : 55               arm_smmu_cmdq_issue_cmdlist():
         : 829              * Try to unlock the cmdq lock. This will fail if we're the last
         : 830              * reader, in which case we can safely update cmdq->q.llq.cons
    2.60 :   ffff80001077ca0c:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001077ca10:       ldr     w22, [x23, #128]
    0.00 :   ffff80001077ca14:       lsl     w19, w1, w19
    0.00 :   ffff80001077ca18:       sub     w20, w19, #0x1
    0.00 :   ffff80001077ca1c:       orr     w27, w19, w20
         : 837              WRITE_ONCE(cmdq->q.llq.cons, llq.cons);
         : 838              arm_smmu_cmdq_shared_unlock(cmdq);
         : 839              }
         : 840              }
         :
         : 842              local_irq_restore(flags);
    0.00 :   ffff80001077ca20:       adrp    x2, ffff8000110af000 <qcom_smmu_client_of_match+0x568>
         : 829              * reader, in which case we can safely update cmdq->q.llq.cons
    0.00 :   ffff80001077ca24:       and     w0, w27, w0
         : 837              local_irq_restore(flags);
    0.00 :   ffff80001077ca28:       add     x1, x2, #0x988
         : 829              * reader, in which case we can safely update cmdq->q.llq.cons
    0.00 :   ffff80001077ca2c:       str     w0, [sp, #112]
         : 837              local_irq_restore(flags);
    0.00 :   ffff80001077ca30:       add     x0, x1, #0x20
    0.01 :   ffff80001077ca34:       str     x0, [sp, #96]
         : 815              /* 5. If we are inserting a CMD_SYNC, we must wait for it to complete */
    0.00 :   ffff80001077ca38:       mov     x0, x5
         :
    0.00 :   ffff80001077ca3c:       ldr     w1, [sp, #112]
         : 815              /* 5. If we are inserting a CMD_SYNC, we must wait for it to complete */
    0.00 :   ffff80001077ca40:       mov     w5, w22
    0.08 :   ffff80001077ca44:       str     wzr, [sp, #104]
    0.00 :   ffff80001077ca48:       mov     x22, x0
         : 834              }
    0.00 :   ffff80001077ca4c:       and     w0, w27, w5
         : 815              /* 5. If we are inserting a CMD_SYNC, we must wait for it to complete */
    0.00 :   ffff80001077ca50:       str     x26, [sp, #120]
         :
    0.00 :   ffff80001077ca54:       cmp     w0, w1
    0.00 :   ffff80001077ca58:       ldr     w1, [sp, #104]
         : 817              llq.prod = queue_inc_prod_n(&llq, n);
    0.00 :   ffff80001077ca5c:       str     wzr, [sp, #128]
         :
    0.00 :   ffff80001077ca60:       cset    w0, ne  // ne = any
         : 818              ret = arm_smmu_cmdq_poll_until_sync(smmu, &llq);
    0.01 :   ffff80001077ca64:       stp     wzr, wzr, [sp, #136]
         :
    0.00 :   ffff80001077ca68:       ands    w1, w0, w1
         : 819              if (ret) {
    0.00 :   ffff80001077ca6c:       str     wzr, [sp, #144]
         : 829              * reader, in which case we can safely update cmdq->q.llq.cons
    0.00 :   ffff80001077ca70:       str     w27, [sp, #184]
         :
    0.00 :   ffff80001077ca74:       b.ne    ffff80001077cd0c <arm_smmu_cmdq_issue_cmdlist+0x404>  // b.any
         : 847              struct arm_smmu_cmdq_ent *ent)
         : 848              {
         : 849              u64 cmd[CMDQ_ENT_DWORDS];
         :
         : 851              if (arm_smmu_cmdq_build_cmd(cmd, ent)) {
         : 852              dev_warn(smmu->dev, "ignoring unknown CMDQ opcode 0x%x\n",
    0.00 :   ffff80001077ca78:       ldr     w1, [sp, #104]
    0.00 :   ffff80001077ca7c:       eor     w2, w1, #0x1
    0.00 :   ffff80001077ca80:       ands    w2, w0, w2
    0.00 :   ffff80001077ca84:       b.ne    ffff80001077cd9c <arm_smmu_cmdq_issue_cmdlist+0x494>  // b.any
         : 857              queue_has_space():
         :
    0.02 :   ffff80001077ca88:       ldr     w3, [x21, #4]
         : 110              cons = Q_IDX(q, q->cons);
    0.00 :   ffff80001077ca8c:       and     w1, w20, w5
         :
    0.00 :   ffff80001077ca90:       and     w0, w20, w3
         : 113              space = (1 << q->max_n_shift) - (prod - cons);
    0.00 :   ffff80001077ca94:       eor     w4, w3, w5
         : 114              else
    0.01 :   ffff80001077ca98:       add     w2, w19, w0
    0.00 :   ffff80001077ca9c:       tst     w4, w19
    0.00 :   ffff80001077caa0:       sub     w0, w0, w1
    0.00 :   ffff80001077caa4:       sub     w1, w2, w1
    0.00 :   ffff80001077caa8:       csel    w0, w0, w1, ne  // ne = any
         : 120              arm_smmu_cmdq_issue_cmdlist():
         : 855              }
         :
         : 857              return arm_smmu_cmdq_issue_cmdlist(smmu, cmd, 1, false);
         : 858              }
         :
         : 860              static int arm_smmu_cmdq_issue_sync(struct arm_smmu_device *smmu)
    0.00 :   ffff80001077caac:       cmp     w0, w25
    0.00 :   ffff80001077cab0:       b.cs    ffff80001077cc5c <arm_smmu_cmdq_issue_cmdlist+0x354>  // b.hs, b.nlast
         : 863              arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cab4:       msr     daif, x22
         : 129              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001077cab8:       nop
         : 23               arch_local_save_flags():
         : 70               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cabc:       mrs     x4, daif
         : 72               arch_irqs_disabled_flags():
         : 85               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cac0:       and     w0, w4, #0x80
         : 87               arch_local_irq_save():
         : 111              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff80001077cac4:       cbz     w0, ffff80001077cc2c <arm_smmu_cmdq_issue_cmdlist+0x324>
         : 113              atomic_cmpxchg_relaxed():
         : 685              atomic64_fetch_add_release(s64 i, atomic64_t *v)
         : 686              {
         : 687              instrument_atomic_read_write(v, sizeof(*v));
         : 688              return arch_atomic64_fetch_add_release(i, v);
         : 689              }
         :
    0.00 :   ffff80001077cac8:       add     x3, x28, #0x10c
         : 692              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001077cacc:       b       ffff80001077cb68 <arm_smmu_cmdq_issue_cmdlist+0x260>
    0.00 :   ffff80001077cad0:       b       ffff80001077cb68 <arm_smmu_cmdq_issue_cmdlist+0x260>
         : 41               __lse__cmpxchg_case_32():
         : 366              return x0;                                                      \
         : 367              }
         :
         : 369              __CMPXCHG_CASE(w, b,     ,  8,   )
         : 370              __CMPXCHG_CASE(w, h,     , 16,   )
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
    0.00 :   ffff80001077cad4:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001077cad8:       mov     x0, x3
    0.00 :   ffff80001077cadc:       mov     w2, #0x80000000                 // #-2147483648
    0.00 :   ffff80001077cae0:       mov     w5, w1
    0.00 :   ffff80001077cae4:       cas     w5, w2, [x3]
    0.00 :   ffff80001077cae8:       mov     w0, w5
         : 378              arm_smmu_cmdq_poll_until_not_full():
         :
    0.00 :   ffff80001077caec:       cbnz    w0, ffff80001077cb7c <arm_smmu_cmdq_issue_cmdlist+0x274>
         : 598              return ret;
    0.00 :   ffff80001077caf0:       dmb     ish
         : 600              __raw_readl():
         :
         : 76               #define __raw_readl __raw_readl
         : 77               static __always_inline u32 __raw_readl(const volatile void __iomem *addr)
         : 78               {
         : 79               u32 val;
         : 80               asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    0.00 :   ffff80001077caf4:       ldr     x1, [x24, #176]
    0.00 :   ffff80001077caf8:       ldr     w1, [x1]
         : 83               arm_smmu_cmdq_poll_until_not_full():
         : 599              }
    0.00 :   ffff80001077cafc:       str     w1, [x28, #68]
         : 601              arch_atomic_set_release():
         :
         : 164              #ifndef arch_atomic_set_release
         : 165              static __always_inline void
         : 166              arch_atomic_set_release(atomic_t *v, int i)
         : 167              {
         : 168              smp_store_release(&(v)->counter, i);
    0.00 :   ffff80001077cb00:       add     x1, x28, #0x10c
    0.00 :   ffff80001077cb04:       stlr    w0, [x1]
         : 171              arch_local_irq_restore():
         : 122              asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cb08:       msr     daif, x4
         : 124              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001077cb0c:       nop
         : 23               arm_smmu_cmdq_poll_until_not_full():
         : 601              /*
    0.00 :   ffff80001077cb10:       dmb     ish
         : 602              * Wait until the SMMU signals a CMD_SYNC completion MSI.
    0.00 :   ffff80001077cb14:       ldr     x0, [x24]
    0.00 :   ffff80001077cb18:       str     x0, [x23, #128]
    0.00 :   ffff80001077cb1c:       nop
         : 606              arch_local_save_flags():
         : 70               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cb20:       mrs     x22, daif
         : 72               arch_irqs_disabled_flags():
         : 85               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cb24:       and     w0, w22, #0x80
         : 87               arch_local_irq_save():
         : 111              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff80001077cb28:       cbz     w0, ffff80001077cb34 <arm_smmu_cmdq_issue_cmdlist+0x22c>
    0.00 :   ffff80001077cb2c:       ldr     w5, [x21]
    0.00 :   ffff80001077cb30:       b       ffff80001077ca88 <arm_smmu_cmdq_issue_cmdlist+0x180>
         : 115              arch_static_branch():
    0.00 :   ffff80001077cb34:       nop
    0.00 :   ffff80001077cb38:       mov     x0, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cb3c:       msr     daifset, #0x3
    0.00 :   ffff80001077cb40:       ldr     w5, [x21]
    0.00 :   ffff80001077cb44:       b       ffff80001077ca88 <arm_smmu_cmdq_issue_cmdlist+0x180>
         : 58               __ll_sc_atomic_fetch_add_relaxed():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff80001077cb48:       add     x3, x24, #0x40
    0.00 :   ffff80001077cb4c:       b       ffff800010780ad0 <arm_smmu_tlb_inv_range_asid+0x158>
    0.00 :   ffff80001077cb50:       b       ffff80001077ca0c <arm_smmu_cmdq_issue_cmdlist+0x104>
         : 120              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff80001077cb54:       adrp    x0, ffff800011f80000 <tpm_dev+0x358>
    0.00 :   ffff80001077cb58:       add     x3, x0, #0x1d8
    0.00 :   ffff80001077cb5c:       b       ffff800010780ae8 <arm_smmu_tlb_inv_range_asid+0x170>
    0.00 :   ffff80001077cb60:       mov     x26, x3
    0.00 :   ffff80001077cb64:       b       ffff80001077c9ec <arm_smmu_cmdq_issue_cmdlist+0xe4>
         : 221              __ll_sc__cmpxchg_case_32():
         : 301              * handle the 'K' constraint for the value 4294967295 - thus we use no
         : 302              * constraint for 32 bit operations.
         : 303              */
         : 304              __CMPXCHG_CASE(w, b,     ,  8,        ,  ,  ,         , K)
         : 305              __CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
    0.00 :   ffff80001077cb68:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001077cb6c:       mov     w2, #0x80000000                 // #-2147483648
    0.00 :   ffff80001077cb70:       add     x5, x28, #0x10c
    0.00 :   ffff80001077cb74:       b       ffff800010780b00 <arm_smmu_tlb_inv_range_asid+0x188>
         : 311              arm_smmu_cmdq_poll_until_not_full():
         :
    0.00 :   ffff80001077cb78:       cbz     w0, ffff80001077caf0 <arm_smmu_cmdq_issue_cmdlist+0x1e8>
         : 599              arch_local_irq_restore():
         : 122              asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cb7c:       msr     daif, x4
         : 124              arch_static_branch():
    0.00 :   ffff80001077cb80:       nop
         : 22               queue_poll_init():
         : 201              qp->delay *= 2;
    0.00 :   ffff80001077cb84:       ldr     w0, [x28, #24]
         : 199              } else {
    0.00 :   ffff80001077cb88:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001077cb8c:       str     x1, [sp, #200]
         : 201              qp->delay *= 2;
    0.00 :   ffff80001077cb90:       ubfx    x0, x0, #6, #1
    0.00 :   ffff80001077cb94:       strb    w0, [sp, #208]
         : 202              qp->spin_cnt = 0;
    0.00 :   ffff80001077cb98:       bl      ffff800010110e30 <ktime_get>
         : 204              ktime_add_us():
         : 181              return ktime_to_ms(ktime_sub(later, earlier));
         : 182              }
         :
         : 184              static inline ktime_t ktime_add_us(const ktime_t kt, const u64 usec)
         : 185              {
         : 186              return ktime_add_ns(kt, usec * NSEC_PER_USEC);
    0.00 :   ffff80001077cb9c:       mov     x1, #0xca00                     // #51712
    0.00 :   ffff80001077cba0:       movk    x1, #0x3b9a, lsl #16
    0.00 :   ffff80001077cba4:       add     x0, x0, x1
         : 190              queue_poll_init():
    0.00 :   ffff80001077cba8:       str     x0, [sp, #192]
    0.00 :   ffff80001077cbac:       nop
         : 204              arm_smmu_cmdq_poll_until_not_full():
         : 608              int ret = 0;
    0.00 :   ffff80001077cbb0:       dmb     ish
         : 609              struct arm_smmu_queue_poll qp;
    0.00 :   ffff80001077cbb4:       ldr     x26, [x28, #64]
    0.00 :   ffff80001077cbb8:       str     x26, [x23, #128]
         : 612              queue_full():
         : 137              (Q_IDX(q, q->cons) <= Q_IDX(q, prod)));
    0.00 :   ffff80001077cbbc:       lsr     x22, x26, #32
    0.00 :   ffff80001077cbc0:       eor     w0, w26, w22
    0.00 :   ffff80001077cbc4:       tst     w20, w0
    0.00 :   ffff80001077cbc8:       b.ne    ffff80001077cb20 <arm_smmu_cmdq_issue_cmdlist+0x218>  // b.any
    0.00 :   ffff80001077cbcc:       tst     w19, w0
    0.00 :   ffff80001077cbd0:       b.eq    ffff80001077cb20 <arm_smmu_cmdq_issue_cmdlist+0x218>  // b.none
         : 144              arm_smmu_cmdq_poll_until_not_full():
         : 613              queue_poll_init(smmu, &qp);
    0.00 :   ffff80001077cbd4:       add     x0, sp, #0xc0
    0.00 :   ffff80001077cbd8:       bl      ffff80001077bd60 <queue_poll>
         :
    0.00 :   ffff80001077cbdc:       cbz     w0, ffff80001077cbb0 <arm_smmu_cmdq_issue_cmdlist+0x2a8>
         : 616              arm_smmu_cmdq_issue_cmdlist():
         : 858              {
         : 859              return arm_smmu_cmdq_issue_cmdlist(smmu, NULL, 0, true);
         : 860              }
    0.00 :   ffff80001077cbe0:       ldr     x1, [sp, #96]
    0.00 :   ffff80001077cbe4:       adrp    x0, ffff800011ea3000 <dev_attr_pcr_sha1_19+0x20>
    0.00 :   ffff80001077cbe8:       add     x0, x0, #0xb90
    0.00 :   ffff80001077cbec:       add     x0, x0, #0x168
    0.00 :   ffff80001077cbf0:       bl      ffff8000104b30d8 <___ratelimit>
    0.00 :   ffff80001077cbf4:       cbz     w0, ffff80001077cb20 <arm_smmu_cmdq_issue_cmdlist+0x218>
    0.00 :   ffff80001077cbf8:       ldr     w4, [x24]
    0.00 :   ffff80001077cbfc:       mov     w7, w22
    0.00 :   ffff80001077cc00:       ldr     w5, [x24, #4]
    0.00 :   ffff80001077cc04:       mov     w6, w26
    0.00 :   ffff80001077cc08:       ldr     w3, [sp, #148]
    0.00 :   ffff80001077cc0c:       adrp    x1, ffff8000114d7000 <kallsyms_token_index+0xcc7a0>
    0.00 :   ffff80001077cc10:       ldr     w2, [sp, #160]
    0.00 :   ffff80001077cc14:       add     x1, x1, #0x488
    0.00 :   ffff80001077cc18:       ldr     x0, [x28]
    0.00 :   ffff80001077cc1c:       bl      ffff800010e1fd58 <_dev_err>
    0.00 :   ffff80001077cc20:       b       ffff80001077cb20 <arm_smmu_cmdq_issue_cmdlist+0x218>
         : 869              arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff80001077cc24:       dsb     sy
    0.00 :   ffff80001077cc28:       b       ffff80001077cabc <arm_smmu_cmdq_issue_cmdlist+0x1b4>
         : 138              arch_static_branch():
    0.00 :   ffff80001077cc2c:       nop
    0.00 :   ffff80001077cc30:       mov     x0, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cc34:       msr     daifset, #0x3
    0.00 :   ffff80001077cc38:       b       ffff80001077cac8 <arm_smmu_cmdq_issue_cmdlist+0x1c0>
         : 57               arch_local_irq_restore():
         : 130              pmr_sync();
    0.00 :   ffff80001077cc3c:       dsb     sy
    0.00 :   ffff80001077cc40:       b       ffff80001077cb10 <arm_smmu_cmdq_issue_cmdlist+0x208>
    0.00 :   ffff80001077cc44:       dsb     sy
    0.00 :   ffff80001077cc48:       b       ffff80001077cb84 <arm_smmu_cmdq_issue_cmdlist+0x27c>
         : 135              arch_static_branch():
    0.00 :   ffff80001077cc4c:       mov     x0, #0xa0                       // #160
    0.00 :   ffff80001077cc50:       b       ffff80001077cb3c <arm_smmu_cmdq_issue_cmdlist+0x234>
    0.00 :   ffff80001077cc54:       mov     x0, #0xa0                       // #160
    0.00 :   ffff80001077cc58:       b       ffff80001077cc34 <arm_smmu_cmdq_issue_cmdlist+0x32c>
         : 25               queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.00 :   ffff80001077cc5c:       and     w0, w27, w5
    0.00 :   ffff80001077cc60:       add     w0, w0, w25
         : 195              arm_smmu_cmdq_issue_cmdlist():
         :
         : 865              static void arm_smmu_cmdq_batch_add(struct arm_smmu_device *smmu,
         : 866              struct arm_smmu_cmdq_batch *cmds,
         : 867              struct arm_smmu_cmdq_ent *cmd)
         : 868              {
         : 869              if (cmds->num == CMDQ_BATCH_ENTRIES) {
    0.00 :   ffff80001077cc64:       and     w0, w0, w27
    0.00 :   ffff80001077cc68:       orr     w0, w0, #0x80000000
         : 863              {
    0.03 :   ffff80001077cc6c:       stp     w0, w3, [x23]
         : 867              arm_smmu_cmdq_issue_cmdlist(smmu, cmds->cmds, cmds->num, false);
         : 868              cmds->num = 0;
         : 869              }
    0.01 :   ffff80001077cc70:       ldr     x1, [x21]
    0.00 :   ffff80001077cc74:       ldr     x2, [x23]
         : 872              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001077cc78:       b       ffff80001077cd94 <arm_smmu_cmdq_issue_cmdlist+0x48c>
    0.02 :   ffff80001077cc7c:       b       ffff80001077cd94 <arm_smmu_cmdq_issue_cmdlist+0x48c>
         : 41               __lse__cmpxchg_case_64():
         : 367              __CMPXCHG_CASE(x,  ,     , 64,   )
    0.00 :   ffff80001077cc80:       mov     x0, x24
    0.00 :   ffff80001077cc84:       mov     x3, x1
    0.01 :   ffff80001077cc88:       cas     x3, x2, [x24]
   13.27 :   ffff80001077cc8c:       mov     x0, x3
         : 372              arch_static_branch_jump():
    0.00 :   ffff80001077cc90:       b       ffff80001077cd58 <arm_smmu_cmdq_issue_cmdlist+0x450>
    0.00 :   ffff80001077cc94:       b       ffff80001077cd58 <arm_smmu_cmdq_issue_cmdlist+0x450>
         : 40               __lse_atomic64_add():
         : 179              ATOMIC64_OP(add, stadd)
    0.00 :   ffff80001077cc98:       ldr     x3, [sp, #120]
    0.00 :   ffff80001077cc9c:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001077cca0:       add     x2, x3, #0x8
    0.00 :   ffff80001077cca4:       stadd   x1, [x2]
         : 184              arm_smmu_cmdq_issue_cmdlist():
         : 869              arm_smmu_cmdq_build_cmd(&cmds->cmds[cmds->num * CMDQ_ENT_DWORDS], cmd);
         : 870              cmds->num++;
    0.16 :   ffff80001077cca8:       ldr     x1, [x21]
    0.00 :   ffff80001077ccac:       cmp     x1, x0
    0.00 :   ffff80001077ccb0:       b.eq    ffff80001077cd70 <arm_smmu_cmdq_issue_cmdlist+0x468>  // b.none
         : 881              }
         :
         : 883              /* Context descriptor manipulation functions */
         : 884              void arm_smmu_tlb_inv_asid(struct arm_smmu_device *smmu, u16 asid)
         : 885              {
         : 886              struct arm_smmu_cmdq_ent cmd = {
    0.00 :   ffff80001077ccb4:       ldp     w1, w3, [x21]
    0.00 :   ffff80001077ccb8:       mov     w5, w0
    0.00 :   ffff80001077ccbc:       lsr     x2, x0, #32
         : 878              /* Context descriptor manipulation functions */
    0.02 :   ffff80001077ccc0:       eor     w1, w1, w0
         : 883              .opcode = smmu->features & ARM_SMMU_FEAT_E2H ?
         : 884              CMDQ_OP_TLBI_EL2_ASID : CMDQ_OP_TLBI_NH_ASID,
    0.00 :   ffff80001077ccc4:       ands    w4, w27, w1
    0.00 :   ffff80001077ccc8:       ccmp    w1, #0x0, #0x0, eq  // eq = none
    0.00 :   ffff80001077cccc:       b.ge    ffff80001077cd38 <arm_smmu_cmdq_issue_cmdlist+0x430>  // b.tcont
         : 884              .tlbi.asid = asid,
    0.00 :   ffff80001077ccd0:       ldr     w1, [sp, #136]
    0.00 :   ffff80001077ccd4:       add     w1, w1, #0x1
    0.01 :   ffff80001077ccd8:       str     w1, [sp, #136]
         :
         : 892              arm_smmu_cmdq_issue_cmd(smmu, &cmd);
         : 893              arm_smmu_cmdq_issue_sync(smmu);
         : 894              }
         :
         : 896              static void arm_smmu_sync_cd(struct arm_smmu_domain *smmu_domain,
    0.00 :   ffff80001077ccdc:       ldr     w1, [sp, #144]
    0.00 :   ffff80001077cce0:       cmp     w3, w2
         : 894              int ssid, bool leaf)
         : 895              {
         : 896              size_t i;
    0.00 :   ffff80001077cce4:       str     x0, [x21]
         : 891              static void arm_smmu_sync_cd(struct arm_smmu_domain *smmu_domain,
    0.00 :   ffff80001077cce8:       cinc    w1, w1, ne  // ne = any
    0.00 :   ffff80001077ccec:       str     w1, [sp, #144]
         :
    0.00 :   ffff80001077ccf0:       ldr     w1, [sp, #112]
         : 834              }
    0.00 :   ffff80001077ccf4:       and     w0, w27, w5
         :
    0.00 :   ffff80001077ccf8:       cmp     w0, w1
    0.00 :   ffff80001077ccfc:       ldr     w1, [sp, #104]
    0.00 :   ffff80001077cd00:       cset    w0, ne  // ne = any
    0.00 :   ffff80001077cd04:       ands    w1, w0, w1
    0.00 :   ffff80001077cd08:       b.eq    ffff80001077ca78 <arm_smmu_cmdq_issue_cmdlist+0x170>  // b.none
         : 837              local_irq_restore(flags);
    0.00 :   ffff80001077cd0c:       ldr     w3, [sp, #112]
    0.00 :   ffff80001077cd10:       mov     w2, w5
    0.00 :   ffff80001077cd14:       str     w1, [sp, #104]
    0.00 :   ffff80001077cd18:       adrp    x0, ffff8000114d7000 <kallsyms_token_index+0xcc7a0>
    0.00 :   ffff80001077cd1c:       ldr     x1, [sp, #96]
    0.00 :   ffff80001077cd20:       mov     w4, #0x1                        // #1
    0.00 :   ffff80001077cd24:       add     x0, x0, #0x450
    0.00 :   ffff80001077cd28:       str     w5, [sp, #188]
    0.00 :   ffff80001077cd2c:       bl      ffff800010e19544 <printk>
         : 847              dev_warn(smmu->dev, "ignoring unknown CMDQ opcode 0x%x\n",
    0.00 :   ffff80001077cd30:       ldr     w5, [sp, #188]
    0.00 :   ffff80001077cd34:       b       ffff80001077ca88 <arm_smmu_cmdq_issue_cmdlist+0x180>
         :
    0.01 :   ffff80001077cd38:       cmp     w4, #0x0
    0.00 :   ffff80001077cd3c:       ccmp    w3, w2, #0x4, ne  // ne = any
    0.00 :   ffff80001077cd40:       b.eq    ffff80001077cdd0 <arm_smmu_cmdq_issue_cmdlist+0x4c8>  // b.none
         : 887              arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    0.00 :   ffff80001077cd44:       ldr     w1, [sp, #128]
         : 894              size_t i;
    0.00 :   ffff80001077cd48:       str     x0, [x21]
         : 887              arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    0.00 :   ffff80001077cd4c:       add     w1, w1, #0x1
    0.00 :   ffff80001077cd50:       str     w1, [sp, #128]
         : 894              size_t i;
    0.00 :   ffff80001077cd54:       b       ffff80001077ccf0 <arm_smmu_cmdq_issue_cmdlist+0x3e8>
         : 896              __ll_sc_atomic64_add():
         : 210              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff80001077cd58:       ldr     x1, [sp, #120]
    0.00 :   ffff80001077cd5c:       add     x3, x1, #0x8
    0.00 :   ffff80001077cd60:       b       ffff800010780b24 <arm_smmu_tlb_inv_range_asid+0x1ac>
         : 214              arm_smmu_cmdq_issue_cmdlist():
         : 869              cmds->num++;
    0.00 :   ffff80001077cd64:       ldr     x1, [x21]
    0.00 :   ffff80001077cd68:       cmp     x1, x0
    0.00 :   ffff80001077cd6c:       b.ne    ffff80001077ccb4 <arm_smmu_cmdq_issue_cmdlist+0x3ac>  // b.any
    0.00 :   ffff80001077cd70:       mov     x5, x22
    0.00 :   ffff80001077cd74:       ldr     x26, [sp, #120]
         : 870              }
    0.00 :   ffff80001077cd78:       dmb     ish
         : 897              unsigned long flags;
         : 898              struct arm_smmu_master *master;
         : 899              struct arm_smmu_cmdq_batch cmds = {};
    1.04 :   ffff80001077cd7c:       ldr     w0, [sp, #136]
         : 901              arch_static_branch_jump():
    0.00 :   ffff80001077cd80:       b       ffff80001077cde8 <arm_smmu_cmdq_issue_cmdlist+0x4e0>
    0.00 :   ffff80001077cd84:       b       ffff80001077cde8 <arm_smmu_cmdq_issue_cmdlist+0x4e0>
         : 40               __lse_atomic64_add():
    0.00 :   ffff80001077cd88:       add     x1, x26, #0x10
    0.01 :   ffff80001077cd8c:       stadd   x0, [x1]
    0.00 :   ffff80001077cd90:       b       ffff80001077cdf0 <arm_smmu_cmdq_issue_cmdlist+0x4e8>
         : 182              __ll_sc__cmpxchg_case_64():
         : 302              __CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
    0.00 :   ffff80001077cd94:       b       ffff800010780b3c <arm_smmu_tlb_inv_range_asid+0x1c4>
    0.00 :   ffff80001077cd98:       b       ffff80001077cc90 <arm_smmu_cmdq_issue_cmdlist+0x388>
         : 305              arm_smmu_cmdq_issue_cmdlist():
         : 848              ent->opcode);
    0.03 :   ffff80001077cd9c:       ldr     w1, [sp, #112]
    0.00 :   ffff80001077cda0:       mov     x0, x24
    0.00 :   ffff80001077cda4:       str     w2, [sp, #104]
    0.00 :   ffff80001077cda8:       bl      ffff800010780cc0 <cmpwait_special>
    0.00 :   ffff80001077cdac:       str     w0, [x21]
         : 849              return -EINVAL;
    0.15 :   ffff80001077cdb0:       dmb     ish
         : 850              }
    0.11 :   ffff80001077cdb4:       ldr     w0, [x24, #4]
    1.90 :   ffff80001077cdb8:       str     w0, [x21, #4]
         :
    0.00 :   ffff80001077cdbc:       dmb     ish
         : 852              return arm_smmu_cmdq_issue_cmdlist(smmu, cmd, 1, false);
    0.13 :   ffff80001077cdc0:       ldr     w2, [sp, #104]
    0.00 :   ffff80001077cdc4:       ldr     w5, [x21]
    0.00 :   ffff80001077cdc8:       str     w2, [sp, #104]
    0.00 :   ffff80001077cdcc:       b       ffff80001077ca88 <arm_smmu_cmdq_issue_cmdlist+0x180>
         : 888              arm_smmu_cmdq_issue_sync(smmu);
    0.00 :   ffff80001077cdd0:       cbz     w4, ffff80001077ccdc <arm_smmu_cmdq_issue_cmdlist+0x3d4>
         : 889              }
    0.00 :   ffff80001077cdd4:       ldr     w1, [sp, #140]
         : 894              size_t i;
    0.00 :   ffff80001077cdd8:       str     x0, [x21]
         : 889              }
    0.00 :   ffff80001077cddc:       add     w1, w1, #0x1
    0.00 :   ffff80001077cde0:       str     w1, [sp, #140]
         : 894              size_t i;
    0.00 :   ffff80001077cde4:       b       ffff80001077ccf0 <arm_smmu_cmdq_issue_cmdlist+0x3e8>
         : 896              __ll_sc_atomic64_add():
         : 210              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff80001077cde8:       add     x3, x26, #0x10
    0.00 :   ffff80001077cdec:       b       ffff800010780b58 <arm_smmu_tlb_inv_range_asid+0x1e0>
         : 213              arm_smmu_cmdq_issue_cmdlist():
         : 898              struct arm_smmu_device *smmu = smmu_domain->smmu;
    0.00 :   ffff80001077cdf0:       ldr     w0, [sp, #128]
         : 900              arch_static_branch_jump():
    0.00 :   ffff80001077cdf4:       b       ffff80001077d028 <arm_smmu_cmdq_issue_cmdlist+0x720>
    0.00 :   ffff80001077cdf8:       b       ffff80001077d028 <arm_smmu_cmdq_issue_cmdlist+0x720>
         : 40               __lse_atomic64_add():
    0.00 :   ffff80001077cdfc:       add     x1, x26, #0x18
    0.00 :   ffff80001077ce00:       stadd   x0, [x1]
         : 181              arm_smmu_cmdq_issue_cmdlist():
         : 899              struct arm_smmu_cmdq_ent cmd = {
    0.30 :   ffff80001077ce04:       ldr     w0, [sp, #140]
         : 901              arch_static_branch_jump():
    0.00 :   ffff80001077ce08:       b       ffff80001077d01c <arm_smmu_cmdq_issue_cmdlist+0x714>
    0.00 :   ffff80001077ce0c:       b       ffff80001077d01c <arm_smmu_cmdq_issue_cmdlist+0x714>
         : 40               __lse_atomic64_add():
    0.00 :   ffff80001077ce10:       add     x1, x26, #0x20
    0.00 :   ffff80001077ce14:       stadd   x0, [x1]
         : 181              arm_smmu_cmdq_issue_cmdlist():
         : 900              .opcode = CMDQ_OP_CFGI_CD,
    0.79 :   ffff80001077ce18:       ldr     w0, [sp, #144]
         : 902              arch_static_branch_jump():
    0.00 :   ffff80001077ce1c:       b       ffff80001077d010 <arm_smmu_cmdq_issue_cmdlist+0x708>
    0.00 :   ffff80001077ce20:       b       ffff80001077d010 <arm_smmu_cmdq_issue_cmdlist+0x708>
         : 40               __lse_atomic64_add():
    0.00 :   ffff80001077ce24:       add     x1, x26, #0x28
    0.00 :   ffff80001077ce28:       stadd   x0, [x1]
         : 181              arm_smmu_cmdq_issue_cmdlist():
         : 902              .cfgi   = {
         : 903              .ssid   = ssid,
    2.13 :   ffff80001077ce2c:       ldrsw   x0, [sp, #164]
    0.00 :   ffff80001077ce30:       adrp    x25, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff80001077ce34:       add     x25, x25, #0x760
    0.00 :   ffff80001077ce38:       adrp    x22, ffff800011778000 <ipi_to_irq>
    0.00 :   ffff80001077ce3c:       add     x22, x22, #0x370
    0.00 :   ffff80001077ce40:       mov     x1, x22
    0.00 :   ffff80001077ce44:       ldr     x3, [x25, x0, lsl #3]
    0.00 :   ffff80001077ce48:       stp     x0, x1, [sp, #96]
    0.01 :   ffff80001077ce4c:       stp     x3, x5, [sp, #112]
    0.00 :   ffff80001077ce50:       str     x1, [sp, #128]
         : 903              .leaf   = leaf,
    0.00 :   ffff80001077ce54:       bl      ffff800010110e30 <ktime_get>
    0.00 :   ffff80001077ce58:       ldr     x1, [sp, #152]
         : 906              arch_static_branch_jump():
    0.00 :   ffff80001077ce5c:       ldp     x3, x5, [sp, #112]
         : 39               arm_smmu_cmdq_issue_cmdlist():
    0.00 :   ffff80001077ce60:       sub     x0, x0, x1
    0.01 :   ffff80001077ce64:       ldr     x1, [sp, #104]
    0.00 :   ffff80001077ce68:       ldr     x2, [x1, x3]
    0.00 :   ffff80001077ce6c:       add     x2, x2, x0
    0.00 :   ffff80001077ce70:       str     x2, [x1, x3]
         : 908              arch_static_branch_jump():
    0.00 :   ffff80001077ce74:       b       ffff80001077d004 <arm_smmu_cmdq_issue_cmdlist+0x6fc>
    0.00 :   ffff80001077ce78:       b       ffff80001077d004 <arm_smmu_cmdq_issue_cmdlist+0x6fc>
         : 40               __lse_atomic64_add():
    0.01 :   ffff80001077ce7c:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001077ce80:       add     x1, x26, #0x30
    0.00 :   ffff80001077ce84:       stadd   x0, [x1]
         : 182              arch_static_branch_jump():
    0.00 :   ffff80001077ce88:       b       ffff80001077cff8 <arm_smmu_cmdq_issue_cmdlist+0x6f0>
    0.00 :   ffff80001077ce8c:       b       ffff80001077cff8 <arm_smmu_cmdq_issue_cmdlist+0x6f0>
         : 40               __lse_atomic64_add():
    0.01 :   ffff80001077ce90:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001077ce94:       add     x1, x26, #0x38
    0.00 :   ffff80001077ce98:       stadd   x0, [x1]
         : 182              arm_smmu_cmdq_issue_cmdlist():
         : 913              list_for_each_entry(master, &smmu_domain->devices, domain_head) {
         : 914              for (i = 0; i < master->num_streams; i++) {
         : 915              cmd.cfgi.sid = master->streams[i].id;
         : 916              arm_smmu_cmdq_batch_add(smmu, &cmds, &cmd);
         : 917              }
         : 918              }
    0.29 :   ffff80001077ce9c:       ldr     w0, [x23]
         : 912              }
    0.00 :   ffff80001077cea0:       ldr     w6, [x23, #128]
         : 913              }
    0.00 :   ffff80001077cea4:       and     w0, w0, #0x7fffffff
         : 915              arm_smmu_cmdq_write_entries():
         : 715              *   freeing an IOVA) after completion of the CMD_SYNC.
    0.00 :   ffff80001077cea8:       ldr     w1, [sp, #160]
         : 717              arm_smmu_cmdq_issue_cmdlist():
         : 914              spin_unlock_irqrestore(&smmu_domain->devices_lock, flags);
    0.00 :   ffff80001077ceac:       and     w12, w6, #0x7fffffff
         : 913              }
    0.00 :   ffff80001077ceb0:       str     w0, [x23]
         : 914              spin_unlock_irqrestore(&smmu_domain->devices_lock, flags);
    0.01 :   ffff80001077ceb4:       str     w12, [x23, #128]
         : 916              arm_smmu_cmdq_write_entries():
         : 715              *   freeing an IOVA) after completion of the CMD_SYNC.
    0.00 :   ffff80001077ceb8:       cmp     w1, #0x0
         : 711              *   in memory (such as a CD or an STE) before the command.
    0.00 :   ffff80001077cebc:       ldr     w0, [x24, #68]
         : 715              *   freeing an IOVA) after completion of the CMD_SYNC.
    0.00 :   ffff80001077cec0:       b.le    ffff80001077cf34 <arm_smmu_cmdq_issue_cmdlist+0x62c>
         : 717              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.17 :   ffff80001077cec4:       mov     w10, #0x1                       // #1
    0.00 :   ffff80001077cec8:       lsl     w11, w1, #1
    0.00 :   ffff80001077cecc:       lsl     w1, w10, w0
    0.00 :   ffff80001077ced0:       sub     w9, w1, #0x1
    0.00 :   ffff80001077ced4:       orr     w9, w9, w1
    0.00 :   ffff80001077ced8:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001077cedc:       and     w2, w12, w9
    0.01 :   ffff80001077cee0:       ldr     x7, [sp, #176]
    0.00 :   ffff80001077cee4:       b       ffff80001077ceec <arm_smmu_cmdq_issue_cmdlist+0x5e4>
    0.00 :   ffff80001077cee8:       ldr     w0, [x24, #68]
         : 203              arm_smmu_cmdq_write_entries():
         : 719              *   CPU will appear before any of the commands from the other CPU.
    0.00 :   ffff80001077ceec:       lsl     w0, w10, w0
    0.00 :   ffff80001077cef0:       sub     w0, w0, #0x1
    0.00 :   ffff80001077cef4:       and     w0, w0, w9
         : 716              *
    0.00 :   ffff80001077cef8:       sxtw    x4, w1
         : 719              *   CPU will appear before any of the commands from the other CPU.
    0.00 :   ffff80001077cefc:       ldr     x13, [x24, #160]
    0.00 :   ffff80001077cf00:       and     w0, w0, w2
    0.08 :   ffff80001077cf04:       ldr     x3, [x24, #136]
         : 716              *
    0.00 :   ffff80001077cf08:       add     x8, x7, x4, lsl #3
         : 719              *   CPU will appear before any of the commands from the other CPU.
    0.00 :   ffff80001077cf0c:       mul     x0, x0, x13
    0.00 :   ffff80001077cf10:       add     w1, w1, #0x2
         : 722              queue_write():
         :
    0.02 :   ffff80001077cf14:       ldr     x13, [x7, x4, lsl #3]
    0.00 :   ffff80001077cf18:       add     w2, w2, #0x1
         : 231              arm_smmu_cmdq_write_entries():
         : 719              *   CPU will appear before any of the commands from the other CPU.
    0.00 :   ffff80001077cf1c:       add     x4, x3, x0, lsl #3
         : 715              *   freeing an IOVA) after completion of the CMD_SYNC.
    0.00 :   ffff80001077cf20:       cmp     w11, w1
         : 717              queue_write():
         :
    0.00 :   ffff80001077cf24:       str     x13, [x3, x0, lsl #3]
    0.02 :   ffff80001077cf28:       ldr     x0, [x8, #8]
    0.00 :   ffff80001077cf2c:       str     x0, [x4, #8]
         : 232              arm_smmu_cmdq_write_entries():
         : 715              *   freeing an IOVA) after completion of the CMD_SYNC.
    0.00 :   ffff80001077cf30:       b.ne    ffff80001077cee8 <arm_smmu_cmdq_issue_cmdlist+0x5e0>  // b.any
         : 717              arm_smmu_cmdq_issue_cmdlist():
         : 921              arm_smmu_cmdq_batch_submit(smmu, &cmds);
         : 922              }
         :
         : 924              static int arm_smmu_alloc_cd_leaf_table(struct arm_smmu_device *smmu,
         : 925              struct arm_smmu_l1_ctx_desc *l1_desc)
         : 926              {
    0.01 :   ffff80001077cf34:       ldr     w0, [sp, #148]
    0.00 :   ffff80001077cf38:       cbnz    w0, ffff80001077d1c4 <arm_smmu_cmdq_issue_cmdlist+0x8bc>
         : 936              return 0;
         : 937              }
         :
         : 939              static void arm_smmu_write_cd_l1_desc(__le64 *dst,
         : 940              struct arm_smmu_l1_ctx_desc *l1_desc)
         : 941              {
    0.01 :   ffff80001077cf3c:       str     w6, [sp, #104]
    0.00 :   ffff80001077cf40:       str     x5, [sp, #112]
    0.00 :   ffff80001077cf44:       dmb     oshst
         : 945              arm_smmu_cmdq_set_valid_map():
         : 574              struct arm_smmu_queue_poll qp;
    0.47 :   ffff80001077cf48:       ldr     w3, [x23]
    0.00 :   ffff80001077cf4c:       add     x7, x28, #0x100
    0.00 :   ffff80001077cf50:       ldr     w2, [x23, #128]
    0.00 :   ffff80001077cf54:       mov     x1, x7
    0.03 :   ffff80001077cf58:       ldr     w0, [x28, #132]
    0.00 :   ffff80001077cf5c:       mov     w4, #0x1                        // #1
    0.23 :   ffff80001077cf60:       str     x7, [sp, #120]
    0.00 :   ffff80001077cf64:       bl      ffff80001077c5d8 <__arm_smmu_cmdq_poll_set_valid_map.isra.25>
         : 583              arm_smmu_cmdq_issue_cmdlist():
         : 940              u64 val = (l1_desc->l2ptr_dma & CTXDESC_L1_DESC_L2PTR_MASK) |
         : 941              CTXDESC_L1_DESC_V;
         :
         : 943              /* See comment in arm_smmu_write_ctx_desc() */
    0.01 :   ffff80001077cf68:       ldr     w6, [sp, #104]
    0.00 :   ffff80001077cf6c:       ldr     x5, [sp, #112]
    0.00 :   ffff80001077cf70:       tbz     w6, #31, ffff80001077d03c <arm_smmu_cmdq_issue_cmdlist+0x734>
         : 972              idx = ssid & (CTXDESC_L2_ENTRIES - 1);
         : 973              return l1_desc->l2ptr + idx * CTXDESC_CD_DWORDS;
         : 974              }
         :
         : 976              int arm_smmu_write_ctx_desc(struct arm_smmu_domain *smmu_domain, int ssid,
         : 977              struct arm_smmu_ctx_desc *cd)
    0.00 :   ffff80001077cf74:       ldr     w0, [sp, #148]
         : 804              */
    0.00 :   ffff80001077cf78:       mov     w6, #0x0                        // #0
         : 972              struct arm_smmu_ctx_desc *cd)
    0.00 :   ffff80001077cf7c:       cbnz    w0, ffff80001077d0e8 <arm_smmu_cmdq_issue_cmdlist+0x7e0>
         :
         : 995              if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
         : 996              return -E2BIG;
         :
         : 998              cdptr = arm_smmu_get_cd_ptr(smmu_domain, ssid);
         : 999              if (!cdptr)
    0.01 :   ffff80001077cf80:       ldr     x0, [sp, #96]
    0.00 :   ffff80001077cf84:       str     x5, [sp, #104]
    0.00 :   ffff80001077cf88:       str     w6, [sp, #112]
    0.00 :   ffff80001077cf8c:       add     x22, x22, #0x10
    0.00 :   ffff80001077cf90:       ldr     x19, [x25, x0, lsl #3]
         : 996              return -ENOMEM;
         :
    0.00 :   ffff80001077cf94:       bl      ffff800010110e30 <ktime_get>
         : 997              val = le64_to_cpu(cdptr[0]);
    0.00 :   ffff80001077cf98:       ldr     x2, [sp, #152]
    0.00 :   ffff80001077cf9c:       ldr     x1, [x22, x19]
    0.00 :   ffff80001077cfa0:       sub     x0, x0, x2
         : 1001             arch_local_irq_restore():
         : 122              asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077cfa4:       ldr     x5, [sp, #104]
         : 124              arm_smmu_cmdq_issue_cmdlist():
    0.00 :   ffff80001077cfa8:       add     x1, x1, x0
    0.00 :   ffff80001077cfac:       str     x1, [x22, x19]
         : 999              arch_local_irq_restore():
    0.00 :   ffff80001077cfb0:       msr     daif, x5
         : 123              arch_static_branch():
         : 21               asm_volatile_goto(
    0.19 :   ffff80001077cfb4:       ldr     w6, [sp, #112]
    0.00 :   ffff80001077cfb8:       nop
         : 24               arm_smmu_cmdq_issue_cmdlist():
         : 1001             cd_live = !!(val & CTXDESC_CD_0_V);
         :
         : 1003             if (!cd) { /* (5) */
         : 1004             val = 0;
    0.00 :   ffff80001077cfbc:       ldr     x1, [sp, #168]
    0.00 :   ffff80001077cfc0:       mov     w0, w6
    0.21 :   ffff80001077cfc4:       ldr     x2, [sp, #552]
    0.01 :   ffff80001077cfc8:       ldr     x1, [x1]
    0.00 :   ffff80001077cfcc:       eor     x1, x2, x1
    0.00 :   ffff80001077cfd0:       cbnz    x1, ffff80001077d49c <arm_smmu_cmdq_issue_cmdlist+0xb94>
    0.00 :   ffff80001077cfd4:       ldp     x29, x30, [sp]
    0.00 :   ffff80001077cfd8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001077cfdc:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001077cfe0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001077cfe4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001077cfe8:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001077cfec:       add     sp, sp, #0x230
    0.00 :   ffff80001077cff0:       autiasp
    0.00 :   ffff80001077cff4:       ret
         : 1020             __ll_sc_atomic64_add():
    0.00 :   ffff80001077cff8:       add     x2, x26, #0x38
    0.00 :   ffff80001077cffc:       b       ffff800010780b74 <arm_smmu_tlb_inv_range_asid+0x1fc>
    0.00 :   ffff80001077d000:       b       ffff80001077ce9c <arm_smmu_cmdq_issue_cmdlist+0x594>
    0.00 :   ffff80001077d004:       add     x2, x26, #0x30
    0.00 :   ffff80001077d008:       b       ffff800010780b8c <arm_smmu_tlb_inv_range_asid+0x214>
    0.00 :   ffff80001077d00c:       b       ffff80001077ce88 <arm_smmu_cmdq_issue_cmdlist+0x580>
    0.00 :   ffff80001077d010:       add     x3, x26, #0x28
    0.00 :   ffff80001077d014:       b       ffff800010780ba4 <arm_smmu_tlb_inv_range_asid+0x22c>
    0.00 :   ffff80001077d018:       b       ffff80001077ce2c <arm_smmu_cmdq_issue_cmdlist+0x524>
    0.00 :   ffff80001077d01c:       add     x3, x26, #0x20
    0.00 :   ffff80001077d020:       b       ffff800010780bbc <arm_smmu_tlb_inv_range_asid+0x244>
    0.00 :   ffff80001077d024:       b       ffff80001077ce18 <arm_smmu_cmdq_issue_cmdlist+0x510>
    0.00 :   ffff80001077d028:       add     x3, x26, #0x18
    0.00 :   ffff80001077d02c:       b       ffff800010780bd4 <arm_smmu_tlb_inv_range_asid+0x25c>
    0.00 :   ffff80001077d030:       b       ffff80001077ce04 <arm_smmu_cmdq_issue_cmdlist+0x4fc>
         : 225              arch_local_irq_restore():
         : 130              pmr_sync();
    0.15 :   ffff80001077d034:       dsb     sy
         : 132              arm_smmu_cmdq_issue_cmdlist():
         : 1000             if (!cd) { /* (5) */
    2.32 :   ffff80001077d038:       b       ffff80001077cfbc <arm_smmu_cmdq_issue_cmdlist+0x6b4>
    0.00 :   ffff80001077d03c:       ldr     x7, [sp, #120]
         : 1003             arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.01 :   ffff80001077d040:       b       ffff80001077d1b8 <arm_smmu_cmdq_issue_cmdlist+0x8b0>
    0.00 :   ffff80001077d044:       b       ffff80001077d1b8 <arm_smmu_cmdq_issue_cmdlist+0x8b0>
         : 41               __lse_atomic64_add():
    0.00 :   ffff80001077d048:       mov     x0, #0x1                        // #1
    0.00 :   ffff80001077d04c:       add     x1, x26, #0x40
    0.00 :   ffff80001077d050:       stadd   x0, [x1]
         : 182              arm_smmu_cmdq_issue_cmdlist():
         :
    0.67 :   ffff80001077d054:       ldr     w0, [x28, #264]
    0.00 :   ffff80001077d058:       add     x1, x28, #0x108
    0.01 :   ffff80001077d05c:       ldr     w2, [x23, #128]
    0.00 :   ffff80001077d060:       cmp     w0, w2
    0.00 :   ffff80001077d064:       b.eq    ffff80001077d094 <arm_smmu_cmdq_issue_cmdlist+0x78c>  // b.none
    0.00 :   ffff80001077d068:       sxtw    x0, w0
         : 944              __cmpwait_case_32():
         : 252              : [val] "r" (val));                                             \
         : 253              }
         :
         : 255              __CMPWAIT_CASE(w, b, 8);
         : 256              __CMPWAIT_CASE(w, h, 16);
         : 257              __CMPWAIT_CASE(w,  , 32);
    0.00 :   ffff80001077d06c:       sevl
    0.00 :   ffff80001077d070:       wfe
    0.05 :   ffff80001077d074:       ldxr    w3, [x1]
    0.00 :   ffff80001077d078:       eor     w3, w3, w0
    0.00 :   ffff80001077d07c:       cbnz    w3, ffff80001077d084 <arm_smmu_cmdq_issue_cmdlist+0x77c>
    0.05 :   ffff80001077d080:       wfe
         : 264              arm_smmu_cmdq_issue_cmdlist():
    0.33 :   ffff80001077d084:       ldr     w0, [x28, #264]
    0.19 :   ffff80001077d088:       ldr     w3, [x21]
    0.00 :   ffff80001077d08c:       cmp     w3, w0
    0.00 :   ffff80001077d090:       b.ne    ffff80001077d068 <arm_smmu_cmdq_issue_cmdlist+0x760>  // b.any
         : 947              arch_static_branch_jump():
    0.00 :   ffff80001077d094:       b       ffff80001077d1a8 <arm_smmu_cmdq_issue_cmdlist+0x8a0>
    0.00 :   ffff80001077d098:       b       ffff80001077d1a8 <arm_smmu_cmdq_issue_cmdlist+0x8a0>
         : 40               __lse_atomic_fetch_andnot_relaxed():
         : 49               ATOMIC_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff80001077d09c:       mov     w0, #0x80000000                 // #-2147483648
    0.00 :   ffff80001077d0a0:       add     x1, x28, #0x40
    0.00 :   ffff80001077d0a4:       ldclr   w0, w0, [x1]
    5.98 :   ffff80001077d0a8:       mov     w26, w0
         : 54               arm_smmu_cmdq_poll_valid_map():
         : 581              */
    0.00 :   ffff80001077d0ac:       ldr     w0, [x28, #132]
         : 583              arm_smmu_cmdq_issue_cmdlist():
         : 948              unsigned int idx;
    0.00 :   ffff80001077d0b0:       and     w26, w26, #0x7fffffff
         : 950              arm_smmu_cmdq_poll_valid_map():
         : 581              */
    0.00 :   ffff80001077d0b4:       mov     x1, x7
    0.00 :   ffff80001077d0b8:       mov     w3, w26
    0.00 :   ffff80001077d0bc:       mov     w4, #0x0                        // #0
    0.00 :   ffff80001077d0c0:       str     x5, [sp, #104]
    0.00 :   ffff80001077d0c4:       bl      ffff80001077c5d8 <__arm_smmu_cmdq_poll_set_valid_map.isra.25>
         : 587              __raw_writel():
         : 39               asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    0.00 :   ffff80001077d0c8:       ldr     x0, [x24, #168]
    0.28 :   ffff80001077d0cc:       str     w26, [x0]
         : 42               arch_atomic_set_release():
    0.00 :   ffff80001077d0d0:       add     x0, x28, #0x108
    0.02 :   ffff80001077d0d4:       stlr    w26, [x0]
         : 165              arm_smmu_cmdq_issue_cmdlist():
         : 972              struct arm_smmu_ctx_desc *cd)
    1.24 :   ffff80001077d0d8:       ldr     w0, [sp, #148]
         : 804              */
    0.00 :   ffff80001077d0dc:       mov     w6, #0x0                        // #0
         : 806              arch_atomic_set_release():
    0.00 :   ffff80001077d0e0:       ldr     x5, [sp, #104]
         : 164              arm_smmu_cmdq_issue_cmdlist():
         : 972              struct arm_smmu_ctx_desc *cd)
    0.00 :   ffff80001077d0e4:       cbz     w0, ffff80001077cf80 <arm_smmu_cmdq_issue_cmdlist+0x678>
         : 973              {
    0.00 :   ffff80001077d0e8:       ldr     w0, [x23, #128]
         : 975              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.01 :   ffff80001077d0ec:       ldr     w3, [sp, #184]
    0.00 :   ffff80001077d0f0:       ldr     w1, [sp, #160]
    0.00 :   ffff80001077d0f4:       and     w26, w3, w0
         : 196              arm_smmu_cmdq_poll_until_sync():
         : 700              prod = queue_inc_prod_n(&llq, i);
    0.06 :   ffff80001077d0f8:       ldr     w2, [x28, #28]
         : 702              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.00 :   ffff80001077d0fc:       add     w26, w26, w1
         : 193              return -ETIMEDOUT;
    0.12 :   ffff80001077d100:       and     w0, w0, #0x80000000
    0.01 :   ffff80001077d104:       and     w26, w26, w3
   17.36 :   ffff80001077d108:       ldr     w1, [x28, #24]
    0.00 :   ffff80001077d10c:       orr     w26, w26, w0
         : 198              arm_smmu_cmdq_issue_cmdlist():
         : 973              {
    0.00 :   ffff80001077d110:       str     w26, [x23, #128]
         : 975              arm_smmu_cmdq_poll_until_sync():
         : 700              prod = queue_inc_prod_n(&llq, i);
    0.00 :   ffff80001077d114:       ubfx    x1, x1, #6, #1
    0.00 :   ffff80001077d118:       tbnz    w2, #2, ffff80001077d3c4 <arm_smmu_cmdq_issue_cmdlist+0xabc>
         : 703              queue_poll_init():
         : 199              } else {
    0.00 :   ffff80001077d11c:       mov     x0, #0x1                        // #1
    0.00 :   ffff80001077d120:       str     x5, [sp, #104]
    0.00 :   ffff80001077d124:       str     x0, [sp, #200]
         : 202              qp->spin_cnt = 0;
    0.00 :   ffff80001077d128:       and     w27, w20, w26
         : 201              qp->delay *= 2;
    0.00 :   ffff80001077d12c:       strb    w1, [sp, #208]
         : 202              qp->spin_cnt = 0;
    0.00 :   ffff80001077d130:       bl      ffff800010110e30 <ktime_get>
         : 204              __arm_smmu_cmdq_poll_until_consumed():
         : 656              *
    0.00 :   ffff80001077d134:       ldr     x2, [x28, #64]
         : 658              ktime_add_us():
    0.00 :   ffff80001077d138:       mov     x1, #0xca00                     // #51712
         : 182              __arm_smmu_cmdq_poll_until_consumed():
    0.00 :   ffff80001077d13c:       ldr     x5, [sp, #104]
         : 657              ktime_add_us():
    0.00 :   ffff80001077d140:       movk    x1, #0x3b9a, lsl #16
    0.00 :   ffff80001077d144:       add     x0, x0, x1
         : 183              queue_poll_init():
         : 202              qp->spin_cnt = 0;
    0.00 :   ffff80001077d148:       str     x0, [sp, #192]
         : 204              __arm_smmu_cmdq_poll_until_consumed():
         : 656              *
    0.00 :   ffff80001077d14c:       lsr     x0, x2, #32
    0.00 :   ffff80001077d150:       str     x23, [sp, #112]
    0.00 :   ffff80001077d154:       mov     w1, w0
    0.00 :   ffff80001077d158:       str     x2, [x23, #128]
    0.00 :   ffff80001077d15c:       mov     x23, x5
         : 662              queue_consumed():
         :
    0.00 :   ffff80001077d160:       eor     w0, w26, w1
    0.00 :   ffff80001077d164:       and     w1, w20, w1
         : 150              static void queue_inc_cons(struct arm_smmu_ll_queue *q)
    0.00 :   ffff80001077d168:       tst     w0, w19
    0.00 :   ffff80001077d16c:       b.eq    ffff80001077d2e4 <arm_smmu_cmdq_issue_cmdlist+0x9dc>  // b.none
         : 151              {
    0.00 :   ffff80001077d170:       cmp     w27, w1
    0.00 :   ffff80001077d174:       b.cc    ffff80001077d2ec <arm_smmu_cmdq_issue_cmdlist+0x9e4>  // b.lo, b.ul, b.last
    0.00 :   ffff80001077d178:       mov     x5, x23
         : 155              __arm_smmu_cmdq_poll_until_consumed():
         : 975              * This function handles the following cases:
    0.00 :   ffff80001077d17c:       mov     w6, #0x0                        // #0
         : 977              atomic_read():
         : 28               return arch_atomic_read(v);
    0.02 :   ffff80001077d180:       ldr     w0, [x28, #268]
    1.18 :   ffff80001077d184:       str     x5, [sp, #104]
    0.00 :   ffff80001077d188:       str     w6, [sp, #112]
         : 32               arm_smmu_cmdq_shared_tryunlock():
         : 461              })
    0.00 :   ffff80001077d18c:       cmp     w0, #0x1
    0.00 :   ffff80001077d190:       b.eq    ffff80001077d3a4 <arm_smmu_cmdq_issue_cmdlist+0xa9c>  // b.none
         : 464              ({                                                                      \
    0.00 :   ffff80001077d194:       mov     x0, x24
    0.00 :   ffff80001077d198:       bl      ffff80001077c700 <arm_smmu_cmdq_shared_unlock>
    0.00 :   ffff80001077d19c:       ldr     w6, [sp, #112]
    0.00 :   ffff80001077d1a0:       ldr     x5, [sp, #104]
         : 465              atomic_set_release(&cmdq->lock, 0);                             \
    0.00 :   ffff80001077d1a4:       b       ffff80001077cf80 <arm_smmu_cmdq_issue_cmdlist+0x678>
         : 467              __ll_sc_atomic_fetch_andnot_relaxed():
         : 130              ATOMIC_OPS(andnot, bic, )
    0.00 :   ffff80001077d1a8:       mov     w0, #0x80000000                 // #-2147483648
    0.00 :   ffff80001077d1ac:       add     x4, x28, #0x40
    0.00 :   ffff80001077d1b0:       b       ffff800010780bec <arm_smmu_tlb_inv_range_asid+0x274>
    0.00 :   ffff80001077d1b4:       b       ffff80001077d0ac <arm_smmu_cmdq_issue_cmdlist+0x7a4>
         : 135              __ll_sc_atomic64_add():
         : 210              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff80001077d1b8:       add     x2, x26, #0x40
    0.00 :   ffff80001077d1bc:       b       ffff800010780c04 <arm_smmu_tlb_inv_range_asid+0x28c>
    0.00 :   ffff80001077d1c0:       b       ffff80001077d054 <arm_smmu_cmdq_issue_cmdlist+0x74c>
         : 214              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.00 :   ffff80001077d1c4:       ldr     w2, [sp, #184]
         : 194              arm_smmu_cmdq_build_sync_cmd():
         :
    0.00 :   ffff80001077d1c8:       mov     w1, #0x46                       // #70
         : 359              };
    0.00 :   ffff80001077d1cc:       ldr     w0, [x28, #28]
         : 361              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
   14.86 :   ffff80001077d1d0:       ldr     w3, [sp, #160]
    0.00 :   ffff80001077d1d4:       and     w7, w2, w12
         : 195              arm_smmu_cmdq_build_sync_cmd():
         :
    0.00 :   ffff80001077d1d8:       stp     xzr, xzr, [sp, #192]
         : 353              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.00 :   ffff80001077d1dc:       add     w7, w7, w3
         : 194              arm_smmu_cmdq_build_sync_cmd():
         :
    0.00 :   ffff80001077d1e0:       strb    w1, [sp, #192]
         : 353              queue_inc_prod_n():
         : 193              return -ETIMEDOUT;
    0.00 :   ffff80001077d1e4:       and     w7, w7, w2
         : 195              arm_smmu_cmdq_build_sync_cmd():
         :
    0.00 :   ffff80001077d1e8:       stp     xzr, xzr, [sp, #208]
         : 359              };
    0.00 :   ffff80001077d1ec:       tbz     w0, #2, ffff80001077d218 <arm_smmu_cmdq_issue_cmdlist+0x910>
         :
    0.01 :   ffff80001077d1f0:       ldr     w1, [x24, #68]
    0.00 :   ffff80001077d1f4:       mov     w0, #0x1                        // #1
         : 361              int i;
    0.00 :   ffff80001077d1f8:       ldr     x2, [x24, #160]
         :
    0.00 :   ffff80001077d1fc:       lsl     w0, w0, w1
    0.00 :   ffff80001077d200:       sub     w0, w0, #0x1
    0.00 :   ffff80001077d204:       and     w0, w0, w7
    0.00 :   ffff80001077d208:       ldr     x1, [x24, #144]
         : 361              int i;
    0.00 :   ffff80001077d20c:       mul     x0, x0, x2
         :
    0.00 :   ffff80001077d210:       add     x0, x1, x0, lsl #3
    0.00 :   ffff80001077d214:       str     x0, [sp, #200]
         : 364              u32 cons = readl_relaxed(q->cons_reg);
    0.00 :   ffff80001077d218:       add     x1, sp, #0xc0
    0.00 :   ffff80001077d21c:       add     x0, sp, #0x218
    0.01 :   ffff80001077d220:       str     w6, [sp, #104]
    0.00 :   ffff80001077d224:       str     x5, [sp, #112]
    0.00 :   ffff80001077d228:       bl      ffff80001077b418 <arm_smmu_cmdq_build_cmd>
         : 370              arm_smmu_cmdq_issue_cmdlist():
         : 924              l1_desc->l2ptr = dmam_alloc_coherent(smmu->dev, size,
    0.01 :   ffff80001077d22c:       ldr     w1, [x24, #68]
    0.00 :   ffff80001077d230:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001077d234:       ldr     x2, [x24, #160]
         : 928              arm_smmu_cmdq_shared_lock():
         : 446              if (atomic_read(&cmdq->lock) == 1)
    0.00 :   ffff80001077d238:       add     x4, x28, #0x10c
         : 448              arm_smmu_cmdq_issue_cmdlist():
         : 924              l1_desc->l2ptr = dmam_alloc_coherent(smmu->dev, size,
    0.00 :   ffff80001077d23c:       lsl     w0, w0, w1
    0.00 :   ffff80001077d240:       sub     w0, w0, #0x1
    0.00 :   ffff80001077d244:       and     w0, w0, w7
         : 928              arch_static_branch_jump():
    0.00 :   ffff80001077d248:       ldr     w6, [sp, #104]
         : 39               arm_smmu_cmdq_issue_cmdlist():
    0.01 :   ffff80001077d24c:       ldr     x1, [x24, #136]
    0.00 :   ffff80001077d250:       mul     x0, x0, x2
         : 926              queue_write():
         :
    0.02 :   ffff80001077d254:       ldr     x2, [sp, #536]
         : 230              arch_static_branch_jump():
    0.02 :   ffff80001077d258:       ldr     x5, [sp, #112]
         : 39               queue_write():
    0.00 :   ffff80001077d25c:       str     x2, [x1, x0, lsl #3]
         : 229              arm_smmu_cmdq_issue_cmdlist():
         : 924              l1_desc->l2ptr = dmam_alloc_coherent(smmu->dev, size,
    0.00 :   ffff80001077d260:       add     x0, x1, x0, lsl #3
         : 926              queue_write():
         :
    0.10 :   ffff80001077d264:       ldr     x1, [sp, #544]
    0.09 :   ffff80001077d268:       str     x1, [x0, #8]
         : 231              arch_static_branch_jump():
    0.00 :   ffff80001077d26c:       b       ffff80001077d38c <arm_smmu_cmdq_issue_cmdlist+0xa84>
    0.00 :   ffff80001077d270:       b       ffff80001077d38c <arm_smmu_cmdq_issue_cmdlist+0xa84>
         : 40               __lse_atomic_fetch_add_relaxed():
         : 52               ATOMIC_FETCH_OPS(add, ldadd)
    0.00 :   ffff80001077d274:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001077d278:       ldadd   w0, w0, [x4]
         : 55               arm_smmu_cmdq_shared_lock():
         : 446              if (atomic_read(&cmdq->lock) == 1)
    3.19 :   ffff80001077d27c:       tbnz    w0, #31, ffff80001077d2a0 <arm_smmu_cmdq_issue_cmdlist+0x998>
    0.00 :   ffff80001077d280:       b       ffff80001077cf3c <arm_smmu_cmdq_issue_cmdlist+0x634>
         : 450              return true;
    0.00 :   ffff80001077d284:       sxtw    x3, w3
         : 452              __cmpwait_case_32():
    0.00 :   ffff80001077d288:       sevl
    0.00 :   ffff80001077d28c:       wfe
    0.00 :   ffff80001077d290:       ldxr    w0, [x4]
    0.00 :   ffff80001077d294:       eor     w0, w0, w3
    0.00 :   ffff80001077d298:       cbnz    w0, ffff80001077d2a0 <arm_smmu_cmdq_issue_cmdlist+0x998>
    0.00 :   ffff80001077d29c:       wfe
         : 258              arm_smmu_cmdq_shared_lock():
    0.00 :   ffff80001077d2a0:       ldr     w3, [x28, #268]
    0.00 :   ffff80001077d2a4:       tbnz    w3, #31, ffff80001077d284 <arm_smmu_cmdq_issue_cmdlist+0x97c>
         : 451              }
    0.00 :   ffff80001077d2a8:       add     w2, w3, #0x1
         : 453              arch_static_branch_jump():
    0.00 :   ffff80001077d2ac:       b       ffff80001077d398 <arm_smmu_cmdq_issue_cmdlist+0xa90>
    0.00 :   ffff80001077d2b0:       b       ffff80001077d398 <arm_smmu_cmdq_issue_cmdlist+0xa90>
         : 40               __lse__cmpxchg_case_32():
         : 366              __CMPXCHG_CASE(w,  ,     , 32,   )
    0.00 :   ffff80001077d2b4:       mov     x0, x4
    0.00 :   ffff80001077d2b8:       mov     w1, w3
    0.00 :   ffff80001077d2bc:       mov     w7, w1
    0.00 :   ffff80001077d2c0:       cas     w7, w2, [x4]
    0.00 :   ffff80001077d2c4:       mov     w0, w7
         : 372              arm_smmu_cmdq_shared_lock():
    0.00 :   ffff80001077d2c8:       cmp     w0, w3
    0.00 :   ffff80001077d2cc:       b.ne    ffff80001077d2a0 <arm_smmu_cmdq_issue_cmdlist+0x998>  // b.any
    0.00 :   ffff80001077d2d0:       b       ffff80001077cf3c <arm_smmu_cmdq_issue_cmdlist+0x634>
         : 454              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001077d2d4:       nop
    0.03 :   ffff80001077d2d8:       mov     x0, #0x60                       // #96
         : 24               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001077d2dc:       msr     daifset, #0x3
    0.23 :   ffff80001077d2e0:       b       ffff80001077c9a8 <arm_smmu_cmdq_issue_cmdlist+0xa0>
         : 57               queue_consumed():
         :
    0.00 :   ffff80001077d2e4:       cmp     w27, w1
    0.00 :   ffff80001077d2e8:       b.cc    ffff80001077d178 <arm_smmu_cmdq_issue_cmdlist+0x870>  // b.lo, b.ul, b.last
         : 152              __arm_smmu_cmdq_poll_until_consumed():
         : 661              * set_valid_map();
    0.00 :   ffff80001077d2ec:       add     x0, sp, #0xc0
    0.00 :   ffff80001077d2f0:       bl      ffff80001077bd60 <queue_poll>
         : 664              __raw_readl():
         : 75               asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    0.00 :   ffff80001077d2f4:       ldr     x1, [x24, #176]
    0.00 :   ffff80001077d2f8:       ldr     w1, [x1]
         : 78               __arm_smmu_cmdq_poll_until_consumed():
         : 691              int i;
    0.00 :   ffff80001077d2fc:       dmb     oshld
    0.00 :   ffff80001077d300:       mov     w2, w1
    0.00 :   ffff80001077d304:       eor     x2, x2, x2
    0.00 :   ffff80001077d308:       cbnz    x2, ffff80001077d308 <arm_smmu_cmdq_issue_cmdlist+0xa00>
    0.00 :   ffff80001077d30c:       str     w1, [x21, #4]
         : 692              struct arm_smmu_ll_queue llq = {
    0.00 :   ffff80001077d310:       cbz     w0, ffff80001077d160 <arm_smmu_cmdq_issue_cmdlist+0x858>
    0.00 :   ffff80001077d314:       mov     x5, x23
    0.00 :   ffff80001077d318:       mov     w6, w0
    0.00 :   ffff80001077d31c:       ldr     x23, [sp, #112]
         : 697              arm_smmu_cmdq_issue_cmdlist():
         : 976              *
    0.00 :   ffff80001077d320:       adrp    x1, ffff8000110af000 <qcom_smmu_client_of_match+0x568>
    0.00 :   ffff80001077d324:       adrp    x0, ffff800011ea3000 <dev_attr_pcr_sha1_19+0x20>
    0.00 :   ffff80001077d328:       add     x1, x1, #0x988
    0.00 :   ffff80001077d32c:       add     x0, x0, #0xb90
    0.00 :   ffff80001077d330:       add     x1, x1, #0x20
    0.00 :   ffff80001077d334:       add     x0, x0, #0x140
    0.00 :   ffff80001077d338:       str     x5, [sp, #104]
    0.00 :   ffff80001077d33c:       str     w6, [sp, #112]
    0.00 :   ffff80001077d340:       bl      ffff8000104b30d8 <___ratelimit>
    0.00 :   ffff80001077d344:       ldr     w6, [sp, #112]
    0.00 :   ffff80001077d348:       ldr     x5, [sp, #104]
    0.00 :   ffff80001077d34c:       cbz     w0, ffff80001077d180 <arm_smmu_cmdq_issue_cmdlist+0x878>
         : 989              __raw_readl():
    0.00 :   ffff80001077d350:       str     w6, [sp, #112]
    0.00 :   ffff80001077d354:       ldr     x3, [x24, #168]
    0.00 :   ffff80001077d358:       ldr     w3, [x3]
    0.00 :   ffff80001077d35c:       ldr     x4, [x24, #176]
    0.00 :   ffff80001077d360:       ldr     w4, [x4]
         : 80               arm_smmu_cmdq_issue_cmdlist():
    0.00 :   ffff80001077d364:       ldr     w2, [x23, #128]
    0.00 :   ffff80001077d368:       adrp    x1, ffff8000114d7000 <kallsyms_token_index+0xcc7a0>
    0.00 :   ffff80001077d36c:       ldr     x0, [x28]
    0.00 :   ffff80001077d370:       add     x1, x1, #0x4e0
    0.00 :   ffff80001077d374:       bl      ffff800010e1fd58 <_dev_err>
    0.00 :   ffff80001077d378:       ldr     w6, [sp, #112]
    0.00 :   ffff80001077d37c:       ldr     x5, [sp, #104]
    0.00 :   ffff80001077d380:       b       ffff80001077d180 <arm_smmu_cmdq_issue_cmdlist+0x878>
         : 984              arch_static_branch():
    0.00 :   ffff80001077d384:       mov     x0, #0xa0                       // #160
    0.00 :   ffff80001077d388:       b       ffff80001077d2dc <arm_smmu_cmdq_issue_cmdlist+0x9d4>
         : 23               __ll_sc_atomic_fetch_add_relaxed():
         : 111              ATOMIC_OPS(add, add, I)
    0.00 :   ffff80001077d38c:       add     x3, x28, #0x10c
    0.00 :   ffff80001077d390:       b       ffff800010780c2c <arm_smmu_tlb_inv_range_asid+0x2b4>
    0.00 :   ffff80001077d394:       b       ffff80001077d27c <arm_smmu_cmdq_issue_cmdlist+0x974>
         : 115              atomic_cmpxchg_relaxed():
         :
    0.00 :   ffff80001077d398:       sxtw    x1, w3
         : 687              __ll_sc__cmpxchg_case_32():
         : 301              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
    0.00 :   ffff80001077d39c:       b       ffff800010780c44 <arm_smmu_tlb_inv_range_asid+0x2cc>
    0.00 :   ffff80001077d3a0:       b       ffff80001077d2c8 <arm_smmu_cmdq_issue_cmdlist+0x9c0>
         : 304              arm_smmu_cmdq_issue_cmdlist():
         : 988              struct arm_smmu_device *smmu = smmu_domain->smmu;
    0.00 :   ffff80001077d3a4:       dmb     ish
         :
    0.02 :   ffff80001077d3a8:       ldr     w1, [x21, #4]
         : 990              if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
    0.00 :   ffff80001077d3ac:       mov     x0, x24
         :
    0.00 :   ffff80001077d3b0:       str     w1, [x28, #68]
         : 990              if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
    0.00 :   ffff80001077d3b4:       bl      ffff80001077c700 <arm_smmu_cmdq_shared_unlock>
    0.00 :   ffff80001077d3b8:       ldr     w6, [sp, #112]
    0.00 :   ffff80001077d3bc:       ldr     x5, [sp, #104]
    0.00 :   ffff80001077d3c0:       b       ffff80001077cf80 <arm_smmu_cmdq_issue_cmdlist+0x678>
         : 995              __arm_smmu_cmdq_poll_until_msi():
         : 629              static int __arm_smmu_cmdq_poll_until_consumed(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077d3c4:       ldr     w3, [x24, #68]
         : 631              queue_poll_init():
         : 199              } else {
    0.01 :   ffff80001077d3c8:       mov     x2, #0x1                        // #1
         : 201              __arm_smmu_cmdq_poll_until_msi():
         : 629              static int __arm_smmu_cmdq_poll_until_consumed(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077d3cc:       mov     w19, #0x1                       // #1
         : 631              queue_poll_init():
         : 199              } else {
    0.01 :   ffff80001077d3d0:       str     x2, [sp, #200]
         : 201              __arm_smmu_cmdq_poll_until_msi():
         : 629              static int __arm_smmu_cmdq_poll_until_consumed(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077d3d4:       ldr     x2, [x24, #136]
    0.00 :   ffff80001077d3d8:       lsl     w19, w19, w3
    0.00 :   ffff80001077d3dc:       sub     w19, w19, #0x1
    0.01 :   ffff80001077d3e0:       str     x2, [sp, #104]
    0.00 :   ffff80001077d3e4:       ldr     x0, [x24, #160]
    0.00 :   ffff80001077d3e8:       and     w19, w19, w26
    0.00 :   ffff80001077d3ec:       str     x5, [sp, #112]
         : 637              queue_poll_init():
         : 201              qp->delay *= 2;
    0.00 :   ffff80001077d3f0:       strb    w1, [sp, #208]
         : 203              __arm_smmu_cmdq_poll_until_msi():
         : 629              static int __arm_smmu_cmdq_poll_until_consumed(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077d3f4:       mul     x19, x19, x0
         : 631              queue_poll_init():
         : 202              qp->spin_cnt = 0;
    0.00 :   ffff80001077d3f8:       bl      ffff800010110e30 <ktime_get>
         : 204              __arm_smmu_cmdq_poll_until_msi():
         : 638              llq->val = READ_ONCE(smmu->cmdq.q.llq.val);
    0.00 :   ffff80001077d3fc:       ldp     x2, x5, [sp, #104]
         : 640              ktime_add_us():
    0.00 :   ffff80001077d400:       mov     x1, #0xca00                     // #51712
         : 182              __arm_smmu_cmdq_poll_until_msi():
         : 629              static int __arm_smmu_cmdq_poll_until_consumed(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077d404:       lsl     x19, x19, #3
         : 631              ktime_add_us():
    0.00 :   ffff80001077d408:       movk    x1, #0x3b9a, lsl #16
    0.00 :   ffff80001077d40c:       add     x0, x0, x1
         : 183              queue_poll_init():
         : 202              qp->spin_cnt = 0;
    0.02 :   ffff80001077d410:       str     x0, [sp, #192]
         : 204              __arm_smmu_cmdq_poll_until_msi():
         : 637              queue_poll_init(smmu, &qp);
    0.00 :   ffff80001077d414:       strb    wzr, [sp, #208]
         : 629              static int __arm_smmu_cmdq_poll_until_consumed(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077d418:       add     x20, x2, x19
         : 638              llq->val = READ_ONCE(smmu->cmdq.q.llq.val);
    0.00 :   ffff80001077d41c:       ldr     w19, [x2, x19]
    0.00 :   ffff80001077d420:       cbz     w19, ffff80001077d478 <arm_smmu_cmdq_issue_cmdlist+0xb70>
    0.57 :   ffff80001077d424:       mov     x26, x5
    0.00 :   ffff80001077d428:       b       ffff80001077d450 <arm_smmu_cmdq_issue_cmdlist+0xb48>
    0.02 :   ffff80001077d42c:       mov     w19, w19
         : 644              __cmpwait_case_32():
    0.00 :   ffff80001077d430:       sevl
    0.00 :   ffff80001077d434:       wfe
    0.55 :   ffff80001077d438:       ldxr    w0, [x20]
    0.00 :   ffff80001077d43c:       eor     w0, w0, w19
    0.00 :   ffff80001077d440:       cbnz    w0, ffff80001077d448 <arm_smmu_cmdq_issue_cmdlist+0xb40>
    0.57 :   ffff80001077d444:       wfe
         : 258              __arm_smmu_cmdq_poll_until_msi():
    3.21 :   ffff80001077d448:       ldr     w19, [x20]
    0.00 :   ffff80001077d44c:       cbz     w19, ffff80001077d470 <arm_smmu_cmdq_issue_cmdlist+0xb68>
    2.30 :   ffff80001077d450:       add     x0, sp, #0xc0
    0.00 :   ffff80001077d454:       bl      ffff80001077bd60 <queue_poll>
    0.00 :   ffff80001077d458:       cbz     w0, ffff80001077d42c <arm_smmu_cmdq_issue_cmdlist+0xb24>
    0.00 :   ffff80001077d45c:       mov     w6, w0
         : 639              do {
    0.00 :   ffff80001077d460:       ldr     w0, [x23, #128]
    0.00 :   ffff80001077d464:       mov     x5, x26
    0.00 :   ffff80001077d468:       str     w0, [x21, #4]
         : 643              arm_smmu_cmdq_issue_cmdlist():
         : 975              * This function handles the following cases:
    0.00 :   ffff80001077d46c:       b       ffff80001077d320 <arm_smmu_cmdq_issue_cmdlist+0xa18>
    2.54 :   ffff80001077d470:       mov     x5, x26
    0.00 :   ffff80001077d474:       ldr     w26, [x23, #128]
         : 979              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    1.13 :   ffff80001077d478:       ldr     w1, [sp, #184]
         : 194              __arm_smmu_cmdq_poll_until_msi():
    0.00 :   ffff80001077d47c:       mov     w6, #0x0                        // #0
         : 193              queue_inc_prod_n():
    0.00 :   ffff80001077d480:       and     w0, w1, w26
         : 193              return -ETIMEDOUT;
    0.00 :   ffff80001077d484:       and     w26, w26, #0x80000000
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.05 :   ffff80001077d488:       add     w0, w0, #0x1
         : 193              return -ETIMEDOUT;
    0.00 :   ffff80001077d48c:       and     w27, w0, w1
    0.00 :   ffff80001077d490:       orr     w26, w27, w26
         : 196              __arm_smmu_cmdq_poll_until_msi():
         : 639              do {
    0.00 :   ffff80001077d494:       str     w26, [x21, #4]
         : 641              arm_smmu_cmdq_issue_cmdlist():
         : 975              * This function handles the following cases:
    0.00 :   ffff80001077d498:       b       ffff80001077d180 <arm_smmu_cmdq_issue_cmdlist+0x878>
         : 1001             val = 0;
    0.00 :   ffff80001077d49c:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (13033 samples, percent: local period)
------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010780388 <arm_smmu_tlb_inv_range_domain>:
         : 6                arm_smmu_tlb_inv_range_domain():
         : 2091             struct arm_smmu_device *smmu = master->smmu;
         :
         : 2093             for (i = 0; i < master->num_streams; ++i) {
         : 2094             u32 sid = master->streams[i].id;
         : 2095             __le64 *step = arm_smmu_get_step_for_sid(smmu, sid);
         :
    0.00 :   ffff800010780388:       paciasp
    0.00 :   ffff80001078038c:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff800010780390:       mov     x29, sp
    0.00 :   ffff800010780394:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010780398:       mov     x19, x4
    0.00 :   ffff80001078039c:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.02 :   ffff8000107803a0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000107803a4:       add     x20, x20, #0x948
    0.00 :   ffff8000107803a8:       ldr     x4, [x20]
    0.08 :   ffff8000107803ac:       str     x4, [sp, #88]
    0.00 :   ffff8000107803b0:       mov     x4, #0x0                        // #0
         : 2098             for (j = 0; j < i; j++)
         : 2099             if (master->streams[j].id == sid)
         : 2100             break;
         : 2101             if (j < i)
         : 2102             continue;
         :
    0.00 :   ffff8000107803b4:       ldr     w5, [x19, #52]
         :
    0.00 :   ffff8000107803b8:       mov     x21, x0
         : 2092             /* Bridged PCI devices may end up with duplicated IDs */
    0.07 :   ffff8000107803bc:       stp     xzr, xzr, [sp, #56]
         :
    0.00 :   ffff8000107803c0:       mov     x22, x1
         : 2092             /* Bridged PCI devices may end up with duplicated IDs */
    0.00 :   ffff8000107803c4:       strb    w3, [sp, #70]
    0.02 :   ffff8000107803c8:       stp     xzr, xzr, [sp, #72]
    0.01 :   ffff8000107803cc:       ldr     x4, [x19]
         :
    0.00 :   ffff8000107803d0:       cbnz    w5, ffff800010780444 <arm_smmu_tlb_inv_range_domain+0xbc>
         : 2099             arm_smmu_write_strtab_ent(master, sid, step);
    0.05 :   ffff8000107803d4:       ldr     w3, [x4, #24]
    0.00 :   ffff8000107803d8:       mov     w0, #0x22                       // #34
         : 2101             }
         : 2102             }
   99.69 :   ffff8000107803dc:       ldrh    w5, [x19, #88]
         : 2099             arm_smmu_write_strtab_ent(master, sid, step);
    0.00 :   ffff8000107803e0:       mov     w1, #0x12                       // #18
         : 2101             }
    0.00 :   ffff8000107803e4:       strh    w5, [sp, #66]
         : 2099             arm_smmu_write_strtab_ent(master, sid, step);
    0.00 :   ffff8000107803e8:       tst     x3, #0x40000
    0.00 :   ffff8000107803ec:       csel    w0, w0, w1, ne  // ne = any
    0.00 :   ffff8000107803f0:       strb    w0, [sp, #56]
         :
         : 2107             static bool arm_smmu_ats_supported(struct arm_smmu_master *master)
         : 2108             {
         : 2109             struct device *dev = master->dev;
         : 2110             struct arm_smmu_device *smmu = master->smmu;
    0.00 :   ffff8000107803f4:       add     x5, x19, #0xa0
    0.00 :   ffff8000107803f8:       mov     x3, x2
    0.00 :   ffff8000107803fc:       mov     x1, x21
    0.00 :   ffff800010780400:       mov     x2, x22
    0.00 :   ffff800010780404:       add     x0, sp, #0x38
    0.00 :   ffff800010780408:       bl      ffff80001077e430 <__arm_smmu_tlb_inv_range.isra.36>
         : 2112             struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
         :
         : 2114             if (!(smmu->features & ARM_SMMU_FEAT_ATS))
         : 2115             return false;
         :
         : 2117             if (!(fwspec->flags & IOMMU_FWSPEC_PCI_RC_ATS))
    0.00 :   ffff80001078040c:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010780410:       mov     x3, x22
    0.00 :   ffff800010780414:       mov     x2, x21
    0.00 :   ffff800010780418:       mov     x0, x19
    0.01 :   ffff80001078041c:       bl      ffff8000107801a0 <arm_smmu_atc_inv_domain>
         : 2113             return false;
    0.00 :   ffff800010780420:       ldr     x1, [sp, #88]
    0.00 :   ffff800010780424:       ldr     x0, [x20]
    0.00 :   ffff800010780428:       eor     x0, x1, x0
    0.00 :   ffff80001078042c:       cbnz    x0, ffff800010780458 <arm_smmu_tlb_inv_range_domain+0xd0>
    0.00 :   ffff800010780430:       ldp     x19, x20, [sp, #16]
    0.05 :   ffff800010780434:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010780438:       ldp     x29, x30, [sp], #96
    0.00 :   ffff80001078043c:       autiasp
    0.00 :   ffff800010780440:       ret
         : 2104             {
    0.00 :   ffff800010780444:       ldrh    w0, [x19, #56]
         : 2103             static bool arm_smmu_ats_supported(struct arm_smmu_master *master)
    0.00 :   ffff800010780448:       mov     w1, #0x2a                       // #42
    0.00 :   ffff80001078044c:       strb    w1, [sp, #56]
         : 2104             {
    0.00 :   ffff800010780450:       strh    w0, [sp, #68]
    0.00 :   ffff800010780454:       b       ffff8000107803f4 <arm_smmu_tlb_inv_range_domain+0x6c>
         : 2113             return false;
    0.00 :   ffff800010780458:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (11948 samples, percent: local period)
------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000107801a0 <arm_smmu_atc_inv_domain>:
         : 6                arm_smmu_atc_inv_domain():
         : 1960             arm_smmu_free_asid(&cfg->cd);
         : 1961             out_unlock:
         : 1962             mutex_unlock(&arm_smmu_asid_lock);
         : 1963             return ret;
         : 1964             }
         :
    0.00 :   ffff8000107801a0:       paciasp
    0.00 :   ffff8000107801a4:       sub     sp, sp, #0x480
    0.00 :   ffff8000107801a8:       stp     x29, x30, [sp]
    0.00 :   ffff8000107801ac:       mov     x29, sp
    0.01 :   ffff8000107801b0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000107801b4:       mov     x21, x0
    0.00 :   ffff8000107801b8:       mov     x22, x2
    0.00 :   ffff8000107801bc:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000107801c0:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000107801c4:       add     x24, x24, #0x948
    0.00 :   ffff8000107801c8:       ldr     x0, [x24]
    0.02 :   ffff8000107801cc:       str     x0, [sp, #1144]
    0.00 :   ffff8000107801d0:       mov     x0, #0x0                        // #0
         : 1965             static int arm_smmu_domain_finalise_s2(struct arm_smmu_domain *smmu_domain,
         : 1966             struct arm_smmu_master *master,
         : 1967             struct io_pgtable_cfg *pgtbl_cfg)
         : 1968             {
         : 1969             int vmid;
    0.00 :   ffff8000107801d4:       mov     x2, #0x408                      // #1032
    0.00 :   ffff8000107801d8:       add     x0, sp, #0x70
         :
    0.00 :   ffff8000107801dc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000107801e0:       mov     w20, w1
    0.00 :   ffff8000107801e4:       mov     x19, x3
         : 1965             int vmid;
    0.00 :   ffff8000107801e8:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000107801ec:       bl      ffff8000104a5e40 <__memset>
         : 1967             struct arm_smmu_device *smmu = smmu_domain->smmu;
         : 1968             struct arm_smmu_s2_cfg *cfg = &smmu_domain->s2_cfg;
    0.08 :   ffff8000107801f0:       ldr     x0, [x21]
    0.02 :   ffff8000107801f4:       ldr     w0, [x0, #24]
    0.00 :   ffff8000107801f8:       tbz     w0, #5, ffff800010780340 <arm_smmu_atc_inv_domain+0x1a0>
         : 1983             FIELD_PREP(STRTAB_STE_2_VTCR_S2SL0, vtcr->sl) |
         : 1984             FIELD_PREP(STRTAB_STE_2_VTCR_S2IR0, vtcr->irgn) |
         : 1985             FIELD_PREP(STRTAB_STE_2_VTCR_S2OR0, vtcr->orgn) |
         : 1986             FIELD_PREP(STRTAB_STE_2_VTCR_S2SH0, vtcr->sh) |
         : 1987             FIELD_PREP(STRTAB_STE_2_VTCR_S2TG, vtcr->tg) |
         : 1988             FIELD_PREP(STRTAB_STE_2_VTCR_S2PS, vtcr->ps);
   99.26 :   ffff8000107801fc:       dmb     ish
         : 1990             atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.53 :   ffff800010780200:       ldr     w0, [x21, #48]
         : 35               arm_smmu_atc_inv_domain():
         : 1984             return 0;
    0.00 :   ffff800010780204:       cbz     w0, ffff800010780340 <arm_smmu_atc_inv_domain+0x1a0>
         : 1986             arm_smmu_atc_inv_to_cmd():
         :
    0.00 :   ffff800010780208:       add     x0, sp, #0x2
    0.00 :   ffff80001078020c:       stp     x25, x26, [sp, #64]
         : 1902             }
    0.00 :   ffff800010780210:       cmp     w20, #0x0
         :
    0.00 :   ffff800010780214:       mov     w1, #0x40                       // #64
    0.00 :   ffff800010780218:       strb    w1, [sp, #80]
    0.00 :   ffff80001078021c:       stp     xzr, xzr, [x0, #80]
         : 1902             }
    0.00 :   ffff800010780220:       cset    w0, ne  // ne = any
    0.00 :   ffff800010780224:       strb    w0, [sp, #81]
         :
    0.00 :   ffff800010780228:       str     w20, [sp, #92]
    0.00 :   ffff80001078022c:       stur    xzr, [sp, #98]
    0.00 :   ffff800010780230:       stur    wzr, [sp, #106]
    0.00 :   ffff800010780234:       strh    wzr, [sp, #110]
         : 1906             struct io_pgtable_cfg *pgtbl_cfg)
    0.00 :   ffff800010780238:       cbz     x19, ffff800010780370 <arm_smmu_atc_inv_domain+0x1d0>
         : 1912             typeof(&pgtbl_cfg->arm_lpae_s1_cfg.tcr) tcr = &pgtbl_cfg->arm_lpae_s1_cfg.tcr;
    0.00 :   ffff80001078023c:       sub     x0, x19, #0x1
         : 1911             struct arm_smmu_s1_cfg *cfg = &smmu_domain->s1_cfg;
    0.00 :   ffff800010780240:       lsr     x2, x22, #12
         : 1912             typeof(&pgtbl_cfg->arm_lpae_s1_cfg.tcr) tcr = &pgtbl_cfg->arm_lpae_s1_cfg.tcr;
    0.00 :   ffff800010780244:       add     x0, x0, x22
         : 1914             fls64():
         : 29               return fls(x);
         : 30               }
         : 31               #elif BITS_PER_LONG == 64
         : 32               static __always_inline int fls64(__u64 x)
         : 33               {
         : 34               if (x == 0)
    0.00 :   ffff800010780248:       mov     w1, #0x0                        // #0
         : 36               arm_smmu_atc_inv_to_cmd():
    0.00 :   ffff80001078024c:       lsr     x0, x0, #12
         : 1913             fls64():
    0.00 :   ffff800010780250:       cmp     x2, x0
    0.00 :   ffff800010780254:       b.eq    ffff80001078027c <arm_smmu_atc_inv_domain+0xdc>  // b.none
         : 31               arm_smmu_atc_inv_to_cmd():
         : 1934             FIELD_PREP(CTXDESC_CD_0_TCR_ORGN0, tcr->orgn) |
    0.00 :   ffff800010780258:       eor     x0, x2, x0
         : 1936             __fls():
         : 13               *
         : 14               * Undefined if no set bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __fls(unsigned long word)
         : 17               {
         : 18               return (sizeof(word) * 8) - 1 - __builtin_clzl(word);
    0.00 :   ffff80001078025c:       mov     x1, #0x3f                       // #63
    0.00 :   ffff800010780260:       clz     x0, x0
    0.00 :   ffff800010780264:       mov     x3, #0xffffffffffffffff         // #-1
    0.00 :   ffff800010780268:       sub     x0, x1, x0
         : 23               fls64():
         : 31               return 0;
         : 32               return __fls(x) + 1;
    0.00 :   ffff80001078026c:       add     w0, w0, #0x1
    0.00 :   ffff800010780270:       and     w1, w0, #0xff
    0.00 :   ffff800010780274:       lsl     x0, x3, x0
    0.00 :   ffff800010780278:       and     x0, x0, x2
         : 37               arm_smmu_atc_inv_to_cmd():
         :
    0.00 :   ffff80001078027c:       lsl     x0, x0, #12
    0.00 :   ffff800010780280:       str     x0, [sp, #96]
         : 1940             /*
    0.00 :   ffff800010780284:       strb    w1, [sp, #104]
         : 1942             arm_smmu_atc_inv_domain():
         : 1990             }
         :
         : 1992             static int arm_smmu_domain_finalise(struct iommu_domain *domain,
         : 1993             struct arm_smmu_master *master)
         : 1994             {
         : 1995             int ret;
    0.00 :   ffff800010780288:       mov     x23, x21
         : 1997             spinlock_check():
         : 329              * Map the spin_lock functions to the raw variants for PREEMPT_RT=n
         : 330              */
         :
         : 332              static __always_inline raw_spinlock_t *spinlock_check(spinlock_t *lock)
         : 333              {
         : 334              return &lock->rlock;
    0.00 :   ffff80001078028c:       add     x25, x21, #0xe8
         : 336              arm_smmu_atc_inv_domain():
         : 1989             {
    0.00 :   ffff800010780290:       mov     x0, x25
    0.00 :   ffff800010780294:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 1995             unsigned long ias, oas;
         : 1996             enum io_pgtable_fmt fmt;
         : 1997             struct io_pgtable_cfg pgtbl_cfg;
         : 1998             struct io_pgtable_ops *pgtbl_ops;
         : 1999             int (*finalise_stage_fn)(struct arm_smmu_domain *,
    0.00 :   ffff800010780298:       mov     w22, #0x28                      // #40
         : 1989             {
    0.00 :   ffff80001078029c:       mov     x26, x0
         : 1990             int ret;
    0.00 :   ffff8000107802a0:       ldr     x20, [x23, #216]!
    0.00 :   ffff8000107802a4:       cmp     x23, x20
    0.00 :   ffff8000107802a8:       sub     x20, x20, #0x18
    0.00 :   ffff8000107802ac:       b.ne    ffff8000107802c4 <arm_smmu_atc_inv_domain+0x124>  // b.any
    0.00 :   ffff8000107802b0:       b       ffff800010780318 <arm_smmu_atc_inv_domain+0x178>
    0.00 :   ffff8000107802b4:       ldr     x20, [x20, #24]
    0.00 :   ffff8000107802b8:       cmp     x23, x20
    0.00 :   ffff8000107802bc:       sub     x20, x20, #0x18
    0.00 :   ffff8000107802c0:       b.eq    ffff800010780318 <arm_smmu_atc_inv_domain+0x178>  // b.none
         : 1991             unsigned long ias, oas;
    0.00 :   ffff8000107802c4:       ldrb    w0, [x20, #52]
    0.00 :   ffff8000107802c8:       cbz     w0, ffff8000107802b4 <arm_smmu_atc_inv_domain+0x114>
         : 1994             struct io_pgtable_ops *pgtbl_ops;
    0.00 :   ffff8000107802cc:       ldr     w0, [x20, #48]
    0.00 :   ffff8000107802d0:       cbz     w0, ffff8000107802b4 <arm_smmu_atc_inv_domain+0x114>
    0.00 :   ffff8000107802d4:       mov     w19, #0x0                       // #0
         : 1995             int (*finalise_stage_fn)(struct arm_smmu_domain *,
    0.00 :   ffff8000107802d8:       smull   x3, w19, w22
         : 1996             struct arm_smmu_master *,
    0.00 :   ffff8000107802dc:       add     x2, sp, #0x50
         : 1995             int (*finalise_stage_fn)(struct arm_smmu_domain *,
    0.00 :   ffff8000107802e0:       ldr     x4, [x20, #40]
         : 1996             struct arm_smmu_master *,
    0.00 :   ffff8000107802e4:       add     x1, sp, #0x70
    0.00 :   ffff8000107802e8:       ldr     x0, [x21]
         : 1994             struct io_pgtable_ops *pgtbl_ops;
    0.00 :   ffff8000107802ec:       add     w19, w19, #0x1
         : 1995             int (*finalise_stage_fn)(struct arm_smmu_domain *,
    0.00 :   ffff8000107802f0:       ldr     w3, [x4, x3]
    0.00 :   ffff8000107802f4:       str     w3, [sp, #88]
         : 1996             struct arm_smmu_master *,
    0.00 :   ffff8000107802f8:       bl      ffff80001077e290 <arm_smmu_cmdq_batch_add>
         : 1994             struct io_pgtable_ops *pgtbl_ops;
    0.00 :   ffff8000107802fc:       ldr     w0, [x20, #48]
    0.00 :   ffff800010780300:       cmp     w0, w19
    0.00 :   ffff800010780304:       b.hi    ffff8000107802d8 <arm_smmu_atc_inv_domain+0x138>  // b.pmore
         : 1990             int ret;
    0.00 :   ffff800010780308:       ldr     x20, [x20, #24]
    0.00 :   ffff80001078030c:       cmp     x23, x20
    0.00 :   ffff800010780310:       sub     x20, x20, #0x18
    0.00 :   ffff800010780314:       b.ne    ffff8000107802c4 <arm_smmu_atc_inv_domain+0x124>  // b.any
         : 1995             spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff800010780318:       mov     x1, x26
    0.00 :   ffff80001078031c:       mov     x0, x25
    0.00 :   ffff800010780320:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 418              arm_smmu_cmdq_batch_submit():
         : 1214             case ARM_SMMU_DOMAIN_S1:
    0.00 :   ffff800010780324:       ldr     w2, [sp, #1136]
    0.00 :   ffff800010780328:       ldr     x0, [x21]
    0.00 :   ffff80001078032c:       add     x1, sp, #0x70
    0.00 :   ffff800010780330:       mov     w3, #0x1                        // #1
    0.00 :   ffff800010780334:       bl      ffff80001077c908 <arm_smmu_cmdq_issue_cmdlist>
         : 1220             arm_smmu_atc_inv_domain():
         : 2001             struct io_pgtable_cfg *);
         : 2002             struct arm_smmu_domain *smmu_domain = to_smmu_domain(domain);
         : 2003             struct arm_smmu_device *smmu = smmu_domain->smmu;
         :
         : 2005             if (domain->type == IOMMU_DOMAIN_IDENTITY) {
    0.00 :   ffff800010780338:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078033c:       b       ffff800010780344 <arm_smmu_atc_inv_domain+0x1a4>
         : 1968             typeof(&pgtbl_cfg->arm_lpae_s2_cfg.vtcr) vtcr;
    0.00 :   ffff800010780340:       mov     w0, #0x0                        // #0
         : 2002             smmu_domain->stage = ARM_SMMU_DOMAIN_BYPASS;
    0.00 :   ffff800010780344:       ldr     x2, [sp, #1144]
    0.00 :   ffff800010780348:       ldr     x1, [x24]
    0.00 :   ffff80001078034c:       eor     x1, x2, x1
    0.00 :   ffff800010780350:       cbnz    x1, ffff80001078037c <arm_smmu_atc_inv_domain+0x1dc>
    0.06 :   ffff800010780354:       ldp     x29, x30, [sp]
    0.00 :   ffff800010780358:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078035c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010780360:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010780364:       add     sp, sp, #0x480
    0.00 :   ffff800010780368:       autiasp
    0.03 :   ffff80001078036c:       ret
         : 2014             arm_smmu_atc_inv_to_cmd():
         : 1907             {
    0.00 :   ffff800010780370:       mov     w0, #0x34                       // #52
    0.00 :   ffff800010780374:       strb    w0, [sp, #104]
         : 1908             int ret;
    0.00 :   ffff800010780378:       b       ffff800010780288 <arm_smmu_atc_inv_domain+0xe8>
    0.00 :   ffff80001078037c:       stp     x25, x26, [sp, #64]
         : 1911             arm_smmu_atc_inv_domain():
         : 2002             smmu_domain->stage = ARM_SMMU_DOMAIN_BYPASS;
    0.00 :   ffff800010780380:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (8931 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077e430 <__arm_smmu_tlb_inv_range.isra.36>:
         : 6                __arm_smmu_tlb_inv_range():
         : 2029             fmt = ARM_64_LPAE_S2;
         : 2030             finalise_stage_fn = arm_smmu_domain_finalise_s2;
         : 2031             break;
         : 2032             default:
         : 2033             return -EINVAL;
         : 2034             }
    0.06 :   ffff80001077e430:       paciasp
    0.00 :   ffff80001077e434:       sub     sp, sp, #0x460
    0.00 :   ffff80001077e438:       stp     x29, x30, [sp]
    0.00 :   ffff80001077e43c:       mov     x29, sp
    0.00 :   ffff80001077e440:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001077e444:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001077e448:       add     x24, x24, #0x948
    0.07 :   ffff80001077e44c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001077e450:       mov     x20, x0
    0.00 :   ffff80001077e454:       ldr     x0, [x24]
    0.00 :   ffff80001077e458:       str     x0, [sp, #1112]
    0.00 :   ffff80001077e45c:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001077e460:       mov     x23, x2
    0.00 :   ffff80001077e464:       mov     x19, x1
         : 2037             .pgsize_bitmap  = smmu->pgsize_bitmap,
         : 2038             .ias            = ias,
         : 2039             .oas            = oas,
         : 2040             .coherent_walk  = smmu->features & ARM_SMMU_FEAT_COHERENCY,
         : 2041             .tlb            = &arm_smmu_flush_ops,
         : 2042             .iommu_dev      = smmu->dev,
    0.00 :   ffff80001077e468:       add     x0, sp, #0x50
    0.00 :   ffff80001077e46c:       mov     x2, #0x408                      // #1032
    0.00 :   ffff80001077e470:       mov     w1, #0x0                        // #0
         : 2029             }
    0.09 :   ffff80001077e474:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001077e478:       mov     x21, x3
    0.00 :   ffff80001077e47c:       mov     x22, x4
    0.00 :   ffff80001077e480:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001077e484:       mov     x25, x5
         : 2037             .iommu_dev      = smmu->dev,
    0.00 :   ffff80001077e488:       bl      ffff8000104a5e40 <__memset>
         : 2039             };
         :
    0.08 :   ffff80001077e48c:       cbz     x23, ffff80001077e518 <__arm_smmu_tlb_inv_range.isra.36+0xe8>
         : 2042             if (!iommu_get_dma_strict(domain))
         : 2043             pgtbl_cfg.quirks |= IO_PGTABLE_QUIRK_NON_STRICT;
         :
    0.00 :   ffff80001077e490:       ldr     w0, [x22, #24]
    0.00 :   ffff80001077e494:       tbnz    w0, #15, ffff80001077e548 <__arm_smmu_tlb_inv_range.isra.36+0x118>
         : 2035             .coherent_walk  = smmu->features & ARM_SMMU_FEAT_COHERENCY,
   76.09 :   ffff80001077e498:       mov     x25, #0x0                       // #0
    0.00 :   ffff80001077e49c:       mov     x26, #0x0                       // #0
    0.00 :   ffff80001077e4a0:       add     x23, x19, x23
         :
         : 2056             ret = finalise_stage_fn(smmu_domain, master, &pgtbl_cfg);
         : 2057             if (ret < 0) {
         : 2058             free_io_pgtable_ops(pgtbl_ops);
         : 2059             return ret;
         : 2060             }
    0.00 :   ffff80001077e4a4:       cmp     x19, x23
    0.02 :   ffff80001077e4a8:       b.cs    ffff80001077e5a0 <__arm_smmu_tlb_inv_range.isra.36+0x170>  // b.hs, b.nlast
    0.06 :   ffff80001077e4ac:       nop
         :
    0.00 :   ffff80001077e4b0:       ldr     w0, [x22, #24]
    0.00 :   ffff80001077e4b4:       tbz     w0, #15, ffff80001077e4e4 <__arm_smmu_tlb_inv_range.isra.36+0xb4>
         : 2059             __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff80001077e4b8:       rbit    x1, x26
    0.00 :   ffff80001077e4bc:       clz     x1, x1
         : 21               __arm_smmu_tlb_inv_range():
         : 2068             __le64 *step;
         : 2069             struct arm_smmu_strtab_cfg *cfg = &smmu->strtab_cfg;
         :
         : 2071             if (smmu->features & ARM_SMMU_FEAT_2_LVL_STRTAB) {
         : 2072             struct arm_smmu_strtab_l1_desc *l1_desc;
         : 2073             int idx;
    0.00 :   ffff80001077e4c0:       strb    w1, [x20, #9]
         : 2075             /* Two-level walk */
         : 2076             idx = (sid >> STRTAB_SPLIT) * STRTAB_L1_DESC_DWORDS;
         : 2077             l1_desc = &cfg->l1_desc[idx];
         : 2078             idx = (sid & ((1 << STRTAB_SPLIT) - 1)) * STRTAB_STE_DWORDS;
         : 2079             step = &l1_desc->l2ptr[idx];
         : 2080             } else {
    0.00 :   ffff80001077e4c4:       add     w21, w25, w1
         : 2071             idx = (sid >> STRTAB_SPLIT) * STRTAB_L1_DESC_DWORDS;
    0.00 :   ffff80001077e4c8:       lsr     x0, x26, x1
    0.00 :   ffff80001077e4cc:       and     x0, x0, #0x1f
         : 2072             l1_desc = &cfg->l1_desc[idx];
    0.00 :   ffff80001077e4d0:       sub     w2, w0, #0x1
    0.00 :   ffff80001077e4d4:       strb    w2, [x20, #8]
         : 2078             /* Simple linear lookup */
         : 2079             step = &cfg->strtab[sid * STRTAB_STE_DWORDS];
         : 2080             }
    0.00 :   ffff80001077e4d8:       lsl     x2, x0, x1
    0.00 :   ffff80001077e4dc:       sub     x26, x26, x2
         : 2075             } else {
    0.00 :   ffff80001077e4e0:       lsl     x21, x0, x21
         :
         : 2082             return step;
         : 2083             }
   23.13 :   ffff80001077e4e4:       str     x19, [x20, #24]
         :
    0.00 :   ffff80001077e4e8:       mov     x2, x20
    0.00 :   ffff80001077e4ec:       add     x1, sp, #0x50
    0.00 :   ffff80001077e4f0:       mov     x0, x22
         : 2083             static void arm_smmu_install_ste_for_dev(struct arm_smmu_master *master)
    0.04 :   ffff80001077e4f4:       add     x19, x19, x21
         :
    0.00 :   ffff80001077e4f8:       bl      ffff80001077e290 <arm_smmu_cmdq_batch_add>
         : 2055             }
    0.00 :   ffff80001077e4fc:       cmp     x23, x19
    0.00 :   ffff80001077e500:       b.hi    ffff80001077e4b0 <__arm_smmu_tlb_inv_range.isra.36+0x80>  // b.pmore
    0.09 :   ffff80001077e504:       ldr     w2, [sp, #1104]
         : 2059             arm_smmu_cmdq_batch_submit():
         : 1214             case ARM_SMMU_DOMAIN_S1:
    0.00 :   ffff80001077e508:       add     x1, sp, #0x50
    0.00 :   ffff80001077e50c:       mov     x0, x22
    0.00 :   ffff80001077e510:       mov     w3, #0x1                        // #1
    0.23 :   ffff80001077e514:       bl      ffff80001077c908 <arm_smmu_cmdq_issue_cmdlist>
         : 1219             __arm_smmu_tlb_inv_range():
         : 2086             {
         : 2087             int i, j;
         : 2088             struct arm_smmu_device *smmu = master->smmu;
    0.00 :   ffff80001077e518:       ldr     x1, [sp, #1112]
    0.00 :   ffff80001077e51c:       ldr     x0, [x24]
    0.00 :   ffff80001077e520:       eor     x0, x1, x0
    0.00 :   ffff80001077e524:       cbnz    x0, ffff80001077e5a8 <__arm_smmu_tlb_inv_range.isra.36+0x178>
    0.02 :   ffff80001077e528:       ldp     x29, x30, [sp]
    0.00 :   ffff80001077e52c:       ldp     x19, x20, [sp, #16]
    0.01 :   ffff80001077e530:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001077e534:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001077e538:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001077e53c:       add     sp, sp, #0x460
    0.00 :   ffff80001077e540:       autiasp
    0.01 :   ffff80001077e544:       ret
         : 2101             __ffs():
    0.00 :   ffff80001077e548:       ldr     x26, [x25]
    0.00 :   ffff80001077e54c:       clz     x0, x21
    0.00 :   ffff80001077e550:       mov     x1, #0x3f                       // #63
    0.00 :   ffff80001077e554:       sub     x0, x1, x0
    0.00 :   ffff80001077e558:       rbit    x26, x26
    0.00 :   ffff80001077e55c:       sub     w0, w0, #0x3
    0.00 :   ffff80001077e560:       clz     x26, x26
    0.00 :   ffff80001077e564:       cmp     x21, #0x0
    0.00 :   ffff80001077e568:       sxtw    x0, w0
    0.00 :   ffff80001077e56c:       mov     x1, #0xfffffffffffffffc         // #-4
    0.00 :   ffff80001077e570:       sxtw    x25, w26
         : 24               __arm_smmu_tlb_inv_range():
         : 2047             domain->pgsize_bitmap = pgtbl_cfg.pgsize_bitmap;
    0.00 :   ffff80001077e574:       csel    x0, x0, x1, ne  // ne = any
         :
    0.00 :   ffff80001077e578:       sub     x3, x25, #0x3
         : 2047             domain->pgsize_bitmap = pgtbl_cfg.pgsize_bitmap;
    0.00 :   ffff80001077e57c:       sub     x2, x25, #0xa
         :
    0.00 :   ffff80001077e580:       mov     w1, #0x4                        // #4
         : 2052             if (ret < 0) {
    0.00 :   ffff80001077e584:       lsr     x26, x23, x26
         : 2047             domain->pgsize_bitmap = pgtbl_cfg.pgsize_bitmap;
    0.00 :   ffff80001077e588:       lsr     x2, x2, #1
    0.00 :   ffff80001077e58c:       strb    w2, [x20, #16]
         :
    0.00 :   ffff80001077e590:       udiv    x0, x0, x3
    0.00 :   ffff80001077e594:       sub     w0, w1, w0
    0.00 :   ffff80001077e598:       strb    w0, [x20, #15]
         : 2052             if (ret < 0) {
    0.00 :   ffff80001077e59c:       b       ffff80001077e4a0 <__arm_smmu_tlb_inv_range.isra.36+0x70>
         : 2055             }
    0.00 :   ffff80001077e5a0:       mov     w2, #0x0                        // #0
    0.00 :   ffff80001077e5a4:       b       ffff80001077e508 <__arm_smmu_tlb_inv_range.isra.36+0xd8>
         : 2086             struct arm_smmu_device *smmu = master->smmu;
    0.00 :   ffff80001077e5a8:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (3788 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e35380 <_raw_spin_unlock_irqrestore>:
         : 6                _raw_spin_unlock_irqrestore():
         : 190              EXPORT_SYMBOL(_raw_spin_unlock);
         : 191              #endif
         :
         : 193              #ifndef CONFIG_INLINE_SPIN_UNLOCK_IRQRESTORE
         : 194              void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)
         : 195              {
    0.79 :   ffff800010e35380:       paciasp
    0.00 :   ffff800010e35384:       stp     x29, x30, [sp, #-16]!
         : 198              queued_spin_unlock():
         : 99               static __always_inline void queued_spin_unlock(struct qspinlock *lock)
         : 100              {
         : 101              /*
         : 102              * unlock() needs release semantics:
         : 103              */
         : 104              smp_store_release(&lock->locked, 0);
    0.00 :   ffff800010e35388:       mov     w2, #0x0                        // #0
         : 106              _raw_spin_unlock_irqrestore():
    0.00 :   ffff800010e3538c:       mov     x29, sp
         : 191              queued_spin_unlock():
    0.00 :   ffff800010e35390:       stlrb   w2, [x0]
         : 100              arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    9.02 :   ffff800010e35394:       msr     daif, x1
         : 129              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    6.66 :   ffff800010e35398:       nop
         : 28               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e3539c:       mrs     x1, sp_el0
         : 26               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e353a0:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e353a4:       sub     x0, x0, #0x1
    0.00 :   ffff800010e353a8:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e353ac:       cbnz    x0, ffff800010e353d8 <_raw_spin_unlock_irqrestore+0x58>
         : 80               __raw_spin_unlock_irqrestore():
         : 161              unsigned long flags)
         : 162              {
         : 163              spin_release(&lock->dep_map, _RET_IP_);
         : 164              do_raw_spin_unlock(lock);
         : 165              local_irq_restore(flags);
         : 166              preempt_enable();
    0.00 :   ffff800010e353b0:       bl      ffff800010e2e620 <preempt_schedule>
         : 168              _raw_spin_unlock_irqrestore():
         : 192              __raw_spin_unlock_irqrestore(lock, flags);
         : 193              }
    0.50 :   ffff800010e353b4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e353b8:       autiasp
    0.03 :   ffff800010e353bc:       ret
         : 197              arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.24 :   ffff800010e353c0:       dsb     sy
         : 137              get_current():
   75.33 :   ffff800010e353c4:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e353c8:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e353cc:       sub     x0, x0, #0x1
    7.44 :   ffff800010e353d0:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e353d4:       cbz     x0, ffff800010e353b0 <_raw_spin_unlock_irqrestore+0x30>
    0.00 :   ffff800010e353d8:       ldr     x0, [x1, #8]
    0.00 :   ffff800010e353dc:       cbnz    x0, ffff800010e353b4 <_raw_spin_unlock_irqrestore+0x34>
         : 77               __raw_spin_unlock_irqrestore():
    0.00 :   ffff800010e353e0:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010e353e4:       b       ffff800010e353b4 <_raw_spin_unlock_irqrestore+0x34>
 Percent |	Source code & Disassembly of vmlinux for cycles (3382 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077c700 <arm_smmu_cmdq_shared_unlock>:
         : 6                arm_smmu_cmdq_shared_unlock():
         : 455              return true;
         : 456              }
         :
         : 458              #define arm_smmu_cmdq_exclusive_trylock_irqsave(cmdq, flags)            \
         : 459              ({                                                                      \
         : 460              bool __ret;                                                     \
    0.15 :   ffff80001077c700:       paciasp
         : 462              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.03 :   ffff80001077c704:       b       ffff80001077c728 <arm_smmu_cmdq_shared_unlock+0x28>
    0.03 :   ffff80001077c708:       b       ffff80001077c728 <arm_smmu_cmdq_shared_unlock+0x28>
    0.00 :   ffff80001077c70c:       add     x2, x0, #0xcc
         : 47               __lse_atomic_sub_return_release():
         : 140              return i;                                                       \
         : 141              }
         :
         : 143              ATOMIC_OP_SUB_RETURN(_relaxed,   )
         : 144              ATOMIC_OP_SUB_RETURN(_acquire,  a, "memory")
         : 145              ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
    0.00 :   ffff80001077c710:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001077c714:       neg     w1, w1
    0.18 :   ffff80001077c718:       ldaddl  w1, w3, [x2]
   99.62 :   ffff80001077c71c:       add     w1, w1, w3
         : 150              arm_smmu_cmdq_shared_unlock():
         : 457              local_irq_save(flags);                                          \
         : 458              __ret = !atomic_cmpxchg_relaxed(&cmdq->lock, 0, INT_MIN);       \
    0.00 :   ffff80001077c720:       autiasp
    0.00 :   ffff80001077c724:       ret
         : 461              __ll_sc_atomic_sub_return_release():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001077c728:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001077c72c:       add     x0, x0, #0xcc
    0.00 :   ffff80001077c730:       b       ffff800010780a5c <arm_smmu_tlb_inv_range_asid+0xe4>
         : 121              arm_smmu_cmdq_shared_unlock():
    0.00 :   ffff80001077c734:       autiasp
    0.00 :   ffff80001077c738:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2812 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104a5b40 <__memcpy>:
         : 6                __memcpy():
         : 42               C_l     .req    x11
         : 43               C_h     .req    x12
         : 44               D_l     .req    x13
         : 45               D_h     .req    x14
         :
         : 47               mov     dst, dstin
    0.32 :   ffff8000104a5b40:       mov     x6, x0
         : 43               cmp     count, #16
    0.00 :   ffff8000104a5b44:       cmp     x2, #0x10
         : 45               /*When memory length is less than 16, the accessed are not aligned.*/
         : 46               b.lo    .Ltiny15
    0.00 :   ffff8000104a5b48:       b.cc    ffff8000104a5bc0 <__memcpy+0x80>  // b.lo, b.ul, b.last
         :
         : 48               neg     tmp2, src
    0.07 :   ffff8000104a5b4c:       neg     x4, x1
         : 48               ands    tmp2, tmp2, #15/* Bytes to reach alignment. */
    0.00 :   ffff8000104a5b50:       ands    x4, x4, #0xf
         : 49               b.eq    .LSrcAligned
    0.00 :   ffff8000104a5b54:       b.eq    ffff8000104a5b8c <__memcpy+0x4c>  // b.none
         : 50               sub     count, count, tmp2
    0.00 :   ffff8000104a5b58:       sub     x2, x2, x4
         : 57               * Copy the leading memory data from src to dst in an increasing
         : 58               * address order.By this way,the risk of overwriting the source
         : 59               * memory data is eliminated when the distance between src and
         : 60               * dst is less than 16. The memory accesses here are alignment.
         : 61               */
         : 62               tbz     tmp2, #0, 1f
    0.00 :   ffff8000104a5b5c:       tbz     w4, #0, ffff8000104a5b68 <__memcpy+0x28>
         : 58               ldrb1   tmp1w, src, #1
    0.00 :   ffff8000104a5b60:       ldrb    w3, [x1], #1
         : 59               strb1   tmp1w, dst, #1
    0.00 :   ffff8000104a5b64:       strb    w3, [x6], #1
         : 61               1:
         : 62               tbz     tmp2, #1, 2f
    0.00 :   ffff8000104a5b68:       tbz     w4, #1, ffff8000104a5b74 <__memcpy+0x34>
         : 62               ldrh1   tmp1w, src, #2
    0.00 :   ffff8000104a5b6c:       ldrh    w3, [x1], #2
         : 63               strh1   tmp1w, dst, #2
    0.00 :   ffff8000104a5b70:       strh    w3, [x6], #2
         : 65               2:
         : 66               tbz     tmp2, #2, 3f
    0.00 :   ffff8000104a5b74:       tbz     w4, #2, ffff8000104a5b80 <__memcpy+0x40>
         : 66               ldr1    tmp1w, src, #4
    0.00 :   ffff8000104a5b78:       ldr     w3, [x1], #4
         : 67               str1    tmp1w, dst, #4
    0.00 :   ffff8000104a5b7c:       str     w3, [x6], #4
         : 69               3:
         : 70               tbz     tmp2, #3, .LSrcAligned
    0.00 :   ffff8000104a5b80:       tbz     w4, #3, ffff8000104a5b8c <__memcpy+0x4c>
         : 70               ldr1    tmp1, src, #8
    0.00 :   ffff8000104a5b84:       ldr     x3, [x1], #8
         : 71               str1    tmp1, dst, #8
    0.00 :   ffff8000104a5b88:       str     x3, [x6], #8
         :
         : 75               .LSrcAligned:
         : 76               cmp     count, #64
    0.28 :   ffff8000104a5b8c:       cmp     x2, #0x40
         : 75               b.ge    .Lcpy_over64
    0.00 :   ffff8000104a5b90:       b.ge    ffff8000104a5bf4 <__memcpy+0xb4>  // b.tcont
         : 85               .Ltail63:
         : 86               /*
         : 87               * Copy up to 48 bytes of data. At this point we only need the
         : 88               * bottom 6 bits of count to be accurate.
         : 89               */
         : 90               ands    tmp1, count, #0x30
    0.00 :   ffff8000104a5b94:       ands    x3, x2, #0x30
         : 86               b.eq    .Ltiny15
    0.00 :   ffff8000104a5b98:       b.eq    ffff8000104a5bc0 <__memcpy+0x80>  // b.none
         : 87               cmp     tmp1w, #0x20
    0.00 :   ffff8000104a5b9c:       cmp     w3, #0x20
         : 88               b.eq    1f
    0.00 :   ffff8000104a5ba0:       b.eq    ffff8000104a5bb0 <__memcpy+0x70>  // b.none
         : 89               b.lt    2f
    0.00 :   ffff8000104a5ba4:       b.lt    ffff8000104a5bb8 <__memcpy+0x78>  // b.tstop
         : 90               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a5ba8:       ldp     x7, x8, [x1], #16
         : 91               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5bac:       stp     x7, x8, [x6], #16
         : 93               1:
         : 94               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a5bb0:       ldp     x7, x8, [x1], #16
         : 94               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5bb4:       stp     x7, x8, [x6], #16
         : 96               2:
         : 97               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a5bb8:       ldp     x7, x8, [x1], #16
         : 97               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5bbc:       stp     x7, x8, [x6], #16
         : 110              * precondition that src address is at least 16 bytes bigger than dst
         : 111              * address,otherwise some source data will be overwritten when memove
         : 112              * call memcpy directly. To make memmove simpler and decouple the
         : 113              * memcpy's dependency on memmove, withdrew the original process.
         : 114              */
         : 115              tbz     count, #3, 1f
    0.00 :   ffff8000104a5bc0:       tbz     w2, #3, ffff8000104a5bcc <__memcpy+0x8c>
         : 111              ldr1    tmp1, src, #8
    0.00 :   ffff8000104a5bc4:       ldr     x3, [x1], #8
         : 112              str1    tmp1, dst, #8
    0.00 :   ffff8000104a5bc8:       str     x3, [x6], #8
         : 114              1:
         : 115              tbz     count, #2, 2f
    0.00 :   ffff8000104a5bcc:       tbz     w2, #2, ffff8000104a5bd8 <__memcpy+0x98>
         : 115              ldr1    tmp1w, src, #4
    0.00 :   ffff8000104a5bd0:       ldr     w3, [x1], #4
         : 116              str1    tmp1w, dst, #4
    0.00 :   ffff8000104a5bd4:       str     w3, [x6], #4
         : 118              2:
         : 119              tbz     count, #1, 3f
    0.00 :   ffff8000104a5bd8:       tbz     w2, #1, ffff8000104a5be4 <__memcpy+0xa4>
         : 119              ldrh1   tmp1w, src, #2
    0.00 :   ffff8000104a5bdc:       ldrh    w3, [x1], #2
         : 120              strh1   tmp1w, dst, #2
    0.00 :   ffff8000104a5be0:       strh    w3, [x6], #2
         : 122              3:
         : 123              tbz     count, #0, .Lexitfunc
    0.00 :   ffff8000104a5be4:       tbz     w2, #0, ffff8000104a5c90 <__memcpy+0x150>
         : 123              ldrb1   tmp1w, src, #1
    0.00 :   ffff8000104a5be8:       ldrb    w3, [x1], #1
         : 124              strb1   tmp1w, dst, #1
    0.00 :   ffff8000104a5bec:       strb    w3, [x6], #1
         :
         : 127              b       .Lexitfunc
    0.00 :   ffff8000104a5bf0:       b       ffff8000104a5c90 <__memcpy+0x150>
         :
         : 130              .Lcpy_over64:
         : 131              subs    count, count, #128
    0.14 :   ffff8000104a5bf4:       subs    x2, x2, #0x80
         : 130              b.ge    .Lcpy_body_large
    0.00 :   ffff8000104a5bf8:       b.ge    ffff8000104a5c40 <__memcpy+0x100>  // b.tcont
         : 135              /*
         : 136              * Less than 128 bytes to copy, so handle 64 here and then jump
         : 137              * to the tail.
         : 138              */
         : 139              ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a5bfc:       ldp     x7, x8, [x1], #16
         : 136              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5c00:       stp     x7, x8, [x6], #16
         : 137              ldp1    B_l, B_h, src, #16
    0.00 :   ffff8000104a5c04:       ldp     x9, x10, [x1], #16
         : 138              ldp1    C_l, C_h, src, #16
    0.00 :   ffff8000104a5c08:       ldp     x11, x12, [x1], #16
         : 139              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a5c0c:       stp     x9, x10, [x6], #16
         : 140              stp1    C_l, C_h, dst, #16
    0.00 :   ffff8000104a5c10:       stp     x11, x12, [x6], #16
         : 141              ldp1    D_l, D_h, src, #16
    0.00 :   ffff8000104a5c14:       ldp     x13, x14, [x1], #16
         : 142              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a5c18:       stp     x13, x14, [x6], #16
         :
         : 145              tst     count, #0x3f
    0.00 :   ffff8000104a5c1c:       tst     x2, #0x3f
         : 145              b.ne    .Ltail63
    0.00 :   ffff8000104a5c20:       b.ne    ffff8000104a5b94 <__memcpy+0x54>  // b.any
         : 146              b       .Lexitfunc
    0.00 :   ffff8000104a5c24:       b       ffff8000104a5c90 <__memcpy+0x150>
    0.00 :   ffff8000104a5c28:       nop
    0.00 :   ffff8000104a5c2c:       nop
    0.00 :   ffff8000104a5c30:       nop
    0.00 :   ffff8000104a5c34:       nop
    0.00 :   ffff8000104a5c38:       nop
    0.00 :   ffff8000104a5c3c:       nop
         : 155              * 64 bytes per line this ensures the entire loop is in one line.
         : 156              */
         : 157              .p2align        L1_CACHE_SHIFT
         : 158              .Lcpy_body_large:
         : 159              /* pre-get 64 bytes data. */
         : 160              ldp1    A_l, A_h, src, #16
    0.21 :   ffff8000104a5c40:       ldp     x7, x8, [x1], #16
         : 156              ldp1    B_l, B_h, src, #16
    2.63 :   ffff8000104a5c44:       ldp     x9, x10, [x1], #16
         : 157              ldp1    C_l, C_h, src, #16
    0.57 :   ffff8000104a5c48:       ldp     x11, x12, [x1], #16
         : 158              ldp1    D_l, D_h, src, #16
    0.60 :   ffff8000104a5c4c:       ldp     x13, x14, [x1], #16
         : 164              1:
         : 165              /*
         : 166              * interlace the load of next 64 bytes data block with store of the last
         : 167              * loaded 64 bytes data.
         : 168              */
         : 169              stp1    A_l, A_h, dst, #16
    6.64 :   ffff8000104a5c50:       stp     x7, x8, [x6], #16
         : 165              ldp1    A_l, A_h, src, #16
   13.34 :   ffff8000104a5c54:       ldp     x7, x8, [x1], #16
         : 166              stp1    B_l, B_h, dst, #16
   36.58 :   ffff8000104a5c58:       stp     x9, x10, [x6], #16
         : 167              ldp1    B_l, B_h, src, #16
    6.08 :   ffff8000104a5c5c:       ldp     x9, x10, [x1], #16
         : 168              stp1    C_l, C_h, dst, #16
    7.25 :   ffff8000104a5c60:       stp     x11, x12, [x6], #16
         : 169              ldp1    C_l, C_h, src, #16
    5.82 :   ffff8000104a5c64:       ldp     x11, x12, [x1], #16
         : 170              stp1    D_l, D_h, dst, #16
   12.76 :   ffff8000104a5c68:       stp     x13, x14, [x6], #16
         : 171              ldp1    D_l, D_h, src, #16
    5.79 :   ffff8000104a5c6c:       ldp     x13, x14, [x1], #16
         : 172              subs    count, count, #64
    0.04 :   ffff8000104a5c70:       subs    x2, x2, #0x40
         : 173              b.ge    1b
    0.04 :   ffff8000104a5c74:       b.ge    ffff8000104a5c50 <__memcpy+0x110>  // b.tcont
         : 174              stp1    A_l, A_h, dst, #16
    0.32 :   ffff8000104a5c78:       stp     x7, x8, [x6], #16
         : 175              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a5c7c:       stp     x9, x10, [x6], #16
         : 176              stp1    C_l, C_h, dst, #16
    0.32 :   ffff8000104a5c80:       stp     x11, x12, [x6], #16
         : 177              stp1    D_l, D_h, dst, #16
    0.07 :   ffff8000104a5c84:       stp     x13, x14, [x6], #16
         :
         : 180              tst     count, #0x3f
    0.00 :   ffff8000104a5c88:       tst     x2, #0x3f
         : 180              b.ne    .Ltail63
    0.00 :   ffff8000104a5c8c:       b.ne    ffff8000104a5b94 <__memcpy+0x54>  // b.any
         : 62               The loop tail is handled by always copying 64 bytes from the end.
         : 63               */
         :
         : 65               SYM_FUNC_START_ALIAS(__memmove)
         : 66               SYM_FUNC_START_WEAK_ALIAS_PI(memmove)
         : 67               SYM_FUNC_START_ALIAS(__memcpy)
    0.14 :   ffff8000104a5c90:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2375 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010110e30 <ktime_get>:
         : 6                ktime_get():
         : 818              timespec64_add_ns(ts, nsecs);
         : 819              }
         : 820              EXPORT_SYMBOL(ktime_get_real_ts64);
         :
         : 822              ktime_t ktime_get(void)
         : 823              {
    0.59 :   ffff800010110e30:       paciasp
         : 824              struct timekeeper *tk = &tk_core.timekeeper;
         : 825              unsigned int seq;
         : 826              ktime_t base;
         : 827              u64 nsecs;
         :
         : 829              WARN_ON(timekeeping_suspended);
    0.42 :   ffff800010110e34:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
         : 818              {
    0.59 :   ffff800010110e38:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010110e3c:       mov     x29, sp
         : 824              WARN_ON(timekeeping_suspended);
    0.08 :   ffff800010110e40:       ldr     w0, [x0, #3068]
         : 818              {
    0.59 :   ffff800010110e44:       stp     x19, x20, [sp, #16]
    0.25 :   ffff800010110e48:       str     x21, [sp, #32]
         : 824              WARN_ON(timekeeping_suspended);
    0.00 :   ffff800010110e4c:       cbnz    w0, ffff800010110ec8 <ktime_get+0x98>
    0.80 :   ffff800010110e50:       adrp    x19, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010110e54:       add     x19, x19, #0xf00
         : 828              __seqprop_raw_spinlock_sequence():
         : 276              lockdep_assert_preemption_disabled();
         : 277              }
         :
         : 279              #define __SEQ_RT        IS_ENABLED(CONFIG_PREEMPT_RT)
         :
         : 281              SEQCOUNT_LOCKNAME(raw_spinlock, raw_spinlock_t,  false,    s->lock,        raw_spin, raw_spin_lock(s->lock))
    0.00 :   ffff800010110e58:       ldr     w20, [x19]
         : 283              ktime_get():
         :
         : 828              do {
         : 829              seq = read_seqcount_begin(&tk_core.seq);
    0.00 :   ffff800010110e5c:       tbnz    w20, #0, ffff800010110ec0 <ktime_get+0x90>
    0.94 :   ffff800010110e60:       dmb     ishld
         : 828              tk_clock_read():
         : 191              struct clocksource *clock = READ_ONCE(tkr->clock);
   78.73 :   ffff800010110e64:       ldr     x1, [x19, #8]
         : 193              ktime_get():
         : 828              base = tk->tkr_mono.base;
    0.00 :   ffff800010110e68:       ldr     x21, [x19, #48]
         : 830              tk_clock_read():
         : 193              return clock->read(clock);
    0.00 :   ffff800010110e6c:       mov     x0, x1
    0.00 :   ffff800010110e70:       ldr     x1, [x1]
    0.00 :   ffff800010110e74:       blr     x1
         : 197              timekeeping_delta_to_ns():
         : 377              nsec >>= tkr->shift;
    0.00 :   ffff800010110e78:       ldp     w2, w3, [x19, #32]
         : 379              timekeeping_get_delta():
         : 290              delta = clocksource_delta(cycle_now, tkr->cycle_last, tkr->mask);
    1.76 :   ffff800010110e7c:       ldp     x5, x6, [x19, #16]
         : 292              timekeeping_delta_to_ns():
         : 376              nsec = delta * tkr->mult + tkr->xtime_nsec;
    0.00 :   ffff800010110e80:       ldr     x4, [x19, #40]
         : 378              do_read_seqcount_retry():
         : 452              #define read_seqcount_retry(s, start)                                   \
         : 453              do_read_seqcount_retry(seqprop_ptr(s), start)
         :
         : 455              static inline int do_read_seqcount_retry(const seqcount_t *s, unsigned start)
         : 456              {
         : 457              smp_rmb();
    0.00 :   ffff800010110e84:       dmb     ishld
         : 459              do___read_seqcount_retry():
         : 433              return unlikely(READ_ONCE(s->sequence) != start);
   13.31 :   ffff800010110e88:       ldr     w1, [x19]
         : 435              ktime_get():
         : 831              nsecs = timekeeping_get_ns(&tk->tkr_mono);
         :
         : 833              } while (read_seqcount_retry(&tk_core.seq, seq));
    0.00 :   ffff800010110e8c:       cmp     w20, w1
    0.00 :   ffff800010110e90:       b.ne    ffff800010110e58 <ktime_get+0x28>  // b.any
         : 836              clocksource_delta():
         : 32               return ret & ~(mask >> 1) ? 0 : ret;
         : 33               }
         : 34               #else
         : 35               static inline u64 clocksource_delta(u64 now, u64 last, u64 mask)
         : 36               {
         : 37               return (now - last) & mask;
    0.00 :   ffff800010110e94:       sub     x0, x0, x6
         : 39               timekeeping_delta_to_ns():
         : 376              nsec = delta * tkr->mult + tkr->xtime_nsec;
    0.00 :   ffff800010110e98:       mov     w2, w2
         : 378              clocksource_delta():
    0.00 :   ffff800010110e9c:       and     x0, x0, x5
         : 33               ktime_get():
         :
         : 835              return ktime_add_ns(base, nsecs);
         : 836              }
    0.00 :   ffff800010110ea0:       ldp     x19, x20, [sp, #16]
         : 838              timekeeping_delta_to_ns():
         : 376              nsec = delta * tkr->mult + tkr->xtime_nsec;
    0.00 :   ffff800010110ea4:       madd    x0, x0, x2, x4
         : 377              nsec >>= tkr->shift;
    0.00 :   ffff800010110ea8:       lsr     x0, x0, x3
         : 379              ktime_get():
         : 834              }
    0.00 :   ffff800010110eac:       add     x0, x0, x21
    0.00 :   ffff800010110eb0:       ldr     x21, [sp, #32]
    1.76 :   ffff800010110eb4:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010110eb8:       autiasp
    0.00 :   ffff800010110ebc:       ret
         : 840              cpu_relax():
         :
         : 13               #ifndef __ASSEMBLY__
         :
         : 15               static inline void cpu_relax(void)
         : 16               {
         : 17               asm volatile("yield" ::: "memory");
    0.13 :   ffff800010110ec0:       yield
    0.04 :   ffff800010110ec4:       b       ffff800010110e58 <ktime_get+0x28>
         : 20               ktime_get():
         : 824              WARN_ON(timekeeping_suspended);
    0.00 :   ffff800010110ec8:       brk     #0x800
    0.00 :   ffff800010110ecc:       b       ffff800010110e50 <ktime_get+0x20>
 Percent |	Source code & Disassembly of vmlinux for cycles (2107 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077c5d8 <__arm_smmu_cmdq_poll_set_valid_map.isra.25>:
         : 6                __arm_smmu_cmdq_poll_set_valid_map():
         :
         : 534              ptr = &cmdq->valid_map[swidx];
         :
         : 536              if ((swidx == ewidx) && (sbidx < ebidx))
         : 537              limit = ebidx;
         :
    0.43 :   ffff80001077c5d8:       mov     w5, #0x1                        // #1
         : 536              mask = GENMASK(limit - 1, sbidx);
         :
         : 538              /*
    0.00 :   ffff80001077c5dc:       cmp     w3, w2
         :
    0.00 :   ffff80001077c5e0:       lsl     w0, w5, w0
    0.00 :   ffff80001077c5e4:       sub     w15, w0, #0x1
    0.00 :   ffff80001077c5e8:       and     w11, w15, w3
         : 536              /*
    0.00 :   ffff80001077c5ec:       b.eq    ffff80001077c6fc <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x124>  // b.none
    0.00 :   ffff80001077c5f0:       lsr     w16, w11, #6
    0.00 :   ffff80001077c5f4:       and     w11, w11, #0x3f
         : 524              u32 limit = BITS_PER_LONG;
    0.00 :   ffff80001077c5f8:       paciasp
    0.19 :   ffff80001077c5fc:       mov     w14, #0x40                      // #64
    0.66 :   ffff80001077c600:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001077c604:       sub     w5, w14, w11
    0.00 :   ffff80001077c608:       mov     x13, #0xffffffffffffffff        // #-1
    0.00 :   ffff80001077c60c:       mov     x29, sp
         : 546              */
         : 547              if (set) {
         : 548              atomic_long_xor(mask, ptr);
         : 549              } else { /* Poll */
         : 550              unsigned long valid;
         :
    0.24 :   ffff80001077c610:       mov     x18, x13
         : 524              u32 limit = BITS_PER_LONG;
    0.00 :   ffff80001077c614:       and     w4, w4, #0xff
    0.00 :   ffff80001077c618:       orr     w12, w15, w0
    0.00 :   ffff80001077c61c:       lsr     x13, x13, x5
         : 549              valid = (ULONG_MAX + !!Q_WRP(&llq, llq.prod)) & mask;
         : 550              atomic_long_cond_read_relaxed(ptr, (VAL & mask) == valid);
         : 551              }
    0.00 :   ffff80001077c620:       mov     x17, #0x1                       // #1
    0.00 :   ffff80001077c624:       b       ffff80001077c654 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x7c>
         : 554              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.09 :   ffff80001077c628:       b       ffff80001077c6f4 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x11c>
    0.00 :   ffff80001077c62c:       b       ffff80001077c6f4 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x11c>
         : 46               __lse_atomic64_xor():
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
    0.19 :   ffff80001077c630:       steor   x7, [x5]
         : 185              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    2.78 :   ffff80001077c634:       and     w5, w2, w12
         : 193              return -ETIMEDOUT;
    0.00 :   ffff80001077c638:       and     w6, w2, #0x80000000
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.00 :   ffff80001077c63c:       sub     w8, w5, w8
    0.00 :   ffff80001077c640:       add     w2, w8, w30
         : 193              return -ETIMEDOUT;
    0.00 :   ffff80001077c644:       and     w2, w2, w12
    0.00 :   ffff80001077c648:       orr     w2, w2, w6
         : 196              __arm_smmu_cmdq_poll_set_valid_map():
         : 536              /*
    0.00 :   ffff80001077c64c:       cmp     w3, w2
    0.00 :   ffff80001077c650:       b.eq    ffff80001077c6e8 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x110>  // b.none
         : 541              */
    0.33 :   ffff80001077c654:       and     w8, w15, w2
         : 544              } else { /* Poll */
    0.38 :   ffff80001077c658:       ldr     x9, [x1]
         : 541              */
    0.00 :   ffff80001077c65c:       lsr     w6, w8, #6
         :
    1.21 :   ffff80001077c660:       cmp     w16, w6
         : 542              if (set) {
    0.00 :   ffff80001077c664:       and     w8, w8, #0x3f
         :
   25.15 :   ffff80001077c668:       ccmp    w11, w8, #0x0, eq  // eq = none
    0.00 :   ffff80001077c66c:       csel    x5, x13, x18, hi  // hi = pmore
         : 549              }
    0.00 :   ffff80001077c670:       lsl     x7, x17, x8
    0.00 :   ffff80001077c674:       neg     x7, x7
         :
    0.00 :   ffff80001077c678:       csel    w30, w11, w14, hi  // hi = pmore
         : 549              }
    0.00 :   ffff80001077c67c:       and     x7, x7, x5
         : 544              } else { /* Poll */
    0.00 :   ffff80001077c680:       add     x5, x9, x6, lsl #3
         : 557              }
         : 558              }
         :
         : 560              /* Mark all entries in the range [sprod, eprod) as valid */
         : 561              static void arm_smmu_cmdq_set_valid_map(struct arm_smmu_cmdq *cmdq,
         : 562              u32 sprod, u32 eprod)
    0.00 :   ffff80001077c684:       cbnz    w4, ffff80001077c628 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x50>
         : 563              {
         : 564              __arm_smmu_cmdq_poll_set_valid_map(cmdq, sprod, eprod, true);
         : 565              }
         :
         : 567              /* Wait for all entries in the range [sprod, eprod) to become valid */
         : 568              static void arm_smmu_cmdq_poll_valid_map(struct arm_smmu_cmdq *cmdq,
    0.33 :   ffff80001077c688:       ldr     x6, [x9, x6, lsl #3]
         : 562              /* Wait for all entries in the range [sprod, eprod) to become valid */
    0.00 :   ffff80001077c68c:       tst     w2, w0
    0.00 :   ffff80001077c690:       csel    x10, x7, xzr, eq  // eq = none
         : 563              static void arm_smmu_cmdq_poll_valid_map(struct arm_smmu_cmdq *cmdq,
    0.00 :   ffff80001077c694:       and     x9, x7, x6
    0.28 :   ffff80001077c698:       cmp     x10, x9
    0.00 :   ffff80001077c69c:       b.eq    ffff80001077c634 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x5c>  // b.none
         : 567              __cmpwait_case_64():
         : 253              }
         :
         : 255              __CMPWAIT_CASE(w, b, 8);
         : 256              __CMPWAIT_CASE(w, h, 16);
         : 257              __CMPWAIT_CASE(w,  , 32);
         : 258              __CMPWAIT_CASE( ,  , 64);
    6.68 :   ffff80001077c6a0:       sevl
    0.62 :   ffff80001077c6a4:       wfe
    8.10 :   ffff80001077c6a8:       ldxr    x9, [x5]
    0.00 :   ffff80001077c6ac:       eor     x9, x9, x6
    0.00 :   ffff80001077c6b0:       cbnz    x9, ffff80001077c6b8 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0xe0>
    3.41 :   ffff80001077c6b4:       wfe
         : 265              __arm_smmu_cmdq_poll_set_valid_map():
   34.86 :   ffff80001077c6b8:       ldr     x6, [x5]
    0.00 :   ffff80001077c6bc:       and     x9, x7, x6
    0.24 :   ffff80001077c6c0:       cmp     x10, x9
    0.00 :   ffff80001077c6c4:       b.ne    ffff80001077c6a0 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0xc8>  // b.any
         : 567              queue_inc_prod_n():
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
   11.89 :   ffff80001077c6c8:       and     w5, w2, w12
         : 193              return -ETIMEDOUT;
    0.00 :   ffff80001077c6cc:       and     w6, w2, #0x80000000
         : 192              if (ktime_compare(ktime_get(), qp->timeout) > 0)
    0.00 :   ffff80001077c6d0:       sub     w8, w5, w8
    0.00 :   ffff80001077c6d4:       add     w2, w8, w30
         : 193              return -ETIMEDOUT;
    0.05 :   ffff80001077c6d8:       and     w2, w2, w12
    0.00 :   ffff80001077c6dc:       orr     w2, w2, w6
         : 196              __arm_smmu_cmdq_poll_set_valid_map():
         : 536              /*
    0.00 :   ffff80001077c6e0:       cmp     w3, w2
    0.00 :   ffff80001077c6e4:       b.ne    ffff80001077c654 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x7c>  // b.any
         : 568              u32 sprod, u32 eprod)
         : 569              {
         : 570              __arm_smmu_cmdq_poll_set_valid_map(cmdq, sprod, eprod, false);
         : 571              }
         :
    0.38 :   ffff80001077c6e8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001077c6ec:       autiasp
    1.52 :   ffff80001077c6f0:       ret
         : 576              __ll_sc_atomic64_xor():
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
         : 228              ATOMIC64_OPS(xor, eor, L)
    0.00 :   ffff80001077c6f4:       b       ffff800010780a44 <arm_smmu_tlb_inv_range_asid+0xcc>
    0.00 :   ffff80001077c6f8:       b       ffff80001077c634 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x5c>
    0.00 :   ffff80001077c6fc:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1809 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010c094c8 <arch_counter_get_cntpct>:
         : 6                arch_counter_get_cntpct():
         : 171              {
         : 172              return __arch_counter_get_cntpct_stable();
         : 173              }
         :
         : 175              static notrace u64 arch_counter_get_cntpct(void)
         : 176              {
    0.18 :   ffff800010c094c8:       paciasp
         : 178              __arch_counter_get_cntpct():
         :
         : 183              static __always_inline u64 __arch_counter_get_cntpct(void)
         : 184              {
         : 185              u64 cnt;
         :
         : 187              isb();
    2.26 :   ffff800010c094cc:       isb
         : 183              cnt = read_sysreg(cntpct_el0);
   45.43 :   ffff800010c094d0:       mrs     x0, cntpct_el0
         : 184              arch_counter_enforce_ordering(cnt);
    1.99 :   ffff800010c094d4:       eor     x1, x0, x0
    0.00 :   ffff800010c094d8:       add     x1, sp, x1
    0.00 :   ffff800010c094dc:       ldr     xzr, [x1]
         : 188              arch_counter_get_cntpct():
         : 173              return __arch_counter_get_cntpct();
         : 174              }
    0.00 :   ffff800010c094e0:       autiasp
   50.14 :   ffff800010c094e4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1045 samples, percent: local period)
-----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104a5e40 <__memset>:
         : 6                memset():
         : 47               tmp3w           .req    w9
         : 48               tmp3            .req    x9
         :
         : 50               SYM_FUNC_START_ALIAS(__memset)
         : 51               SYM_FUNC_START_WEAK_PI(memset)
         : 52               mov     dst, dstin      /* Preserve return value.  */
    0.00 :   ffff8000104a5e40:       mov     x8, x0
         : 48               and     A_lw, val, #255
    0.00 :   ffff8000104a5e44:       and     w7, w1, #0xff
         : 49               orr     A_lw, A_lw, A_lw, lsl #8
    0.00 :   ffff8000104a5e48:       orr     w7, w7, w7, lsl #8
         : 50               orr     A_lw, A_lw, A_lw, lsl #16
    0.00 :   ffff8000104a5e4c:       orr     w7, w7, w7, lsl #16
         : 51               orr     A_l, A_l, A_l, lsl #32
    7.47 :   ffff8000104a5e50:       orr     x7, x7, x7, lsl #32
         :
         : 54               cmp     count, #15
    0.00 :   ffff8000104a5e54:       cmp     x2, #0xf
         : 54               b.hi    .Lover16_proc
    0.00 :   ffff8000104a5e58:       b.hi    ffff8000104a5e80 <__memset+0x40>  // b.pmore
         : 56               /*All store maybe are non-aligned..*/
         : 57               tbz     count, #3, 1f
    0.00 :   ffff8000104a5e5c:       tbz     w2, #3, ffff8000104a5e64 <__memset+0x24>
         : 57               str     A_l, [dst], #8
    0.00 :   ffff8000104a5e60:       str     x7, [x8], #8
         : 59               1:
         : 60               tbz     count, #2, 2f
    0.00 :   ffff8000104a5e64:       tbz     w2, #2, ffff8000104a5e6c <__memset+0x2c>
         : 60               str     A_lw, [dst], #4
    0.00 :   ffff8000104a5e68:       str     w7, [x8], #4
         : 62               2:
         : 63               tbz     count, #1, 3f
    0.00 :   ffff8000104a5e6c:       tbz     w2, #1, ffff8000104a5e74 <__memset+0x34>
         : 63               strh    A_lw, [dst], #2
    0.00 :   ffff8000104a5e70:       strh    w7, [x8], #2
         : 65               3:
         : 66               tbz     count, #0, 4f
    0.00 :   ffff8000104a5e74:       tbz     w2, #0, ffff8000104a5e7c <__memset+0x3c>
         : 66               strb    A_lw, [dst]
    0.00 :   ffff8000104a5e78:       strb    w7, [x8]
         : 68               4:
         : 69               ret
    0.00 :   ffff8000104a5e7c:       ret
         :
         : 73               .Lover16_proc:
         : 74               /*Whether  the start address is aligned with 16.*/
         : 75               neg     tmp2, dst
    0.67 :   ffff8000104a5e80:       neg     x4, x8
         : 73               ands    tmp2, tmp2, #15
    0.00 :   ffff8000104a5e84:       ands    x4, x4, #0xf
         : 74               b.eq    .Laligned
    0.00 :   ffff8000104a5e88:       b.eq    ffff8000104a5e98 <__memset+0x58>  // b.none
         : 80               /*
         : 81               * The count is not less than 16, we can use stp to store the start 16 bytes,
         : 82               * then adjust the dst aligned with 16.This process will make the current
         : 83               * memory address at alignment boundary.
         : 84               */
         : 85               stp     A_l, A_l, [dst] /*non-aligned store..*/
    0.00 :   ffff8000104a5e8c:       stp     x7, x7, [x8]
         : 82               /*make the dst aligned..*/
         : 83               sub     count, count, tmp2
    0.00 :   ffff8000104a5e90:       sub     x2, x2, x4
         : 83               add     dst, dst, tmp2
    0.00 :   ffff8000104a5e94:       add     x8, x8, x4
         :
         : 87               .Laligned:
         : 88               cbz     A_l, .Lzero_mem
    0.00 :   ffff8000104a5e98:       cbz     x7, ffff8000104a5f30 <__memset+0xf0>
         :
         : 90               .Ltail_maybe_long:
         : 91               cmp     count, #64
    0.00 :   ffff8000104a5e9c:       cmp     x2, #0x40
         : 90               b.ge    .Lnot_short
    0.00 :   ffff8000104a5ea0:       b.ge    ffff8000104a5f00 <__memset+0xc0>  // b.tcont
         : 92               .Ltail63:
         : 93               ands    tmp1, count, #0x30
    0.00 :   ffff8000104a5ea4:       ands    x3, x2, #0x30
         : 93               b.eq    3f
    0.00 :   ffff8000104a5ea8:       b.eq    ffff8000104a5ec4 <__memset+0x84>  // b.none
         : 94               cmp     tmp1w, #0x20
    0.87 :   ffff8000104a5eac:       cmp     w3, #0x20
         : 95               b.eq    1f
    0.00 :   ffff8000104a5eb0:       b.eq    ffff8000104a5ebc <__memset+0x7c>  // b.none
         : 96               b.lt    2f
    0.00 :   ffff8000104a5eb4:       b.lt    ffff8000104a5ec0 <__memset+0x80>  // b.tstop
         : 97               stp     A_l, A_l, [dst], #16
    0.00 :   ffff8000104a5eb8:       stp     x7, x7, [x8], #16
         : 99               1:
         : 100              stp     A_l, A_l, [dst], #16
    0.00 :   ffff8000104a5ebc:       stp     x7, x7, [x8], #16
         : 101              2:
         : 102              stp     A_l, A_l, [dst], #16
    2.11 :   ffff8000104a5ec0:       stp     x7, x7, [x8], #16
         : 107              /*
         : 108              * The last store length is less than 16,use stp to write last 16 bytes.
         : 109              * It will lead some bytes written twice and the access is non-aligned.
         : 110              */
         : 111              3:
         : 112              ands    count, count, #15
    0.00 :   ffff8000104a5ec4:       ands    x2, x2, #0xf
         : 108              cbz     count, 4f
    0.00 :   ffff8000104a5ec8:       cbz     x2, ffff8000104a5ed4 <__memset+0x94>
         : 109              add     dst, dst, count
    1.06 :   ffff8000104a5ecc:       add     x8, x8, x2
         : 110              stp     A_l, A_l, [dst, #-16]   /* Repeat some/all of last store. */
    0.10 :   ffff8000104a5ed0:       stp     x7, x7, [x8, #-16]
         : 112              4:
         : 113              ret
    0.00 :   ffff8000104a5ed4:       ret
    0.00 :   ffff8000104a5ed8:       nop
    0.00 :   ffff8000104a5edc:       nop
    0.00 :   ffff8000104a5ee0:       nop
    0.00 :   ffff8000104a5ee4:       nop
    0.00 :   ffff8000104a5ee8:       nop
    0.00 :   ffff8000104a5eec:       nop
    0.00 :   ffff8000104a5ef0:       nop
    0.00 :   ffff8000104a5ef4:       nop
    0.00 :   ffff8000104a5ef8:       nop
    0.00 :   ffff8000104a5efc:       nop
         : 120              * Critical loop. Start at a new cache line boundary. Assuming
         : 121              * 64 bytes per line, this ensures the entire loop is in one line.
         : 122              */
         : 123              .p2align        L1_CACHE_SHIFT
         : 124              .Lnot_short:
         : 125              sub     dst, dst, #16/* Pre-bias.  */
    0.00 :   ffff8000104a5f00:       sub     x8, x8, #0x10
         : 121              sub     count, count, #64
    0.00 :   ffff8000104a5f04:       sub     x2, x2, #0x40
         : 123              1:
         : 124              stp     A_l, A_l, [dst, #16]
    0.00 :   ffff8000104a5f08:       stp     x7, x7, [x8, #16]
         : 124              stp     A_l, A_l, [dst, #32]
    0.00 :   ffff8000104a5f0c:       stp     x7, x7, [x8, #32]
         : 125              stp     A_l, A_l, [dst, #48]
    0.00 :   ffff8000104a5f10:       stp     x7, x7, [x8, #48]
         : 126              stp     A_l, A_l, [dst, #64]!
    0.00 :   ffff8000104a5f14:       stp     x7, x7, [x8, #64]!
         : 127              subs    count, count, #64
    0.00 :   ffff8000104a5f18:       subs    x2, x2, #0x40
         : 128              b.ge    1b
    0.00 :   ffff8000104a5f1c:       b.ge    ffff8000104a5f08 <__memset+0xc8>  // b.tcont
         : 129              tst     count, #0x3f
    0.00 :   ffff8000104a5f20:       tst     x2, #0x3f
         : 130              add     dst, dst, #16
    0.00 :   ffff8000104a5f24:       add     x8, x8, #0x10
         : 131              b.ne    .Ltail63
    0.00 :   ffff8000104a5f28:       b.ne    ffff8000104a5ea4 <__memset+0x64>  // b.any
         : 133              .Lexitfunc:
         : 134              ret
    0.00 :   ffff8000104a5f2c:       ret
         : 140              /*
         : 141              * For zeroing memory, check to see if we can use the ZVA feature to
         : 142              * zero entire 'cache' lines.
         : 143              */
         : 144              .Lzero_mem:
         : 145              cmp     count, #63
    0.00 :   ffff8000104a5f30:       cmp     x2, #0x3f
         : 141              b.le    .Ltail63
    0.00 :   ffff8000104a5f34:       b.le    ffff8000104a5ea4 <__memset+0x64>
         : 146              /*
         : 147              * For zeroing small amounts of memory, it's not worth setting up
         : 148              * the line-clear code.
         : 149              */
         : 150              cmp     count, #128
    0.19 :   ffff8000104a5f38:       cmp     x2, #0x80
         : 147              b.lt    .Lnot_short /*count is at least  128 bytes*/
    0.00 :   ffff8000104a5f3c:       b.lt    ffff8000104a5f00 <__memset+0xc0>  // b.tstop
         :
         : 150              mrs     tmp1, dczid_el0
    0.77 :   ffff8000104a5f40:       mrs     x3, dczid_el0
         : 150              tbnz    tmp1, #4, .Lnot_short
    0.00 :   ffff8000104a5f44:       tbnz    w3, #4, ffff8000104a5f00 <__memset+0xc0>
         : 151              mov     tmp3w, #4
    0.00 :   ffff8000104a5f48:       mov     w9, #0x4                        // #4
         : 152              and     zva_len, tmp1w, #15     /* Safety: other bits reserved.  */
    0.00 :   ffff8000104a5f4c:       and     w5, w3, #0xf
         : 153              lsl     zva_len, tmp3w, zva_len
    0.00 :   ffff8000104a5f50:       lsl     w5, w9, w5
         :
         : 156              ands    tmp3w, zva_len, #63
    0.00 :   ffff8000104a5f54:       ands    w9, w5, #0x3f
         : 160              /*
         : 161              * ensure the zva_len is not less than 64.
         : 162              * It is not meaningful to use ZVA if the block size is less than 64.
         : 163              */
         : 164              b.ne    .Lnot_short
    0.86 :   ffff8000104a5f58:       b.ne    ffff8000104a5f00 <__memset+0xc0>  // b.any
         : 166              .Lzero_by_line:
         : 167              /*
         : 168              * Compute how far we need to go to become suitably aligned. We're
         : 169              * already at quad-word alignment.
         : 170              */
         : 171              cmp     count, zva_len_x
    2.01 :   ffff8000104a5f5c:       cmp     x2, x5
         : 167              b.lt    .Lnot_short             /* Not enough to reach alignment.  */
    0.00 :   ffff8000104a5f60:       b.lt    ffff8000104a5f00 <__memset+0xc0>  // b.tstop
         : 168              sub     zva_bits_x, zva_len_x, #1
    0.00 :   ffff8000104a5f64:       sub     x6, x5, #0x1
         : 169              neg     tmp2, dst
    0.00 :   ffff8000104a5f68:       neg     x4, x8
         : 170              ands    tmp2, tmp2, zva_bits_x
    0.00 :   ffff8000104a5f6c:       ands    x4, x4, x6
         : 171              b.eq    2f                      /* Already aligned.  */
    0.00 :   ffff8000104a5f70:       b.eq    ffff8000104a5fa8 <__memset+0x168>  // b.none
         : 173              /* Not aligned, check that there's enough to copy after alignment.*/
         : 174              sub     tmp1, count, tmp2
    0.00 :   ffff8000104a5f74:       sub     x3, x2, x4
         : 177              /*
         : 178              * grantee the remain length to be ZVA is bigger than 64,
         : 179              * avoid to make the 2f's process over mem range.*/
         : 180              cmp     tmp1, #64
    0.00 :   ffff8000104a5f78:       cmp     x3, #0x40
         : 178              ccmp    tmp1, zva_len_x, #8, ge /* NZCV=0b1000 */
    0.19 :   ffff8000104a5f7c:       ccmp    x3, x5, #0x8, ge  // ge = tcont
         : 179              b.lt    .Lnot_short
    0.00 :   ffff8000104a5f80:       b.lt    ffff8000104a5f00 <__memset+0xc0>  // b.tstop
         : 184              /*
         : 185              * We know that there's at least 64 bytes to zero and that it's safe
         : 186              * to overrun by 64 bytes.
         : 187              */
         : 188              mov     count, tmp1
    0.10 :   ffff8000104a5f84:       mov     x2, x3
         : 186              1:
         : 187              stp     A_l, A_l, [dst]
    0.48 :   ffff8000104a5f88:       stp     x7, x7, [x8]
         : 187              stp     A_l, A_l, [dst, #16]
    0.00 :   ffff8000104a5f8c:       stp     x7, x7, [x8, #16]
         : 188              stp     A_l, A_l, [dst, #32]
    1.73 :   ffff8000104a5f90:       stp     x7, x7, [x8, #32]
         : 189              subs    tmp2, tmp2, #64
    0.00 :   ffff8000104a5f94:       subs    x4, x4, #0x40
         : 190              stp     A_l, A_l, [dst, #48]
    0.38 :   ffff8000104a5f98:       stp     x7, x7, [x8, #48]
         : 191              add     dst, dst, #64
    0.00 :   ffff8000104a5f9c:       add     x8, x8, #0x40
         : 192              b.ge    1b
    0.00 :   ffff8000104a5fa0:       b.ge    ffff8000104a5f88 <__memset+0x148>  // b.tcont
         : 194              /* We've overrun a bit, so adjust dst downwards.*/
         : 195              add     dst, dst, tmp2
    0.29 :   ffff8000104a5fa4:       add     x8, x8, x4
         : 196              2:
         : 197              sub     count, count, zva_len_x
    0.00 :   ffff8000104a5fa8:       sub     x2, x2, x5
         : 198              3:
         : 199              dc      zva, dst
    0.00 :   ffff8000104a5fac:       dc      zva, x8
         : 199              add     dst, dst, zva_len_x
   80.73 :   ffff8000104a5fb0:       add     x8, x8, x5
         : 200              subs    count, count, zva_len_x
    0.00 :   ffff8000104a5fb4:       subs    x2, x2, x5
         : 201              b.ge    3b
    0.00 :   ffff8000104a5fb8:       b.ge    ffff8000104a5fac <__memset+0x16c>  // b.tcont
         : 202              ands    count, count, zva_bits_x
    0.00 :   ffff8000104a5fbc:       ands    x2, x2, x6
         : 203              b.ne    .Ltail_maybe_long
    0.00 :   ffff8000104a5fc0:       b.ne    ffff8000104a5e9c <__memset+0x5c>  // b.any
         : 204              ret
    0.00 :   ffff8000104a5fc4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (931 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e34d88 <_raw_spin_lock_irqsave>:
         : 6                _raw_spin_lock_irqsave():
         : 158              EXPORT_SYMBOL(_raw_spin_lock);
         : 159              #endif
         :
         : 161              #ifndef CONFIG_INLINE_SPIN_LOCK_IRQSAVE
         : 162              unsigned long __lockfunc _raw_spin_lock_irqsave(raw_spinlock_t *lock)
         : 163              {
    3.58 :   ffff800010e34d88:       paciasp
    1.19 :   ffff800010e34d8c:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff800010e34d90:       mov     x3, x0
    0.00 :   ffff800010e34d94:       mov     x29, sp
    0.00 :   ffff800010e34d98:       str     x19, [sp, #16]
         : 169              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010e34d9c:       mrs     x19, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.22 :   ffff800010e34da0:       and     w0, w19, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff800010e34da4:       cbz     w0, ffff800010e34e10 <_raw_spin_lock_irqsave+0x88>
         : 118              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    2.38 :   ffff800010e34da8:       mrs     x1, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    9.98 :   ffff800010e34dac:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff800010e34db0:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
   16.83 :   ffff800010e34db4:       str     w0, [x1, #8]
         : 50               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e34db8:       b       ffff800010e34df0 <_raw_spin_lock_irqsave+0x68>
    0.00 :   ffff800010e34dbc:       b       ffff800010e34df0 <_raw_spin_lock_irqsave+0x68>
         : 46               __lse__cmpxchg_case_acq_32():
         : 370              __CMPXCHG_CASE(w, h,     , 16,   )
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
         : 372              __CMPXCHG_CASE(x,  ,     , 64,   )
         : 373              __CMPXCHG_CASE(w, b, acq_,  8,  a, "memory")
         : 374              __CMPXCHG_CASE(w, h, acq_, 16,  a, "memory")
         : 375              __CMPXCHG_CASE(w,  , acq_, 32,  a, "memory")
    0.00 :   ffff800010e34dc0:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010e34dc4:       mov     x0, x3
    0.00 :   ffff800010e34dc8:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e34dcc:       mov     w4, w1
    0.00 :   ffff800010e34dd0:       casa    w4, w2, [x3]
   33.29 :   ffff800010e34dd4:       mov     w0, w4
         : 382              arch_atomic_try_cmpxchg_acquire():
         : 1004             static __always_inline bool
         : 1005             arch_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
         : 1006             {
         : 1007             int r, o = *old;
         : 1008             r = arch_atomic_cmpxchg_acquire(v, o, new);
         : 1009             if (unlikely(r != o))
    0.00 :   ffff800010e34dd8:       cbnz    w0, ffff800010e34e00 <_raw_spin_lock_irqsave+0x78>
         : 1011             _raw_spin_lock_irqsave():
         : 160              return __raw_spin_lock_irqsave(lock);
         : 161              }
    0.00 :   ffff800010e34ddc:       mov     x0, x19
    1.63 :   ffff800010e34de0:       ldr     x19, [sp, #16]
    0.00 :   ffff800010e34de4:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010e34de8:       autiasp
    0.00 :   ffff800010e34dec:       ret
         : 167              __ll_sc__cmpxchg_case_acq_32():
         : 305              __CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
         : 307              __CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
         : 308              __CMPXCHG_CASE(w, b, acq_,  8,        , a,  , "memory", K)
         : 309              __CMPXCHG_CASE(w, h, acq_, 16,        , a,  , "memory", K)
         : 310              __CMPXCHG_CASE(w,  , acq_, 32,        , a,  , "memory", K)
    0.00 :   ffff800010e34df0:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010e34df4:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e34df8:       b       ffff800010e357f4 <_raw_read_lock_irqsave+0xfc>
         : 314              arch_atomic_try_cmpxchg_acquire():
    0.00 :   ffff800010e34dfc:       cbz     w0, ffff800010e34ddc <_raw_spin_lock_irqsave+0x54>
         : 1005             queued_spin_lock():
         : 85               int val = 0;
         :
         : 87               if (likely(atomic_try_cmpxchg_acquire(&lock->val, &val, _Q_LOCKED_VAL)))
         : 88               return;
         :
         : 90               queued_spin_lock_slowpath(lock, val);
    0.00 :   ffff800010e34e00:       mov     w1, w0
    0.00 :   ffff800010e34e04:       mov     x0, x3
    0.00 :   ffff800010e34e08:       bl      ffff8000100dac80 <queued_spin_lock_slowpath>
    0.00 :   ffff800010e34e0c:       b       ffff800010e34ddc <_raw_spin_lock_irqsave+0x54>
         : 95               arch_static_branch():
         : 21               asm_volatile_goto(
    0.65 :   ffff800010e34e10:       nop
    0.22 :   ffff800010e34e14:       mov     x0, #0x60                       // #96
         : 24               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010e34e18:       msr     daifset, #0x3
   30.03 :   ffff800010e34e1c:       b       ffff800010e34da8 <_raw_spin_lock_irqsave+0x20>
         : 57               arch_static_branch():
    0.00 :   ffff800010e34e20:       mov     x0, #0xa0                       // #160
    0.00 :   ffff800010e34e24:       b       ffff800010e34e18 <_raw_spin_lock_irqsave+0x90>
 Percent |	Source code & Disassembly of vmlinux for cycles (652 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001078a308 <__arm_lpae_map>:
         : 6                __arm_lpae_map():
         : 336              }
         :
         : 338              static int __arm_lpae_map(struct arm_lpae_io_pgtable *data, unsigned long iova,
         : 339              phys_addr_t paddr, size_t size, arm_lpae_iopte prot,
         : 340              int lvl, arm_lpae_iopte *ptep, gfp_t gfp)
         : 341              {
    0.00 :   ffff80001078a308:       paciasp
    0.00 :   ffff80001078a30c:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff80001078a310:       mov     x29, sp
    3.35 :   ffff80001078a314:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001078a318:       mov     x20, x0
         : 338              arm_lpae_iopte *cptep, pte;
         : 339              size_t block_size = ARM_LPAE_BLOCK_SIZE(lvl, data);
    0.00 :   ffff80001078a31c:       mov     w19, #0x4                       // #4
         : 336              {
    3.35 :   ffff80001078a320:       stp     x21, x22, [sp, #32]
         : 338              size_t block_size = ARM_LPAE_BLOCK_SIZE(lvl, data);
    0.00 :   ffff80001078a324:       sub     w19, w19, w5
         : 336              {
    0.00 :   ffff80001078a328:       mov     w21, w5
    1.10 :   ffff80001078a32c:       stp     x23, x24, [sp, #48]
         : 338              size_t block_size = ARM_LPAE_BLOCK_SIZE(lvl, data);
    0.00 :   ffff80001078a330:       mov     x5, #0x1                        // #1
         : 336              {
    0.00 :   ffff80001078a334:       mov     x23, x1
    0.61 :   ffff80001078a338:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a33c:       mov     x24, x2
    0.00 :   ffff80001078a340:       mov     x22, x3
    2.28 :   ffff80001078a344:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001078a348:       mov     x25, x4
    0.00 :   ffff80001078a34c:       mov     w27, w7
         : 338              size_t block_size = ARM_LPAE_BLOCK_SIZE(lvl, data);
    4.27 :   ffff80001078a350:       ldr     w0, [x0, #120]
    0.00 :   ffff80001078a354:       mul     w19, w19, w0
    0.00 :   ffff80001078a358:       add     w19, w19, #0x3
    0.00 :   ffff80001078a35c:       lsl     x5, x5, x19
         : 343              size_t tblsz = ARM_LPAE_GRANULE(data);
         : 344              struct io_pgtable_cfg *cfg = &data->iop.cfg;
         :
         : 346              /* Find our entry at the current level */
         : 347              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    1.98 :   ffff80001078a360:       lsr     x19, x1, x19
    0.00 :   ffff80001078a364:       ldr     w1, [x20, #116]
    0.00 :   ffff80001078a368:       cmp     w1, w21
    0.00 :   ffff80001078a36c:       b.eq    ffff80001078a43c <__arm_lpae_map+0x134>  // b.none
    0.15 :   ffff80001078a370:       mov     w1, w0
    0.00 :   ffff80001078a374:       mov     w2, #0x1                        // #1
         :
         : 347              /* If we can install a leaf entry at this level, then do so */
         : 348              if (size == block_size)
    0.00 :   ffff80001078a378:       cmp     x5, x22
         : 343              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.00 :   ffff80001078a37c:       lsl     w2, w2, w1
    0.91 :   ffff80001078a380:       sub     w2, w2, #0x1
    0.00 :   ffff80001078a384:       sxtw    x2, w2
    0.00 :   ffff80001078a388:       and     x19, x2, x19
    0.00 :   ffff80001078a38c:       add     x7, x6, x19, lsl #3
         : 346              if (size == block_size)
    0.61 :   ffff80001078a390:       b.eq    ffff80001078a460 <__arm_lpae_map+0x158>  // b.none
         : 350              return arm_lpae_init_pte(data, iova, paddr, prot, lvl, ptep);
         :
         : 352              /* We can't allocate tables at the final level */
         : 353              if (WARN_ON(lvl >= ARM_LPAE_MAX_LEVELS - 1))
    0.00 :   ffff80001078a394:       cmp     w21, #0x2
    0.00 :   ffff80001078a398:       b.gt    ffff80001078a574 <__arm_lpae_map+0x26c>
         : 354              return -EINVAL;
         :
         : 356              /* Grab a pointer to the next level */
         : 357              pte = READ_ONCE(*ptep);
   12.82 :   ffff80001078a39c:       ldr     x19, [x6, x19, lsl #3]
         : 355              if (!pte) {
    0.00 :   ffff80001078a3a0:       cbz     x19, ffff80001078a508 <__arm_lpae_map+0x200>
         : 363              return -ENOMEM;
         :
         : 365              pte = arm_lpae_install_table(cptep, ptep, 0, cfg);
         : 366              if (pte)
         : 367              __arm_lpae_free_pages(cptep, tblsz, cfg);
         : 368              } else if (!cfg->coherent_walk && !(pte & ARM_LPAE_PTE_SW_SYNC)) {
   20.98 :   ffff80001078a3a4:       ldrb    w0, [x20, #40]
    0.00 :   ffff80001078a3a8:       cbnz    w0, ffff80001078a3b0 <__arm_lpae_map+0xa8>
    0.00 :   ffff80001078a3ac:       tbz     x19, #55, ffff80001078a564 <__arm_lpae_map+0x25c>
         : 364              iopte_leaf():
         : 156              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;
    4.89 :   ffff80001078a3b0:       and     x0, x19, #0x3
         : 158              __arm_lpae_map():
         : 367              __arm_lpae_sync_pte(ptep, cfg);
         : 368              }
         :
         : 370              if (pte && !iopte_leaf(pte, lvl, data->iop.fmt)) {
    0.00 :   ffff80001078a3b4:       cmp     x0, #0x1
    0.00 :   ffff80001078a3b8:       b.eq    ffff80001078a580 <__arm_lpae_map+0x278>  // b.none
         : 373              iopte_to_paddr():
         : 171              u64 paddr = pte & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff80001078a3bc:       and     x19, x19, #0xfffffffff000
         : 173              __arm_lpae_map():
         : 368              cptep = iopte_deref(pte, data);
    0.00 :   ffff80001078a3c0:       adrp    x4, ffff800011571000 <rt_sched_class+0x10>
         : 370              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    3.20 :   ffff80001078a3c4:       ldr     w3, [x20, #120]
    0.00 :   ffff80001078a3c8:       mov     x1, #0x8                        // #8
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a3cc:       orr     x0, x19, x19, lsl #36
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff80001078a3d0:       mov     x2, #0xffff                     // #65535
         : 175              __arm_lpae_map():
         : 368              cptep = iopte_deref(pte, data);
    0.00 :   ffff80001078a3d4:       ldr     x6, [x4, #3512]
         : 370              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a3d8:       and     x0, x0, #0xfffffffff0000
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff80001078a3dc:       lsl     x1, x1, x3
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a3e0:       cmp     x1, x2
    0.00 :   ffff80001078a3e4:       csel    x19, x19, x0, ls  // ls = plast
         : 180              __arm_lpae_map():
         : 368              cptep = iopte_deref(pte, data);
    0.00 :   ffff80001078a3e8:       sub     x19, x19, x6
    0.00 :   ffff80001078a3ec:       orr     x28, x19, #0xffff000000000000
         : 376              WARN_ON(!selftest_running);
         : 377              return -EEXIST;
         : 378              }
         :
         : 380              /* Rinse, repeat */
         : 381              return __arm_lpae_map(data, iova, paddr, size, prot, lvl + 1, cptep, gfp);
    0.00 :   ffff80001078a3f0:       mov     w7, w27
    0.15 :   ffff80001078a3f4:       mov     x6, x28
    0.00 :   ffff80001078a3f8:       add     w5, w21, #0x1
    0.00 :   ffff80001078a3fc:       mov     x4, x25
    0.00 :   ffff80001078a400:       mov     x3, x22
    3.67 :   ffff80001078a404:       mov     x2, x24
    0.00 :   ffff80001078a408:       mov     x1, x23
    0.00 :   ffff80001078a40c:       mov     x0, x20
    0.00 :   ffff80001078a410:       bl      ffff80001078a308 <__arm_lpae_map>
    1.83 :   ffff80001078a414:       mov     w19, w0
         : 377              }
    0.46 :   ffff80001078a418:       mov     w0, w19
    1.53 :   ffff80001078a41c:       ldp     x19, x20, [sp, #16]
    0.31 :   ffff80001078a420:       ldp     x21, x22, [sp, #32]
    0.61 :   ffff80001078a424:       ldp     x23, x24, [sp, #48]
    5.65 :   ffff80001078a428:       ldp     x25, x26, [sp, #64]
    0.31 :   ffff80001078a42c:       ldp     x27, x28, [sp, #80]
    1.07 :   ffff80001078a430:       ldp     x29, x30, [sp], #112
    0.00 :   ffff80001078a434:       autiasp
    1.07 :   ffff80001078a438:       ret
         : 343              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.76 :   ffff80001078a43c:       ldr     w1, [x20, #112]
    0.00 :   ffff80001078a440:       mov     w2, #0x1                        // #1
         : 346              if (size == block_size)
    0.00 :   ffff80001078a444:       cmp     x5, x22
         : 343              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.00 :   ffff80001078a448:       lsl     w2, w2, w1
    3.51 :   ffff80001078a44c:       sub     w2, w2, #0x1
    0.00 :   ffff80001078a450:       sxtw    x2, w2
    0.00 :   ffff80001078a454:       and     x19, x2, x19
    0.00 :   ffff80001078a458:       add     x7, x6, x19, lsl #3
         : 346              if (size == block_size)
    0.00 :   ffff80001078a45c:       b.ne    ffff80001078a394 <__arm_lpae_map+0x8c>  // b.any
         : 348              iopte_leaf():
         : 153              if (lvl == (ARM_LPAE_MAX_LEVELS - 1) && fmt != ARM_MALI_LPAE)
    0.00 :   ffff80001078a460:       ldr     x0, [x6, x19, lsl #3]
    0.00 :   ffff80001078a464:       cmp     w21, #0x3
   13.57 :   ffff80001078a468:       ldr     w1, [x20]
    0.00 :   ffff80001078a46c:       cset    w26, eq  // eq = none
    0.00 :   ffff80001078a470:       and     x0, x0, #0x3
    0.00 :   ffff80001078a474:       cmp     w1, #0x5
    0.00 :   ffff80001078a478:       csel    w1, w26, wzr, ne  // ne = any
         : 156              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;
    0.00 :   ffff80001078a47c:       cmp     x0, #0x1
    0.00 :   ffff80001078a480:       cset    w2, eq  // eq = none
         : 153              if (lvl == (ARM_LPAE_MAX_LEVELS - 1) && fmt != ARM_MALI_LPAE)
    0.00 :   ffff80001078a484:       cbnz    w1, ffff80001078a58c <__arm_lpae_map+0x284>
         : 155              arm_lpae_init_pte():
         : 279              if (iopte_leaf(pte, lvl, data->iop.fmt)) {
    0.00 :   ffff80001078a488:       cbnz    w2, ffff80001078a5ac <__arm_lpae_map+0x2a4>
         : 283              } else if (iopte_type(pte) == ARM_LPAE_PTE_TYPE_TABLE) {
    0.91 :   ffff80001078a48c:       cmp     x0, #0x3
    0.00 :   ffff80001078a490:       b.ne    ffff80001078a4cc <__arm_lpae_map+0x1c4>  // b.any
         : 292              if (__arm_lpae_unmap(data, NULL, iova, sz, lvl, tblp) != sz) {
    0.00 :   ffff80001078a494:       mov     w4, w21
    0.00 :   ffff80001078a498:       mov     x2, x23
    0.00 :   ffff80001078a49c:       mov     x5, x6
    0.00 :   ffff80001078a4a0:       mov     x3, x22
    0.00 :   ffff80001078a4a4:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001078a4a8:       mov     x0, x20
    0.00 :   ffff80001078a4ac:       stp     x6, x7, [sp, #96]
    0.00 :   ffff80001078a4b0:       bl      ffff800010789d98 <__arm_lpae_unmap>
    0.00 :   ffff80001078a4b4:       cmp     x22, x0
    0.00 :   ffff80001078a4b8:       b.ne    ffff80001078a5a0 <__arm_lpae_map+0x298>  // b.any
    0.00 :   ffff80001078a4bc:       ldr     w0, [x20]
    0.00 :   ffff80001078a4c0:       ldp     x6, x7, [sp, #96]
    0.00 :   ffff80001078a4c4:       cmp     w0, #0x5
    0.00 :   ffff80001078a4c8:       csel    w1, w26, wzr, ne  // ne = any
         : 307              __arm_lpae_init_pte():
         : 263              pte |= ARM_LPAE_PTE_TYPE_PAGE;
    4.12 :   ffff80001078a4cc:       cmp     w1, #0x0
         : 265              paddr_to_iopte():
         : 165              return (pte | (pte >> (48 - 12))) & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff80001078a4d0:       orr     x24, x24, x24, lsr #36
         : 167              __arm_lpae_init_pte():
         : 263              pte |= ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a4d4:       orr     x1, x25, #0x3
    0.00 :   ffff80001078a4d8:       orr     x25, x25, #0x1
         : 266              paddr_to_iopte():
         : 165              return (pte | (pte >> (48 - 12))) & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff80001078a4dc:       and     x0, x24, #0xfffffffff000
         : 167              __arm_lpae_init_pte():
         : 263              pte |= ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a4e0:       csel    x25, x25, x1, eq  // eq = none
         : 267              pte |= paddr_to_iopte(paddr, data);
    0.00 :   ffff80001078a4e4:       orr     x0, x0, x25
         : 269              __arm_lpae_set_pte():
         : 245              *ptep = pte;
    0.00 :   ffff80001078a4e8:       str     x0, [x6, x19, lsl #3]
         : 247              arm_lpae_init_pte():
         : 299              return 0;
    0.00 :   ffff80001078a4ec:       mov     w19, #0x0                       // #0
         : 301              __arm_lpae_set_pte():
         : 247              if (!cfg->coherent_walk)
    0.00 :   ffff80001078a4f0:       ldrb    w0, [x20, #40]
    0.00 :   ffff80001078a4f4:       cbnz    w0, ffff80001078a418 <__arm_lpae_map+0x110>
         : 248              __arm_lpae_sync_pte(ptep, cfg);
    0.00 :   ffff80001078a4f8:       ldr     x1, [x20, #56]
    0.00 :   ffff80001078a4fc:       mov     x0, x7
    0.00 :   ffff80001078a500:       bl      ffff800010789350 <__arm_lpae_sync_pte.isra.17>
    0.00 :   ffff80001078a504:       b       ffff80001078a418 <__arm_lpae_map+0x110>
         : 253              __arm_lpae_map():
         : 356              cptep = __arm_lpae_alloc_pages(tblsz, gfp, cfg);
    0.00 :   ffff80001078a508:       ldr     x3, [x20, #56]
         : 339              size_t tblsz = ARM_LPAE_GRANULE(data);
    0.00 :   ffff80001078a50c:       mov     x26, #0x8                       // #8
    0.00 :   ffff80001078a510:       lsl     x26, x26, x0
         : 356              cptep = __arm_lpae_alloc_pages(tblsz, gfp, cfg);
    0.00 :   ffff80001078a514:       add     x2, x20, #0x28
    0.00 :   ffff80001078a518:       mov     x0, x26
    0.00 :   ffff80001078a51c:       mov     w1, w27
    0.00 :   ffff80001078a520:       str     x7, [sp, #96]
    0.00 :   ffff80001078a524:       bl      ffff8000107894b8 <__arm_lpae_alloc_pages.isra.18>
    0.00 :   ffff80001078a528:       mov     x28, x0
         : 357              if (!cptep)
    0.00 :   ffff80001078a52c:       cbz     x0, ffff80001078a598 <__arm_lpae_map+0x290>
         : 360              pte = arm_lpae_install_table(cptep, ptep, 0, cfg);
    0.00 :   ffff80001078a530:       ldr     x7, [sp, #96]
    0.00 :   ffff80001078a534:       add     x3, x20, #0x10
    0.00 :   ffff80001078a538:       mov     x2, #0x0                        // #0
    0.00 :   ffff80001078a53c:       mov     x1, x7
    0.00 :   ffff80001078a540:       bl      ffff8000107893c8 <arm_lpae_install_table>
    0.00 :   ffff80001078a544:       mov     x19, x0
         : 361              if (pte)
    0.00 :   ffff80001078a548:       cbz     x0, ffff80001078a3f0 <__arm_lpae_map+0xe8>
         : 362              __arm_lpae_free_pages(cptep, tblsz, cfg);
    0.00 :   ffff80001078a54c:       ldrb    w2, [x20, #40]
    0.00 :   ffff80001078a550:       mov     x1, x26
    0.00 :   ffff80001078a554:       mov     x0, x28
    0.00 :   ffff80001078a558:       add     x3, x20, #0x38
    0.00 :   ffff80001078a55c:       bl      ffff800010789178 <__arm_lpae_free_pages.isra.15>
    0.00 :   ffff80001078a560:       b       ffff80001078a3b0 <__arm_lpae_map+0xa8>
         : 364              __arm_lpae_sync_pte(ptep, cfg);
    0.00 :   ffff80001078a564:       ldr     x1, [x20, #56]
    0.00 :   ffff80001078a568:       mov     x0, x7
    0.00 :   ffff80001078a56c:       bl      ffff800010789350 <__arm_lpae_sync_pte.isra.17>
    0.00 :   ffff80001078a570:       b       ffff80001078a3b0 <__arm_lpae_map+0xa8>
         : 350              if (WARN_ON(lvl >= ARM_LPAE_MAX_LEVELS - 1))
    0.00 :   ffff80001078a574:       brk     #0x800
         : 351              return -EINVAL;
    0.00 :   ffff80001078a578:       mov     w19, #0xffffffea                // #-22
    0.00 :   ffff80001078a57c:       b       ffff80001078a418 <__arm_lpae_map+0x110>
         : 371              WARN_ON(!selftest_running);
    0.00 :   ffff80001078a580:       brk     #0x800
         : 372              return -EEXIST;
    0.00 :   ffff80001078a584:       mov     w19, #0xffffffef                // #-17
    0.00 :   ffff80001078a588:       b       ffff80001078a418 <__arm_lpae_map+0x110>
         : 375              iopte_leaf():
         : 154              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a58c:       cmp     x0, #0x3
    0.00 :   ffff80001078a590:       cset    w2, eq  // eq = none
    0.00 :   ffff80001078a594:       b       ffff80001078a488 <__arm_lpae_map+0x180>
         : 158              __arm_lpae_map():
         : 358              return -ENOMEM;
    0.00 :   ffff80001078a598:       mov     w19, #0xfffffff4                // #-12
    0.00 :   ffff80001078a59c:       b       ffff80001078a418 <__arm_lpae_map+0x110>
         : 361              arm_lpae_init_pte():
         : 293              WARN_ON(1);
    0.00 :   ffff80001078a5a0:       brk     #0x800
         : 294              return -EINVAL;
    0.00 :   ffff80001078a5a4:       mov     w19, #0xffffffea                // #-22
    0.00 :   ffff80001078a5a8:       b       ffff80001078a418 <__arm_lpae_map+0x110>
         : 281              WARN_ON(!selftest_running);
    0.00 :   ffff80001078a5ac:       brk     #0x800
         : 282              return -EEXIST;
    0.00 :   ffff80001078a5b0:       mov     w19, #0xffffffef                // #-17
    0.00 :   ffff80001078a5b4:       b       ffff80001078a418 <__arm_lpae_map+0x110>
 Percent |	Source code & Disassembly of vmlinux for cycles (595 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010789d98 <__arm_lpae_unmap>:
         : 6                __arm_lpae_unmap():
         :
         : 574              static size_t __arm_lpae_unmap(struct arm_lpae_io_pgtable *data,
         : 575              struct iommu_iotlb_gather *gather,
         : 576              unsigned long iova, size_t size, int lvl,
         : 577              arm_lpae_iopte *ptep)
         : 578              {
    0.33 :   ffff800010789d98:       paciasp
    0.84 :   ffff800010789d9c:       stp     x29, x30, [sp, #-144]!
         : 578              arm_lpae_iopte pte;
         : 579              struct io_pgtable *iop = &data->iop;
         :
         : 581              /* Something went horribly wrong and we ran out of page table */
         : 582              if (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))
    0.00 :   ffff800010789da0:       cmp     w4, #0x4
         : 573              {
    0.00 :   ffff800010789da4:       mov     x29, sp
    1.17 :   ffff800010789da8:       stp     x19, x20, [sp, #16]
         : 578              if (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))
    0.00 :   ffff800010789dac:       b.eq    ffff80001078a094 <__arm_lpae_unmap+0x2fc>  // b.none
         : 581              return 0;
         :
         : 583              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.17 :   ffff800010789db0:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010789db4:       mov     w7, #0x4                        // #4
    0.00 :   ffff800010789db8:       sub     w7, w7, w4
    2.85 :   ffff800010789dbc:       ldp     w6, w8, [x0, #116]
    0.00 :   ffff800010789dc0:       mov     w9, w8
    0.00 :   ffff800010789dc4:       cmp     w6, w4
    0.00 :   ffff800010789dc8:       mul     w7, w7, w8
    3.68 :   ffff800010789dcc:       add     w7, w7, #0x3
    0.00 :   ffff800010789dd0:       lsr     x10, x2, x7
    0.00 :   ffff800010789dd4:       b.ne    ffff800010789ddc <__arm_lpae_unmap+0x44>  // b.any
    0.50 :   ffff800010789dd8:       ldr     w9, [x0, #112]
    0.00 :   ffff800010789ddc:       mov     w6, #0x1                        // #1
    0.00 :   ffff800010789de0:       lsl     w6, w6, w9
    0.00 :   ffff800010789de4:       sub     w6, w6, #0x1
    1.67 :   ffff800010789de8:       sxtw    x6, w6
    7.08 :   ffff800010789dec:       and     x6, x6, x10
    0.00 :   ffff800010789df0:       add     x26, x5, x6, lsl #3
         : 582              pte = READ_ONCE(*ptep);
    0.00 :   ffff800010789df4:       ldr     x19, [x5, x6, lsl #3]
         : 583              if (WARN_ON(!pte))
    0.00 :   ffff800010789df8:       cbz     x19, ffff80001078a0f0 <__arm_lpae_unmap+0x358>
         : 587              return 0;
         :
         : 589              /* If the size matches this level, we're in the right place */
         : 590              if (size == ARM_LPAE_BLOCK_SIZE(lvl, data)) {
   42.85 :   ffff800010789dfc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010789e00:       cmp     w4, #0x3
    0.00 :   ffff800010789e04:       mov     x20, x0
    3.84 :   ffff800010789e08:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010789e0c:       mov     x0, #0x1                        // #1
    0.00 :   ffff800010789e10:       cset    w25, eq  // eq = none
    0.00 :   ffff800010789e14:       lsl     x7, x0, x7
    0.00 :   ffff800010789e18:       mov     x21, x3
    0.00 :   ffff800010789e1c:       mov     x22, x2
    0.00 :   ffff800010789e20:       mov     x24, x1
    0.00 :   ffff800010789e24:       and     x23, x19, #0x3
    0.00 :   ffff800010789e28:       cmp     x7, x3
    0.00 :   ffff800010789e2c:       b.eq    ffff800010789ed4 <__arm_lpae_unmap+0x13c>  // b.none
         : 604              iopte_leaf():
         : 153              if (lvl == (ARM_LPAE_MAX_LEVELS - 1) && fmt != ARM_MALI_LPAE)
    0.00 :   ffff800010789e30:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010789e34:       cmp     w25, #0x0
    3.01 :   ffff800010789e38:       ldr     w0, [x20]
    0.00 :   ffff800010789e3c:       ccmp    w0, #0x5, #0x4, ne  // ne = any
    0.00 :   ffff800010789e40:       b.ne    ffff800010789ebc <__arm_lpae_unmap+0x124>  // b.any
         : 156              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;
    0.00 :   ffff800010789e44:       mov     x28, #0x8                       // #8
    0.00 :   ffff800010789e48:       add     w4, w4, #0x1
         : 159              __arm_lpae_unmap():
         : 608              } else {
         : 609              io_pgtable_tlb_add_page(iop, gather, iova, size);
         : 610              }
         :
         : 612              return size;
         : 613              } else if (iopte_leaf(pte, lvl, iop->fmt)) {
    0.00 :   ffff800010789e4c:       cmp     x23, #0x1
    0.00 :   ffff800010789e50:       lsl     x28, x28, x8
    0.00 :   ffff800010789e54:       b.eq    ffff800010789f80 <__arm_lpae_unmap+0x1e8>  // b.none
         : 617              iopte_to_paddr():
         : 171              u64 paddr = pte & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff800010789e58:       and     x19, x19, #0xfffffffff000
         : 173              __arm_lpae_unmap():
         : 618              return arm_lpae_split_blk_unmap(data, gather, iova, size, pte,
         : 619              lvl + 1, ptep);
         : 620              }
         :
         : 622              /* Keep on walkin' */
         : 623              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010789e5c:       adrp    x1, ffff800011571000 <rt_sched_class+0x10>
         : 625              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010789e60:       mov     x0, #0xffff                     // #65535
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789e64:       cmp     x28, x0
         : 179              __arm_lpae_unmap():
         : 618              ptep = iopte_deref(pte, data);
    5.37 :   ffff800010789e68:       ldr     x5, [x1, #3512]
         : 620              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789e6c:       orr     x0, x19, x19, lsl #36
    0.00 :   ffff800010789e70:       and     x0, x0, #0xfffffffff0000
         : 180              __arm_lpae_unmap():
         : 619              return __arm_lpae_unmap(data, gather, iova, size, lvl + 1, ptep);
    0.00 :   ffff800010789e74:       mov     x3, x21
         : 621              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789e78:       csel    x19, x19, x0, ls  // ls = plast
         : 179              __arm_lpae_unmap():
         : 619              return __arm_lpae_unmap(data, gather, iova, size, lvl + 1, ptep);
    0.00 :   ffff800010789e7c:       mov     x2, x22
         : 618              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010789e80:       sub     x5, x19, x5
         : 619              return __arm_lpae_unmap(data, gather, iova, size, lvl + 1, ptep);
    0.00 :   ffff800010789e84:       mov     x1, x24
    0.00 :   ffff800010789e88:       mov     x0, x20
    0.00 :   ffff800010789e8c:       orr     x5, x5, #0xffff000000000000
    0.00 :   ffff800010789e90:       bl      ffff800010789d98 <__arm_lpae_unmap>
    0.00 :   ffff800010789e94:       mov     x19, x0
    2.01 :   ffff800010789e98:       ldp     x21, x22, [sp, #32]
    2.18 :   ffff800010789e9c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010789ea0:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010789ea4:       ldp     x27, x28, [sp, #80]
         : 620              }
    0.00 :   ffff800010789ea8:       mov     x0, x19
    1.68 :   ffff800010789eac:       ldp     x19, x20, [sp, #16]
   12.05 :   ffff800010789eb0:       ldp     x29, x30, [sp], #144
    0.00 :   ffff800010789eb4:       autiasp
    0.17 :   ffff800010789eb8:       ret
         : 608              } else if (iopte_leaf(pte, lvl, iop->fmt)) {
    0.00 :   ffff800010789ebc:       cmp     x23, #0x3
    0.00 :   ffff800010789ec0:       b.eq    ffff80001078a148 <__arm_lpae_unmap+0x3b0>  // b.none
    0.00 :   ffff800010789ec4:       mov     x28, #0x8                       // #8
    0.00 :   ffff800010789ec8:       mov     w4, #0x4                        // #4
    0.00 :   ffff800010789ecc:       lsl     x28, x28, x8
    0.00 :   ffff800010789ed0:       b       ffff800010789e58 <__arm_lpae_unmap+0xc0>
         : 615              __arm_lpae_set_pte():
         : 245              *ptep = pte;
    0.00 :   ffff800010789ed4:       str     xzr, [x5, x6, lsl #3]
         : 247              if (!cfg->coherent_walk)
    1.17 :   ffff800010789ed8:       ldrb    w0, [x20, #40]
    0.00 :   ffff800010789edc:       cbz     w0, ffff80001078a164 <__arm_lpae_unmap+0x3cc>
         : 250              iopte_leaf():
         : 153              if (lvl == (ARM_LPAE_MAX_LEVELS - 1) && fmt != ARM_MALI_LPAE)
    0.00 :   ffff800010789ee0:       ldr     w0, [x20]
    0.00 :   ffff800010789ee4:       cmp     w25, #0x0
    0.00 :   ffff800010789ee8:       ccmp    w0, #0x5, #0x4, ne  // ne = any
    0.00 :   ffff800010789eec:       b.ne    ffff80001078a13c <__arm_lpae_unmap+0x3a4>  // b.any
         : 156              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;
    0.00 :   ffff800010789ef0:       cmp     x23, #0x1
    0.00 :   ffff800010789ef4:       cset    w0, eq  // eq = none
         : 159              __arm_lpae_unmap():
         : 590              if (!iopte_leaf(pte, lvl, iop->fmt)) {
    0.00 :   ffff800010789ef8:       cbnz    w0, ffff80001078a0fc <__arm_lpae_unmap+0x364>
         : 592              io_pgtable_tlb_flush_walk(iop, iova, size,
    0.00 :   ffff800010789efc:       ldr     x0, [x20, #48]
    0.00 :   ffff800010789f00:       mov     x23, #0x8                       // #8
    0.00 :   ffff800010789f04:       ldr     w2, [x20, #120]
    0.00 :   ffff800010789f08:       lsl     x2, x23, x2
         : 597              io_pgtable_tlb_flush_walk():
         :
         : 218              static inline void
         : 219              io_pgtable_tlb_flush_walk(struct io_pgtable *iop, unsigned long iova,
         : 220              size_t size, size_t granule)
         : 221              {
         : 222              if (iop->cfg.tlb && iop->cfg.tlb->tlb_flush_walk)
    0.00 :   ffff800010789f0c:       cbz     x0, ffff800010789f38 <__arm_lpae_unmap+0x1a0>
    0.00 :   ffff800010789f10:       ldr     x5, [x0, #8]
    0.00 :   ffff800010789f14:       cbz     x5, ffff800010789f38 <__arm_lpae_unmap+0x1a0>
         : 218              iop->cfg.tlb->tlb_flush_walk(iova, size, granule, iop->cookie);
    0.00 :   ffff800010789f18:       ldr     x3, [x20, #8]
    0.00 :   ffff800010789f1c:       mov     x0, x22
    0.00 :   ffff800010789f20:       mov     x1, x21
    0.00 :   ffff800010789f24:       str     w4, [sp, #96]
    0.00 :   ffff800010789f28:       blr     x5
    0.00 :   ffff800010789f2c:       ldr     w4, [sp, #96]
    0.00 :   ffff800010789f30:       ldr     w2, [x20, #120]
    0.00 :   ffff800010789f34:       lsl     x2, x23, x2
         : 227              iopte_to_paddr():
         : 171              u64 paddr = pte & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff800010789f38:       and     x19, x19, #0xfffffffff000
         : 173              __arm_lpae_unmap():
         : 594              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010789f3c:       adrp    x3, ffff800011571000 <rt_sched_class+0x10>
         : 596              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010789f40:       mov     x0, #0xffff                     // #65535
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789f44:       cmp     x2, x0
    0.00 :   ffff800010789f48:       orr     x0, x19, x19, lsl #36
         : 180              __arm_lpae_unmap():
         : 595              __arm_lpae_free_pgtable(data, lvl + 1, ptep);
    0.00 :   ffff800010789f4c:       add     w1, w4, #0x1
         : 594              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010789f50:       ldr     x2, [x3, #3512]
         : 596              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789f54:       and     x0, x0, #0xfffffffff0000
    0.00 :   ffff800010789f58:       csel    x19, x19, x0, ls  // ls = plast
         : 180              __arm_lpae_unmap():
         : 595              __arm_lpae_free_pgtable(data, lvl + 1, ptep);
    0.00 :   ffff800010789f5c:       mov     x0, x20
         : 594              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010789f60:       sub     x2, x19, x2
    0.00 :   ffff800010789f64:       mov     x19, x21
         : 595              __arm_lpae_free_pgtable(data, lvl + 1, ptep);
    0.00 :   ffff800010789f68:       orr     x2, x2, #0xffff000000000000
    0.00 :   ffff800010789f6c:       bl      ffff800010789218 <__arm_lpae_free_pgtable>
    0.00 :   ffff800010789f70:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010789f74:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010789f78:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010789f7c:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 602              arm_lpae_split_blk_unmap():
         : 525              size_t split_sz = ARM_LPAE_BLOCK_SIZE(lvl, data);
    0.00 :   ffff800010789f80:       mov     w25, #0x4                       // #4
    0.00 :   ffff800010789f84:       sub     w25, w25, w4
         : 528              if (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))
    0.00 :   ffff800010789f88:       cmp     w4, #0x4
         : 521              struct io_pgtable_cfg *cfg = &data->iop.cfg;
    0.00 :   ffff800010789f8c:       add     x9, x20, #0x10
         : 525              size_t split_sz = ARM_LPAE_BLOCK_SIZE(lvl, data);
    0.00 :   ffff800010789f90:       mul     w27, w8, w25
    0.00 :   ffff800010789f94:       add     w27, w27, #0x3
    0.00 :   ffff800010789f98:       lsl     x27, x23, x27
         : 528              if (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))
    0.00 :   ffff800010789f9c:       b.eq    ffff80001078a148 <__arm_lpae_unmap+0x3b0>  // b.none
         : 531              tablep = __arm_lpae_alloc_pages(tablesz, GFP_ATOMIC, cfg);
    0.00 :   ffff800010789fa0:       ldr     x3, [x20, #56]
    0.00 :   ffff800010789fa4:       add     x2, x20, #0x28
    0.00 :   ffff800010789fa8:       mov     w1, #0xa20                      // #2592
    0.00 :   ffff800010789fac:       mov     x0, x28
    0.00 :   ffff800010789fb0:       str     w4, [sp, #96]
    0.00 :   ffff800010789fb4:       str     x9, [sp, #104]
    0.00 :   ffff800010789fb8:       bl      ffff8000107894b8 <__arm_lpae_alloc_pages.isra.18>
    0.00 :   ffff800010789fbc:       mov     x5, x0
         : 532              if (!tablep)
    0.00 :   ffff800010789fc0:       ldr     w4, [sp, #96]
    0.00 :   ffff800010789fc4:       ldr     x9, [sp, #104]
    0.00 :   ffff800010789fc8:       cbz     x0, ffff80001078a14c <__arm_lpae_unmap+0x3b4>
         : 535              if (size == split_sz)
    0.00 :   ffff800010789fcc:       cmp     x21, x27
         : 526              int i, unmap_idx = -1;
    0.00 :   ffff800010789fd0:       mov     w7, #0xffffffff                 // #-1
    0.00 :   ffff800010789fd4:       ldr     w3, [x20, #120]
         : 535              if (size == split_sz)
    0.00 :   ffff800010789fd8:       b.eq    ffff80001078a1f4 <__arm_lpae_unmap+0x45c>  // b.none
         : 537              iopte_to_paddr():
         : 171              u64 paddr = pte & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff800010789fdc:       and     x23, x19, #0xfffffffff000
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010789fe0:       mov     x1, #0x8                        // #8
         : 175              arm_lpae_split_blk_unmap():
         : 539              pte = iopte_prot(blk_pte);
    0.00 :   ffff800010789fe4:       and     x2, x19, #0x7ffffffffffffc
         : 541              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010789fe8:       lsl     x1, x1, x3
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789fec:       orr     x0, x23, x23, lsl #36
         : 179              arm_lpae_split_blk_unmap():
         : 539              pte = iopte_prot(blk_pte);
    0.00 :   ffff800010789ff0:       and     x2, x2, #0xffe0000000000fff
         : 541              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010789ff4:       mov     x3, #0xffff                     // #65535
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010789ff8:       and     x0, x0, #0xfffffffff0000
    0.00 :   ffff800010789ffc:       cmp     x1, x3
         : 180              __arm_lpae_init_pte():
         : 263              pte |= ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a000:       orr     x10, x2, #0x3
         : 265              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a004:       csel    x23, x23, x0, ls  // ls = plast
         : 179              __arm_lpae_init_pte():
         : 263              pte |= ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a008:       orr     x2, x2, #0x1
         : 265              arm_lpae_split_blk_unmap():
         : 541              for (i = 0; i < tablesz / sizeof(pte); i++, blk_paddr += split_sz) {
    0.00 :   ffff80001078a00c:       lsr     x8, x28, #3
    0.00 :   ffff80001078a010:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001078a014:       mov     w25, #0x0                       // #0
    0.00 :   ffff80001078a018:       cbnz    x8, ffff80001078a030 <__arm_lpae_unmap+0x298>
    0.00 :   ffff80001078a01c:       b       ffff80001078a0a0 <__arm_lpae_unmap+0x308>
    0.00 :   ffff80001078a020:       sxtw    x1, w25
    0.00 :   ffff80001078a024:       add     x23, x23, x27
    0.00 :   ffff80001078a028:       cmp     x8, x1
    0.00 :   ffff80001078a02c:       b.ls    ffff80001078a0a0 <__arm_lpae_unmap+0x308>  // b.plast
         : 551              paddr_to_iopte():
         : 165              return (pte | (pte >> (48 - 12))) & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff80001078a030:       orr     x0, x23, x23, lsr #36
         : 167              arm_lpae_split_blk_unmap():
         : 543              if (i == unmap_idx)
    0.00 :   ffff80001078a034:       cmp     w25, w7
         : 545              paddr_to_iopte():
         : 165              return (pte | (pte >> (48 - 12))) & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff80001078a038:       and     x6, x0, #0xfffffffff000
         : 167              arm_lpae_split_blk_unmap():
         : 541              for (i = 0; i < tablesz / sizeof(pte); i++, blk_paddr += split_sz) {
    0.00 :   ffff80001078a03c:       add     w25, w25, #0x1
         : 543              if (i == unmap_idx)
    0.00 :   ffff80001078a040:       b.eq    ffff80001078a020 <__arm_lpae_unmap+0x288>  // b.none
         : 545              __arm_lpae_init_pte():
         : 262              if (data->iop.fmt != ARM_MALI_LPAE && lvl == ARM_LPAE_MAX_LEVELS - 1)
    0.00 :   ffff80001078a044:       ldr     w3, [x20]
         : 264              arm_lpae_split_blk_unmap():
         : 546              __arm_lpae_init_pte(data, blk_paddr, pte, lvl, &tablep[i]);
    0.00 :   ffff80001078a048:       add     x0, x5, x1, lsl #3
         : 548              __arm_lpae_init_pte():
         : 262              if (data->iop.fmt != ARM_MALI_LPAE && lvl == ARM_LPAE_MAX_LEVELS - 1)
    0.00 :   ffff80001078a04c:       cmp     w3, #0x5
         : 263              pte |= ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a050:       ccmp    w4, #0x3, #0x0, ne  // ne = any
    0.00 :   ffff80001078a054:       csel    x3, x2, x10, ne  // ne = any
         : 267              pte |= paddr_to_iopte(paddr, data);
    0.00 :   ffff80001078a058:       orr     x6, x6, x3
         : 269              __arm_lpae_set_pte():
         : 245              *ptep = pte;
    0.00 :   ffff80001078a05c:       str     x6, [x5, x1, lsl #3]
         : 247              if (!cfg->coherent_walk)
    0.00 :   ffff80001078a060:       ldrb    w1, [x9, #24]
    0.00 :   ffff80001078a064:       cbnz    w1, ffff80001078a020 <__arm_lpae_unmap+0x288>
         : 248              __arm_lpae_sync_pte(ptep, cfg);
    0.00 :   ffff80001078a068:       ldr     x1, [x20, #56]
    0.00 :   ffff80001078a06c:       stp     x8, x5, [sp, #96]
    0.00 :   ffff80001078a070:       stp     w7, w4, [sp, #112]
    0.00 :   ffff80001078a074:       stp     x9, x10, [sp, #120]
    0.00 :   ffff80001078a078:       str     x2, [sp, #136]
    0.00 :   ffff80001078a07c:       bl      ffff800010789350 <__arm_lpae_sync_pte.isra.17>
    0.00 :   ffff80001078a080:       ldp     w7, w4, [sp, #112]
    0.00 :   ffff80001078a084:       ldp     x8, x5, [sp, #96]
    0.00 :   ffff80001078a088:       ldp     x9, x10, [sp, #120]
    0.00 :   ffff80001078a08c:       ldr     x2, [sp, #136]
    0.00 :   ffff80001078a090:       b       ffff80001078a020 <__arm_lpae_unmap+0x288>
         : 260              __arm_lpae_unmap():
         : 578              if (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))
    0.00 :   ffff80001078a094:       brk     #0x800
         : 579              return 0;
    0.00 :   ffff80001078a098:       mov     x19, #0x0                       // #0
    0.00 :   ffff80001078a09c:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 582              arm_lpae_split_blk_unmap():
         : 549              pte = arm_lpae_install_table(tablep, ptep, blk_pte, cfg);
    0.00 :   ffff80001078a0a0:       mov     x0, x5
    0.00 :   ffff80001078a0a4:       mov     x3, x9
    0.00 :   ffff80001078a0a8:       mov     x1, x26
    0.00 :   ffff80001078a0ac:       mov     x2, x19
    0.00 :   ffff80001078a0b0:       str     x5, [sp, #96]
    0.00 :   ffff80001078a0b4:       str     w7, [sp, #104]
    0.00 :   ffff80001078a0b8:       str     w4, [sp, #112]
    0.00 :   ffff80001078a0bc:       bl      ffff8000107893c8 <arm_lpae_install_table>
    0.00 :   ffff80001078a0c0:       mov     x23, x0
         : 550              if (pte != blk_pte) {
    0.00 :   ffff80001078a0c4:       cmp     x19, x0
    0.00 :   ffff80001078a0c8:       ldr     w7, [sp, #104]
    0.00 :   ffff80001078a0cc:       ldr     w4, [sp, #112]
    0.00 :   ffff80001078a0d0:       ldr     x5, [sp, #96]
    0.00 :   ffff80001078a0d4:       b.ne    ffff80001078a17c <__arm_lpae_unmap+0x3e4>  // b.any
         : 561              } else if (unmap_idx >= 0) {
    0.00 :   ffff80001078a0d8:       tbz     w7, #31, ffff80001078a240 <__arm_lpae_unmap+0x4a8>
         : 566              return __arm_lpae_unmap(data, gather, iova, size, lvl, tablep);
    0.00 :   ffff80001078a0dc:       mov     x3, x21
    0.00 :   ffff80001078a0e0:       mov     x2, x22
    0.00 :   ffff80001078a0e4:       mov     x1, x24
    0.00 :   ffff80001078a0e8:       mov     x0, x20
    0.00 :   ffff80001078a0ec:       b       ffff800010789e90 <__arm_lpae_unmap+0xf8>
         : 572              __arm_lpae_unmap():
         : 583              if (WARN_ON(!pte))
    0.00 :   ffff80001078a0f0:       brk     #0x800
    0.00 :   ffff80001078a0f4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a0f8:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 596              } else if (iop->cfg.quirks & IO_PGTABLE_QUIRK_NON_STRICT) {
    0.67 :   ffff80001078a0fc:       ldr     x0, [x20, #16]
    0.00 :   ffff80001078a100:       tbnz    w0, #4, ffff80001078a1dc <__arm_lpae_unmap+0x444>
         : 604              io_pgtable_tlb_add_page(iop, gather, iova, size);
    2.01 :   ffff80001078a104:       ldr     x0, [x20, #48]
         : 606              io_pgtable_tlb_add_page():
         : 226              static inline void
         : 227              io_pgtable_tlb_add_page(struct io_pgtable *iop,
         : 228              struct iommu_iotlb_gather * gather, unsigned long iova,
         : 229              size_t granule)
         : 230              {
         : 231              if (iop->cfg.tlb && iop->cfg.tlb->tlb_add_page)
    0.00 :   ffff80001078a108:       cbz     x0, ffff80001078a22c <__arm_lpae_unmap+0x494>
    0.00 :   ffff80001078a10c:       ldr     x4, [x0, #16]
    0.00 :   ffff80001078a110:       cbz     x4, ffff80001078a22c <__arm_lpae_unmap+0x494>
         : 227              iop->cfg.tlb->tlb_add_page(gather, iova, granule, iop->cookie);
    2.68 :   ffff80001078a114:       ldr     x3, [x20, #8]
    0.00 :   ffff80001078a118:       mov     x1, x22
    0.00 :   ffff80001078a11c:       mov     x0, x24
    0.00 :   ffff80001078a120:       mov     x2, x21
    1.17 :   ffff80001078a124:       mov     x19, x21
    0.00 :   ffff80001078a128:       blr     x4
    0.00 :   ffff80001078a12c:       ldp     x21, x22, [sp, #32]
    0.67 :   ffff80001078a130:       ldp     x23, x24, [sp, #48]
    0.17 :   ffff80001078a134:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a138:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 238              iopte_leaf():
         : 154              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff80001078a13c:       cmp     x23, #0x3
    0.00 :   ffff80001078a140:       cset    w0, eq  // eq = none
    0.00 :   ffff80001078a144:       b       ffff800010789ef8 <__arm_lpae_unmap+0x160>
         : 158              arm_lpae_split_blk_unmap():
         : 528              if (WARN_ON(lvl == ARM_LPAE_MAX_LEVELS))
    0.00 :   ffff80001078a148:       brk     #0x800
         : 558              return 0;
    0.00 :   ffff80001078a14c:       mov     x19, #0x0                       // #0
    0.00 :   ffff80001078a150:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078a154:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078a158:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a15c:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001078a160:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 565              __arm_lpae_set_pte():
         : 248              __arm_lpae_sync_pte(ptep, cfg);
    0.00 :   ffff80001078a164:       ldr     x1, [x20, #56]
    0.00 :   ffff80001078a168:       mov     x0, x26
    0.00 :   ffff80001078a16c:       str     w4, [sp, #96]
    0.00 :   ffff80001078a170:       bl      ffff800010789350 <__arm_lpae_sync_pte.isra.17>
    0.00 :   ffff80001078a174:       ldr     w4, [sp, #96]
    0.00 :   ffff80001078a178:       b       ffff800010789ee0 <__arm_lpae_unmap+0x148>
         : 255              arm_lpae_split_blk_unmap():
         : 551              __arm_lpae_free_pages(tablep, tablesz, cfg);
    0.00 :   ffff80001078a17c:       ldrb    w2, [x20, #40]
    0.00 :   ffff80001078a180:       mov     x0, x5
    0.00 :   ffff80001078a184:       mov     x1, x28
    0.00 :   ffff80001078a188:       add     x3, x20, #0x38
    0.00 :   ffff80001078a18c:       str     w4, [sp, #96]
    0.00 :   ffff80001078a190:       bl      ffff800010789178 <__arm_lpae_free_pages.isra.15>
         : 557              if (iopte_type(pte) != ARM_LPAE_PTE_TYPE_TABLE)
    0.00 :   ffff80001078a194:       ldr     w4, [sp, #96]
    0.00 :   ffff80001078a198:       and     x0, x23, #0x3
    0.00 :   ffff80001078a19c:       cmp     x0, #0x3
    0.00 :   ffff80001078a1a0:       b.ne    ffff80001078a14c <__arm_lpae_unmap+0x3b4>  // b.any
         : 562              iopte_to_paddr():
         : 171              u64 paddr = pte & ARM_LPAE_PTE_ADDR_MASK;
    0.00 :   ffff80001078a1a4:       and     x23, x23, #0xfffffffff000
         : 173              arm_lpae_split_blk_unmap():
         : 560              tablep = iopte_deref(pte, data);
    0.00 :   ffff80001078a1a8:       adrp    x5, ffff800011571000 <rt_sched_class+0x10>
         : 562              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff80001078a1ac:       ldr     w3, [x20, #120]
    0.00 :   ffff80001078a1b0:       mov     x1, #0x8                        // #8
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a1b4:       orr     x0, x23, x23, lsl #36
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff80001078a1b8:       mov     x2, #0xffff                     // #65535
         : 175              arm_lpae_split_blk_unmap():
         : 560              tablep = iopte_deref(pte, data);
    0.00 :   ffff80001078a1bc:       ldr     x5, [x5, #3512]
         : 562              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a1c0:       and     x0, x0, #0xfffffffff0000
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff80001078a1c4:       lsl     x1, x1, x3
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff80001078a1c8:       cmp     x1, x2
    0.00 :   ffff80001078a1cc:       csel    x23, x23, x0, ls  // ls = plast
         : 180              arm_lpae_split_blk_unmap():
         : 560              tablep = iopte_deref(pte, data);
    0.00 :   ffff80001078a1d0:       sub     x23, x23, x5
    0.00 :   ffff80001078a1d4:       orr     x5, x23, #0xffff000000000000
    0.00 :   ffff80001078a1d8:       b       ffff80001078a0dc <__arm_lpae_unmap+0x344>
         : 564              __arm_lpae_unmap():
         : 602              smp_wmb();
    0.00 :   ffff80001078a1dc:       dmb     ishst
    0.00 :   ffff80001078a1e0:       mov     x19, x21
    0.00 :   ffff80001078a1e4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078a1e8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078a1ec:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a1f0:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 609              arm_lpae_split_blk_unmap():
         : 536              unmap_idx = ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.00 :   ffff80001078a1f4:       mul     w7, w25, w3
    0.00 :   ffff80001078a1f8:       ldr     w0, [x20, #116]
    0.00 :   ffff80001078a1fc:       mov     w1, w3
    0.00 :   ffff80001078a200:       add     w7, w7, #0x3
    0.00 :   ffff80001078a204:       cmp     w0, w4
    0.00 :   ffff80001078a208:       lsr     x0, x22, x7
    0.00 :   ffff80001078a20c:       b.ne    ffff80001078a214 <__arm_lpae_unmap+0x47c>  // b.any
    0.00 :   ffff80001078a210:       ldr     w1, [x20, #112]
    0.00 :   ffff80001078a214:       mov     w7, #0x1                        // #1
    0.00 :   ffff80001078a218:       lsl     w7, w7, w1
    0.00 :   ffff80001078a21c:       sub     w7, w7, #0x1
    0.00 :   ffff80001078a220:       and     w7, w7, w0
    0.00 :   ffff80001078a224:       b       ffff800010789fdc <__arm_lpae_unmap+0x244>
    0.00 :   ffff80001078a228:       ldp     x27, x28, [sp, #80]
         : 558              return 0;
    0.00 :   ffff80001078a22c:       mov     x19, x21
    0.00 :   ffff80001078a230:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078a234:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078a238:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a23c:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
         : 562              io_pgtable_tlb_add_page(&data->iop, gather, iova, size);
    0.00 :   ffff80001078a240:       ldr     x0, [x20, #48]
         : 564              io_pgtable_tlb_add_page():
         : 226              if (iop->cfg.tlb && iop->cfg.tlb->tlb_add_page)
    0.00 :   ffff80001078a244:       cbz     x0, ffff80001078a228 <__arm_lpae_unmap+0x490>
    0.00 :   ffff80001078a248:       ldr     x4, [x0, #16]
    0.00 :   ffff80001078a24c:       cbz     x4, ffff80001078a228 <__arm_lpae_unmap+0x490>
         : 227              iop->cfg.tlb->tlb_add_page(gather, iova, granule, iop->cookie);
    0.00 :   ffff80001078a250:       ldr     x3, [x20, #8]
    0.00 :   ffff80001078a254:       mov     x1, x22
    0.00 :   ffff80001078a258:       mov     x0, x24
    0.00 :   ffff80001078a25c:       mov     x2, x21
    0.00 :   ffff80001078a260:       mov     x19, x21
    0.00 :   ffff80001078a264:       blr     x4
    0.00 :   ffff80001078a268:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078a26c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078a270:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078a274:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001078a278:       b       ffff800010789ea8 <__arm_lpae_unmap+0x110>
 Percent |	Source code & Disassembly of vmlinux for cycles (562 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001078a5b8 <arm_lpae_map>:
         : 6                arm_lpae_map():
         : 445              return pte;
         : 446              }
         :
         : 448              static int arm_lpae_map(struct io_pgtable_ops *ops, unsigned long iova,
         : 449              phys_addr_t paddr, size_t size, int iommu_prot, gfp_t gfp)
         : 450              {
    2.32 :   ffff80001078a5b8:       paciasp
    2.33 :   ffff80001078a5bc:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001078a5c0:       mov     x6, x0
    0.00 :   ffff80001078a5c4:       mov     x29, sp
         : 451              struct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);
         : 452              struct io_pgtable_cfg *cfg = &data->iop.cfg;
         : 453              arm_lpae_iopte *ptep = data->pgd;
         : 454              int ret, lvl = data->start_level;
         : 455              arm_lpae_iopte prot;
         : 456              long iaext = (s64)iova >> cfg->ias;
    0.00 :   ffff80001078a5c8:       ldur    w0, [x0, #-56]
    0.00 :   ffff80001078a5cc:       asr     x0, x1, x0
         :
         : 454              if (WARN_ON(!size || (size & cfg->pgsize_bitmap) != size))
    0.00 :   ffff80001078a5d0:       cbnz    x3, ffff80001078a5e8 <arm_lpae_map+0x30>
    0.00 :   ffff80001078a5d4:       brk     #0x800
         : 454              return -EINVAL;
    0.00 :   ffff80001078a5d8:       mov     w0, #0xffffffea                 // #-22
         : 474              * a chance for anything to kick off a table walk for the new iova.
         : 475              */
         : 476              wmb();
         :
         : 478              return ret;
         : 479              }
    0.00 :   ffff80001078a5dc:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001078a5e0:       autiasp
    0.00 :   ffff80001078a5e4:       ret
         : 453              if (WARN_ON(!size || (size & cfg->pgsize_bitmap) != size))
    0.36 :   ffff80001078a5e8:       ldur    x7, [x6, #-64]
    0.00 :   ffff80001078a5ec:       bics    xzr, x3, x7
    0.00 :   ffff80001078a5f0:       b.ne    ffff80001078a5d4 <arm_lpae_map+0x1c>  // b.any
         : 456              if (cfg->quirks & IO_PGTABLE_QUIRK_ARM_TTBR1)
    2.68 :   ffff80001078a5f4:       ldur    x9, [x6, #-72]
         : 457              iaext = ~iaext;
    0.00 :   ffff80001078a5f8:       tst     x9, #0x20
    0.00 :   ffff80001078a5fc:       cinv    x0, x0, ne  // ne = any
         : 458              if (WARN_ON(iaext || paddr >> cfg->oas))
    0.00 :   ffff80001078a600:       cbz     x0, ffff80001078a610 <arm_lpae_map+0x58>
    0.00 :   ffff80001078a604:       brk     #0x800
         : 459              return -ERANGE;
    0.00 :   ffff80001078a608:       mov     w0, #0xffffffde                 // #-34
    0.00 :   ffff80001078a60c:       b       ffff80001078a5dc <arm_lpae_map+0x24>
         : 458              if (WARN_ON(iaext || paddr >> cfg->oas))
    0.00 :   ffff80001078a610:       ldur    w8, [x6, #-52]
    0.00 :   ffff80001078a614:       lsr     x8, x2, x8
    0.00 :   ffff80001078a618:       cbnz    x8, ffff80001078a604 <arm_lpae_map+0x4c>
         : 462              if (!(iommu_prot & (IOMMU_READ | IOMMU_WRITE)))
    1.25 :   ffff80001078a61c:       ands    w0, w4, #0x3
    0.00 :   ffff80001078a620:       b.eq    ffff80001078a5dc <arm_lpae_map+0x24>  // b.none
         : 465              prot = arm_lpae_prot_to_pte(data, iommu_prot);
    3.38 :   ffff80001078a624:       ldur    w7, [x6, #-88]
         : 467              arm_lpae_prot_to_pte():
         : 384              if (data->iop.fmt == ARM_64_LPAE_S1 ||
    0.00 :   ffff80001078a628:       ands    w8, w7, #0xfffffffd
    0.00 :   ffff80001078a62c:       b.eq    ffff80001078a654 <arm_lpae_map+0x9c>  // b.none
         : 403              if (data->iop.fmt == ARM_64_LPAE_S2 ||
    0.00 :   ffff80001078a630:       cmp     w8, #0x1
    0.00 :   ffff80001078a634:       and     w10, w4, #0x10
         : 396              pte |= ARM_LPAE_PTE_HAP_WRITE;
    0.00 :   ffff80001078a638:       ubfiz   x8, x4, #6, #2
         : 403              if (data->iop.fmt == ARM_64_LPAE_S2 ||
    0.00 :   ffff80001078a63c:       and     w0, w4, #0x4
    0.00 :   ffff80001078a640:       b.ne    ffff80001078a678 <arm_lpae_map+0xc0>  // b.any
         : 405              if (prot & IOMMU_MMIO)
    0.00 :   ffff80001078a644:       cbnz    w10, ffff80001078a6f0 <arm_lpae_map+0x138>
         : 407              else if (prot & IOMMU_CACHE)
    0.00 :   ffff80001078a648:       cbz     w0, ffff80001078a6f8 <arm_lpae_map+0x140>
         : 408              pte |= ARM_LPAE_PTE_MEMATTR_OIWB;
    0.00 :   ffff80001078a64c:       orr     x8, x8, #0x3c
    0.00 :   ffff80001078a650:       b       ffff80001078a680 <arm_lpae_map+0xc8>
         : 386              pte = ARM_LPAE_PTE_nG;
    0.00 :   ffff80001078a654:       cmp     w0, #0x1
    0.00 :   ffff80001078a658:       mov     x8, #0x880                      // #2176
    0.00 :   ffff80001078a65c:       mov     x0, #0x800                      // #2048
    0.00 :   ffff80001078a660:       csel    x8, x8, x0, eq  // eq = none
         : 390              pte |= ARM_LPAE_PTE_AP_UNPRIV;
    0.89 :   ffff80001078a664:       orr     x0, x8, #0x40
    0.00 :   ffff80001078a668:       tst     x4, #0x20
    0.00 :   ffff80001078a66c:       csel    x8, x0, x8, eq  // eq = none
         : 403              if (data->iop.fmt == ARM_64_LPAE_S2 ||
    0.00 :   ffff80001078a670:       and     w10, w4, #0x10
    0.00 :   ffff80001078a674:       and     w0, w4, #0x4
         : 412              if (prot & IOMMU_MMIO)
    0.00 :   ffff80001078a678:       cbz     w10, ffff80001078a6ec <arm_lpae_map+0x134>
         : 413              pte |= (ARM_LPAE_MAIR_ATTR_IDX_DEV
    0.00 :   ffff80001078a67c:       orr     x8, x8, #0x8
         : 426              if (prot & IOMMU_CACHE && data->iop.fmt != ARM_MALI_LPAE)
    1.78 :   ffff80001078a680:       cmp     w7, #0x5
    0.00 :   ffff80001078a684:       cset    w10, ne  // ne = any
    0.00 :   ffff80001078a688:       cmp     w0, #0x0
    0.00 :   ffff80001078a68c:       csel    w0, w10, wzr, ne  // ne = any
    0.00 :   ffff80001078a690:       cbnz    w0, ffff80001078a6e0 <arm_lpae_map+0x128>
         : 429              pte |= ARM_LPAE_PTE_SH_OS;
    0.00 :   ffff80001078a694:       orr     x8, x8, #0x200
         : 431              arm_lpae_map():
         : 448              arm_lpae_iopte *ptep = data->pgd;
    4.45 :   ffff80001078a698:       sub     x0, x6, #0x58
         : 450              arm_lpae_prot_to_pte():
         : 432              pte |= ARM_LPAE_PTE_XN;
    0.00 :   ffff80001078a69c:       tst     x4, #0x8
    0.00 :   ffff80001078a6a0:       orr     x4, x8, #0x60000000000000
    0.00 :   ffff80001078a6a4:       mov     w7, w5
    0.00 :   ffff80001078a6a8:       csel    x8, x4, x8, ne  // ne = any
         : 435              pte |= ARM_LPAE_PTE_NS;
    0.00 :   ffff80001078a6ac:       tst     x9, #0x1
    0.00 :   ffff80001078a6b0:       orr     x4, x8, #0x20
         : 438              arm_lpae_map():
         : 466              ret = __arm_lpae_map(data, iova, paddr, size, prot, lvl, ptep, gfp);
    0.00 :   ffff80001078a6b4:       ldr     w5, [x0, #116]
    4.98 :   ffff80001078a6b8:       ldr     x6, [x0, #128]
         : 469              arm_lpae_prot_to_pte():
         : 435              pte |= ARM_LPAE_PTE_NS;
    0.00 :   ffff80001078a6bc:       csel    x8, x4, x8, ne  // ne = any
         : 438              pte |= ARM_LPAE_PTE_AF;
    0.00 :   ffff80001078a6c0:       cmp     w10, #0x0
    0.00 :   ffff80001078a6c4:       orr     x4, x8, #0x400
         : 441              arm_lpae_map():
         : 466              ret = __arm_lpae_map(data, iova, paddr, size, prot, lvl, ptep, gfp);
    0.00 :   ffff80001078a6c8:       csel    x4, x4, x8, ne  // ne = any
    0.00 :   ffff80001078a6cc:       bl      ffff80001078a308 <__arm_lpae_map>
         : 471              wmb();
    0.36 :   ffff80001078a6d0:       dsb     st
         : 474              }
   55.56 :   ffff80001078a6d4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001078a6d8:       autiasp
   19.31 :   ffff80001078a6dc:       ret
         : 478              arm_lpae_prot_to_pte():
         : 427              pte |= ARM_LPAE_PTE_SH_IS;
    0.00 :   ffff80001078a6e0:       orr     x8, x8, #0x300
         : 426              if (prot & IOMMU_CACHE && data->iop.fmt != ARM_MALI_LPAE)
    0.00 :   ffff80001078a6e4:       mov     w10, w0
    0.00 :   ffff80001078a6e8:       b       ffff80001078a698 <arm_lpae_map+0xe0>
         : 415              else if (prot & IOMMU_CACHE)
    0.18 :   ffff80001078a6ec:       cbz     w0, ffff80001078a700 <arm_lpae_map+0x148>
         : 416              pte |= (ARM_LPAE_MAIR_ATTR_IDX_CACHE
    0.18 :   ffff80001078a6f0:       orr     x8, x8, #0x4
    0.00 :   ffff80001078a6f4:       b       ffff80001078a680 <arm_lpae_map+0xc8>
         : 410              pte |= ARM_LPAE_PTE_MEMATTR_NC;
    0.00 :   ffff80001078a6f8:       mov     x0, #0x14                       // #20
    0.00 :   ffff80001078a6fc:       orr     x8, x8, x0
         : 426              if (prot & IOMMU_CACHE && data->iop.fmt != ARM_MALI_LPAE)
    0.00 :   ffff80001078a700:       cmp     w7, #0x5
    0.00 :   ffff80001078a704:       cset    w10, ne  // ne = any
    0.00 :   ffff80001078a708:       b       ffff80001078a694 <arm_lpae_map+0xdc>
 Percent |	Source code & Disassembly of vmlinux for cycles (395 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010788eb8 <arm_lpae_iova_to_phys>:
         : 6                arm_lpae_iova_to_phys():
         :
         : 646              static phys_addr_t arm_lpae_iova_to_phys(struct io_pgtable_ops *ops,
         : 647              unsigned long iova)
         : 648              {
         : 649              struct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);
         : 650              arm_lpae_iopte pte, *ptep = data->pgd;
    0.76 :   ffff800010788eb8:       sub     x7, x0, #0x58
         : 643              {
    0.00 :   ffff800010788ebc:       paciasp
         : 646              int lvl = data->start_level;
    0.00 :   ffff800010788ec0:       ldr     w8, [x7, #116]
         : 645              arm_lpae_iopte pte, *ptep = data->pgd;
    0.51 :   ffff800010788ec4:       ldr     x0, [x7, #128]
         :
         : 651              do {
         : 652              /* Valid IOPTE pointer? */
         : 653              if (!ptep)
    0.00 :   ffff800010788ec8:       cbz     x0, ffff800010788fbc <arm_lpae_iova_to_phys+0x104>
         : 654              return 0;
         :
         : 656              /* Grab the IOPTE we're interested in */
         : 657              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.25 :   ffff800010788ecc:       ldr     w5, [x7, #120]
    0.00 :   ffff800010788ed0:       mov     w4, #0x4                        // #4
    0.00 :   ffff800010788ed4:       sub     w4, w4, w8
         : 666              /* Leaf entry? */
         : 667              if (iopte_leaf(pte, lvl, data->iop.fmt))
         : 668              goto found_translation;
         :
         : 670              /* Take it to the next level */
         : 671              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010788ed8:       adrp    x2, ffff800011571000 <rt_sched_class+0x10>
         : 673              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.51 :   ffff800010788edc:       mov     x9, #0x8                        // #8
         : 175              arm_lpae_iova_to_phys():
         : 646              int lvl = data->start_level;
    0.00 :   ffff800010788ee0:       mov     w3, w8
         : 666              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010788ee4:       ldr     x12, [x2, #3512]
    0.00 :   ffff800010788ee8:       mul     w4, w4, w5
         : 654              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.00 :   ffff800010788eec:       mov     w10, #0x1                       // #1
         : 656              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010788ef0:       mov     x11, #0xffff                    // #65535
    0.25 :   ffff800010788ef4:       lsl     x9, x9, x5
    0.00 :   ffff800010788ef8:       add     w4, w4, #0x3
    0.00 :   ffff800010788efc:       b       ffff800010788f38 <arm_lpae_iova_to_phys+0x80>
         : 178              iopte_leaf():
         : 156              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;
    7.87 :   ffff800010788f00:       cmp     x2, #0x1
         : 158              arm_lpae_iova_to_phys():
         : 667              } while (++lvl < ARM_LPAE_MAX_LEVELS);
    0.00 :   ffff800010788f04:       add     w3, w3, #0x1
         : 669              iopte_leaf():
         : 156              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_BLOCK;
    0.00 :   ffff800010788f08:       cset    w2, eq  // eq = none
    0.00 :   ffff800010788f0c:       and     x0, x0, #0xfffffffff000
         : 159              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010788f10:       cmp     x9, x11
         : 179              arm_lpae_iova_to_phys():
         : 662              if (iopte_leaf(pte, lvl, data->iop.fmt))
    0.00 :   ffff800010788f14:       cbnz    w2, ffff800010788f90 <arm_lpae_iova_to_phys+0xd8>
         : 664              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010788f18:       orr     x2, x0, x0, lsl #36
    0.51 :   ffff800010788f1c:       sub     w4, w4, w5
    0.00 :   ffff800010788f20:       and     x2, x2, #0xfffffffff0000
    0.00 :   ffff800010788f24:       csel    x0, x2, x0, hi  // hi = pmore
         : 182              arm_lpae_iova_to_phys():
         : 667              } while (++lvl < ARM_LPAE_MAX_LEVELS);
   14.48 :   ffff800010788f28:       cmp     w3, #0x3
         : 666              ptep = iopte_deref(pte, data);
    0.00 :   ffff800010788f2c:       sub     x0, x0, x12
    0.00 :   ffff800010788f30:       orr     x0, x0, #0xffff000000000000
         : 667              } while (++lvl < ARM_LPAE_MAX_LEVELS);
    0.00 :   ffff800010788f34:       b.gt    ffff800010788fbc <arm_lpae_iova_to_phys+0x104>
         : 654              ptep += ARM_LPAE_LVL_IDX(iova, lvl, data);
    0.00 :   ffff800010788f38:       cmp     w8, w3
    0.00 :   ffff800010788f3c:       lsr     x6, x1, x4
    0.00 :   ffff800010788f40:       mov     w2, w5
    0.00 :   ffff800010788f44:       b.ne    ffff800010788f4c <arm_lpae_iova_to_phys+0x94>  // b.any
    0.50 :   ffff800010788f48:       ldr     w2, [x7, #112]
    0.00 :   ffff800010788f4c:       lsl     w2, w10, w2
    0.00 :   ffff800010788f50:       sub     w2, w2, #0x1
    0.00 :   ffff800010788f54:       sxtw    x2, w2
    0.76 :   ffff800010788f58:       and     x2, x2, x6
         : 655              pte = READ_ONCE(*ptep);
    0.00 :   ffff800010788f5c:       ldr     x0, [x0, x2, lsl #3]
         : 658              if (!pte)
    1.27 :   ffff800010788f60:       and     x2, x0, #0x3
    2.59 :   ffff800010788f64:       cbz     x0, ffff800010788fb4 <arm_lpae_iova_to_phys+0xfc>
         : 661              iopte_leaf():
         : 153              if (lvl == (ARM_LPAE_MAX_LEVELS - 1) && fmt != ARM_MALI_LPAE)
   63.66 :   ffff800010788f68:       ldr     w6, [x7]
    0.00 :   ffff800010788f6c:       cmp     w6, #0x5
    0.00 :   ffff800010788f70:       ccmp    w3, #0x3, #0x0, ne  // ne = any
    0.26 :   ffff800010788f74:       b.ne    ffff800010788f00 <arm_lpae_iova_to_phys+0x48>  // b.any
         : 154              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_PAGE;
    0.50 :   ffff800010788f78:       cmp     x2, #0x3
         : 156              arm_lpae_iova_to_phys():
         : 667              } while (++lvl < ARM_LPAE_MAX_LEVELS);
    0.00 :   ffff800010788f7c:       add     w3, w3, #0x1
         : 669              iopte_leaf():
         : 154              return iopte_type(pte) == ARM_LPAE_PTE_TYPE_PAGE;
    0.00 :   ffff800010788f80:       cset    w2, eq  // eq = none
         : 156              iopte_to_paddr():
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010788f84:       and     x0, x0, #0xfffffffff000
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010788f88:       cmp     x9, x11
         : 179              arm_lpae_iova_to_phys():
         : 662              if (iopte_leaf(pte, lvl, data->iop.fmt))
    0.00 :   ffff800010788f8c:       cbz     w2, ffff800010788f18 <arm_lpae_iova_to_phys+0x60>
         : 664              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010788f90:       orr     x3, x0, x0, lsl #36
         : 173              if (ARM_LPAE_GRANULE(data) < SZ_64K)
    0.00 :   ffff800010788f94:       mov     x2, #0xffff                     // #65535
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010788f98:       and     x3, x3, #0xfffffffff0000
    0.00 :   ffff800010788f9c:       cmp     x9, x2
         : 180              arm_lpae_iova_to_phys():
         :
         : 674              /* Ran out of page tables to walk */
         : 675              return 0;
         :
         : 677              found_translation:
         : 678              iova &= (ARM_LPAE_BLOCK_SIZE(lvl, data) - 1);
    5.32 :   ffff800010788fa0:       mov     x2, #0xffffffffffffffff         // #-1
         : 680              iopte_to_paddr():
         : 177              return (paddr | (paddr << (48 - 12))) & (ARM_LPAE_PTE_ADDR_MASK << 4);
    0.00 :   ffff800010788fa4:       csel    x0, x3, x0, hi  // hi = pmore
         : 179              arm_lpae_iova_to_phys():
         : 673              iova &= (ARM_LPAE_BLOCK_SIZE(lvl, data) - 1);
    0.00 :   ffff800010788fa8:       lsl     x4, x2, x4
    0.00 :   ffff800010788fac:       bic     x4, x1, x4
         : 674              return iopte_to_paddr(pte, data) | iova;
    0.00 :   ffff800010788fb0:       orr     x0, x4, x0
         : 675              }
    0.00 :   ffff800010788fb4:       autiasp
    0.00 :   ffff800010788fb8:       ret
         : 651              return 0;
    0.00 :   ffff800010788fbc:       mov     x0, #0x0                        // #0
         : 675              }
    0.00 :   ffff800010788fc0:       autiasp
    0.00 :   ffff800010788fc4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (272 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001078b588 <alloc_iova_fast>:
         : 6                alloc_iova_fast():
         : 495              * @flush_rcache: - set to flush rcache on regular allocation failure
         : 496              * This function tries to satisfy an iova allocation from the rcache,
         : 497              * and falls back to regular allocation on failure. If regular allocation
         : 498              * fails too and the flush_rcache flag is set then the rcache will be flushed.
         : 499              */
         : 500              unsigned long
    1.47 :   ffff80001078b588:       paciasp
    0.00 :   ffff80001078b58c:       stp     x29, x30, [sp, #-96]!
         : 503              __order_base_2():
         : 201              )
         :
         : 203              static inline __attribute_const__
         : 204              int __order_base_2(unsigned long n)
         : 205              {
         : 206              return n > 1 ? ilog2(n - 1) + 1 : 0;
    0.00 :   ffff80001078b590:       cmp     x1, #0x1
         : 208              alloc_iova_fast():
    0.00 :   ffff80001078b594:       mov     x29, sp
    0.00 :   ffff80001078b598:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001078b59c:       and     w20, w3, #0xff
    0.37 :   ffff80001078b5a0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001078b5a4:       mov     x21, x0
    3.31 :   ffff80001078b5a8:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001078b5ac:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001078b5b0:       mov     x26, x1
    2.21 :   ffff80001078b5b4:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001078b5b8:       mov     x27, x2
         : 505              __order_base_2():
    0.00 :   ffff80001078b5bc:       b.ls    ffff80001078b6cc <alloc_iova_fast+0x144>  // b.plast
    0.00 :   ffff80001078b5c0:       sub     x0, x1, #0x1
         : 203              __fls():
         : 13               *
         : 14               * Undefined if no set bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __fls(unsigned long word)
         : 17               {
         : 18               return (sizeof(word) * 8) - 1 - __builtin_clzl(word);
    0.00 :   ffff80001078b5c4:       mov     x19, #0x3f                      // #63
    0.00 :   ffff80001078b5c8:       clz     x0, x0
    0.00 :   ffff80001078b5cc:       sub     x19, x19, x0
         : 22               fls64():
         : 31               #elif BITS_PER_LONG == 64
         : 32               static __always_inline int fls64(__u64 x)
         : 33               {
         : 34               if (x == 0)
         : 35               return 0;
         : 36               return __fls(x) + 1;
    0.00 :   ffff80001078b5d0:       add     w19, w19, #0x1
         : 38               iova_rcache_get():
         : 1011             * size is too big or the DMA limit we are given isn't satisfied by the
         : 1012             * top element in the magazine.
         : 1013             */
         : 1014             static unsigned long iova_rcache_get(struct iova_domain *iovad,
         : 1015             unsigned long size,
         : 1016             unsigned long limit_pfn)
    0.00 :   ffff80001078b5d4:       cmp     w19, #0x5
    0.00 :   ffff80001078b5d8:       b.ls    ffff80001078b7fc <alloc_iova_fast+0x274>  // b.plast
         : 1019             alloc_iova_fast():
         : 504              return iova_pfn;
    0.00 :   ffff80001078b5dc:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001078b5e0:       adrp    x23, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001078b5e4:       add     x24, x24, #0x9e8
    0.00 :   ffff80001078b5e8:       add     x23, x23, #0xc30
    0.00 :   ffff80001078b5ec:       mov     w3, #0x1                        // #1
    0.00 :   ffff80001078b5f0:       mov     x2, x27
    0.00 :   ffff80001078b5f4:       mov     x1, x26
    0.00 :   ffff80001078b5f8:       mov     x0, x21
    0.00 :   ffff80001078b5fc:       bl      ffff80001078aa18 <alloc_iova>
         :
    0.00 :   ffff80001078b600:       cbnz    x0, ffff80001078b6c4 <alloc_iova_fast+0x13c>
    0.00 :   ffff80001078b604:       nop
         : 508              if (!new_iova) {
    0.00 :   ffff80001078b608:       cbz     w20, ffff80001078b7b8 <alloc_iova_fast+0x230>
         :
    0.00 :   ffff80001078b60c:       mov     w19, #0xffffffff                // #-1
    0.00 :   ffff80001078b610:       b       ffff80001078b61c <alloc_iova_fast+0x94>
         : 514              /* Try replenishing IOVAs by flushing rcache. */
    0.00 :   ffff80001078b614:       mov     x1, x21
    0.00 :   ffff80001078b618:       bl      ffff80001078b298 <free_cpu_cached_iovas>
         :
    0.00 :   ffff80001078b61c:       mov     w0, w19
    0.00 :   ffff80001078b620:       mov     x1, x24
    0.00 :   ffff80001078b624:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff80001078b628:       mov     w19, w0
    0.00 :   ffff80001078b62c:       ldr     w1, [x23]
    0.00 :   ffff80001078b630:       cmp     w1, w0
    0.00 :   ffff80001078b634:       b.hi    ffff80001078b614 <alloc_iova_fast+0x8c>  // b.pmore
    0.00 :   ffff80001078b638:       add     x19, x21, #0x80
    0.00 :   ffff80001078b63c:       add     x25, x21, #0x710
         : 523              free_global_cached_iovas():
         : 1071             */
         : 1072             static void free_global_cached_iovas(struct iova_domain *iovad)
         : 1073             {
         : 1074             struct iova_rcache *rcache;
         : 1075             unsigned long flags;
         : 1076             int i, j;
    0.00 :   ffff80001078b640:       mov     x0, x19
    0.00 :   ffff80001078b644:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff80001078b648:       mov     x22, x0
         :
    0.00 :   ffff80001078b64c:       sub     x28, x19, #0x80
    0.00 :   ffff80001078b650:       ldr     x0, [x19, #8]
    0.00 :   ffff80001078b654:       mov     x20, #0x0                       // #0
    0.00 :   ffff80001078b658:       cbz     x0, ffff80001078b68c <alloc_iova_fast+0x104>
    0.00 :   ffff80001078b65c:       nop
         : 1073             for (i = 0; i < IOVA_RANGE_CACHE_MAX_SIZE; ++i) {
    0.00 :   ffff80001078b660:       ldr     x0, [x28, #144]
         : 1075             iova_magazine_free_pfns():
         : 817              unsigned long flags;
    0.00 :   ffff80001078b664:       cbz     x0, ffff80001078b674 <alloc_iova_fast+0xec>
    0.00 :   ffff80001078b668:       mov     x1, x21
    0.00 :   ffff80001078b66c:       bl      ffff80001078b200 <iova_magazine_free_pfns.part.13>
    0.00 :   ffff80001078b670:       ldr     x0, [x28, #144]
         : 822              iova_magazine_free():
         :
    0.00 :   ffff80001078b674:       bl      ffff800010206230 <kfree>
         : 810              free_global_cached_iovas():
         :
    0.00 :   ffff80001078b678:       ldr     x0, [x19, #8]
    0.00 :   ffff80001078b67c:       add     x20, x20, #0x1
    0.00 :   ffff80001078b680:       add     x28, x28, #0x8
    0.00 :   ffff80001078b684:       cmp     x0, x20
    0.00 :   ffff80001078b688:       b.hi    ffff80001078b660 <alloc_iova_fast+0xd8>  // b.pmore
         : 1076             rcache = &iovad->rcaches[i];
         : 1077             spin_lock_irqsave(&rcache->lock, flags);
         : 1078             for (j = 0; j < rcache->depot_size; ++j) {
    0.00 :   ffff80001078b68c:       str     xzr, [x19, #8]
         : 1080             spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001078b690:       mov     x0, x19
    0.00 :   ffff80001078b694:       mov     x1, x22
    0.00 :   ffff80001078b698:       add     x19, x19, #0x118
    0.00 :   ffff80001078b69c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 419              alloc_iova_fast():
         : 512              return 0;
    0.00 :   ffff80001078b6a0:       mov     w20, #0x0                       // #0
         : 514              free_global_cached_iovas():
         : 1069             struct iova_rcache *rcache;
    0.00 :   ffff80001078b6a4:       cmp     x19, x25
    0.00 :   ffff80001078b6a8:       b.ne    ffff80001078b640 <alloc_iova_fast+0xb8>  // b.any
         : 1072             alloc_iova_fast():
         : 504              return iova_pfn;
    0.00 :   ffff80001078b6ac:       mov     w3, #0x1                        // #1
    0.00 :   ffff80001078b6b0:       mov     x2, x27
    0.00 :   ffff80001078b6b4:       mov     x1, x26
    0.00 :   ffff80001078b6b8:       mov     x0, x21
    0.00 :   ffff80001078b6bc:       bl      ffff80001078aa18 <alloc_iova>
         :
    0.00 :   ffff80001078b6c0:       cbz     x0, ffff80001078b608 <alloc_iova_fast+0x80>
         : 519              goto retry;
    0.00 :   ffff80001078b6c4:       ldr     x19, [x0, #32]
    0.00 :   ffff80001078b6c8:       b       ffff80001078b794 <alloc_iova_fast+0x20c>
         : 522              __order_base_2():
    0.74 :   ffff80001078b6cc:       mov     x24, #0x80                      // #128
         : 202              iova_rcache_get():
         : 1009             static unsigned long iova_rcache_get(struct iova_domain *iovad,
    0.00 :   ffff80001078b6d0:       mov     x19, #0x0                       // #0
         : 1011             __iova_rcache_get():
         : 974              unsigned long iova_pfn = 0;
    0.00 :   ffff80001078b6d4:       add     x0, x19, x19, lsl #3
         : 976              iova_rcache_get():
         :
    0.00 :   ffff80001078b6d8:       sub     x22, x27, x26
         : 1016             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    1.84 :   ffff80001078b6dc:       mrs     x1, tpidr_el1
         : 46               __iova_rcache_get():
         : 974              unsigned long iova_pfn = 0;
    0.00 :   ffff80001078b6e0:       lsl     x0, x0, #2
         : 976              iova_rcache_get():
         :
    0.00 :   ffff80001078b6e4:       add     x22, x22, #0x1
         : 1016             __iova_rcache_get():
         : 974              unsigned long iova_pfn = 0;
    0.00 :   ffff80001078b6e8:       sub     x0, x0, x19
    0.00 :   ffff80001078b6ec:       add     x0, x21, x0, lsl #3
    0.00 :   ffff80001078b6f0:       ldr     x23, [x0, #400]
    0.00 :   ffff80001078b6f4:       add     x23, x23, x1
         : 975              bool has_pfn = false;
    0.00 :   ffff80001078b6f8:       mov     x0, x23
    0.00 :   ffff80001078b6fc:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff80001078b700:       mov     x25, x0
         :
   28.77 :   ffff80001078b704:       ldr     x4, [x23, #8]
         : 979              iova_magazine_empty():
         : 843              }
    0.00 :   ffff80001078b708:       cbz     x4, ffff80001078b714 <alloc_iova_fast+0x18c>
   28.85 :   ffff80001078b70c:       ldr     x5, [x4]
    0.00 :   ffff80001078b710:       cbnz    x5, ffff80001078b738 <alloc_iova_fast+0x1b0>
         : 847              __iova_rcache_get():
         : 979              spin_lock_irqsave(&cpu_rcache->lock, flags);
    0.00 :   ffff80001078b714:       ldr     x0, [x23, #16]
         : 981              iova_magazine_empty():
         : 843              }
    0.00 :   ffff80001078b718:       cbz     x0, ffff80001078b7c0 <alloc_iova_fast+0x238>
    0.00 :   ffff80001078b71c:       ldr     x1, [x0]
    0.00 :   ffff80001078b720:       cbz     x1, ffff80001078b7c0 <alloc_iova_fast+0x238>
         : 847              __iova_rcache_get():
         :
    0.00 :   ffff80001078b724:       stp     x0, x4, [x23, #8]
         : 992              }
    0.00 :   ffff80001078b728:       ldr     x5, [x0]
         : 994              iova_magazine_empty():
         : 843              }
    0.00 :   ffff80001078b72c:       mov     x4, x0
    0.00 :   ffff80001078b730:       cbnz    x5, ffff80001078b738 <alloc_iova_fast+0x1b0>
         : 846              iova_magazine_pop():
         : 852              {
    0.00 :   ffff80001078b734:       brk     #0x800
         :
    9.62 :   ffff80001078b738:       sub     w0, w5, #0x1
    0.00 :   ffff80001078b73c:       sxtw    x2, w0
    0.00 :   ffff80001078b740:       add     x1, x4, x2, lsl #3
    1.47 :   ffff80001078b744:       ldr     x19, [x1, #8]
    0.00 :   ffff80001078b748:       cmp     x22, x19
    0.00 :   ffff80001078b74c:       b.cs    ffff80001078b76c <alloc_iova_fast+0x1e4>  // b.hs, b.nlast
         : 856              BUG_ON(iova_magazine_empty(mag));
    0.00 :   ffff80001078b750:       cbz     w0, ffff80001078b848 <alloc_iova_fast+0x2c0>
         :
    0.00 :   ffff80001078b754:       sub     w0, w0, #0x1
    0.00 :   ffff80001078b758:       sxtw    x2, w0
    0.00 :   ffff80001078b75c:       add     x3, x4, x2, lsl #3
    0.00 :   ffff80001078b760:       ldr     x19, [x3, #8]
    0.00 :   ffff80001078b764:       cmp     x22, x19
    0.00 :   ffff80001078b768:       b.cc    ffff80001078b750 <alloc_iova_fast+0x1c8>  // b.lo, b.ul, b.last
         : 861              return 0;
   15.09 :   ffff80001078b76c:       sub     x5, x5, #0x1
    1.83 :   ffff80001078b770:       str     x5, [x4]
    0.00 :   ffff80001078b774:       add     x2, x4, x2, lsl #3
         : 865              spin_unlock_irqrestore():
    0.00 :   ffff80001078b778:       mov     x1, x25
         : 410              iova_magazine_pop():
    0.00 :   ffff80001078b77c:       add     x5, x4, x5, lsl #3
         : 862              spin_unlock_irqrestore():
    0.00 :   ffff80001078b780:       mov     x0, x23
         : 410              iova_magazine_pop():
    0.00 :   ffff80001078b784:       ldr     x3, [x5, #8]
    4.42 :   ffff80001078b788:       str     x3, [x2, #8]
         : 863              spin_unlock_irqrestore():
    0.00 :   ffff80001078b78c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 410              alloc_iova_fast():
         : 500              struct iova *new_iova;
    0.00 :   ffff80001078b790:       cbz     x19, ffff80001078b5dc <alloc_iova_fast+0x54>
         : 520              }
    0.00 :   ffff80001078b794:       mov     x0, x19
    0.00 :   ffff80001078b798:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078b79c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078b7a0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078b7a4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078b7a8:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001078b7ac:       ldp     x29, x30, [sp], #96
    0.00 :   ffff80001078b7b0:       autiasp
    0.00 :   ffff80001078b7b4:       ret
         : 509              unsigned int cpu;
    0.00 :   ffff80001078b7b8:       mov     x19, #0x0                       // #0
    0.00 :   ffff80001078b7bc:       b       ffff80001078b794 <alloc_iova_fast+0x20c>
         : 512              iova_rcache_get():
         :
    0.00 :   ffff80001078b7c0:       add     x24, x21, x24
         : 1016             spin_lock():
         :
    0.00 :   ffff80001078b7c4:       mov     x0, x24
    0.00 :   ffff80001078b7c8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 357              __iova_rcache_get():
         : 984              swap(cpu_rcache->prev, cpu_rcache->loaded);
    0.00 :   ffff80001078b7cc:       add     x0, x19, x19, lsl #3
    0.00 :   ffff80001078b7d0:       lsl     x0, x0, #2
    0.00 :   ffff80001078b7d4:       sub     x19, x0, x19
    0.00 :   ffff80001078b7d8:       add     x28, x21, x19, lsl #3
    0.00 :   ffff80001078b7dc:       ldr     x0, [x28, #136]
    0.00 :   ffff80001078b7e0:       cbnz    x0, ffff80001078b80c <alloc_iova_fast+0x284>
         : 991              spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff80001078b7e4:       mov     x0, x24
    0.00 :   ffff80001078b7e8:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 397              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001078b7ec:       mov     x1, x25
    0.00 :   ffff80001078b7f0:       mov     x0, x23
    0.00 :   ffff80001078b7f4:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 413              alloc_iova_fast():
         : 500              struct iova *new_iova;
    0.00 :   ffff80001078b7f8:       b       ffff80001078b5dc <alloc_iova_fast+0x54>
    0.00 :   ffff80001078b7fc:       mov     w24, #0x118                     // #280
    0.00 :   ffff80001078b800:       mov     x0, #0x80                       // #128
    0.00 :   ffff80001078b804:       umaddl  x24, w19, w24, x0
    0.00 :   ffff80001078b808:       b       ffff80001078b6d4 <alloc_iova_fast+0x14c>
         : 506              iova_magazine_free():
         :
    0.00 :   ffff80001078b80c:       ldr     x0, [x23, #8]
    0.00 :   ffff80001078b810:       bl      ffff800010206230 <kfree>
         : 811              __iova_rcache_get():
         : 986              } else {
    0.00 :   ffff80001078b814:       ldr     x2, [x28, #136]
         : 988              spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff80001078b818:       mov     x0, x24
         : 396              __iova_rcache_get():
    0.00 :   ffff80001078b81c:       sub     x2, x2, #0x1
    0.00 :   ffff80001078b820:       str     x2, [x28, #136]
    0.00 :   ffff80001078b824:       add     x19, x19, x2
    0.00 :   ffff80001078b828:       add     x2, x19, #0x12
    0.00 :   ffff80001078b82c:       ldr     x1, [x21, x2, lsl #3]
    0.00 :   ffff80001078b830:       str     x1, [x23, #8]
         : 992              spin_unlock():
    0.00 :   ffff80001078b834:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 395              __iova_rcache_get():
         : 993              spin_unlock(&rcache->lock);
    0.00 :   ffff80001078b838:       ldr     x0, [x23, #8]
         : 995              iova_magazine_empty():
         : 843              }
    0.00 :   ffff80001078b83c:       cbz     x0, ffff80001078b734 <alloc_iova_fast+0x1ac>
    0.00 :   ffff80001078b840:       ldr     x5, [x0]
    0.00 :   ffff80001078b844:       b       ffff80001078b72c <alloc_iova_fast+0x1a4>
         : 847              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001078b848:       mov     x1, x25
    0.00 :   ffff80001078b84c:       mov     x0, x23
    0.00 :   ffff80001078b850:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 413              alloc_iova_fast():
         : 500              struct iova *new_iova;
    0.00 :   ffff80001078b854:       b       ffff80001078b5dc <alloc_iova_fast+0x54>
 Percent |	Source code & Disassembly of vmlinux for cycles (194 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010738778 <serial8250_early_in>:
         : 6                serial8250_early_in():
         : 38               #include <linux/serial_8250.h>
         : 39               #include <asm/io.h>
         : 40               #include <asm/serial.h>
         :
         : 42               static unsigned int serial8250_early_in(struct uart_port *port, int offset)
         : 43               {
    0.00 :   ffff800010738778:       paciasp
    0.00 :   ffff80001073877c:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010738780:       mov     x29, sp
         : 40               int reg_offset = offset;
         : 41               offset <<= port->regshift;
    0.00 :   ffff800010738784:       ldrb    w2, [x0, #185]
         :
         : 43               switch (port->iotype) {
    0.00 :   ffff800010738788:       ldrb    w3, [x0, #186]
         : 40               offset <<= port->regshift;
    0.00 :   ffff80001073878c:       lsl     w2, w1, w2
         : 42               switch (port->iotype) {
    0.00 :   ffff800010738790:       cmp     w3, #0x3
    0.00 :   ffff800010738794:       b.eq    ffff80001073882c <serial8250_early_in+0xb4>  // b.none
    0.00 :   ffff800010738798:       b.ls    ffff8000107387c4 <serial8250_early_in+0x4c>  // b.plast
    0.00 :   ffff80001073879c:       cmp     w3, #0x6
    0.00 :   ffff8000107387a0:       b.eq    ffff800010738854 <serial8250_early_in+0xdc>  // b.none
    0.00 :   ffff8000107387a4:       cmp     w3, #0x7
    0.00 :   ffff8000107387a8:       b.eq    ffff800010738880 <serial8250_early_in+0x108>  // b.none
    0.00 :   ffff8000107387ac:       cmp     w3, #0x4
    0.00 :   ffff8000107387b0:       b.eq    ffff8000107387fc <serial8250_early_in+0x84>  // b.none
         : 56               case UPIO_PORT:
         : 57               return inb(port->iobase + offset);
         : 58               case UPIO_AU:
         : 59               return port->serial_in(port, reg_offset);
         : 60               default:
         : 61               return 0;
    0.00 :   ffff8000107387b4:       mov     w0, #0x0                        // #0
         : 58               }
         : 59               }
    0.00 :   ffff8000107387b8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000107387bc:       autiasp
    0.00 :   ffff8000107387c0:       ret
         : 42               switch (port->iotype) {
    0.00 :   ffff8000107387c4:       cbz     w3, ffff800010738810 <serial8250_early_in+0x98>
    0.00 :   ffff8000107387c8:       cmp     w3, #0x2
    0.00 :   ffff8000107387cc:       b.ne    ffff8000107387b4 <serial8250_early_in+0x3c>  // b.any
         : 44               return readb(port->membase + offset);
    0.00 :   ffff8000107387d0:       ldr     x0, [x0, #16]
    0.00 :   ffff8000107387d4:       add     x2, x0, w2, sxtw
         : 47               __raw_readb():
         :
         : 53               #define __raw_readb __raw_readb
         : 54               static inline u8 __raw_readb(const volatile void __iomem *addr)
         : 55               {
         : 56               u8 val;
         : 57               asm volatile(ALTERNATIVE("ldrb %w0, [%1]",
    0.00 :   ffff8000107387d8:       ldrb    w2, [x2]
    0.00 :   ffff8000107387dc:       and     w0, w2, #0xff
         : 60               serial8250_early_in():
    0.00 :   ffff8000107387e0:       dmb     oshld
  100.00 :   ffff8000107387e4:       and     x2, x2, #0xff
    0.00 :   ffff8000107387e8:       eor     x2, x2, x2
    0.00 :   ffff8000107387ec:       cbnz    x2, ffff8000107387ec <serial8250_early_in+0x74>
         : 58               }
    0.00 :   ffff8000107387f0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000107387f4:       autiasp
    0.00 :   ffff8000107387f8:       ret
         : 54               return port->serial_in(port, reg_offset);
    0.00 :   ffff8000107387fc:       ldr     x2, [x0, #24]
    0.00 :   ffff800010738800:       blr     x2
         : 58               }
    0.00 :   ffff800010738804:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010738808:       autiasp
    0.00 :   ffff80001073880c:       ret
         : 52               return inb(port->iobase + offset);
    0.00 :   ffff800010738810:       ldr     x0, [x0, #8]
    0.00 :   ffff800010738814:       add     x0, x0, w2, sxtw
    0.00 :   ffff800010738818:       bl      ffff8000104b02f8 <logic_inb>
    0.00 :   ffff80001073881c:       and     w0, w0, #0xff
         : 58               }
    0.00 :   ffff800010738820:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010738824:       autiasp
    0.00 :   ffff800010738828:       ret
         : 48               return readl(port->membase + offset);
    0.00 :   ffff80001073882c:       ldr     x0, [x0, #16]
    0.00 :   ffff800010738830:       add     x2, x0, w2, sxtw
         : 51               __raw_readl():
         :
         : 76               #define __raw_readl __raw_readl
         : 77               static __always_inline u32 __raw_readl(const volatile void __iomem *addr)
         : 78               {
         : 79               u32 val;
         : 80               asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    0.00 :   ffff800010738834:       ldr     w0, [x2]
         : 82               serial8250_early_in():
    0.00 :   ffff800010738838:       dmb     oshld
    0.00 :   ffff80001073883c:       mov     w1, w0
    0.00 :   ffff800010738840:       eor     x1, x1, x1
    0.00 :   ffff800010738844:       cbnz    x1, ffff800010738844 <serial8250_early_in+0xcc>
         : 58               }
    0.00 :   ffff800010738848:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001073884c:       autiasp
    0.00 :   ffff800010738850:       ret
         : 50               return ioread32be(port->membase + offset);
    0.00 :   ffff800010738854:       ldr     x0, [x0, #16]
    0.00 :   ffff800010738858:       add     x0, x0, w2, sxtw
         : 53               __raw_readl():
    0.00 :   ffff80001073885c:       ldr     w0, [x0]
         : 76               serial8250_early_in():
         : 62               static inline __attribute_const__ __u32 __fswab32(__u32 val)
         : 63               {
         : 64               #if defined(__arch_swab32)
         : 65               return __arch_swab32(val);
         : 66               #else
         : 67               return ___constant_swab32(val);
    0.00 :   ffff800010738860:       rev     w1, w0
    0.00 :   ffff800010738864:       mov     x0, x1
    0.00 :   ffff800010738868:       dmb     oshld
    0.00 :   ffff80001073886c:       eor     x1, x1, x1
    0.00 :   ffff800010738870:       cbnz    x1, ffff800010738870 <serial8250_early_in+0xf8>
         : 58               }
    0.00 :   ffff800010738874:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010738878:       autiasp
    0.00 :   ffff80001073887c:       ret
         : 46               return readw(port->membase + offset);
    0.00 :   ffff800010738880:       ldr     x0, [x0, #16]
    0.00 :   ffff800010738884:       add     x2, x0, w2, sxtw
         : 49               __raw_readw():
         : 64               asm volatile(ALTERNATIVE("ldrh %w0, [%1]",
    0.00 :   ffff800010738888:       ldrh    w2, [x2]
    0.00 :   ffff80001073888c:       and     w0, w2, #0xffff
         : 67               serial8250_early_in():
    0.00 :   ffff800010738890:       dmb     oshld
    0.00 :   ffff800010738894:       and     x2, x2, #0xffff
    0.00 :   ffff800010738898:       eor     x2, x2, x2
    0.00 :   ffff80001073889c:       cbnz    x2, ffff80001073889c <serial8250_early_in+0x124>
         : 58               }
    0.00 :   ffff8000107388a0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000107388a4:       autiasp
    0.00 :   ffff8000107388a8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (220 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001078b858 <free_iova_fast>:
         : 6                free_iova_fast():
         : 532              * @iovad: - iova domain in question.
         : 533              * @pfn: - pfn that is allocated previously
         : 534              * @size: - # of pages in range
         : 535              * This functions frees an iova range by trying to put it into the rcache,
         : 536              * falling back to regular iova deallocation via free_iova() if this fails.
         : 537              */
    0.00 :   ffff80001078b858:       paciasp
    0.00 :   ffff80001078b85c:       stp     x29, x30, [sp, #-80]!
         : 540              __order_base_2():
         : 201              )
         :
         : 203              static inline __attribute_const__
         : 204              int __order_base_2(unsigned long n)
         : 205              {
         : 206              return n > 1 ? ilog2(n - 1) + 1 : 0;
    0.00 :   ffff80001078b860:       cmp     x2, #0x1
         : 208              free_iova_fast():
    0.00 :   ffff80001078b864:       mov     x29, sp
    0.00 :   ffff80001078b868:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001078b86c:       mov     x21, x0
    0.00 :   ffff80001078b870:       mov     x22, x1
    2.27 :   ffff80001078b874:       stp     x23, x24, [sp, #48]
         : 537              __order_base_2():
    0.00 :   ffff80001078b878:       b.ls    ffff80001078b8b8 <free_iova_fast+0x60>  // b.plast
    0.00 :   ffff80001078b87c:       sub     x2, x2, #0x1
         : 203              __fls():
         : 13               *
         : 14               * Undefined if no set bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __fls(unsigned long word)
         : 17               {
         : 18               return (sizeof(word) * 8) - 1 - __builtin_clzl(word);
    0.00 :   ffff80001078b880:       mov     x1, #0x3f                       // #63
    0.00 :   ffff80001078b884:       clz     x2, x2
    0.00 :   ffff80001078b888:       sub     x1, x1, x2
         : 22               fls64():
         : 31               #elif BITS_PER_LONG == 64
         : 32               static __always_inline int fls64(__u64 x)
         : 33               {
         : 34               if (x == 0)
         : 35               return 0;
         : 36               return __fls(x) + 1;
    0.00 :   ffff80001078b88c:       add     w1, w1, #0x1
         : 38               iova_rcache_insert():
         :
         : 956              return can_insert;
         : 957              }
         :
         : 959              static bool iova_rcache_insert(struct iova_domain *iovad, unsigned long pfn,
         : 960              unsigned long size)
    0.00 :   ffff80001078b890:       cmp     w1, #0x5
    0.00 :   ffff80001078b894:       b.ls    ffff80001078b954 <free_iova_fast+0xfc>  // b.plast
         : 963              free_iova_fast():
         : 536              if (iova_rcache_insert(iovad, pfn, size))
    0.00 :   ffff80001078b898:       mov     x1, x22
    0.00 :   ffff80001078b89c:       mov     x0, x21
    0.00 :   ffff80001078b8a0:       bl      ffff80001078b3c8 <free_iova>
         : 537              return;
    0.00 :   ffff80001078b8a4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078b8a8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078b8ac:       ldp     x29, x30, [sp], #80
    0.00 :   ffff80001078b8b0:       autiasp
    0.00 :   ffff80001078b8b4:       ret
         : 543              __order_base_2():
    0.00 :   ffff80001078b8b8:       mov     x23, #0x80                      // #128
         : 202              iova_rcache_insert():
         :
    0.00 :   ffff80001078b8bc:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001078b8c0:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001078b8c4:       stp     x25, x26, [sp, #64]
         : 957              __iova_rcache_insert():
         : 911              struct iova_cpu_rcache *cpu_rcache;
    0.00 :   ffff80001078b8c8:       add     x20, x1, x1, lsl #3
         : 913              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    4.09 :   ffff80001078b8cc:       mrs     x0, tpidr_el1
         : 46               __iova_rcache_insert():
    0.00 :   ffff80001078b8d0:       lsl     x20, x20, #2
    0.00 :   ffff80001078b8d4:       sub     x20, x20, x1
    0.00 :   ffff80001078b8d8:       add     x24, x21, x20, lsl #3
    0.00 :   ffff80001078b8dc:       ldr     x19, [x24, #400]
    0.00 :   ffff80001078b8e0:       add     x19, x19, x0
         : 912              bool can_insert = false;
    0.00 :   ffff80001078b8e4:       mov     x0, x19
    0.00 :   ffff80001078b8e8:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff80001078b8ec:       mov     x25, x0
         :
   43.16 :   ffff80001078b8f0:       ldr     x2, [x19, #8]
         : 916              iova_magazine_full():
         : 838              }
    0.00 :   ffff80001078b8f4:       cbz     x2, ffff80001078b96c <free_iova_fast+0x114>
   35.98 :   ffff80001078b8f8:       ldr     x0, [x2]
    0.00 :   ffff80001078b8fc:       cmp     x0, #0x80
    0.00 :   ffff80001078b900:       b.eq    ffff80001078b92c <free_iova_fast+0xd4>  // b.none
         : 843              iova_magazine_push():
         : 870              static void iova_magazine_push(struct iova_magazine *mag, unsigned long pfn)
   12.24 :   ffff80001078b904:       add     x3, x2, x0, lsl #3
    0.00 :   ffff80001078b908:       add     x0, x0, #0x1
    2.27 :   ffff80001078b90c:       str     x0, [x2]
         : 874              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001078b910:       mov     x1, x25
    0.00 :   ffff80001078b914:       mov     x0, x19
         : 417              iova_magazine_push():
    0.00 :   ffff80001078b918:       str     x22, [x3, #8]
         : 871              spin_unlock_irqrestore():
    0.00 :   ffff80001078b91c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
    0.00 :   ffff80001078b920:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078b924:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078b928:       b       ffff80001078b8a4 <free_iova_fast+0x4c>
         : 413              __iova_rcache_insert():
         : 916              spin_lock_irqsave(&cpu_rcache->lock, flags);
    0.00 :   ffff80001078b92c:       ldr     x3, [x19, #16]
         : 918              iova_magazine_full():
         : 838              }
    0.00 :   ffff80001078b930:       cbz     x3, ffff80001078baa4 <free_iova_fast+0x24c>
    0.00 :   ffff80001078b934:       ldr     x0, [x3]
    0.00 :   ffff80001078b938:       cmp     x0, #0x80
    0.00 :   ffff80001078b93c:       b.eq    ffff80001078b9a8 <free_iova_fast+0x150>  // b.none
         : 843              __iova_rcache_insert():
         :
    0.00 :   ffff80001078b940:       stp     x3, x2, [x19, #8]
         : 919              iova_magazine_full():
         : 838              }
    0.00 :   ffff80001078b944:       ldr     x0, [x3]
    0.00 :   ffff80001078b948:       cmp     x0, #0x80
    0.00 :   ffff80001078b94c:       b.ne    ffff80001078ba7c <free_iova_fast+0x224>  // b.any
         : 842              iova_magazine_push():
         : 868              }
    0.00 :   ffff80001078b950:       brk     #0x800
    0.00 :   ffff80001078b954:       mov     w23, #0x118                     // #280
    0.00 :   ffff80001078b958:       mov     x0, #0x80                       // #128
    0.00 :   ffff80001078b95c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001078b960:       umaddl  x23, w1, w23, x0
    0.00 :   ffff80001078b964:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001078b968:       b       ffff80001078b8c8 <free_iova_fast+0x70>
         : 876              iova_magazine_full():
         : 838              }
    0.00 :   ffff80001078b96c:       ldr     x3, [x2]
         : 840              spin_unlock_irqrestore():
    0.00 :   ffff80001078b970:       mov     x1, x0
    0.00 :   ffff80001078b974:       mov     x0, x19
         : 411              iova_magazine_push():
         : 870              static void iova_magazine_push(struct iova_magazine *mag, unsigned long pfn)
    0.00 :   ffff80001078b978:       add     x4, x3, #0x1
    0.00 :   ffff80001078b97c:       str     x4, [x2]
    0.00 :   ffff80001078b980:       lsl     x3, x3, #3
    0.00 :   ffff80001078b984:       str     x22, [x3, #8]
         : 875              spin_unlock_irqrestore():
    0.00 :   ffff80001078b988:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 410              __iova_rcache_insert():
         : 942              iova_magazine_push(cpu_rcache->loaded, iova_pfn);
    0.00 :   ffff80001078b98c:       ldp     x19, x20, [sp, #16]
         : 944              free_iova_fast():
         : 537              return;
    0.00 :   ffff80001078b990:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078b994:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078b998:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078b99c:       ldp     x29, x30, [sp], #80
    0.00 :   ffff80001078b9a0:       autiasp
    0.00 :   ffff80001078b9a4:       ret
         : 544              kmalloc():
         : 556              *
         : 557              * %GFP_HIGHUSER
         : 558              *       Allocate memory from high memory on behalf of user.
         : 559              *
         : 560              * Also it is possible to set different flags by OR'ing
         : 561              * in one or more of the following additional @flags:
    0.00 :   ffff80001078b9a8:       adrp    x0, ffff800011571000 <rt_sched_class+0x10>
         : 563              kmem_cache_alloc_trace():
         : 452              void *kmem_cache_alloc_node(struct kmem_cache *, gfp_t flags, int node) __assume_slab_alignment __malloc;
    0.00 :   ffff80001078b9ac:       mov     w1, #0xb20                      // #2848
    0.00 :   ffff80001078b9b0:       ldr     x0, [x0, #4064]
    0.00 :   ffff80001078b9b4:       bl      ffff800010208a10 <kmem_cache_alloc>
    0.00 :   ffff80001078b9b8:       mov     x26, x0
         : 457              __iova_rcache_insert():
         : 922              can_insert = true;
    0.00 :   ffff80001078b9bc:       cbz     x0, ffff80001078ba44 <free_iova_fast+0x1ec>
         : 924              iova_rcache_insert():
         : 958              {
         : 959              unsigned int log_size = order_base_2(size);
         :
    0.00 :   ffff80001078b9c0:       add     x23, x21, x23
         : 962              spin_lock():
         :
    0.00 :   ffff80001078b9c4:       mov     x0, x23
    0.00 :   ffff80001078b9c8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 357              __iova_rcache_insert():
         : 924              struct iova_magazine *new_mag = iova_magazine_alloc(GFP_ATOMIC);
    0.00 :   ffff80001078b9cc:       ldr     x0, [x24, #136]
    0.00 :   ffff80001078b9d0:       cmp     x0, #0x1f
    0.00 :   ffff80001078b9d4:       b.ls    ffff80001078ba5c <free_iova_fast+0x204>  // b.plast
         : 928              if (rcache->depot_size < MAX_GLOBAL_MAGS) {
    0.00 :   ffff80001078b9d8:       ldr     x20, [x19, #8]
         : 930              spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff80001078b9dc:       mov     x0, x23
    0.00 :   ffff80001078b9e0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 397              __iova_rcache_insert():
         : 932              mag_to_free = cpu_rcache->loaded;
    0.00 :   ffff80001078b9e4:       str     x26, [x19, #8]
         : 937              can_insert = true;
    0.00 :   ffff80001078b9e8:       ldr     x0, [x26]
         : 939              iova_magazine_full():
         : 838              }
    0.00 :   ffff80001078b9ec:       cmp     x0, #0x80
    0.00 :   ffff80001078b9f0:       b.eq    ffff80001078b950 <free_iova_fast+0xf8>  // b.none
         : 841              iova_magazine_push():
         : 870              static void iova_magazine_push(struct iova_magazine *mag, unsigned long pfn)
    0.00 :   ffff80001078b9f4:       add     x2, x26, x0, lsl #3
    0.00 :   ffff80001078b9f8:       add     x0, x0, #0x1
    0.00 :   ffff80001078b9fc:       str     x0, [x26]
         : 874              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001078ba00:       mov     x1, x25
    0.00 :   ffff80001078ba04:       mov     x0, x19
         : 412              iova_magazine_push():
    0.00 :   ffff80001078ba08:       str     x22, [x2, #8]
         : 871              spin_unlock_irqrestore():
    0.00 :   ffff80001078ba0c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 410              __iova_rcache_insert():
         : 942              iova_magazine_push(cpu_rcache->loaded, iova_pfn);
    0.00 :   ffff80001078ba10:       cbz     x20, ffff80001078b920 <free_iova_fast+0xc8>
         : 944              iova_magazine_free_pfns():
         : 817              unsigned long flags;
    0.00 :   ffff80001078ba14:       mov     x1, x21
    0.00 :   ffff80001078ba18:       mov     x0, x20
    0.00 :   ffff80001078ba1c:       bl      ffff80001078b200 <iova_magazine_free_pfns.part.13>
         : 821              iova_magazine_free():
         :
    0.00 :   ffff80001078ba20:       mov     x0, x20
    0.00 :   ffff80001078ba24:       bl      ffff800010206230 <kfree>
    0.00 :   ffff80001078ba28:       ldp     x19, x20, [sp, #16]
         : 812              free_iova_fast():
         : 537              return;
    0.00 :   ffff80001078ba2c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001078ba30:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001078ba34:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078ba38:       ldp     x29, x30, [sp], #80
    0.00 :   ffff80001078ba3c:       autiasp
    0.00 :   ffff80001078ba40:       ret
         : 544              spin_unlock_irqrestore():
    0.00 :   ffff80001078ba44:       mov     x1, x25
    0.00 :   ffff80001078ba48:       mov     x0, x19
    0.00 :   ffff80001078ba4c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 412              __iova_rcache_insert():
         : 942              iova_magazine_push(cpu_rcache->loaded, iova_pfn);
    0.00 :   ffff80001078ba50:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078ba54:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078ba58:       b       ffff80001078b898 <free_iova_fast+0x40>
         :
    0.00 :   ffff80001078ba5c:       add     x1, x20, x0
    0.00 :   ffff80001078ba60:       add     x0, x0, #0x1
    0.00 :   ffff80001078ba64:       add     x1, x1, #0x12
    0.00 :   ffff80001078ba68:       str     x0, [x24, #136]
         : 906              static bool __iova_rcache_insert(struct iova_domain *iovad,
    0.00 :   ffff80001078ba6c:       mov     x20, #0x0                       // #0
         : 926              if (new_mag) {
    0.00 :   ffff80001078ba70:       ldr     x0, [x19, #8]
         :
    0.00 :   ffff80001078ba74:       str     x0, [x21, x1, lsl #3]
    0.00 :   ffff80001078ba78:       b       ffff80001078b9dc <free_iova_fast+0x184>
         : 928              iova_magazine_push():
         : 870              static void iova_magazine_push(struct iova_magazine *mag, unsigned long pfn)
    0.00 :   ffff80001078ba7c:       add     x2, x3, x0, lsl #3
    0.00 :   ffff80001078ba80:       add     x0, x0, #0x1
    0.00 :   ffff80001078ba84:       str     x0, [x3]
         : 874              spin_unlock_irqrestore():
    0.00 :   ffff80001078ba88:       mov     x1, x25
    0.00 :   ffff80001078ba8c:       mov     x0, x19
         : 411              iova_magazine_push():
    0.00 :   ffff80001078ba90:       str     x22, [x2, #8]
         : 871              spin_unlock_irqrestore():
    0.00 :   ffff80001078ba94:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 410              __iova_rcache_insert():
         : 942              iova_magazine_push(cpu_rcache->loaded, iova_pfn);
    0.00 :   ffff80001078ba98:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078ba9c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078baa0:       b       ffff80001078b8a4 <free_iova_fast+0x4c>
         :
    0.00 :   ffff80001078baa4:       stp     xzr, x2, [x19, #8]
         : 919              spin_unlock_irqrestore():
    0.00 :   ffff80001078baa8:       mov     x1, x25
    0.00 :   ffff80001078baac:       mov     x0, x19
         : 411              iova_magazine_push():
         : 870              static void iova_magazine_push(struct iova_magazine *mag, unsigned long pfn)
    0.00 :   ffff80001078bab0:       ldr     x2, [x3]
    0.00 :   ffff80001078bab4:       add     x4, x2, #0x1
    0.00 :   ffff80001078bab8:       str     x4, [x3]
    0.00 :   ffff80001078babc:       lsl     x2, x2, #3
    0.00 :   ffff80001078bac0:       str     x22, [x2, #8]
         : 876              spin_unlock_irqrestore():
    0.00 :   ffff80001078bac4:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 410              __iova_rcache_insert():
         : 942              iova_magazine_push(cpu_rcache->loaded, iova_pfn);
    0.00 :   ffff80001078bac8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078bacc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001078bad0:       b       ffff80001078b8a4 <free_iova_fast+0x4c>
 Percent |	Source code & Disassembly of vmlinux for cycles (131 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010782e60 <__iommu_map>:
         : 6                __iommu_map():
         : 2407             pgsize &= domain->pgsize_bitmap;
         :
         : 2409             /* make sure we're still sane */
         : 2410             BUG_ON(!pgsize);
         :
         : 2412             /* pick the biggest page */
    0.00 :   ffff800010782e60:       paciasp
    0.00 :   ffff800010782e64:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff800010782e68:       mov     x29, sp
    0.00 :   ffff800010782e6c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010782e70:       stp     x27, x28, [sp, #80]
         : 2408             pgsize_idx = __fls(pgsize);
    0.00 :   ffff800010782e74:       ldr     x24, [x0, #8]
         : 2407             /* pick the biggest page */
    0.00 :   ffff800010782e78:       str     x2, [sp, #104]
         :
         : 2416             return pgsize;
         : 2417             }
         :
         : 2419             static int __iommu_map(struct iommu_domain *domain, unsigned long iova,
         : 2420             phys_addr_t paddr, size_t size, int prot, gfp_t gfp)
    0.00 :   ffff800010782e7c:       ldr     x7, [x24, #40]
    0.00 :   ffff800010782e80:       cbz     x7, ffff800010782fa0 <__iommu_map+0x140>
   29.76 :   ffff800010782e84:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010782e88:       mov     x21, x0
    1.53 :   ffff800010782e8c:       ldr     x0, [x0, #16]
    0.00 :   ffff800010782e90:       cbz     x0, ffff800010782fbc <__iommu_map+0x15c>
         : 2419             {
         : 2420             const struct iommu_ops *ops = domain->ops;
         : 2421             unsigned long orig_iova = iova;
         : 2422             unsigned int min_pagesz;
    3.05 :   ffff800010782e94:       ldr     w6, [x21]
    0.00 :   ffff800010782e98:       tbz     w6, #0, ffff800010782fc8 <__iommu_map+0x168>
         : 2412             }
   32.07 :   ffff800010782e9c:       mov     x6, x2
         : 2414             __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff800010782ea0:       rbit    x2, x0
    0.00 :   ffff800010782ea4:       clz     x2, x2
    0.00 :   ffff800010782ea8:       mov     w23, w5
    0.00 :   ffff800010782eac:       mov     w22, w4
         : 23               __iommu_map():
         : 2430             domain->pgsize_bitmap == 0UL))
         : 2431             return -ENODEV;
         :
         : 2433             if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
         : 2434             return -EINVAL;
         :
    0.00 :   ffff800010782eb0:       orr     x5, x3, x6
         :
    0.00 :   ffff800010782eb4:       mov     w4, #0x1                        // #1
    0.76 :   ffff800010782eb8:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010782ebc:       lsl     w2, w4, w2
         :
    0.00 :   ffff800010782ec0:       orr     x5, x5, x1
         :
    0.00 :   ffff800010782ec4:       mov     x4, x2
         :
    0.00 :   ffff800010782ec8:       sub     x2, x2, #0x1
    0.00 :   ffff800010782ecc:       mov     x26, x1
    0.00 :   ffff800010782ed0:       mov     x25, x3
    0.00 :   ffff800010782ed4:       tst     x5, x2
    0.00 :   ffff800010782ed8:       b.ne    ffff800010782fd4 <__iommu_map+0x174>  // b.any
    0.00 :   ffff800010782edc:       stp     x19, x20, [sp, #16]
         :
         : 2439             /*
         : 2440             * both the virtual address and the physical one, as well as
         : 2441             * the size of the mapping, must be aligned (at least) to the
         : 2442             * size of the smallest page supported by the hardware
         : 2443             */
    0.00 :   ffff800010782ee0:       mov     x27, x3
    0.00 :   ffff800010782ee4:       mov     x20, x1
    0.00 :   ffff800010782ee8:       cbnz    x3, ffff800010782f10 <__iommu_map+0xb0>
    0.00 :   ffff800010782eec:       b       ffff800010782f78 <__iommu_map+0x118>
         :
         : 2450             pr_debug("map: iova 0x%lx pa %pa size 0x%zx\n", iova, &paddr, size);
         :
         : 2452             while (size) {
         : 2453             size_t pgsize = iommu_pgsize(domain, iova | paddr, size);
         :
    4.56 :   ffff800010782ef0:       ldr     x6, [sp, #104]
         : 2448             size_t pgsize = iommu_pgsize(domain, iova | paddr, size);
    0.00 :   ffff800010782ef4:       add     x20, x20, x19
         : 2438             */
    0.00 :   ffff800010782ef8:       subs    x27, x27, x19
         :
    0.00 :   ffff800010782efc:       add     x6, x19, x6
    0.00 :   ffff800010782f00:       str     x6, [sp, #104]
         : 2438             */
    0.00 :   ffff800010782f04:       b.eq    ffff800010782f78 <__iommu_map+0x118>  // b.none
    0.00 :   ffff800010782f08:       ldr     x0, [x21, #16]
    0.00 :   ffff800010782f0c:       ldr     x7, [x24, #40]
         : 2439             if (!IS_ALIGNED(iova | paddr | size, min_pagesz)) {
   13.75 :   ffff800010782f10:       orr     x1, x6, x20
    0.00 :   ffff800010782f14:       mov     x2, x27
    0.00 :   ffff800010782f18:       bl      ffff800010782c20 <iommu_pgsize.isra.24>
         : 2443             }
    0.00 :   ffff800010782f1c:       mov     w5, w23
    0.00 :   ffff800010782f20:       mov     x3, x0
         : 2439             if (!IS_ALIGNED(iova | paddr | size, min_pagesz)) {
    0.00 :   ffff800010782f24:       mov     x19, x0
         : 2443             }
    0.00 :   ffff800010782f28:       mov     w4, w22
    0.00 :   ffff800010782f2c:       mov     x2, x6
    0.00 :   ffff800010782f30:       mov     x1, x20
    0.00 :   ffff800010782f34:       mov     x0, x21
    0.00 :   ffff800010782f38:       blr     x7
    0.00 :   ffff800010782f3c:       mov     w28, w0
         : 2445             pr_debug("map: iova 0x%lx pa %pa size 0x%zx\n", iova, &paddr, size);
    0.00 :   ffff800010782f40:       cbz     w0, ffff800010782ef0 <__iommu_map+0x90>
         : 2455             pr_debug("mapping: iova 0x%lx pa %pa pgsize 0x%zx\n",
         : 2456             iova, &paddr, pgsize);
         : 2457             ret = ops->map(domain, iova, paddr, pgsize, prot, gfp);
         :
         : 2459             if (ret)
         : 2460             break;
    0.00 :   ffff800010782f44:       sub     x2, x25, x27
    0.00 :   ffff800010782f48:       mov     x1, x26
    0.00 :   ffff800010782f4c:       mov     x0, x21
    0.00 :   ffff800010782f50:       bl      ffff800010782db0 <iommu_unmap>
    0.00 :   ffff800010782f54:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010782f58:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010782f5c:       ldp     x25, x26, [sp, #64]
         :
         : 2461             iova += pgsize;
         : 2462             paddr += pgsize;
         : 2463             size -= pgsize;
         : 2464             }
    0.00 :   ffff800010782f60:       mov     w0, w28
    0.00 :   ffff800010782f64:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010782f68:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010782f6c:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010782f70:       autiasp
    0.00 :   ffff800010782f74:       ret
         : 2438             */
    3.05 :   ffff800010782f78:       mov     w28, #0x0                       // #0
         : 2460             }
    0.00 :   ffff800010782f7c:       mov     w0, w28
    0.00 :   ffff800010782f80:       ldp     x19, x20, [sp, #16]
    3.82 :   ffff800010782f84:       ldp     x21, x22, [sp, #32]
    0.76 :   ffff800010782f88:       ldp     x23, x24, [sp, #48]
    1.53 :   ffff800010782f8c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010782f90:       ldp     x27, x28, [sp, #80]
    3.83 :   ffff800010782f94:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010782f98:       autiasp
    1.53 :   ffff800010782f9c:       ret
         : 2417             const struct iommu_ops *ops = domain->ops;
    0.00 :   ffff800010782fa0:       mov     w28, #0xffffffed                // #-19
         : 2460             }
    0.00 :   ffff800010782fa4:       mov     w0, w28
    0.00 :   ffff800010782fa8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010782fac:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010782fb0:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010782fb4:       autiasp
    0.00 :   ffff800010782fb8:       ret
         : 2417             const struct iommu_ops *ops = domain->ops;
    0.00 :   ffff800010782fbc:       mov     w28, #0xffffffed                // #-19
    0.00 :   ffff800010782fc0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010782fc4:       b       ffff800010782f60 <__iommu_map+0x100>
         : 2420             size_t orig_size = size;
    0.00 :   ffff800010782fc8:       mov     w28, #0xffffffea                // #-22
    0.00 :   ffff800010782fcc:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010782fd0:       b       ffff800010782f60 <__iommu_map+0x100>
         : 2431             /* find out the minimum page size supported */
    0.00 :   ffff800010782fd4:       adrp    x0, ffff8000114d8000 <kallsyms_token_index+0xcd7a0>
    0.00 :   ffff800010782fd8:       add     x2, sp, #0x68
    0.00 :   ffff800010782fdc:       add     x0, x0, #0x28
         :
    0.00 :   ffff800010782fe0:       mov     w28, #0xffffffea                // #-22
         : 2431             /* find out the minimum page size supported */
    0.00 :   ffff800010782fe4:       bl      ffff800010e19544 <printk>
         :
    0.00 :   ffff800010782fe8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010782fec:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010782ff0:       b       ffff800010782f60 <__iommu_map+0x100>
 Percent |	Source code & Disassembly of vmlinux for cycles (127 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000107860b0 <__iommu_dma_map>:
         : 6                __iommu_dma_map():
         :
         : 514              if (unlikely(is_swiotlb_buffer(phys)))
         : 515              swiotlb_tbl_unmap_single(dev, phys, size, dir, attrs);
         : 516              }
         :
         : 518              static dma_addr_t __iommu_dma_map(struct device *dev, phys_addr_t phys,
    0.00 :   ffff8000107860b0:       paciasp
    1.57 :   ffff8000107860b4:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff8000107860b8:       mov     x29, sp
   21.28 :   ffff8000107860bc:       stp     x19, x20, [sp, #16]
    3.94 :   ffff8000107860c0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000107860c4:       mov     x21, x1
    3.95 :   ffff8000107860c8:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000107860cc:       mov     w24, w3
    0.79 :   ffff8000107860d0:       mov     x23, x4
    2.37 :   ffff8000107860d4:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000107860d8:       sub     x26, x2, #0x1
    0.00 :   ffff8000107860dc:       mov     x25, x0
    5.50 :   ffff8000107860e0:       str     x27, [sp, #80]
         : 514              size_t size, int prot, u64 dma_mask)
    0.00 :   ffff8000107860e4:       bl      ffff800010784d10 <iommu_get_dma_domain>
         : 515              {
   19.71 :   ffff8000107860e8:       ldr     x22, [x0, #64]
         : 514              size_t size, int prot, u64 dma_mask)
    0.00 :   ffff8000107860ec:       mov     x27, x0
         : 516              iova_offset():
         : 118              return iovad->granule - 1;
         : 119              }
         :
         : 121              static inline size_t iova_offset(struct iova_domain *iovad, dma_addr_t iova)
         : 122              {
         : 123              return iova & iova_mask(iovad);
   16.52 :   ffff8000107860f0:       ldr     x0, [x22, #40]
         : 125              iova_mask():
         : 113              return iovad->granule - 1;
    0.00 :   ffff8000107860f4:       sub     x19, x0, #0x1
         : 115              iova_offset():
         : 118              return iova & iova_mask(iovad);
    0.00 :   ffff8000107860f8:       and     x19, x19, x21
         : 120              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000107860fc:       nop
         : 28               iova_align():
         : 123              }
         :
         : 125              static inline size_t iova_align(struct iova_domain *iovad, size_t size)
         : 126              {
         : 127              return ALIGN(size, iovad->granule);
   12.60 :   ffff800010786100:       add     x20, x19, x0
    0.00 :   ffff800010786104:       neg     x0, x0
    0.00 :   ffff800010786108:       add     x20, x20, x26
         : 131              __iommu_dma_map():
         :
         : 527              if (static_branch_unlikely(&iommu_deferred_attach_enabled) &&
         : 528              iommu_deferred_attach(dev, domain))
         : 529              return DMA_MAPPING_ERROR;
         :
         : 531              size = iova_align(iovad, size + iova_off);
    0.00 :   ffff80001078610c:       mov     x2, x23
         : 533              iova_align():
    0.00 :   ffff800010786110:       and     x20, x20, x0
         : 124              __iommu_dma_map():
    0.00 :   ffff800010786114:       add     x3, x25, #0x250
    0.00 :   ffff800010786118:       mov     x1, x20
    0.00 :   ffff80001078611c:       mov     x0, x27
    0.00 :   ffff800010786120:       bl      ffff800010785fe8 <iommu_dma_alloc_iova.isra.23>
    0.00 :   ffff800010786124:       mov     x23, x0
         :
    0.00 :   ffff800010786128:       cbz     x0, ffff800010786188 <__iommu_dma_map+0xd8>
         : 530              iova = iommu_dma_alloc_iova(domain, size, dma_mask, dev);
         : 531              if (!iova)
         : 532              return DMA_MAPPING_ERROR;
    0.00 :   ffff80001078612c:       sub     x2, x21, x19
    0.00 :   ffff800010786130:       mov     w4, w24
    0.00 :   ffff800010786134:       mov     x0, x27
    0.00 :   ffff800010786138:       mov     x3, x20
    0.00 :   ffff80001078613c:       mov     x1, x23
         :
         : 535              if (iommu_map_atomic(domain, iova, phys - iova_off, size, prot)) {
         : 536              iommu_dma_free_iova(cookie, iova, size, NULL);
         : 537              return DMA_MAPPING_ERROR;
    0.00 :   ffff800010786140:       add     x19, x23, x19
         : 530              return DMA_MAPPING_ERROR;
    0.00 :   ffff800010786144:       bl      ffff800010783080 <iommu_map_atomic>
    0.00 :   ffff800010786148:       cbnz    w0, ffff800010786170 <__iommu_dma_map+0xc0>
         : 535              }
    3.93 :   ffff80001078614c:       mov     x0, x19
    0.00 :   ffff800010786150:       ldp     x19, x20, [sp, #16]
    2.36 :   ffff800010786154:       ldp     x21, x22, [sp, #32]
    1.57 :   ffff800010786158:       ldp     x23, x24, [sp, #48]
    3.93 :   ffff80001078615c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010786160:       ldr     x27, [sp, #80]
    0.00 :   ffff800010786164:       ldp     x29, x30, [sp], #96
    0.00 :   ffff800010786168:       autiasp
    0.00 :   ffff80001078616c:       ret
         :
    0.00 :   ffff800010786170:       mov     x2, x20
    0.00 :   ffff800010786174:       mov     x1, x23
    0.00 :   ffff800010786178:       mov     x0, x22
    0.00 :   ffff80001078617c:       mov     x3, #0x0                        // #0
    0.00 :   ffff800010786180:       bl      ffff800010785880 <iommu_dma_free_iova>
    0.00 :   ffff800010786184:       nop
         : 532              if (iommu_map_atomic(domain, iova, phys - iova_off, size, prot)) {
    0.00 :   ffff800010786188:       mov     x19, #0xffffffffffffffff        // #-1
    0.00 :   ffff80001078618c:       b       ffff80001078614c <__iommu_dma_map+0x9c>
         :
    0.00 :   ffff800010786190:       mov     x1, x27
    0.00 :   ffff800010786194:       mov     x0, x25
    0.00 :   ffff800010786198:       bl      ffff800010784c88 <iommu_deferred_attach>
         : 520              dma_addr_t iova;
    0.00 :   ffff80001078619c:       cbnz    w0, ffff800010786188 <__iommu_dma_map+0xd8>
    0.00 :   ffff8000107861a0:       ldr     x0, [x22, #40]
    0.00 :   ffff8000107861a4:       b       ffff800010786100 <__iommu_dma_map+0x50>
 Percent |	Source code & Disassembly of vmlinux for cycles (125 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010785a20 <__iommu_dma_unmap_swiotlb>:
         : 6                __iommu_dma_unmap_swiotlb():
         : 497              iommu_iotlb_sync(domain, &iotlb_gather);
         : 498              iommu_dma_free_iova(cookie, dma_addr, size, iotlb_gather.freelist);
         : 499              }
         :
         : 501              static void __iommu_dma_unmap_swiotlb(struct device *dev, dma_addr_t dma_addr,
         : 502              size_t size, enum dma_data_direction dir,
    0.00 :   ffff800010785a20:       paciasp
    4.04 :   ffff800010785a24:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010785a28:       mov     x29, sp
    3.20 :   ffff800010785a2c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010785a30:       mov     x20, x1
    0.00 :   ffff800010785a34:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010785a38:       mov     x22, x2
    0.00 :   ffff800010785a3c:       mov     x21, x0
    0.80 :   ffff800010785a40:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010785a44:       mov     w23, w3
    0.00 :   ffff800010785a48:       mov     x24, x4
         : 498              unsigned long attrs)
    0.00 :   ffff800010785a4c:       bl      ffff800010784d10 <iommu_get_dma_domain>
         : 501              {
         : 502              struct iommu_domain *domain = iommu_get_dma_domain(dev);
         : 503              phys_addr_t phys;
    4.78 :   ffff800010785a50:       mov     x1, x20
    0.00 :   ffff800010785a54:       bl      ffff800010780f30 <iommu_iova_to_phys>
         :
    4.02 :   ffff800010785a58:       cbz     x0, ffff800010785ac4 <__iommu_dma_unmap_swiotlb+0xa4>
         : 505              phys = iommu_iova_to_phys(domain, dma_addr);
         : 506              if (WARN_ON(!phys))
         : 507              return;
    1.60 :   ffff800010785a5c:       mov     x19, x0
    8.82 :   ffff800010785a60:       mov     x1, x20
    0.00 :   ffff800010785a64:       mov     x0, x21
    0.00 :   ffff800010785a68:       mov     x2, x22
    3.21 :   ffff800010785a6c:       bl      ffff8000107858f0 <__iommu_dma_unmap>
         : 513              is_swiotlb_buffer():
         : 106              };
         : 107              extern struct io_tlb_mem *io_tlb_default_mem;
         :
         : 109              static inline bool is_swiotlb_buffer(phys_addr_t paddr)
         : 110              {
         : 111              struct io_tlb_mem *mem = io_tlb_default_mem;
    2.40 :   ffff800010785a70:       adrp    x0, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010785a74:       ldr     x0, [x0, #3624]
         :
         : 109              return mem && paddr >= mem->start && paddr < mem->end;
    0.00 :   ffff800010785a78:       cbz     x0, ffff800010785aac <__iommu_dma_unmap_swiotlb+0x8c>
    0.00 :   ffff800010785a7c:       ldr     x1, [x0]
    0.00 :   ffff800010785a80:       cmp     x19, x1
    0.00 :   ffff800010785a84:       b.cc    ffff800010785aac <__iommu_dma_unmap_swiotlb+0x8c>  // b.lo, b.ul, b.last
   38.34 :   ffff800010785a88:       ldr     x0, [x0, #8]
    0.00 :   ffff800010785a8c:       cmp     x19, x0
    0.00 :   ffff800010785a90:       b.cs    ffff800010785aac <__iommu_dma_unmap_swiotlb+0x8c>  // b.hs, b.nlast
         : 117              __iommu_dma_unmap_swiotlb():
         :
         : 509              __iommu_dma_unmap(dev, dma_addr, size);
         :
    0.00 :   ffff800010785a94:       mov     x4, x24
    0.00 :   ffff800010785a98:       mov     w3, w23
    0.00 :   ffff800010785a9c:       mov     x2, x22
    0.00 :   ffff800010785aa0:       mov     x1, x19
    0.00 :   ffff800010785aa4:       mov     x0, x21
    0.00 :   ffff800010785aa8:       bl      ffff800010108fd8 <swiotlb_tbl_unmap_single>
         : 509              if (unlikely(is_swiotlb_buffer(phys)))
   23.98 :   ffff800010785aac:       ldp     x19, x20, [sp, #16]
    4.80 :   ffff800010785ab0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010785ab4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010785ab8:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010785abc:       autiasp
    0.00 :   ffff800010785ac0:       ret
         :
    0.00 :   ffff800010785ac4:       brk     #0x800
    0.00 :   ffff800010785ac8:       b       ffff800010785aac <__iommu_dma_unmap_swiotlb+0x8c>
 Percent |	Source code & Disassembly of vmlinux for cycles (120 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000107858f0 <__iommu_dma_unmap>:
         : 6                __iommu_dma_unmap():
         : 474              else
         : 475              free_iova_fast(iovad, iova_pfn(iovad, iova),
         : 476              size >> iova_shift(iovad));
         : 477              }
         :
         : 479              static void __iommu_dma_unmap(struct device *dev, dma_addr_t dma_addr,
    0.00 :   ffff8000107858f0:       paciasp
    0.00 :   ffff8000107858f4:       stp     x29, x30, [sp, #-128]!
    0.00 :   ffff8000107858f8:       mov     x29, sp
    0.00 :   ffff8000107858fc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010785900:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010785904:       add     x21, x21, #0x948
    4.18 :   ffff800010785908:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001078590c:       mov     x20, x1
    0.00 :   ffff800010785910:       ldr     x1, [x21]
    0.00 :   ffff800010785914:       str     x1, [sp, #120]
    0.00 :   ffff800010785918:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001078591c:       mov     x19, x2
    0.00 :   ffff800010785920:       str     x23, [sp, #48]
         : 475              size_t size)
    0.00 :   ffff800010785924:       bl      ffff800010784d10 <iommu_get_dma_domain>
    0.00 :   ffff800010785928:       mov     x23, x0
         : 476              {
    3.35 :   ffff80001078592c:       ldr     x22, [x0, #64]
         : 478              iommu_iotlb_gather_init():
         : 373              return (struct iommu_device *)dev_get_drvdata(dev);
         : 374              }
         :
         : 376              static inline void iommu_iotlb_gather_init(struct iommu_iotlb_gather *gather)
         : 377              {
         : 378              *gather = (struct iommu_iotlb_gather) {
    0.00 :   ffff800010785930:       mov     x1, #0xffffffffffffffff         // #-1
    0.00 :   ffff800010785934:       str     x1, [sp, #88]
         : 381              iova_align():
         : 123              return iova & iova_mask(iovad);
         : 124              }
         :
         : 126              static inline size_t iova_align(struct iova_domain *iovad, size_t size)
         : 127              {
         : 128              return ALIGN(size, iovad->granule);
    0.00 :   ffff800010785938:       sub     x2, x19, #0x1
         : 130              __iommu_dma_unmap():
         : 486              struct iommu_iotlb_gather iotlb_gather;
         : 487              size_t unmapped;
         :
         : 489              dma_addr -= iova_off;
         : 490              size = iova_align(iovad, size + iova_off);
         : 491              iommu_iotlb_gather_init(&iotlb_gather);
    0.00 :   ffff80001078593c:       add     x3, sp, #0x58
         : 493              iommu_iotlb_gather_init():
    0.00 :   ffff800010785940:       stp     xzr, xzr, [sp, #96]
         : 374              iova_offset():
         : 118              return iova & iova_mask(iovad);
    0.00 :   ffff800010785944:       ldr     x4, [x22, #40]
         : 120              iommu_iotlb_gather_init():
    9.17 :   ffff800010785948:       str     xzr, [sp, #112]
         : 374              iova_mask():
         : 113              return iovad->granule - 1;
    0.00 :   ffff80001078594c:       add     x1, x4, x1
         : 115              iova_align():
         : 123              return ALIGN(size, iovad->granule);
    0.00 :   ffff800010785950:       neg     x5, x4
         : 125              iova_offset():
         : 118              return iova & iova_mask(iovad);
    0.00 :   ffff800010785954:       and     x1, x1, x20
         : 120              iova_align():
         : 123              return ALIGN(size, iovad->granule);
    0.00 :   ffff800010785958:       add     x19, x4, x1
         : 125              __iommu_dma_unmap():
         : 482              size_t unmapped;
    0.00 :   ffff80001078595c:       sub     x20, x20, x1
         : 484              iova_align():
    0.00 :   ffff800010785960:       add     x19, x19, x2
         : 124              __iommu_dma_unmap():
         : 486              iommu_iotlb_gather_init(&iotlb_gather);
    0.00 :   ffff800010785964:       mov     x1, x20
         : 488              iova_align():
    0.00 :   ffff800010785968:       and     x19, x19, x5
         : 124              __iommu_dma_unmap():
    0.00 :   ffff80001078596c:       mov     x2, x19
    0.00 :   ffff800010785970:       bl      ffff800010782e40 <iommu_unmap_fast>
         :
    0.00 :   ffff800010785974:       cmp     x0, x19
    0.00 :   ffff800010785978:       b.ne    ffff8000107859f4 <__iommu_dma_unmap+0x104>  // b.any
         : 489              unmapped = iommu_unmap_fast(domain, dma_addr, size, &iotlb_gather);
         : 490              WARN_ON(unmapped != size);
    4.16 :   ffff80001078597c:       ldr     x3, [x22, #1912]
    0.00 :   ffff800010785980:       cbz     x3, ffff8000107859c0 <__iommu_dma_unmap+0xd0>
    0.00 :   ffff800010785984:       ldr     x3, [sp, #112]
         :
         : 492              if (!cookie->fq_domain)
    0.00 :   ffff800010785988:       mov     x1, x20
    0.00 :   ffff80001078598c:       mov     x0, x22
    0.00 :   ffff800010785990:       mov     x2, x19
    0.00 :   ffff800010785994:       bl      ffff800010785880 <iommu_dma_free_iova>
         : 492              iommu_iotlb_sync(domain, &iotlb_gather);
    0.00 :   ffff800010785998:       ldr     x1, [sp, #120]
    0.00 :   ffff80001078599c:       ldr     x0, [x21]
    0.00 :   ffff8000107859a0:       eor     x0, x1, x0
    0.00 :   ffff8000107859a4:       cbnz    x0, ffff8000107859fc <__iommu_dma_unmap+0x10c>
    1.66 :   ffff8000107859a8:       ldp     x19, x20, [sp, #16]
    3.34 :   ffff8000107859ac:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000107859b0:       ldr     x23, [sp, #48]
    0.00 :   ffff8000107859b4:       ldp     x29, x30, [sp], #128
    0.00 :   ffff8000107859b8:       autiasp
    0.00 :   ffff8000107859bc:       ret
         : 503              iommu_iotlb_sync():
         : 494              }
         :
         : 496              static inline void iommu_iotlb_sync(struct iommu_domain *domain,
         : 497              struct iommu_iotlb_gather *iotlb_gather)
         : 498              {
         : 499              if (domain->ops->iotlb_sync)
   11.64 :   ffff8000107859c0:       ldr     x0, [x23, #8]
   20.85 :   ffff8000107859c4:       ldr     x2, [x0, #72]
    0.00 :   ffff8000107859c8:       cbz     x2, ffff8000107859e0 <__iommu_dma_unmap+0xf0>
         : 495              domain->ops->iotlb_sync(domain, iotlb_gather);
   27.47 :   ffff8000107859cc:       add     x1, sp, #0x58
    0.00 :   ffff8000107859d0:       mov     x0, x23
   10.03 :   ffff8000107859d4:       str     x3, [sp, #72]
    0.00 :   ffff8000107859d8:       blr     x2
    0.00 :   ffff8000107859dc:       ldr     x3, [sp, #72]
         : 501              iommu_iotlb_gather_init():
         : 373              *gather = (struct iommu_iotlb_gather) {
    0.00 :   ffff8000107859e0:       mov     x0, #0xffffffffffffffff         // #-1
    0.00 :   ffff8000107859e4:       str     x0, [sp, #88]
    0.00 :   ffff8000107859e8:       stp     xzr, xzr, [sp, #96]
    4.17 :   ffff8000107859ec:       str     xzr, [sp, #112]
    0.00 :   ffff8000107859f0:       b       ffff800010785988 <__iommu_dma_unmap+0x98>
         : 379              __iommu_dma_unmap():
         :
    0.00 :   ffff8000107859f4:       brk     #0x800
    0.00 :   ffff8000107859f8:       b       ffff80001078597c <__iommu_dma_unmap+0x8c>
         : 492              iommu_iotlb_sync(domain, &iotlb_gather);
    0.00 :   ffff8000107859fc:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (105 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001072ebe8 <mem_serial_in>:
         : 6                mem_serial_in():
         : 398              outb(value, p->iobase + 1);
         : 399              }
         :
         : 401              static unsigned int mem_serial_in(struct uart_port *p, int offset)
         : 402              {
         : 403              offset = offset << p->regshift;
    0.00 :   ffff80001072ebe8:       ldrb    w2, [x0, #185]
         : 397              {
    0.00 :   ffff80001072ebec:       paciasp
         : 399              return readb(p->membase + offset);
    0.00 :   ffff80001072ebf0:       ldr     x0, [x0, #16]
         : 398              offset = offset << p->regshift;
    0.00 :   ffff80001072ebf4:       lsl     w1, w1, w2
         : 399              return readb(p->membase + offset);
    0.00 :   ffff80001072ebf8:       add     x1, x0, w1, sxtw
         : 401              __raw_readb():
         :
         : 53               #define __raw_readb __raw_readb
         : 54               static inline u8 __raw_readb(const volatile void __iomem *addr)
         : 55               {
         : 56               u8 val;
         : 57               asm volatile(ALTERNATIVE("ldrb %w0, [%1]",
    0.00 :   ffff80001072ebfc:       ldrb    w1, [x1]
    0.00 :   ffff80001072ec00:       and     w0, w1, #0xff
         : 60               mem_serial_in():
    0.00 :   ffff80001072ec04:       dmb     oshld
  100.00 :   ffff80001072ec08:       and     x1, x1, #0xff
    0.00 :   ffff80001072ec0c:       eor     x1, x1, x1
    0.00 :   ffff80001072ec10:       cbnz    x1, ffff80001072ec10 <mem_serial_in+0x28>
         : 400              }
    0.00 :   ffff80001072ec14:       autiasp
    0.00 :   ffff80001072ec18:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (111 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077b418 <arm_smmu_cmdq_build_cmd>:
         : 6                arm_smmu_cmdq_build_cmd():
         : 253              case CMDQ_OP_CFGI_CD:
         : 254              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SSID, ent->cfgi.ssid);
         : 255              fallthrough;
         : 256              case CMDQ_OP_CFGI_STE:
         : 257              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
         : 258              cmd[1] |= FIELD_PREP(CMDQ_CFGI_1_LEAF, ent->cfgi.leaf);
    0.00 :   ffff80001077b418:       stp     xzr, xzr, [x0]
         : 252              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
    0.00 :   ffff80001077b41c:       paciasp
         : 254              break;
   15.30 :   ffff80001077b420:       ldr     x2, [x0]
   14.42 :   ffff80001077b424:       ldrb    w3, [x1]
    0.00 :   ffff80001077b428:       orr     x3, x3, x2
    0.00 :   ffff80001077b42c:       str     x3, [x0]
         : 256              case CMDQ_OP_CFGI_CD_ALL:
         : 257              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
    3.60 :   ffff80001077b430:       ldrb    w2, [x1]
    0.00 :   ffff80001077b434:       cmp     w2, #0x20
    0.00 :   ffff80001077b438:       b.eq    ffff80001077b764 <arm_smmu_cmdq_build_cmd+0x34c>  // b.none
    8.10 :   ffff80001077b43c:       b.ls    ffff80001077b4a0 <arm_smmu_cmdq_build_cmd+0x88>  // b.plast
    1.80 :   ffff80001077b440:       cmp     w2, #0x2a
    0.00 :   ffff80001077b444:       b.eq    ffff80001077b610 <arm_smmu_cmdq_build_cmd+0x1f8>  // b.none
    0.91 :   ffff80001077b448:       b.ls    ffff80001077b51c <arm_smmu_cmdq_build_cmd+0x104>  // b.plast
    0.00 :   ffff80001077b44c:       cmp     w2, #0x40
    0.00 :   ffff80001077b450:       b.eq    ffff80001077b698 <arm_smmu_cmdq_build_cmd+0x280>  // b.none
    9.02 :   ffff80001077b454:       b.ls    ffff80001077b504 <arm_smmu_cmdq_build_cmd+0xec>  // b.plast
    0.00 :   ffff80001077b458:       cmp     w2, #0x41
    0.00 :   ffff80001077b45c:       b.eq    ffff80001077b6f8 <arm_smmu_cmdq_build_cmd+0x2e0>  // b.none
    0.00 :   ffff80001077b460:       cmp     w2, #0x46
    0.00 :   ffff80001077b464:       b.ne    ffff80001077b4f4 <arm_smmu_cmdq_build_cmd+0xdc>  // b.any
         : 331              return -ENOENT;
         : 332              }
         :
         : 334              return 0;
         : 335              }
         :
    0.00 :   ffff80001077b468:       ldr     x4, [x1, #8]
         : 335              static void arm_smmu_cmdq_build_sync_cmd(u64 *cmd, struct arm_smmu_device *smmu,
         : 336              u32 prod)
         : 337              {
         : 338              struct arm_smmu_queue *q = &smmu->cmdq.q;
    0.00 :   ffff80001077b46c:       orr     x2, x3, #0x2000
         :
    0.00 :   ffff80001077b470:       cbz     x4, ffff80001077b490 <arm_smmu_cmdq_build_cmd+0x78>
         : 332              static void arm_smmu_cmdq_build_sync_cmd(u64 *cmd, struct arm_smmu_device *smmu,
    7.23 :   ffff80001077b474:       orr     x2, x3, #0x1000
    0.89 :   ffff80001077b478:       str     x2, [x0]
         : 333              u32 prod)
    0.00 :   ffff80001077b47c:       ldr     x3, [x0, #8]
    0.90 :   ffff80001077b480:       ldr     x1, [x1, #8]
    0.00 :   ffff80001077b484:       and     x1, x1, #0xffffffffffffc
    0.00 :   ffff80001077b488:       orr     x3, x3, x1
    4.51 :   ffff80001077b48c:       str     x3, [x0, #8]
         : 338              struct arm_smmu_cmdq_ent ent = {
         : 339              .opcode = CMDQ_OP_CMD_SYNC,
         : 340              };
    0.00 :   ffff80001077b490:       orr     x1, x2, #0xfc00000
         :
         : 345              /*
         : 346              * Beware that Hi16xx adds an extra 32 bits of goodness to its MSI
         : 347              * payload, so the write will zero the entire command on that platform.
         : 348              */
         : 349              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b494:       mov     w2, #0x0                        // #0
         : 338              };
    0.00 :   ffff80001077b498:       str     x1, [x0]
         :
    0.00 :   ffff80001077b49c:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 256              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
    0.00 :   ffff80001077b4a0:       cmp     w2, #0x5
    0.00 :   ffff80001077b4a4:       b.eq    ffff80001077b544 <arm_smmu_cmdq_build_cmd+0x12c>  // b.none
    0.00 :   ffff80001077b4a8:       b.hi    ffff80001077b4dc <arm_smmu_cmdq_build_cmd+0xc4>  // b.pmore
    0.00 :   ffff80001077b4ac:       cmp     w2, #0x3
    0.00 :   ffff80001077b4b0:       b.eq    ffff80001077b558 <arm_smmu_cmdq_build_cmd+0x140>  // b.none
    0.00 :   ffff80001077b4b4:       b.hi    ffff80001077b684 <arm_smmu_cmdq_build_cmd+0x26c>  // b.pmore
    0.00 :   ffff80001077b4b8:       cmp     w2, #0x1
    0.00 :   ffff80001077b4bc:       b.ne    ffff80001077b4f4 <arm_smmu_cmdq_build_cmd+0xdc>  // b.any
         : 271              cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_TG, ent->tlbi.tg);
    0.00 :   ffff80001077b4c0:       ldr     w1, [x1, #8]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b4c4:       mov     w2, #0x0                        // #0
         : 345              ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    0.00 :   ffff80001077b4c8:       autiasp
         : 271              cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_TG, ent->tlbi.tg);
    0.00 :   ffff80001077b4cc:       orr     x3, x3, x1, lsl #32
    0.00 :   ffff80001077b4d0:       str     x3, [x0]
         : 345              ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    0.00 :   ffff80001077b4d4:       mov     w0, w2
    0.00 :   ffff80001077b4d8:       ret
         : 256              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
    0.00 :   ffff80001077b4dc:       cmp     w2, #0x11
    0.00 :   ffff80001077b4e0:       b.eq    ffff80001077b754 <arm_smmu_cmdq_build_cmd+0x33c>  // b.none
    0.00 :   ffff80001077b4e4:       cmp     w2, #0x12
    0.00 :   ffff80001077b4e8:       b.eq    ffff80001077b57c <arm_smmu_cmdq_build_cmd+0x164>  // b.none
    0.00 :   ffff80001077b4ec:       cmp     w2, #0x6
    0.00 :   ffff80001077b4f0:       b.eq    ffff80001077b4c0 <arm_smmu_cmdq_build_cmd+0xa8>  // b.none
         : 341              * Beware that Hi16xx adds an extra 32 bits of goodness to its MSI
    0.00 :   ffff80001077b4f4:       mov     w2, #0xfffffffe                 // #-2
         : 345              ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    1.79 :   ffff80001077b4f8:       mov     w0, w2
    0.00 :   ffff80001077b4fc:       autiasp
    0.00 :   ffff80001077b500:       ret
         : 341              * Beware that Hi16xx adds an extra 32 bits of goodness to its MSI
    0.00 :   ffff80001077b504:       cmp     w2, #0x30
    0.00 :   ffff80001077b508:       mov     w2, #0xfffffffe                 // #-2
    0.00 :   ffff80001077b50c:       csel    w2, wzr, w2, eq  // eq = none
         : 345              ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    0.00 :   ffff80001077b510:       autiasp
    0.00 :   ffff80001077b514:       mov     w0, w2
    0.00 :   ffff80001077b518:       ret
         : 256              cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
    5.40 :   ffff80001077b51c:       cmp     w2, #0x22
    0.00 :   ffff80001077b520:       b.eq    ffff80001077b588 <arm_smmu_cmdq_build_cmd+0x170>  // b.none
    0.00 :   ffff80001077b524:       b.cc    ffff80001077b5fc <arm_smmu_cmdq_build_cmd+0x1e4>  // b.lo, b.ul, b.last
    0.00 :   ffff80001077b528:       cmp     w2, #0x28
    0.00 :   ffff80001077b52c:       b.ne    ffff80001077b4f4 <arm_smmu_cmdq_build_cmd+0xdc>  // b.any
         : 302              cmd[0] |= FIELD_PREP(CMDQ_PRI_0_SSID, ent->pri.ssid);
    0.00 :   ffff80001077b530:       ldrh    w1, [x1, #12]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b534:       mov     w2, #0x0                        // #0
         : 302              cmd[0] |= FIELD_PREP(CMDQ_PRI_0_SSID, ent->pri.ssid);
    0.00 :   ffff80001077b538:       orr     x3, x3, x1, lsl #32
    0.00 :   ffff80001077b53c:       str     x3, [x0]
         : 303              cmd[0] |= FIELD_PREP(CMDQ_PRI_0_SID, ent->pri.sid);
    0.00 :   ffff80001077b540:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 264              fallthrough;
    0.00 :   ffff80001077b544:       ldr     w2, [x1, #12]
    0.00 :   ffff80001077b548:       lsl     w2, w2, #12
    0.00 :   ffff80001077b54c:       orr     x3, x3, x2
    0.00 :   ffff80001077b550:       str     x3, [x0]
    0.00 :   ffff80001077b554:       nop
         : 267              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_SCALE, ent->tlbi.scale);
    0.00 :   ffff80001077b558:       ldr     w5, [x1, #8]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b55c:       mov     w2, #0x0                        // #0
         : 268              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
    0.00 :   ffff80001077b560:       ldr     x4, [x0, #8]
         : 267              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_SCALE, ent->tlbi.scale);
    0.00 :   ffff80001077b564:       orr     x3, x3, x5, lsl #32
    0.00 :   ffff80001077b568:       str     x3, [x0]
         : 268              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
    0.00 :   ffff80001077b56c:       ldrb    w1, [x1, #16]
    0.00 :   ffff80001077b570:       orr     x4, x4, x1
    0.00 :   ffff80001077b574:       str     x4, [x0, #8]
         : 269              cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_LEAF, ent->tlbi.leaf);
    0.00 :   ffff80001077b578:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 278              cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_LEAF, ent->tlbi.leaf);
    0.00 :   ffff80001077b57c:       ldrh    w2, [x1, #12]
    0.00 :   ffff80001077b580:       orr     x3, x3, x2, lsl #32
    0.00 :   ffff80001077b584:       str     x3, [x0]
         : 281              cmd[1] |= ent->tlbi.addr & CMDQ_TLBI_1_IPA_MASK;
    0.00 :   ffff80001077b588:       ldrb    w4, [x1, #8]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b58c:       mov     w2, #0x0                        // #0
         : 284              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
    1.81 :   ffff80001077b590:       ldr     x6, [x0, #8]
         : 281              cmd[1] |= ent->tlbi.addr & CMDQ_TLBI_1_IPA_MASK;
    0.00 :   ffff80001077b594:       ubfiz   x4, x4, #12, #5
    0.00 :   ffff80001077b598:       orr     x4, x4, x3
    0.00 :   ffff80001077b59c:       str     x4, [x0]
         : 282              break;
    1.79 :   ffff80001077b5a0:       ldrb    w3, [x1, #9]
    0.00 :   ffff80001077b5a4:       ubfiz   x3, x3, #20, #5
    0.00 :   ffff80001077b5a8:       orr     x3, x3, x4
    0.00 :   ffff80001077b5ac:       str     x3, [x0]
         : 283              case CMDQ_OP_TLBI_NH_ASID:
    3.62 :   ffff80001077b5b0:       ldrh    w5, [x1, #10]
    0.00 :   ffff80001077b5b4:       orr     x3, x3, x5, lsl #48
    0.00 :   ffff80001077b5b8:       str     x3, [x0]
         : 284              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
    1.80 :   ffff80001077b5bc:       ldrb    w4, [x1, #14]
    0.00 :   ffff80001077b5c0:       orr     x4, x4, x6
    0.00 :   ffff80001077b5c4:       str     x4, [x0, #8]
         : 285              fallthrough;
    7.19 :   ffff80001077b5c8:       ldrb    w3, [x1, #15]
    0.00 :   ffff80001077b5cc:       ubfiz   x3, x3, #8, #2
    0.00 :   ffff80001077b5d0:       orr     x4, x3, x4
    0.00 :   ffff80001077b5d4:       str     x4, [x0, #8]
         : 286              case CMDQ_OP_TLBI_S12_VMALL:
    3.60 :   ffff80001077b5d8:       ldrb    w3, [x1, #16]
    0.00 :   ffff80001077b5dc:       ubfiz   x3, x3, #10, #2
    0.00 :   ffff80001077b5e0:       orr     x3, x3, x4
    0.00 :   ffff80001077b5e4:       str     x3, [x0, #8]
         : 287              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_VMID, ent->tlbi.vmid);
    6.32 :   ffff80001077b5e8:       ldr     x1, [x1, #24]
    0.00 :   ffff80001077b5ec:       and     x1, x1, #0xfffffffffffff000
    0.00 :   ffff80001077b5f0:       orr     x3, x1, x3
    0.00 :   ffff80001077b5f4:       str     x3, [x0, #8]
         : 288              break;
    0.00 :   ffff80001077b5f8:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 305              switch (ent->pri.resp) {
    0.00 :   ffff80001077b5fc:       ldrh    w1, [x1, #10]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b600:       mov     w2, #0x0                        // #0
         : 305              switch (ent->pri.resp) {
    0.00 :   ffff80001077b604:       orr     x3, x3, x1, lsl #48
    0.00 :   ffff80001077b608:       str     x3, [x0]
         : 306              case PRI_RESP_DENY:
    0.00 :   ffff80001077b60c:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 290              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
    0.00 :   ffff80001077b610:       ldrb    w4, [x1, #8]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b614:       mov     w2, #0x0                        // #0
         : 293              cmd[0] |= FIELD_PREP(CMDQ_0_SSV, ent->substream_valid);
    0.00 :   ffff80001077b618:       ldr     x6, [x0, #8]
         : 290              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
    0.00 :   ffff80001077b61c:       ubfiz   x4, x4, #12, #5
    0.00 :   ffff80001077b620:       orr     x4, x4, x3
    0.00 :   ffff80001077b624:       str     x4, [x0]
         : 291              break;
    0.00 :   ffff80001077b628:       ldrb    w3, [x1, #9]
    0.00 :   ffff80001077b62c:       ubfiz   x3, x3, #20, #5
    0.00 :   ffff80001077b630:       orr     x3, x3, x4
    0.00 :   ffff80001077b634:       str     x3, [x0]
         : 292              case CMDQ_OP_ATC_INV:
    0.00 :   ffff80001077b638:       ldrh    w5, [x1, #12]
    0.00 :   ffff80001077b63c:       orr     x3, x3, x5, lsl #32
    0.00 :   ffff80001077b640:       str     x3, [x0]
         : 293              cmd[0] |= FIELD_PREP(CMDQ_0_SSV, ent->substream_valid);
    0.00 :   ffff80001077b644:       ldrb    w4, [x1, #14]
    0.00 :   ffff80001077b648:       orr     x4, x4, x6
    0.00 :   ffff80001077b64c:       str     x4, [x0, #8]
         : 294              cmd[0] |= FIELD_PREP(CMDQ_ATC_0_GLOBAL, ent->atc.global);
    0.00 :   ffff80001077b650:       ldrb    w3, [x1, #15]
    0.00 :   ffff80001077b654:       ubfiz   x3, x3, #8, #2
    0.00 :   ffff80001077b658:       orr     x4, x3, x4
    0.00 :   ffff80001077b65c:       str     x4, [x0, #8]
         : 295              cmd[0] |= FIELD_PREP(CMDQ_ATC_0_SSID, ent->atc.ssid);
    0.00 :   ffff80001077b660:       ldrb    w3, [x1, #16]
    0.00 :   ffff80001077b664:       ubfiz   x3, x3, #10, #2
    0.00 :   ffff80001077b668:       orr     x3, x3, x4
    0.00 :   ffff80001077b66c:       str     x3, [x0, #8]
         : 296              cmd[0] |= FIELD_PREP(CMDQ_ATC_0_SID, ent->atc.sid);
    0.00 :   ffff80001077b670:       ldr     x1, [x1, #24]
    0.00 :   ffff80001077b674:       and     x1, x1, #0xffffffffff000
    0.00 :   ffff80001077b678:       orr     x3, x1, x3
    0.00 :   ffff80001077b67c:       str     x3, [x0, #8]
         : 297              cmd[1] |= FIELD_PREP(CMDQ_ATC_1_SIZE, ent->atc.size);
    0.00 :   ffff80001077b680:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 275              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_NUM, ent->tlbi.num);
    0.00 :   ffff80001077b684:       ldr     x1, [x0, #8]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b688:       mov     w2, #0x0                        // #0
         : 275              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_NUM, ent->tlbi.num);
    0.00 :   ffff80001077b68c:       orr     x1, x1, #0x1f
    0.00 :   ffff80001077b690:       str     x1, [x0, #8]
         : 276              cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_SCALE, ent->tlbi.scale);
    0.00 :   ffff80001077b694:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 308              case PRI_RESP_SUCC:
    0.00 :   ffff80001077b698:       ldrb    w4, [x1, #1]
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b69c:       mov     w2, #0x0                        // #0
         : 312              }
    0.00 :   ffff80001077b6a0:       ldr     x6, [x0, #8]
         : 308              case PRI_RESP_SUCC:
    0.00 :   ffff80001077b6a4:       orr     x3, x3, x4, lsl #11
    0.00 :   ffff80001077b6a8:       str     x3, [x0]
         : 309              break;
    0.00 :   ffff80001077b6ac:       ldrb    w4, [x1, #25]
    0.00 :   ffff80001077b6b0:       orr     x3, x3, x4, lsl #9
    0.00 :   ffff80001077b6b4:       str     x3, [x0]
         : 310              default:
    0.00 :   ffff80001077b6b8:       ldr     w4, [x1, #12]
    0.00 :   ffff80001077b6bc:       lsl     w4, w4, #12
    0.00 :   ffff80001077b6c0:       orr     x4, x4, x3
    0.00 :   ffff80001077b6c4:       str     x4, [x0]
         : 311              return -EINVAL;
    0.00 :   ffff80001077b6c8:       ldr     w5, [x1, #8]
    0.00 :   ffff80001077b6cc:       orr     x4, x4, x5, lsl #32
    0.00 :   ffff80001077b6d0:       str     x4, [x0]
         : 312              }
    0.00 :   ffff80001077b6d4:       ldrb    w3, [x1, #24]
    0.00 :   ffff80001077b6d8:       and     x3, x3, #0x3f
    0.00 :   ffff80001077b6dc:       orr     x3, x3, x6
    0.00 :   ffff80001077b6e0:       str     x3, [x0, #8]
         : 313              cmd[1] |= FIELD_PREP(CMDQ_PRI_1_RESP, ent->pri.resp);
    0.00 :   ffff80001077b6e4:       ldr     x1, [x1, #16]
    0.00 :   ffff80001077b6e8:       and     x1, x1, #0xfffffffffffff000
    0.00 :   ffff80001077b6ec:       orr     x3, x1, x3
    0.00 :   ffff80001077b6f0:       str     x3, [x0, #8]
         : 314              break;
    0.00 :   ffff80001077b6f4:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 316              if (ent->sync.msiaddr) {
    0.00 :   ffff80001077b6f8:       ldrb    w2, [x1, #1]
         : 319              } else {
    0.00 :   ffff80001077b6fc:       ldr     x4, [x0, #8]
         : 316              if (ent->sync.msiaddr) {
    0.00 :   ffff80001077b700:       orr     x2, x3, x2, lsl #11
    0.00 :   ffff80001077b704:       str     x2, [x0]
         : 317              cmd[0] |= FIELD_PREP(CMDQ_SYNC_0_CS, CMDQ_SYNC_0_CS_IRQ);
    0.00 :   ffff80001077b708:       ldr     w3, [x1, #12]
    0.00 :   ffff80001077b70c:       lsl     w3, w3, #12
    0.00 :   ffff80001077b710:       orr     x3, x3, x2
    0.00 :   ffff80001077b714:       str     x3, [x0]
         : 318              cmd[1] |= ent->sync.msiaddr & CMDQ_SYNC_1_MSIADDR_MASK;
    0.00 :   ffff80001077b718:       ldr     w2, [x1, #8]
    0.00 :   ffff80001077b71c:       orr     x3, x3, x2, lsl #32
    0.00 :   ffff80001077b720:       str     x3, [x0]
         : 319              } else {
    0.00 :   ffff80001077b724:       ldrh    w3, [x1, #16]
    0.00 :   ffff80001077b728:       and     x3, x3, #0x1ff
    0.00 :   ffff80001077b72c:       orr     x3, x3, x4
    0.00 :   ffff80001077b730:       str     x3, [x0, #8]
         : 320              cmd[0] |= FIELD_PREP(CMDQ_SYNC_0_CS, CMDQ_SYNC_0_CS_SEV);
    0.00 :   ffff80001077b734:       ldr     w1, [x1, #20]
    0.00 :   ffff80001077b738:       cmp     w1, #0x2
    0.00 :   ffff80001077b73c:       b.hi    ffff80001077b76c <arm_smmu_cmdq_build_cmd+0x354>  // b.pmore
         :
    0.00 :   ffff80001077b740:       ubfiz   x1, x1, #12, #32
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b744:       mov     w2, #0x0                        // #0
         :
    0.00 :   ffff80001077b748:       orr     x3, x1, x3
    0.00 :   ffff80001077b74c:       str     x3, [x0, #8]
         : 329              return 0;
    0.00 :   ffff80001077b750:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 299              break;
    0.00 :   ffff80001077b754:       ldrh    w2, [x1, #10]
    0.00 :   ffff80001077b758:       orr     x3, x3, x2, lsl #48
    0.00 :   ffff80001077b75c:       str     x3, [x0]
    0.00 :   ffff80001077b760:       b       ffff80001077b530 <arm_smmu_cmdq_build_cmd+0x118>
         : 344              if (smmu->options & ARM_SMMU_OPT_MSIPOLL) {
    0.00 :   ffff80001077b764:       mov     w2, #0x0                        // #0
    0.00 :   ffff80001077b768:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
         : 326              return -ENOENT;
    0.00 :   ffff80001077b76c:       mov     w2, #0xffffffea                 // #-22
    0.00 :   ffff80001077b770:       b       ffff80001077b4f8 <arm_smmu_cmdq_build_cmd+0xe0>
 Percent |	Source code & Disassembly of vmlinux for cycles (107 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077b1e8 <arm_smmu_tlb_inv_page_nosync>:
         : 6                arm_smmu_tlb_inv_page_nosync():
         : 2134             /* Smallest Translation Unit: log2 of the smallest supported granule */
         : 2135             stu = __ffs(smmu->pgsize_bitmap);
         : 2136             pdev = to_pci_dev(master->dev);
         :
         : 2138             atomic_inc(&smmu_domain->nr_ats_masters);
         : 2139             arm_smmu_atc_inv_domain(smmu_domain, 0, 0, 0);
    0.00 :   ffff80001077b1e8:       paciasp
    4.70 :   ffff80001077b1ec:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff80001077b1f0:       mov     x29, sp
    0.00 :   ffff80001077b1f4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001077b1f8:       mov     x20, x2
         : 2145             iommu_iotlb_gather_add_page():
         :
         : 505              static inline void iommu_iotlb_gather_add_page(struct iommu_domain *domain,
         : 506              struct iommu_iotlb_gather *gather,
         : 507              unsigned long iova, size_t size)
         : 508              {
         : 509              unsigned long start = iova, end = start + size - 1;
    0.00 :   ffff80001077b1fc:       add     x2, x1, x2
         : 511              arm_smmu_tlb_inv_page_nosync():
    1.88 :   ffff80001077b200:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001077b204:       mov     x21, x1
    0.00 :   ffff80001077b208:       mov     x19, x0
         : 2137             iommu_iotlb_gather_add_page():
         : 511              /*
         : 512              * If the new page is disjoint from the current range or is mapped at
         : 513              * a different granularity, then sync the TLB so that the gather
         : 514              * structure can be rewritten.
         : 515              */
         : 516              if (gather->pgsize != size ||
    1.88 :   ffff80001077b20c:       ldr     x1, [x0, #16]
         : 504              unsigned long start = iova, end = start + size - 1;
    0.00 :   ffff80001077b210:       sub     x22, x2, #0x1
         : 511              if (gather->pgsize != size ||
    0.00 :   ffff80001077b214:       cmp     x20, x1
    0.00 :   ffff80001077b218:       b.eq    ffff80001077b288 <arm_smmu_tlb_inv_page_nosync+0xa0>  // b.none
         : 513              end + 1 < gather->start || start > gather->end + 1) {
         : 514              if (gather->pgsize)
   14.10 :   ffff80001077b21c:       cbz     x1, ffff80001077b280 <arm_smmu_tlb_inv_page_nosync+0x98>
         : 516              iommu_iotlb_sync():
         : 494              if (domain->ops->iotlb_sync)
    0.00 :   ffff80001077b220:       add     x0, x3, #0x90
    0.00 :   ffff80001077b224:       ldr     x1, [x0, #8]
    0.00 :   ffff80001077b228:       ldr     x2, [x1, #72]
    0.00 :   ffff80001077b22c:       cbz     x2, ffff80001077b238 <arm_smmu_tlb_inv_page_nosync+0x50>
         : 495              domain->ops->iotlb_sync(domain, iotlb_gather);
    0.00 :   ffff80001077b230:       mov     x1, x19
    0.00 :   ffff80001077b234:       blr     x2
         : 498              iommu_iotlb_gather_init():
         : 373              *gather = (struct iommu_iotlb_gather) {
    0.00 :   ffff80001077b238:       mov     x1, #0xffffffffffffffff         // #-1
    0.00 :   ffff80001077b23c:       mov     x0, x1
    0.00 :   ffff80001077b240:       stp     xzr, xzr, [x19]
    0.00 :   ffff80001077b244:       mov     x2, #0x0                        // #0
    0.00 :   ffff80001077b248:       str     x1, [x19]
    0.00 :   ffff80001077b24c:       stp     xzr, xzr, [x19, #16]
         : 380              iommu_iotlb_gather_add_page():
         : 515              iommu_iotlb_sync(domain, gather);
         : 516              gather->pgsize = size;
   33.86 :   ffff80001077b250:       str     x20, [x19, #16]
         : 518              }
         :
         : 520              if (gather->end < end)
    0.00 :   ffff80001077b254:       cmp     x22, x2
    0.00 :   ffff80001077b258:       b.ls    ffff80001077b260 <arm_smmu_tlb_inv_page_nosync+0x78>  // b.plast
         : 519              gather->end = end;
    0.00 :   ffff80001077b25c:       str     x22, [x19, #8]
         :
         : 522              if (gather->start > start)
    0.00 :   ffff80001077b260:       cmp     x21, x0
    0.00 :   ffff80001077b264:       b.cs    ffff80001077b26c <arm_smmu_tlb_inv_page_nosync+0x84>  // b.hs, b.nlast
         : 522              gather->start = start;
   14.08 :   ffff80001077b268:       str     x21, [x19]
         : 524              arm_smmu_tlb_inv_page_nosync():
         : 2139             if (pci_enable_ats(pdev, stu))
         : 2140             dev_err(master->dev, "Failed to enable ATS (STU %zu)\n", stu);
         : 2141             }
         :
         : 2143             static void arm_smmu_disable_ats(struct arm_smmu_master *master)
    2.81 :   ffff80001077b26c:       ldp     x19, x20, [sp, #16]
    8.79 :   ffff80001077b270:       ldp     x21, x22, [sp, #32]
   11.30 :   ffff80001077b274:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001077b278:       autiasp
    5.65 :   ffff80001077b27c:       ret
    0.94 :   ffff80001077b280:       ldp     x0, x2, [x19]
    0.00 :   ffff80001077b284:       b       ffff80001077b250 <arm_smmu_tlb_inv_page_nosync+0x68>
         : 2151             iommu_iotlb_gather_add_page():
         : 512              end + 1 < gather->start || start > gather->end + 1) {
    0.00 :   ffff80001077b288:       ldr     x0, [x0]
         : 511              if (gather->pgsize != size ||
    0.00 :   ffff80001077b28c:       cmp     x2, x0
    0.00 :   ffff80001077b290:       b.cc    ffff80001077b21c <arm_smmu_tlb_inv_page_nosync+0x34>  // b.lo, b.ul, b.last
         : 512              end + 1 < gather->start || start > gather->end + 1) {
    0.00 :   ffff80001077b294:       ldr     x2, [x19, #8]
    0.00 :   ffff80001077b298:       add     x4, x2, #0x1
    0.00 :   ffff80001077b29c:       cmp     x21, x4
    0.00 :   ffff80001077b2a0:       b.ls    ffff80001077b254 <arm_smmu_tlb_inv_page_nosync+0x6c>  // b.plast
         : 513              if (gather->pgsize)
    0.00 :   ffff80001077b2a4:       cbnz    x1, ffff80001077b220 <arm_smmu_tlb_inv_page_nosync+0x38>
    0.00 :   ffff80001077b2a8:       b       ffff80001077b280 <arm_smmu_tlb_inv_page_nosync+0x98>
 Percent |	Source code & Disassembly of vmlinux for cycles (94 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010786418 <iommu_dma_map_page>:
         : 6                iommu_dma_map_page():
         : 847              arch_sync_dma_for_device(sg_phys(sg), sg->length, dir);
         : 848              }
         : 849              }
         :
         : 851              static dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,
         : 852              unsigned long offset, size_t size, enum dma_data_direction dir,
   42.60 :   ffff800010786418:       paciasp
    6.39 :   ffff80001078641c:       stp     x29, x30, [sp, #-64]!
         : 848              unsigned long attrs)
    0.00 :   ffff800010786420:       adrp    x6, ffff800011571000 <rt_sched_class+0x10>
         : 847              unsigned long offset, size_t size, enum dma_data_direction dir,
    0.00 :   ffff800010786424:       mov     x29, sp
    2.12 :   ffff800010786428:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001078642c:       mov     x22, x3
    0.00 :   ffff800010786430:       mov     x21, x5
         : 848              unsigned long attrs)
    0.00 :   ffff800010786434:       ldr     x3, [x6, #3512]
         : 847              unsigned long offset, size_t size, enum dma_data_direction dir,
    7.45 :   ffff800010786438:       stp     x19, x20, [sp, #16]
         : 848              unsigned long attrs)
    0.00 :   ffff80001078643c:       mov     x19, #0xfffffc0000000000        // #-4398046511104
         : 847              unsigned long offset, size_t size, enum dma_data_direction dir,
    6.37 :   ffff800010786440:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010786444:       mov     w23, w4
         : 848              unsigned long attrs)
    0.00 :   ffff800010786448:       asr     x3, x3, #12
         : 850              dev_is_dma_coherent():
         : 252              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
         : 253              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
         : 254              extern bool dma_default_coherent;
         : 255              static inline bool dev_is_dma_coherent(struct device *dev)
         : 256              {
         : 257              return dev->dma_coherent;
    0.00 :   ffff80001078644c:       ldrb    w4, [x0, #736]
         : 259              iommu_dma_map_page():
    0.00 :   ffff800010786450:       sub     x3, x19, x3, lsl #6
    0.00 :   ffff800010786454:       sub     x19, x1, x3
         : 852              {
         : 853              phys_addr_t phys = page_to_phys(page) + offset;
         : 854              bool coherent = dev_is_dma_coherent(dev);
         : 855              dma_addr_t dma_handle;
    2.13 :   ffff800010786458:       ldr     x6, [x0, #576]
         : 848              unsigned long attrs)
    0.00 :   ffff80001078645c:       asr     x19, x19, #6
         : 850              dev_is_dma_coherent():
    0.00 :   ffff800010786460:       ubfx    x4, x4, #5, #1
    0.00 :   ffff800010786464:       and     w24, w4, #0xff
         : 254              iommu_dma_map_page():
    1.07 :   ffff800010786468:       add     x19, x2, x19, lsl #12
         : 849              dma_get_mask():
         : 451              }
         :
         :
         : 454              static inline u64 dma_get_mask(struct device *dev)
         : 455              {
         : 456              if (dev->dma_mask && *dev->dma_mask)
    0.00 :   ffff80001078646c:       cbz     x6, ffff8000107864f0 <iommu_dma_map_page+0xd8>
    9.58 :   ffff800010786470:       ldr     x3, [x6]
         : 453              return *dev->dma_mask;
         : 454              return DMA_BIT_MASK(32);
    0.00 :   ffff800010786474:       mov     x1, #0xffffffff                 // #4294967295
    0.00 :   ffff800010786478:       cmp     x3, #0x0
    0.00 :   ffff80001078647c:       csel    x3, x3, x1, ne  // ne = any
         : 458              iommu_dma_map_page():
         : 852              dma_addr_t dma_handle;
    9.56 :   ffff800010786480:       mov     x6, x21
    0.00 :   ffff800010786484:       mov     w5, w23
    0.00 :   ffff800010786488:       mov     x2, x22
    0.00 :   ffff80001078648c:       mov     x1, x19
    0.00 :   ffff800010786490:       bl      ffff800010786238 <__iommu_dma_map_swiotlb>
    0.00 :   ffff800010786494:       mov     x20, x0
         :
         : 855              dma_handle = __iommu_dma_map_swiotlb(dev, phys, size, dma_get_mask(dev),
    0.00 :   ffff800010786498:       cbnz    w24, ffff8000107864a8 <iommu_dma_map_page+0x90>
    0.00 :   ffff80001078649c:       tst     x21, #0x20
    0.00 :   ffff8000107864a0:       ccmn    x0, #0x1, #0x4, eq  // eq = none
    0.00 :   ffff8000107864a4:       b.ne    ffff8000107864c4 <iommu_dma_map_page+0xac>  // b.any
         : 858              coherent, dir, attrs);
         : 859              if (!coherent && !(attrs & DMA_ATTR_SKIP_CPU_SYNC) &&
         : 860              dma_handle != DMA_MAPPING_ERROR)
         : 861              arch_sync_dma_for_device(phys, size, dir);
    3.17 :   ffff8000107864a8:       mov     x0, x20
    2.12 :   ffff8000107864ac:       ldp     x19, x20, [sp, #16]
    1.06 :   ffff8000107864b0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000107864b4:       ldp     x23, x24, [sp, #48]
    4.27 :   ffff8000107864b8:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000107864bc:       autiasp
    2.12 :   ffff8000107864c0:       ret
         : 856              if (!coherent && !(attrs & DMA_ATTR_SKIP_CPU_SYNC) &&
    0.00 :   ffff8000107864c4:       mov     w2, w23
    0.00 :   ffff8000107864c8:       mov     x1, x22
    0.00 :   ffff8000107864cc:       mov     x0, x19
    0.00 :   ffff8000107864d0:       bl      ffff800010031e58 <arch_sync_dma_for_device>
         : 858              arch_sync_dma_for_device(phys, size, dir);
    0.00 :   ffff8000107864d4:       mov     x0, x20
    0.00 :   ffff8000107864d8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000107864dc:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000107864e0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000107864e4:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000107864e8:       autiasp
    0.00 :   ffff8000107864ec:       ret
         : 866              dma_get_mask():
    0.00 :   ffff8000107864f0:       mov     x3, #0xffffffff                 // #4294967295
    0.00 :   ffff8000107864f4:       b       ffff800010786480 <iommu_dma_map_page+0x68>
 Percent |	Source code & Disassembly of vmlinux for cycles (86 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001083fc28 <testthread>:
         : 6                testthread():
    0.00 :   ffff80001083fc28:       paciasp
    0.00 :   ffff80001083fc2c:       mov     x16, #0x1340                    // #4928
    0.00 :   ffff80001083fc30:       sub     sp, sp, x16
    0.00 :   ffff80001083fc34:       adrp    x2, ffff80001176d000 <cpu_number>
    0.00 :   ffff80001083fc38:       add     x2, x2, #0x0
    0.00 :   ffff80001083fc3c:       stp     x29, x30, [sp]
    0.00 :   ffff80001083fc40:       mov     x29, sp
    0.00 :   ffff80001083fc44:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001083fc48:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001083fc4c:       add     x24, x24, #0x948
    0.00 :   ffff80001083fc50:       ldr     x1, [x24]
    0.00 :   ffff80001083fc54:       str     x1, [sp, #4920]
    0.00 :   ffff80001083fc58:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001083fc5c:       adrp    x23, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff80001083fc60:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001083fc64:       adrp    x20, ffff800011eae000 <dev_attr_spm_target_link_state+0x18>
    0.00 :   ffff80001083fc68:       add     x20, x20, #0xdf8
    0.00 :   ffff80001083fc6c:       stp     x21, x22, [sp, #32]
         : 61               __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001083fc70:       mrs     x3, tpidr_el1
         : 46               testthread():
    0.00 :   ffff80001083fc74:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001083fc78:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001083fc7c:       ldr     x25, [x23, #2432]
    0.00 :   ffff80001083fc80:       ldr     w27, [x2, x3]
    0.00 :   ffff80001083fc84:       ldp     w1, w26, [x20, #4]
    0.00 :   ffff80001083fc88:       ldp     x2, x21, [x0]
    0.00 :   ffff80001083fc8c:       str     x2, [sp, #104]
    0.00 :   ffff80001083fc90:       cmp     w1, #0x0
    0.00 :   ffff80001083fc94:       b.le    ffff80001083fe78 <testthread+0x250>
    0.00 :   ffff80001083fc98:       adrp    x19, ffff800011571000 <rt_sched_class+0x10>
    0.00 :   ffff80001083fc9c:       add     x28, sp, #0x78
    0.00 :   ffff80001083fca0:       add     x19, x19, #0xf88
    0.00 :   ffff80001083fca4:       mov     w22, #0x0                       // #0
    0.00 :   ffff80001083fca8:       b       ffff80001083fcc0 <testthread+0x98>
    0.00 :   ffff80001083fcac:       ldr     w1, [x20, #4]
    0.00 :   ffff80001083fcb0:       add     w22, w22, #0x1
    0.00 :   ffff80001083fcb4:       add     x28, x28, #0x8
    0.00 :   ffff80001083fcb8:       cmp     w1, w22
    0.00 :   ffff80001083fcbc:       b.le    ffff80001083fd10 <testthread+0xe8>
         : 75               kmem_cache_alloc_trace():
         : 452              kmem_cache_free_bulk(NULL, size, p);
         : 453              }
         :
         : 455              #ifdef CONFIG_NUMA
         : 456              void *__kmalloc_node(size_t size, gfp_t flags, int node) __assume_kmalloc_alignment __malloc;
         : 457              void *kmem_cache_alloc_node(struct kmem_cache *, gfp_t flags, int node) __assume_slab_alignment __malloc;
    0.00 :   ffff80001083fcc0:       ldr     x0, [x19, #96]
    0.00 :   ffff80001083fcc4:       mov     w1, #0xdc0                      // #3520
    0.00 :   ffff80001083fcc8:       bl      ffff800010208a10 <kmem_cache_alloc>
         : 461              testthread():
    0.00 :   ffff80001083fccc:       str     x0, [x28]
    0.00 :   ffff80001083fcd0:       cbnz    x0, ffff80001083fcac <testthread+0x84>
    0.00 :   ffff80001083fcd4:       mov     w0, #0xfffffff4                 // #-12
    0.00 :   ffff80001083fcd8:       ldr     x2, [sp, #4920]
    0.00 :   ffff80001083fcdc:       ldr     x1, [x24]
    0.00 :   ffff80001083fce0:       eor     x1, x2, x1
    0.00 :   ffff80001083fce4:       cbnz    x1, ffff80001083feb0 <testthread+0x288>
    0.00 :   ffff80001083fce8:       mov     x16, #0x1340                    // #4928
    0.00 :   ffff80001083fcec:       ldp     x29, x30, [sp]
    0.00 :   ffff80001083fcf0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001083fcf4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001083fcf8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001083fcfc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001083fd00:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001083fd04:       add     sp, sp, x16
    0.00 :   ffff80001083fd08:       autiasp
    0.00 :   ffff80001083fd0c:       ret
    0.00 :   ffff80001083fd10:       cmp     w1, #0x0
    0.00 :   ffff80001083fd14:       b.le    ffff80001083fe94 <testthread+0x26c>
    0.00 :   ffff80001083fd18:       add     x28, sp, #0x6b8
    0.00 :   ffff80001083fd1c:       mov     w22, #0x0                       // #0
    0.00 :   ffff80001083fd20:       b       ffff80001083fd38 <testthread+0x110>
    0.00 :   ffff80001083fd24:       ldr     w1, [x20, #4]
    0.00 :   ffff80001083fd28:       add     w22, w22, #0x1
    0.00 :   ffff80001083fd2c:       add     x28, x28, #0x8
    0.00 :   ffff80001083fd30:       cmp     w1, w22
    0.00 :   ffff80001083fd34:       b.le    ffff80001083fd50 <testthread+0x128>
         : 81               kmem_cache_alloc_trace():
    0.00 :   ffff80001083fd38:       ldr     x0, [x19, #96]
    0.00 :   ffff80001083fd3c:       mov     w1, #0xdc0                      // #3520
    0.00 :   ffff80001083fd40:       bl      ffff800010208a10 <kmem_cache_alloc>
         : 455              testthread():
    0.00 :   ffff80001083fd44:       str     x0, [x28]
    0.00 :   ffff80001083fd48:       cbnz    x0, ffff80001083fd24 <testthread+0xfc>
    0.00 :   ffff80001083fd4c:       b       ffff80001083fcd4 <testthread+0xac>
    0.00 :   ffff80001083fd50:       mov     w0, #0xfa                       // #250
    0.00 :   ffff80001083fd54:       ldr     x2, [x23, #2432]
    0.00 :   ffff80001083fd58:       mul     w26, w26, w0
    0.00 :   ffff80001083fd5c:       add     x25, x25, w26, sxtw
    0.00 :   ffff80001083fd60:       cmp     x2, x25
    0.00 :   ffff80001083fd64:       b.pl    ffff80001083fe24 <testthread+0x1fc>  // b.nfrst
    0.00 :   ffff80001083fd68:       adrp    x23, ffff800011f89000 <megasas_mgmt_info+0x1120>
    0.00 :   ffff80001083fd6c:       add     x23, x23, #0xf40
    0.00 :   ffff80001083fd70:       adrp    x26, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff80001083fd74:       sxtw    x22, w27
    0.00 :   ffff80001083fd78:       add     x23, x23, #0x8
    0.00 :   ffff80001083fd7c:       add     x26, x26, #0x980
    0.00 :   ffff80001083fd80:       cmp     w1, #0x0
    0.00 :   ffff80001083fd84:       mov     x28, #0x1                       // #1
    0.00 :   ffff80001083fd88:       b.le    ffff80001083fe0c <testthread+0x1e4>
    0.00 :   ffff80001083fd8c:       nop
    9.50 :   ffff80001083fd90:       lsl     x19, x28, #3
    1.14 :   ffff80001083fd94:       add     x1, sp, #0x78
    0.00 :   ffff80001083fd98:       add     x1, x1, x19
    0.00 :   ffff80001083fd9c:       mov     x0, x21
    0.00 :   ffff80001083fda0:       add     x28, x28, #0x1
    0.00 :   ffff80001083fda4:       ldur    x27, [x1, #-8]
    0.00 :   ffff80001083fda8:       mov     x1, x27
    0.00 :   ffff80001083fdac:       bl      ffff80001083fb78 <test_mapsingle.constprop.6>
    0.00 :   ffff80001083fdb0:       add     x1, sp, #0xcf8
    0.00 :   ffff80001083fdb4:       add     x3, x1, x19
    0.00 :   ffff80001083fdb8:       add     x1, sp, #0x6b8
    0.00 :   ffff80001083fdbc:       add     x19, x1, x19
    0.00 :   ffff80001083fdc0:       mov     x1, x27
    2.32 :   ffff80001083fdc4:       stur    x0, [x3, #-8]
   26.69 :   ffff80001083fdc8:       ldur    x0, [x19, #-8]
    0.00 :   ffff80001083fdcc:       bl      ffff80001083fb30 <test_memcpy.constprop.5>
    0.00 :   ffff80001083fdd0:       ldr     w1, [x20, #4]
    0.00 :   ffff80001083fdd4:       sub     w0, w28, #0x1
    1.15 :   ffff80001083fdd8:       cmp     w1, w0
    0.00 :   ffff80001083fddc:       b.gt    ffff80001083fd90 <testthread+0x168>
    2.31 :   ffff80001083fde0:       cmp     w1, #0x0
    0.00 :   ffff80001083fde4:       b.le    ffff80001083fe0c <testthread+0x1e4>
    0.00 :   ffff80001083fde8:       add     x28, sp, #0xcf8
    0.00 :   ffff80001083fdec:       mov     w19, #0x0                       // #0
    4.71 :   ffff80001083fdf0:       ldr     x1, [x28], #8
    0.00 :   ffff80001083fdf4:       mov     x0, x21
    0.00 :   ffff80001083fdf8:       add     w19, w19, #0x1
    0.00 :   ffff80001083fdfc:       bl      ffff80001083fb50 <test_unmapsingle.isra.4.constprop.7>
    0.00 :   ffff80001083fe00:       ldr     w1, [x20, #4]
    0.00 :   ffff80001083fe04:       cmp     w1, w19
    0.00 :   ffff80001083fe08:       b.gt    ffff80001083fdf0 <testthread+0x1c8>
    0.00 :   ffff80001083fe0c:       ldr     x0, [x23, x22, lsl #3]
   52.18 :   ffff80001083fe10:       ldr     x2, [x26]
    0.00 :   ffff80001083fe14:       add     x0, x0, w1, sxtw
    0.00 :   ffff80001083fe18:       str     x0, [x23, x22, lsl #3]
    0.00 :   ffff80001083fe1c:       cmp     x2, x25
    0.00 :   ffff80001083fe20:       b.mi    ffff80001083fd80 <testthread+0x158>  // b.first
    0.00 :   ffff80001083fe24:       mov     x21, #0x1                       // #1
    0.00 :   ffff80001083fe28:       cmp     w1, #0x0
    0.00 :   ffff80001083fe2c:       b.le    ffff80001083fe68 <testthread+0x240>
    0.00 :   ffff80001083fe30:       lsl     x19, x21, #3
    0.00 :   ffff80001083fe34:       add     x0, sp, #0x6b8
    0.00 :   ffff80001083fe38:       add     x0, x0, x19
    0.00 :   ffff80001083fe3c:       add     x21, x21, #0x1
    0.00 :   ffff80001083fe40:       ldur    x0, [x0, #-8]
    0.00 :   ffff80001083fe44:       bl      ffff800010206230 <kfree>
    0.00 :   ffff80001083fe48:       add     x0, sp, #0x78
    0.00 :   ffff80001083fe4c:       add     x19, x0, x19
    0.00 :   ffff80001083fe50:       ldur    x0, [x19, #-8]
    0.00 :   ffff80001083fe54:       bl      ffff800010206230 <kfree>
    0.00 :   ffff80001083fe58:       ldr     w1, [x20, #4]
    0.00 :   ffff80001083fe5c:       sub     w0, w21, #0x1
    0.00 :   ffff80001083fe60:       cmp     w1, w0
    0.00 :   ffff80001083fe64:       b.gt    ffff80001083fe30 <testthread+0x208>
    0.00 :   ffff80001083fe68:       ldr     x0, [sp, #104]
    0.00 :   ffff80001083fe6c:       bl      ffff8000100d9078 <up>
    0.00 :   ffff80001083fe70:       mov     w0, #0x0                        // #0
    0.00 :   ffff80001083fe74:       b       ffff80001083fcd8 <testthread+0xb0>
    0.00 :   ffff80001083fe78:       mov     w0, #0xfa                       // #250
    0.00 :   ffff80001083fe7c:       ldr     x2, [x23, #2432]
    0.00 :   ffff80001083fe80:       mul     w26, w26, w0
    0.00 :   ffff80001083fe84:       add     x25, x25, w26, sxtw
    0.00 :   ffff80001083fe88:       cmp     x2, x25
    0.00 :   ffff80001083fe8c:       b.mi    ffff80001083fd68 <testthread+0x140>  // b.first
    0.00 :   ffff80001083fe90:       b       ffff80001083fe68 <testthread+0x240>
    0.00 :   ffff80001083fe94:       mov     w2, #0xfa                       // #250
    0.00 :   ffff80001083fe98:       ldr     x0, [x23, #2432]
    0.00 :   ffff80001083fe9c:       mul     w26, w26, w2
    0.00 :   ffff80001083fea0:       add     x25, x25, w26, sxtw
    0.00 :   ffff80001083fea4:       cmp     x0, x25
    0.00 :   ffff80001083fea8:       b.mi    ffff80001083fd68 <testthread+0x140>  // b.first
    0.00 :   ffff80001083feac:       b       ffff80001083fe68 <testthread+0x240>
    0.00 :   ffff80001083feb0:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (84 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010780460 <arm_smmu_iotlb_sync>:
         : 6                arm_smmu_iotlb_sync():
         : 2667             .release_device         = arm_smmu_release_device,
         : 2668             .device_group           = arm_smmu_device_group,
         : 2669             .enable_nesting         = arm_smmu_enable_nesting,
         : 2670             .of_xlate               = arm_smmu_of_xlate,
         : 2671             .get_resv_regions       = arm_smmu_get_resv_regions,
         : 2672             .put_resv_regions       = generic_iommu_put_resv_regions,
    0.00 :   ffff800010780460:       ldr     x2, [x1, #16]
    0.00 :   ffff800010780464:       cbnz    x2, ffff80001078046c <arm_smmu_iotlb_sync+0xc>
    0.00 :   ffff800010780468:       ret
         : 2664             .enable_nesting         = arm_smmu_enable_nesting,
    4.76 :   ffff80001078046c:       paciasp
    0.00 :   ffff800010780470:       stp     x29, x30, [sp, #-16]!
         : 2670             .dev_has_feat           = arm_smmu_dev_has_feature,
         : 2671             .dev_feat_enabled       = arm_smmu_dev_feature_enabled,
         : 2672             .dev_enable_feat        = arm_smmu_dev_enable_feature,
    0.00 :   ffff800010780474:       sub     x4, x0, #0x90
         : 2664             .enable_nesting         = arm_smmu_enable_nesting,
    0.00 :   ffff800010780478:       mov     x29, sp
         : 2670             .dev_enable_feat        = arm_smmu_dev_enable_feature,
   22.63 :   ffff80001078047c:       ldp     x0, x3, [x1]
    0.00 :   ffff800010780480:       add     x1, x3, #0x1
    0.00 :   ffff800010780484:       mov     w3, #0x1                        // #1
    0.00 :   ffff800010780488:       sub     x1, x1, x0
   66.66 :   ffff80001078048c:       bl      ffff800010780388 <arm_smmu_tlb_inv_range_domain>
         : 2673             .dev_disable_feat       = arm_smmu_dev_disable_feature,
         : 2674             .sva_bind               = arm_smmu_sva_bind,
         : 2675             .sva_unbind             = arm_smmu_sva_unbind,
    0.00 :   ffff800010780490:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010780494:       autiasp
    5.95 :   ffff800010780498:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (78 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010786238 <__iommu_dma_map_swiotlb>:
         : 6                dma_info_to_prot():
         : 398              * @attrs: DMA attributes for the mapping
         : 399              *
         : 400              * Return: corresponding IOMMU API page protection flags
         : 401              */
         : 402              static int dma_info_to_prot(enum dma_data_direction dir, bool coherent,
         : 403              unsigned long attrs)
    1.28 :   ffff800010786238:       tst     w4, #0xff
         : 405              __iommu_dma_map_swiotlb():
         : 540              }
         : 541              return iova + iova_off;
         : 542              }
         :
         : 544              static dma_addr_t __iommu_dma_map_swiotlb(struct device *dev, phys_addr_t phys,
         : 545              size_t org_size, dma_addr_t dma_mask, bool coherent,
    0.00 :   ffff80001078623c:       paciasp
    0.00 :   ffff800010786240:       stp     x29, x30, [sp, #-80]!
         : 548              dma_info_to_prot():
         : 398              unsigned long attrs)
    0.00 :   ffff800010786244:       cset    w4, ne  // ne = any
         :
    0.00 :   ffff800010786248:       tst     x6, #0x200
         : 403              __iommu_dma_map_swiotlb():
         : 540              size_t org_size, dma_addr_t dma_mask, bool coherent,
    0.00 :   ffff80001078624c:       mov     x29, sp
    6.41 :   ffff800010786250:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010786254:       mov     x19, x0
         : 544              dma_info_to_prot():
         : 398              unsigned long attrs)
    0.00 :   ffff800010786258:       lsl     w0, w4, #2
         : 400              __iommu_dma_map_swiotlb():
         : 540              size_t org_size, dma_addr_t dma_mask, bool coherent,
    1.28 :   ffff80001078625c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010786260:       mov     x22, x1
         : 543              dma_info_to_prot():
         :
    0.00 :   ffff800010786264:       orr     w1, w0, #0x20
         : 403              __iommu_dma_map_swiotlb():
         : 540              size_t org_size, dma_addr_t dma_mask, bool coherent,
    6.43 :   ffff800010786268:       stp     x23, x24, [sp, #48]
         : 542              dma_info_to_prot():
         :
    0.00 :   ffff80001078626c:       csel    w0, w1, w0, ne  // ne = any
         : 403              __iommu_dma_map_swiotlb():
         : 540              size_t org_size, dma_addr_t dma_mask, bool coherent,
    0.00 :   ffff800010786270:       mov     x24, x6
   10.24 :   ffff800010786274:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010786278:       mov     w21, w5
    0.00 :   ffff80001078627c:       mov     x23, x2
    0.00 :   ffff800010786280:       mov     x25, x3
         : 546              dma_info_to_prot():
         : 403              prot |= IOMMU_PRIV;
    3.85 :   ffff800010786284:       cmp     w5, #0x1
         : 407              return prot | IOMMU_READ | IOMMU_WRITE;
    0.00 :   ffff800010786288:       orr     w26, w0, #0x1
         : 403              prot |= IOMMU_PRIV;
    0.00 :   ffff80001078628c:       b.eq    ffff8000107862a4 <__iommu_dma_map_swiotlb+0x6c>  // b.none
         : 405              switch (dir) {
    0.00 :   ffff800010786290:       orr     w26, w0, #0x3
         : 403              prot |= IOMMU_PRIV;
    0.00 :   ffff800010786294:       cbz     w5, ffff8000107862a4 <__iommu_dma_map_swiotlb+0x6c>
         : 411              return prot | IOMMU_WRITE;
    0.00 :   ffff800010786298:       orr     w0, w0, #0x2
    0.00 :   ffff80001078629c:       cmp     w5, #0x2
    0.00 :   ffff8000107862a0:       csel    w26, w0, wzr, eq  // eq = none
         : 415              __iommu_dma_map_swiotlb():
         : 542              enum dma_data_direction dir, unsigned long attrs)
         : 543              {
    0.00 :   ffff8000107862a4:       mov     x0, x19
    0.00 :   ffff8000107862a8:       bl      ffff800010784d10 <iommu_get_dma_domain>
         : 546              dev_is_untrusted():
         : 315              static bool dev_is_untrusted(struct device *dev)
   21.82 :   ffff8000107862ac:       ldr     x2, [x19, #96]
    0.00 :   ffff8000107862b0:       adrp    x1, ffff800011d4b000 <gpio_rcar_device_driver+0xa8>
    0.00 :   ffff8000107862b4:       add     x1, x1, #0xcc0
         : 319              __iommu_dma_map_swiotlb():
         : 545              int prot = dma_info_to_prot(dir, coherent, attrs);
         : 546              struct iommu_domain *domain = iommu_get_dma_domain(dev);
         : 547              struct iommu_dma_cookie *cookie = domain->iova_cookie;
    0.00 :   ffff8000107862b8:       mov     x20, x23
         : 549              dev_is_untrusted():
         : 315              static bool dev_is_untrusted(struct device *dev)
    5.11 :   ffff8000107862bc:       cmp     x2, x1
    0.00 :   ffff8000107862c0:       b.eq    ffff800010786364 <__iommu_dma_map_swiotlb+0x12c>  // b.none
         : 318              __iommu_dma_map_swiotlb():
         : 577              padding_start += org_size;
         : 578              padding_size -= org_size;
         : 579              }
         :
         : 581              memset(padding_start, 0, padding_size);
         : 582              }
   11.54 :   ffff8000107862c4:       mov     x2, x20
    0.00 :   ffff8000107862c8:       mov     x4, x25
    0.00 :   ffff8000107862cc:       mov     w3, w26
    0.00 :   ffff8000107862d0:       mov     x1, x22
    3.83 :   ffff8000107862d4:       mov     x0, x19
    0.00 :   ffff8000107862d8:       bl      ffff8000107860b0 <__iommu_dma_map>
   11.51 :   ffff8000107862dc:       mov     x20, x0
         :
    0.00 :   ffff8000107862e0:       cmn     x0, #0x1
    0.00 :   ffff8000107862e4:       b.eq    ffff800010786308 <__iommu_dma_map_swiotlb+0xd0>  // b.none
         : 581              iova = __iommu_dma_map(dev, phys, aligned_size, prot, dma_mask);
         : 582              if (iova == DMA_MAPPING_ERROR && is_swiotlb_buffer(phys))
         : 583              swiotlb_tbl_unmap_single(dev, phys, org_size, dir, attrs);
    1.30 :   ffff8000107862e8:       mov     x0, x20
    0.00 :   ffff8000107862ec:       ldp     x19, x20, [sp, #16]
    1.29 :   ffff8000107862f0:       ldp     x21, x22, [sp, #32]
    7.70 :   ffff8000107862f4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000107862f8:       ldp     x25, x26, [sp, #64]
    2.56 :   ffff8000107862fc:       ldp     x29, x30, [sp], #80
    0.00 :   ffff800010786300:       autiasp
    3.84 :   ffff800010786304:       ret
         : 592              is_swiotlb_buffer():
         : 106              };
         : 107              extern struct io_tlb_mem *io_tlb_default_mem;
         :
         : 109              static inline bool is_swiotlb_buffer(phys_addr_t paddr)
         : 110              {
         : 111              struct io_tlb_mem *mem = io_tlb_default_mem;
    0.00 :   ffff800010786308:       adrp    x0, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff80001078630c:       ldr     x0, [x0, #3624]
         :
         : 109              return mem && paddr >= mem->start && paddr < mem->end;
    0.00 :   ffff800010786310:       cbz     x0, ffff8000107863bc <__iommu_dma_map_swiotlb+0x184>
    0.00 :   ffff800010786314:       ldr     x1, [x0]
    0.00 :   ffff800010786318:       cmp     x22, x1
    0.00 :   ffff80001078631c:       b.cc    ffff8000107863bc <__iommu_dma_map_swiotlb+0x184>  // b.lo, b.ul, b.last
    0.00 :   ffff800010786320:       ldr     x0, [x0, #8]
    0.00 :   ffff800010786324:       cmp     x22, x0
    0.00 :   ffff800010786328:       b.cs    ffff8000107863bc <__iommu_dma_map_swiotlb+0x184>  // b.hs, b.nlast
         : 117              __iommu_dma_map_swiotlb():
         : 579              iova = __iommu_dma_map(dev, phys, aligned_size, prot, dma_mask);
    0.00 :   ffff80001078632c:       mov     x4, x24
    0.00 :   ffff800010786330:       mov     w3, w21
    0.00 :   ffff800010786334:       mov     x2, x23
    0.00 :   ffff800010786338:       mov     x1, x22
    0.00 :   ffff80001078633c:       mov     x0, x19
    0.00 :   ffff800010786340:       bl      ffff800010108fd8 <swiotlb_tbl_unmap_single>
         : 581              swiotlb_tbl_unmap_single(dev, phys, org_size, dir, attrs);
    0.00 :   ffff800010786344:       mov     x0, x20
    0.00 :   ffff800010786348:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078634c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010786350:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010786354:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010786358:       ldp     x29, x30, [sp], #80
    0.00 :   ffff80001078635c:       autiasp
    0.00 :   ffff800010786360:       ret
         : 590              dev_is_untrusted():
         : 315              static bool dev_is_untrusted(struct device *dev)
    0.00 :   ffff800010786364:       ldrb    w1, [x19, #1844]
    0.00 :   ffff800010786368:       tbz     w1, #3, ffff8000107862c4 <__iommu_dma_map_swiotlb+0x8c>
         : 318              iova_offset():
         : 118              return iovad->granule - 1;
         : 119              }
         :
         : 121              static inline size_t iova_offset(struct iova_domain *iovad, dma_addr_t iova)
         : 122              {
         : 123              return iova & iova_mask(iovad);
    0.00 :   ffff80001078636c:       ldr     x1, [x0, #64]
         : 125              __iommu_dma_map_swiotlb():
         : 555              */
    0.00 :   ffff800010786370:       orr     x0, x23, x22
         : 557              iova_offset():
    0.00 :   ffff800010786374:       ldr     x1, [x1, #40]
         : 119              iova_mask():
         : 113              return iovad->granule - 1;
    0.00 :   ffff800010786378:       sub     x2, x1, #0x1
         : 115              __iommu_dma_map_swiotlb():
         : 554              * page aligned, we don't need to use a bounce page.
    0.00 :   ffff80001078637c:       tst     x0, x2
    0.00 :   ffff800010786380:       b.eq    ffff8000107862c4 <__iommu_dma_map_swiotlb+0x8c>  // b.none
         : 557              iova_align():
         : 123              }
         :
         : 125              static inline size_t iova_align(struct iova_domain *iovad, size_t size)
         : 126              {
         : 127              return ALIGN(size, iovad->granule);
    0.00 :   ffff800010786384:       sub     x20, x23, #0x1
    0.00 :   ffff800010786388:       neg     x0, x1
    0.00 :   ffff80001078638c:       add     x20, x20, x1
         : 131              __iommu_dma_map_swiotlb():
         : 557              iova_offset(iovad, phys | org_size)) {
    0.00 :   ffff800010786390:       mov     x5, x24
         : 559              iova_align():
    0.00 :   ffff800010786394:       and     x20, x20, x0
         : 124              __iommu_dma_map_swiotlb():
    0.00 :   ffff800010786398:       mov     x1, x22
    0.00 :   ffff80001078639c:       mov     x3, x20
    0.00 :   ffff8000107863a0:       mov     w4, w21
    0.00 :   ffff8000107863a4:       mov     x2, x23
    0.00 :   ffff8000107863a8:       mov     x0, x19
    0.00 :   ffff8000107863ac:       bl      ffff800010108bf0 <swiotlb_tbl_map_single>
    0.00 :   ffff8000107863b0:       mov     x22, x0
         : 560              aligned_size, dir, attrs);
    0.00 :   ffff8000107863b4:       cmn     x0, #0x1
    0.00 :   ffff8000107863b8:       b.ne    ffff8000107863e0 <__iommu_dma_map_swiotlb+0x1a8>  // b.any
         :
    0.00 :   ffff8000107863bc:       mov     x20, #0xffffffffffffffff        // #-1
         : 581              swiotlb_tbl_unmap_single(dev, phys, org_size, dir, attrs);
    0.00 :   ffff8000107863c0:       mov     x0, x20
    0.00 :   ffff8000107863c4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000107863c8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000107863cc:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000107863d0:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000107863d4:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000107863d8:       autiasp
    0.00 :   ffff8000107863dc:       ret
         : 590              phys_to_virt():
         : 312              #define phys_to_virt phys_to_virt
         : 313              static inline void *phys_to_virt(phys_addr_t x)
         : 314              {
         : 315              return (void *)(__phys_to_virt(x));
         : 316              }
         :
    0.00 :   ffff8000107863e0:       adrp    x0, ffff800011571000 <rt_sched_class+0x10>
         : 319              __iommu_dma_map_swiotlb():
         : 567              padding_size = aligned_size;
    0.00 :   ffff8000107863e4:       tst     x24, #0x20
    0.00 :   ffff8000107863e8:       ccmp    w21, #0x1, #0x2, eq  // eq = none
         : 565              /* Cleanup the padding area. */
    0.00 :   ffff8000107863ec:       mov     x2, x20
         : 567              phys_to_virt():
    0.00 :   ffff8000107863f0:       ldr     x0, [x0, #3512]
    0.00 :   ffff8000107863f4:       sub     x0, x22, x0
    0.00 :   ffff8000107863f8:       orr     x0, x0, #0xffff000000000000
         : 315              __iommu_dma_map_swiotlb():
         : 567              padding_size = aligned_size;
    0.00 :   ffff8000107863fc:       b.ls    ffff80001078640c <__iommu_dma_map_swiotlb+0x1d4>  // b.plast
         : 574              }
    0.00 :   ffff800010786400:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010786404:       bl      ffff8000104a5e40 <__memset>
    0.00 :   ffff800010786408:       b       ffff8000107862c4 <__iommu_dma_map_swiotlb+0x8c>
         : 570              (dir == DMA_TO_DEVICE ||
    0.00 :   ffff80001078640c:       add     x0, x0, x23
         : 571              dir == DMA_BIDIRECTIONAL)) {
    0.00 :   ffff800010786410:       sub     x2, x20, x23
    0.00 :   ffff800010786414:       b       ffff800010786400 <__iommu_dma_map_swiotlb+0x1c8>
 Percent |	Source code & Disassembly of vmlinux for cycles (73 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010782c90 <__iommu_unmap>:
         : 6                __iommu_unmap():
         : 2493             return _iommu_map(domain, iova, paddr, size, prot, GFP_KERNEL);
         : 2494             }
         : 2495             EXPORT_SYMBOL_GPL(iommu_map);
         :
         : 2497             int iommu_map_atomic(struct iommu_domain *domain, unsigned long iova,
         : 2498             phys_addr_t paddr, size_t size, int prot)
    0.00 :   ffff800010782c90:       paciasp
    0.00 :   ffff800010782c94:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010782c98:       mov     x29, sp
    0.00 :   ffff800010782c9c:       stp     x19, x20, [sp, #16]
   12.34 :   ffff800010782ca0:       stp     x23, x24, [sp, #48]
         : 2494             {
    0.00 :   ffff800010782ca4:       ldr     x23, [x0, #8]
         : 2499             return _iommu_map(domain, iova, paddr, size, prot, GFP_ATOMIC);
         : 2500             }
         : 2501             EXPORT_SYMBOL_GPL(iommu_map_atomic);
         :
         : 2503             static size_t __iommu_unmap(struct iommu_domain *domain,
    0.00 :   ffff800010782ca8:       ldr     x4, [x23, #48]
    0.00 :   ffff800010782cac:       cbz     x4, ffff800010782d78 <__iommu_unmap+0xe8>
    1.37 :   ffff800010782cb0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010782cb4:       mov     x21, x0
    8.21 :   ffff800010782cb8:       ldr     x0, [x0, #16]
    0.00 :   ffff800010782cbc:       cbz     x0, ffff800010782d58 <__iommu_unmap+0xc8>
         : 2503             unsigned long iova, size_t size,
         : 2504             struct iommu_iotlb_gather *iotlb_gather)
         : 2505             {
         : 2506             const struct iommu_ops *ops = domain->ops;
    0.00 :   ffff800010782cc0:       mov     x24, x3
    0.00 :   ffff800010782cc4:       ldr     w3, [x21]
    0.00 :   ffff800010782cc8:       tbz     w3, #0, ffff800010782d58 <__iommu_unmap+0xc8>
         : 2510             __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff800010782ccc:       rbit    x5, x0
         : 20               __iommu_unmap():
         : 2507             size_t unmapped_page, unmapped = 0;
         : 2508             unsigned long orig_iova = iova;
         : 2509             unsigned int min_pagesz;
         :
    0.00 :   ffff800010782cd0:       mov     w3, #0x1                        // #1
         : 2512             __ffs():
    0.00 :   ffff800010782cd4:       clz     x5, x5
         : 14               __iommu_unmap():
         : 2514             domain->pgsize_bitmap == 0UL))
         : 2515             return 0;
         :
         : 2517             if (unlikely(!(domain->type & __IOMMU_DOMAIN_PAGING)))
         : 2518             return 0;
         :
    0.00 :   ffff800010782cd8:       orr     x19, x1, x2
   10.98 :   ffff800010782cdc:       mov     x20, x1
    0.00 :   ffff800010782ce0:       mov     x22, x2
         :
    0.00 :   ffff800010782ce4:       lsl     w5, w3, w5
    0.00 :   ffff800010782ce8:       mov     x3, x5
         :
    0.00 :   ffff800010782cec:       sub     x5, x5, #0x1
    0.00 :   ffff800010782cf0:       ands    x19, x19, x5
    0.00 :   ffff800010782cf4:       b.ne    ffff800010782d94 <__iommu_unmap+0x104>  // b.any
         : 2526             * by the hardware
         : 2527             */
         : 2528             if (!IS_ALIGNED(iova | size, min_pagesz)) {
         : 2529             pr_err("unaligned: iova 0x%lx size 0x%zx min_pagesz 0x%x\n",
         : 2530             iova, size, min_pagesz);
         : 2531             return 0;
    1.38 :   ffff800010782cf8:       cbnz    x2, ffff800010782d18 <__iommu_unmap+0x88>
    0.00 :   ffff800010782cfc:       b       ffff800010782d3c <__iommu_unmap+0xac>
         : 2537             * Keep iterating until we either unmap 'size' bytes (or more)
         : 2538             * or we hit an area that isn't mapped.
         : 2539             */
         : 2540             while (unmapped < size) {
         : 2541             size_t pgsize = iommu_pgsize(domain, iova, size - unmapped);
         :
   10.95 :   ffff800010782d00:       add     x19, x19, x0
         : 2536             size_t pgsize = iommu_pgsize(domain, iova, size - unmapped);
    0.00 :   ffff800010782d04:       add     x20, x20, x0
         : 2526             return 0;
    0.00 :   ffff800010782d08:       cmp     x22, x19
    0.00 :   ffff800010782d0c:       b.ls    ffff800010782d3c <__iommu_unmap+0xac>  // b.plast
    0.00 :   ffff800010782d10:       ldr     x0, [x21, #16]
    0.00 :   ffff800010782d14:       ldr     x4, [x23, #48]
         : 2527             }
    2.76 :   ffff800010782d18:       sub     x2, x22, x19
    0.00 :   ffff800010782d1c:       mov     x1, x20
    0.00 :   ffff800010782d20:       bl      ffff800010782c20 <iommu_pgsize.isra.24>
         : 2529             pr_debug("unmap this: iova 0x%lx size 0x%zx\n", iova, size);
    0.00 :   ffff800010782d24:       mov     x3, x24
    0.00 :   ffff800010782d28:       mov     x2, x0
    0.00 :   ffff800010782d2c:       mov     x1, x20
    0.00 :   ffff800010782d30:       mov     x0, x21
    0.00 :   ffff800010782d34:       blr     x4
         :
    0.00 :   ffff800010782d38:       cbnz    x0, ffff800010782d00 <__iommu_unmap+0x70>
    0.00 :   ffff800010782d3c:       ldp     x21, x22, [sp, #32]
         : 2542             unmapped_page = ops->unmap(domain, iova, pgsize, iotlb_gather);
         : 2543             if (!unmapped_page)
         : 2544             break;
         :
         : 2546             pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
    0.00 :   ffff800010782d40:       mov     x0, x19
   35.59 :   ffff800010782d44:       ldp     x19, x20, [sp, #16]
    8.21 :   ffff800010782d48:       ldp     x23, x24, [sp, #48]
    8.21 :   ffff800010782d4c:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010782d50:       autiasp
    0.00 :   ffff800010782d54:       ret
         : 2501             struct iommu_iotlb_gather *iotlb_gather)
    0.00 :   ffff800010782d58:       mov     x19, #0x0                       // #0
         : 2542             pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
    0.00 :   ffff800010782d5c:       mov     x0, x19
    0.00 :   ffff800010782d60:       ldp     x19, x20, [sp, #16]
         : 2501             struct iommu_iotlb_gather *iotlb_gather)
    0.00 :   ffff800010782d64:       ldp     x21, x22, [sp, #32]
         : 2542             pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
    0.00 :   ffff800010782d68:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010782d6c:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010782d70:       autiasp
    0.00 :   ffff800010782d74:       ret
         : 2501             struct iommu_iotlb_gather *iotlb_gather)
    0.00 :   ffff800010782d78:       mov     x19, #0x0                       // #0
         : 2542             pr_debug("unmapped: iova 0x%lx size 0x%zx\n",
    0.00 :   ffff800010782d7c:       mov     x0, x19
    0.00 :   ffff800010782d80:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010782d84:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010782d88:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010782d8c:       autiasp
    0.00 :   ffff800010782d90:       ret
         : 2515             /* find out the minimum page size supported */
    0.00 :   ffff800010782d94:       adrp    x0, ffff8000114d7000 <kallsyms_token_index+0xcc7a0>
         :
    0.00 :   ffff800010782d98:       mov     x19, #0x0                       // #0
         : 2515             /* find out the minimum page size supported */
    0.00 :   ffff800010782d9c:       add     x0, x0, #0xfe8
    0.00 :   ffff800010782da0:       bl      ffff800010e19544 <printk>
         :
    0.00 :   ffff800010782da4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010782da8:       b       ffff800010782d40 <__iommu_unmap+0xb0>
 Percent |	Source code & Disassembly of vmlinux for cycles (72 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010105168 <dma_map_page_attrs>:
         : 6                dma_map_page_attrs():
         : 145              }
         :
         : 147              dma_addr_t dma_map_page_attrs(struct device *dev, struct page *page,
         : 148              size_t offset, size_t size, enum dma_data_direction dir,
         : 149              unsigned long attrs)
         : 150              {
    0.00 :   ffff800010105168:       paciasp
    1.40 :   ffff80001010516c:       stp     x29, x30, [sp, #-64]!
         : 149              const struct dma_map_ops *ops = get_dma_ops(dev);
         : 150              dma_addr_t addr;
         :
         : 152              BUG_ON(!valid_dma_direction(dir));
    0.00 :   ffff800010105170:       cmp     w4, #0x2
         : 145              {
    0.00 :   ffff800010105174:       mov     x29, sp
   18.03 :   ffff800010105178:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001010517c:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010105180:       add     x20, x20, #0x948
    6.92 :   ffff800010105184:       ldr     x6, [x20]
   29.21 :   ffff800010105188:       str     x6, [sp, #56]
    0.00 :   ffff80001010518c:       mov     x6, #0x0                        // #0
         : 149              BUG_ON(!valid_dma_direction(dir));
    0.00 :   ffff800010105190:       b.hi    ffff8000101052fc <dma_map_page_attrs+0x194>  // b.pmore
         :
         : 152              if (WARN_ON_ONCE(!dev->dma_mask))
    0.00 :   ffff800010105194:       ldr     x10, [x0, #576]
    0.00 :   ffff800010105198:       mov     x19, x0
    0.00 :   ffff80001010519c:       cbz     x10, ffff800010105304 <dma_map_page_attrs+0x19c>
         : 146              const struct dma_map_ops *ops = get_dma_ops(dev);
    6.96 :   ffff8000101051a0:       ldr     x11, [x0, #568]
         : 148              dma_go_direct():
         : 114              if (likely(!ops))
    0.00 :   ffff8000101051a4:       cbnz    x11, ffff800010105310 <dma_map_page_attrs+0x1a8>
         : 116              dma_direct_map_page():
         :
         : 88               static inline dma_addr_t dma_direct_map_page(struct device *dev,
         : 89               struct page *page, unsigned long offset, size_t size,
         : 90               enum dma_data_direction dir, unsigned long attrs)
         : 91               {
         : 92               phys_addr_t phys = page_to_phys(page) + offset;
    0.00 :   ffff8000101051a8:       adrp    x0, ffff800011571000 <rt_sched_class+0x10>
    0.00 :   ffff8000101051ac:       mov     x6, x2
    0.00 :   ffff8000101051b0:       mov     x2, #0xfffffc0000000000         // #-4398046511104
    0.00 :   ffff8000101051b4:       str     x21, [sp, #32]
    0.00 :   ffff8000101051b8:       ldr     x0, [x0, #3512]
    0.00 :   ffff8000101051bc:       mov     w8, w4
    0.00 :   ffff8000101051c0:       mov     x9, x5
    0.00 :   ffff8000101051c4:       mov     x21, x3
    0.00 :   ffff8000101051c8:       asr     x0, x0, #12
    0.00 :   ffff8000101051cc:       sub     x0, x2, x0, lsl #6
    0.00 :   ffff8000101051d0:       sub     x7, x1, x0
         : 104              phys_to_dma():
         : 74               * phys_to_dma_unencrypted is for use on special unencrypted memory like swiotlb
         : 75               * buffers.
         : 76               */
         : 77               static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
         : 78               {
         : 79               return __sme_set(phys_to_dma_unencrypted(dev, paddr));
    0.00 :   ffff8000101051d4:       ldr     x1, [x19, #600]
         : 81               dma_direct_map_page():
    0.00 :   ffff8000101051d8:       asr     x7, x7, #6
    0.00 :   ffff8000101051dc:       add     x6, x6, x7, lsl #12
         : 89               phys_to_dma_unencrypted():
         : 61               if (dev->dma_range_map)
    0.00 :   ffff8000101051e0:       cbz     x1, ffff800010105254 <dma_map_page_attrs+0xec>
         : 63               translate_phys_to_dma():
         : 32               for (m = dev->dma_range_map; m->size; m++)
    0.00 :   ffff8000101051e4:       ldr     x2, [x1, #16]
    0.00 :   ffff8000101051e8:       cbz     x2, ffff800010105214 <dma_map_page_attrs+0xac>
    0.00 :   ffff8000101051ec:       nop
         : 33               if (paddr >= m->cpu_start && paddr - m->cpu_start < m->size)
    0.00 :   ffff8000101051f0:       ldr     x0, [x1]
    0.00 :   ffff8000101051f4:       cmp     x6, x0
    0.00 :   ffff8000101051f8:       b.cc    ffff800010105208 <dma_map_page_attrs+0xa0>  // b.lo, b.ul, b.last
    0.00 :   ffff8000101051fc:       sub     x0, x6, x0
    0.00 :   ffff800010105200:       cmp     x0, x2
    0.00 :   ffff800010105204:       b.cc    ffff8000101052f0 <dma_map_page_attrs+0x188>  // b.lo, b.ul, b.last
         : 32               for (m = dev->dma_range_map; m->size; m++)
    0.00 :   ffff800010105208:       add     x1, x1, #0x20
    0.00 :   ffff80001010520c:       ldr     x2, [x1, #16]
    0.00 :   ffff800010105210:       cbnz    x2, ffff8000101051f0 <dma_map_page_attrs+0x88>
         : 36               dma_direct_map_page():
         : 90               dma_addr_t dma_addr = phys_to_dma(dev, phys);
         :
         : 92               if (unlikely(swiotlb_force == SWIOTLB_FORCE))
    0.00 :   ffff800010105214:       adrp    x0, ffff800011f4c000 <__log_buf+0x1fb98>
         : 88               dma_addr_t dma_addr = phys_to_dma(dev, phys);
    0.00 :   ffff800010105218:       mov     x1, #0xffffffffffffffff         // #-1
    0.00 :   ffff80001010521c:       str     x1, [sp, #48]
         : 90               if (unlikely(swiotlb_force == SWIOTLB_FORCE))
    0.00 :   ffff800010105220:       ldr     w3, [x0, #3636]
    0.00 :   ffff800010105224:       cmp     w3, #0x1
    0.00 :   ffff800010105228:       b.eq    ffff800010105234 <dma_map_page_attrs+0xcc>  // b.none
         : 94               return swiotlb_map(dev, phys, size, dir, attrs);
         :
         : 96               if (unlikely(!dma_capable(dev, dma_addr, size, true))) {
         : 97               if (swiotlb_force != SWIOTLB_NO_FORCE)
    0.00 :   ffff80001010522c:       cmp     w3, #0x2
    0.00 :   ffff800010105230:       b.eq    ffff80001010531c <dma_map_page_attrs+0x1b4>  // b.none
         : 95               return swiotlb_map(dev, phys, size, dir, attrs);
    0.00 :   ffff800010105234:       mov     x2, x21
    0.00 :   ffff800010105238:       mov     x4, x9
    0.00 :   ffff80001010523c:       mov     w3, w8
    0.00 :   ffff800010105240:       mov     x1, x6
    0.00 :   ffff800010105244:       mov     x0, x19
    0.00 :   ffff800010105248:       bl      ffff8000101091e0 <swiotlb_map>
    0.00 :   ffff80001010524c:       ldr     x21, [sp, #32]
    0.00 :   ffff800010105250:       b       ffff8000101052ac <dma_map_page_attrs+0x144>
         : 87               phys_addr_t phys = page_to_phys(page) + offset;
    0.00 :   ffff800010105254:       mov     x0, x6
         : 90               if (unlikely(swiotlb_force == SWIOTLB_FORCE))
    0.00 :   ffff800010105258:       adrp    x1, ffff800011f4c000 <__log_buf+0x1fb98>
         : 88               dma_addr_t dma_addr = phys_to_dma(dev, phys);
    0.00 :   ffff80001010525c:       str     x0, [sp, #48]
         : 90               if (unlikely(swiotlb_force == SWIOTLB_FORCE))
    0.00 :   ffff800010105260:       ldr     w3, [x1, #3636]
    0.00 :   ffff800010105264:       cmp     w3, #0x1
    0.00 :   ffff800010105268:       b.eq    ffff800010105234 <dma_map_page_attrs+0xcc>  // b.none
         : 94               dma_capable():
         : 102              #endif /* CONFIG_ARCH_HAS_FORCE_DMA_UNENCRYPTED */
         :
         : 104              static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size,
         : 105              bool is_ram)
         : 106              {
         : 107              dma_addr_t end = addr + size - 1;
    0.00 :   ffff80001010526c:       sub     x1, x21, #0x1
         :
         : 105              if (addr == DMA_MAPPING_ERROR)
    0.00 :   ffff800010105270:       cmn     x0, #0x1
         : 102              dma_addr_t end = addr + size - 1;
    0.00 :   ffff800010105274:       add     x1, x1, x0
         : 104              if (addr == DMA_MAPPING_ERROR)
    0.00 :   ffff800010105278:       b.eq    ffff80001010522c <dma_map_page_attrs+0xc4>  // b.none
         : 110              return false;
         : 111              if (is_ram && !IS_ENABLED(CONFIG_ARCH_DMA_ADDR_T_64BIT) &&
         : 112              min(addr, end) < phys_to_dma(dev, PFN_PHYS(min_low_pfn)))
         : 113              return false;
         :
         : 115              return end <= min_not_zero(*dev->dma_mask, dev->bus_dma_limit);
    0.00 :   ffff80001010527c:       ldr     x4, [x10]
    0.00 :   ffff800010105280:       ldr     x2, [x19, #592]
    0.00 :   ffff800010105284:       cbz     x4, ffff800010105294 <dma_map_page_attrs+0x12c>
    0.00 :   ffff800010105288:       cbz     x2, ffff8000101052cc <dma_map_page_attrs+0x164>
    0.00 :   ffff80001010528c:       cmp     x2, x4
    0.00 :   ffff800010105290:       csel    x2, x2, x4, ls  // ls = plast
         : 122              dma_direct_map_page():
         : 93               if (unlikely(!dma_capable(dev, dma_addr, size, true))) {
    0.00 :   ffff800010105294:       cmp     x1, x2
    0.00 :   ffff800010105298:       b.hi    ffff80001010522c <dma_map_page_attrs+0xc4>  // b.pmore
         : 96               dev_is_dma_coherent():
         : 252              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
         : 253              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
         : 254              extern bool dma_default_coherent;
         : 255              static inline bool dev_is_dma_coherent(struct device *dev)
         : 256              {
         : 257              return dev->dma_coherent;
    0.00 :   ffff80001010529c:       ldrb    w1, [x19, #736]
         : 259              dma_direct_map_page():
         : 103              "DMA addr %pad+%zu overflow (mask %llx, bus limit %llx).\n",
         : 104              &dma_addr, size, *dev->dma_mask, dev->bus_dma_limit);
         : 105              return DMA_MAPPING_ERROR;
         : 106              }
         :
         : 108              if (!dev_is_dma_coherent(dev) && !(attrs & DMA_ATTR_SKIP_CPU_SYNC))
    0.00 :   ffff8000101052a0:       tbnz    w1, #5, ffff8000101052a8 <dma_map_page_attrs+0x140>
    0.00 :   ffff8000101052a4:       tbz     w9, #5, ffff8000101052d4 <dma_map_page_attrs+0x16c>
    0.00 :   ffff8000101052a8:       ldr     x21, [sp, #32]
         : 112              dma_map_page_attrs():
         : 162              else
         : 163              addr = ops->map_page(dev, page, offset, size, dir, attrs);
         : 164              debug_dma_map_page(dev, page, offset, size, dir, addr);
         :
         : 166              return addr;
         : 167              }
    0.00 :   ffff8000101052ac:       ldr     x2, [sp, #56]
    4.15 :   ffff8000101052b0:       ldr     x1, [x20]
    0.00 :   ffff8000101052b4:       eor     x1, x2, x1
    0.00 :   ffff8000101052b8:       cbnz    x1, ffff80001010537c <dma_map_page_attrs+0x214>
   11.08 :   ffff8000101052bc:       ldp     x19, x20, [sp, #16]
   12.54 :   ffff8000101052c0:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000101052c4:       autiasp
    0.00 :   ffff8000101052c8:       ret
         : 176              dma_capable():
    0.00 :   ffff8000101052cc:       mov     x2, x4
    0.00 :   ffff8000101052d0:       b       ffff800010105294 <dma_map_page_attrs+0x12c>
         : 112              dma_direct_map_page():
         : 104              arch_sync_dma_for_device(phys, size, dir);
    0.00 :   ffff8000101052d4:       mov     x0, x6
    0.00 :   ffff8000101052d8:       mov     x1, x21
    0.00 :   ffff8000101052dc:       mov     w2, w8
    0.00 :   ffff8000101052e0:       bl      ffff800010031e58 <arch_sync_dma_for_device>
    0.00 :   ffff8000101052e4:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101052e8:       ldr     x0, [sp, #48]
         : 105              return dma_addr;
    0.00 :   ffff8000101052ec:       b       ffff8000101052ac <dma_map_page_attrs+0x144>
         : 107              translate_phys_to_dma():
         : 34               return (dma_addr_t)paddr - m->offset;
    0.00 :   ffff8000101052f0:       ldr     x0, [x1, #24]
    0.00 :   ffff8000101052f4:       sub     x0, x6, x0
    0.00 :   ffff8000101052f8:       b       ffff800010105258 <dma_map_page_attrs+0xf0>
    0.00 :   ffff8000101052fc:       str     x21, [sp, #32]
         : 39               dma_map_page_attrs():
         : 149              BUG_ON(!valid_dma_direction(dir));
    0.00 :   ffff800010105300:       brk     #0x800
         : 151              if (WARN_ON_ONCE(!dev->dma_mask))
    0.00 :   ffff800010105304:       brk     #0x800
         : 152              return DMA_MAPPING_ERROR;
    0.00 :   ffff800010105308:       mov     x0, #0xffffffffffffffff         // #-1
    0.00 :   ffff80001010530c:       b       ffff8000101052ac <dma_map_page_attrs+0x144>
         : 158              addr = ops->map_page(dev, page, offset, size, dir, attrs);
    8.31 :   ffff800010105310:       ldr     x6, [x11, #64]
    0.00 :   ffff800010105314:       blr     x6
    1.40 :   ffff800010105318:       b       ffff8000101052ac <dma_map_page_attrs+0x144>
         : 162              dma_direct_map_page():
         : 97               dev_WARN_ONCE(dev, 1,
    0.00 :   ffff80001010531c:       adrp    x1, ffff800011efe000 <errmap+0xc38>
         : 100              return DMA_MAPPING_ERROR;
    0.00 :   ffff800010105320:       mov     x0, #0xffffffffffffffff         // #-1
         : 97               dev_WARN_ONCE(dev, 1,
    0.00 :   ffff800010105324:       ldrb    w2, [x1, #2805]
    0.00 :   ffff800010105328:       cbnz    w2, ffff8000101052a8 <dma_map_page_attrs+0x140>
    0.00 :   ffff80001010532c:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010105330:       mov     x0, x19
    0.00 :   ffff800010105334:       strb    w2, [x1, #2805]
    0.00 :   ffff800010105338:       bl      ffff800010797610 <dev_driver_string>
         : 104              dev_name():
         : 611              struct kref kref;
         : 612              struct work_struct rm_work;
         : 613              bool supplier_preactivated; /* Owned by consumer probe. */
         : 614              };
         :
         : 616              static inline struct device *kobj_to_dev(struct kobject *kobj)
    0.00 :   ffff80001010533c:       ldr     x2, [x19, #80]
    0.00 :   ffff800010105340:       cbnz    x2, ffff800010105348 <dma_map_page_attrs+0x1e0>
         : 614              {
         : 615              return container_of(kobj, struct device, kobj);
         : 616              }
    0.00 :   ffff800010105344:       ldr     x2, [x19]
         : 618              dma_direct_map_page():
    0.00 :   ffff800010105348:       mov     x1, x0
    0.00 :   ffff80001010534c:       ldr     x3, [x19, #576]
    0.00 :   ffff800010105350:       mov     x4, x21
    0.00 :   ffff800010105354:       ldr     x6, [x19, #592]
    0.00 :   ffff800010105358:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff80001010535c:       ldr     x5, [x3]
    0.00 :   ffff800010105360:       add     x0, x0, #0xf78
    0.00 :   ffff800010105364:       add     x3, sp, #0x30
    0.00 :   ffff800010105368:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff80001010536c:       brk     #0x800
         : 100              return DMA_MAPPING_ERROR;
    0.00 :   ffff800010105370:       mov     x0, #0xffffffffffffffff         // #-1
    0.00 :   ffff800010105374:       ldr     x21, [sp, #32]
    0.00 :   ffff800010105378:       b       ffff8000101052ac <dma_map_page_attrs+0x144>
    0.00 :   ffff80001010537c:       str     x21, [sp, #32]
         : 105              dma_map_page_attrs():
         : 162              }
    0.00 :   ffff800010105380:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (67 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001078a280 <arm_lpae_unmap>:
         : 6                arm_lpae_unmap():
         : 624              return __arm_lpae_unmap(data, gather, iova, size, lvl + 1, ptep);
         : 625              }
         :
         : 627              static size_t arm_lpae_unmap(struct io_pgtable_ops *ops, unsigned long iova,
         : 628              size_t size, struct iommu_iotlb_gather *gather)
         : 629              {
   11.94 :   ffff80001078a280:       paciasp
    4.50 :   ffff80001078a284:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001078a288:       mov     x29, sp
         : 628              struct arm_lpae_io_pgtable *data = io_pgtable_ops_to_data(ops);
         : 629              struct io_pgtable_cfg *cfg = &data->iop.cfg;
         : 630              arm_lpae_iopte *ptep = data->pgd;
         : 631              long iaext = (s64)iova >> cfg->ias;
    0.00 :   ffff80001078a28c:       ldur    w4, [x0, #-56]
    1.51 :   ffff80001078a290:       asr     x4, x1, x4
         :
         : 631              if (WARN_ON(!size || (size & cfg->pgsize_bitmap) != size))
    0.00 :   ffff80001078a294:       cbnz    x2, ffff80001078a2ac <arm_lpae_unmap+0x2c>
    0.00 :   ffff80001078a298:       brk     #0x800
         : 631              return 0;
    0.00 :   ffff80001078a29c:       mov     x0, #0x0                        // #0
         : 639              iaext = ~iaext;
         : 640              if (WARN_ON(iaext))
         : 641              return 0;
         :
         : 643              return __arm_lpae_unmap(data, gather, iova, size, data->start_level, ptep);
         : 644              }
    0.00 :   ffff80001078a2a0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001078a2a4:       autiasp
    0.00 :   ffff80001078a2a8:       ret
         : 630              if (WARN_ON(!size || (size & cfg->pgsize_bitmap) != size))
   25.32 :   ffff80001078a2ac:       ldur    x5, [x0, #-64]
    0.00 :   ffff80001078a2b0:       and     x5, x2, x5
    0.00 :   ffff80001078a2b4:       cmp     x5, x2
    0.00 :   ffff80001078a2b8:       b.ne    ffff80001078a298 <arm_lpae_unmap+0x18>  // b.any
         : 633              if (cfg->quirks & IO_PGTABLE_QUIRK_ARM_TTBR1)
    8.96 :   ffff80001078a2bc:       sub     x7, x0, #0x58
    7.45 :   ffff80001078a2c0:       ldur    x0, [x0, #-72]
         : 634              iaext = ~iaext;
    0.00 :   ffff80001078a2c4:       tst     x0, #0x20
    0.00 :   ffff80001078a2c8:       cinv    x4, x4, ne  // ne = any
         : 635              if (WARN_ON(iaext))
    0.00 :   ffff80001078a2cc:       cbnz    x4, ffff80001078a2fc <arm_lpae_unmap+0x7c>
         : 638              return __arm_lpae_unmap(data, gather, iova, size, data->start_level, ptep);
    0.00 :   ffff80001078a2d0:       mov     x6, x3
   34.36 :   ffff80001078a2d4:       ldr     w4, [x7, #116]
    0.00 :   ffff80001078a2d8:       mov     x3, x5
    0.00 :   ffff80001078a2dc:       mov     x2, x1
    0.00 :   ffff80001078a2e0:       ldr     x5, [x7, #128]
    0.00 :   ffff80001078a2e4:       mov     x1, x6
    0.00 :   ffff80001078a2e8:       mov     x0, x7
    0.00 :   ffff80001078a2ec:       bl      ffff800010789d98 <__arm_lpae_unmap>
         : 639              }
    0.00 :   ffff80001078a2f0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001078a2f4:       autiasp
    5.96 :   ffff80001078a2f8:       ret
         : 635              if (WARN_ON(iaext))
    0.00 :   ffff80001078a2fc:       brk     #0x800
         : 636              return 0;
    0.00 :   ffff80001078a300:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001078a304:       b       ffff80001078a2a0 <arm_lpae_unmap+0x20>
 Percent |	Source code & Disassembly of vmlinux for cycles (58 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010782c20 <iommu_pgsize.isra.24>:
         : 6                __fls():
         : 13               *
         : 14               * Undefined if no set bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __fls(unsigned long word)
         : 17               {
         : 18               return (sizeof(word) * 8) - 1 - __builtin_clzl(word);
    5.17 :   ffff800010782c20:       clz     x3, x2
    0.00 :   ffff800010782c24:       mov     x2, #0x3f                       // #63
    0.00 :   ffff800010782c28:       sub     x2, x2, x3
         : 22               iommu_pgsize():
         : 2383             return domain->ops->iova_to_phys(domain, iova);
         : 2384             }
         : 2385             EXPORT_SYMBOL_GPL(iommu_iova_to_phys);
         :
         : 2387             static size_t iommu_pgsize(struct iommu_domain *domain,
         : 2388             unsigned long addr_merge, size_t size)
    0.00 :   ffff800010782c2c:       cbz     x1, ffff800010782c6c <iommu_pgsize.isra.24+0x4c>
         : 2390             __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    1.73 :   ffff800010782c30:       rbit    x1, x1
    0.00 :   ffff800010782c34:       clz     x1, x1
         : 21               iommu_pgsize():
         : 2386             {
         : 2387             unsigned int pgsize_idx;
         : 2388             size_t pgsize;
    0.00 :   ffff800010782c38:       cmp     w2, w1
    0.00 :   ffff800010782c3c:       csel    w3, w2, w1, ls  // ls = plast
         : 2393             /* Max page size that still fits into 'size' */
         : 2394             pgsize_idx = __fls(size);
         :
         : 2396             /* need to consider alignment requirements ? */
         : 2397             if (likely(addr_merge)) {
         : 2398             /* Max page size allowed by address */
    1.73 :   ffff800010782c40:       mov     x1, #0xffffffffffffffff         // #-1
         :
    0.00 :   ffff800010782c44:       add     w3, w3, #0x1
         : 2393             /* Max page size allowed by address */
    0.00 :   ffff800010782c48:       lsl     x1, x1, x3
         : 2396             unsigned int align_pgsize_idx = __ffs(addr_merge);
         : 2397             pgsize_idx = min(pgsize_idx, align_pgsize_idx);
         : 2398             }
    0.00 :   ffff800010782c4c:       bics    x1, x0, x1
   13.76 :   ffff800010782c50:       b.eq    ffff800010782c88 <iommu_pgsize.isra.24+0x68>  // b.none
         : 2401             __fls():
    3.46 :   ffff800010782c54:       clz     x1, x1
    0.00 :   ffff800010782c58:       mov     x0, #0x3f                       // #63
    0.00 :   ffff800010782c5c:       sub     x1, x0, x1
         : 16               iommu_pgsize():
         :
         : 2401             /* build a mask of acceptable page sizes */
         : 2402             pgsize = (1UL << (pgsize_idx + 1)) - 1;
         :
    0.00 :   ffff800010782c60:       mov     x0, #0x1                        // #1
         : 2403             /* throw away page sizes not supported by the hardware */
         : 2404             pgsize &= domain->pgsize_bitmap;
         :
   74.14 :   ffff800010782c64:       lsl     x0, x0, x1
    0.00 :   ffff800010782c68:       ret
    0.00 :   ffff800010782c6c:       mov     w3, w2
         : 2393             /* Max page size allowed by address */
    0.00 :   ffff800010782c70:       mov     x1, #0xffffffffffffffff         // #-1
         :
    0.00 :   ffff800010782c74:       add     w3, w3, #0x1
         : 2393             /* Max page size allowed by address */
    0.00 :   ffff800010782c78:       lsl     x1, x1, x3
         : 2396             }
    0.00 :   ffff800010782c7c:       bics    x1, x0, x1
    0.00 :   ffff800010782c80:       b.ne    ffff800010782c54 <iommu_pgsize.isra.24+0x34>  // b.any
    0.00 :   ffff800010782c84:       nop
    0.00 :   ffff800010782c88:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (57 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010780f30 <iommu_iova_to_phys>:
         : 6                iommu_iova_to_phys():
         : 2366             else
         : 2367             group->domain = group->default_domain;
         : 2368             }
         :
         : 2370             void iommu_detach_group(struct iommu_domain *domain, struct iommu_group *group)
         : 2371             {
    6.98 :   ffff800010780f30:       ldr     x2, [x0, #8]
   47.41 :   ffff800010780f34:       ldr     x2, [x2, #80]
    0.00 :   ffff800010780f38:       cbz     x2, ffff800010780f58 <iommu_iova_to_phys+0x28>
         : 2365             void iommu_detach_group(struct iommu_domain *domain, struct iommu_group *group)
   43.85 :   ffff800010780f3c:       paciasp
    1.77 :   ffff800010780f40:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010780f44:       mov     x29, sp
         : 2369             mutex_lock(&group->mutex);
         : 2370             __iommu_detach_group(domain, group);
         : 2371             mutex_unlock(&group->mutex);
    0.00 :   ffff800010780f48:       blr     x2
         : 2370             }
    0.00 :   ffff800010780f4c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010780f50:       autiasp
    0.00 :   ffff800010780f54:       ret
         : 2367             mutex_lock(&group->mutex);
    0.00 :   ffff800010780f58:       mov     x0, #0x0                        // #0
         : 2370             }
    0.00 :   ffff800010780f5c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (57 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010785fe8 <iommu_dma_alloc_iova.isra.23>:
         : 6                iommu_dma_alloc_iova():
         : 418              return 0;
         : 419              }
         : 420              }
         :
         : 422              static dma_addr_t iommu_dma_alloc_iova(struct iommu_domain *domain,
         : 423              size_t size, u64 dma_limit, struct device *dev)
    0.00 :   ffff800010785fe8:       ldr     x5, [x0, #64]
         : 419              {
    0.00 :   ffff800010785fec:       mov     x4, x5
         : 422              struct iommu_dma_cookie *cookie = domain->iova_cookie;
         : 423              struct iova_domain *iovad = &cookie->iovad;
         : 424              unsigned long shift, iova_len, iova = 0;
   14.03 :   ffff800010785ff0:       ldr     w6, [x4], #8
    0.00 :   ffff800010785ff4:       cmp     w6, #0x1
    0.00 :   ffff800010785ff8:       b.eq    ffff800010786090 <iommu_dma_alloc_iova.isra.23+0xa8>  // b.none
         : 415              }
    1.76 :   ffff800010785ffc:       paciasp
    8.79 :   ffff800010786000:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff800010786004:       mov     x29, sp
    0.00 :   ffff800010786008:       str     x19, [sp, #16]
         : 420              __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    3.50 :   ffff80001078600c:       ldr     x19, [x5, #40]
    0.00 :   ffff800010786010:       rbit    x19, x19
    0.00 :   ffff800010786014:       clz     x19, x19
         : 22               iommu_dma_alloc_iova():
         :
         : 429              if (cookie->type == IOMMU_DMA_MSI_COOKIE) {
         : 430              cookie->msi_iova += size;
         : 431              return cookie->msi_iova - size;
         : 432              }
         :
    0.00 :   ffff800010786018:       lsr     x1, x1, x19
         : 435              iova_len = size >> shift;
         : 436              /*
         : 437              * Freeing non-power-of-two-sized allocations back into the IOVA caches
         : 438              * will come back to bite us badly, so we have to waste a bit of space
         : 439              * rounding up anything cacheable to make sure that can't happen. The
         : 440              * order of the unadjusted size will still match upon freeing.
    0.00 :   ffff80001078601c:       cmp     x1, #0x1f
    0.00 :   ffff800010786020:       b.hi    ffff800010786044 <iommu_dma_alloc_iova.isra.23+0x5c>  // b.pmore
         : 443              __roundup_pow_of_two():
         : 57               * @n: value to round up
         : 58               */
         : 59               static inline __attribute__((const))
         : 60               unsigned long __roundup_pow_of_two(unsigned long n)
         : 61               {
         : 62               return 1UL << fls_long(n - 1);
    8.79 :   ffff800010786024:       subs    x1, x1, #0x1
         : 64               fls64():
         : 29               return fls(x);
         : 30               }
         : 31               #elif BITS_PER_LONG == 64
         : 32               static __always_inline int fls64(__u64 x)
         : 33               {
         : 34               if (x == 0)
    0.00 :   ffff800010786028:       mov     x5, #0x3f                       // #63
    0.00 :   ffff80001078602c:       clz     x6, x1
    0.00 :   ffff800010786030:       mov     x1, #0x1                        // #1
   40.38 :   ffff800010786034:       sub     x5, x5, x6
    0.00 :   ffff800010786038:       add     w5, w5, #0x1
    0.00 :   ffff80001078603c:       lsl     x5, x1, x5
    0.00 :   ffff800010786040:       csel    x1, x5, x1, ne  // ne = any
         : 42               iommu_dma_alloc_iova():
         : 438              */
         : 439              if (iova_len < (1 << (IOVA_RANGE_CACHE_MAX_SIZE - 1)))
         : 440              iova_len = roundup_pow_of_two(iova_len);
    0.00 :   ffff800010786044:       ldr     x3, [x3]
    0.00 :   ffff800010786048:       cbz     x2, ffff800010786058 <iommu_dma_alloc_iova.isra.23+0x70>
    0.00 :   ffff80001078604c:       cbz     x3, ffff8000107860a0 <iommu_dma_alloc_iova.isra.23+0xb8>
    0.00 :   ffff800010786050:       cmp     x3, x2
    0.00 :   ffff800010786054:       csel    x3, x3, x2, ls  // ls = plast
         :
         : 441              dma_limit = min_not_zero(dma_limit, dev->bus_dma_limit);
    0.00 :   ffff800010786058:       ldrb    w2, [x0, #56]
    0.00 :   ffff80001078605c:       cbz     w2, ffff80001078606c <iommu_dma_alloc_iova.isra.23+0x84>
         :
    3.48 :   ffff800010786060:       ldr     x0, [x0, #48]
    0.00 :   ffff800010786064:       cmp     x3, x0
    0.00 :   ffff800010786068:       csel    x3, x3, x0, ls  // ls = plast
         :
         : 450              /* Try to get PCI devices a SAC address */
         : 451              if (dma_limit > DMA_BIT_MASK(32) && !iommu_dma_forcedac && dev_is_pci(dev))
         : 452              iova = alloc_iova_fast(iovad, iova_len,
         : 453              DMA_BIT_MASK(32) >> shift, false);
         :
    0.00 :   ffff80001078606c:       lsr     x2, x3, x19
    0.00 :   ffff800010786070:       mov     x0, x4
    0.00 :   ffff800010786074:       mov     w3, #0x1                        // #1
    0.00 :   ffff800010786078:       bl      ffff80001078b588 <alloc_iova_fast>
         : 452              if (!iova)
         : 453              iova = alloc_iova_fast(iovad, iova_len, dma_limit >> shift,
         : 454              true);
    0.00 :   ffff80001078607c:       lsl     x0, x0, x19
         :
    0.00 :   ffff800010786080:       ldr     x19, [sp, #16]
    5.24 :   ffff800010786084:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010786088:       autiasp
    0.00 :   ffff80001078608c:       ret
         :
    0.00 :   ffff800010786090:       ldr     x0, [x5, #8]
    0.00 :   ffff800010786094:       add     x1, x0, x1
    0.00 :   ffff800010786098:       str     x1, [x5, #8]
         :
    0.00 :   ffff80001078609c:       ret
         : 438              iova_len = roundup_pow_of_two(iova_len);
    0.00 :   ffff8000107860a0:       mov     x3, x2
         : 440              dma_limit = min_not_zero(dma_limit, dev->bus_dma_limit);
   14.03 :   ffff8000107860a4:       ldrb    w2, [x0, #56]
    0.00 :   ffff8000107860a8:       cbz     w2, ffff80001078606c <iommu_dma_alloc_iova.isra.23+0x84>
    0.00 :   ffff8000107860ac:       b       ffff800010786060 <iommu_dma_alloc_iova.isra.23+0x78>
 Percent |	Source code & Disassembly of vmlinux for cycles (53 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104a4e40 <__arch_copy_from_user>:
         : 6                __arch_copy_from_user():
         : 57               stp \reg1, \reg2, [\ptr], \val
         : 58               .endm
         :
         : 60               end     .req    x5
         : 61               SYM_FUNC_START(__arch_copy_from_user)
         : 62               add     end, x0, x2
    0.00 :   ffff8000104a4e40:       add     x5, x0, x2
         : 42               C_l     .req    x11
         : 43               C_h     .req    x12
         : 44               D_l     .req    x13
         : 45               D_h     .req    x14
         :
         : 47               mov     dst, dstin
    0.00 :   ffff8000104a4e44:       mov     x6, x0
         : 43               cmp     count, #16
    0.00 :   ffff8000104a4e48:       cmp     x2, #0x10
         : 45               /*When memory length is less than 16, the accessed are not aligned.*/
         : 46               b.lo    .Ltiny15
    0.00 :   ffff8000104a4e4c:       b.cc    ffff8000104a4eec <__arch_copy_from_user+0xac>  // b.lo, b.ul, b.last
         :
         : 48               neg     tmp2, src
    0.00 :   ffff8000104a4e50:       neg     x4, x1
         : 48               ands    tmp2, tmp2, #15/* Bytes to reach alignment. */
    0.00 :   ffff8000104a4e54:       ands    x4, x4, #0xf
         : 49               b.eq    .LSrcAligned
    0.00 :   ffff8000104a4e58:       b.eq    ffff8000104a4ea0 <__arch_copy_from_user+0x60>  // b.none
         : 50               sub     count, count, tmp2
    0.00 :   ffff8000104a4e5c:       sub     x2, x2, x4
         : 57               * Copy the leading memory data from src to dst in an increasing
         : 58               * address order.By this way,the risk of overwriting the source
         : 59               * memory data is eliminated when the distance between src and
         : 60               * dst is less than 16. The memory accesses here are alignment.
         : 61               */
         : 62               tbz     tmp2, #0, 1f
    0.00 :   ffff8000104a4e60:       tbz     w4, #0, ffff8000104a4e70 <__arch_copy_from_user+0x30>
         : 58               ldrb1   tmp1w, src, #1
    0.00 :   ffff8000104a4e64:       ldtrb   w3, [x1]
    0.00 :   ffff8000104a4e68:       add     x1, x1, #0x1
         : 59               strb1   tmp1w, dst, #1
    0.00 :   ffff8000104a4e6c:       strb    w3, [x6], #1
         : 61               1:
         : 62               tbz     tmp2, #1, 2f
    0.00 :   ffff8000104a4e70:       tbz     w4, #1, ffff8000104a4e80 <__arch_copy_from_user+0x40>
         : 62               ldrh1   tmp1w, src, #2
    0.00 :   ffff8000104a4e74:       ldtrh   w3, [x1]
    0.00 :   ffff8000104a4e78:       add     x1, x1, #0x2
         : 63               strh1   tmp1w, dst, #2
    0.00 :   ffff8000104a4e7c:       strh    w3, [x6], #2
         : 65               2:
         : 66               tbz     tmp2, #2, 3f
    0.00 :   ffff8000104a4e80:       tbz     w4, #2, ffff8000104a4e90 <__arch_copy_from_user+0x50>
         : 66               ldr1    tmp1w, src, #4
    0.00 :   ffff8000104a4e84:       ldtr    w3, [x1]
    0.00 :   ffff8000104a4e88:       add     x1, x1, #0x4
         : 67               str1    tmp1w, dst, #4
    0.00 :   ffff8000104a4e8c:       str     w3, [x6], #4
         : 69               3:
         : 70               tbz     tmp2, #3, .LSrcAligned
    0.00 :   ffff8000104a4e90:       tbz     w4, #3, ffff8000104a4ea0 <__arch_copy_from_user+0x60>
         : 70               ldr1    tmp1, src, #8
    0.00 :   ffff8000104a4e94:       ldtr    x3, [x1]
    0.00 :   ffff8000104a4e98:       add     x1, x1, #0x8
         : 71               str1    tmp1, dst, #8
    0.00 :   ffff8000104a4e9c:       str     x3, [x6], #8
         :
         : 75               .LSrcAligned:
         : 76               cmp     count, #64
    0.00 :   ffff8000104a4ea0:       cmp     x2, #0x40
         : 75               b.ge    .Lcpy_over64
    0.00 :   ffff8000104a4ea4:       b.ge    ffff8000104a4f30 <__arch_copy_from_user+0xf0>  // b.tcont
         : 85               .Ltail63:
         : 86               /*
         : 87               * Copy up to 48 bytes of data. At this point we only need the
         : 88               * bottom 6 bits of count to be accurate.
         : 89               */
         : 90               ands    tmp1, count, #0x30
    0.00 :   ffff8000104a4ea8:       ands    x3, x2, #0x30
         : 86               b.eq    .Ltiny15
    0.00 :   ffff8000104a4eac:       b.eq    ffff8000104a4eec <__arch_copy_from_user+0xac>  // b.none
         : 87               cmp     tmp1w, #0x20
    0.00 :   ffff8000104a4eb0:       cmp     w3, #0x20
         : 88               b.eq    1f
    0.00 :   ffff8000104a4eb4:       b.eq    ffff8000104a4ecc <__arch_copy_from_user+0x8c>  // b.none
         : 89               b.lt    2f
    0.00 :   ffff8000104a4eb8:       b.lt    ffff8000104a4edc <__arch_copy_from_user+0x9c>  // b.tstop
         : 90               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a4ebc:       ldtr    x7, [x1]
    0.00 :   ffff8000104a4ec0:       ldtr    x8, [x1, #8]
    0.00 :   ffff8000104a4ec4:       add     x1, x1, #0x10
         : 91               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a4ec8:       stp     x7, x8, [x6], #16
         : 93               1:
         : 94               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a4ecc:       ldtr    x7, [x1]
    0.00 :   ffff8000104a4ed0:       ldtr    x8, [x1, #8]
    0.00 :   ffff8000104a4ed4:       add     x1, x1, #0x10
         : 94               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a4ed8:       stp     x7, x8, [x6], #16
         : 96               2:
         : 97               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a4edc:       ldtr    x7, [x1]
    0.00 :   ffff8000104a4ee0:       ldtr    x8, [x1, #8]
    0.00 :   ffff8000104a4ee4:       add     x1, x1, #0x10
         : 97               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a4ee8:       stp     x7, x8, [x6], #16
         : 110              * precondition that src address is at least 16 bytes bigger than dst
         : 111              * address,otherwise some source data will be overwritten when memove
         : 112              * call memcpy directly. To make memmove simpler and decouple the
         : 113              * memcpy's dependency on memmove, withdrew the original process.
         : 114              */
         : 115              tbz     count, #3, 1f
    0.00 :   ffff8000104a4eec:       tbz     w2, #3, ffff8000104a4efc <__arch_copy_from_user+0xbc>
         : 111              ldr1    tmp1, src, #8
    0.00 :   ffff8000104a4ef0:       ldtr    x3, [x1]
    0.00 :   ffff8000104a4ef4:       add     x1, x1, #0x8
         : 112              str1    tmp1, dst, #8
    0.00 :   ffff8000104a4ef8:       str     x3, [x6], #8
         : 114              1:
         : 115              tbz     count, #2, 2f
    0.00 :   ffff8000104a4efc:       tbz     w2, #2, ffff8000104a4f0c <__arch_copy_from_user+0xcc>
         : 115              ldr1    tmp1w, src, #4
    0.00 :   ffff8000104a4f00:       ldtr    w3, [x1]
    0.00 :   ffff8000104a4f04:       add     x1, x1, #0x4
         : 116              str1    tmp1w, dst, #4
    0.00 :   ffff8000104a4f08:       str     w3, [x6], #4
         : 118              2:
         : 119              tbz     count, #1, 3f
    0.00 :   ffff8000104a4f0c:       tbz     w2, #1, ffff8000104a4f1c <__arch_copy_from_user+0xdc>
         : 119              ldrh1   tmp1w, src, #2
    0.00 :   ffff8000104a4f10:       ldtrh   w3, [x1]
    0.00 :   ffff8000104a4f14:       add     x1, x1, #0x2
         : 120              strh1   tmp1w, dst, #2
    0.00 :   ffff8000104a4f18:       strh    w3, [x6], #2
         : 122              3:
         : 123              tbz     count, #0, .Lexitfunc
    0.00 :   ffff8000104a4f1c:       tbz     w2, #0, ffff8000104a5050 <__arch_copy_from_user+0x210>
         : 123              ldrb1   tmp1w, src, #1
    0.00 :   ffff8000104a4f20:       ldtrb   w3, [x1]
    0.00 :   ffff8000104a4f24:       add     x1, x1, #0x1
         : 124              strb1   tmp1w, dst, #1
    0.00 :   ffff8000104a4f28:       strb    w3, [x6], #1
         :
         : 127              b       .Lexitfunc
    0.00 :   ffff8000104a4f2c:       b       ffff8000104a5050 <__arch_copy_from_user+0x210>
         :
         : 130              .Lcpy_over64:
         : 131              subs    count, count, #128
    3.93 :   ffff8000104a4f30:       subs    x2, x2, #0x80
         : 130              b.ge    .Lcpy_body_large
    0.00 :   ffff8000104a4f34:       b.ge    ffff8000104a4fc0 <__arch_copy_from_user+0x180>  // b.tcont
         : 135              /*
         : 136              * Less than 128 bytes to copy, so handle 64 here and then jump
         : 137              * to the tail.
         : 138              */
         : 139              ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a4f38:       ldtr    x7, [x1]
    0.00 :   ffff8000104a4f3c:       ldtr    x8, [x1, #8]
    0.00 :   ffff8000104a4f40:       add     x1, x1, #0x10
         : 136              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a4f44:       stp     x7, x8, [x6], #16
         : 137              ldp1    B_l, B_h, src, #16
    0.00 :   ffff8000104a4f48:       ldtr    x9, [x1]
    0.00 :   ffff8000104a4f4c:       ldtr    x10, [x1, #8]
    0.00 :   ffff8000104a4f50:       add     x1, x1, #0x10
         : 138              ldp1    C_l, C_h, src, #16
    0.00 :   ffff8000104a4f54:       ldtr    x11, [x1]
    0.00 :   ffff8000104a4f58:       ldtr    x12, [x1, #8]
    0.00 :   ffff8000104a4f5c:       add     x1, x1, #0x10
         : 139              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a4f60:       stp     x9, x10, [x6], #16
         : 140              stp1    C_l, C_h, dst, #16
    0.00 :   ffff8000104a4f64:       stp     x11, x12, [x6], #16
         : 141              ldp1    D_l, D_h, src, #16
    0.00 :   ffff8000104a4f68:       ldtr    x13, [x1]
    0.00 :   ffff8000104a4f6c:       ldtr    x14, [x1, #8]
    0.00 :   ffff8000104a4f70:       add     x1, x1, #0x10
         : 142              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a4f74:       stp     x13, x14, [x6], #16
         :
         : 145              tst     count, #0x3f
    0.00 :   ffff8000104a4f78:       tst     x2, #0x3f
         : 145              b.ne    .Ltail63
    0.00 :   ffff8000104a4f7c:       b.ne    ffff8000104a4ea8 <__arch_copy_from_user+0x68>  // b.any
         : 146              b       .Lexitfunc
    0.00 :   ffff8000104a4f80:       b       ffff8000104a5050 <__arch_copy_from_user+0x210>
    0.00 :   ffff8000104a4f84:       nop
    0.00 :   ffff8000104a4f88:       nop
    0.00 :   ffff8000104a4f8c:       nop
    0.00 :   ffff8000104a4f90:       nop
    0.00 :   ffff8000104a4f94:       nop
    0.00 :   ffff8000104a4f98:       nop
    0.00 :   ffff8000104a4f9c:       nop
    0.00 :   ffff8000104a4fa0:       nop
    0.00 :   ffff8000104a4fa4:       nop
    0.00 :   ffff8000104a4fa8:       nop
    0.00 :   ffff8000104a4fac:       nop
    0.00 :   ffff8000104a4fb0:       nop
    0.00 :   ffff8000104a4fb4:       nop
    0.00 :   ffff8000104a4fb8:       nop
    0.00 :   ffff8000104a4fbc:       nop
         : 155              * 64 bytes per line this ensures the entire loop is in one line.
         : 156              */
         : 157              .p2align        L1_CACHE_SHIFT
         : 158              .Lcpy_body_large:
         : 159              /* pre-get 64 bytes data. */
         : 160              ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a4fc0:       ldtr    x7, [x1]
    1.94 :   ffff8000104a4fc4:       ldtr    x8, [x1, #8]
    0.00 :   ffff8000104a4fc8:       add     x1, x1, #0x10
         : 156              ldp1    B_l, B_h, src, #16
    0.00 :   ffff8000104a4fcc:       ldtr    x9, [x1]
    1.72 :   ffff8000104a4fd0:       ldtr    x10, [x1, #8]
    0.00 :   ffff8000104a4fd4:       add     x1, x1, #0x10
         : 157              ldp1    C_l, C_h, src, #16
    0.00 :   ffff8000104a4fd8:       ldtr    x11, [x1]
    0.00 :   ffff8000104a4fdc:       ldtr    x12, [x1, #8]
    0.00 :   ffff8000104a4fe0:       add     x1, x1, #0x10
         : 158              ldp1    D_l, D_h, src, #16
    0.00 :   ffff8000104a4fe4:       ldtr    x13, [x1]
    0.00 :   ffff8000104a4fe8:       ldtr    x14, [x1, #8]
    0.00 :   ffff8000104a4fec:       add     x1, x1, #0x10
         : 164              1:
         : 165              /*
         : 166              * interlace the load of next 64 bytes data block with store of the last
         : 167              * loaded 64 bytes data.
         : 168              */
         : 169              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a4ff0:       stp     x7, x8, [x6], #16
         : 165              ldp1    A_l, A_h, src, #16
   21.00 :   ffff8000104a4ff4:       ldtr    x7, [x1]
   10.86 :   ffff8000104a4ff8:       ldtr    x8, [x1, #8]
    0.00 :   ffff8000104a4ffc:       add     x1, x1, #0x10
         : 166              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a5000:       stp     x9, x10, [x6], #16
         : 167              ldp1    B_l, B_h, src, #16
    3.66 :   ffff8000104a5004:       ldtr    x9, [x1]
   13.52 :   ffff8000104a5008:       ldtr    x10, [x1, #8]
    0.00 :   ffff8000104a500c:       add     x1, x1, #0x10
         : 168              stp1    C_l, C_h, dst, #16
    1.80 :   ffff8000104a5010:       stp     x11, x12, [x6], #16
         : 169              ldp1    C_l, C_h, src, #16
    2.01 :   ffff8000104a5014:       ldtr    x11, [x1]
    7.32 :   ffff8000104a5018:       ldtr    x12, [x1, #8]
    0.00 :   ffff8000104a501c:       add     x1, x1, #0x10
         : 170              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a5020:       stp     x13, x14, [x6], #16
         : 171              ldp1    D_l, D_h, src, #16
   18.90 :   ffff8000104a5024:       ldtr    x13, [x1]
   13.34 :   ffff8000104a5028:       ldtr    x14, [x1, #8]
    0.00 :   ffff8000104a502c:       add     x1, x1, #0x10
         : 172              subs    count, count, #64
    0.00 :   ffff8000104a5030:       subs    x2, x2, #0x40
         : 173              b.ge    1b
    0.00 :   ffff8000104a5034:       b.ge    ffff8000104a4ff0 <__arch_copy_from_user+0x1b0>  // b.tcont
         : 174              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5038:       stp     x7, x8, [x6], #16
         : 175              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a503c:       stp     x9, x10, [x6], #16
         : 176              stp1    C_l, C_h, dst, #16
    0.00 :   ffff8000104a5040:       stp     x11, x12, [x6], #16
         : 177              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a5044:       stp     x13, x14, [x6], #16
         :
         : 180              tst     count, #0x3f
    0.00 :   ffff8000104a5048:       tst     x2, #0x3f
         : 180              b.ne    .Ltail63
    0.00 :   ffff8000104a504c:       b.ne    ffff8000104a4ea8 <__arch_copy_from_user+0x68>  // b.any
         : 59               #include "copy_template.S"
         : 60               mov     x0, #0                          // Nothing to copy
    0.00 :   ffff8000104a5050:       mov     x0, #0x0                        // #0
         : 60               ret
    0.00 :   ffff8000104a5054:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (50 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077bd60 <queue_poll>:
         : 6                queue_poll():
         : 206              qp->delay *= 2;
         : 207              qp->spin_cnt = 0;
         : 208              }
         :
         : 210              return 0;
         : 211              }
    8.03 :   ffff80001077bd60:       paciasp
   45.99 :   ffff80001077bd64:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff80001077bd68:       mov     x29, sp
   10.01 :   ffff80001077bd6c:       str     x19, [sp, #16]
    0.00 :   ffff80001077bd70:       mov     x19, x0
         :
    0.00 :   ffff80001077bd74:       bl      ffff800010110e30 <ktime_get>
         : 209              ktime_compare():
         : 99               */
         : 100              static inline int ktime_compare(const ktime_t cmp1, const ktime_t cmp2)
         : 101              {
         : 102              if (cmp1 < cmp2)
         : 103              return -1;
         : 104              if (cmp1 > cmp2)
    0.00 :   ffff80001077bd78:       ldr     x1, [x19]
    0.00 :   ffff80001077bd7c:       cmp     x0, x1
    0.00 :   ffff80001077bd80:       b.gt    ffff80001077bdd0 <queue_poll+0x70>
         : 108              queue_poll():
         : 210              static void queue_write(__le64 *dst, u64 *src, size_t n_dwords)
         : 211              {
         : 212              int i;
    0.00 :   ffff80001077bd84:       ldrb    w0, [x19, #16]
    0.00 :   ffff80001077bd88:       cbz     w0, ffff80001077bda4 <queue_poll+0x44>
         :
    0.00 :   ffff80001077bd8c:       wfe
         :
         : 221              static void queue_read(u64 *dst, __le64 *src, size_t n_dwords)
         : 222              {
         : 223              int i;
         :
         : 225              for (i = 0; i < n_dwords; ++i)
    0.00 :   ffff80001077bd90:       mov     w0, #0x0                        // #0
         : 221              *dst++ = le64_to_cpu(*src++);
    0.00 :   ffff80001077bd94:       ldr     x19, [sp, #16]
    0.00 :   ffff80001077bd98:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001077bd9c:       autiasp
    0.00 :   ffff80001077bda0:       ret
         : 212              for (i = 0; i < n_dwords; ++i)
   21.96 :   ffff80001077bda4:       ldr     w0, [x19, #12]
    0.00 :   ffff80001077bda8:       add     w0, w0, #0x1
    0.00 :   ffff80001077bdac:       str     w0, [x19, #12]
    0.00 :   ffff80001077bdb0:       cmp     w0, #0x9
    0.00 :   ffff80001077bdb4:       b.hi    ffff80001077bde4 <queue_poll+0x84>  // b.pmore
         : 218              cpu_relax():
         :
         : 13               #ifndef __ASSEMBLY__
         :
         : 15               static inline void cpu_relax(void)
         : 16               {
         : 17               asm volatile("yield" ::: "memory");
    0.00 :   ffff80001077bdb8:       yield
         : 19               queue_poll():
         : 220              for (i = 0; i < n_dwords; ++i)
    0.00 :   ffff80001077bdbc:       mov     w0, #0x0                        // #0
         : 221              *dst++ = le64_to_cpu(*src++);
   14.01 :   ffff80001077bdc0:       ldr     x19, [sp, #16]
    0.00 :   ffff80001077bdc4:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001077bdc8:       autiasp
    0.00 :   ffff80001077bdcc:       ret
         : 208              static void queue_write(__le64 *dst, u64 *src, size_t n_dwords)
    0.00 :   ffff80001077bdd0:       mov     w0, #0xffffff92                 // #-110
         : 221              *dst++ = le64_to_cpu(*src++);
    0.00 :   ffff80001077bdd4:       ldr     x19, [sp, #16]
    0.00 :   ffff80001077bdd8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001077bddc:       autiasp
    0.00 :   ffff80001077bde0:       ret
         :
    0.00 :   ffff80001077bde4:       ldr     w0, [x19, #8]
    0.00 :   ffff80001077bde8:       bl      ffff8000104a58c0 <__udelay>
         : 216              static void queue_read(u64 *dst, __le64 *src, size_t n_dwords)
    0.00 :   ffff80001077bdec:       ldr     w1, [x19, #8]
         : 217              {
    0.00 :   ffff80001077bdf0:       mov     w0, #0x0                        // #0
         : 216              static void queue_read(u64 *dst, __le64 *src, size_t n_dwords)
    0.00 :   ffff80001077bdf4:       lsl     w1, w1, #1
         : 217              {
    0.00 :   ffff80001077bdf8:       stp     w1, wzr, [x19, #8]
         : 221              *dst++ = le64_to_cpu(*src++);
    0.00 :   ffff80001077bdfc:       ldr     x19, [sp, #16]
    0.00 :   ffff80001077be00:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001077be04:       autiasp
    0.00 :   ffff80001077be08:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (42 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010784d10 <iommu_get_dma_domain>:
         : 6                iommu_get_dma_domain():
         : 2275             domain = group->domain;
         :
         : 2277             iommu_group_put(group);
         :
         : 2279             return domain;
         : 2280             }
   52.39 :   ffff800010784d10:       ldr     x0, [x0, #720]
         : 2274             return domain;
    4.70 :   ffff800010784d14:       paciasp
         : 2276             EXPORT_SYMBOL_GPL(iommu_get_domain_for_dev);
   40.53 :   ffff800010784d18:       autiasp
    2.37 :   ffff800010784d1c:       ldr     x0, [x0, #200]
    0.00 :   ffff800010784d20:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (37 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010785ad0 <iommu_dma_unmap_page>:
         : 6                iommu_dma_unmap_page():
         : 862              dma_handle != DMA_MAPPING_ERROR)
         : 863              arch_sync_dma_for_device(phys, size, dir);
         : 864              return dma_handle;
         : 865              }
         :
         : 867              static void iommu_dma_unmap_page(struct device *dev, dma_addr_t dma_handle,
    0.00 :   ffff800010785ad0:       paciasp
    0.00 :   ffff800010785ad4:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010785ad8:       mov     x29, sp
    0.00 :   ffff800010785adc:       stp     x19, x20, [sp, #16]
   10.77 :   ffff800010785ae0:       mov     x19, x0
    0.00 :   ffff800010785ae4:       mov     x20, x1
    0.00 :   ffff800010785ae8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010785aec:       mov     x21, x2
    0.00 :   ffff800010785af0:       mov     w22, w3
         : 863              size_t size, enum dma_data_direction dir, unsigned long attrs)
    0.00 :   ffff800010785af4:       tbz     w4, #5, ffff800010785b20 <iommu_dma_unmap_page+0x50>
         : 865              {
         : 866              if (!(attrs & DMA_ATTR_SKIP_CPU_SYNC))
   21.57 :   ffff800010785af8:       mov     w3, w22
    0.00 :   ffff800010785afc:       mov     x2, x21
    0.00 :   ffff800010785b00:       mov     x1, x20
    0.00 :   ffff800010785b04:       mov     x0, x19
    0.00 :   ffff800010785b08:       bl      ffff800010785a20 <__iommu_dma_unmap_swiotlb>
         : 866              iommu_dma_sync_single_for_cpu(dev, dma_handle, size, dir);
   27.03 :   ffff800010785b0c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010785b10:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010785b14:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010785b18:       autiasp
    0.00 :   ffff800010785b1c:       ret
    2.69 :   ffff800010785b20:       str     x4, [sp, #56]
         : 864              {
    0.00 :   ffff800010785b24:       bl      ffff8000107857c0 <iommu_dma_sync_single_for_cpu>
   37.94 :   ffff800010785b28:       ldr     x4, [sp, #56]
    0.00 :   ffff800010785b2c:       b       ffff800010785af8 <iommu_dma_unmap_page+0x28>
 Percent |	Source code & Disassembly of vmlinux for cycles (34 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010105e70 <dma_unmap_page_attrs>:
         : 6                dma_unmap_page_attrs():
         : 167              }
         : 168              EXPORT_SYMBOL(dma_map_page_attrs);
         :
         : 170              void dma_unmap_page_attrs(struct device *dev, dma_addr_t addr, size_t size,
         : 171              enum dma_data_direction dir, unsigned long attrs)
         : 172              {
    0.00 :   ffff800010105e70:       paciasp
    2.94 :   ffff800010105e74:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff800010105e78:       mov     x29, sp
   20.62 :   ffff800010105e7c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010105e80:       mov     w21, w3
         : 168              const struct dma_map_ops *ops = get_dma_ops(dev);
    2.96 :   ffff800010105e84:       ldr     x5, [x0, #568]
         : 170              get_dma_ops():
         : 79               #ifdef CONFIG_DMA_OPS
         : 80               #include <asm/dma-mapping.h>
         :
         : 82               static inline const struct dma_map_ops *get_dma_ops(struct device *dev)
         : 83               {
         : 84               if (dev->dma_ops)
    0.00 :   ffff800010105e88:       cbz     x5, ffff800010105eb0 <dma_unmap_page_attrs+0x40>
         : 86               dma_unmap_page_attrs():
         :
         : 171              BUG_ON(!valid_dma_direction(dir));
    2.92 :   ffff800010105e8c:       cmp     w3, #0x2
    0.00 :   ffff800010105e90:       b.hi    ffff800010106020 <dma_unmap_page_attrs+0x1b0>  // b.pmore
         : 174              if (dma_map_direct(dev, ops) ||
         : 175              arch_dma_unmap_page_direct(dev, addr + size))
         : 176              dma_direct_unmap_page(dev, addr, size, dir, attrs);
         : 177              else if (ops->unmap_page)
    2.95 :   ffff800010105e94:       ldr     x5, [x5, #72]
    0.00 :   ffff800010105e98:       cbz     x5, ffff800010105ea0 <dma_unmap_page_attrs+0x30>
         : 175              ops->unmap_page(dev, addr, size, dir, attrs);
   29.41 :   ffff800010105e9c:       blr     x5
         : 177              debug_dma_unmap_page(dev, addr, size, dir);
         : 178              }
   35.28 :   ffff800010105ea0:       ldp     x21, x22, [sp, #32]
    2.92 :   ffff800010105ea4:       ldp     x29, x30, [sp], #80
    0.00 :   ffff800010105ea8:       autiasp
    0.00 :   ffff800010105eac:       ret
    0.00 :   ffff800010105eb0:       stp     x19, x20, [sp, #16]
         : 170              BUG_ON(!valid_dma_direction(dir));
    0.00 :   ffff800010105eb4:       cmp     w3, #0x2
    0.00 :   ffff800010105eb8:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010105ebc:       str     x25, [sp, #64]
    0.00 :   ffff800010105ec0:       b.hi    ffff80001010602c <dma_unmap_page_attrs+0x1bc>  // b.pmore
         : 175              dma_direct_unmap_page():
         : 111              }
         :
         : 113              static inline void dma_direct_unmap_page(struct device *dev, dma_addr_t addr,
         : 114              size_t size, enum dma_data_direction dir, unsigned long attrs)
         : 115              {
         : 116              phys_addr_t phys = dma_to_phys(dev, addr);
    0.00 :   ffff800010105ec4:       mov     x20, x0
    0.00 :   ffff800010105ec8:       mov     x19, x1
    0.00 :   ffff800010105ecc:       ldr     x0, [x0, #600]
         : 120              dma_to_phys():
         :
         : 82               static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dma_addr)
         : 83               {
         : 84               phys_addr_t paddr;
         :
         : 86               if (dev->dma_range_map)
    0.00 :   ffff800010105ed0:       mov     x25, x2
    0.00 :   ffff800010105ed4:       mov     x23, x4
    0.00 :   ffff800010105ed8:       and     x5, x4, #0x20
    0.00 :   ffff800010105edc:       cbz     x0, ffff800010105ff0 <dma_unmap_page_attrs+0x180>
         : 91               translate_dma_to_phys():
         : 45               for (m = dev->dma_range_map; m->size; m++)
    0.00 :   ffff800010105ee0:       ldr     x3, [x0, #16]
    0.00 :   ffff800010105ee4:       cbz     x3, ffff80001010603c <dma_unmap_page_attrs+0x1cc>
    0.00 :   ffff800010105ee8:       mov     x4, x3
    0.00 :   ffff800010105eec:       mov     x2, x0
         : 46               if (dma_addr >= m->dma_start && dma_addr - m->dma_start < m->size)
    0.00 :   ffff800010105ef0:       ldr     x1, [x2, #8]
    0.00 :   ffff800010105ef4:       cmp     x19, x1
    0.00 :   ffff800010105ef8:       b.cc    ffff800010105f08 <dma_unmap_page_attrs+0x98>  // b.lo, b.ul, b.last
    0.00 :   ffff800010105efc:       sub     x1, x19, x1
    0.00 :   ffff800010105f00:       cmp     x1, x4
    0.00 :   ffff800010105f04:       b.cc    ffff800010106010 <dma_unmap_page_attrs+0x1a0>  // b.lo, b.ul, b.last
         : 45               for (m = dev->dma_range_map; m->size; m++)
    0.00 :   ffff800010105f08:       add     x2, x2, #0x20
    0.00 :   ffff800010105f0c:       ldr     x4, [x2, #16]
    0.00 :   ffff800010105f10:       cbnz    x4, ffff800010105ef0 <dma_unmap_page_attrs+0x80>
         : 49               return (phys_addr_t)-1;
    0.00 :   ffff800010105f14:       mov     x22, #0xffffffffffffffff        // #-1
         : 51               dma_direct_unmap_page():
         :
         : 114              if (!(attrs & DMA_ATTR_SKIP_CPU_SYNC))
    0.00 :   ffff800010105f18:       cbz     x5, ffff800010105f68 <dma_unmap_page_attrs+0xf8>
    0.00 :   ffff800010105f1c:       adrp    x24, ffff800011f4c000 <__log_buf+0x1fb98>
         : 117              is_swiotlb_buffer():
         : 106              };
         : 107              extern struct io_tlb_mem *io_tlb_default_mem;
         :
         : 109              static inline bool is_swiotlb_buffer(phys_addr_t paddr)
         : 110              {
         : 111              struct io_tlb_mem *mem = io_tlb_default_mem;
    0.00 :   ffff800010105f20:       ldr     x0, [x24, #3624]
         :
         : 109              return mem && paddr >= mem->start && paddr < mem->end;
    0.00 :   ffff800010105f24:       cbz     x0, ffff800010105fd4 <dma_unmap_page_attrs+0x164>
    0.00 :   ffff800010105f28:       ldr     x1, [x0]
    0.00 :   ffff800010105f2c:       cmp     x22, x1
    0.00 :   ffff800010105f30:       b.cc    ffff800010105fd4 <dma_unmap_page_attrs+0x164>  // b.lo, b.ul, b.last
    0.00 :   ffff800010105f34:       ldr     x0, [x0, #8]
    0.00 :   ffff800010105f38:       cmp     x0, x22
    0.00 :   ffff800010105f3c:       b.ls    ffff800010105fd4 <dma_unmap_page_attrs+0x164>  // b.plast
         : 117              dma_direct_unmap_page():
         : 117              dma_direct_sync_single_for_cpu(dev, addr, size, dir);
         :
         : 119              if (unlikely(is_swiotlb_buffer(phys)))
         : 120              swiotlb_tbl_unmap_single(dev, phys, size, dir, attrs);
    0.00 :   ffff800010105f40:       mov     x4, x23
    0.00 :   ffff800010105f44:       mov     x2, x25
    0.00 :   ffff800010105f48:       mov     x0, x20
    0.00 :   ffff800010105f4c:       mov     w3, w21
    0.00 :   ffff800010105f50:       mov     x1, x22
    0.00 :   ffff800010105f54:       bl      ffff800010108fd8 <swiotlb_tbl_unmap_single>
    0.00 :   ffff800010105f58:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010105f5c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010105f60:       ldr     x25, [sp, #64]
    0.00 :   ffff800010105f64:       b       ffff800010105ea0 <dma_unmap_page_attrs+0x30>
         : 131              translate_dma_to_phys():
         : 46               if (dma_addr >= m->dma_start && dma_addr - m->dma_start < m->size)
    0.00 :   ffff800010105f68:       ldr     x1, [x0, #8]
    0.00 :   ffff800010105f6c:       cmp     x19, x1
    0.00 :   ffff800010105f70:       b.cc    ffff800010105f80 <dma_unmap_page_attrs+0x110>  // b.lo, b.ul, b.last
    0.00 :   ffff800010105f74:       sub     x1, x19, x1
    0.00 :   ffff800010105f78:       cmp     x1, x3
    0.00 :   ffff800010105f7c:       b.cc    ffff800010106030 <dma_unmap_page_attrs+0x1c0>  // b.lo, b.ul, b.last
         : 45               for (m = dev->dma_range_map; m->size; m++)
    0.00 :   ffff800010105f80:       add     x0, x0, #0x20
    0.00 :   ffff800010105f84:       ldr     x3, [x0, #16]
    0.00 :   ffff800010105f88:       cbnz    x3, ffff800010105f68 <dma_unmap_page_attrs+0xf8>
         : 49               return (phys_addr_t)-1;
    0.00 :   ffff800010105f8c:       mov     x19, #0xffffffffffffffff        // #-1
         : 51               dev_is_dma_coherent():
         : 252              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
         : 253              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
         : 254              extern bool dma_default_coherent;
         : 255              static inline bool dev_is_dma_coherent(struct device *dev)
         : 256              {
         : 257              return dev->dma_coherent;
    0.00 :   ffff800010105f90:       ldrb    w0, [x20, #736]
         : 259              dma_direct_sync_single_for_cpu():
         : 71               if (!dev_is_dma_coherent(dev)) {
    0.00 :   ffff800010105f94:       tbz     w0, #5, ffff800010105ffc <dma_unmap_page_attrs+0x18c>
         : 73               is_swiotlb_buffer():
         : 106              struct io_tlb_mem *mem = io_tlb_default_mem;
    0.00 :   ffff800010105f98:       adrp    x24, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010105f9c:       ldr     x0, [x24, #3624]
         : 108              return mem && paddr >= mem->start && paddr < mem->end;
    0.00 :   ffff800010105fa0:       cbz     x0, ffff800010105fd4 <dma_unmap_page_attrs+0x164>
    0.00 :   ffff800010105fa4:       ldr     x1, [x0]
    0.00 :   ffff800010105fa8:       cmp     x19, x1
    0.00 :   ffff800010105fac:       b.cc    ffff800010105f2c <dma_unmap_page_attrs+0xbc>  // b.lo, b.ul, b.last
    0.00 :   ffff800010105fb0:       ldr     x2, [x0, #8]
    0.00 :   ffff800010105fb4:       cmp     x19, x2
    0.00 :   ffff800010105fb8:       b.cs    ffff800010105f2c <dma_unmap_page_attrs+0xbc>  // b.hs, b.nlast
         : 116              dma_direct_sync_single_for_cpu():
         : 77               swiotlb_sync_single_for_cpu(dev, paddr, size, dir);
    0.00 :   ffff800010105fbc:       mov     x1, x19
    0.00 :   ffff800010105fc0:       mov     w3, w21
    0.00 :   ffff800010105fc4:       mov     x2, x25
    0.00 :   ffff800010105fc8:       mov     x0, x20
    0.00 :   ffff800010105fcc:       bl      ffff8000101091a0 <swiotlb_sync_single_for_cpu>
    0.00 :   ffff800010105fd0:       b       ffff800010105f20 <dma_unmap_page_attrs+0xb0>
    0.00 :   ffff800010105fd4:       ldp     x19, x20, [sp, #16]
         : 85               dma_unmap_page_attrs():
         : 177              }
    0.00 :   ffff800010105fd8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010105fdc:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010105fe0:       ldr     x25, [sp, #64]
    0.00 :   ffff800010105fe4:       ldp     x29, x30, [sp], #80
    0.00 :   ffff800010105fe8:       autiasp
    0.00 :   ffff800010105fec:       ret
         : 184              dma_direct_unmap_page():
         : 113              if (!(attrs & DMA_ATTR_SKIP_CPU_SYNC))
    0.00 :   ffff800010105ff0:       mov     x22, x1
    0.00 :   ffff800010105ff4:       cbnz    x5, ffff800010105f1c <dma_unmap_page_attrs+0xac>
    0.00 :   ffff800010105ff8:       b       ffff800010105f90 <dma_unmap_page_attrs+0x120>
         : 117              dma_direct_sync_single_for_cpu():
         : 72               arch_sync_dma_for_cpu(paddr, size, dir);
    0.00 :   ffff800010105ffc:       mov     w2, w21
    0.00 :   ffff800010106000:       mov     x1, x25
    0.00 :   ffff800010106004:       mov     x0, x19
    0.00 :   ffff800010106008:       bl      ffff800010031e88 <arch_sync_dma_for_cpu>
         : 77               dma_unmap_page_attrs():
         : 311              #ifdef CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL
         : 312              void arch_sync_dma_for_cpu_all(void);
         : 313              #else
         : 314              static inline void arch_sync_dma_for_cpu_all(void)
         : 315              {
         : 316              }
    0.00 :   ffff80001010600c:       b       ffff800010105f98 <dma_unmap_page_attrs+0x128>
         : 318              translate_dma_to_phys():
         : 47               return (phys_addr_t)dma_addr + m->offset;
    0.00 :   ffff800010106010:       ldr     x22, [x2, #24]
    0.00 :   ffff800010106014:       add     x22, x19, x22
         : 50               dma_direct_unmap_page():
         : 113              if (!(attrs & DMA_ATTR_SKIP_CPU_SYNC))
    0.00 :   ffff800010106018:       cbnz    x5, ffff800010105f1c <dma_unmap_page_attrs+0xac>
    0.00 :   ffff80001010601c:       b       ffff800010105f68 <dma_unmap_page_attrs+0xf8>
    0.00 :   ffff800010106020:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010106024:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010106028:       str     x25, [sp, #64]
         : 119              dma_unmap_page_attrs():
         : 170              BUG_ON(!valid_dma_direction(dir));
    0.00 :   ffff80001010602c:       brk     #0x800
         : 172              translate_dma_to_phys():
    0.00 :   ffff800010106030:       ldr     x0, [x0, #24]
    0.00 :   ffff800010106034:       add     x19, x19, x0
    0.00 :   ffff800010106038:       b       ffff800010105f90 <dma_unmap_page_attrs+0x120>
         : 49               return (phys_addr_t)-1;
    0.00 :   ffff80001010603c:       mov     x22, #0xffffffffffffffff        // #-1
         : 51               dma_direct_unmap_page():
    0.00 :   ffff800010106040:       cbnz    x5, ffff800010105f1c <dma_unmap_page_attrs+0xac>
         : 114              translate_dma_to_phys():
    0.00 :   ffff800010106044:       mov     x19, x22
    0.00 :   ffff800010106048:       b       ffff800010105f90 <dma_unmap_page_attrs+0x120>
 Percent |	Source code & Disassembly of vmlinux for cycles (34 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010c09508 <arch_counter_read>:
         : 6                arch_counter_read():
         : 195              */
         : 196              u64 (*arch_timer_read_counter)(void) __ro_after_init = arch_counter_get_cntvct;
         : 197              EXPORT_SYMBOL_GPL(arch_timer_read_counter);
         :
         : 199              static u64 arch_counter_read(struct clocksource *cs)
         : 200              {
    2.94 :   ffff800010c09508:       paciasp
         : 196              return arch_timer_read_counter();
   97.06 :   ffff800010c0950c:       adrp    x0, ffff800011572000 <kmalloc_caches+0x78>
         : 195              {
    0.00 :   ffff800010c09510:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010c09514:       mov     x29, sp
         : 196              return arch_timer_read_counter();
    0.00 :   ffff800010c09518:       ldr     x0, [x0, #3096]
    0.00 :   ffff800010c0951c:       blr     x0
         : 197              }
    0.00 :   ffff800010c09520:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010c09524:       autiasp
    0.00 :   ffff800010c09528:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (24 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c4e10 <update_sd_lb_stats.constprop.135>:
         : 6                update_sd_lb_stats():
         : 8986             return idlest;
         : 8987             #endif
         : 8988             /*
         : 8989             * Otherwise, keep the task on this node to stay close
         : 8990             * its wakeup source and improve locality. If there is
         : 8991             * a real need of migration, periodic load balance will
    0.00 :   ffff8000100c4e10:       paciasp
    0.00 :   ffff8000100c4e14:       stp     x29, x30, [sp, #-240]!
    0.00 :   ffff8000100c4e18:       mov     x29, sp
    0.00 :   ffff8000100c4e1c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c4e20:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c4e24:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c4e28:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
         : 8999             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c4e2c:       adrp    x23, ffff800011779000 <cpu_armpmu>
         : 8454             update_sd_lb_stats():
         : 8986             * a real need of migration, periodic load balance will
    0.00 :   ffff8000100c4e30:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c4e34:       mov     x26, x1
         : 8989             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c4e38:       add     x23, x23, #0xc40
         : 8454             update_sd_lb_stats():
         : 8986             * a real need of migration, periodic load balance will
    0.00 :   ffff8000100c4e3c:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c4e40:       mov     x28, x0
    0.00 :   ffff8000100c4e44:       adrp    x27, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c4e48:       add     x0, x27, #0x948
    0.00 :   ffff8000100c4e4c:       str     x0, [sp, #136]
    0.00 :   ffff8000100c4e50:       ldr     x1, [x0]
    0.00 :   ffff8000100c4e54:       str     x1, [sp, #232]
    0.00 :   ffff8000100c4e58:       mov     x1, #0x0                        // #0
         : 8990             * take care of it.
         : 8991             */
         : 8992             if (allow_numa_imbalance(local_sgs.sum_nr_running, sd->span_weight))
         : 8993             return NULL;
    0.00 :   ffff8000100c4e5c:       add     x0, x26, #0x80
    0.00 :   ffff8000100c4e60:       str     x0, [sp, #120]
    0.00 :   ffff8000100c4e64:       add     x1, x24, #0xc30
         : 8988             */
    0.00 :   ffff8000100c4e68:       ldr     x0, [x28]
    0.00 :   ffff8000100c4e6c:       str     x1, [sp, #104]
         : 8992             }
         :
    0.00 :   ffff8000100c4e70:       mov     w27, #0x0                       // #0
         : 8989             if (allow_numa_imbalance(local_sgs.sum_nr_running, sd->span_weight))
    0.00 :   ffff8000100c4e74:       ldp     x1, x25, [x0, #8]
         : 8988             */
    0.00 :   ffff8000100c4e78:       str     x1, [sp, #128]
         : 8991             }
    0.00 :   ffff8000100c4e7c:       nop
         : 8998             /*
         : 8999             * Select group with highest number of idle CPUs. We could also
         : 9000             * compare the utilization which is more stable but it can end
         : 9001             * up that the group has less spare capacity but finally more
         : 9002             * idle CPUs which means more opportunity to run task.
         : 9003             */
    0.00 :   ffff8000100c4e80:       ldr     w1, [x28, #20]
         : 9005             cpumask_test_cpu():
         : 344              *
         : 345              * Returns 1 if @cpu is set in @cpumask, else returns 0
         : 346              */
         : 347              static inline int cpumask_test_cpu(int cpu, const struct cpumask *cpumask)
         : 348              {
         : 349              return test_bit(cpumask_check(cpu), cpumask_bits((cpumask)));
    0.00 :   ffff8000100c4e84:       add     x22, x25, #0x20
         : 351              update_sd_lb_stats():
         : 8995             * compare the utilization which is more stable but it can end
    0.00 :   ffff8000100c4e88:       add     x19, sp, #0x98
         : 8997             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100c4e8c:       cmp     w1, #0x0
    0.00 :   ffff8000100c4e90:       add     w0, w1, #0x3f
    0.00 :   ffff8000100c4e94:       csel    w0, w0, w1, lt  // lt = tstop
    0.00 :   ffff8000100c4e98:       asr     w0, w0, #6
    0.00 :   ffff8000100c4e9c:       sxtw    x0, w0
    0.00 :   ffff8000100c4ea0:       ldr     x0, [x22, x0, lsl #3]
    0.00 :   ffff8000100c4ea4:       lsr     x0, x0, x1
         : 119              update_sd_lb_stats():
         : 8999             if (local_sgs.idle_cpus >= idlest_sgs.idle_cpus)
    0.00 :   ffff8000100c4ea8:       and     w1, w0, #0x1
    0.00 :   ffff8000100c4eac:       str     w1, [sp, #116]
    0.00 :   ffff8000100c4eb0:       tbz     w0, #0, ffff8000100c4ef0 <update_sd_lb_stats.constprop.135+0xe0>
         : 9000             return NULL;
    0.00 :   ffff8000100c4eb4:       str     x25, [x26, #8]
         : 9003             break;
         : 9004             }
         :
    0.00 :   ffff8000100c4eb8:       ldr     w0, [x28, #44]
    0.00 :   ffff8000100c4ebc:       cmp     w0, #0x2
    0.00 :   ffff8000100c4ec0:       b.ne    ffff8000100c4ee0 <update_sd_lb_stats.constprop.135+0xd0>  // b.any
         : 9004             return idlest;
    0.00 :   ffff8000100c4ec4:       ldr     x0, [x25, #16]
    0.00 :   ffff8000100c4ec8:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
         : 9001             break;
    0.00 :   ffff8000100c4ecc:       ldr     x19, [sp, #120]
         : 9004             return idlest;
    0.00 :   ffff8000100c4ed0:       ldr     x1, [x1, #2432]
    0.00 :   ffff8000100c4ed4:       ldr     x0, [x0, #32]
    0.00 :   ffff8000100c4ed8:       cmp     x1, x0
    0.00 :   ffff8000100c4edc:       b.mi    ffff8000100c4ef0 <update_sd_lb_stats.constprop.135+0xe0>  // b.first
         : 9005             }
    0.00 :   ffff8000100c4ee0:       ldr     w1, [x28, #20]
    0.00 :   ffff8000100c4ee4:       ldr     x0, [x28]
         : 9001             break;
    0.00 :   ffff8000100c4ee8:       ldr     x19, [sp, #120]
         : 9005             }
    0.00 :   ffff8000100c4eec:       bl      ffff8000100c4c20 <update_group_capacity>
         : 9007             update_sg_lb_stats():
         : 8447             if (sgs->group_misfit_task_load)
    0.00 :   ffff8000100c4ef0:       stp     xzr, xzr, [x19]
         :
    0.00 :   ffff8000100c4ef4:       adrp    x6, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c4ef8:       add     x24, x6, #0x760
         : 8447             if (sgs->group_misfit_task_load)
    0.00 :   ffff8000100c4efc:       stp     xzr, xzr, [x19, #16]
         : 8451             return group_fully_busy;
    0.00 :   ffff8000100c4f00:       mov     w1, #0xffffffff                 // #-1
         : 8447             if (sgs->group_misfit_task_load)
    0.00 :   ffff8000100c4f04:       stp     xzr, xzr, [x19, #32]
    0.00 :   ffff8000100c4f08:       stp     xzr, xzr, [x19, #48]
    0.00 :   ffff8000100c4f0c:       stp     xzr, xzr, [x19, #64]
         :
    0.00 :   ffff8000100c4f10:       ldr     x0, [sp, #104]
    0.00 :   ffff8000100c4f14:       ldr     w2, [x28, #20]
         : 8452             test_bit():
    0.00 :   ffff8000100c4f18:       ldr     w8, [x0]
    0.00 :   ffff8000100c4f1c:       cmp     w2, #0x0
    0.00 :   ffff8000100c4f20:       add     w0, w2, #0x3f
    0.00 :   ffff8000100c4f24:       csel    w0, w0, w2, lt  // lt = tstop
    0.00 :   ffff8000100c4f28:       asr     w0, w0, #6
    0.00 :   ffff8000100c4f2c:       sxtw    x0, w0
    0.00 :   ffff8000100c4f30:       ldr     x21, [x22, x0, lsl #3]
    0.00 :   ffff8000100c4f34:       lsr     x21, x21, x2
    0.00 :   ffff8000100c4f38:       and     w21, w21, #0x1
         : 115              update_sg_lb_stats():
    0.00 :   ffff8000100c4f3c:       nop
         : 8451             return group_fully_busy;
    0.00 :   ffff8000100c4f40:       ldr     x2, [x28, #56]
    0.00 :   ffff8000100c4f44:       mov     w0, w1
    0.00 :   ffff8000100c4f48:       mov     x1, x22
    0.00 :   ffff8000100c4f4c:       str     w8, [sp, #112]
    0.00 :   ffff8000100c4f50:       bl      ffff8000104a75d0 <cpumask_next_and>
    0.00 :   ffff8000100c4f54:       ldr     w8, [sp, #112]
    0.00 :   ffff8000100c4f58:       mov     w1, w0
    0.00 :   ffff8000100c4f5c:       cmp     w0, w8
    0.00 :   ffff8000100c4f60:       b.cs    ffff8000100c50d0 <update_sd_lb_stats.constprop.135+0x2c0>  // b.hs, b.nlast
         :
    0.00 :   ffff8000100c4f64:       sxtw    x10, w1
    0.00 :   ffff8000100c4f68:       mov     x0, x23
         : 8454             }
    0.00 :   ffff8000100c4f6c:       ldr     x2, [x19, #8]
         :
    0.00 :   ffff8000100c4f70:       ldr     x20, [x24, x10, lsl #3]
    0.00 :   ffff8000100c4f74:       add     x20, x0, x20
         : 8454             }
    0.00 :   ffff8000100c4f78:       ldr     x9, [x20, #288]
    1.06 :   ffff8000100c4f7c:       add     x2, x2, x9
   26.73 :   ffff8000100c4f80:       str     x2, [x19, #8]
         : 8458             cpu_util():
         :
    0.00 :   ffff8000100c4f84:       ldr     x9, [x24, x10, lsl #3]
    0.00 :   ffff8000100c4f88:       add     x0, x0, x9
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100c4f8c:       add     x0, x0, #0x80
    0.00 :   ffff8000100c4f90:       ldr     x11, [x0, #176]
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c4f94:       ldr     w0, [x0, #184]
    0.00 :   ffff8000100c4f98:       str     w0, [sp, #144]
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100c4f9c:       mov     w2, w11
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c4fa0:       ldr     w0, [sp, #144]
    0.00 :   ffff8000100c4fa4:       cmp     w11, w0
    0.00 :   ffff8000100c4fa8:       b.hi    ffff8000100c4fb0 <update_sd_lb_stats.constprop.135+0x1a0>  // b.pmore
   14.14 :   ffff8000100c4fac:       ldr     w2, [sp, #144]
         : 6426             capacity_orig_of():
         : 2604             if (__rq_lockp(rq1) != __rq_lockp(rq2))
         : 2605             raw_spin_rq_unlock(rq2);
         : 2606             else
         : 2607             __release(rq2->lock);
         : 2608             raw_spin_rq_unlock(rq1);
         : 2609             }
    0.00 :   ffff8000100c4fb0:       mov     x0, x23
         : 2611             cpu_util():
         :
    0.00 :   ffff8000100c4fb4:       mov     w2, w2
         : 6425             capacity_orig_of():
    0.00 :   ffff8000100c4fb8:       add     x9, x9, x0
         : 2605             update_sg_lb_stats():
         : 8463             static inline void update_sg_lb_stats(struct lb_env *env,
    0.00 :   ffff8000100c4fbc:       orr     w13, w27, #0x1
         : 8456             /**
    0.00 :   ffff8000100c4fc0:       ldp     x15, x14, [x19, #24]
         : 8458             cpu_util():
         :
    0.00 :   ffff8000100c4fc4:       ldr     x9, [x9, #2488]
         : 6425             update_sg_lb_stats():
         : 8457             * update_sg_lb_stats - Update sched_group's statistics for load balancing.
    3.31 :   ffff8000100c4fc8:       ldp     w12, w11, [x19, #40]
         : 8459             cpu_util():
         :
    0.00 :   ffff8000100c4fcc:       cmp     x9, x2
    0.00 :   ffff8000100c4fd0:       csel    x2, x9, x2, ls  // ls = plast
         : 6426             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c4fd4:       add     x2, x15, x2
   13.47 :   ffff8000100c4fd8:       str     x2, [x19, #24]
         : 8456             /**
    0.00 :   ffff8000100c4fdc:       ldr     x2, [x20, #296]
    0.00 :   ffff8000100c4fe0:       add     x2, x14, x2
    0.00 :   ffff8000100c4fe4:       str     x2, [x19, #32]
         : 8457             * update_sg_lb_stats - Update sched_group's statistics for load balancing.
    0.00 :   ffff8000100c4fe8:       ldr     w2, [x20, #148]
    0.00 :   ffff8000100c4fec:       add     w2, w11, w2
    0.00 :   ffff8000100c4ff0:       str     w2, [x19, #44]
         : 8459             * @group: sched_group whose statistics are to be updated.
    0.00 :   ffff8000100c4ff4:       ldr     w11, [x20, #4]
         : 8460             * @sgs: variable to hold the statistics for this group.
    0.00 :   ffff8000100c4ff8:       add     w2, w12, w11
    0.00 :   ffff8000100c4ffc:       str     w2, [x19, #40]
         : 8463             static inline void update_sg_lb_stats(struct lb_env *env,
    0.00 :   ffff8000100c5000:       cmp     w11, #0x1
         : 8465             cpu_util():
         :
    0.00 :   ffff8000100c5004:       ldr     x9, [x24, x10, lsl #3]
         : 6419             update_sg_lb_stats():
         : 8463             static inline void update_sg_lb_stats(struct lb_env *env,
    0.00 :   ffff8000100c5008:       csel    w27, w13, w27, gt
         : 8465             cpu_util():
         :
    0.00 :   ffff8000100c500c:       add     x0, x0, x9
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100c5010:       add     x0, x0, #0x80
    0.00 :   ffff8000100c5014:       ldr     x2, [x0, #176]
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c5018:       ldr     w0, [x0, #184]
    0.00 :   ffff8000100c501c:       str     w0, [sp, #148]
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100c5020:       mov     w0, w2
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c5024:       ldr     w10, [sp, #148]
    0.00 :   ffff8000100c5028:       cmp     w2, w10
    0.00 :   ffff8000100c502c:       b.hi    ffff8000100c5034 <update_sd_lb_stats.constprop.135+0x224>  // b.pmore
   14.14 :   ffff8000100c5030:       ldr     w0, [sp, #148]
         : 6426             capacity_orig_of():
    0.00 :   ffff8000100c5034:       mov     x2, x23
         : 2605             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c5038:       ldr     w13, [x20, #8]
         : 8471             capacity_orig_of():
    0.00 :   ffff8000100c503c:       add     x9, x9, x2
         : 2605             cpu_util():
         :
    0.00 :   ffff8000100c5040:       mov     w2, w0
         : 6425             update_sg_lb_stats():
         : 8470             memset(sgs, 0, sizeof(*sgs));
    0.00 :   ffff8000100c5044:       ldp     w12, w10, [x19, #72]
         : 8472             cpu_util():
         :
    0.00 :   ffff8000100c5048:       ldr     x0, [x9, #2488]
         : 6425             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c504c:       add     w12, w12, w13
         : 8471             cpu_overutilized():
         :
    0.00 :   ffff8000100c5050:       ldr     x9, [x9, #2480]
         : 5480             cpu_util():
         :
    0.00 :   ffff8000100c5054:       cmp     x0, x2
         : 6425             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c5058:       str     w12, [x19, #72]
         : 8471             cpu_util():
         :
    0.00 :   ffff8000100c505c:       csel    x0, x0, x2, ls  // ls = plast
         : 6425             update_sg_lb_stats():
         : 8466             int *sg_status)
    0.00 :   ffff8000100c5060:       orr     w13, w27, #0x2
         : 8470             memset(sgs, 0, sizeof(*sgs));
    0.00 :   ffff8000100c5064:       ldr     w12, [x20, #12]
         : 8472             cpu_overutilized():
         :
    0.00 :   ffff8000100c5068:       add     x0, x0, x0, lsl #2
    0.00 :   ffff8000100c506c:       lsl     x2, x9, #10
         : 5481             update_sg_lb_stats():
         : 8470             memset(sgs, 0, sizeof(*sgs));
    0.00 :   ffff8000100c5070:       add     w9, w10, w12
    0.00 :   ffff8000100c5074:       str     w9, [x19, #76]
         : 8466             int *sg_status)
    0.00 :   ffff8000100c5078:       cmp     x2, x0, lsl #8
    0.00 :   ffff8000100c507c:       csel    w27, w13, w27, ls  // ls = plast
         : 8475             struct rq *rq = cpu_rq(i);
    0.00 :   ffff8000100c5080:       cbz     w11, ffff8000100c50b0 <update_sd_lb_stats.constprop.135+0x2a0>
         :
    0.00 :   ffff8000100c5084:       cbnz    w21, ffff8000100c4f40 <update_sd_lb_stats.constprop.135+0x130>
         : 8485             if (nr_running > 1)
    0.00 :   ffff8000100c5088:       ldr     x0, [x28]
    0.00 :   ffff8000100c508c:       ldr     w0, [x0, #56]
    0.00 :   ffff8000100c5090:       tbz     w0, #5, ffff8000100c4f40 <update_sd_lb_stats.constprop.135+0x130>
    0.00 :   ffff8000100c5094:       ldr     x2, [x19, #64]
         : 8486             *sg_status |= SG_OVERLOAD;
    0.00 :   ffff8000100c5098:       ldr     x0, [x20, #2512]
         : 8485             if (nr_running > 1)
    0.00 :   ffff8000100c509c:       cmp     x2, x0
    0.00 :   ffff8000100c50a0:       b.cs    ffff8000100c4f40 <update_sd_lb_stats.constprop.135+0x130>  // b.hs, b.nlast
         : 8488             if (cpu_overutilized(i))
    0.00 :   ffff8000100c50a4:       orr     w27, w27, #0x1
         :
    0.00 :   ffff8000100c50a8:       str     x0, [x19, #64]
         : 8488             if (cpu_overutilized(i))
    0.00 :   ffff8000100c50ac:       b       ffff8000100c4f40 <update_sd_lb_stats.constprop.135+0x130>
         : 8475             struct rq *rq = cpu_rq(i);
    0.00 :   ffff8000100c50b0:       mov     w0, w1
    0.00 :   ffff8000100c50b4:       str     w1, [sp, #112]
    0.00 :   ffff8000100c50b8:       bl      ffff8000100b75b8 <idle_cpu>
    0.00 :   ffff8000100c50bc:       ldr     w1, [sp, #112]
    0.00 :   ffff8000100c50c0:       cbnz    w0, ffff8000100c530c <update_sd_lb_stats.constprop.135+0x4fc>
    0.00 :   ffff8000100c50c4:       ldr     x0, [sp, #104]
    0.00 :   ffff8000100c50c8:       ldr     w8, [x0]
    0.00 :   ffff8000100c50cc:       b       ffff8000100c5084 <update_sd_lb_stats.constprop.135+0x274>
         : 8493             sgs->nr_preferred_running += rq->nr_preferred_running;
    0.00 :   ffff8000100c50d0:       ldr     x0, [x28]
    0.00 :   ffff8000100c50d4:       ldr     w0, [x0, #56]
    0.00 :   ffff8000100c50d8:       tbz     w0, #9, ffff8000100c50f0 <update_sd_lb_stats.constprop.135+0x2e0>
    0.00 :   ffff8000100c50dc:       ldr     w0, [x28, #44]
    0.00 :   ffff8000100c50e0:       cmp     w0, #0x1
    0.00 :   ffff8000100c50e4:       b.eq    ffff8000100c50f0 <update_sd_lb_stats.constprop.135+0x2e0>  // b.none
         : 8494             #endif
    0.00 :   ffff8000100c50e8:       ldr     w0, [x19, #44]
    0.00 :   ffff8000100c50ec:       cbnz    w0, ffff8000100c5414 <update_sd_lb_stats.constprop.135+0x604>
         : 8500             /* Idle cpu can't have misfit task */
    0.00 :   ffff8000100c50f0:       ldr     x0, [x25, #16]
         : 8502             group_is_overloaded():
         :
    0.00 :   ffff8000100c50f4:       ldr     w10, [x19, #40]
         : 8398             update_sg_lb_stats():
         : 8500             /* Idle cpu can't have misfit task */
    0.00 :   ffff8000100c50f8:       ldr     x0, [x0, #8]
    3.64 :   ffff8000100c50fc:       str     x0, [x19, #16]
         : 8502             }
    0.00 :   ffff8000100c5100:       ldr     w2, [x25, #12]
    0.00 :   ffff8000100c5104:       str     w2, [x19, #52]
         : 8505             group_is_overloaded():
         :
    0.00 :   ffff8000100c5108:       cmp     w2, w10
         : 8398             update_sg_lb_stats():
         : 8504             if (local_group)
    0.00 :   ffff8000100c510c:       ldr     x1, [x28]
    0.00 :   ffff8000100c5110:       ldr     w6, [x1, #44]
         : 8507             group_is_overloaded():
         :
    0.00 :   ffff8000100c5114:       b.cs    ffff8000100c514c <update_sd_lb_stats.constprop.135+0x33c>  // b.hs, b.nlast
         :
    0.00 :   ffff8000100c5118:       ldr     x8, [x19, #24]
    0.00 :   ffff8000100c511c:       mov     w9, w6
         : 8399             return false;
    0.00 :   ffff8000100c5120:       add     x1, x0, x0, lsl #1
         :
    0.00 :   ffff8000100c5124:       mul     x8, x9, x8
         : 8399             return false;
    0.00 :   ffff8000100c5128:       add     x1, x0, x1, lsl #3
    0.00 :   ffff8000100c512c:       cmp     x8, x1, lsl #2
    0.00 :   ffff8000100c5130:       b.hi    ffff8000100c5324 <update_sd_lb_stats.constprop.135+0x514>  // b.pmore
         :
    0.00 :   ffff8000100c5134:       ldr     x8, [x19, #32]
         : 8403             return true;
    0.00 :   ffff8000100c5138:       mul     x9, x0, x9
         :
    0.00 :   ffff8000100c513c:       add     x1, x8, x8, lsl #1
    0.00 :   ffff8000100c5140:       add     x1, x8, x1, lsl #3
         : 8403             return true;
    6.46 :   ffff8000100c5144:       cmp     x9, x1, lsl #2
    0.00 :   ffff8000100c5148:       b.cc    ffff8000100c5324 <update_sd_lb_stats.constprop.135+0x514>  // b.lo, b.ul, b.last
         : 8406             sg_imbalanced():
         : 8353             *       { 0 1 2 3 } { 4 5 6 7 }
    0.00 :   ffff8000100c514c:       ldr     x1, [x25, #16]
         : 8355             group_classify():
         : 8418             {
    0.00 :   ffff8000100c5150:       ldr     w1, [x1, #40]
    0.00 :   ffff8000100c5154:       cbnz    w1, ffff8000100c53d4 <update_sd_lb_stats.constprop.135+0x5c4>
         :
    2.34 :   ffff8000100c5158:       ldr     w1, [x19, #60]
    0.00 :   ffff8000100c515c:       cbnz    w1, ffff8000100c5440 <update_sd_lb_stats.constprop.135+0x630>
         : 8424             return true;
    0.00 :   ffff8000100c5160:       ldr     x1, [x19, #64]
    0.00 :   ffff8000100c5164:       cbnz    x1, ffff8000100c5498 <update_sd_lb_stats.constprop.135+0x688>
         : 8427             group_has_capacity():
         : 8371             * subtle and fragile situation.
    0.00 :   ffff8000100c5168:       cmp     w2, w10
    0.00 :   ffff8000100c516c:       b.hi    ffff8000100c5390 <update_sd_lb_stats.constprop.135+0x580>  // b.pmore
         : 8375             {
    0.00 :   ffff8000100c5170:       ldr     x2, [x19, #32]
         : 8374             static inline int sg_imbalanced(struct sched_group *group)
    0.00 :   ffff8000100c5174:       mov     w6, w6
         : 8375             {
    0.00 :   ffff8000100c5178:       add     x1, x2, x2, lsl #1
         : 8374             static inline int sg_imbalanced(struct sched_group *group)
    0.00 :   ffff8000100c517c:       mul     x8, x0, x6
         : 8375             {
    0.00 :   ffff8000100c5180:       add     x1, x2, x1, lsl #3
         : 8374             static inline int sg_imbalanced(struct sched_group *group)
    0.00 :   ffff8000100c5184:       cmp     x8, x1, lsl #2
    0.00 :   ffff8000100c5188:       b.cc    ffff8000100c51a4 <update_sd_lb_stats.constprop.135+0x394>  // b.lo, b.ul, b.last
         : 8379             /*
    0.00 :   ffff8000100c518c:       ldr     x2, [x19, #24]
         :
    0.00 :   ffff8000100c5190:       add     x1, x0, x0, lsl #1
    0.00 :   ffff8000100c5194:       add     x0, x0, x1, lsl #3
         : 8379             /*
    0.00 :   ffff8000100c5198:       mul     x6, x6, x2
         :
    0.00 :   ffff8000100c519c:       cmp     x6, x0, lsl #2
    0.00 :   ffff8000100c51a0:       b.cc    ffff8000100c5390 <update_sd_lb_stats.constprop.135+0x580>  // b.lo, b.ul, b.last
         : 8381             update_sg_lb_stats():
         : 8504             if (local_group)
    0.00 :   ffff8000100c51a4:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c51a8:       str     w0, [x19, #56]
         : 8507             update_sd_lb_stats():
         :
         : 9011             /**
         : 9012             * update_sd_lb_stats - Update sched_domain's statistics for load balancing.
         : 9013             * @env: The load balancing environment.
         : 9014             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c51ac:       ldr     w0, [sp, #116]
    0.00 :   ffff8000100c51b0:       cbnz    w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 9017             update_sd_pick_busiest():
         : 8533             }
    0.00 :   ffff8000100c51b4:       ldr     w0, [x19, #44]
    0.00 :   ffff8000100c51b8:       cbz     w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8547             */
    0.00 :   ffff8000100c51bc:       add     x20, x26, #0x30
    0.00 :   ffff8000100c51c0:       ldr     w0, [x20, #56]
    0.00 :   ffff8000100c51c4:       cbz     w0, ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>
         : 8550             struct sched_group *sg,
    0.00 :   ffff8000100c51c8:       cmp     w0, #0x1
    0.00 :   ffff8000100c51cc:       b.hi    ffff8000100c5408 <update_sd_lb_stats.constprop.135+0x5f8>  // b.pmore
         : 8598             return false;
    0.00 :   ffff8000100c51d0:       ldr     x1, [x19]
    0.00 :   ffff8000100c51d4:       ldr     x0, [x26, #48]
    0.00 :   ffff8000100c51d8:       cmp     x1, x0
    0.00 :   ffff8000100c51dc:       b.ls    ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>  // b.plast
         : 8625             case group_has_spare:
    0.00 :   ffff8000100c51e0:       ldr     x0, [x28]
    0.00 :   ffff8000100c51e4:       ldr     w0, [x0, #56]
    0.00 :   ffff8000100c51e8:       tbz     w0, #5, ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>
         : 8629             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c51ec:       ldrsw   x8, [x28, #20]
    0.00 :   ffff8000100c51f0:       adrp    x0, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c51f4:       add     x0, x0, #0x760
    0.00 :   ffff8000100c51f8:       mov     x1, x23
         : 5769             update_sd_pick_busiest():
         : 8627             * Select not overloaded group with lowest number of idle cpus
    0.00 :   ffff8000100c51fc:       ldr     x2, [x25, #16]
    0.00 :   ffff8000100c5200:       mov     x6, #0x436                      // #1078
         : 8630             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c5204:       ldr     x0, [x0, x8, lsl #3]
         : 5766             update_sd_pick_busiest():
         : 8627             * Select not overloaded group with lowest number of idle cpus
    0.00 :   ffff8000100c5208:       ldr     x2, [x2, #16]
         : 8629             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c520c:       add     x0, x0, x1
         : 5766             update_sd_pick_busiest():
         : 8627             * Select not overloaded group with lowest number of idle cpus
    0.00 :   ffff8000100c5210:       ldr     x0, [x0, #2480]
    0.00 :   ffff8000100c5214:       mul     x0, x0, x6
         : 8626             /*
    0.00 :   ffff8000100c5218:       cmp     x0, x2, lsl #10
    0.00 :   ffff8000100c521c:       b.cc    ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>  // b.lo, b.ul, b.last
         : 8629             update_sd_lb_stats():
         : 9015             */
         :
         : 9017             static inline void update_sd_lb_stats(struct lb_env *env, struct sd_lb_stats *sds)
         : 9018             {
         : 9019             struct sched_domain *child = env->sd->child;
    0.00 :   ffff8000100c5220:       str     x25, [x26]
         : 9016             struct sched_group *sg = env->sd->groups;
    0.00 :   ffff8000100c5224:       ldp     x0, x1, [x19]
    0.00 :   ffff8000100c5228:       stp     x0, x1, [x20]
    0.00 :   ffff8000100c522c:       ldp     x0, x1, [x19, #16]
    0.00 :   ffff8000100c5230:       stp     x0, x1, [x20, #16]
    0.00 :   ffff8000100c5234:       ldp     x0, x1, [x19, #32]
    0.00 :   ffff8000100c5238:       stp     x0, x1, [x20, #32]
    0.00 :   ffff8000100c523c:       ldp     x0, x1, [x19, #48]
    0.00 :   ffff8000100c5240:       stp     x0, x1, [x20, #48]
    0.00 :   ffff8000100c5244:       ldp     x0, x1, [x19, #64]
    0.00 :   ffff8000100c5248:       stp     x0, x1, [x20, #64]
    0.00 :   ffff8000100c524c:       ldr     x6, [x19, #8]
         : 9022             struct sg_lb_stats *local = &sds->local_stat;
         : 9023             struct sg_lb_stats tmp_sgs;
         : 9024             int sg_status = 0;
         :
         : 9026             do {
         : 9027             struct sg_lb_stats *sgs = &tmp_sgs;
    0.00 :   ffff8000100c5250:       ldp     x1, x0, [x26, #16]
         : 9021             do {
    0.00 :   ffff8000100c5254:       add     x1, x1, x6
   14.14 :   ffff8000100c5258:       str     x1, [x26, #16]
         : 9022             struct sg_lb_stats *sgs = &tmp_sgs;
    0.00 :   ffff8000100c525c:       ldr     x1, [x19, #16]
    0.00 :   ffff8000100c5260:       add     x0, x0, x1
    0.00 :   ffff8000100c5264:       str     x0, [x26, #24]
         : 9025             int local_group;
         :
         : 9027             local_group = cpumask_test_cpu(env->dst_cpu, sched_group_span(sg));
    0.00 :   ffff8000100c5268:       ldr     x0, [x28]
         :
    0.00 :   ffff8000100c526c:       ldr     x25, [x25]
         : 9025             local_group = cpumask_test_cpu(env->dst_cpu, sched_group_span(sg));
    0.00 :   ffff8000100c5270:       ldr     x0, [x0, #16]
    0.00 :   ffff8000100c5274:       cmp     x25, x0
    0.00 :   ffff8000100c5278:       b.ne    ffff8000100c4e80 <update_sd_lb_stats.constprop.135+0x70>  // b.any
         : 9028             if (local_group) {
         : 9029             sds->local = sg;
         : 9030             sgs = local;
    0.00 :   ffff8000100c527c:       ldr     x1, [sp, #128]
    0.00 :   ffff8000100c5280:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000100c5284:       cbz     x1, ffff8000100c5290 <update_sd_lb_stats.constprop.135+0x480>
    0.00 :   ffff8000100c5288:       ldr     w0, [x1, #56]
    0.00 :   ffff8000100c528c:       ubfx    x0, x0, #10, #1
    0.00 :   ffff8000100c5290:       str     w0, [x26, #40]
         :
         : 9032             if (env->idle != CPU_NEWLY_IDLE ||
         : 9033             time_after_eq(jiffies, sg->sgc->next_update))
    0.00 :   ffff8000100c5294:       ldr     x0, [x28]
    0.00 :   ffff8000100c5298:       ldr     w1, [x0, #56]
    0.00 :   ffff8000100c529c:       tbz     w1, #12, ffff8000100c52c8 <update_sd_lb_stats.constprop.135+0x4b8>
         : 9037             fbq_classify_group():
         : 8636             (sgs->sum_nr_running <= busiest->sum_nr_running))
    0.00 :   ffff8000100c52a0:       ldr     w2, [x26, #92]
         : 8637             return false;
    0.00 :   ffff8000100c52a4:       mov     w1, #0x0                        // #0
         : 8636             (sgs->sum_nr_running <= busiest->sum_nr_running))
    0.00 :   ffff8000100c52a8:       ldr     w5, [x26, #120]
    0.00 :   ffff8000100c52ac:       cmp     w2, w5
    0.00 :   ffff8000100c52b0:       b.hi    ffff8000100c52c4 <update_sd_lb_stats.constprop.135+0x4b4>  // b.pmore
         :
    0.00 :   ffff8000100c52b4:       ldr     w1, [x26, #124]
         : 8639             break;
    0.00 :   ffff8000100c52b8:       cmp     w2, w1
    0.00 :   ffff8000100c52bc:       cset    w1, ls  // ls = plast
    0.00 :   ffff8000100c52c0:       add     w1, w1, #0x1
         : 8643             update_sd_lb_stats():
         : 9032             update_group_capacity(env->sd, env->dst_cpu);
    0.00 :   ffff8000100c52c4:       str     w1, [x28, #80]
         : 9034             }
         :
    0.00 :   ffff8000100c52c8:       ldr     x1, [x0]
    0.00 :   ffff8000100c52cc:       and     w0, w27, #0x2
    0.00 :   ffff8000100c52d0:       cbz     x1, ffff8000100c5528 <update_sd_lb_stats.constprop.135+0x718>
         : 9043             goto next_group;
         :
         :
         : 9046             if (update_sd_pick_busiest(env, sds, sg, sgs)) {
         : 9047             sds->busiest = sg;
         : 9048             sds->busiest_stat = *sgs;
    0.00 :   ffff8000100c52d4:       cbnz    w0, ffff8000100c5514 <update_sd_lb_stats.constprop.135+0x704>
         : 9049             }
         :
         : 9051             next_group:
         : 9052             /* Now, start updating sd_lb_stats */
         : 9053             sds->total_load += sgs->group_load;
         : 9054             sds->total_capacity += sgs->group_capacity;
    0.00 :   ffff8000100c52d8:       ldr     x0, [sp, #136]
    0.00 :   ffff8000100c52dc:       ldr     x1, [sp, #232]
    0.00 :   ffff8000100c52e0:       ldr     x0, [x0]
    0.00 :   ffff8000100c52e4:       eor     x0, x1, x0
    0.00 :   ffff8000100c52e8:       cbnz    x0, ffff8000100c5540 <update_sd_lb_stats.constprop.135+0x730>
    0.00 :   ffff8000100c52ec:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c52f0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c52f4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c52f8:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c52fc:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c5300:       ldp     x29, x30, [sp], #240
    0.00 :   ffff8000100c5304:       autiasp
    0.00 :   ffff8000100c5308:       ret
         : 9068             update_sg_lb_stats():
         :
    0.00 :   ffff8000100c530c:       ldr     x2, [sp, #104]
    0.57 :   ffff8000100c5310:       ldr     w0, [x19, #48]
    0.00 :   ffff8000100c5314:       ldr     w8, [x2]
    0.00 :   ffff8000100c5318:       add     w0, w0, #0x1
    0.00 :   ffff8000100c531c:       str     w0, [x19, #48]
         : 8478             sgs->group_util += cpu_util(i);
    0.00 :   ffff8000100c5320:       b       ffff8000100c4f40 <update_sd_lb_stats.constprop.135+0x130>
         : 8508             if (env->sd->flags & SD_ASYM_CPUCAPACITY &&
    0.00 :   ffff8000100c5324:       ldr     x6, [x19, #8]
         : 8504             if (local_group)
    0.00 :   ffff8000100c5328:       mov     w1, #0x5                        // #5
    0.00 :   ffff8000100c532c:       str     w1, [x19, #56]
         : 8508             if (env->sd->flags & SD_ASYM_CPUCAPACITY &&
    0.00 :   ffff8000100c5330:       mov     x2, x6
    0.00 :   ffff8000100c5334:       lsl     x1, x6, #10
    0.00 :   ffff8000100c5338:       udiv    x0, x1, x0
         : 8512             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c533c:       ldr     w1, [sp, #116]
         : 9012             update_sg_lb_stats():
         : 8508             if (env->sd->flags & SD_ASYM_CPUCAPACITY &&
    0.00 :   ffff8000100c5340:       str     x0, [x19]
         : 8510             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c5344:       cbnz    w1, ffff8000100c5250 <update_sd_lb_stats.constprop.135+0x440>
         : 9012             update_sd_pick_busiest():
         : 8533             }
    0.00 :   ffff8000100c5348:       ldr     w1, [x19, #44]
    0.00 :   ffff8000100c534c:       cbz     w1, ffff8000100c5250 <update_sd_lb_stats.constprop.135+0x440>
         : 8547             */
    0.00 :   ffff8000100c5350:       add     x20, x26, #0x30
    0.00 :   ffff8000100c5354:       ldr     w1, [x20, #56]
    0.00 :   ffff8000100c5358:       cmp     w1, #0x4
    0.00 :   ffff8000100c535c:       b.ls    ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>  // b.plast
         : 8550             struct sched_group *sg,
    0.00 :   ffff8000100c5360:       cmp     w1, #0x5
    0.00 :   ffff8000100c5364:       b.ne    ffff8000100c540c <update_sd_lb_stats.constprop.135+0x5fc>  // b.any
         : 8561             * We can use max_capacity here as reduction in capacity on some
    0.00 :   ffff8000100c5368:       ldr     x1, [x26, #48]
    0.00 :   ffff8000100c536c:       cmp     x0, x1
    0.00 :   ffff8000100c5370:       b.ls    ffff8000100c5250 <update_sd_lb_stats.constprop.135+0x440>  // b.plast
         : 8625             case group_has_spare:
    0.00 :   ffff8000100c5374:       ldr     x0, [x28]
    0.00 :   ffff8000100c5378:       ldr     w0, [x0, #56]
    0.00 :   ffff8000100c537c:       tbz     w0, #5, ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>
    0.00 :   ffff8000100c5380:       ldr     w0, [x19, #56]
    0.00 :   ffff8000100c5384:       cmp     w0, #0x1
    0.00 :   ffff8000100c5388:       b.hi    ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>  // b.pmore
    0.00 :   ffff8000100c538c:       b       ffff8000100c51ec <update_sd_lb_stats.constprop.135+0x3dc>
         : 8633             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c5390:       ldr     w0, [sp, #116]
         : 9012             update_sg_lb_stats():
         : 8504             if (local_group)
    0.00 :   ffff8000100c5394:       str     wzr, [x19, #56]
         : 8506             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c5398:       cbnz    w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 9012             update_sd_pick_busiest():
         : 8533             }
    0.00 :   ffff8000100c539c:       ldr     w0, [x19, #44]
    0.00 :   ffff8000100c53a0:       cbz     w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8547             */
    0.00 :   ffff8000100c53a4:       add     x20, x26, #0x30
         : 8550             struct sched_group *sg,
    0.00 :   ffff8000100c53a8:       ldr     w0, [x20, #56]
    0.00 :   ffff8000100c53ac:       cbnz    w0, ffff8000100c5408 <update_sd_lb_stats.constprop.135+0x5f8>
         : 8610             case group_fully_busy:
    0.00 :   ffff8000100c53b0:       ldr     w1, [x19, #48]
    0.00 :   ffff8000100c53b4:       ldr     w0, [x20, #48]
    0.00 :   ffff8000100c53b8:       cmp     w1, w0
    0.00 :   ffff8000100c53bc:       b.hi    ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>  // b.pmore
         : 8612             * Select the fully busy group with highest avg_load. In
    0.00 :   ffff8000100c53c0:       b.ne    ffff8000100c5374 <update_sd_lb_stats.constprop.135+0x564>  // b.any
    0.00 :   ffff8000100c53c4:       ldr     w0, [x20, #40]
    0.00 :   ffff8000100c53c8:       cmp     w10, w0
    0.00 :   ffff8000100c53cc:       b.hi    ffff8000100c5374 <update_sd_lb_stats.constprop.135+0x564>  // b.pmore
    0.00 :   ffff8000100c53d0:       b       ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8618             update_sg_lb_stats():
         : 8504             if (local_group)
    0.00 :   ffff8000100c53d4:       mov     w0, #0x4                        // #4
    0.00 :   ffff8000100c53d8:       str     w0, [x19, #56]
         : 8507             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c53dc:       ldr     w0, [sp, #116]
    0.00 :   ffff8000100c53e0:       cbnz    w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 9013             update_sd_pick_busiest():
         : 8533             }
    0.00 :   ffff8000100c53e4:       ldr     w0, [x19, #44]
    0.00 :   ffff8000100c53e8:       cbz     w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8547             */
    0.00 :   ffff8000100c53ec:       add     x20, x26, #0x30
    0.00 :   ffff8000100c53f0:       ldr     w0, [x20, #56]
    0.00 :   ffff8000100c53f4:       cmp     w0, #0x3
    0.00 :   ffff8000100c53f8:       b.ls    ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>  // b.plast
         : 8550             struct sched_group *sg,
    0.00 :   ffff8000100c53fc:       cmp     w0, #0x4
    0.00 :   ffff8000100c5400:       b.eq    ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>  // b.none
    0.00 :   ffff8000100c5404:       nop
    0.00 :   ffff8000100c5408:       ldr     x2, [x19, #8]
    0.00 :   ffff8000100c540c:       mov     x6, x2
    0.00 :   ffff8000100c5410:       b       ffff8000100c5250 <update_sd_lb_stats.constprop.135+0x440>
         : 8557             sched_asym_prefer():
         : 759              }
    0.00 :   ffff8000100c5414:       ldr     w0, [x28, #20]
         : 761              update_sg_lb_stats():
         : 8496             * No need to call idle_cpu() if nr_running is not 0
    0.00 :   ffff8000100c5418:       ldr     w21, [x25, #24]
         : 8498             sched_asym_prefer():
    0.00 :   ffff8000100c541c:       bl      ffff8000100c35e8 <arch_asym_cpu_priority>
    0.00 :   ffff8000100c5420:       mov     w20, w0
    0.00 :   ffff8000100c5424:       mov     w0, w21
    0.00 :   ffff8000100c5428:       bl      ffff8000100c35e8 <arch_asym_cpu_priority>
         : 763              update_sg_lb_stats():
         : 8495             /*
    0.00 :   ffff8000100c542c:       cmp     w20, w0
    0.00 :   ffff8000100c5430:       b.le    ffff8000100c50f0 <update_sd_lb_stats.constprop.135+0x2e0>
         : 8497             */
    0.00 :   ffff8000100c5434:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c5438:       str     w0, [x19, #60]
    0.00 :   ffff8000100c543c:       b       ffff8000100c50f0 <update_sd_lb_stats.constprop.135+0x2e0>
         : 8504             if (local_group)
    0.00 :   ffff8000100c5440:       mov     w0, #0x3                        // #3
    0.00 :   ffff8000100c5444:       str     w0, [x19, #56]
         : 8507             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c5448:       ldr     w0, [sp, #116]
    0.00 :   ffff8000100c544c:       cbnz    w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 9013             update_sd_pick_busiest():
         : 8533             }
    0.00 :   ffff8000100c5450:       ldr     w0, [x19, #44]
    0.00 :   ffff8000100c5454:       cbz     w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8547             */
    0.00 :   ffff8000100c5458:       add     x20, x26, #0x30
    0.00 :   ffff8000100c545c:       ldr     w0, [x20, #56]
    0.00 :   ffff8000100c5460:       cmp     w0, #0x2
    0.00 :   ffff8000100c5464:       b.ls    ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>  // b.plast
         : 8550             struct sched_group *sg,
    0.00 :   ffff8000100c5468:       cmp     w0, #0x3
    0.00 :   ffff8000100c546c:       b.ne    ffff8000100c5408 <update_sd_lb_stats.constprop.135+0x5f8>  // b.any
         : 8574             return false;
    0.00 :   ffff8000100c5470:       ldr     x1, [x26]
         : 8576             sched_asym_prefer():
    0.00 :   ffff8000100c5474:       ldr     w0, [x25, #24]
         : 760              update_sd_pick_busiest():
    0.00 :   ffff8000100c5478:       ldr     w22, [x1, #24]
         : 8575             sched_asym_prefer():
    0.00 :   ffff8000100c547c:       bl      ffff8000100c35e8 <arch_asym_cpu_priority>
    0.00 :   ffff8000100c5480:       mov     w21, w0
    0.00 :   ffff8000100c5484:       mov     w0, w22
    0.00 :   ffff8000100c5488:       bl      ffff8000100c35e8 <arch_asym_cpu_priority>
         : 763              update_sd_pick_busiest():
    0.00 :   ffff8000100c548c:       cmp     w21, w0
    0.00 :   ffff8000100c5490:       b.le    ffff8000100c5374 <update_sd_lb_stats.constprop.135+0x564>
    0.00 :   ffff8000100c5494:       b       ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8577             update_sg_lb_stats():
         : 8504             if (local_group)
    0.00 :   ffff8000100c5498:       mov     w0, #0x2                        // #2
    0.00 :   ffff8000100c549c:       str     w0, [x19, #56]
         : 8507             update_sd_lb_stats():
         : 9010             * @sds: variable to hold the statistics for this sched_domain.
    0.00 :   ffff8000100c54a0:       ldr     w0, [sp, #116]
    0.00 :   ffff8000100c54a4:       cbnz    w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 9013             update_sd_pick_busiest():
         : 8533             }
    0.00 :   ffff8000100c54a8:       ldr     w0, [x19, #44]
    0.00 :   ffff8000100c54ac:       cbz     w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8536             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c54b0:       ldrsw   x2, [x28, #20]
    0.00 :   ffff8000100c54b4:       adrp    x0, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c54b8:       add     x0, x0, #0x760
    0.00 :   ffff8000100c54bc:       mov     x6, x23
         : 5769             update_sd_pick_busiest():
         : 8543             * busiest group.
    0.00 :   ffff8000100c54c0:       ldr     x9, [x25, #16]
         : 8545             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c54c4:       ldr     x2, [x0, x2, lsl #3]
         : 5766             update_sd_pick_busiest():
         : 8543             * busiest group.
    0.00 :   ffff8000100c54c8:       mov     x8, #0x436                      // #1078
    0.00 :   ffff8000100c54cc:       ldr     x0, [x9, #24]
         : 8546             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c54d0:       add     x2, x2, x6
         : 5766             update_sd_pick_busiest():
         : 8543             * busiest group.
    0.00 :   ffff8000100c54d4:       ldr     x2, [x2, #2480]
    0.00 :   ffff8000100c54d8:       mul     x0, x0, x8
         : 8542             * Determine if @sg is a busier group than the previously selected
    0.00 :   ffff8000100c54dc:       cmp     x0, x2, lsl #10
    0.00 :   ffff8000100c54e0:       b.cs    ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>  // b.hs, b.nlast
         : 8543             * busiest group.
    0.00 :   ffff8000100c54e4:       ldr     w0, [x26, #184]
    0.00 :   ffff8000100c54e8:       cbnz    w0, ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8547             */
    0.00 :   ffff8000100c54ec:       add     x20, x26, #0x30
    0.00 :   ffff8000100c54f0:       ldr     w0, [x20, #56]
    0.00 :   ffff8000100c54f4:       cmp     w0, #0x1
    0.00 :   ffff8000100c54f8:       b.ls    ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>  // b.plast
         : 8550             struct sched_group *sg,
    0.00 :   ffff8000100c54fc:       cmp     w0, #0x2
    0.00 :   ffff8000100c5500:       b.ne    ffff8000100c5408 <update_sd_lb_stats.constprop.135+0x5f8>  // b.any
         : 8583             /* Select the overloaded group with highest avg_load. */
    0.00 :   ffff8000100c5504:       ldr     x0, [x20, #64]
    0.00 :   ffff8000100c5508:       cmp     x1, x0
    0.00 :   ffff8000100c550c:       b.cs    ffff8000100c5220 <update_sd_lb_stats.constprop.135+0x410>  // b.hs, b.nlast
    0.00 :   ffff8000100c5510:       b       ffff8000100c524c <update_sd_lb_stats.constprop.135+0x43c>
         : 8588             update_sd_lb_stats():
         : 9044             }
    0.00 :   ffff8000100c5514:       ldr     x0, [x28, #24]
         : 9046             next_group:
    0.00 :   ffff8000100c5518:       mov     w1, #0x2                        // #2
         : 9044             }
    0.00 :   ffff8000100c551c:       ldr     x0, [x0, #2464]
         : 9046             next_group:
    0.00 :   ffff8000100c5520:       str     w1, [x0, #92]
         : 9047             /* Now, start updating sd_lb_stats */
    0.00 :   ffff8000100c5524:       b       ffff8000100c52d8 <update_sd_lb_stats.constprop.135+0x4c8>
         : 9035             update_sg_lb_stats(env, sg, sgs, &sg_status);
    0.00 :   ffff8000100c5528:       ldr     x1, [x28, #24]
         : 9038             goto next_group;
    0.00 :   ffff8000100c552c:       and     w4, w27, #0x1
         : 9035             update_sg_lb_stats(env, sg, sgs, &sg_status);
    0.00 :   ffff8000100c5530:       ldr     x1, [x1, #2464]
         : 9038             goto next_group;
    0.00 :   ffff8000100c5534:       str     w4, [x1, #88]
         : 9041             if (update_sd_pick_busiest(env, sds, sg, sgs)) {
    0.00 :   ffff8000100c5538:       str     w0, [x1, #92]
         : 9042             sds->busiest = sg;
    0.00 :   ffff8000100c553c:       b       ffff8000100c52d8 <update_sd_lb_stats.constprop.135+0x4c8>
         : 9049             sds->total_capacity += sgs->group_capacity;
    0.00 :   ffff8000100c5540:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (29 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001083fb78 <test_mapsingle.constprop.6>:
         : 6                test_mapsingle():
   14.19 :   ffff80001083fb78:       paciasp
    7.04 :   ffff80001083fb7c:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff80001083fb80:       mov     x29, sp
    3.55 :   ffff80001083fb84:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001083fb88:       mov     x19, x1
    0.00 :   ffff80001083fb8c:       mov     x20, x0
         : 48               dma_map_single_attrs():
         :
         : 319              static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,
         : 320              size_t size, enum dma_data_direction dir, unsigned long attrs)
         : 321              {
         : 322              /* DMA must never operate on areas that might be remapped. */
         : 323              if (dev_WARN_ONCE(dev, is_vmalloc_addr(ptr),
    0.00 :   ffff80001083fb90:       mov     x0, x1
    3.52 :   ffff80001083fb94:       bl      ffff8000101d0ab0 <is_vmalloc_addr>
    3.57 :   ffff80001083fb98:       tst     w0, #0xff
    0.00 :   ffff80001083fb9c:       b.ne    ffff80001083fbdc <test_mapsingle.constprop.6+0x64>  // b.any
         : 322              "rejecting DMA map of vmalloc memory\n"))
         : 323              return DMA_MAPPING_ERROR;
         : 324              debug_dma_map_single(dev, ptr, size);
         : 325              return dma_map_page_attrs(dev, virt_to_page(ptr), offset_in_page(ptr),
    4.59 :   ffff80001083fba0:       mov     x3, #0x1000000000000            // #281474976710656
    0.00 :   ffff80001083fba4:       add     x3, x19, x3
    0.00 :   ffff80001083fba8:       mov     x1, #0xfffffc0000000000         // #-4398046511104
    0.00 :   ffff80001083fbac:       mov     x0, x20
   28.27 :   ffff80001083fbb0:       lsr     x3, x3, #12
    0.00 :   ffff80001083fbb4:       and     x2, x19, #0xfff
    0.00 :   ffff80001083fbb8:       mov     x5, #0x0                        // #0
    0.00 :   ffff80001083fbbc:       mov     w4, #0x1                        // #1
    0.00 :   ffff80001083fbc0:       add     x1, x1, x3, lsl #6
    0.00 :   ffff80001083fbc4:       mov     x3, #0x1000                     // #4096
    0.00 :   ffff80001083fbc8:       bl      ffff800010105168 <dma_map_page_attrs>
         : 337              test_mapsingle():
   10.58 :   ffff80001083fbcc:       ldp     x19, x20, [sp, #16]
   14.08 :   ffff80001083fbd0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001083fbd4:       autiasp
   10.61 :   ffff80001083fbd8:       ret
         : 50               dma_map_single_attrs():
         : 318              if (dev_WARN_ONCE(dev, is_vmalloc_addr(ptr),
    0.00 :   ffff80001083fbdc:       adrp    x1, ffff800011efe000 <errmap+0xc38>
         : 320              return DMA_MAPPING_ERROR;
    0.00 :   ffff80001083fbe0:       mov     x0, #0xffffffffffffffff         // #-1
         : 318              if (dev_WARN_ONCE(dev, is_vmalloc_addr(ptr),
    0.00 :   ffff80001083fbe4:       ldrb    w2, [x1, #2984]
    0.00 :   ffff80001083fbe8:       cbnz    w2, ffff80001083fbcc <test_mapsingle.constprop.6+0x54>
    0.00 :   ffff80001083fbec:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001083fbf0:       mov     x0, x20
    0.00 :   ffff80001083fbf4:       strb    w2, [x1, #2984]
    0.00 :   ffff80001083fbf8:       bl      ffff800010797610 <dev_driver_string>
         : 325              dev_name():
         : 611              struct kref kref;
         : 612              struct work_struct rm_work;
         : 613              bool supplier_preactivated; /* Owned by consumer probe. */
         : 614              };
         :
         : 616              static inline struct device *kobj_to_dev(struct kobject *kobj)
    0.00 :   ffff80001083fbfc:       ldr     x2, [x20, #80]
    0.00 :   ffff80001083fc00:       cbnz    x2, ffff80001083fc08 <test_mapsingle.constprop.6+0x90>
         : 614              {
         : 615              return container_of(kobj, struct device, kobj);
         : 616              }
    0.00 :   ffff80001083fc04:       ldr     x2, [x20]
         : 618              dma_map_single_attrs():
    0.00 :   ffff80001083fc08:       mov     x1, x0
    0.00 :   ffff80001083fc0c:       adrp    x0, ffff800011480000 <kallsyms_token_index+0x757a0>
    0.00 :   ffff80001083fc10:       add     x0, x0, #0x178
    0.00 :   ffff80001083fc14:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff80001083fc18:       brk     #0x800
         : 320              return DMA_MAPPING_ERROR;
    0.00 :   ffff80001083fc1c:       mov     x0, #0xffffffffffffffff         // #-1
    0.00 :   ffff80001083fc20:       b       ffff80001083fbcc <test_mapsingle.constprop.6+0x54>
 Percent |	Source code & Disassembly of vmlinux for cycles (26 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077e290 <arm_smmu_cmdq_batch_add>:
         : 6                arm_smmu_cmdq_batch_add():
         : 1202             struct arm_smmu_s1_cfg *s1_cfg = NULL;
         : 1203             struct arm_smmu_s2_cfg *s2_cfg = NULL;
         : 1204             struct arm_smmu_domain *smmu_domain = NULL;
         : 1205             struct arm_smmu_cmdq_ent prefetch_cmd = {
         : 1206             .opcode         = CMDQ_OP_PREFETCH_CFG,
         : 1207             .prefetch       = {
   11.48 :   ffff80001077e290:       paciasp
    0.00 :   ffff80001077e294:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff80001077e298:       mov     x29, sp
    0.00 :   ffff80001077e29c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001077e2a0:       mov     x20, x2
    0.00 :   ffff80001077e2a4:       mov     x19, x1
         : 1203             .sid    = sid,
   26.97 :   ffff80001077e2a8:       ldr     w2, [x1, #1024]
    0.00 :   ffff80001077e2ac:       cmp     w2, #0x40
    0.00 :   ffff80001077e2b0:       b.eq    ffff80001077e2e0 <arm_smmu_cmdq_batch_add+0x50>  // b.none
    7.69 :   ffff80001077e2b4:       lsl     w2, w2, #1
    0.00 :   ffff80001077e2b8:       add     x0, x1, w2, sxtw #3
         : 1207             },
         : 1208             };
         :
         : 1210             if (master) {
    0.00 :   ffff80001077e2bc:       mov     x1, x20
    0.00 :   ffff80001077e2c0:       bl      ffff80001077b418 <arm_smmu_cmdq_build_cmd>
         : 1208             smmu_domain = master->domain;
    0.00 :   ffff80001077e2c4:       ldr     w0, [x19, #1024]
    0.00 :   ffff80001077e2c8:       add     w0, w0, #0x1
    0.00 :   ffff80001077e2cc:       str     w0, [x19, #1024]
         : 1209             smmu = master->smmu;
   26.87 :   ffff80001077e2d0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001077e2d4:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001077e2d8:       autiasp
   26.99 :   ffff80001077e2dc:       ret
         : 1204             },
    0.00 :   ffff80001077e2e0:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001077e2e4:       bl      ffff80001077c908 <arm_smmu_cmdq_issue_cmdlist>
         : 1205             };
    0.00 :   ffff80001077e2e8:       mov     x0, x19
    0.00 :   ffff80001077e2ec:       str     wzr, [x19, #1024]
    0.00 :   ffff80001077e2f0:       b       ffff80001077e2bc <arm_smmu_cmdq_batch_add+0x2c>
 Percent |	Source code & Disassembly of vmlinux for cycles (24 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010782e40 <iommu_unmap_fast>:
         : 6                iommu_unmap_fast():
         : 2561             struct iommu_iotlb_gather iotlb_gather;
         : 2562             size_t ret;
         :
         : 2564             iommu_iotlb_gather_init(&iotlb_gather);
         : 2565             ret = __iommu_unmap(domain, iova, size, &iotlb_gather);
         : 2566             iommu_iotlb_sync(domain, &iotlb_gather);
    4.17 :   ffff800010782e40:       paciasp
    8.34 :   ffff800010782e44:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010782e48:       mov     x29, sp
         :
    0.00 :   ffff800010782e4c:       bl      ffff800010782c90 <__iommu_unmap>
         : 2563             return ret;
    0.00 :   ffff800010782e50:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010782e54:       autiasp
   87.50 :   ffff800010782e58:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (24 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010168418 <perf_poll>:
         : 6                perf_poll():
         : 5389             ctx = perf_event_ctx_lock(event);
         : 5390             ret = __perf_read(event, buf, count);
         : 5391             perf_event_ctx_unlock(event, ctx);
         :
         : 5393             return ret;
         : 5394             }
    0.00 :   ffff800010168418:       paciasp
    0.00 :   ffff80001016841c:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010168420:       mov     x29, sp
    0.00 :   ffff800010168424:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010168428:       str     x21, [sp, #32]
         :
    0.00 :   ffff80001016842c:       ldr     x19, [x0, #200]
         : 5392             poll_wait():
         : 50               __poll_t _key;
         : 51               } poll_table;
         :
         : 53               static inline void poll_wait(struct file * filp, wait_queue_head_t * wait_address, poll_table *p)
         : 54               {
         : 55               if (p && p->_qproc && wait_address)
    0.00 :   ffff800010168430:       cbz     x1, ffff800010168444 <perf_poll+0x2c>
    0.00 :   ffff800010168434:       ldr     x3, [x1]
    0.00 :   ffff800010168438:       adds    x4, x19, #0x2f0
    0.00 :   ffff80001016843c:       ccmp    x3, #0x0, #0x4, ne  // ne = any
    0.00 :   ffff800010168440:       b.ne    ffff8000101684a4 <perf_poll+0x8c>  // b.any
         : 61               is_event_hup():
         : 5332             {
    0.00 :   ffff800010168444:       ldr     w0, [x19, #168]
    0.00 :   ffff800010168448:       cmn     w0, #0x2
    0.00 :   ffff80001016844c:       b.lt    ffff8000101684bc <perf_poll+0xa4>  // b.tstop
         : 5336             perf_poll():
         :
         : 5404             if (is_event_hup(event))
         : 5405             return events;
         :
         : 5407             /*
         : 5408             * Pin the event->rb by taking event->mmap_mutex; otherwise
   16.24 :   ffff800010168450:       add     x21, x19, #0x2a0
         : 5392             {
    0.00 :   ffff800010168454:       mov     w20, #0x10                      // #16
         : 5403             * Pin the event->rb by taking event->mmap_mutex; otherwise
    0.00 :   ffff800010168458:       mov     x0, x21
    0.00 :   ffff80001016845c:       bl      ffff800010e304e0 <mutex_lock>
         : 5404             * perf_event_set_output() can swizzle our rb and make us miss wakeups.
    0.00 :   ffff800010168460:       ldr     x0, [x19, #712]
         : 5405             */
    0.00 :   ffff800010168464:       cbz     x0, ffff800010168484 <perf_poll+0x6c>
         : 5407             __xchg_case_mb_32():
         : 59               __XCHG_CASE(w, h, rel_, 16,        ,    ,  ,  , l, "memory")
         : 60               __XCHG_CASE(w,  , rel_, 32,        ,    ,  ,  , l, "memory")
         : 61               __XCHG_CASE( ,  , rel_, 64,        ,    ,  ,  , l, "memory")
         : 62               __XCHG_CASE(w, b,  mb_,  8, dmb ish, nop,  , a, l, "memory")
         : 63               __XCHG_CASE(w, h,  mb_, 16, dmb ish, nop,  , a, l, "memory")
         : 64               __XCHG_CASE(w,  ,  mb_, 32, dmb ish, nop,  , a, l, "memory")
   16.94 :   ffff800010168468:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001016846c:       add     x0, x0, #0x24
    0.00 :   ffff800010168470:       prfm    pstl1strm, [x0]
   66.81 :   ffff800010168474:       ldxr    w20, [x0]
    0.00 :   ffff800010168478:       stlxr   w2, w1, [x0]
    0.00 :   ffff80001016847c:       cbnz    w2, ffff800010168474 <perf_poll+0x5c>
    0.00 :   ffff800010168480:       dmb     ish
         : 72               perf_poll():
         : 5407             mutex_lock(&event->mmap_mutex);
         : 5408             rb = event->rb;
    0.00 :   ffff800010168484:       mov     x0, x21
    0.00 :   ffff800010168488:       bl      ffff800010e2fe60 <mutex_unlock>
         : 5409             if (rb)
         : 5410             events = atomic_xchg(&rb->poll, 0);
    0.00 :   ffff80001016848c:       mov     w0, w20
    0.00 :   ffff800010168490:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010168494:       ldr     x21, [sp, #32]
    0.00 :   ffff800010168498:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001016849c:       autiasp
    0.00 :   ffff8000101684a0:       ret
         : 5417             poll_wait():
         : 51               p->_qproc(filp, wait_address, p);
    0.00 :   ffff8000101684a4:       mov     x2, x1
    0.00 :   ffff8000101684a8:       mov     x1, x4
    0.00 :   ffff8000101684ac:       blr     x3
         : 55               is_event_hup():
         : 5332             {
    0.00 :   ffff8000101684b0:       ldr     w0, [x19, #168]
    0.00 :   ffff8000101684b4:       cmn     w0, #0x2
    0.00 :   ffff8000101684b8:       b.ge    ffff800010168450 <perf_poll+0x38>  // b.tcont
         : 5335             if (event->state > PERF_EVENT_STATE_EXIT)
    0.00 :   ffff8000101684bc:       add     x21, x19, #0x248
         : 5337             perf_poll():
         : 5397             poll_wait(file, &event->waitq, wait);
    0.00 :   ffff8000101684c0:       mov     w20, #0x10                      // #16
         : 5399             is_event_hup():
         : 5335             if (event->state > PERF_EVENT_STATE_EXIT)
    0.00 :   ffff8000101684c4:       mov     x0, x21
    0.00 :   ffff8000101684c8:       bl      ffff800010e304e0 <mutex_lock>
         :
    0.00 :   ffff8000101684cc:       mov     x0, x21
         : 5339             list_empty():
         : 282              * list_empty - tests whether a list is empty
         : 283              * @head: the list to test.
         : 284              */
         : 285              static inline int list_empty(const struct list_head *head)
         : 286              {
         : 287              return READ_ONCE(head->next) == head;
    0.00 :   ffff8000101684d0:       ldr     x21, [x19, #616]
         : 289              is_event_hup():
    0.00 :   ffff8000101684d4:       bl      ffff800010e2fe60 <mutex_unlock>
         : 5336             return false;
    0.00 :   ffff8000101684d8:       add     x0, x19, #0x268
         : 5338             perf_poll():
         :
    0.00 :   ffff8000101684dc:       cmp     x21, x0
    0.00 :   ffff8000101684e0:       b.ne    ffff800010168450 <perf_poll+0x38>  // b.any
         : 5409             events = atomic_xchg(&rb->poll, 0);
    0.00 :   ffff8000101684e4:       mov     w0, w20
    0.00 :   ffff8000101684e8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101684ec:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101684f0:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101684f4:       autiasp
    0.00 :   ffff8000101684f8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (21 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001083fb30 <test_memcpy.constprop.5>:
         : 6                test_memcpy():
   71.35 :   ffff80001083fb30:       paciasp
    0.00 :   ffff80001083fb34:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001083fb38:       mov     x2, #0x1000                     // #4096
    0.00 :   ffff80001083fb3c:       mov     x29, sp
    0.00 :   ffff80001083fb40:       bl      ffff8000104a5b40 <__memcpy>
    0.00 :   ffff80001083fb44:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001083fb48:       autiasp
   28.65 :   ffff80001083fb4c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (20 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010782ff8 <_iommu_map>:
         : 6                _iommu_map():
         : 2464             size -= pgsize;
         : 2465             }
         :
         : 2467             /* unroll mapping in case something went wrong */
         : 2468             if (ret)
         : 2469             iommu_unmap(domain, orig_iova, orig_size - size);
    0.00 :   ffff800010782ff8:       paciasp
    9.99 :   ffff800010782ffc:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010783000:       mov     x29, sp
    0.00 :   ffff800010783004:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010783008:       mov     x20, x0
    0.00 :   ffff80001078300c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010783010:       mov     x22, x1
    0.00 :   ffff800010783014:       str     x23, [sp, #48]
    0.00 :   ffff800010783018:       mov     x23, x3
         : 2465             else
    0.00 :   ffff80001078301c:       ldr     x21, [x0, #8]
         : 2468             trace_map(orig_iova, orig_paddr, orig_size);
         :
         : 2470             return ret;
    0.00 :   ffff800010783020:       bl      ffff800010782e60 <__iommu_map>
    5.01 :   ffff800010783024:       mov     w19, w0
         : 2469             }
    0.00 :   ffff800010783028:       cbnz    w0, ffff800010783044 <_iommu_map+0x4c>
   10.01 :   ffff80001078302c:       ldr     x3, [x21, #64]
    0.00 :   ffff800010783030:       cbz     x3, ffff800010783044 <_iommu_map+0x4c>
         :
    0.00 :   ffff800010783034:       mov     x2, x23
    0.00 :   ffff800010783038:       mov     x1, x22
    0.00 :   ffff80001078303c:       mov     x0, x20
    0.00 :   ffff800010783040:       blr     x3
         : 2473             static int _iommu_map(struct iommu_domain *domain, unsigned long iova,
         : 2474             phys_addr_t paddr, size_t size, int prot, gfp_t gfp)
         : 2475             {
   10.00 :   ffff800010783044:       mov     w0, w19
   29.90 :   ffff800010783048:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001078304c:       ldp     x21, x22, [sp, #32]
    4.98 :   ffff800010783050:       ldr     x23, [sp, #48]
    0.00 :   ffff800010783054:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010783058:       autiasp
   30.12 :   ffff80001078305c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (18 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010783080 <iommu_map_atomic>:
         : 6                iommu_map_atomic():
         :
         : 2486             return ret;
         : 2487             }
         :
         : 2489             int iommu_map(struct iommu_domain *domain, unsigned long iova,
         : 2490             phys_addr_t paddr, size_t size, int prot)
    0.00 :   ffff800010783080:       paciasp
    0.00 :   ffff800010783084:       stp     x29, x30, [sp, #-16]!
         : 2486             {
    0.00 :   ffff800010783088:       mov     w5, #0xa20                      // #2592
         : 2485             phys_addr_t paddr, size_t size, int prot)
    0.00 :   ffff80001078308c:       mov     x29, sp
         : 2486             {
    0.00 :   ffff800010783090:       bl      ffff800010782ff8 <_iommu_map>
         : 2487             might_sleep();
    0.00 :   ffff800010783094:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010783098:       autiasp
  100.00 :   ffff80001078309c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (17 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001083fb50 <test_unmapsingle.isra.4.constprop.7>:
         : 6                test_unmapsingle():
   11.78 :   ffff80001083fb50:       paciasp
   23.53 :   ffff80001083fb54:       stp     x29, x30, [sp, #-16]!
         : 50               dma_unmap_single_attrs():
         : 329              }
         :
         : 331              static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,
         : 332              size_t size, enum dma_data_direction dir, unsigned long attrs)
         : 333              {
         : 334              return dma_unmap_page_attrs(dev, addr, size, dir, attrs);
    0.00 :   ffff80001083fb58:       mov     x4, #0x0                        // #0
         : 336              test_unmapsingle():
    0.00 :   ffff80001083fb5c:       mov     x29, sp
         : 49               dma_unmap_single_attrs():
    0.00 :   ffff80001083fb60:       mov     w3, #0x1                        // #1
    0.00 :   ffff80001083fb64:       mov     x2, #0x1000                     // #4096
    0.00 :   ffff80001083fb68:       bl      ffff800010105e70 <dma_unmap_page_attrs>
         : 332              test_unmapsingle():
    0.00 :   ffff80001083fb6c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001083fb70:       autiasp
   64.70 :   ffff80001083fb74:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (15 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077b338 <arm_smmu_iova_to_phys>:
         : 6                arm_smmu_iova_to_phys():
         : 2680             .pgsize_bitmap          = -1UL, /* Restricted during device attach */
         : 2681             .owner                  = THIS_MODULE,
         : 2682             };
         :
         : 2684             /* Probing and initialisation functions */
         : 2685             static int arm_smmu_init_one_queue(struct arm_smmu_device *smmu,
    0.00 :   ffff80001077b338:       ldr     w3, [x0]
    0.00 :   ffff80001077b33c:       cmp     w3, #0x4
    0.00 :   ffff80001077b340:       b.eq    ffff80001077b36c <arm_smmu_iova_to_phys+0x34>  // b.none
         :
   33.29 :   ffff80001077b344:       ldur    x0, [x0, #-104]
         : 2683             struct arm_smmu_queue *q,
         : 2684             void __iomem *page,
         : 2685             unsigned long prod_off,
    0.00 :   ffff80001077b348:       cbz     x0, ffff80001077b374 <arm_smmu_iova_to_phys+0x3c>
         : 2677             };
    0.00 :   ffff80001077b34c:       paciasp
   46.66 :   ffff80001077b350:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001077b354:       mov     x29, sp
         : 2686             unsigned long cons_off,
         : 2687             size_t dwords, const char *name)
         : 2688             {
    0.00 :   ffff80001077b358:       ldr     x2, [x0, #16]
    0.00 :   ffff80001077b35c:       blr     x2
         : 2687             size_t qsz;
    0.00 :   ffff80001077b360:       ldp     x29, x30, [sp], #16
    6.71 :   ffff80001077b364:       autiasp
   13.34 :   ffff80001077b368:       ret
         : 2681             struct arm_smmu_queue *q,
    0.00 :   ffff80001077b36c:       mov     x0, x1
    0.00 :   ffff80001077b370:       ret
         : 2684             unsigned long cons_off,
    0.00 :   ffff80001077b374:       mov     x0, #0x0                        // #0
         : 2687             size_t qsz;
    0.00 :   ffff80001077b378:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (14 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e304e0 <mutex_lock>:
         : 6                mutex_lock():
         : 280              * deadlock debugging)
         : 281              *
         : 282              * This function is similar to (but not equivalent to) down().
         : 283              */
         : 284              void __sched mutex_lock(struct mutex *lock)
         : 285              {
    0.00 :   ffff800010e304e0:       paciasp
    0.00 :   ffff800010e304e4:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e304e8:       mov     x3, x0
    0.00 :   ffff800010e304ec:       mov     x29, sp
         : 290              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e304f0:       mrs     x2, sp_el0
         : 26               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e304f4:       b       ffff800010e30524 <mutex_lock+0x44>
    0.00 :   ffff800010e304f8:       b       ffff800010e30524 <mutex_lock+0x44>
         : 46               __lse__cmpxchg_case_acq_64():
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
         : 372              __CMPXCHG_CASE(x,  ,     , 64,   )
         : 373              __CMPXCHG_CASE(w, b, acq_,  8,  a, "memory")
         : 374              __CMPXCHG_CASE(w, h, acq_, 16,  a, "memory")
         : 375              __CMPXCHG_CASE(w,  , acq_, 32,  a, "memory")
         : 376              __CMPXCHG_CASE(x,  , acq_, 64,  a, "memory")
    0.00 :   ffff800010e304fc:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010e30500:       mov     x4, x1
    0.00 :   ffff800010e30504:       casa    x4, x2, [x0]
  100.00 :   ffff800010e30508:       mov     x0, x4
         : 381              __mutex_trylock_fast():
         : 161              if (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))
    0.00 :   ffff800010e3050c:       cbz     x0, ffff800010e30518 <mutex_lock+0x38>
    0.00 :   ffff800010e30510:       mov     x0, x3
         : 164              mutex_lock():
         : 284              might_sleep();
         :
         : 286              if (!__mutex_trylock_fast(lock))
         : 287              __mutex_lock_slowpath(lock);
    0.00 :   ffff800010e30514:       bl      ffff800010e304c0 <__mutex_lock_slowpath>
         : 285              }
    0.00 :   ffff800010e30518:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e3051c:       autiasp
    0.00 :   ffff800010e30520:       ret
         : 289              __ll_sc__cmpxchg_case_acq_64():
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
         : 307              __CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
         : 308              __CMPXCHG_CASE(w, b, acq_,  8,        , a,  , "memory", K)
         : 309              __CMPXCHG_CASE(w, h, acq_, 16,        , a,  , "memory", K)
         : 310              __CMPXCHG_CASE(w,  , acq_, 32,        , a,  , "memory", K)
         : 311              __CMPXCHG_CASE( ,  , acq_, 64,        , a,  , "memory", L)
    0.00 :   ffff800010e30524:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010e30528:       b       ffff800010e31070 <ww_mutex_lock_interruptible+0x1b8>
    0.00 :   ffff800010e3052c:       b       ffff800010e3050c <mutex_lock+0x2c>
 Percent |	Source code & Disassembly of vmlinux for cycles (12 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077b308 <arm_smmu_unmap>:
         : 6                arm_smmu_unmap():
         : 2646             return -EINVAL;
         :
         : 2648             switch (feat) {
         : 2649             case IOMMU_DEV_FEAT_SVA:
         : 2650             return arm_smmu_master_disable_sva(dev_iommu_priv_get(dev));
         : 2651             default:
    8.39 :   ffff80001077b308:       ldur    x0, [x0, #-104]
         : 2648             return -EINVAL;
         : 2649             }
    0.00 :   ffff80001077b30c:       cbz     x0, ffff80001077b330 <arm_smmu_unmap+0x28>
         : 2644             case IOMMU_DEV_FEAT_SVA:
   58.19 :   ffff80001077b310:       paciasp
   25.11 :   ffff80001077b314:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001077b318:       mov     x29, sp
         : 2651             }
         :
         : 2653             static struct iommu_ops arm_smmu_ops = {
    0.00 :   ffff80001077b31c:       ldr     x4, [x0, #8]
    0.00 :   ffff80001077b320:       blr     x4
         : 2652             .capable                = arm_smmu_capable,
    0.00 :   ffff80001077b324:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001077b328:       autiasp
    8.32 :   ffff80001077b32c:       ret
         : 2649             }
    0.00 :   ffff80001077b330:       mov     x0, #0x0                        // #0
         : 2652             .capable                = arm_smmu_capable,
    0.00 :   ffff80001077b334:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (12 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e2fe60 <mutex_unlock>:
         : 6                mutex_unlock():
         : 735              * of a not locked mutex is not allowed.
         : 736              *
         : 737              * This function is similar to (but not equivalent to) up().
         : 738              */
         : 739              void __sched mutex_unlock(struct mutex *lock)
         : 740              {
    8.48 :   ffff800010e2fe60:       paciasp
    0.00 :   ffff800010e2fe64:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e2fe68:       mov     x3, x0
    0.00 :   ffff800010e2fe6c:       mov     x29, sp
         : 745              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e2fe70:       mrs     x4, sp_el0
         : 26               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e2fe74:       b       ffff800010e2fe94 <mutex_unlock+0x34>
    0.00 :   ffff800010e2fe78:       b       ffff800010e2fe94 <mutex_unlock+0x34>
         : 46               __lse__cmpxchg_case_rel_64():
         : 375              __CMPXCHG_CASE(w,  , acq_, 32,  a, "memory")
         : 376              __CMPXCHG_CASE(x,  , acq_, 64,  a, "memory")
         : 377              __CMPXCHG_CASE(w, b, rel_,  8,  l, "memory")
         : 378              __CMPXCHG_CASE(w, h, rel_, 16,  l, "memory")
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
    0.00 :   ffff800010e2fe7c:       mov     x2, #0x0                        // #0
    0.00 :   ffff800010e2fe80:       mov     x1, x4
    0.00 :   ffff800010e2fe84:       mov     x5, x1
    0.00 :   ffff800010e2fe88:       casl    x5, x2, [x0]
   91.52 :   ffff800010e2fe8c:       mov     x0, x5
    0.00 :   ffff800010e2fe90:       b       ffff800010e2fe9c <mutex_unlock+0x3c>
         : 387              __ll_sc__cmpxchg_case_rel_64():
         : 310              __CMPXCHG_CASE(w,  , acq_, 32,        , a,  , "memory", K)
         : 311              __CMPXCHG_CASE( ,  , acq_, 64,        , a,  , "memory", L)
         : 312              __CMPXCHG_CASE(w, b, rel_,  8,        ,  , l, "memory", K)
         : 313              __CMPXCHG_CASE(w, h, rel_, 16,        ,  , l, "memory", K)
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
    0.00 :   ffff800010e2fe94:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010e2fe98:       b       ffff800010e30f60 <ww_mutex_lock_interruptible+0xa8>
         : 318              __mutex_unlock_fast():
         : 171              if (atomic_long_cmpxchg_release(&lock->owner, curr, 0UL) == curr)
    0.00 :   ffff800010e2fe9c:       cmp     x4, x0
    0.00 :   ffff800010e2fea0:       b.eq    ffff800010e2feac <mutex_unlock+0x4c>  // b.none
    0.00 :   ffff800010e2fea4:       mov     x0, x3
         : 175              mutex_unlock():
         : 740              #ifndef CONFIG_DEBUG_LOCK_ALLOC
         : 741              if (__mutex_unlock_fast(lock))
         : 742              return;
         : 743              #endif
         : 744              __mutex_unlock_slowpath(lock, _RET_IP_);
    0.00 :   ffff800010e2fea8:       bl      ffff800010e2fce0 <__mutex_unlock_slowpath.isra.24>
         : 741              }
    0.00 :   ffff800010e2feac:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e2feb0:       autiasp
    0.00 :   ffff800010e2feb4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (11 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001077b2d8 <arm_smmu_map>:
         : 6                arm_smmu_map():
         : 2634             switch (feat) {
         : 2635             case IOMMU_DEV_FEAT_SVA:
         : 2636             return arm_smmu_master_enable_sva(dev_iommu_priv_get(dev));
         : 2637             default:
         : 2638             return -EINVAL;
         : 2639             }
    0.00 :   ffff80001077b2d8:       ldur    x0, [x0, #-104]
         : 2636             }
         :
    0.00 :   ffff80001077b2dc:       cbz     x0, ffff80001077b300 <arm_smmu_map+0x28>
         : 2633             return -EINVAL;
   54.59 :   ffff80001077b2e0:       paciasp
    0.00 :   ffff80001077b2e4:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001077b2e8:       mov     x29, sp
         : 2639             static int arm_smmu_dev_disable_feature(struct device *dev,
         : 2640             enum iommu_dev_features feat)
         : 2641             {
    0.00 :   ffff80001077b2ec:       ldr     x6, [x0]
    0.00 :   ffff80001077b2f0:       blr     x6
         : 2640             if (!arm_smmu_dev_feature_enabled(dev, feat))
    0.00 :   ffff80001077b2f4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001077b2f8:       autiasp
   45.41 :   ffff80001077b2fc:       ret
         : 2637             static int arm_smmu_dev_disable_feature(struct device *dev,
    0.00 :   ffff80001077b300:       mov     w0, #0xffffffed                 // #-19
         : 2640             if (!arm_smmu_dev_feature_enabled(dev, feat))
    0.00 :   ffff80001077b304:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (7 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010466c08 <iov_iter_fault_in_readable>:
         : 6                iov_iter_fault_in_readable():
         :
         : 480              if (unlikely(!len))
         : 481              continue;
         : 482              err = fault_in_pages_writeable(p->iov_base + skip, len);
         : 483              if (unlikely(err))
         : 484              return err;
    0.00 :   ffff800010466c08:       ldr     w2, [x0]
    0.00 :   ffff800010466c0c:       tst     w2, #0x18
    0.00 :   ffff800010466c10:       b.ne    ffff800010466d2c <iov_iter_fault_in_readable+0x124>  // b.any
         : 480              bytes -= len;
    0.00 :   ffff800010466c14:       ldr     x10, [x0, #24]
         : 473              int err;
    0.00 :   ffff800010466c18:       paciasp
    9.69 :   ffff800010466c1c:       sub     sp, sp, #0x10
         :
    0.00 :   ffff800010466c20:       ldr     x2, [x0, #8]
         : 480              bytes -= len;
    0.00 :   ffff800010466c24:       ldr     x3, [x10, #8]
    0.00 :   ffff800010466c28:       sub     x3, x3, x2
    0.00 :   ffff800010466c2c:       cmp     x3, x1
    0.00 :   ffff800010466c30:       csel    x3, x3, x1, ls  // ls = plast
    0.00 :   ffff800010466c34:       cbz     x3, ffff800010466ce4 <iov_iter_fault_in_readable+0xdc>
    0.00 :   ffff800010466c38:       ldr     x0, [x10]
         : 481              fault_in_pages_readable():
         : 764              }
         :
         : 766              static inline int fault_in_pages_readable(const char __user *uaddr, int size)
         : 767              {
         : 768              volatile char c;
         : 769              const char __user *end = uaddr + size - 1;
    0.00 :   ffff800010466c3c:       sxtw    x4, w3
    0.00 :   ffff800010466c40:       sub     x4, x4, #0x1
         : 772              iov_iter_fault_in_readable():
    0.00 :   ffff800010466c44:       add     x0, x0, x2
         : 481              fault_in_pages_readable():
    0.00 :   ffff800010466c48:       add     x4, x0, x4
         :
         : 767              if (unlikely(size == 0))
    0.00 :   ffff800010466c4c:       cbz     w3, ffff800010466ce0 <iov_iter_fault_in_readable+0xd8>
         : 769              return 0;
         :
         : 771              if (unlikely(uaddr > end))
    0.00 :   ffff800010466c50:       cmp     x0, x4
    0.00 :   ffff800010466c54:       lsl     x5, x0, #8
         : 774              __range_ok():
         : 51               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
         : 52               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
         : 53               addr = untagged_addr(addr);
         :
         : 55               __chk_user_ptr(addr);
         : 56               asm volatile(
    0.00 :   ffff800010466c58:       mov     x8, #0xffffffffffff             // #281474976710655
         : 58               fault_in_pages_readable():
         : 773              return -EFAULT;
         :
         : 775              do {
         : 776              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466c5c:       mov     w11, #0x0                       // #0
         : 769              if (unlikely(uaddr > end))
    0.00 :   ffff800010466c60:       b.hi    ffff800010466d34 <iov_iter_fault_in_readable+0x12c>  // b.pmore
    0.00 :   ffff800010466c64:       nop
         : 772              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010466c68:       mrs     x7, sp_el0
         : 26               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff800010466c6c:       ldr     w9, [x7, #36]
         : 51               asm volatile(
    0.00 :   ffff800010466c70:       mov     x6, x8
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff800010466c74:       mov     x2, x0
    0.00 :   ffff800010466c78:       tbnz    w9, #21, ffff800010466cf8 <iov_iter_fault_in_readable+0xf0>
         : 49               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010466c7c:       ldr     x7, [x7]
         : 113              __range_ok():
    0.00 :   ffff800010466c80:       tbnz    w7, #26, ffff800010466cf8 <iov_iter_fault_in_readable+0xf0>
         : 51               asm volatile(
    0.00 :   ffff800010466c84:       adds    x2, x2, #0x1
    0.00 :   ffff800010466c88:       csel    x6, xzr, x6, hi  // hi = pmore
    0.00 :   ffff800010466c8c:       csinv   x2, x2, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff800010466c90:       sbcs    xzr, x2, x6
    0.00 :   ffff800010466c94:       cset    x2, ls  // ls = plast
         : 57               __uaccess_mask_ptr():
         : 244              asm volatile(
         : 245              "       bics    xzr, %3, %2\n"
         : 246              "       csel    %0, %1, xzr, eq\n"
         : 247              : "=&r" (safe_ptr)
         : 248              : "r" (ptr), "r" (TASK_SIZE_MAX - 1),
         : 249              "r" (untagged_addr(ptr))
    0.00 :   ffff800010466c98:       and     x6, x0, x5, asr #8
         : 251              fault_in_pages_readable():
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466c9c:       cbz     x2, ffff800010466d18 <iov_iter_fault_in_readable+0x110>
         : 775              __uaccess_mask_ptr():
         : 239              asm volatile(
    0.00 :   ffff800010466ca0:       bics    xzr, x6, x8
    0.00 :   ffff800010466ca4:       csel    x7, x0, xzr, eq  // eq = none
         : 247              : "cc");
         :
         : 249              csdb();
    0.00 :   ffff800010466ca8:       csdb
         : 251              fault_in_pages_readable():
    0.00 :   ffff800010466cac:       mov     w2, w11
    0.00 :   ffff800010466cb0:       ldtrb   w6, [x7]
    0.00 :   ffff800010466cb4:       and     w6, w6, #0xff
   35.75 :   ffff800010466cb8:       strb    w6, [sp, #14]
         : 775              return -EFAULT;
         : 776              uaddr += PAGE_SIZE;
    0.00 :   ffff800010466cbc:       add     x0, x0, #0x1, lsl #12
    0.00 :   ffff800010466cc0:       add     x5, x5, #0x100, lsl #12
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466cc4:       cbnz    w2, ffff800010466d34 <iov_iter_fault_in_readable+0x12c>
         : 776              } while (uaddr <= end);
    0.00 :   ffff800010466cc8:       cmp     x4, x0
    0.00 :   ffff800010466ccc:       b.cs    ffff800010466c68 <iov_iter_fault_in_readable+0x60>  // b.hs, b.nlast
         :
         : 780              /* Check whether the range spilled into the next page. */
         : 781              if (((unsigned long)uaddr & PAGE_MASK) ==
    0.00 :   ffff800010466cd0:       eor     x0, x0, x4
    0.00 :   ffff800010466cd4:       tst     x0, #0xfffffffffffff000
    0.00 :   ffff800010466cd8:       b.eq    ffff800010466e2c <iov_iter_fault_in_readable+0x224>  // b.none
         : 784              ((unsigned long)end & PAGE_MASK)) {
         : 785              return __get_user(c, end);
         : 786              }
         :
         : 788              (void)c;
    0.00 :   ffff800010466cdc:       ldrb    w0, [sp, #14]
         : 790              iov_iter_fault_in_readable():
    0.00 :   ffff800010466ce0:       sub     x1, x1, x3
    0.00 :   ffff800010466ce4:       cbnz    x1, ffff800010466d3c <iov_iter_fault_in_readable+0x134>
         : 486              }
         : 487              }
         : 488              return 0;
         : 489              }
         : 490              EXPORT_SYMBOL(iov_iter_fault_in_writeable);
         :
    0.00 :   ffff800010466ce8:       mov     w0, #0x0                        // #0
         : 487              void iov_iter_init(struct iov_iter *i, unsigned int direction,
    0.00 :   ffff800010466cec:       add     sp, sp, #0x10
    0.00 :   ffff800010466cf0:       autiasp
    0.00 :   ffff800010466cf4:       ret
         : 491              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff800010466cf8:       and     x2, x0, x5, asr #8
         : 51               asm volatile(
    0.00 :   ffff800010466cfc:       adds    x2, x2, #0x1
    0.00 :   ffff800010466d00:       csel    x6, xzr, x6, hi  // hi = pmore
    0.00 :   ffff800010466d04:       csinv   x2, x2, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff800010466d08:       sbcs    xzr, x2, x6
    0.00 :   ffff800010466d0c:       cset    x2, ls  // ls = plast
         : 57               __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff800010466d10:       and     x6, x0, x5, asr #8
         : 246              fault_in_pages_readable():
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466d14:       cbnz    x2, ffff800010466ca0 <iov_iter_fault_in_readable+0x98>
         : 781              return __get_user(c, end);
    0.00 :   ffff800010466d18:       strb    wzr, [sp, #14]
    0.00 :   ffff800010466d1c:       mov     w0, #0xfffffff2                 // #-14
         : 784              iov_iter_fault_in_readable():
    0.00 :   ffff800010466d20:       add     sp, sp, #0x10
    0.00 :   ffff800010466d24:       autiasp
    0.00 :   ffff800010466d28:       ret
         :
    0.00 :   ffff800010466d2c:       mov     w0, #0x0                        // #0
         : 487              void iov_iter_init(struct iov_iter *i, unsigned int direction,
    0.00 :   ffff800010466d30:       ret
         : 489              fault_in_pages_readable():
         : 770              return -EFAULT;
    0.00 :   ffff800010466d34:       mov     w0, #0xfffffff2                 // #-14
    0.00 :   ffff800010466d38:       b       ffff800010466cec <iov_iter_fault_in_readable+0xe4>
         : 773              __range_ok():
         : 51               asm volatile(
    0.00 :   ffff800010466d3c:       mov     x8, #0xffffffffffff             // #281474976710655
         : 53               fault_in_pages_readable():
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466d40:       mov     w11, #0x0                       // #0
         : 775              iov_iter_fault_in_readable():
         : 480              bytes -= len;
    0.00 :   ffff800010466d44:       add     x10, x10, #0x10
    0.00 :   ffff800010466d48:       ldr     x9, [x10, #8]
    0.00 :   ffff800010466d4c:       cmp     x9, x1
    0.00 :   ffff800010466d50:       csel    x9, x9, x1, ls  // ls = plast
    0.00 :   ffff800010466d54:       cbz     x9, ffff800010466d44 <iov_iter_fault_in_readable+0x13c>
    0.00 :   ffff800010466d58:       ldr     x2, [x10]
         : 481              fault_in_pages_readable():
         : 764              const char __user *end = uaddr + size - 1;
    0.00 :   ffff800010466d5c:       sxtw    x5, w9
    0.00 :   ffff800010466d60:       sub     x5, x5, #0x1
    0.00 :   ffff800010466d64:       add     x5, x2, x5
         : 766              if (unlikely(size == 0))
    0.00 :   ffff800010466d68:       cbz     w9, ffff800010466df4 <iov_iter_fault_in_readable+0x1ec>
         : 769              if (unlikely(uaddr > end))
    0.00 :   ffff800010466d6c:       cmp     x2, x5
    0.00 :   ffff800010466d70:       b.hi    ffff800010466d34 <iov_iter_fault_in_readable+0x12c>  // b.pmore
    0.00 :   ffff800010466d74:       nop
         : 773              get_current():
    0.00 :   ffff800010466d78:       mrs     x4, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff800010466d7c:       ldr     w6, [x4, #36]
         : 49               sign_extend64():
         : 182              * @index: 0 based bit index (0<=index<64) to sign bit
         : 183              */
         : 184              static __always_inline __s64 sign_extend64(__u64 value, int index)
         : 185              {
         : 186              __u8 shift = 63 - index;
         : 187              return (__s64)(value << shift) >> shift;
    0.00 :   ffff800010466d80:       sbfx    x7, x2, #0, #56
         : 189              __range_ok():
         : 51               asm volatile(
    0.00 :   ffff800010466d84:       mov     x3, x8
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff800010466d88:       mov     x0, x2
    0.00 :   ffff800010466d8c:       tbnz    w6, #21, ffff800010466e00 <iov_iter_fault_in_readable+0x1f8>
         : 49               test_bit():
    0.00 :   ffff800010466d90:       ldr     x4, [x4]
         : 107              __range_ok():
    0.00 :   ffff800010466d94:       tbnz    w4, #26, ffff800010466e00 <iov_iter_fault_in_readable+0x1f8>
         : 51               asm volatile(
    0.00 :   ffff800010466d98:       adds    x0, x0, #0x1
    0.00 :   ffff800010466d9c:       csel    x3, xzr, x3, hi  // hi = pmore
    0.00 :   ffff800010466da0:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff800010466da4:       sbcs    xzr, x0, x3
    0.00 :   ffff800010466da8:       cset    x0, ls  // ls = plast
         : 57               sign_extend64():
    0.00 :   ffff800010466dac:       sbfx    x3, x2, #0, #56
         : 183              fault_in_pages_readable():
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466db0:       cbz     x0, ffff800010466e20 <iov_iter_fault_in_readable+0x218>
         : 775              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff800010466db4:       and     x3, x3, x2
         : 239              asm volatile(
    0.00 :   ffff800010466db8:       bics    xzr, x3, x8
    0.00 :   ffff800010466dbc:       csel    x4, x2, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff800010466dc0:       csdb
         : 249              fault_in_pages_readable():
    0.00 :   ffff800010466dc4:       mov     w0, w11
    0.00 :   ffff800010466dc8:       ldtrb   w3, [x4]
    0.00 :   ffff800010466dcc:       and     w3, w3, #0xff
    0.00 :   ffff800010466dd0:       strb    w3, [sp, #15]
         : 775              uaddr += PAGE_SIZE;
    0.00 :   ffff800010466dd4:       add     x2, x2, #0x1, lsl #12
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466dd8:       cbnz    w0, ffff800010466d34 <iov_iter_fault_in_readable+0x12c>
         : 776              } while (uaddr <= end);
    0.00 :   ffff800010466ddc:       cmp     x5, x2
    0.00 :   ffff800010466de0:       b.cs    ffff800010466d78 <iov_iter_fault_in_readable+0x170>  // b.hs, b.nlast
         : 779              if (((unsigned long)uaddr & PAGE_MASK) ==
    0.00 :   ffff800010466de4:       eor     x2, x2, x5
    0.00 :   ffff800010466de8:       tst     x2, #0xfffffffffffff000
    0.00 :   ffff800010466dec:       b.eq    ffff800010466ea0 <iov_iter_fault_in_readable+0x298>  // b.none
         : 784              (void)c;
    0.00 :   ffff800010466df0:       ldrb    w0, [sp, #15]
         : 786              iov_iter_fault_in_readable():
    0.00 :   ffff800010466df4:       subs    x1, x1, x9
    0.00 :   ffff800010466df8:       b.eq    ffff800010466ce8 <iov_iter_fault_in_readable+0xe0>  // b.none
    0.00 :   ffff800010466dfc:       b       ffff800010466d44 <iov_iter_fault_in_readable+0x13c>
         : 483              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff800010466e00:       and     x0, x7, x2
         : 51               asm volatile(
    0.00 :   ffff800010466e04:       adds    x0, x0, #0x1
    0.00 :   ffff800010466e08:       csel    x3, xzr, x3, hi  // hi = pmore
    0.00 :   ffff800010466e0c:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff800010466e10:       sbcs    xzr, x0, x3
    0.00 :   ffff800010466e14:       cset    x0, ls  // ls = plast
         : 57               sign_extend64():
    0.00 :   ffff800010466e18:       sbfx    x3, x2, #0, #56
         : 183              fault_in_pages_readable():
         : 773              if (unlikely(__get_user(c, uaddr) != 0))
    0.00 :   ffff800010466e1c:       cbnz    x0, ffff800010466db4 <iov_iter_fault_in_readable+0x1ac>
         : 781              return __get_user(c, end);
    0.00 :   ffff800010466e20:       mov     w0, #0xfffffff2                 // #-14
    0.00 :   ffff800010466e24:       strb    wzr, [sp, #15]
         : 784              iov_iter_fault_in_readable():
    0.00 :   ffff800010466e28:       b       ffff800010466cec <iov_iter_fault_in_readable+0xe4>
         : 481              get_current():
    0.00 :   ffff800010466e2c:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff800010466e30:       ldr     w2, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff800010466e34:       tbnz    w2, #21, ffff800010466e48 <iov_iter_fault_in_readable+0x240>
         : 48               test_bit():
    0.00 :   ffff800010466e38:       ldr     x2, [x0]
         : 107              __range_ok():
    0.00 :   ffff800010466e3c:       mov     x0, x4
    0.00 :   ffff800010466e40:       tst     w2, #0x4000000
    0.00 :   ffff800010466e44:       b.eq    ffff800010466e50 <iov_iter_fault_in_readable+0x248>  // b.none
         : 49               sign_extend64():
    0.00 :   ffff800010466e48:       sbfx    x0, x4, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff800010466e4c:       and     x0, x4, x0
         : 51               asm volatile(
    0.00 :   ffff800010466e50:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff800010466e54:       mov     x5, x2
    0.00 :   ffff800010466e58:       adds    x0, x0, #0x1
    0.00 :   ffff800010466e5c:       csel    x5, xzr, x5, hi  // hi = pmore
    0.00 :   ffff800010466e60:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff800010466e64:       sbcs    xzr, x0, x5
    0.00 :   ffff800010466e68:       cset    x0, ls  // ls = plast
         : 59               fault_in_pages_readable():
    0.00 :   ffff800010466e6c:       cbz     x0, ffff800010466d18 <iov_iter_fault_in_readable+0x110>
         : 782              sign_extend64():
    0.00 :   ffff800010466e70:       sbfx    x0, x4, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff800010466e74:       and     x0, x4, x0
         : 239              asm volatile(
    0.00 :   ffff800010466e78:       bics    xzr, x0, x2
    0.00 :   ffff800010466e7c:       csel    x5, x4, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff800010466e80:       csdb
         : 249              fault_in_pages_readable():
    0.00 :   ffff800010466e84:       mov     w0, #0x0                        // #0
    0.00 :   ffff800010466e88:       ldtrb   w2, [x5]
    0.00 :   ffff800010466e8c:       and     w2, w2, #0xff
   54.56 :   ffff800010466e90:       strb    w2, [sp, #14]
         : 785              iov_iter_fault_in_readable():
    0.00 :   ffff800010466e94:       cbnz    w0, ffff800010466cec <iov_iter_fault_in_readable+0xe4>
    0.00 :   ffff800010466e98:       sub     x1, x1, x3
    0.00 :   ffff800010466e9c:       b       ffff800010466ce4 <iov_iter_fault_in_readable+0xdc>
         : 483              get_current():
    0.00 :   ffff800010466ea0:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff800010466ea4:       ldr     w2, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff800010466ea8:       tbnz    w2, #21, ffff800010466eb8 <iov_iter_fault_in_readable+0x2b0>
         : 48               test_bit():
    0.00 :   ffff800010466eac:       ldr     x2, [x0]
         : 107              __range_ok():
    0.00 :   ffff800010466eb0:       mov     x0, x5
    0.00 :   ffff800010466eb4:       tbz     w2, #26, ffff800010466ec0 <iov_iter_fault_in_readable+0x2b8>
         : 48               sign_extend64():
    0.00 :   ffff800010466eb8:       sbfx    x0, x5, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff800010466ebc:       and     x0, x5, x0
         : 51               asm volatile(
    0.00 :   ffff800010466ec0:       mov     x2, x8
    0.00 :   ffff800010466ec4:       adds    x0, x0, #0x1
    0.00 :   ffff800010466ec8:       csel    x2, xzr, x2, hi  // hi = pmore
    0.00 :   ffff800010466ecc:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff800010466ed0:       sbcs    xzr, x0, x2
    0.00 :   ffff800010466ed4:       cset    x0, ls  // ls = plast
         : 58               fault_in_pages_readable():
    0.00 :   ffff800010466ed8:       cbz     x0, ffff800010466e20 <iov_iter_fault_in_readable+0x218>
         : 782              sign_extend64():
    0.00 :   ffff800010466edc:       sbfx    x0, x5, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff800010466ee0:       and     x0, x5, x0
         : 239              asm volatile(
    0.00 :   ffff800010466ee4:       bics    xzr, x0, x8
    0.00 :   ffff800010466ee8:       csel    x3, x5, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff800010466eec:       csdb
         : 249              fault_in_pages_readable():
    0.00 :   ffff800010466ef0:       mov     w0, w11
    0.00 :   ffff800010466ef4:       ldtrb   w2, [x3]
    0.00 :   ffff800010466ef8:       and     w2, w2, #0xff
    0.00 :   ffff800010466efc:       strb    w2, [sp, #15]
         : 785              iov_iter_fault_in_readable():
    0.00 :   ffff800010466f00:       cbz     w0, ffff800010466df4 <iov_iter_fault_in_readable+0x1ec>
    0.00 :   ffff800010466f04:       b       ffff800010466cec <iov_iter_fault_in_readable+0xe4>
 Percent |	Source code & Disassembly of vmlinux for cycles (9 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000107857c0 <iommu_dma_sync_single_for_cpu>:
         : 6                dev_is_dma_coherent():
         : 252              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
         : 253              defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
         : 254              extern bool dma_default_coherent;
         : 255              static inline bool dev_is_dma_coherent(struct device *dev)
         : 256              {
         : 257              return dev->dma_coherent;
    0.00 :   ffff8000107857c0:       ldrb    w4, [x0, #736]
         : 259              iommu_dma_sync_single_for_cpu():
         : 777              #endif /* CONFIG_DMA_REMAP */
         :
         : 779              static void iommu_dma_sync_single_for_cpu(struct device *dev,
         : 780              dma_addr_t dma_handle, size_t size, enum dma_data_direction dir)
         : 781              {
         : 782              phys_addr_t phys;
    0.00 :   ffff8000107857c4:       tbz     w4, #5, ffff8000107857e8 <iommu_dma_sync_single_for_cpu+0x28>
         : 784              dev_is_untrusted():
         : 315              static bool dev_is_untrusted(struct device *dev)
   66.74 :   ffff8000107857c8:       ldr     x5, [x0, #96]
    0.00 :   ffff8000107857cc:       adrp    x4, ffff800011d4b000 <gpio_rcar_device_driver+0xa8>
    0.00 :   ffff8000107857d0:       add     x4, x4, #0xcc0
    0.00 :   ffff8000107857d4:       cmp     x5, x4
   22.22 :   ffff8000107857d8:       b.eq    ffff8000107857e0 <iommu_dma_sync_single_for_cpu+0x20>  // b.none
   11.04 :   ffff8000107857dc:       ret
    0.00 :   ffff8000107857e0:       ldrb    w4, [x0, #1844]
    0.00 :   ffff8000107857e4:       tbz     w4, #3, ffff8000107857dc <iommu_dma_sync_single_for_cpu+0x1c>
         : 324              iommu_dma_sync_single_for_cpu():
         : 774              static void iommu_dma_sync_single_for_cpu(struct device *dev,
    0.00 :   ffff8000107857e8:       paciasp
    0.00 :   ffff8000107857ec:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000107857f0:       mov     x29, sp
    0.00 :   ffff8000107857f4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000107857f8:       mov     x19, x0
    0.00 :   ffff8000107857fc:       mov     x20, x1
    0.00 :   ffff800010785800:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010785804:       mov     w22, w3
    0.00 :   ffff800010785808:       mov     x21, x2
         :
         : 781              if (dev_is_dma_coherent(dev) && !dev_is_untrusted(dev))
         : 782              return;
    0.00 :   ffff80001078580c:       bl      ffff800010784d10 <iommu_get_dma_domain>
    0.00 :   ffff800010785810:       mov     x1, x20
    0.00 :   ffff800010785814:       bl      ffff800010780f30 <iommu_iova_to_phys>
         : 786              dev_is_dma_coherent():
    0.00 :   ffff800010785818:       ldrb    w1, [x19, #736]
         : 253              iommu_dma_sync_single_for_cpu():
    0.00 :   ffff80001078581c:       mov     x20, x0
         :
    0.00 :   ffff800010785820:       tbz     w1, #5, ffff800010785870 <iommu_dma_sync_single_for_cpu+0xb0>
         : 783              is_swiotlb_buffer():
         : 106              };
         : 107              extern struct io_tlb_mem *io_tlb_default_mem;
         :
         : 109              static inline bool is_swiotlb_buffer(phys_addr_t paddr)
         : 110              {
         : 111              struct io_tlb_mem *mem = io_tlb_default_mem;
    0.00 :   ffff800010785824:       adrp    x0, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010785828:       ldr     x0, [x0, #3624]
         :
         : 109              return mem && paddr >= mem->start && paddr < mem->end;
    0.00 :   ffff80001078582c:       cbz     x0, ffff80001078585c <iommu_dma_sync_single_for_cpu+0x9c>
    0.00 :   ffff800010785830:       ldr     x1, [x0]
    0.00 :   ffff800010785834:       cmp     x20, x1
    0.00 :   ffff800010785838:       b.cc    ffff80001078585c <iommu_dma_sync_single_for_cpu+0x9c>  // b.lo, b.ul, b.last
    0.00 :   ffff80001078583c:       ldr     x0, [x0, #8]
    0.00 :   ffff800010785840:       cmp     x20, x0
    0.00 :   ffff800010785844:       b.cs    ffff80001078585c <iommu_dma_sync_single_for_cpu+0x9c>  // b.hs, b.nlast
         : 117              iommu_dma_sync_single_for_cpu():
         : 785              phys = iommu_iova_to_phys(iommu_get_dma_domain(dev), dma_handle);
         : 786              if (!dev_is_dma_coherent(dev))
         : 787              arch_sync_dma_for_cpu(phys, size, dir);
         :
    0.00 :   ffff800010785848:       mov     w3, w22
    0.00 :   ffff80001078584c:       mov     x2, x21
    0.00 :   ffff800010785850:       mov     x1, x20
    0.00 :   ffff800010785854:       mov     x0, x19
    0.00 :   ffff800010785858:       bl      ffff8000101091a0 <swiotlb_sync_single_for_cpu>
         : 786              if (is_swiotlb_buffer(phys))
    0.00 :   ffff80001078585c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010785860:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010785864:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010785868:       autiasp
    0.00 :   ffff80001078586c:       ret
         : 782              phys = iommu_iova_to_phys(iommu_get_dma_domain(dev), dma_handle);
    0.00 :   ffff800010785870:       mov     w2, w22
    0.00 :   ffff800010785874:       mov     x1, x21
    0.00 :   ffff800010785878:       bl      ffff800010031e88 <arch_sync_dma_for_cpu>
    0.00 :   ffff80001078587c:       b       ffff800010785824 <iommu_dma_sync_single_for_cpu+0x64>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001046d010 <_find_next_bit>:
         : 6                _find_next_bit():
         : 35               *  - The optional "addr2", which is anded with "addr1" if present.
         : 36               */
         : 37               unsigned long _find_next_bit(const unsigned long *addr1,
         : 38               const unsigned long *addr2, unsigned long nbits,
         : 39               unsigned long start, unsigned long invert, unsigned long le)
         : 40               {
    0.00 :   ffff80001046d010:       paciasp
         : 38               unsigned long tmp, mask;
         :
         : 40               if (unlikely(start >= nbits))
    2.08 :   ffff80001046d014:       cmp     x3, x2
    0.00 :   ffff80001046d018:       b.cs    ffff80001046d0a4 <_find_next_bit+0x94>  // b.hs, b.nlast
         : 41               return nbits;
         :
         : 43               tmp = addr1[start / BITS_PER_LONG];
    0.00 :   ffff80001046d01c:       lsr     x7, x3, #6
    0.00 :   ffff80001046d020:       ldr     x6, [x0, x7, lsl #3]
         : 42               if (addr2)
    0.00 :   ffff80001046d024:       cbz     x1, ffff80001046d030 <_find_next_bit+0x20>
         : 43               tmp &= addr2[start / BITS_PER_LONG];
    0.00 :   ffff80001046d028:       ldr     x7, [x1, x7, lsl #3]
    0.00 :   ffff80001046d02c:       and     x6, x6, x7
         : 47               tmp ^= invert;
         :
         : 49               /* Handle 1st word. */
         : 50               mask = BITMAP_FIRST_WORD_MASK(start);
    0.00 :   ffff80001046d030:       mov     x7, #0xffffffffffffffff         // #-1
         : 44               tmp ^= invert;
    0.00 :   ffff80001046d034:       eor     x6, x6, x4
         : 47               mask = BITMAP_FIRST_WORD_MASK(start);
    0.00 :   ffff80001046d038:       lsl     x7, x7, x3
         : 48               if (le)
    0.00 :   ffff80001046d03c:       and     x3, x3, #0xffffffffffffffc0
    0.00 :   ffff80001046d040:       cbnz    x5, ffff80001046d0b0 <_find_next_bit+0xa0>
         :
         : 56               tmp &= mask;
         :
         : 58               start = round_down(start, BITS_PER_LONG);
         :
         : 60               while (!tmp) {
    0.00 :   ffff80001046d044:       ands    x6, x6, x7
    0.00 :   ffff80001046d048:       b.ne    ffff80001046d090 <_find_next_bit+0x80>  // b.any
         : 56               start += BITS_PER_LONG;
    0.00 :   ffff80001046d04c:       add     x3, x3, #0x40
         : 57               if (start >= nbits)
    0.00 :   ffff80001046d050:       cmp     x3, x2
    0.00 :   ffff80001046d054:       b.cc    ffff80001046d068 <_find_next_bit+0x58>  // b.lo, b.ul, b.last
    0.00 :   ffff80001046d058:       b       ffff80001046d0a4 <_find_next_bit+0x94>
         : 56               start += BITS_PER_LONG;
   45.63 :   ffff80001046d05c:       add     x3, x3, #0x40
         : 57               if (start >= nbits)
    0.00 :   ffff80001046d060:       cmp     x2, x3
    0.00 :   ffff80001046d064:       b.ls    ffff80001046d0a4 <_find_next_bit+0x94>  // b.plast
         : 60               return nbits;
         :
         : 62               tmp = addr1[start / BITS_PER_LONG];
    0.00 :   ffff80001046d068:       lsr     x7, x3, #6
    0.00 :   ffff80001046d06c:       ldr     x6, [x0, x7, lsl #3]
         : 61               if (addr2)
    0.00 :   ffff80001046d070:       cbz     x1, ffff80001046d07c <_find_next_bit+0x6c>
         : 62               tmp &= addr2[start / BITS_PER_LONG];
    0.00 :   ffff80001046d074:       ldr     x7, [x1, x7, lsl #3]
    0.00 :   ffff80001046d078:       and     x6, x6, x7
         : 55               while (!tmp) {
    0.00 :   ffff80001046d07c:       cmp     x6, x4
    0.00 :   ffff80001046d080:       b.eq    ffff80001046d05c <_find_next_bit+0x4c>  // b.none
         : 63               tmp ^= invert;
   52.29 :   ffff80001046d084:       eor     x6, x6, x4
         : 66               }
         :
         : 68               if (le)
    0.00 :   ffff80001046d088:       cbz     x5, ffff80001046d090 <_find_next_bit+0x80>
         : 75               #elif defined(__SWAB_64_THRU_32__)
         : 76               __u32 h = val >> 32;
         : 77               __u32 l = val & ((1ULL << 32) - 1);
         : 78               return (((__u64)__fswab32(l)) << 32) | ((__u64)(__fswab32(h)));
         : 79               #else
         : 80               return ___constant_swab64(val);
    0.00 :   ffff80001046d08c:       rev     x6, x6
         : 82               __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff80001046d090:       rbit    x6, x6
    0.00 :   ffff80001046d094:       clz     x6, x6
         : 21               _find_next_bit():
         : 69               tmp = swab(tmp);
         :
         : 71               return min(start + __ffs(tmp), nbits);
    0.00 :   ffff80001046d098:       add     x3, x6, x3
    0.00 :   ffff80001046d09c:       cmp     x2, x3
    0.00 :   ffff80001046d0a0:       csel    x2, x2, x3, ls  // ls = plast
         : 70               }
    0.00 :   ffff80001046d0a4:       mov     x0, x2
    0.00 :   ffff80001046d0a8:       autiasp
    0.00 :   ffff80001046d0ac:       ret
    0.00 :   ffff80001046d0b0:       rev     x7, x7
         : 55               while (!tmp) {
    0.00 :   ffff80001046d0b4:       ands    x6, x6, x7
    0.00 :   ffff80001046d0b8:       b.eq    ffff80001046d04c <_find_next_bit+0x3c>  // b.none
    0.00 :   ffff80001046d0bc:       b       ffff80001046d08c <_find_next_bit+0x7c>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b75b8 <idle_cpu>:
         : 6                idle_cpu():
         : 5834             *         - in IRQ context, return from interrupt-handler to
         : 5835             *           preemptible context
         : 5836             *
         : 5837             *       - If the kernel is not preemptible (CONFIG_PREEMPTION is not set)
         : 5838             *         then at the next:
         : 5839             *
    0.00 :   ffff8000100b75b8:       adrp    x2, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100b75bc:       add     x2, x2, #0x760
    0.00 :   ffff8000100b75c0:       adrp    x1, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100b75c4:       add     x1, x1, #0xc40
    0.00 :   ffff8000100b75c8:       ldr     x0, [x2, w0, sxtw #3]
         : 5833             *         then at the next:
    0.00 :   ffff8000100b75cc:       paciasp
         : 5834             *
    0.00 :   ffff8000100b75d0:       add     x1, x1, x0
         : 5836             *          - cond_resched() call
         : 5837             *          - explicit schedule() call
    0.00 :   ffff8000100b75d4:       ldr     x2, [x1, #2352]
   47.80 :   ffff8000100b75d8:       ldr     x0, [x1, #2360]
    0.00 :   ffff8000100b75dc:       cmp     x2, x0
    0.00 :   ffff8000100b75e0:       b.eq    ffff8000100b75f0 <idle_cpu+0x38>  // b.none
         : 5837             *          - return from syscall or exception to user-space
    0.00 :   ffff8000100b75e4:       mov     w0, #0x0                        // #0
         : 5848             {
         : 5849             struct task_struct *prev, *next;
         : 5850             unsigned long *switch_count;
         : 5851             unsigned long prev_state;
         : 5852             struct rq_flags rf;
         : 5853             struct rq *rq;
    0.00 :   ffff8000100b75e8:       autiasp
    0.00 :   ffff8000100b75ec:       ret
         : 5839             *
   52.20 :   ffff8000100b75f0:       ldr     w2, [x1, #4]
         : 5837             *          - return from syscall or exception to user-space
    0.00 :   ffff8000100b75f4:       mov     w0, #0x0                        // #0
         : 5839             *
    0.00 :   ffff8000100b75f8:       cbnz    w2, ffff8000100b75e8 <idle_cpu+0x30>
         : 5843             {
    0.00 :   ffff8000100b75fc:       ldr     w0, [x1, #104]
         : 5848             struct rq *rq;
    0.00 :   ffff8000100b7600:       autiasp
         : 5843             {
    0.00 :   ffff8000100b7604:       cmp     w0, #0x0
    0.00 :   ffff8000100b7608:       cset    w0, eq  // eq = none
         : 5848             struct rq *rq;
    0.00 :   ffff8000100b760c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (12 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e351f8 <_raw_spin_lock>:
         : 6                _raw_spin_lock():
         : 150              EXPORT_SYMBOL(_raw_spin_trylock_bh);
         : 151              #endif
         :
         : 153              #ifndef CONFIG_INLINE_SPIN_LOCK
         : 154              void __lockfunc _raw_spin_lock(raw_spinlock_t *lock)
         : 155              {
    0.00 :   ffff800010e351f8:       paciasp
    0.00 :   ffff800010e351fc:       stp     x29, x30, [sp, #-16]!
         : 158              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e35200:       mrs     x2, sp_el0
         : 26               _raw_spin_lock():
    0.00 :   ffff800010e35204:       mov     x29, sp
         : 151              __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010e35208:       ldr     w1, [x2, #8]
         : 53               _raw_spin_lock():
    0.00 :   ffff800010e3520c:       mov     x3, x0
         : 151              __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff800010e35210:       add     w1, w1, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010e35214:       str     w1, [x2, #8]
         : 50               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e35218:       b       ffff800010e35244 <_raw_spin_lock+0x4c>
    0.00 :   ffff800010e3521c:       b       ffff800010e35244 <_raw_spin_lock+0x4c>
         : 46               __lse__cmpxchg_case_acq_32():
         : 370              __CMPXCHG_CASE(w, h,     , 16,   )
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
         : 372              __CMPXCHG_CASE(x,  ,     , 64,   )
         : 373              __CMPXCHG_CASE(w, b, acq_,  8,  a, "memory")
         : 374              __CMPXCHG_CASE(w, h, acq_, 16,  a, "memory")
         : 375              __CMPXCHG_CASE(w,  , acq_, 32,  a, "memory")
    0.00 :   ffff800010e35220:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010e35224:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e35228:       mov     w4, w1
    0.00 :   ffff800010e3522c:       casa    w4, w2, [x0]
   99.82 :   ffff800010e35230:       mov     w0, w4
         : 381              arch_atomic_try_cmpxchg_acquire():
         : 1004             static __always_inline bool
         : 1005             arch_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
         : 1006             {
         : 1007             int r, o = *old;
         : 1008             r = arch_atomic_cmpxchg_acquire(v, o, new);
         : 1009             if (unlikely(r != o))
    0.00 :   ffff800010e35234:       cbnz    w0, ffff800010e35254 <_raw_spin_lock+0x5c>
         : 1011             _raw_spin_lock():
         : 152              __raw_spin_lock(lock);
         : 153              }
    0.00 :   ffff800010e35238:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e3523c:       autiasp
    0.18 :   ffff800010e35240:       ret
         : 157              __ll_sc__cmpxchg_case_acq_32():
         : 305              __CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
         : 307              __CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
         : 308              __CMPXCHG_CASE(w, b, acq_,  8,        , a,  , "memory", K)
         : 309              __CMPXCHG_CASE(w, h, acq_, 16,        , a,  , "memory", K)
         : 310              __CMPXCHG_CASE(w,  , acq_, 32,        , a,  , "memory", K)
    0.00 :   ffff800010e35244:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010e35248:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e3524c:       b       ffff800010e358d0 <_raw_read_lock_irqsave+0x1d8>
         : 314              arch_atomic_try_cmpxchg_acquire():
    0.00 :   ffff800010e35250:       cbz     w0, ffff800010e35238 <_raw_spin_lock+0x40>
         : 1005             queued_spin_lock():
         : 85               int val = 0;
         :
         : 87               if (likely(atomic_try_cmpxchg_acquire(&lock->val, &val, _Q_LOCKED_VAL)))
         : 88               return;
         :
         : 90               queued_spin_lock_slowpath(lock, val);
    0.00 :   ffff800010e35254:       mov     w1, w0
    0.00 :   ffff800010e35258:       mov     x0, x3
    0.00 :   ffff800010e3525c:       bl      ffff8000100dac80 <queued_spin_lock_slowpath>
    0.00 :   ffff800010e35260:       b       ffff800010e35238 <_raw_spin_lock+0x40>
 Percent |	Source code & Disassembly of vmlinux for cycles (7 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001027d158 <__find_get_block>:
         : 6                __find_get_block():
         : 1328             }
         :
         : 1330             /*
         : 1331             * Look up the bh in this cpu's LRU.  If it's there, move it to the head.
         : 1332             */
         : 1333             static struct buffer_head *
    0.00 :   ffff80001027d158:       paciasp
    0.00 :   ffff80001027d15c:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff80001027d160:       mov     x29, sp
    0.00 :   ffff80001027d164:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001027d168:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001027d16c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001027d170:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001027d174:       str     x27, [sp, #80]
         : 1342             arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d178:       mrs     x4, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d17c:       and     w3, w4, #0x80
         : 92               check_irqs_on():
         : 1247             brelse(bh);
    0.00 :   ffff80001027d180:       cbnz    w3, ffff80001027d43c <__find_get_block+0x2e4>
         : 1249             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff80001027d184:       nop
    0.00 :   ffff80001027d188:       mov     x3, #0x60                       // #96
         : 29               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d18c:       msr     daifset, #0x3
   13.48 :   ffff80001027d190:       adrp    x21, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff80001027d194:       add     x21, x21, #0xa00
         : 58               lookup_bh_lru():
         : 1303             * failing page migration.
    0.00 :   ffff80001027d198:       mov     w2, w2
         : 1305             __kern_my_cpu_offset():
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
         : 45               "mrs %0, tpidr_el2",
         : 46               ARM64_HAS_VIRT_HOST_EXTN)
         : 47               : "=r" (off) :
         : 48               "Q" (*(const unsigned long *)current_stack_pointer));
    0.00 :   ffff80001027d19c:       mov     x6, x21
    0.00 :   ffff80001027d1a0:       mov     x7, sp
         : 51               lookup_bh_lru():
         : 1299             check_irqs_on();
    0.00 :   ffff80001027d1a4:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001027d1a8:       b       ffff80001027d1bc <__find_get_block+0x64>
    0.00 :   ffff80001027d1ac:       add     w3, w3, #0x1
    0.00 :   ffff80001027d1b0:       add     x6, x6, #0x8
    0.00 :   ffff80001027d1b4:       cmp     w3, #0x10
    0.00 :   ffff80001027d1b8:       b.eq    ffff80001027d250 <__find_get_block+0xf8>  // b.none
         : 1300             /*
    0.00 :   ffff80001027d1bc:       mov     x4, x6
         : 1302             __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
   15.52 :   ffff80001027d1c0:       mrs     x5, tpidr_el1
         : 41               lookup_bh_lru():
    0.00 :   ffff80001027d1c4:       ldr     x19, [x4, x5]
         : 1302             * attached page(i.e., try_to_free_buffers) so it could cause
    0.00 :   ffff80001027d1c8:       cbz     x19, ffff80001027d1ac <__find_get_block+0x54>
    0.00 :   ffff80001027d1cc:       ldr     x4, [x19, #24]
    0.00 :   ffff80001027d1d0:       cmp     x1, x4
    0.00 :   ffff80001027d1d4:       b.ne    ffff80001027d1ac <__find_get_block+0x54>  // b.any
   14.70 :   ffff80001027d1d8:       ldr     x4, [x19, #48]
    0.00 :   ffff80001027d1dc:       cmp     x0, x4
    0.00 :   ffff80001027d1e0:       b.ne    ffff80001027d1ac <__find_get_block+0x54>  // b.any
    0.00 :   ffff80001027d1e4:       ldr     x4, [x19, #32]
    0.00 :   ffff80001027d1e8:       cmp     x4, x2
    0.00 :   ffff80001027d1ec:       b.ne    ffff80001027d1ac <__find_get_block+0x54>  // b.any
         : 1304             * Skip putting upcoming bh into bh_lru until migration is done.
    0.00 :   ffff80001027d1f0:       cbz     w3, ffff80001027d230 <__find_get_block+0xd8>
    0.00 :   ffff80001027d1f4:       sub     w4, w3, #0x1
    0.00 :   ffff80001027d1f8:       mov     w2, w3
    0.00 :   ffff80001027d1fc:       sub     x2, x2, x4
    0.00 :   ffff80001027d200:       add     x3, x21, x4, lsl #3
    0.00 :   ffff80001027d204:       lsl     x2, x2, #3
         : 1306             if (lru_cache_disabled())
    0.00 :   ffff80001027d208:       mov     x5, x3
    0.00 :   ffff80001027d20c:       add     x4, x3, x2
         : 1309             __kern_my_cpu_offset():
    0.00 :   ffff80001027d210:       mrs     x6, tpidr_el1
         : 40               lookup_bh_lru():
    0.00 :   ffff80001027d214:       ldr     x7, [x5, x6]
    0.00 :   ffff80001027d218:       str     x7, [x4, x6]
         : 1305             */
    0.00 :   ffff80001027d21c:       cmp     x3, x21
    0.00 :   ffff80001027d220:       sub     x3, x3, #0x8
    0.00 :   ffff80001027d224:       b.ne    ffff80001027d208 <__find_get_block+0xb0>  // b.any
         : 1309             __kern_my_cpu_offset():
    0.00 :   ffff80001027d228:       mrs     x2, tpidr_el1
         : 40               lookup_bh_lru():
         :
    0.00 :   ffff80001027d22c:       str     x19, [x5, x2]
         : 1312             get_bh():
         : 279              * inline definitions
         : 280              */
         :
         : 282              static inline void get_bh(struct buffer_head *bh)
         : 283              {
         : 284              atomic_inc(&bh->b_count);
    0.00 :   ffff80001027d230:       add     x2, x19, #0x60
         : 286              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001027d234:       b       ffff80001027d458 <__find_get_block+0x300>
    0.00 :   ffff80001027d238:       b       ffff80001027d458 <__find_get_block+0x300>
         : 46               __lse_atomic_add():
         : 26               }
         :
         : 28               ATOMIC_OP(andnot, stclr)
         : 29               ATOMIC_OP(or, stset)
         : 30               ATOMIC_OP(xor, steor)
         : 31               ATOMIC_OP(add, stadd)
    0.00 :   ffff80001027d23c:       mov     w3, #0x1                        // #1
    0.00 :   ffff80001027d240:       stadd   w3, [x2]
    0.00 :   ffff80001027d244:       b       ffff80001027d254 <__find_get_block+0xfc>
         : 35               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001027d248:       mov     x3, #0xa0                       // #160
    0.00 :   ffff80001027d24c:       b       ffff80001027d18c <__find_get_block+0x34>
         : 24               lookup_bh_lru():
         : 1294             {
    0.00 :   ffff80001027d250:       mov     x19, #0x0                       // #0
         : 1296             arch_local_irq_enable():
         : 35               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d254:       mov     x2, #0xe0                       // #224
    0.00 :   ffff80001027d258:       msr     daifclr, #0x3
         : 38               arch_static_branch():
   14.28 :   ffff80001027d25c:       nop
         : 22               __find_get_block():
         : 1331             lookup_bh_lru(struct block_device *bdev, sector_t block, unsigned size)
         : 1332             {
         : 1333             struct buffer_head *ret = NULL;
    0.00 :   ffff80001027d260:       mov     x22, x1
    0.00 :   ffff80001027d264:       mov     x25, x0
    0.00 :   ffff80001027d268:       cbz     x19, ffff80001027d2a8 <__find_get_block+0x150>
         : 1337             touch_buffer():
         : 63               mark_page_accessed(bh->b_page);
    0.00 :   ffff80001027d26c:       ldr     x0, [x19, #16]
    0.00 :   ffff80001027d270:       bl      ffff80001018ec70 <mark_page_accessed>
         : 66               __find_get_block():
         : 1340             bh_lru_lock();
         : 1341             for (i = 0; i < BH_LRU_SIZE; i++) {
         : 1342             struct buffer_head *bh = __this_cpu_read(bh_lrus.bhs[i]);
         :
         : 1344             if (bh && bh->b_blocknr == block && bh->b_bdev == bdev &&
         : 1345             bh->b_size == size) {
    0.00 :   ffff80001027d274:       mov     x0, x19
    0.00 :   ffff80001027d278:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001027d27c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001027d280:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001027d284:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001027d288:       ldr     x27, [sp, #80]
    0.00 :   ffff80001027d28c:       ldp     x29, x30, [sp], #96
    0.00 :   ffff80001027d290:       autiasp
    0.00 :   ffff80001027d294:       ret
         : 1355             arch_local_irq_enable():
         : 43               pmr_sync();
    0.00 :   ffff80001027d298:       dsb     sy
         : 45               __find_get_block():
         : 1331             struct buffer_head *ret = NULL;
   42.02 :   ffff80001027d29c:       mov     x22, x1
    0.00 :   ffff80001027d2a0:       mov     x25, x0
    0.00 :   ffff80001027d2a4:       cbnz    x19, ffff80001027d26c <__find_get_block+0x114>
         : 1335             __find_get_block_slow():
         : 191              struct inode *bd_inode = bdev->bd_inode;
    0.00 :   ffff80001027d2a8:       ldr     x24, [x0, #40]
         : 201              index = block >> (PAGE_SHIFT - bd_inode->i_blkbits);
    0.00 :   ffff80001027d2ac:       mov     w1, #0xc                        // #12
         : 203              find_get_page_flags():
         : 357              }
         :
         : 359              static inline struct page *find_get_page_flags(struct address_space *mapping,
         : 360              pgoff_t offset, int fgp_flags)
         : 361              {
         : 362              return pagecache_get_page(mapping, offset, fgp_flags, 0);
    0.00 :   ffff80001027d2b0:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001027d2b4:       mov     w2, #0x1                        // #1
         : 365              __find_get_block_slow():
    0.00 :   ffff80001027d2b8:       ldrb    w0, [x24, #142]
         : 192              struct address_space *bd_mapping = bd_inode->i_mapping;
    0.00 :   ffff80001027d2bc:       ldr     x26, [x24, #48]
         : 201              index = block >> (PAGE_SHIFT - bd_inode->i_blkbits);
    0.00 :   ffff80001027d2c0:       sub     w1, w1, w0
         : 203              find_get_page_flags():
    0.00 :   ffff80001027d2c4:       mov     x0, x26
    0.00 :   ffff80001027d2c8:       lsr     x1, x22, x1
    0.00 :   ffff80001027d2cc:       bl      ffff800010180af8 <pagecache_get_page>
    0.00 :   ffff80001027d2d0:       mov     x23, x0
         : 361              __find_get_block_slow():
         : 203              if (!page)
    0.00 :   ffff80001027d2d4:       cbz     x0, ffff80001027d274 <__find_get_block+0x11c>
         : 205              spin_lock():
         : 354              # define spin_lock_init(_lock)                  \
         : 355              do {                                            \
         : 356              spinlock_check(_lock);                  \
         : 357              *(_lock) = __SPIN_LOCK_UNLOCKED(_lock); \
         : 358              } while (0)
         :
    0.00 :   ffff80001027d2d8:       add     x26, x26, #0x7c
    0.00 :   ffff80001027d2dc:       mov     x0, x26
    0.00 :   ffff80001027d2e0:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 363              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001027d2e4:       ldr     x0, [x23]
         : 113              __find_get_block_slow():
         : 207              if (!page_has_buffers(page))
    0.00 :   ffff80001027d2e8:       tst     w0, #0x2000
    0.00 :   ffff80001027d2ec:       b.eq    ffff80001027d360 <__find_get_block+0x208>  // b.none
         : 210              test_bit():
    0.00 :   ffff80001027d2f0:       ldr     x2, [x23]
    0.00 :   ffff80001027d2f4:       ubfx    w2, w2, #13, #1
         : 108              __find_get_block_slow():
         : 209              head = page_buffers(page);
    0.00 :   ffff80001027d2f8:       cbz     w2, ffff80001027d4a0 <__find_get_block+0x348>
    0.00 :   ffff80001027d2fc:       ldr     x3, [x23, #40]
         : 210              bh = head;
    0.00 :   ffff80001027d300:       mov     x20, x3
    0.00 :   ffff80001027d304:       b       ffff80001027d320 <__find_get_block+0x1c8>
         : 214              else if (bh->b_blocknr == block) {
    0.00 :   ffff80001027d308:       ldr     x1, [x20, #24]
    0.00 :   ffff80001027d30c:       cmp     x22, x1
    0.00 :   ffff80001027d310:       b.eq    ffff80001027d460 <__find_get_block+0x308>  // b.none
         : 219              bh = bh->b_this_page;
    0.00 :   ffff80001027d314:       ldr     x20, [x20, #8]
         : 220              } while (bh != head);
    0.00 :   ffff80001027d318:       cmp     x3, x20
    0.00 :   ffff80001027d31c:       b.eq    ffff80001027d330 <__find_get_block+0x1d8>  // b.none
         : 223              test_bit():
    0.00 :   ffff80001027d320:       ldr     x1, [x20]
         : 107              __find_get_block_slow():
         : 212              if (!buffer_mapped(bh))
    0.00 :   ffff80001027d324:       tbnz    w1, #4, ffff80001027d308 <__find_get_block+0x1b0>
         : 213              all_mapped = 0;
    0.00 :   ffff80001027d328:       mov     w2, #0x0                        // #0
    0.00 :   ffff80001027d32c:       b       ffff80001027d314 <__find_get_block+0x1bc>
         : 216              ratelimit_set_flags():
         : 40               }
         :
         : 42               static inline void
         : 43               ratelimit_set_flags(struct ratelimit_state *rs, unsigned long flags)
         : 44               {
         : 45               rs->flags = flags;
    0.00 :   ffff80001027d330:       adrp    x0, ffff800011cc1000 <hugetlb_cgrp_subsys+0x88>
    0.00 :   ffff80001027d334:       add     x0, x0, #0x948
    0.00 :   ffff80001027d338:       add     x0, x0, #0x28
    0.00 :   ffff80001027d33c:       mov     x27, #0x1                       // #1
    0.00 :   ffff80001027d340:       str     x27, [x0, #32]
         : 51               __find_get_block_slow():
         : 228              if (all_mapped && __ratelimit(&last_warned)) {
    0.00 :   ffff80001027d344:       cbz     w2, ffff80001027d360 <__find_get_block+0x208>
    0.00 :   ffff80001027d348:       adrp    x1, ffff800010e80000 <bad_file_ops+0x80>
    0.00 :   ffff80001027d34c:       add     x1, x1, #0xd28
    0.00 :   ffff80001027d350:       add     x1, x1, #0x10
    0.00 :   ffff80001027d354:       bl      ffff8000104b30d8 <___ratelimit>
    0.00 :   ffff80001027d358:       cbnz    w0, ffff80001027d4e0 <__find_get_block+0x388>
    0.00 :   ffff80001027d35c:       nop
         : 193              struct buffer_head *ret = NULL;
    0.00 :   ffff80001027d360:       mov     x20, #0x0                       // #0
         : 195              spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff80001027d364:       mov     x0, x26
    0.00 :   ffff80001027d368:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 402              compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff80001027d36c:       ldr     x0, [x23, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff80001027d370:       sub     x1, x0, #0x1
    0.00 :   ffff80001027d374:       tst     x0, #0x1
    0.00 :   ffff80001027d378:       csel    x23, x1, x23, ne  // ne = any
         : 193              page_ref_dec_and_test():
         : 148              return ret;
         : 149              }
         :
         : 151              static inline int page_ref_dec_and_test(struct page *page)
         : 152              {
         : 153              int ret = atomic_dec_and_test(&page->_refcount);
    0.00 :   ffff80001027d37c:       add     x1, x23, #0x34
         : 155              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001027d380:       b       ffff80001027d440 <__find_get_block+0x2e8>
    0.00 :   ffff80001027d384:       b       ffff80001027d440 <__find_get_block+0x2e8>
         : 41               __lse_atomic_sub_return():
         : 141              }
         :
         : 143              ATOMIC_OP_SUB_RETURN(_relaxed,   )
         : 144              ATOMIC_OP_SUB_RETURN(_acquire,  a, "memory")
         : 145              ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
         : 146              ATOMIC_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff80001027d388:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001027d38c:       neg     w0, w0
    0.00 :   ffff80001027d390:       ldaddal w0, w2, [x1]
    0.00 :   ffff80001027d394:       add     w0, w0, w2
         : 151              put_page():
         : 1242             put_devmap_managed_page(page);
         : 1243             return;
         : 1244             }
         :
         : 1246             if (put_page_testzero(page))
         : 1247             __put_page(page);
    0.00 :   ffff80001027d398:       cbz     w0, ffff80001027d430 <__find_get_block+0x2d8>
         : 1249             __find_get_block():
         : 1334             check_irqs_on();
    0.00 :   ffff80001027d39c:       cbz     x20, ffff80001027d274 <__find_get_block+0x11c>
         : 1336             arch_local_save_flags():
         : 70               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d3a0:       mrs     x1, daif
         : 72               arch_irqs_disabled_flags():
         : 85               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d3a4:       and     w0, w1, #0x80
         : 87               check_irqs_on():
         : 1247             brelse(bh);
    0.00 :   ffff80001027d3a8:       cbnz    w0, ffff80001027d43c <__find_get_block+0x2e4>
         : 1249             atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff80001027d3ac:       adrp    x0, ffff800011f52000 <pmus_srcu+0x2c8>
         : 35               bh_lru_install():
         : 1269             };
    0.00 :   ffff80001027d3b0:       mov     x19, x20
         : 1271             atomic_read():
    0.00 :   ffff80001027d3b4:       ldr     w0, [x0, #1784]
         : 29               bh_lru_install():
    0.00 :   ffff80001027d3b8:       cbnz    w0, ffff80001027d274 <__find_get_block+0x11c>
         : 1270             arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001027d3bc:       nop
    0.00 :   ffff80001027d3c0:       mov     x0, #0x60                       // #96
         : 24               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d3c4:       msr     daifset, #0x3
         : 56               __kern_my_cpu_offset():
    0.00 :   ffff80001027d3c8:       mrs     x0, tpidr_el1
         : 40               bh_lru_install():
         : 1274             #define bh_lru_lock()   local_irq_disable()
    0.00 :   ffff80001027d3cc:       add     x0, x21, x0
    0.00 :   ffff80001027d3d0:       mov     x1, x20
    0.00 :   ffff80001027d3d4:       add     x2, x0, #0x80
         : 1276             #else
    0.00 :   ffff80001027d3d8:       ldr     x19, [x0]
    0.00 :   ffff80001027d3dc:       str     x1, [x0]
         : 1277             #define bh_lru_lock()   preempt_disable()
    0.00 :   ffff80001027d3e0:       cmp     x20, x19
    0.00 :   ffff80001027d3e4:       b.eq    ffff80001027d478 <__find_get_block+0x320>  // b.none
    0.00 :   ffff80001027d3e8:       add     x0, x0, #0x8
    0.00 :   ffff80001027d3ec:       mov     x1, x19
         : 1275             #define bh_lru_unlock() local_irq_enable()
    0.00 :   ffff80001027d3f0:       cmp     x0, x2
    0.00 :   ffff80001027d3f4:       b.ne    ffff80001027d3d8 <__find_get_block+0x280>  // b.any
         : 1278             get_bh():
    0.00 :   ffff80001027d3f8:       add     x0, x20, #0x60
         : 280              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001027d3fc:       b       ffff80001027d498 <__find_get_block+0x340>
    0.00 :   ffff80001027d400:       b       ffff80001027d498 <__find_get_block+0x340>
         : 41               __lse_atomic_add():
         : 26               ATOMIC_OP(add, stadd)
    0.00 :   ffff80001027d404:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001027d408:       stadd   w1, [x0]
         : 29               arch_local_irq_enable():
         : 35               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001027d40c:       mov     x0, #0xe0                       // #224
    0.00 :   ffff80001027d410:       msr     daifclr, #0x3
         : 38               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001027d414:       nop
         : 23               brelse():
         : 290              atomic_dec(&bh->b_count);
         : 291              }
         :
         : 293              static inline void brelse(struct buffer_head *bh)
         : 294              {
         : 295              if (bh)
    0.00 :   ffff80001027d418:       cbz     x19, ffff80001027d4b4 <__find_get_block+0x35c>
         : 297              atomic_read():
    0.00 :   ffff80001027d41c:       ldr     w0, [x19, #96]
         : 29               __brelse():
         : 1169             if (mapping)
    0.00 :   ffff80001027d420:       cbnz    w0, ffff80001027d4bc <__find_get_block+0x364>
    0.00 :   ffff80001027d424:       bl      ffff800010279c48 <__brelse.part.52>
    0.00 :   ffff80001027d428:       mov     x19, x20
    0.00 :   ffff80001027d42c:       b       ffff80001027d274 <__find_get_block+0x11c>
         : 1174             put_page():
         : 1243             }
    0.00 :   ffff80001027d430:       mov     x0, x23
    0.00 :   ffff80001027d434:       bl      ffff80001018d6f0 <__put_page>
    0.00 :   ffff80001027d438:       b       ffff80001027d39c <__find_get_block+0x244>
         : 1247             check_irqs_on():
         : 1247             brelse(bh);
    0.00 :   ffff80001027d43c:       brk     #0x800
         : 1249             __ll_sc_atomic_sub_return():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001027d440:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001027d444:       b       ffff8000102806b8 <__arm64_sys_bdflush+0x880>
         : 120              put_page():
         : 1242             __put_page(page);
    0.00 :   ffff80001027d448:       cbnz    w0, ffff80001027d39c <__find_get_block+0x244>
    0.00 :   ffff80001027d44c:       b       ffff80001027d430 <__find_get_block+0x2d8>
         : 1245             arch_static_branch():
    0.00 :   ffff80001027d450:       mov     x0, #0xa0                       // #160
    0.00 :   ffff80001027d454:       b       ffff80001027d3c4 <__find_get_block+0x26c>
         : 23               __ll_sc_atomic_add():
         : 111              ATOMIC_OPS(add, add, I)
    0.00 :   ffff80001027d458:       b       ffff8000102806d4 <__arm64_sys_bdflush+0x89c>
    0.00 :   ffff80001027d45c:       b       ffff80001027d254 <__find_get_block+0xfc>
         : 114              get_bh():
         : 279              atomic_inc(&bh->b_count);
    0.00 :   ffff80001027d460:       add     x0, x20, #0x60
         : 281              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001027d464:       b       ffff80001027d488 <__find_get_block+0x330>
    0.00 :   ffff80001027d468:       b       ffff80001027d488 <__find_get_block+0x330>
         : 41               __lse_atomic_add():
    0.00 :   ffff80001027d46c:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001027d470:       stadd   w1, [x0]
    0.00 :   ffff80001027d474:       b       ffff80001027d364 <__find_get_block+0x20c>
         : 29               arch_local_irq_enable():
    0.00 :   ffff80001027d478:       mov     x0, #0xe0                       // #224
    0.00 :   ffff80001027d47c:       msr     daifclr, #0x3
         : 37               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001027d480:       nop
         : 23               arch_local_irq_enable():
         : 43               pmr_sync();
    0.00 :   ffff80001027d484:       b       ffff80001027d274 <__find_get_block+0x11c>
         : 45               __ll_sc_atomic_add():
    0.00 :   ffff80001027d488:       b       ffff8000102806f0 <__arm64_sys_bdflush+0x8b8>
    0.00 :   ffff80001027d48c:       b       ffff80001027d364 <__find_get_block+0x20c>
         : 113              arch_local_irq_enable():
    0.00 :   ffff80001027d490:       dsb     sy
    0.00 :   ffff80001027d494:       b       ffff80001027d418 <__find_get_block+0x2c0>
         : 45               __ll_sc_atomic_add():
    0.00 :   ffff80001027d498:       b       ffff800010280708 <__arm64_sys_bdflush+0x8d0>
    0.00 :   ffff80001027d49c:       b       ffff80001027d40c <__find_get_block+0x2b4>
         : 113              __find_get_block_slow():
         : 209              head = page_buffers(page);
    0.00 :   ffff80001027d4a0:       brk     #0x800
         : 211              arch_local_irq_enable():
    0.00 :   ffff80001027d4a4:       dsb     sy
    0.00 :   ffff80001027d4a8:       b       ffff80001027d274 <__find_get_block+0x11c>
         : 45               __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001027d4ac:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001027d4b0:       b       ffff800010280720 <__arm64_sys_bdflush+0x8e8>
    0.00 :   ffff80001027d4b4:       mov     x19, x20
    0.00 :   ffff80001027d4b8:       b       ffff80001027d274 <__find_get_block+0x11c>
         : 117              put_bh():
         : 284              smp_mb__before_atomic();
    0.00 :   ffff80001027d4bc:       dmb     ish
         : 285              atomic_dec(&bh->b_count);
    0.00 :   ffff80001027d4c0:       add     x19, x19, #0x60
         : 287              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001027d4c4:       b       ffff80001027d4ac <__find_get_block+0x354>
    0.00 :   ffff80001027d4c8:       b       ffff80001027d4ac <__find_get_block+0x354>
         : 41               __lse_atomic_sub():
         : 113              asm volatile(
    0.00 :   ffff80001027d4cc:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001027d4d0:       neg     w0, w0
    0.00 :   ffff80001027d4d4:       stadd   w0, [x19]
    0.00 :   ffff80001027d4d8:       mov     x19, x20
    0.00 :   ffff80001027d4dc:       b       ffff80001027d274 <__find_get_block+0x11c>
         : 119              __find_get_block_slow():
         : 229              printk("__find_get_block_slow() failed. block=%llu, "
    0.00 :   ffff80001027d4e0:       ldp     x2, x4, [x20, #24]
    0.00 :   ffff80001027d4e4:       mov     x5, x25
    0.00 :   ffff80001027d4e8:       ldr     x3, [x20]
    0.00 :   ffff80001027d4ec:       mov     x1, x22
         : 235              1 << bd_inode->i_blkbits);
    0.00 :   ffff80001027d4f0:       ldrb    w6, [x24, #142]
         : 229              printk("__find_get_block_slow() failed. block=%llu, "
    0.00 :   ffff80001027d4f4:       adrp    x0, ffff80001142d000 <kallsyms_token_index+0x227a0>
         : 193              struct buffer_head *ret = NULL;
    0.00 :   ffff80001027d4f8:       mov     x20, #0x0                       // #0
         : 229              printk("__find_get_block_slow() failed. block=%llu, "
    0.00 :   ffff80001027d4fc:       add     x0, x0, #0x6a8
    0.00 :   ffff80001027d500:       lsl     w6, w27, w6
    0.00 :   ffff80001027d504:       bl      ffff800010e19544 <printk>
    0.00 :   ffff80001027d508:       b       ffff80001027d364 <__find_get_block+0x20c>
 Percent |	Source code & Disassembly of vmlinux for cycles (7 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104b2a78 <__radix_tree_lookup>:
         : 6                __radix_tree_lookup():
         : 748              *       pointing to a node, in which case *@nodep will be NULL.
         : 749              */
         : 750              void *__radix_tree_lookup(const struct radix_tree_root *root,
         : 751              unsigned long index, struct radix_tree_node **nodep,
         : 752              void __rcu ***slotp)
         : 753              {
    0.00 :   ffff8000104b2a78:       mov     x9, x0
    0.00 :   ffff8000104b2a7c:       add     x10, x0, #0x8
         : 756              shift_maxindex():
         : 211              return (RADIX_TREE_MAP_SIZE << shift) - 1;
    0.00 :   ffff8000104b2a80:       mov     x11, #0x40                      // #64
         : 213              __radix_tree_lookup():
         : 748              {
    0.00 :   ffff8000104b2a84:       paciasp
         : 750              radix_tree_load_root():
         : 389              struct radix_tree_node *node = rcu_dereference_raw(root->xa_head);
    0.00 :   ffff8000104b2a88:       ldr     x0, [x9, #8]
         : 391              radix_tree_is_internal_node():
         : 55               #define RADIX_TREE_ENTRY_MASK           3UL
         : 56               #define RADIX_TREE_INTERNAL_NODE        2UL
         :
         : 58               static inline bool radix_tree_is_internal_node(void *ptr)
         : 59               {
         : 60               return ((unsigned long)ptr & RADIX_TREE_ENTRY_MASK) ==
    0.00 :   ffff8000104b2a8c:       and     x6, x0, #0x3
         : 62               radix_tree_load_root():
         : 393              if (likely(radix_tree_is_internal_node(node))) {
    0.00 :   ffff8000104b2a90:       cmp     x6, #0x2
    0.00 :   ffff8000104b2a94:       b.ne    ffff8000104b2b0c <__radix_tree_lookup+0x94>  // b.any
         : 396              entry_to_node():
         : 67               return (void *)((unsigned long)ptr & ~RADIX_TREE_INTERNAL_NODE);
    0.00 :   ffff8000104b2a98:       and     x4, x0, #0xfffffffffffffffd
         : 69               node_maxindex():
         : 216              return shift_maxindex(node->shift);
    0.00 :   ffff8000104b2a9c:       ldrb    w4, [x4]
         : 218              shift_maxindex():
         : 211              return (RADIX_TREE_MAP_SIZE << shift) - 1;
    0.00 :   ffff8000104b2aa0:       lsl     x4, x11, x4
    0.00 :   ffff8000104b2aa4:       sub     x4, x4, #0x1
         : 214              __radix_tree_lookup():
         :
         : 758              restart:
         : 759              parent = NULL;
         : 760              slot = (void __rcu **)&root->xa_head;
         : 761              radix_tree_load_root(root, &node, &maxindex);
         : 762              if (index > maxindex)
    0.00 :   ffff8000104b2aa8:       cmp     x1, x4
   28.63 :   ffff8000104b2aac:       b.hi    ffff8000104b2b1c <__radix_tree_lookup+0xa4>  // b.pmore
         : 755              slot = (void __rcu **)&root->xa_head;
    0.00 :   ffff8000104b2ab0:       mov     x4, x10
         : 754              parent = NULL;
    0.00 :   ffff8000104b2ab4:       mov     x5, #0x0                        // #0
         : 760              return NULL;
         :
         : 762              while (radix_tree_is_internal_node(node)) {
    0.00 :   ffff8000104b2ab8:       cmp     x6, #0x2
    0.00 :   ffff8000104b2abc:       b.ne    ffff8000104b2af4 <__radix_tree_lookup+0x7c>  // b.any
         : 765              entry_to_node():
         : 67               return (void *)((unsigned long)ptr & ~RADIX_TREE_INTERNAL_NODE);
    0.00 :   ffff8000104b2ac0:       and     x5, x0, #0xfffffffffffffffd
         : 69               __radix_tree_lookup():
         : 765              unsigned offset;
         :
         : 767              parent = entry_to_node(node);
         : 768              offset = radix_tree_descend(parent, &node, index);
         : 769              slot = parent->slots + offset;
    0.00 :   ffff8000104b2ac4:       add     x8, x5, #0x28
         : 771              radix_tree_descend():
         : 86               unsigned int offset = (index >> parent->shift) & RADIX_TREE_MAP_MASK;
    0.00 :   ffff8000104b2ac8:       ldrb    w7, [x5]
    0.00 :   ffff8000104b2acc:       lsr     x4, x1, x7
         : 87               void __rcu **entry = rcu_dereference_raw(parent->slots[offset]);
    0.00 :   ffff8000104b2ad0:       and     x4, x4, #0x3f
    0.00 :   ffff8000104b2ad4:       add     x6, x4, #0x4
         : 90               __radix_tree_lookup():
         : 765              slot = parent->slots + offset;
   28.64 :   ffff8000104b2ad8:       add     x4, x8, x4, lsl #3
         : 767              radix_tree_descend():
         : 87               void __rcu **entry = rcu_dereference_raw(parent->slots[offset]);
    0.00 :   ffff8000104b2adc:       add     x6, x5, x6, lsl #3
    0.00 :   ffff8000104b2ae0:       ldr     x0, [x6, #8]
         : 90               __radix_tree_lookup():
         : 145              * Context: Any context.
         : 146              * Return: An XArray internal entry corresponding to this value.
         : 147              */
         : 148              static inline void *xa_mk_internal(unsigned long v)
         : 149              {
         : 150              return (void *)((v << 2) | 2);
    0.00 :   ffff8000104b2ae4:       and     x6, x0, #0x3
         : 766              if (node == RADIX_TREE_RETRY)
    0.00 :   ffff8000104b2ae8:       cmp     x0, #0x402
   14.22 :   ffff8000104b2aec:       b.eq    ffff8000104b2a88 <__radix_tree_lookup+0x10>  // b.none
         : 768              goto restart;
         : 769              if (parent->shift == 0)
   28.51 :   ffff8000104b2af0:       cbnz    w7, ffff8000104b2ab8 <__radix_tree_lookup+0x40>
         : 772              break;
         : 773              }
         :
         : 775              if (nodep)
    0.00 :   ffff8000104b2af4:       cbz     x2, ffff8000104b2afc <__radix_tree_lookup+0x84>
         : 773              *nodep = parent;
    0.00 :   ffff8000104b2af8:       str     x5, [x2]
         : 774              if (slotp)
    0.00 :   ffff8000104b2afc:       cbz     x3, ffff8000104b2b04 <__radix_tree_lookup+0x8c>
         : 775              *slotp = slot;
    0.00 :   ffff8000104b2b00:       str     x4, [x3]
         : 777              return node;
         : 778              }
    0.00 :   ffff8000104b2b04:       autiasp
    0.00 :   ffff8000104b2b08:       ret
         : 757              if (index > maxindex)
    0.00 :   ffff8000104b2b0c:       cbnz    x1, ffff8000104b2b1c <__radix_tree_lookup+0xa4>
         : 755              slot = (void __rcu **)&root->xa_head;
    0.00 :   ffff8000104b2b10:       mov     x4, x10
         : 754              parent = NULL;
    0.00 :   ffff8000104b2b14:       mov     x5, #0x0                        // #0
    0.00 :   ffff8000104b2b18:       b       ffff8000104b2af4 <__radix_tree_lookup+0x7c>
         : 758              return NULL;
    0.00 :   ffff8000104b2b1c:       mov     x0, #0x0                        // #0
    0.00 :   ffff8000104b2b20:       b       ffff8000104b2b04 <__radix_tree_lookup+0x8c>
 Percent |	Source code & Disassembly of vmlinux for cycles (7 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010785880 <iommu_dma_free_iova>:
         : 6                iommu_dma_free_iova():
         :
         : 462              static void iommu_dma_free_iova(struct iommu_dma_cookie *cookie,
         : 463              dma_addr_t iova, size_t size, struct page *freelist)
         : 464              {
         : 465              struct iova_domain *iovad = &cookie->iovad;
         :
    0.00 :   ffff800010785880:       ldr     w4, [x0]
    0.00 :   ffff800010785884:       cmp     w4, #0x1
    0.00 :   ffff800010785888:       b.eq    ffff8000107858cc <iommu_dma_free_iova+0x4c>  // b.none
    0.00 :   ffff80001078588c:       mov     x4, x0
         : 457              static void iommu_dma_free_iova(struct iommu_dma_cookie *cookie,
    0.00 :   ffff800010785890:       paciasp
   28.59 :   ffff800010785894:       stp     x29, x30, [sp, #-16]!
         : 458              dma_addr_t iova, size_t size, struct page *freelist)
    0.00 :   ffff800010785898:       add     x0, x0, #0x8
         : 457              static void iommu_dma_free_iova(struct iommu_dma_cookie *cookie,
    0.00 :   ffff80001078589c:       mov     x29, sp
         : 463              /* The MSI case is only ever cleaning up its most recent allocation */
         : 464              if (cookie->type == IOMMU_DMA_MSI_COOKIE)
    0.00 :   ffff8000107858a0:       ldr     x5, [x4, #1912]
    0.00 :   ffff8000107858a4:       ldr     x4, [x4, #40]
    0.00 :   ffff8000107858a8:       rbit    x4, x4
    0.00 :   ffff8000107858ac:       clz     x4, x4
    0.00 :   ffff8000107858b0:       lsr     x1, x1, x4
    0.00 :   ffff8000107858b4:       lsr     x2, x2, x4
    0.00 :   ffff8000107858b8:       cbz     x5, ffff8000107858dc <iommu_dma_free_iova+0x5c>
         : 464              cookie->msi_iova -= size;
    0.00 :   ffff8000107858bc:       bl      ffff80001078bc70 <queue_iova>
         : 470              else if (cookie->fq_domain)     /* non-strict mode */
         : 471              queue_iova(iovad, iova_pfn(iovad, iova),
         : 472              size >> iova_shift(iovad),
         : 473              (unsigned long)freelist);
         : 474              else
         : 475              free_iova_fast(iovad, iova_pfn(iovad, iova),
    0.00 :   ffff8000107858c0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000107858c4:       autiasp
    0.00 :   ffff8000107858c8:       ret
         : 462              /* The MSI case is only ever cleaning up its most recent allocation */
    0.00 :   ffff8000107858cc:       ldr     x1, [x0, #8]
    0.00 :   ffff8000107858d0:       sub     x2, x1, x2
    0.00 :   ffff8000107858d4:       str     x2, [x0, #8]
    0.00 :   ffff8000107858d8:       ret
         : 468              (unsigned long)freelist);
   57.18 :   ffff8000107858dc:       bl      ffff80001078b858 <free_iova_fast>
         : 470              free_iova_fast(iovad, iova_pfn(iovad, iova),
    0.00 :   ffff8000107858e0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000107858e4:       autiasp
   14.23 :   ffff8000107858e8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (8 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102354b8 <fput_many>:
         : 6                fput_many():
         : 335              EXPORT_SYMBOL_GPL(flush_delayed_fput);
         :
         : 337              static DECLARE_DELAYED_WORK(delayed_fput_work, delayed_fput);
         :
         : 339              void fput_many(struct file *file, unsigned int refs)
         : 340              {
    0.00 :   ffff8000102354b8:       paciasp
    0.00 :   ffff8000102354bc:       stp     x29, x30, [sp, #-32]!
         : 336              if (atomic_long_sub_and_test(refs, &file->f_count)) {
    0.00 :   ffff8000102354c0:       mov     w1, w1
         : 335              {
    0.00 :   ffff8000102354c4:       mov     x29, sp
         : 337              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000102354c8:       b       ffff800010235564 <fput_many+0xac>
    0.00 :   ffff8000102354cc:       b       ffff800010235564 <fput_many+0xac>
    0.00 :   ffff8000102354d0:       add     x2, x0, #0x38
         : 47               __lse_atomic64_sub_return():
         : 294              }
         :
         : 296              ATOMIC64_OP_SUB_RETURN(_relaxed,   )
         : 297              ATOMIC64_OP_SUB_RETURN(_acquire,  a, "memory")
         : 298              ATOMIC64_OP_SUB_RETURN(_release,  l, "memory")
         : 299              ATOMIC64_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff8000102354d4:       neg     x1, x1
    0.00 :   ffff8000102354d8:       ldaddal x1, x3, [x2]
   82.68 :   ffff8000102354dc:       add     x1, x1, x3
         : 303              fput_many():
         : 336              if (atomic_long_sub_and_test(refs, &file->f_count)) {
    0.00 :   ffff8000102354e0:       cbnz    x1, ffff800010235558 <fput_many+0xa0>
         : 338              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000102354e4:       str     x19, [sp, #16]
    0.00 :   ffff8000102354e8:       mov     x19, x0
    0.00 :   ffff8000102354ec:       mrs     x0, sp_el0
         : 28               preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000102354f0:       ldr     w1, [x0, #8]
    0.00 :   ffff8000102354f4:       ldr     w3, [x0, #8]
    0.00 :   ffff8000102354f8:       ldr     w2, [x0, #8]
         : 21               fput_many():
         : 339              struct task_struct *task = current;
         :
         : 341              if (likely(!in_interrupt() && !(task->flags & PF_KTHREAD))) {
    0.00 :   ffff8000102354fc:       and     w1, w1, #0xf00000
    0.00 :   ffff800010235500:       and     w3, w3, #0xf0000
    0.00 :   ffff800010235504:       orr     w1, w1, w3
    0.00 :   ffff800010235508:       and     w2, w2, #0xff00
    0.00 :   ffff80001023550c:       orr     w1, w1, w2
    0.00 :   ffff800010235510:       cbnz    w1, ffff800010235538 <fput_many+0x80>
    0.00 :   ffff800010235514:       ldr     w1, [x0, #36]
    0.00 :   ffff800010235518:       tbnz    w1, #21, ffff800010235538 <fput_many+0x80>
         : 350              init_task_work():
         : 13               typedef void (*task_work_func_t)(struct callback_head *);
         :
         : 15               static inline void
         : 16               init_task_work(struct callback_head *twork, task_work_func_t func)
         : 17               {
         : 18               twork->func = func;
    0.00 :   ffff80001023551c:       adrp    x1, ffff800010235000 <__fput+0x208>
    0.00 :   ffff800010235520:       add     x1, x1, #0x98
    0.00 :   ffff800010235524:       str     x1, [x19, #8]
         : 22               fput_many():
         : 341              init_task_work(&file->f_u.fu_rcuhead, ____fput);
         : 342              if (!task_work_add(task, &file->f_u.fu_rcuhead, TWA_RESUME))
    0.00 :   ffff800010235528:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001023552c:       mov     x1, x19
    0.00 :   ffff800010235530:       bl      ffff8000100a5b80 <task_work_add>
    0.00 :   ffff800010235534:       cbz     w0, ffff800010235554 <fput_many+0x9c>
         : 347              llist_add():
         : 219              *
         : 220              * Returns true if the list was empty prior to adding this entry.
         : 221              */
         : 222              static inline bool llist_add(struct llist_node *new, struct llist_head *head)
         : 223              {
         : 224              return llist_add_batch(new, new, head);
    0.00 :   ffff800010235538:       adrp    x2, ffff800011f5e000 <cma_areas+0x710>
    0.00 :   ffff80001023553c:       mov     x1, x19
    0.00 :   ffff800010235540:       add     x2, x2, #0x88
    0.00 :   ffff800010235544:       mov     x0, x19
    0.00 :   ffff800010235548:       bl      ffff80001046d1c0 <llist_add_batch>
         : 230              fput_many():
         : 350              * task_work_add() will fail.  Fall through to delayed
         : 351              * fput to avoid leaking *file.
         : 352              */
         : 353              }
         :
         : 355              if (llist_add(&file->f_u.fu_llist, &delayed_fput_list))
    0.00 :   ffff80001023554c:       tst     w0, #0xff
    0.00 :   ffff800010235550:       b.ne    ffff800010235574 <fput_many+0xbc>  // b.any
    0.00 :   ffff800010235554:       ldr     x19, [sp, #16]
         : 353              schedule_delayed_work(&delayed_fput_work, 1);
         : 354              }
         : 355              }
    0.00 :   ffff800010235558:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001023555c:       autiasp
   17.32 :   ffff800010235560:       ret
         : 359              __ll_sc_atomic64_sub_return():
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
         : 216              ATOMIC64_OPS(sub, sub, J)
    0.00 :   ffff800010235564:       add     x4, x0, #0x38
    0.00 :   ffff800010235568:       b       ffff8000102356b4 <__fput_sync+0xec>
    0.00 :   ffff80001023556c:       mov     x1, x2
    0.00 :   ffff800010235570:       b       ffff8000102354e0 <fput_many+0x28>
         : 221              schedule_delayed_work():
         : 626              * After waiting for a given time this puts a job in the kernel-global
         : 627              * workqueue.
         : 628              */
         : 629              static inline bool schedule_delayed_work(struct delayed_work *dwork,
         : 630              unsigned long delay)
         : 631              {
    0.00 :   ffff800010235574:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
         : 633              queue_delayed_work():
         : 522              {
    0.00 :   ffff800010235578:       adrp    x2, ffff800011cc1000 <hugetlb_cgrp_subsys+0x88>
    0.00 :   ffff80001023557c:       add     x2, x2, #0x280
    0.00 :   ffff800010235580:       mov     x3, #0x1                        // #1
    0.00 :   ffff800010235584:       ldr     x1, [x0, #2712]
    0.00 :   ffff800010235588:       add     x2, x2, #0x18
    0.00 :   ffff80001023558c:       mov     w0, #0x100                      // #256
    0.00 :   ffff800010235590:       bl      ffff8000100a0d98 <queue_delayed_work_on>
    0.00 :   ffff800010235594:       ldr     x19, [sp, #16]
         : 531              fput_many():
    0.00 :   ffff800010235598:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001023559c:       autiasp
    0.00 :   ffff8000102355a0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (6 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101d9dc8 <rmqueue_bulk.constprop.127>:
         : 6                rmqueue_bulk():
         :
         : 2953             /*
         : 2954             * Find the largest available free page in the other list. This roughly
         : 2955             * approximates finding the pageblock with the most free pages, which
         : 2956             * would be too costly to do exactly.
         : 2957             */
    0.00 :   ffff8000101d9dc8:       paciasp
    0.00 :   ffff8000101d9dcc:       stp     x29, x30, [sp, #-160]!
    0.00 :   ffff8000101d9dd0:       mov     x29, sp
    0.00 :   ffff8000101d9dd4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101d9dd8:       mov     x20, x1
    0.00 :   ffff8000101d9ddc:       mov     x19, x0
    0.00 :   ffff8000101d9de0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101d9de4:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101d9de8:       add     x5, x21, #0x948
    0.00 :   ffff8000101d9dec:       stp     x25, x26, [sp, #64]
         : 2968             spin_lock():
         : 354              # define spin_lock_init(_lock)                  \
         : 355              do {                                            \
         : 356              spinlock_check(_lock);                  \
         : 357              *(_lock) = __SPIN_LOCK_UNLOCKED(_lock); \
         : 358              } while (0)
         :
    0.00 :   ffff8000101d9df0:       add     x0, x0, #0x540
         : 361              rmqueue_bulk():
    0.00 :   ffff8000101d9df4:       mov     w22, w3
    0.00 :   ffff8000101d9df8:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000101d9dfc:       mov     w21, w4
    0.00 :   ffff8000101d9e00:       mov     x28, x2
    0.00 :   ffff8000101d9e04:       ldr     x1, [x5]
    0.00 :   ffff8000101d9e08:       str     x1, [sp, #152]
    0.00 :   ffff8000101d9e0c:       mov     x1, #0x0                        // #0
    0.00 :   ffff8000101d9e10:       str     w3, [sp, #116]
    0.00 :   ffff8000101d9e14:       stp     x0, x5, [sp, #120]
    0.00 :   ffff8000101d9e18:       str     w4, [sp, #136]
         : 2962             spin_lock():
    0.00 :   ffff8000101d9e1c:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 355              rmqueue_bulk():
         : 2959             --current_order) {
         : 2960             area = &(zone->free_area[current_order]);
         : 2961             fallback_mt = find_suitable_fallback(area, current_order,
         : 2962             start_migratetype, false, &can_steal);
         : 2963             if (fallback_mt == -1)
         : 2964             continue;
    0.00 :   ffff8000101d9e20:       cbz     x20, ffff8000101da410 <rmqueue_bulk.constprop.127+0x648>
         : 2966             __rmqueue():
         : 2923             * fallback was found so that __rmqueue_smallest() can grab it.
    0.00 :   ffff8000101d9e24:       mov     x0, x21
    0.00 :   ffff8000101d9e28:       sxtw    x27, w22
    0.00 :   ffff8000101d9e2c:       mov     w25, #0x9                       // #9
    0.00 :   ffff8000101d9e30:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000101d9e34:       tst     x0, #0x100
    0.00 :   ffff8000101d9e38:       csel    w0, w25, wzr, ne  // ne = any
    0.00 :   ffff8000101d9e3c:       str     w0, [sp, #140]
    0.00 :   ffff8000101d9e40:       and     w22, w21, #0x80
         : 2932             list_del():
         : 147              * in an undefined state.
         : 148              */
         : 149              static inline void list_del(struct list_head *entry)
         : 150              {
         : 151              __list_del_entry(entry);
         : 152              entry->next = LIST_POISON1;
    0.00 :   ffff8000101d9e44:       mov     x21, #0x100                     // #256
    0.00 :   ffff8000101d9e48:       lsl     x26, x27, #4
         : 155              rmqueue_bulk():
         : 2959             continue;
    0.00 :   ffff8000101d9e4c:       mov     w24, #0x0                       // #0
         : 2956             fallback_mt = find_suitable_fallback(area, current_order,
    0.00 :   ffff8000101d9e50:       mov     w25, #0x0                       // #0
         : 2958             __rmqueue_fallback():
         : 2882             */
    0.00 :   ffff8000101d9e54:       mov     w23, #0x1                       // #1
         : 2884             list_del():
    0.00 :   ffff8000101d9e58:       movk    x21, #0xdead, lsl #48
         : 148              __rmqueue():
         : 2923             * fallback was found so that __rmqueue_smallest() can grab it.
    0.00 :   ffff8000101d9e5c:       cbnz    w22, ffff8000101d9fdc <rmqueue_bulk.constprop.127+0x214>
    0.00 :   ffff8000101d9e60:       add     x6, x26, #0xc0
         : 2926             get_page_from_free_area():
         : 104              unsigned long           nr_free;
         : 105              };
         :
         : 107              static inline struct page *get_page_from_free_area(struct free_area *area,
         : 108              int migratetype)
         : 109              {
    0.00 :   ffff8000101d9e64:       lsl     x5, x27, #4
         : 111              __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101d9e68:       add     x2, x19, x6
    0.00 :   ffff8000101d9e6c:       mov     w3, #0x0                        // #0
         : 2391             get_page_from_free_area():
    0.00 :   ffff8000101d9e70:       mov     w1, w3
    0.00 :   ffff8000101d9e74:       add     x0, x1, x1, lsl #1
    0.00 :   ffff8000101d9e78:       add     x0, x1, x0, lsl #2
    0.00 :   ffff8000101d9e7c:       add     x0, x5, x0, lsl #3
    0.00 :   ffff8000101d9e80:       add     x0, x19, x0
    0.00 :   ffff8000101d9e84:       ldr     x16, [x0, #192]
    0.00 :   ffff8000101d9e88:       cmp     x16, x2
    0.00 :   ffff8000101d9e8c:       b.eq    ffff8000101da164 <rmqueue_bulk.constprop.127+0x39c>  // b.none
    0.00 :   ffff8000101d9e90:       sub     x15, x16, #0x8
    0.00 :   ffff8000101d9e94:       mov     x0, x15
         : 114              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101d9e98:       cbz     x15, ffff8000101da164 <rmqueue_bulk.constprop.127+0x39c>
         : 2393             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000101d9e9c:       nop
         : 28               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101d9ea0:       ldp     x5, x4, [x16]
         : 148              __list_del():
         : 112              next->prev = prev;
   63.82 :   ffff8000101d9ea4:       str     x4, [x5, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101d9ea8:       mov     x13, #0x122                     // #290
         : 150              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101d9eac:       add     x2, x1, x1, lsl #1
         : 967              list_del():
    0.00 :   ffff8000101d9eb0:       movk    x13, #0xdead, lsl #48
   18.18 :   ffff8000101d9eb4:       sub     w7, w3, #0x1
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101d9eb8:       add     x1, x1, x2, lsl #2
         : 966              expand():
         : 2228             */
    0.00 :   ffff8000101d9ebc:       lsl     w6, w23, w3
    0.00 :   ffff8000101d9ec0:       sxtw    x7, w7
    0.00 :   ffff8000101d9ec4:       sxtw    x6, w6
         : 2232             __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101d9ec8:       str     x5, [x4]
         : 115              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101d9ecc:       add     x1, x19, x1, lsl #3
         : 967              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101d9ed0:       stp     x21, x13, [x16]
         : 150              add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101d9ed4:       mov     w30, #0x68                      // #104
    0.00 :   ffff8000101d9ed8:       mov     x18, #0xc0                      // #192
         : 931              __ClearPageBuddy():
         :
         : 743              static inline int page_has_type(struct page *page)
         : 744              {
         : 745              return (int)page->page_type < PAGE_MAPCOUNT_RESERVE;
         : 746              }
         :
    0.00 :   ffff8000101d9edc:       ldr     w2, [x15, #48]
         : 749              list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101d9ee0:       lsl     x17, x27, #4
         : 88               __ClearPageBuddy():
    0.00 :   ffff8000101d9ee4:       orr     w2, w2, #0x80
    0.00 :   ffff8000101d9ee8:       str     w2, [x15, #48]
         : 744              set_page_private():
         : 249              }
         :
         : 251              /*
         : 252              * Used for sizing the vmemmap region on some architectures
         : 253              */
         : 254              #define STRUCT_PAGE_MAX_SHIFT   (order_base_2(sizeof(struct page)))
    0.00 :   ffff8000101d9eec:       str     xzr, [x16, #32]
         : 256              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101d9ef0:       ldr     x2, [x1, #288]
    0.00 :   ffff8000101d9ef4:       sub     x2, x2, #0x1
   18.00 :   ffff8000101d9ef8:       str     x2, [x1, #288]
         : 969              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101d9efc:       cbz     w3, ffff8000101d9f6c <rmqueue_bulk.constprop.127+0x1a4>
         : 2231             {
    0.00 :   ffff8000101d9f00:       sub     w5, w3, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101d9f04:       lsr     x6, x6, #1
         : 2231             {
    0.00 :   ffff8000101d9f08:       mov     x3, x5
         : 2233             list_add():
    0.00 :   ffff8000101d9f0c:       add     x1, x5, x5, lsl #1
         : 87               expand():
         :
    0.00 :   ffff8000101d9f10:       add     x2, x15, x6, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101d9f14:       smaddl  x4, w5, w30, x18
    0.00 :   ffff8000101d9f18:       add     x13, x2, #0x8
         : 931              list_add():
    0.00 :   ffff8000101d9f1c:       add     x1, x5, x1, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101d9f20:       add     x4, x4, x26
         : 929              list_add():
    0.00 :   ffff8000101d9f24:       lsl     x1, x1, #3
         : 87               add_to_free_list():
    0.00 :   ffff8000101d9f28:       add     x14, x19, x4
         : 929              list_add():
    0.00 :   ffff8000101d9f2c:       add     x5, x17, x1
         : 87               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101d9f30:       add     x1, x19, x1
         : 931              list_add():
    0.00 :   ffff8000101d9f34:       add     x5, x19, x5
    0.00 :   ffff8000101d9f38:       ldr     x5, [x5, #192]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101d9f3c:       str     x13, [x5, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101d9f40:       stp     x5, x14, [x2, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101d9f44:       str     x13, [x19, x4]
         : 75               add_to_free_list():
    0.00 :   ffff8000101d9f48:       ldr     x4, [x1, #288]
    0.00 :   ffff8000101d9f4c:       add     x4, x4, #0x1
    0.00 :   ffff8000101d9f50:       str     x4, [x1, #288]
         : 932              set_page_private():
    0.00 :   ffff8000101d9f54:       str     x7, [x2, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101d9f58:       sub     x7, x7, #0x1
    0.00 :   ffff8000101d9f5c:       ldr     w1, [x2, #48]
    0.00 :   ffff8000101d9f60:       and     w1, w1, #0xffffff7f
    0.00 :   ffff8000101d9f64:       str     w1, [x2, #48]
         : 746              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101d9f68:       cbnz    w3, ffff8000101d9f00 <rmqueue_bulk.constprop.127+0x138>
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101d9f6c:       str     x27, [x16, #24]
         : 220              atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff8000101d9f70:       ldr     w1, [x0, #48]
         : 35               page_expected_state():
         : 1126             * merge with it and move up one order.
    0.00 :   ffff8000101d9f74:       cmn     w1, #0x1
    0.00 :   ffff8000101d9f78:       b.ne    ffff8000101da100 <rmqueue_bulk.constprop.127+0x338>  // b.any
         : 1129             atomic_read():
    0.00 :   ffff8000101d9f7c:       ldr     w3, [x0, #52]
         : 29               page_expected_state():
         : 1129             clear_page_guard(zone, buddy, order, migratetype);
    0.00 :   ffff8000101d9f80:       ldr     x1, [x0]
    0.00 :   ffff8000101d9f84:       ldr     x2, [x0, #24]
    0.00 :   ffff8000101d9f88:       sxtw    x3, w3
    0.00 :   ffff8000101d9f8c:       ldr     x4, [x0, #56]
    0.00 :   ffff8000101d9f90:       and     x1, x1, #0xffffff
    0.00 :   ffff8000101d9f94:       orr     x2, x2, x3
    0.00 :   ffff8000101d9f98:       orr     x1, x1, x4
    0.00 :   ffff8000101d9f9c:       orr     x1, x1, x2
    0.00 :   ffff8000101d9fa0:       cbnz    x1, ffff8000101da100 <rmqueue_bulk.constprop.127+0x338>
         : 1139             list_add_tail():
         : 100              __list_add(new, head->prev, head);
    0.00 :   ffff8000101d9fa4:       ldr     x1, [x28, #8]
         : 102              rmqueue_bulk():
         : 2978             goto do_steal;
         : 2979             }
         :
         : 2981             return false;
         :
         : 2983             find_smallest:
    0.00 :   ffff8000101d9fa8:       add     x2, x0, #0x8
         : 2985             __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101d9fac:       str     x2, [x28, #8]
         : 72               rmqueue_bulk():
         : 2979             for (current_order = order; current_order < MAX_ORDER;
    0.00 :   ffff8000101d9fb0:       add     w25, w25, #0x1
         : 2981             __list_add():
         : 72               new->prev = prev;
    0.00 :   ffff8000101d9fb4:       stp     x28, x1, [x0, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101d9fb8:       str     x2, [x1]
         : 75               get_pcppage_migratetype():
         : 213              static bool _init_on_free_enabled_early __read_mostly
    0.00 :   ffff8000101d9fbc:       ldr     x0, [x0, #32]
         : 215              rmqueue_bulk():
         : 2980             current_order++) {
    0.00 :   ffff8000101d9fc0:       cmp     w0, #0x4
    0.00 :   ffff8000101d9fc4:       b.eq    ffff8000101da24c <rmqueue_bulk.constprop.127+0x484>  // b.none
         : 2959             continue;
    0.00 :   ffff8000101d9fc8:       add     w0, w24, #0x1
    0.00 :   ffff8000101d9fcc:       cmp     x20, w0, sxtw
    0.00 :   ffff8000101d9fd0:       b.ls    ffff8000101da110 <rmqueue_bulk.constprop.127+0x348>  // b.plast
    0.00 :   ffff8000101d9fd4:       mov     w24, w0
         : 2964             __rmqueue():
         : 2923             * fallback was found so that __rmqueue_smallest() can grab it.
    0.00 :   ffff8000101d9fd8:       cbz     w22, ffff8000101d9e60 <rmqueue_bulk.constprop.127+0x98>
         : 2925             atomic64_read():
         : 838              static __always_inline s64
         : 839              atomic64_dec_return_acquire(atomic64_t *v)
         : 840              {
         : 841              instrument_atomic_read_write(v, sizeof(*v));
         : 842              return arch_atomic64_dec_return_acquire(v);
         : 843              }
    0.00 :   ffff8000101d9fdc:       ldr     x0, [x19, #1544]
    0.00 :   ffff8000101d9fe0:       ldr     x1, [x19, #1472]
         : 846              zone_page_state():
         :
         : 223              /*
         : 224              * More accurate version that also considers the currently pending
         : 225              * deltas. For that we need to loop over all cpus to find the current
         : 226              * deltas. There is no synchronization so the result cannot be
         : 227              * exactly accurate either.
    0.00 :   ffff8000101d9fe4:       cmp     x0, #0x0
    0.00 :   ffff8000101d9fe8:       csel    x0, x0, xzr, ge  // ge = tcont
    0.00 :   ffff8000101d9fec:       cmp     x1, #0x0
    0.00 :   ffff8000101d9ff0:       csel    x1, x1, xzr, ge  // ge = tcont
         : 232              __rmqueue():
    0.00 :   ffff8000101d9ff4:       cmp     x0, x1, lsr #1
    0.00 :   ffff8000101d9ff8:       b.ls    ffff8000101d9e60 <rmqueue_bulk.constprop.127+0x98>  // b.plast
    0.00 :   ffff8000101d9ffc:       add     x3, x19, #0x100
         : 2926             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101da000:       mov     w1, #0x0                        // #0
         : 2390             get_page_from_free_area():
    0.00 :   ffff8000101da004:       mov     w2, w1
    0.00 :   ffff8000101da008:       add     x0, x2, x2, lsl #1
    0.00 :   ffff8000101da00c:       add     x0, x2, x0, lsl #2
    0.00 :   ffff8000101da010:       add     x0, x19, x0, lsl #3
    0.00 :   ffff8000101da014:       ldr     x13, [x0, #256]
    0.00 :   ffff8000101da018:       cmp     x13, x3
    0.00 :   ffff8000101da01c:       b.eq    ffff8000101da238 <rmqueue_bulk.constprop.127+0x470>  // b.none
    0.00 :   ffff8000101da020:       sub     x7, x13, #0x8
    0.00 :   ffff8000101da024:       mov     x0, x7
         : 113              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101da028:       cbz     x7, ffff8000101da238 <rmqueue_bulk.constprop.127+0x470>
         : 2393             arch_static_branch():
    0.00 :   ffff8000101da02c:       nop
         : 22               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101da030:       ldp     x5, x3, [x13]
         : 148              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101da034:       str     x3, [x5, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101da038:       mov     x14, #0x122                     // #290
         : 150              __rmqueue_smallest():
         : 2394             static inline bool check_pcp_refill(struct page *page)
    0.00 :   ffff8000101da03c:       mov     w4, w1
         : 2396             list_del():
    0.00 :   ffff8000101da040:       movk    x14, #0xdead, lsl #48
         : 149              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da044:       add     x1, x2, x2, lsl #1
    0.00 :   ffff8000101da048:       sub     w6, w4, #0x1
         : 968              add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101da04c:       mov     w15, #0x68                      // #104
         : 930              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da050:       add     x1, x2, x1, lsl #2
         : 967              __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101da054:       str     x5, [x3]
         : 115              expand():
         : 2228             */
    0.00 :   ffff8000101da058:       lsl     w5, w23, w4
         : 2230             list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101da05c:       stp     x21, x14, [x13]
         : 150              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da060:       add     x1, x19, x1, lsl #3
    0.00 :   ffff8000101da064:       sxtw    x6, w6
         : 968              __ClearPageBuddy():
    0.00 :   ffff8000101da068:       ldr     w2, [x7, #48]
         : 743              expand():
         : 2228             */
    0.00 :   ffff8000101da06c:       sxtw    x5, w5
         : 2230             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101da070:       mov     x14, #0x100                     // #256
         : 930              __ClearPageBuddy():
    0.00 :   ffff8000101da074:       orr     w2, w2, #0x80
    0.00 :   ffff8000101da078:       str     w2, [x7, #48]
         : 744              set_page_private():
    0.00 :   ffff8000101da07c:       str     xzr, [x13, #32]
         : 250              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da080:       ldr     x2, [x1, #288]
    0.00 :   ffff8000101da084:       sub     x2, x2, #0x1
    0.00 :   ffff8000101da088:       str     x2, [x1, #288]
         : 969              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101da08c:       cbz     w4, ffff8000101da0ec <rmqueue_bulk.constprop.127+0x324>
         : 2231             {
    0.00 :   ffff8000101da090:       sub     w18, w4, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101da094:       lsr     x5, x5, #1
         : 2231             {
    0.00 :   ffff8000101da098:       mov     x4, x18
         : 2233             list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101da09c:       add     x1, x18, x18, lsl #1
         : 88               expand():
         :
    0.00 :   ffff8000101da0a0:       add     x3, x7, x5, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101da0a4:       smaddl  x2, w18, w15, x14
    0.00 :   ffff8000101da0a8:       add     x16, x3, #0x8
         : 931              list_add():
    0.00 :   ffff8000101da0ac:       add     x1, x18, x1, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101da0b0:       add     x17, x19, x2
         : 929              list_add():
    0.00 :   ffff8000101da0b4:       add     x1, x19, x1, lsl #3
    0.00 :   ffff8000101da0b8:       ldr     x18, [x1, #256]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101da0bc:       str     x16, [x18, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101da0c0:       stp     x18, x17, [x3, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101da0c4:       str     x16, [x19, x2]
         : 75               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101da0c8:       ldr     x2, [x1, #288]
    0.00 :   ffff8000101da0cc:       add     x2, x2, #0x1
    0.00 :   ffff8000101da0d0:       str     x2, [x1, #288]
         : 933              set_page_private():
    0.00 :   ffff8000101da0d4:       str     x6, [x3, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101da0d8:       sub     x6, x6, #0x1
    0.00 :   ffff8000101da0dc:       ldr     w2, [x3, #48]
    0.00 :   ffff8000101da0e0:       and     w2, w2, #0xffffff7f
    0.00 :   ffff8000101da0e4:       str     w2, [x3, #48]
         : 746              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101da0e8:       cbnz    w4, ffff8000101da090 <rmqueue_bulk.constprop.127+0x2c8>
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101da0ec:       mov     x1, #0x4                        // #4
    0.00 :   ffff8000101da0f0:       str     x1, [x13, #24]
         : 221              atomic_read():
         : 28               return arch_atomic_read(v);
    0.00 :   ffff8000101da0f4:       ldr     w1, [x0, #48]
         : 30               page_expected_state():
         : 1126             * merge with it and move up one order.
    0.00 :   ffff8000101da0f8:       cmn     w1, #0x1
    0.00 :   ffff8000101da0fc:       b.eq    ffff8000101d9f7c <rmqueue_bulk.constprop.127+0x1b4>  // b.none
         : 1129             check_new_page():
         :
    0.00 :   ffff8000101da100:       bl      ffff8000101d7088 <check_new_page_bad>
         : 2272             rmqueue_bulk():
         : 2959             continue;
    0.00 :   ffff8000101da104:       add     w0, w24, #0x1
    0.00 :   ffff8000101da108:       cmp     x20, w0, sxtw
    0.00 :   ffff8000101da10c:       b.hi    ffff8000101d9fd4 <rmqueue_bulk.constprop.127+0x20c>  // b.pmore
    0.00 :   ffff8000101da110:       mvn     w2, w24
    0.00 :   ffff8000101da114:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000101da118:       sxtw    x2, w2
         : 2991             }
         :
         : 2993             /*
         : 2994             * This should not happen - we already found a suitable fallback
         : 2995             * when looking for the largest page.
         : 2996             */
    0.00 :   ffff8000101da11c:       mov     x0, x19
    0.00 :   ffff8000101da120:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101da124:       bl      ffff8000101a4ca0 <__mod_zone_page_state>
         : 3000             spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000101da128:       ldr     x0, [sp, #120]
    0.00 :   ffff8000101da12c:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 402              rmqueue_bulk():
         : 2994             VM_BUG_ON(current_order == MAX_ORDER);
         :
         : 2996             do_steal:
    0.00 :   ffff8000101da130:       ldr     x1, [sp, #128]
    0.00 :   ffff8000101da134:       mov     w0, w25
    0.00 :   ffff8000101da138:       ldr     x2, [sp, #152]
    0.00 :   ffff8000101da13c:       ldr     x1, [x1]
    0.00 :   ffff8000101da140:       eor     x1, x2, x1
    0.00 :   ffff8000101da144:       cbnz    x1, ffff8000101da41c <rmqueue_bulk.constprop.127+0x654>
    0.00 :   ffff8000101da148:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101da14c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101da150:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000101da154:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000101da158:       ldp     x29, x30, [sp], #160
    0.00 :   ffff8000101da15c:       autiasp
    0.00 :   ffff8000101da160:       ret
         : 3010             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101da164:       add     w3, w3, #0x1
    0.00 :   ffff8000101da168:       add     x2, x2, #0x68
    0.00 :   ffff8000101da16c:       cmp     w3, #0xb
    0.00 :   ffff8000101da170:       b.ne    ffff8000101d9e70 <rmqueue_bulk.constprop.127+0xa8>  // b.any
         : 2393             __rmqueue():
         : 2934             int current_order;
    0.00 :   ffff8000101da174:       cbnz    w22, ffff8000101da2b4 <rmqueue_bulk.constprop.127+0x4ec>
    0.00 :   ffff8000101da178:       add     x15, x19, #0x4d0
         : 2937             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101da17c:       mov     w14, #0xa                       // #10
         : 2390             __rmqueue_fallback():
         : 2856             bool ret;
    0.00 :   ffff8000101da180:       ldr     w2, [sp, #116]
    0.00 :   ffff8000101da184:       add     x4, sp, #0x97
    0.00 :   ffff8000101da188:       mov     w3, #0x0                        // #0
    0.00 :   ffff8000101da18c:       mov     w1, w14
    0.00 :   ffff8000101da190:       mov     x0, x15
    0.00 :   ffff8000101da194:       stp     x5, x6, [sp, #96]
    0.00 :   ffff8000101da198:       bl      ffff8000101d9d30 <find_suitable_fallback>
         : 2855             int order;
    0.00 :   ffff8000101da19c:       mov     x13, x15
         : 2858             for_each_zone_zonelist_nodemask(zone, z, zonelist, ac->highest_zoneidx,
    0.00 :   ffff8000101da1a0:       cmn     w0, #0x1
    0.00 :   ffff8000101da1a4:       ldp     x5, x6, [sp, #96]
    0.00 :   ffff8000101da1a8:       b.eq    ffff8000101da3b0 <rmqueue_bulk.constprop.127+0x5e8>  // b.none
         : 2869             for (order = 0; order < MAX_ORDER; order++) {
    0.00 :   ffff8000101da1ac:       ldrb    w4, [sp, #151]
    0.00 :   ffff8000101da1b0:       cbnz    w4, ffff8000101da278 <rmqueue_bulk.constprop.127+0x4b0>
    0.00 :   ffff8000101da1b4:       ldr     w1, [sp, #116]
    0.00 :   ffff8000101da1b8:       cmp     w1, #0x1
    0.00 :   ffff8000101da1bc:       cset    w4, eq  // eq = none
         : 2870             struct free_area *area = &(zone->free_area[order]);
    0.00 :   ffff8000101da1c0:       cmp     w14, #0x0
    0.00 :   ffff8000101da1c4:       cset    w1, gt
    0.00 :   ffff8000101da1c8:       ands    w4, w4, w1
    0.00 :   ffff8000101da1cc:       b.eq    ffff8000101da278 <rmqueue_bulk.constprop.127+0x4b0>  // b.none
    0.00 :   ffff8000101da1d0:       add     x0, x19, #0xc0
         : 2879             * in this loop although we changed the pageblock type
    0.00 :   ffff8000101da1d4:       mov     w14, #0x0                       // #0
         : 2881             * adjust the count once.
    0.00 :   ffff8000101da1d8:       mov     x13, x0
         : 2882             */
    0.00 :   ffff8000101da1dc:       add     x4, sp, #0x97
    0.00 :   ffff8000101da1e0:       mov     w3, #0x0                        // #0
    0.00 :   ffff8000101da1e4:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000101da1e8:       mov     w1, w14
    0.00 :   ffff8000101da1ec:       stp     x5, x6, [sp, #96]
    0.00 :   ffff8000101da1f0:       bl      ffff8000101d9d30 <find_suitable_fallback>
         : 2884             /*
    0.00 :   ffff8000101da1f4:       cmn     w0, #0x1
    0.00 :   ffff8000101da1f8:       ldp     x5, x6, [sp, #96]
    0.00 :   ffff8000101da1fc:       b.ne    ffff8000101da3e8 <rmqueue_bulk.constprop.127+0x620>  // b.any
         : 2880             * from highatomic to ac->migratetype. So we should
    0.00 :   ffff8000101da200:       add     w14, w14, #0x1
    0.00 :   ffff8000101da204:       add     x0, x13, #0x68
         : 2879             * in this loop although we changed the pageblock type
    0.00 :   ffff8000101da208:       cmp     w14, #0xb
    0.00 :   ffff8000101da20c:       b.ne    ffff8000101da1d8 <rmqueue_bulk.constprop.127+0x410>  // b.any
    0.00 :   ffff8000101da210:       ldrb    w4, [sp, #151]
    0.00 :   ffff8000101da214:       mov     x7, #0xfffffffffffffff0         // #-16
    0.00 :   ffff8000101da218:       mov     x0, #0xffffffffffffffff         // #-1
    0.00 :   ffff8000101da21c:       b       ffff8000101da280 <rmqueue_bulk.constprop.127+0x4b8>
         : 2886             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101da220:       ldur    x2, [x16, #-8]
         : 113              page_reported():
         : 21               DECLARE_STATIC_KEY_FALSE(page_reporting_enabled);
         : 22               void __page_reporting_notify(void);
         :
         : 24               static inline bool page_reported(struct page *page)
         : 25               {
         : 26               return static_branch_unlikely(&page_reporting_enabled) &&
    0.00 :   ffff8000101da224:       tbz     w2, #2, ffff8000101d9ea0 <rmqueue_bulk.constprop.127+0xd8>
         : 28               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101da228:       ldur    x2, [x16, #-8]
    0.00 :   ffff8000101da22c:       and     x2, x2, #0xfffffffffffffffb
    0.00 :   ffff8000101da230:       stur    x2, [x16, #-8]
    0.00 :   ffff8000101da234:       b       ffff8000101d9ea0 <rmqueue_bulk.constprop.127+0xd8>
         : 34               __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101da238:       add     w1, w1, #0x1
    0.00 :   ffff8000101da23c:       add     x3, x3, #0x68
    0.00 :   ffff8000101da240:       cmp     w1, #0xb
    0.00 :   ffff8000101da244:       b.ne    ffff8000101da004 <rmqueue_bulk.constprop.127+0x23c>  // b.any
    0.00 :   ffff8000101da248:       b       ffff8000101d9e60 <rmqueue_bulk.constprop.127+0x98>
         : 2394             rmqueue_bulk():
         : 2981             area = &(zone->free_area[current_order]);
    0.00 :   ffff8000101da24c:       mov     x2, #0xffffffffffffffff         // #-1
    0.00 :   ffff8000101da250:       mov     w1, #0x9                        // #9
    0.00 :   ffff8000101da254:       mov     x0, x19
    0.00 :   ffff8000101da258:       bl      ffff8000101a4ca0 <__mod_zone_page_state>
    0.00 :   ffff8000101da25c:       b       ffff8000101d9fc8 <rmqueue_bulk.constprop.127+0x200>
         : 2987             test_bit():
         : 106              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101da260:       ldur    x3, [x13, #-8]
         : 108              page_reported():
    0.00 :   ffff8000101da264:       tbz     w3, #2, ffff8000101da030 <rmqueue_bulk.constprop.127+0x268>
         : 22               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101da268:       ldur    x3, [x13, #-8]
    0.00 :   ffff8000101da26c:       and     x3, x3, #0xfffffffffffffffb
    0.00 :   ffff8000101da270:       stur    x3, [x13, #-8]
    0.00 :   ffff8000101da274:       b       ffff8000101da030 <rmqueue_bulk.constprop.127+0x268>
    0.00 :   ffff8000101da278:       sxtw    x0, w0
    0.00 :   ffff8000101da27c:       lsl     x7, x0, #4
         : 36               get_page_from_free_area():
    0.00 :   ffff8000101da280:       lsl     x0, x0, #4
    0.00 :   ffff8000101da284:       add     x7, x13, x7
         : 106              __rmqueue_fallback():
         : 2897             * Convert to ac->migratetype and avoid the normal
    0.00 :   ffff8000101da288:       ldr     w3, [sp, #116]
    0.00 :   ffff8000101da28c:       ldr     w2, [sp, #136]
         : 2900             get_page_from_free_area():
    0.00 :   ffff8000101da290:       ldr     x1, [x13, x0]
         : 105              __rmqueue_fallback():
    0.00 :   ffff8000101da294:       mov     x0, x19
    0.00 :   ffff8000101da298:       stp     x5, x6, [sp, #96]
         : 2899             get_page_from_free_area():
    0.00 :   ffff8000101da29c:       cmp     x1, x7
    0.00 :   ffff8000101da2a0:       sub     x1, x1, #0x8
         : 106              __rmqueue_fallback():
    0.00 :   ffff8000101da2a4:       csel    x1, x1, xzr, ne  // ne = any
    0.00 :   ffff8000101da2a8:       bl      ffff8000101d98f8 <steal_suitable_fallback>
         : 2899             __rmqueue():
         :
    0.00 :   ffff8000101da2ac:       ldp     x5, x6, [sp, #96]
    0.00 :   ffff8000101da2b0:       b       ffff8000101d9e68 <rmqueue_bulk.constprop.127+0xa0>
    0.00 :   ffff8000101da2b4:       add     x2, x19, #0x100
         : 2943             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101da2b8:       mov     w4, #0x0                        // #0
         : 2390             get_page_from_free_area():
    0.00 :   ffff8000101da2bc:       mov     w1, w4
    0.00 :   ffff8000101da2c0:       add     x0, x1, x1, lsl #1
    0.00 :   ffff8000101da2c4:       add     x0, x1, x0, lsl #2
    0.00 :   ffff8000101da2c8:       add     x0, x19, x0, lsl #3
    0.00 :   ffff8000101da2cc:       ldr     x13, [x0, #256]
    0.00 :   ffff8000101da2d0:       cmp     x13, x2
    0.00 :   ffff8000101da2d4:       b.eq    ffff8000101da3d4 <rmqueue_bulk.constprop.127+0x60c>  // b.none
    0.00 :   ffff8000101da2d8:       sub     x7, x13, #0x8
    0.00 :   ffff8000101da2dc:       mov     x0, x7
         : 113              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101da2e0:       cbz     x7, ffff8000101da3d4 <rmqueue_bulk.constprop.127+0x60c>
         : 2393             arch_static_branch():
    0.00 :   ffff8000101da2e4:       nop
         : 22               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101da2e8:       ldp     x5, x3, [x13]
         : 148              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101da2ec:       str     x3, [x5, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101da2f0:       mov     x14, #0x122                     // #290
         : 150              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da2f4:       add     x2, x1, x1, lsl #1
         : 967              list_del():
    0.00 :   ffff8000101da2f8:       movk    x14, #0xdead, lsl #48
    0.00 :   ffff8000101da2fc:       sub     w6, w4, #0x1
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101da300:       add     x1, x1, x2, lsl #2
         : 966              add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101da304:       mov     w15, #0x68                      // #104
    0.00 :   ffff8000101da308:       sxtw    x6, w6
         : 931              __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101da30c:       str     x5, [x3]
         : 115              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da310:       add     x1, x19, x1, lsl #3
         : 967              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101da314:       stp     x21, x14, [x13]
         : 150              expand():
         : 2228             */
    0.00 :   ffff8000101da318:       lsl     w5, w23, w4
    0.00 :   ffff8000101da31c:       sxtw    x5, w5
         : 2231             __ClearPageBuddy():
    0.00 :   ffff8000101da320:       ldr     w2, [x7, #48]
         : 743              add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101da324:       mov     x14, #0x100                     // #256
         : 930              __ClearPageBuddy():
    0.00 :   ffff8000101da328:       orr     w2, w2, #0x80
    0.00 :   ffff8000101da32c:       str     w2, [x7, #48]
         : 744              set_page_private():
    0.00 :   ffff8000101da330:       str     xzr, [x13, #32]
         : 250              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101da334:       ldr     x2, [x1, #288]
    0.00 :   ffff8000101da338:       sub     x2, x2, #0x1
    0.00 :   ffff8000101da33c:       str     x2, [x1, #288]
         : 969              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101da340:       cbz     w4, ffff8000101da0ec <rmqueue_bulk.constprop.127+0x324>
    0.00 :   ffff8000101da344:       nop
         : 2231             {
    0.00 :   ffff8000101da348:       sub     w18, w4, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101da34c:       lsr     x5, x5, #1
         : 2231             {
    0.00 :   ffff8000101da350:       mov     x4, x18
         : 2233             list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101da354:       add     x1, x18, x18, lsl #1
         : 88               expand():
         :
    0.00 :   ffff8000101da358:       add     x3, x7, x5, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101da35c:       smaddl  x2, w18, w15, x14
    0.00 :   ffff8000101da360:       add     x16, x3, #0x8
         : 931              list_add():
    0.00 :   ffff8000101da364:       add     x1, x18, x1, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101da368:       add     x17, x19, x2
         : 929              list_add():
    0.00 :   ffff8000101da36c:       add     x1, x19, x1, lsl #3
    0.00 :   ffff8000101da370:       ldr     x18, [x1, #256]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101da374:       str     x16, [x18, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101da378:       stp     x18, x17, [x3, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101da37c:       str     x16, [x19, x2]
         : 75               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101da380:       ldr     x2, [x1, #288]
    0.00 :   ffff8000101da384:       add     x2, x2, #0x1
    0.00 :   ffff8000101da388:       str     x2, [x1, #288]
         : 933              set_page_private():
    0.00 :   ffff8000101da38c:       str     x6, [x3, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101da390:       sub     x6, x6, #0x1
    0.00 :   ffff8000101da394:       ldr     w1, [x3, #48]
    0.00 :   ffff8000101da398:       and     w1, w1, #0xffffff7f
    0.00 :   ffff8000101da39c:       str     w1, [x3, #48]
         : 746              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101da3a0:       cbnz    w4, ffff8000101da348 <rmqueue_bulk.constprop.127+0x580>
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101da3a4:       mov     x1, #0x4                        // #4
    0.00 :   ffff8000101da3a8:       str     x1, [x13, #24]
         : 221              __rmqueue():
         : 2937             int fallback_mt;
    0.00 :   ffff8000101da3ac:       b       ffff8000101da0f4 <rmqueue_bulk.constprop.127+0x32c>
         : 2939             __rmqueue_fallback():
         : 2853             struct zone *zone;
    0.00 :   ffff8000101da3b0:       ldr     w0, [sp, #140]
         : 2854             struct page *page;
    0.00 :   ffff8000101da3b4:       sub     w14, w14, #0x1
    0.00 :   ffff8000101da3b8:       sub     x15, x15, #0x68
         : 2853             struct zone *zone;
    0.00 :   ffff8000101da3bc:       cmp     w14, w0
    0.00 :   ffff8000101da3c0:       b.ge    ffff8000101da180 <rmqueue_bulk.constprop.127+0x3b8>  // b.tcont
         : 2856             rmqueue_bulk():
         : 2962             * We cannot steal all free pages from the pageblock and the
    0.00 :   ffff8000101da3c4:       neg     w2, w24
    0.00 :   ffff8000101da3c8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000101da3cc:       sxtw    x2, w2
    0.00 :   ffff8000101da3d0:       b       ffff8000101da11c <rmqueue_bulk.constprop.127+0x354>
         : 2967             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101da3d4:       add     w4, w4, #0x1
    0.00 :   ffff8000101da3d8:       add     x2, x2, #0x68
    0.00 :   ffff8000101da3dc:       cmp     w4, #0xb
    0.00 :   ffff8000101da3e0:       b.ne    ffff8000101da2bc <rmqueue_bulk.constprop.127+0x4f4>  // b.any
    0.00 :   ffff8000101da3e4:       b       ffff8000101da178 <rmqueue_bulk.constprop.127+0x3b0>
    0.00 :   ffff8000101da3e8:       sxtw    x0, w0
    0.00 :   ffff8000101da3ec:       ldrb    w4, [sp, #151]
    0.00 :   ffff8000101da3f0:       lsl     x7, x0, #4
    0.00 :   ffff8000101da3f4:       b       ffff8000101da280 <rmqueue_bulk.constprop.127+0x4b8>
         : 2398             test_bit():
         : 106              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101da3f8:       ldur    x2, [x13, #-8]
         : 108              page_reported():
    0.00 :   ffff8000101da3fc:       tbz     w2, #2, ffff8000101da2e8 <rmqueue_bulk.constprop.127+0x520>
         : 22               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101da400:       ldur    x2, [x13, #-8]
    0.00 :   ffff8000101da404:       and     x2, x2, #0xfffffffffffffffb
    0.00 :   ffff8000101da408:       stur    x2, [x13, #-8]
    0.00 :   ffff8000101da40c:       b       ffff8000101da2e8 <rmqueue_bulk.constprop.127+0x520>
         : 34               rmqueue_bulk():
         : 2959             continue;
    0.00 :   ffff8000101da410:       mov     x2, #0x0                        // #0
         : 2956             fallback_mt = find_suitable_fallback(area, current_order,
    0.00 :   ffff8000101da414:       mov     w25, #0x0                       // #0
    0.00 :   ffff8000101da418:       b       ffff8000101da11c <rmqueue_bulk.constprop.127+0x354>
    0.00 :   ffff8000101da41c:       stp     x23, x24, [sp, #48]
         : 2994             do_steal:
    0.00 :   ffff8000101da420:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (6 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101db958 <get_page_from_freelist>:
         : 6                get_page_from_freelist():
         : 3880             bool __zone_watermark_ok(struct zone *z, unsigned int order, unsigned long mark,
         : 3881             int highest_zoneidx, unsigned int alloc_flags,
         : 3882             long free_pages)
         : 3883             {
         : 3884             long min = mark;
         : 3885             int o;
    0.00 :   ffff8000101db958:       paciasp
    0.00 :   ffff8000101db95c:       stp     x29, x30, [sp, #-256]!
    0.00 :   ffff8000101db960:       adrp    x4, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101db964:       mov     x29, sp
    0.00 :   ffff8000101db968:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000101db96c:       mov     x24, x3
    0.00 :   ffff8000101db970:       add     x5, x4, #0x948
    0.00 :   ffff8000101db974:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000101db978:       mov     w26, w1
    0.00 :   ffff8000101db97c:       mov     w1, #0x68                       // #104
    0.00 :   ffff8000101db980:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101db984:       mov     x3, #0xc0                       // #192
    0.00 :   ffff8000101db988:       umull   x4, w26, w1
    0.00 :   ffff8000101db98c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101db990:       smaddl  x1, w26, w1, x3
         : 3901             rmqueue():
         : 3572             if (order >= pageblock_order - 1) {
    0.00 :   ffff8000101db994:       mov     w25, w26
         : 3574             get_page_from_freelist():
         : 3880             int o;
    0.00 :   ffff8000101db998:       stp     x27, x28, [sp, #80]
         : 3882             rmqueue():
         : 3572             if (order >= pageblock_order - 1) {
    0.00 :   ffff8000101db99c:       mov     x21, x24
    0.00 :   ffff8000101db9a0:       ldr     x22, [x24, #16]
         : 3575             get_page_from_freelist():
         : 3880             int o;
    0.00 :   ffff8000101db9a4:       str     w0, [sp, #184]
    0.00 :   ffff8000101db9a8:       add     x0, x4, #0x100
    0.00 :   ffff8000101db9ac:       str     x0, [sp, #216]
    0.00 :   ffff8000101db9b0:       ldr     x0, [x5]
    0.00 :   ffff8000101db9b4:       str     x0, [sp, #248]
    0.00 :   ffff8000101db9b8:       mov     x0, #0x0                        // #0
         : 3887             rmqueue():
         : 3572             if (order >= pageblock_order - 1) {
    0.00 :   ffff8000101db9bc:       mov     x27, x22
         : 3574             check_new_pages():
         : 2314             * subsystem according to empirical testing, and this is also justified
    0.00 :   ffff8000101db9c0:       mov     w0, #0x1                        // #1
         : 2316             get_page_from_freelist():
         : 3883             const bool alloc_harder = (alloc_flags & (ALLOC_HARDER|ALLOC_OOM));
         :
         : 3885             /* free_pages may go negative - that's OK */
    0.00 :   ffff8000101db9c4:       str     xzr, [sp, #152]
    0.00 :   ffff8000101db9c8:       ldr     x28, [x22]
         : 3888             check_new_pages():
         : 2314             * subsystem according to empirical testing, and this is also justified
    0.00 :   ffff8000101db9cc:       lsl     w0, w0, w26
         : 2316             rmqueue():
         : 3572             if (order >= pageblock_order - 1) {
    0.00 :   ffff8000101db9d0:       mov     w26, w2
         : 3574             check_new_pages():
         : 2314             * subsystem according to empirical testing, and this is also justified
    0.00 :   ffff8000101db9d4:       str     w0, [sp, #112]
    0.00 :   ffff8000101db9d8:       str     x4, [sp, #208]
         : 2317             get_page_from_freelist():
         : 3880             int o;
   17.37 :   ffff8000101db9dc:       stp     x1, x5, [sp, #224]
    0.00 :   ffff8000101db9e0:       add     x1, x4, #0xf0
    0.00 :   ffff8000101db9e4:       str     x1, [sp, #200]
         : 3891             if (alloc_flags & ALLOC_HIGH)
         : 3892             min -= min / 2;
         :
         : 3894             if (unlikely(alloc_harder)) {
         : 3895             /*
         : 3896             * OOM victims can try even harder than normal ALLOC_HARDER
    0.00 :   ffff8000101db9e8:       and     w0, w26, #0x100
    0.00 :   ffff8000101db9ec:       str     w0, [sp, #136]
         : 3893             * users on the grounds that it's definitely going to be in
         : 3894             * the exit path shortly and free memory. Any allocation it
    0.00 :   ffff8000101db9f0:       cbz     x28, ffff8000101dbc44 <get_page_from_freelist+0x2ec>
         : 3896             list_del():
         : 147              * in an undefined state.
         : 148              */
         : 149              static inline void list_del(struct list_head *entry)
         : 150              {
         : 151              __list_del_entry(entry);
         : 152              entry->next = LIST_POISON1;
    0.00 :   ffff8000101db9f4:       mov     w22, w25
    0.00 :   ffff8000101db9f8:       mov     x25, x28
    0.00 :   ffff8000101db9fc:       nop
         : 156              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000101dba00:       nop
         : 28               get_page_from_freelist():
         : 3921             struct free_area *area = &z->free_area[o];
         : 3922             int mt;
         :
         : 3924             if (!area->nr_free)
         : 3925             continue;
         :
    0.00 :   ffff8000101dba04:       ldrb    w0, [x21, #32]
    0.00 :   ffff8000101dba08:       cbz     w0, ffff8000101dba28 <get_page_from_freelist+0xd0>
         : 3922             for (mt = 0; mt < MIGRATE_PCPTYPES; mt++) {
    0.00 :   ffff8000101dba0c:       ldr     x0, [x25, #80]
    0.00 :   ffff8000101dba10:       ldr     x1, [sp, #152]
    0.00 :   ffff8000101dba14:       cmp     x0, x1
    0.00 :   ffff8000101dba18:       b.eq    ffff8000101dbc18 <get_page_from_freelist+0x2c0>  // b.none
         : 3925             if (!free_area_empty(area, mt))
         : 3926             return true;
         : 3927             }
    0.00 :   ffff8000101dba1c:       bl      ffff80001018ab20 <node_dirty_ok>
    0.00 :   ffff8000101dba20:       tst     w0, #0xff
    0.00 :   ffff8000101dba24:       b.eq    ffff8000101dc59c <get_page_from_freelist+0xc44>  // b.none
         :
         : 3932             #ifdef CONFIG_CMA
         : 3933             if ((alloc_flags & ALLOC_CMA) &&
         : 3934             !free_area_empty(area, MIGRATE_CMA)) {
         : 3935             return true;
         : 3936             }
    0.00 :   ffff8000101dba28:       ldr     w0, [sp, #136]
    0.00 :   ffff8000101dba2c:       cbz     w0, ffff8000101dba60 <get_page_from_freelist+0x108>
    0.00 :   ffff8000101dba30:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101dba34:       ldr     w0, [x0, #3504]
    0.00 :   ffff8000101dba38:       cmp     w0, #0x1
    0.00 :   ffff8000101dba3c:       b.ls    ffff8000101dba60 <get_page_from_freelist+0x108>  // b.plast
         : 3932             #endif
    0.00 :   ffff8000101dba40:       ldr     x1, [x21, #16]
    0.00 :   ffff8000101dba44:       ldr     x0, [x1]
         : 3931             }
    0.00 :   ffff8000101dba48:       cmp     x0, x25
    0.00 :   ffff8000101dba4c:       b.eq    ffff8000101dba60 <get_page_from_freelist+0x108>  // b.none
         : 3941             return false;
         : 3942             }
         :
         : 3944             bool zone_watermark_ok(struct zone *z, unsigned int order, unsigned long mark,
         : 3945             int highest_zoneidx, unsigned int alloc_flags)
         : 3946             {
    0.00 :   ffff8000101dba50:       ldr     w3, [x0, #72]
    0.00 :   ffff8000101dba54:       ldr     w2, [x25, #72]
    0.00 :   ffff8000101dba58:       cmp     w3, w2
    0.00 :   ffff8000101dba5c:       b.ne    ffff8000101dc7a8 <get_page_from_freelist+0xe50>  // b.any
         : 3947             return __zone_watermark_ok(z, order, mark, highest_zoneidx, alloc_flags,
         : 3948             zone_page_state(z, NR_FREE_PAGES));
         : 3949             }
         :
         : 3951             static inline bool zone_watermark_fast(struct zone *z, unsigned int order,
         : 3952             unsigned long mark, int highest_zoneidx,
    0.00 :   ffff8000101dba60:       and     w15, w26, #0x3
         : 3948             unsigned int alloc_flags, gfp_t gfp_mask)
    0.00 :   ffff8000101dba64:       ldr     w14, [x21, #28]
         : 3950             atomic64_read():
         : 838              static __always_inline s64
         : 839              atomic64_dec_return_acquire(atomic64_t *v)
         : 840              {
         : 841              instrument_atomic_read_write(v, sizeof(*v));
         : 842              return arch_atomic64_dec_return_acquire(v);
         : 843              }
    0.00 :   ffff8000101dba68:       ldr     x5, [x25, #1472]
         : 845              get_page_from_freelist():
         : 3947             unsigned long mark, int highest_zoneidx,
    0.00 :   ffff8000101dba6c:       ldr     x19, [x25, w15, sxtw #3]
    0.00 :   ffff8000101dba70:       cmp     x5, #0x0
    0.00 :   ffff8000101dba74:       ldr     x0, [x25, #24]
    0.00 :   ffff8000101dba78:       csel    x13, x5, xzr, ge  // ge = tcont
    0.00 :   ffff8000101dba7c:       add     x19, x19, x0
         : 3953             zone_watermark_fast():
         : 3769             return NULL;
    0.00 :   ffff8000101dba80:       cbnz    w22, ffff8000101dbc90 <get_page_from_freelist+0x338>
         : 3771             __zone_watermark_unusable_free():
         :
    0.00 :   ffff8000101dba84:       tst     w26, #0x18
    0.00 :   ffff8000101dba88:       b.ne    ffff8000101dc6c4 <get_page_from_freelist+0xd6c>  // b.any
         : 3669             /* Lock and remove page from the per-cpu list */
    0.00 :   ffff8000101dba8c:       ldr     x0, [x25, #32]
         : 3673             unsigned int alloc_flags)
    0.00 :   ffff8000101dba90:       and     w18, w26, #0x80
    0.00 :   ffff8000101dba94:       tbnz    w26, #7, ffff8000101dbaa8 <get_page_from_freelist+0x150>
         : 3676             atomic64_read():
    0.00 :   ffff8000101dba98:       ldr     x1, [x25, #1544]
         : 839              zone_page_state():
         :
         : 223              /*
         : 224              * More accurate version that also considers the currently pending
         : 225              * deltas. For that we need to loop over all cpus to find the current
         : 226              * deltas. There is no synchronization so the result cannot be
         : 227              * exactly accurate either.
    0.00 :   ffff8000101dba9c:       cmp     x1, #0x0
    0.00 :   ffff8000101dbaa0:       csel    x1, x1, xzr, ge  // ge = tcont
         : 230              __zone_watermark_unusable_free():
         : 3674             {
    0.00 :   ffff8000101dbaa4:       add     x0, x1, x0
         : 3676             zone_watermark_fast():
         : 3774             static struct {
    0.00 :   ffff8000101dbaa8:       add     x1, x25, w14, sxtw #3
         :
    0.00 :   ffff8000101dbaac:       sub     x0, x13, x0
         : 3774             static struct {
    0.00 :   ffff8000101dbab0:       ldr     x1, [x1, #40]
    0.00 :   ffff8000101dbab4:       add     x1, x19, x1
    0.00 :   ffff8000101dbab8:       cmp     x1, x0
    0.00 :   ffff8000101dbabc:       b.cc    ffff8000101dbae4 <get_page_from_freelist+0x18c>  // b.lo, b.ul, b.last
         : 3778             bool ignore_gfp_reclaim;
    0.00 :   ffff8000101dbac0:       mov     x5, x13
    0.00 :   ffff8000101dbac4:       mov     w4, w26
    0.00 :   ffff8000101dbac8:       mov     w3, w14
    0.00 :   ffff8000101dbacc:       mov     x2, x19
    0.00 :   ffff8000101dbad0:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101dbad4:       mov     x0, x25
    0.00 :   ffff8000101dbad8:       bl      ffff8000101db5c0 <__zone_watermark_ok>
    0.00 :   ffff8000101dbadc:       tst     w0, #0xff
    0.00 :   ffff8000101dbae0:       b.eq    ffff8000101dc708 <get_page_from_freelist+0xdb0>  // b.none
         : 3788             get_page_from_freelist():
         : 3991             bool zone_watermark_ok_safe(struct zone *z, unsigned int order,
         : 3992             unsigned long mark, int highest_zoneidx)
         : 3993             {
         : 3994             long free_pages = zone_page_state(z, NR_FREE_PAGES);
         :
         : 3996             if (z->percpu_drift_mark && free_pages < z->percpu_drift_mark)
    0.00 :   ffff8000101dbae4:       ldr     x0, [x21, #16]
    0.00 :   ffff8000101dbae8:       ldr     w19, [x21, #24]
    0.00 :   ffff8000101dbaec:       ldr     x0, [x0]
    0.00 :   ffff8000101dbaf0:       str     x0, [sp, #128]
         : 4001             rmqueue():
         : 3527             int i;
    0.00 :   ffff8000101dbaf4:       cmp     w18, #0x0
    0.00 :   ffff8000101dbaf8:       ccmp    w19, #0x1, #0x0, eq  // eq = none
    0.00 :   ffff8000101dbafc:       b.eq    ffff8000101dc58c <get_page_from_freelist+0xc34>  // b.none
         : 3531             arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101dbb00:       mrs     x5, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101dbb04:       and     w0, w5, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff8000101dbb08:       cbz     w0, ffff8000101dc664 <get_page_from_freelist+0xd0c>
         : 118              rmqueue_pcplist():
         : 3500             migratetype = get_pcppage_migratetype(page);
    0.00 :   ffff8000101dbb0c:       sxtw    x20, w19
         : 3502             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000101dbb10:       mrs     x28, tpidr_el1
         : 46               rmqueue_pcplist():
         : 3499             set_page_private(page, 0);
    0.00 :   ffff8000101dbb14:       ldr     x23, [x25, #88]
    0.00 :   ffff8000101dbb18:       add     x0, x23, x28
         : 3500             migratetype = get_pcppage_migratetype(page);
    0.00 :   ffff8000101dbb1c:       add     x24, x20, #0x1
    0.00 :   ffff8000101dbb20:       add     x20, x0, x20, lsl #4
    0.00 :   ffff8000101dbb24:       add     x24, x0, x24, lsl #4
         : 3504             list_empty():
         : 282              * list_empty - tests whether a list is empty
         : 283              * @head: the list to test.
         : 284              */
         : 285              static inline int list_empty(const struct list_head *head)
         : 286              {
         : 287              return READ_ONCE(head->next) == head;
    0.00 :   ffff8000101dbb28:       ldr     x1, [x20, #16]
         : 289              __rmqueue_pcplist():
         :
    0.00 :   ffff8000101dbb2c:       cmp     x24, x1
    0.00 :   ffff8000101dbb30:       b.eq    ffff8000101dc5b8 <get_page_from_freelist+0xc60>  // b.none
         : 3480             list_del(&page->lru);
    0.00 :   ffff8000101dbb34:       ldr     x0, [x20, #16]
         : 3482             list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dbb38:       mov     x3, #0x122                      // #290
    0.00 :   ffff8000101dbb3c:       movk    x3, #0xdead, lsl #48
         : 151              __rmqueue_pcplist():
    0.00 :   ffff8000101dbb40:       mov     x24, x0
         : 3481             list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101dbb44:       ldr     x1, [x0, #8]
    0.00 :   ffff8000101dbb48:       ldr     x2, [x24], #-8
         : 149              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101dbb4c:       str     x1, [x2, #8]
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101dbb50:       str     x2, [x1]
         : 115              list_del():
         : 147              entry->next = LIST_POISON1;
    0.00 :   ffff8000101dbb54:       mov     x1, #0x100                      // #256
    0.00 :   ffff8000101dbb58:       movk    x1, #0xdead, lsl #48
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dbb5c:       stp     x1, x3, [x0]
         : 150              __rmqueue_pcplist():
         : 3482             migratetype, FPI_NONE);
    0.00 :   ffff8000101dbb60:       ldr     w1, [x23, x28]
    0.00 :   ffff8000101dbb64:       sub     w1, w1, #0x1
    0.00 :   ffff8000101dbb68:       str     w1, [x23, x28]
         : 3486             rmqueue_pcplist():
         : 3502             free_unref_page_commit(page, pfn, migratetype, 0);
    0.00 :   ffff8000101dbb6c:       cbz     x24, ffff8000101dc5f8 <get_page_from_freelist+0xca0>
         : 3504             page_zonenum():
         :
         : 1128             static inline enum zone_type page_zonenum(const struct page *page)
         : 1129             {
         : 1130             ASSERT_EXCLUSIVE_BITS(page->flags, ZONES_MASK << ZONES_PGSHIFT);
         : 1131             return (page->flags >> ZONES_PGSHIFT) & ZONES_MASK;
         : 1132             }
    0.00 :   ffff8000101dbb70:       ldur    x0, [x0, #-8]
         : 1134             __count_vm_events():
         : 76               raw_cpu_add(vm_event_states.event[item], delta);
    0.00 :   ffff8000101dbb74:       adrp    x1, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000101dbb78:       add     x1, x1, #0x1f8
         : 79               __kern_my_cpu_offset():
    0.00 :   ffff8000101dbb7c:       mrs     x2, tpidr_el1
         : 40               rmqueue_pcplist():
         :
    0.00 :   ffff8000101dbb80:       ubfx    x0, x0, #58, #2
         : 3505             __count_vm_events():
    0.00 :   ffff8000101dbb84:       add     x0, x0, #0x4
    0.00 :   ffff8000101dbb88:       add     x0, x1, x0, lsl #3
    0.00 :   ffff8000101dbb8c:       ldr     x1, [x0, x2]
    0.00 :   ffff8000101dbb90:       add     x1, x1, #0x1
    0.00 :   ffff8000101dbb94:       str     x1, [x0, x2]
         : 81               arch_static_branch():
    0.00 :   ffff8000101dbb98:       nop
         : 22               zone_statistics():
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dbb9c:       ldr     x2, [sp, #128]
         : 3454             numa_node_id():
         :
         : 90               #ifndef numa_node_id
         : 91               /* Returns the number of the current Node. */
         : 92               static inline int numa_node_id(void)
         : 93               {
         : 94               return raw_cpu_read(numa_node);
    0.00 :   ffff8000101dbba0:       adrp    x0, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000101dbba4:       add     x0, x0, #0x5b0
         : 97               zone_statistics():
         : 3449             migratetype = MIGRATE_MOVABLE;
    0.00 :   ffff8000101dbba8:       ldr     w1, [x25, #72]
         : 3451             numa_node_id():
    0.00 :   ffff8000101dbbac:       add     x0, x0, #0x60
    0.00 :   ffff8000101dbbb0:       str     x5, [sp, #104]
         : 91               __kern_my_cpu_offset():
    0.00 :   ffff8000101dbbb4:       mrs     x3, tpidr_el1
         : 40               zone_statistics():
    0.00 :   ffff8000101dbbb8:       ldr     w0, [x0, x3]
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dbbbc:       ldr     w2, [x2, #72]
         : 3450             }
    0.00 :   ffff8000101dbbc0:       cmp     w1, w0
    0.00 :   ffff8000101dbbc4:       cset    w19, ne  // ne = any
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dbbc8:       cmp     w1, w2
         : 3450             }
    0.00 :   ffff8000101dbbcc:       add     w19, w19, #0x4
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dbbd0:       b.eq    ffff8000101dc718 <get_page_from_freelist+0xdc0>  // b.none
         : 3455             }
    0.00 :   ffff8000101dbbd4:       mov     x0, x25
    0.00 :   ffff8000101dbbd8:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000101dbbdc:       bl      ffff8000101a66b0 <__inc_numa_state>
         :
    0.00 :   ffff8000101dbbe0:       ldr     x0, [sp, #128]
    0.00 :   ffff8000101dbbe4:       mov     w1, #0x2                        // #2
    0.00 :   ffff8000101dbbe8:       bl      ffff8000101a66b0 <__inc_numa_state>
    0.00 :   ffff8000101dbbec:       ldr     x5, [sp, #104]
         : 3458             * Free a list of 0-order pages
    0.00 :   ffff8000101dbbf0:       mov     w1, w19
    0.00 :   ffff8000101dbbf4:       mov     x0, x25
    0.00 :   ffff8000101dbbf8:       str     x5, [sp, #104]
    0.00 :   ffff8000101dbbfc:       bl      ffff8000101a66b0 <__inc_numa_state>
    0.00 :   ffff8000101dbc00:       ldr     x5, [sp, #104]
         : 3464             arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101dbc04:       msr     daif, x5
         : 129              arch_static_branch():
    0.00 :   ffff8000101dbc08:       nop
         : 22               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101dbc0c:       ldr     x0, [x25, #1336]
         : 113              rmqueue():
         : 3570             * pageblock
    0.00 :   ffff8000101dbc10:       tbnz    w0, #0, ffff8000101dc2f8 <get_page_from_freelist+0x9a0>
         : 3572             get_page_from_freelist():
         : 3993             free_pages = zone_page_state_snapshot(z, NR_FREE_PAGES);
         :
    0.00 :   ffff8000101dbc14:       cbnz    x24, ffff8000101dc60c <get_page_from_freelist+0xcb4>
         : 3893             * the exit path shortly and free memory. Any allocation it
    0.00 :   ffff8000101dbc18:       ldr     x2, [x21, #8]
    0.00 :   ffff8000101dbc1c:       add     x0, x27, #0x10
    0.00 :   ffff8000101dbc20:       ldr     w1, [x21, #28]
         : 3897             next_zones_zonelist():
         : 1126             return zone_to_nid(zoneref->zone);
         : 1127             }
         :
         : 1129             struct zoneref *__next_zones_zonelist(struct zoneref *z,
         : 1130             enum zone_type highest_zoneidx,
         : 1131             nodemask_t *nodes);
    0.00 :   ffff8000101dbc24:       cbnz    x2, ffff8000101dbc88 <get_page_from_freelist+0x330>
    0.00 :   ffff8000101dbc28:       ldr     w3, [x27, #24]
    0.00 :   ffff8000101dbc2c:       cmp     w1, w3
    0.00 :   ffff8000101dbc30:       b.cc    ffff8000101dbc88 <get_page_from_freelist+0x330>  // b.lo, b.ul, b.last
         : 1129             get_page_from_freelist():
    0.00 :   ffff8000101dbc34:       ldr     x25, [x0]
    0.00 :   ffff8000101dbc38:       mov     x27, x0
    0.00 :   ffff8000101dbc3c:       cbnz    x25, ffff8000101dba00 <get_page_from_freelist+0xa8>
    0.00 :   ffff8000101dbc40:       mov     w25, w22
         : 4019             * premature use of a lower zone may cause lowmem pressure problems that
         : 4020             * are worse than fragmentation. If the next zone is ZONE_DMA then it is
         : 4021             * probably too small. It only makes sense to spread allocations to avoid
         : 4022             * fragmentation between the Normal and DMA32 zones.
         : 4023             */
         : 4024             static inline unsigned int
    0.00 :   ffff8000101dbc44:       ldr     w0, [sp, #136]
    0.00 :   ffff8000101dbc48:       cbz     w0, ffff8000101dc7bc <get_page_from_freelist+0xe64>
         : 4020             alloc_flags_nofragment(struct zone *zone, gfp_t gfp_mask)
    0.00 :   ffff8000101dbc4c:       ldr     x27, [x21, #16]
    0.00 :   ffff8000101dbc50:       and     w26, w26, #0xfffffeff
         : 4021             {
    0.00 :   ffff8000101dbc54:       ldr     x28, [x27]
    0.00 :   ffff8000101dbc58:       b       ffff8000101db9e8 <get_page_from_freelist+0x90>
         : 3898             else
    0.00 :   ffff8000101dbc5c:       tbz     w26, #6, ffff8000101dba04 <get_page_from_freelist+0xac>
         : 3900             __cpuset_zone_allowed():
         : 78               return true;
         : 79               }
         :
         : 81               static inline bool __cpuset_zone_allowed(struct zone *z, gfp_t gfp_mask)
         : 82               {
         : 83               return __cpuset_node_allowed(zone_to_nid(z), gfp_mask);
    0.00 :   ffff8000101dbc60:       ldr     w0, [x25, #72]
    0.00 :   ffff8000101dbc64:       ldr     w1, [sp, #184]
    0.00 :   ffff8000101dbc68:       bl      ffff8000101472b0 <__cpuset_node_allowed>
         : 87               get_page_from_freelist():
         : 3899             min -= min / 4;
    0.00 :   ffff8000101dbc6c:       tst     w0, #0xff
    0.00 :   ffff8000101dbc70:       b.ne    ffff8000101dba04 <get_page_from_freelist+0xac>  // b.any
         : 3893             * the exit path shortly and free memory. Any allocation it
    0.00 :   ffff8000101dbc74:       ldr     x2, [x21, #8]
    0.00 :   ffff8000101dbc78:       add     x0, x27, #0x10
    0.00 :   ffff8000101dbc7c:       ldr     w1, [x21, #28]
         : 3897             next_zones_zonelist():
    0.00 :   ffff8000101dbc80:       cbz     x2, ffff8000101dbc28 <get_page_from_freelist+0x2d0>
    0.00 :   ffff8000101dbc84:       nop
         :
         : 1129             /**
    0.00 :   ffff8000101dbc88:       bl      ffff8000101a2e20 <__next_zones_zonelist>
    0.00 :   ffff8000101dbc8c:       b       ffff8000101dbc34 <get_page_from_freelist+0x2dc>
         : 1132             zone_watermark_fast():
         : 3778             bool ignore_gfp_reclaim;
    0.00 :   ffff8000101dbc90:       mov     x5, x13
    0.00 :   ffff8000101dbc94:       mov     w3, w14
    0.00 :   ffff8000101dbc98:       mov     w4, w26
    0.00 :   ffff8000101dbc9c:       mov     x2, x19
    0.00 :   ffff8000101dbca0:       mov     w1, w22
    0.00 :   ffff8000101dbca4:       mov     x0, x25
    0.00 :   ffff8000101dbca8:       bl      ffff8000101db5c0 <__zone_watermark_ok>
    0.00 :   ffff8000101dbcac:       tst     w0, #0xff
    0.00 :   ffff8000101dbcb0:       b.ne    ffff8000101dc6cc <get_page_from_freelist+0xd74>  // b.any
         : 3788             get_page_from_freelist():
         : 3965             }
    0.00 :   ffff8000101dbcb4:       tbnz    w26, #2, ffff8000101dc6cc <get_page_from_freelist+0xd74>
         : 3967             node_reclaim_enabled():
         : 400              #ifdef CONFIG_NUMA
         : 401              extern int node_reclaim_mode;
         : 402              extern int sysctl_min_unmapped_ratio;
         : 403              extern int sysctl_min_slab_ratio;
         : 404              #else
         : 405              #define node_reclaim_mode 0
    0.00 :   ffff8000101dbcb8:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101dbcbc:       ldr     w0, [x0, #3320]
         : 408              get_page_from_freelist():
         : 3968             free_pages))
    0.00 :   ffff8000101dbcc0:       tst     x0, #0x7
    0.00 :   ffff8000101dbcc4:       b.eq    ffff8000101dbc18 <get_page_from_freelist+0x2c0>  // b.none
         : 3969             return true;
    0.00 :   ffff8000101dbcc8:       ldr     x0, [x21, #16]
         : 3971             zone_allows_reclaim():
         : 3812             umode_t mode = S_IFREG | 0600;
    0.00 :   ffff8000101dbccc:       ldr     w1, [x25, #72]
    0.00 :   ffff8000101dbcd0:       ldr     x0, [x0]
    0.00 :   ffff8000101dbcd4:       ldr     w0, [x0, #72]
    0.00 :   ffff8000101dbcd8:       bl      ffff8000107ca388 <__node_distance>
    0.00 :   ffff8000101dbcdc:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
         : 3818             get_page_from_freelist():
         : 3968             free_pages))
    0.00 :   ffff8000101dbce0:       ldr     w1, [x1, #2808]
    0.00 :   ffff8000101dbce4:       cmp     w0, w1
    0.00 :   ffff8000101dbce8:       b.gt    ffff8000101dbc18 <get_page_from_freelist+0x2c0>
         : 3972             * when checking the min watermark. The min watermark is the
    0.00 :   ffff8000101dbcec:       ldr     w1, [sp, #184]
    0.00 :   ffff8000101dbcf0:       mov     w2, w22
    0.00 :   ffff8000101dbcf4:       ldr     x0, [x25, #80]
    0.00 :   ffff8000101dbcf8:       bl      ffff800010199038 <node_reclaim>
         : 3973             * point where boosting is ignored so that kswapd is woken up
    0.00 :   ffff8000101dbcfc:       add     w0, w0, #0x2
    0.00 :   ffff8000101dbd00:       cmp     w0, #0x1
    0.00 :   ffff8000101dbd04:       b.ls    ffff8000101dbc18 <get_page_from_freelist+0x2c0>  // b.plast
         : 3977             atomic64_read():
    0.00 :   ffff8000101dbd08:       ldr     x5, [x25, #1472]
         : 839              zone_watermark_ok():
         :
    0.00 :   ffff8000101dbd0c:       mov     x2, x19
    0.00 :   ffff8000101dbd10:       ldr     w3, [x21, #28]
    0.00 :   ffff8000101dbd14:       mov     w4, w26
    0.00 :   ffff8000101dbd18:       cmp     x5, #0x0
    0.00 :   ffff8000101dbd1c:       mov     w1, w22
    0.00 :   ffff8000101dbd20:       csel    x5, x5, xzr, ge  // ge = tcont
    0.00 :   ffff8000101dbd24:       mov     x0, x25
    0.00 :   ffff8000101dbd28:       bl      ffff8000101db5c0 <__zone_watermark_ok>
         : 3762             get_page_from_freelist():
         :
    0.00 :   ffff8000101dbd2c:       tst     w0, #0xff
    0.00 :   ffff8000101dbd30:       b.eq    ffff8000101dbc18 <get_page_from_freelist+0x2c0>  // b.none
         : 3991             if (z->percpu_drift_mark && free_pages < z->percpu_drift_mark)
    0.00 :   ffff8000101dbd34:       ldr     x0, [x21, #16]
    0.00 :   ffff8000101dbd38:       and     w18, w26, #0x80
    0.00 :   ffff8000101dbd3c:       ldr     w19, [x21, #24]
    0.00 :   ffff8000101dbd40:       ldr     x0, [x0]
    0.00 :   ffff8000101dbd44:       str     x0, [sp, #128]
         : 3997             rmqueue():
         : 3522             * Note: this is probably too low level an operation for use in drivers.
    0.00 :   ffff8000101dbd48:       cbz     w22, ffff8000101dbaf4 <get_page_from_freelist+0x19c>
         : 3539             int __isolate_free_page(struct page *page, unsigned int order)
    0.00 :   ffff8000101dbd4c:       ldr     x0, [sp, #184]
    0.00 :   ffff8000101dbd50:       sxtw    x28, w19
    0.00 :   ffff8000101dbd54:       lsl     x23, x28, #4
    0.00 :   ffff8000101dbd58:       tst     x0, #0x8000
    0.00 :   ffff8000101dbd5c:       ccmp    w22, #0x1, #0x0, ne  // ne = any
    0.00 :   ffff8000101dbd60:       b.ls    ffff8000101dbd68 <get_page_from_freelist+0x410>  // b.plast
    0.00 :   ffff8000101dbd64:       brk     #0x800
         : 3547             spinlock_check():
         : 329              * Map the spin_lock functions to the raw variants for PREEMPT_RT=n
         : 330              */
         :
         : 332              static __always_inline raw_spinlock_t *spinlock_check(spinlock_t *lock)
         : 333              {
         : 334              return &lock->rlock;
    0.00 :   ffff8000101dbd68:       add     x0, x25, #0x540
    0.00 :   ffff8000101dbd6c:       str     x0, [sp, #168]
         : 337              rmqueue():
         : 3540             {
    0.00 :   ffff8000101dbd70:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff8000101dbd74:       str     x0, [sp, #176]
    0.00 :   ffff8000101dbd78:       ldr     x0, [sp, #208]
    0.00 :   ffff8000101dbd7c:       sxtw    x20, w19
    0.00 :   ffff8000101dbd80:       mov     w24, w26
    0.00 :   ffff8000101dbd84:       mov     x26, x21
    0.00 :   ffff8000101dbd88:       add     x0, x0, #0xc0
    0.00 :   ffff8000101dbd8c:       mov     w21, w22
    0.00 :   ffff8000101dbd90:       add     x0, x0, x23
         : 3550             get_page_from_free_area():
         : 104              {
    0.00 :   ffff8000101dbd94:       lsl     x1, x20, #4
    0.00 :   ffff8000101dbd98:       add     x0, x25, x0
    0.00 :   ffff8000101dbd9c:       str     x0, [sp, #104]
    0.00 :   ffff8000101dbda0:       sub     w0, w22, #0x1
    0.00 :   ffff8000101dbda4:       str     w0, [sp, #116]
    0.00 :   ffff8000101dbda8:       ldr     x0, [sp, #200]
    0.00 :   ffff8000101dbdac:       mov     x22, x25
    0.00 :   ffff8000101dbdb0:       str     x1, [sp, #120]
    0.00 :   ffff8000101dbdb4:       add     x0, x25, x0
    0.00 :   ffff8000101dbdb8:       str     x0, [sp, #160]
    0.00 :   ffff8000101dbdbc:       ldr     x0, [sp, #216]
    0.00 :   ffff8000101dbdc0:       str     w19, [sp, #140]
    0.00 :   ffff8000101dbdc4:       add     x0, x25, x0
    0.00 :   ffff8000101dbdc8:       str     x0, [sp, #144]
    0.00 :   ffff8000101dbdcc:       ldr     x0, [sp, #224]
    0.00 :   ffff8000101dbdd0:       add     x0, x25, x0
    0.00 :   ffff8000101dbdd4:       mov     x25, x20
    0.00 :   ffff8000101dbdd8:       str     x0, [sp, #192]
    0.00 :   ffff8000101dbddc:       nop
         : 124              rmqueue():
         : 3550             if (!is_migrate_isolate(mt)) {
    0.00 :   ffff8000101dbde0:       ldr     w0, [sp, #116]
    0.00 :   ffff8000101dbde4:       cmp     w0, #0x9
    0.00 :   ffff8000101dbde8:       b.hi    ffff8000101dbdf0 <get_page_from_freelist+0x498>  // b.pmore
    0.00 :   ffff8000101dbdec:       tbnz    w24, #4, ffff8000101dc338 <get_page_from_freelist+0x9e0>
         : 3555             __rmqueue():
         : 2923             * fallback was found so that __rmqueue_smallest() can grab it.
    0.00 :   ffff8000101dbdf0:       and     w19, w24, #0x80
    0.00 :   ffff8000101dbdf4:       tbnz    w24, #7, ffff8000101dbfac <get_page_from_freelist+0x654>
         : 2926             __rmqueue_fallback():
         : 2846             */
    0.00 :   ffff8000101dbdf8:       mov     w20, #0x9                       // #9
         : 2848             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101dbdfc:       cmp     w21, #0xa
    0.00 :   ffff8000101dbe00:       b.hi    ffff8000101dc44c <get_page_from_freelist+0xaf4>  // b.pmore
    0.00 :   ffff8000101dbe04:       ldr     x4, [sp, #104]
    0.00 :   ffff8000101dbe08:       mov     w0, w21
         : 2393             get_page_from_free_area():
    0.00 :   ffff8000101dbe0c:       mov     w2, w0
    0.00 :   ffff8000101dbe10:       ldr     x3, [sp, #120]
    0.00 :   ffff8000101dbe14:       add     x1, x2, x2, lsl #1
    0.00 :   ffff8000101dbe18:       add     x1, x2, x1, lsl #2
    0.00 :   ffff8000101dbe1c:       add     x1, x3, x1, lsl #3
    0.00 :   ffff8000101dbe20:       add     x1, x22, x1
    0.00 :   ffff8000101dbe24:       ldr     x1, [x1, #192]
    0.00 :   ffff8000101dbe28:       cmp     x1, x4
    0.00 :   ffff8000101dbe2c:       b.eq    ffff8000101dc0ec <get_page_from_freelist+0x794>  // b.none
    0.00 :   ffff8000101dbe30:       sub     x9, x1, #0x8
    0.00 :   ffff8000101dbe34:       mov     x3, x9
         : 115              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101dbe38:       cbz     x9, ffff8000101dc0ec <get_page_from_freelist+0x794>
         : 2393             arch_static_branch():
    0.00 :   ffff8000101dbe3c:       nop
         : 22               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101dbe40:       ldp     x10, x8, [x1]
         : 148              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101dbe44:       add     x4, x2, x2, lsl #1
         : 967              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101dbe48:       str     x8, [x10, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dbe4c:       mov     x11, #0x122                     // #290
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101dbe50:       add     x2, x2, x4, lsl #2
         : 966              list_del():
         : 147              entry->next = LIST_POISON1;
    0.00 :   ffff8000101dbe54:       mov     x4, #0x100                      // #256
    0.00 :   ffff8000101dbe58:       movk    x4, #0xdead, lsl #48
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dbe5c:       movk    x11, #0xdead, lsl #48
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101dbe60:       add     x2, x22, x2, lsl #3
         : 966              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dbe64:       cmp     w0, w21
         : 2232             __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101dbe68:       str     x10, [x8]
         : 115              add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dbe6c:       mov     w14, #0x68                      // #104
         : 930              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dbe70:       stp     x4, x11, [x1]
         : 150              expand():
         : 2228             */
    0.00 :   ffff8000101dbe74:       mov     w4, #0x1                        // #1
    0.00 :   ffff8000101dbe78:       lsl     w4, w4, w0
         : 2231             __ClearPageBuddy():
         :
         : 743              static inline int page_has_type(struct page *page)
         : 744              {
         : 745              return (int)page->page_type < PAGE_MAPCOUNT_RESERVE;
         : 746              }
         :
    0.00 :   ffff8000101dbe7c:       ldr     w8, [x9, #48]
         : 749              add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dbe80:       mov     x13, #0xc0                      // #192
         : 930              list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101dbe84:       lsl     x12, x25, #4
         : 88               expand():
         : 2228             */
    0.00 :   ffff8000101dbe88:       sxtw    x4, w4
         : 2230             __ClearPageBuddy():
    0.00 :   ffff8000101dbe8c:       orr     w8, w8, #0x80
    0.00 :   ffff8000101dbe90:       str     w8, [x9, #48]
         : 744              set_page_private():
         : 249              }
         :
         : 251              /*
         : 252              * Used for sizing the vmemmap region on some architectures
         : 253              */
         : 254              #define STRUCT_PAGE_MAX_SHIFT   (order_base_2(sizeof(struct page)))
    0.00 :   ffff8000101dbe94:       str     xzr, [x1, #32]
         : 256              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101dbe98:       ldr     x8, [x2, #288]
    0.00 :   ffff8000101dbe9c:       sub     x8, x8, #0x1
    0.00 :   ffff8000101dbea0:       str     x8, [x2, #288]
         : 969              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dbea4:       b.le    ffff8000101dbf14 <get_page_from_freelist+0x5bc>
         : 2231             {
    0.00 :   ffff8000101dbea8:       sub     w6, w0, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101dbeac:       lsr     x4, x4, #1
         : 2231             {
    0.00 :   ffff8000101dbeb0:       mov     x0, x6
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dbeb4:       cmp     w6, w21
         : 2232             list_add():
    0.00 :   ffff8000101dbeb8:       add     x2, x6, x6, lsl #1
         : 87               expand():
         :
    0.00 :   ffff8000101dbebc:       add     x5, x9, x4, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dbec0:       umaddl  x7, w6, w14, x13
    0.00 :   ffff8000101dbec4:       add     x10, x5, #0x8
         : 931              list_add():
    0.00 :   ffff8000101dbec8:       add     x2, x6, x2, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101dbecc:       add     x7, x7, x23
         : 929              list_add():
    0.00 :   ffff8000101dbed0:       lsl     x2, x2, #3
         : 87               add_to_free_list():
    0.00 :   ffff8000101dbed4:       add     x11, x22, x7
         : 929              list_add():
    0.00 :   ffff8000101dbed8:       add     x8, x12, x2
         : 87               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101dbedc:       add     x2, x22, x2
         : 931              list_add():
    0.00 :   ffff8000101dbee0:       add     x8, x22, x8
    0.00 :   ffff8000101dbee4:       ldr     x8, [x8, #192]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101dbee8:       str     x10, [x8, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101dbeec:       stp     x8, x11, [x5, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101dbef0:       str     x10, [x22, x7]
         : 75               add_to_free_list():
    0.00 :   ffff8000101dbef4:       ldr     x7, [x2, #288]
    0.00 :   ffff8000101dbef8:       add     x7, x7, #0x1
    0.00 :   ffff8000101dbefc:       str     x7, [x2, #288]
         : 932              set_page_private():
    0.00 :   ffff8000101dbf00:       str     x6, [x5, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101dbf04:       ldr     w2, [x5, #48]
    0.00 :   ffff8000101dbf08:       and     w2, w2, #0xffffff7f
    0.00 :   ffff8000101dbf0c:       str     w2, [x5, #48]
         : 745              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dbf10:       b.ne    ffff8000101dbea8 <get_page_from_freelist+0x550>  // b.any
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101dbf14:       str     x28, [x1, #24]
         : 220              atomic_read():
         : 28               return arch_atomic_read(v);
    0.00 :   ffff8000101dbf18:       ldr     w0, [x3, #48]
         : 30               page_expected_state():
         : 1126             * merge with it and move up one order.
    0.00 :   ffff8000101dbf1c:       cmn     w0, #0x1
    0.00 :   ffff8000101dbf20:       b.ne    ffff8000101dc0e0 <get_page_from_freelist+0x788>  // b.any
         : 1129             atomic_read():
    0.00 :   ffff8000101dbf24:       ldr     w2, [x3, #52]
         : 29               page_expected_state():
         : 1129             clear_page_guard(zone, buddy, order, migratetype);
    0.00 :   ffff8000101dbf28:       ldr     x0, [x3]
    0.00 :   ffff8000101dbf2c:       ldr     x1, [x3, #24]
    0.00 :   ffff8000101dbf30:       sxtw    x2, w2
    0.00 :   ffff8000101dbf34:       ldr     x4, [x3, #56]
    0.00 :   ffff8000101dbf38:       and     x0, x0, #0xffffff
    0.00 :   ffff8000101dbf3c:       orr     x1, x1, x2
    0.00 :   ffff8000101dbf40:       add     x2, x3, #0x40
    0.00 :   ffff8000101dbf44:       orr     x0, x0, x4
         : 1138             check_new_pages():
         : 2314             * subsystem according to empirical testing, and this is also justified
    0.00 :   ffff8000101dbf48:       mov     w4, #0x0                        // #0
         : 2316             page_expected_state():
         : 1129             clear_page_guard(zone, buddy, order, migratetype);
    0.00 :   ffff8000101dbf4c:       orr     x0, x0, x1
    0.00 :   ffff8000101dbf50:       cbnz    x0, ffff8000101dc0e0 <get_page_from_freelist+0x788>
    0.00 :   ffff8000101dbf54:       nop
         : 1133             check_new_pages():
         : 2314             * subsystem according to empirical testing, and this is also justified
    0.00 :   ffff8000101dbf58:       ldr     w0, [sp, #112]
    0.00 :   ffff8000101dbf5c:       add     w4, w4, #0x1
    0.00 :   ffff8000101dbf60:       cmp     w0, w4
    0.00 :   ffff8000101dbf64:       b.le    ffff8000101dc218 <get_page_from_freelist+0x8c0>
         : 2319             atomic_read():
    0.00 :   ffff8000101dbf68:       ldr     w1, [x2, #48]
         : 29               check_new_pages():
         : 2315             * by considering the behavior of a buddy system containing a single
    0.00 :   ffff8000101dbf6c:       mov     x0, x2
         : 2317             page_expected_state():
         : 1126             * merge with it and move up one order.
    0.00 :   ffff8000101dbf70:       cmn     w1, #0x1
    0.00 :   ffff8000101dbf74:       b.ne    ffff8000101dbfa4 <get_page_from_freelist+0x64c>  // b.any
         : 1129             atomic_read():
    0.00 :   ffff8000101dbf78:       ldr     w6, [x2, #52]
    0.00 :   ffff8000101dbf7c:       add     x2, x2, #0x40
         : 30               page_expected_state():
         : 1129             clear_page_guard(zone, buddy, order, migratetype);
    0.00 :   ffff8000101dbf80:       ldr     x1, [x0]
    0.00 :   ffff8000101dbf84:       ldr     x5, [x0, #24]
    0.00 :   ffff8000101dbf88:       sxtw    x6, w6
    0.00 :   ffff8000101dbf8c:       ldr     x7, [x0, #56]
    0.00 :   ffff8000101dbf90:       and     x1, x1, #0xffffff
    0.00 :   ffff8000101dbf94:       orr     x5, x5, x6
    0.00 :   ffff8000101dbf98:       orr     x1, x1, x7
    0.00 :   ffff8000101dbf9c:       orr     x1, x1, x5
    0.00 :   ffff8000101dbfa0:       cbz     x1, ffff8000101dbf58 <get_page_from_freelist+0x600>
         : 1139             check_new_page():
         :
    0.00 :   ffff8000101dbfa4:       bl      ffff8000101d7088 <check_new_page_bad>
         : 2271             for_each_populated_zone(zone)
    0.00 :   ffff8000101dbfa8:       b       ffff8000101dbde0 <get_page_from_freelist+0x488>
         : 2273             atomic64_read():
         : 838              }
    0.00 :   ffff8000101dbfac:       ldr     x0, [x22, #1544]
    0.00 :   ffff8000101dbfb0:       ldr     x1, [x22, #1472]
         : 841              zone_page_state():
         : 222              * exactly accurate either.
    0.00 :   ffff8000101dbfb4:       cmp     x0, #0x0
    0.00 :   ffff8000101dbfb8:       csel    x0, x0, xzr, ge  // ge = tcont
    0.00 :   ffff8000101dbfbc:       cmp     x1, #0x0
    0.00 :   ffff8000101dbfc0:       csel    x1, x1, xzr, ge  // ge = tcont
         : 227              __rmqueue():
         : 2923             * fallback was found so that __rmqueue_smallest() can grab it.
    0.00 :   ffff8000101dbfc4:       cmp     x0, x1, lsr #1
    0.00 :   ffff8000101dbfc8:       b.ls    ffff8000101dbdf8 <get_page_from_freelist+0x4a0>  // b.plast
         : 2926             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101dbfcc:       cmp     w21, #0xa
    0.00 :   ffff8000101dbfd0:       mov     w1, w21
    0.00 :   ffff8000101dbfd4:       ldr     x4, [sp, #144]
    0.00 :   ffff8000101dbfd8:       b.hi    ffff8000101dbdf8 <get_page_from_freelist+0x4a0>  // b.pmore
         : 2393             get_page_from_free_area():
    0.00 :   ffff8000101dbfdc:       mov     w2, w1
    0.00 :   ffff8000101dbfe0:       add     x0, x2, x2, lsl #1
    0.00 :   ffff8000101dbfe4:       add     x0, x2, x0, lsl #2
    0.00 :   ffff8000101dbfe8:       add     x0, x22, x0, lsl #3
    0.00 :   ffff8000101dbfec:       ldr     x10, [x0, #256]
    0.00 :   ffff8000101dbff0:       cmp     x10, x4
    0.00 :   ffff8000101dbff4:       b.eq    ffff8000101dc438 <get_page_from_freelist+0xae0>  // b.none
    0.00 :   ffff8000101dbff8:       sub     x11, x10, #0x8
    0.00 :   ffff8000101dbffc:       mov     x3, x11
         : 113              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101dc000:       cbz     x11, ffff8000101dc438 <get_page_from_freelist+0xae0>
         : 2393             arch_static_branch():
    0.00 :   ffff8000101dc004:       nop
         : 22               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101dc008:       ldp     x4, x0, [x10]
         : 148              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101dc00c:       str     x0, [x4, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dc010:       mov     x9, #0x122                      // #290
         : 150              expand():
         : 2228             */
    0.00 :   ffff8000101dc014:       mov     w8, #0x1                        // #1
         : 2230             list_del():
    0.00 :   ffff8000101dc018:       movk    x9, #0xdead, lsl #48
         : 149              expand():
    0.00 :   ffff8000101dc01c:       lsl     w8, w8, w1
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc020:       cmp     w1, w21
         : 2232             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc024:       mov     w13, #0x68                      // #104
         : 930              expand():
         : 2228             */
    0.00 :   ffff8000101dc028:       sxtw    x8, w8
         : 2230             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc02c:       mov     x12, #0x100                     // #256
         : 930              __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101dc030:       str     x4, [x0]
         : 115              list_del():
         : 147              entry->next = LIST_POISON1;
    0.00 :   ffff8000101dc034:       mov     x4, #0x100                      // #256
         : 149              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101dc038:       add     x0, x2, x2, lsl #1
         : 967              list_del():
    0.00 :   ffff8000101dc03c:       movk    x4, #0xdead, lsl #48
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dc040:       stp     x4, x9, [x10]
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101dc044:       add     x2, x2, x0, lsl #2
         : 966              __ClearPageBuddy():
    0.00 :   ffff8000101dc048:       ldr     w0, [x11, #48]
         : 743              del_page_from_free_list():
    0.00 :   ffff8000101dc04c:       add     x2, x22, x2, lsl #3
         : 966              __ClearPageBuddy():
    0.00 :   ffff8000101dc050:       orr     w0, w0, #0x80
    0.00 :   ffff8000101dc054:       str     w0, [x11, #48]
         : 744              set_page_private():
    0.00 :   ffff8000101dc058:       str     xzr, [x10, #32]
         : 250              del_page_from_free_list():
    0.00 :   ffff8000101dc05c:       ldr     x0, [x2, #288]
    0.00 :   ffff8000101dc060:       sub     x0, x0, #0x1
    0.00 :   ffff8000101dc064:       str     x0, [x2, #288]
         : 968              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc068:       b.le    ffff8000101dc0cc <get_page_from_freelist+0x774>
    0.00 :   ffff8000101dc06c:       nop
         : 2231             {
    0.00 :   ffff8000101dc070:       sub     w4, w1, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101dc074:       lsr     x8, x8, #1
         : 2231             {
    0.00 :   ffff8000101dc078:       mov     x1, x4
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc07c:       cmp     w4, w21
         : 2232             list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101dc080:       add     x0, x4, x4, lsl #1
         : 88               expand():
         :
    0.00 :   ffff8000101dc084:       add     x2, x11, x8, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc088:       umaddl  x5, w4, w13, x12
    0.00 :   ffff8000101dc08c:       add     x6, x2, #0x8
         : 931              list_add():
    0.00 :   ffff8000101dc090:       add     x0, x4, x0, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101dc094:       add     x9, x22, x5
         : 929              list_add():
    0.00 :   ffff8000101dc098:       add     x0, x22, x0, lsl #3
    0.00 :   ffff8000101dc09c:       ldr     x7, [x0, #256]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101dc0a0:       str     x6, [x7, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101dc0a4:       stp     x7, x9, [x2, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101dc0a8:       str     x6, [x22, x5]
         : 75               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101dc0ac:       ldr     x5, [x0, #288]
    0.00 :   ffff8000101dc0b0:       add     x5, x5, #0x1
    0.00 :   ffff8000101dc0b4:       str     x5, [x0, #288]
         : 933              set_page_private():
    0.00 :   ffff8000101dc0b8:       str     x4, [x2, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101dc0bc:       ldr     w0, [x2, #48]
    0.00 :   ffff8000101dc0c0:       and     w0, w0, #0xffffff7f
    0.00 :   ffff8000101dc0c4:       str     w0, [x2, #48]
         : 745              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc0c8:       b.ne    ffff8000101dc070 <get_page_from_freelist+0x718>  // b.any
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101dc0cc:       mov     x0, #0x4                        // #4
    0.00 :   ffff8000101dc0d0:       str     x0, [x10, #24]
         : 221              atomic_read():
         : 28               return arch_atomic_read(v);
    0.00 :   ffff8000101dc0d4:       ldr     w0, [x3, #48]
         : 30               page_expected_state():
         : 1126             * merge with it and move up one order.
    0.00 :   ffff8000101dc0d8:       cmn     w0, #0x1
    0.00 :   ffff8000101dc0dc:       b.eq    ffff8000101dbf24 <get_page_from_freelist+0x5cc>  // b.none
    0.00 :   ffff8000101dc0e0:       mov     x0, x3
         : 1130             check_new_page():
         :
    0.00 :   ffff8000101dc0e4:       bl      ffff8000101d7088 <check_new_page_bad>
         : 2271             for_each_populated_zone(zone)
    0.00 :   ffff8000101dc0e8:       b       ffff8000101dbde0 <get_page_from_freelist+0x488>
         : 2273             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101dc0ec:       add     w0, w0, #0x1
    0.00 :   ffff8000101dc0f0:       add     x4, x4, #0x68
    0.00 :   ffff8000101dc0f4:       cmp     w0, #0xb
    0.00 :   ffff8000101dc0f8:       b.ne    ffff8000101dbe0c <get_page_from_freelist+0x4b4>  // b.any
         : 2393             __rmqueue():
         : 2934             int current_order;
    0.00 :   ffff8000101dc0fc:       mov     w2, w21
    0.00 :   ffff8000101dc100:       ldr     x4, [sp, #144]
    0.00 :   ffff8000101dc104:       cbz     w19, ffff8000101dc44c <get_page_from_freelist+0xaf4>
         : 2938             get_page_from_free_area():
    0.00 :   ffff8000101dc108:       mov     w1, w2
    0.00 :   ffff8000101dc10c:       add     x0, x1, x1, lsl #1
    0.00 :   ffff8000101dc110:       add     x0, x1, x0, lsl #2
    0.00 :   ffff8000101dc114:       add     x0, x22, x0, lsl #3
    0.00 :   ffff8000101dc118:       ldr     x11, [x0, #256]
    0.00 :   ffff8000101dc11c:       cmp     x11, x4
    0.00 :   ffff8000101dc120:       b.eq    ffff8000101dc6e0 <get_page_from_freelist+0xd88>  // b.none
    0.00 :   ffff8000101dc124:       sub     x10, x11, #0x8
    0.00 :   ffff8000101dc128:       mov     x3, x10
         : 113              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101dc12c:       cbz     x10, ffff8000101dc6e0 <get_page_from_freelist+0xd88>
         : 2393             arch_static_branch():
    0.00 :   ffff8000101dc130:       nop
         : 22               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101dc134:       ldp     x4, x0, [x11]
         : 148              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101dc138:       str     x0, [x4, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dc13c:       mov     x8, #0x122                      // #290
         : 150              expand():
         : 2228             */
    0.00 :   ffff8000101dc140:       mov     w9, #0x1                        // #1
         : 2230             list_del():
    0.00 :   ffff8000101dc144:       movk    x8, #0xdead, lsl #48
         : 149              expand():
    0.00 :   ffff8000101dc148:       lsl     w9, w9, w2
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc14c:       cmp     w2, w21
         : 2232             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc150:       mov     w13, #0x68                      // #104
         : 930              expand():
         : 2228             */
    0.00 :   ffff8000101dc154:       sxtw    x9, w9
         : 2230             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc158:       mov     x12, #0x100                     // #256
         : 930              __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101dc15c:       str     x4, [x0]
         : 115              list_del():
         : 147              entry->next = LIST_POISON1;
    0.00 :   ffff8000101dc160:       mov     x4, #0x100                      // #256
         : 149              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101dc164:       add     x0, x1, x1, lsl #1
         : 967              list_del():
    0.00 :   ffff8000101dc168:       movk    x4, #0xdead, lsl #48
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dc16c:       stp     x4, x8, [x11]
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101dc170:       add     x1, x1, x0, lsl #2
         : 966              __ClearPageBuddy():
    0.00 :   ffff8000101dc174:       ldr     w0, [x10, #48]
         : 743              del_page_from_free_list():
    0.00 :   ffff8000101dc178:       add     x1, x22, x1, lsl #3
         : 966              __ClearPageBuddy():
    0.00 :   ffff8000101dc17c:       orr     w0, w0, #0x80
    0.00 :   ffff8000101dc180:       str     w0, [x10, #48]
         : 744              set_page_private():
    0.00 :   ffff8000101dc184:       str     xzr, [x11, #32]
         : 250              del_page_from_free_list():
    0.00 :   ffff8000101dc188:       ldr     x0, [x1, #288]
    0.00 :   ffff8000101dc18c:       sub     x0, x0, #0x1
    0.00 :   ffff8000101dc190:       str     x0, [x1, #288]
         : 968              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc194:       b.le    ffff8000101dc1f4 <get_page_from_freelist+0x89c>
         : 2231             {
    0.00 :   ffff8000101dc198:       sub     w4, w2, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101dc19c:       lsr     x9, x9, #1
         : 2231             {
    0.00 :   ffff8000101dc1a0:       mov     x2, x4
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc1a4:       cmp     w4, w21
         : 2232             list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101dc1a8:       add     x0, x4, x4, lsl #1
         : 88               expand():
         :
    0.00 :   ffff8000101dc1ac:       add     x1, x10, x9, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc1b0:       umaddl  x5, w4, w13, x12
    0.00 :   ffff8000101dc1b4:       add     x6, x1, #0x8
         : 931              list_add():
    0.00 :   ffff8000101dc1b8:       add     x0, x4, x0, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101dc1bc:       add     x8, x22, x5
         : 929              list_add():
    0.00 :   ffff8000101dc1c0:       add     x0, x22, x0, lsl #3
    0.00 :   ffff8000101dc1c4:       ldr     x7, [x0, #256]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101dc1c8:       str     x6, [x7, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101dc1cc:       stp     x7, x8, [x1, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101dc1d0:       str     x6, [x22, x5]
         : 75               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101dc1d4:       ldr     x5, [x0, #288]
    0.00 :   ffff8000101dc1d8:       add     x5, x5, #0x1
    0.00 :   ffff8000101dc1dc:       str     x5, [x0, #288]
         : 933              set_page_private():
    0.00 :   ffff8000101dc1e0:       str     x4, [x1, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101dc1e4:       ldr     w0, [x1, #48]
    0.00 :   ffff8000101dc1e8:       and     w0, w0, #0xffffff7f
    0.00 :   ffff8000101dc1ec:       str     w0, [x1, #48]
         : 745              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc1f0:       b.ne    ffff8000101dc198 <get_page_from_freelist+0x840>  // b.any
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101dc1f4:       mov     x0, #0x4                        // #4
    0.00 :   ffff8000101dc1f8:       str     x0, [x11, #24]
         : 221              __rmqueue():
         : 2937             int fallback_mt;
    0.00 :   ffff8000101dc1fc:       b       ffff8000101dbf18 <get_page_from_freelist+0x5c0>
         : 2939             test_bit():
    0.00 :   ffff8000101dc200:       ldur    x4, [x1, #-8]
         : 107              page_reported():
         : 21               DECLARE_STATIC_KEY_FALSE(page_reporting_enabled);
         : 22               void __page_reporting_notify(void);
         :
         : 24               static inline bool page_reported(struct page *page)
         : 25               {
         : 26               return static_branch_unlikely(&page_reporting_enabled) &&
    0.00 :   ffff8000101dc204:       tbz     w4, #2, ffff8000101dbe40 <get_page_from_freelist+0x4e8>
         : 28               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101dc208:       ldur    x4, [x1, #-8]
    0.00 :   ffff8000101dc20c:       and     x4, x4, #0xfffffffffffffffb
    0.00 :   ffff8000101dc210:       stur    x4, [x1, #-8]
    0.00 :   ffff8000101dc214:       b       ffff8000101dbe40 <get_page_from_freelist+0x4e8>
         : 34               spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000101dc218:       ldr     x0, [sp, #168]
    0.00 :   ffff8000101dc21c:       mov     x25, x22
    0.00 :   ffff8000101dc220:       mov     w22, w21
    0.00 :   ffff8000101dc224:       mov     x21, x26
    0.00 :   ffff8000101dc228:       mov     w26, w24
    0.00 :   ffff8000101dc22c:       mov     x24, x3
    0.00 :   ffff8000101dc230:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 407              rmqueue():
         : 3561             __mod_zone_freepage_state(zone, -(1UL << order), mt);
    0.00 :   ffff8000101dc234:       ldr     w0, [sp, #112]
         : 3563             __mod_zone_freepage_state():
         :
         : 409              #define inc_zone_state __inc_zone_state
         : 410              #define inc_node_state __inc_node_state
         : 411              #define dec_zone_state __dec_zone_state
         :
         : 413              #define set_pgdat_percpu_threshold(pgdat, callback) { }
    0.00 :   ffff8000101dc238:       mov     w1, #0x0                        // #0
         : 415              rmqueue():
    0.00 :   ffff8000101dc23c:       neg     w19, w0
         : 3562             __mod_zone_freepage_state():
    0.00 :   ffff8000101dc240:       mov     x0, x25
         : 409              get_pcppage_migratetype():
         : 213              static bool _init_on_free_enabled_early __read_mostly
    0.00 :   ffff8000101dc244:       ldr     x20, [x24, #32]
         : 215              __mod_zone_freepage_state():
    0.00 :   ffff8000101dc248:       sxtw    x19, w19
    0.00 :   ffff8000101dc24c:       mov     x2, x19
    0.00 :   ffff8000101dc250:       bl      ffff8000101a4ca0 <__mod_zone_page_state>
         :
    0.00 :   ffff8000101dc254:       cmp     w20, #0x4
    0.00 :   ffff8000101dc258:       b.eq    ffff8000101dc754 <get_page_from_freelist+0xdfc>  // b.none
         : 412              page_zonenum():
    0.00 :   ffff8000101dc25c:       ldr     x0, [x24]
         : 1128             __count_vm_events():
         : 76               raw_cpu_add(vm_event_states.event[item], delta);
    0.00 :   ffff8000101dc260:       adrp    x1, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000101dc264:       add     x1, x1, #0x1f8
    0.00 :   ffff8000101dc268:       ldr     w3, [sp, #112]
         : 80               __kern_my_cpu_offset():
    0.00 :   ffff8000101dc26c:       mrs     x2, tpidr_el1
         : 40               rmqueue():
         : 3564             /* Remove page from free list */
    0.00 :   ffff8000101dc270:       ubfx    x0, x0, #58, #2
         : 3566             __count_vm_events():
    0.00 :   ffff8000101dc274:       add     x0, x0, #0x4
    0.00 :   ffff8000101dc278:       add     x0, x1, x0, lsl #3
    0.00 :   ffff8000101dc27c:       ldr     x1, [x0, x2]
    0.00 :   ffff8000101dc280:       add     x1, x1, w3, sxtw
    0.00 :   ffff8000101dc284:       str     x1, [x0, x2]
         : 81               arch_static_branch():
    0.00 :   ffff8000101dc288:       nop
         : 22               zone_statistics():
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dc28c:       ldr     x2, [sp, #128]
         : 3454             numa_node_id():
    0.00 :   ffff8000101dc290:       adrp    x0, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000101dc294:       add     x0, x0, #0x5b0
         : 91               zone_statistics():
         : 3449             migratetype = MIGRATE_MOVABLE;
    0.00 :   ffff8000101dc298:       ldr     w1, [x25, #72]
         : 3451             numa_node_id():
    0.00 :   ffff8000101dc29c:       add     x0, x0, #0x60
         : 90               __kern_my_cpu_offset():
    0.00 :   ffff8000101dc2a0:       mrs     x3, tpidr_el1
         : 40               zone_statistics():
    0.00 :   ffff8000101dc2a4:       ldr     w0, [x0, x3]
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dc2a8:       ldr     w2, [x2, #72]
         : 3450             }
    0.00 :   ffff8000101dc2ac:       cmp     w1, w0
    0.00 :   ffff8000101dc2b0:       cset    w19, ne  // ne = any
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dc2b4:       cmp     w1, w2
         : 3450             }
    0.00 :   ffff8000101dc2b8:       add     w19, w19, #0x4
         : 3452             local_lock_irqsave(&pagesets.lock, flags);
    0.00 :   ffff8000101dc2bc:       b.eq    ffff8000101dc680 <get_page_from_freelist+0xd28>  // b.none
         : 3455             }
    0.00 :   ffff8000101dc2c0:       mov     x0, x25
    0.00 :   ffff8000101dc2c4:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000101dc2c8:       bl      ffff8000101a66b0 <__inc_numa_state>
         :
    0.00 :   ffff8000101dc2cc:       ldr     x0, [sp, #128]
    0.00 :   ffff8000101dc2d0:       mov     w1, #0x2                        // #2
    0.00 :   ffff8000101dc2d4:       bl      ffff8000101a66b0 <__inc_numa_state>
         : 3458             * Free a list of 0-order pages
    0.00 :   ffff8000101dc2d8:       mov     w1, w19
    0.00 :   ffff8000101dc2dc:       mov     x0, x25
    0.00 :   ffff8000101dc2e0:       bl      ffff8000101a66b0 <__inc_numa_state>
         : 3462             arch_local_irq_restore():
    0.00 :   ffff8000101dc2e4:       ldr     x0, [sp, #176]
    0.00 :   ffff8000101dc2e8:       msr     daif, x0
         : 124              arch_static_branch():
    0.00 :   ffff8000101dc2ec:       nop
         : 22               test_bit():
         : 106              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101dc2f0:       ldr     x0, [x25, #1336]
         : 108              rmqueue():
         : 3570             * pageblock
    0.00 :   ffff8000101dc2f4:       tbz     w0, #0, ffff8000101dc60c <get_page_from_freelist+0xcb4>
         : 3571             */
    0.00 :   ffff8000101dc2f8:       add     x0, x25, #0x538
         : 3573             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101dc2fc:       b       ffff8000101dc674 <get_page_from_freelist+0xd1c>
    0.00 :   ffff8000101dc300:       b       ffff8000101dc674 <get_page_from_freelist+0xd1c>
         : 46               __lse_atomic64_andnot():
         : 176              "       " #asm_op "     %[i], %[v]\n"                                   \
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff8000101dc304:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000101dc308:       stclr   x1, [x0]
         : 184              rmqueue():
         : 3572             if (order >= pageblock_order - 1) {
    0.00 :   ffff8000101dc30c:       ldr     x3, [x25, #80]
    0.00 :   ffff8000101dc310:       mov     w4, #0x5c29                     // #23593
    0.00 :   ffff8000101dc314:       movk    w4, #0xc28f, lsl #16
    0.00 :   ffff8000101dc318:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000101dc31c:       sub     x3, x25, x3
    0.00 :   ffff8000101dc320:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101dc324:       mov     x0, x25
    0.00 :   ffff8000101dc328:       asr     x3, x3, #6
    0.00 :   ffff8000101dc32c:       mul     w3, w3, w4
    0.00 :   ffff8000101dc330:       bl      ffff800010198cf0 <wakeup_kswapd>
    0.00 :   ffff8000101dc334:       b       ffff8000101dbc14 <get_page_from_freelist+0x2bc>
         : 3550             if (!is_migrate_isolate(mt)) {
    0.00 :   ffff8000101dc338:       ldr     x4, [sp, #160]
    0.00 :   ffff8000101dc33c:       mov     w1, w21
         : 3553             get_page_from_free_area():
    0.00 :   ffff8000101dc340:       mov     w2, w1
    0.00 :   ffff8000101dc344:       add     x0, x2, x2, lsl #1
    0.00 :   ffff8000101dc348:       add     x0, x2, x0, lsl #2
    0.00 :   ffff8000101dc34c:       add     x0, x22, x0, lsl #3
    0.00 :   ffff8000101dc350:       ldr     x10, [x0, #240]
    0.00 :   ffff8000101dc354:       cmp     x10, x4
    0.00 :   ffff8000101dc358:       b.eq    ffff8000101dc53c <get_page_from_freelist+0xbe4>  // b.none
    0.00 :   ffff8000101dc35c:       sub     x11, x10, #0x8
    0.00 :   ffff8000101dc360:       mov     x3, x11
         : 113              __rmqueue_smallest():
         : 2391             * when pcp lists are being refilled from the free lists. With debug_pagealloc
    0.00 :   ffff8000101dc364:       cbz     x11, ffff8000101dc53c <get_page_from_freelist+0xbe4>
         : 2393             arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff8000101dc368:       nop
         : 23               list_del():
         : 146              __list_del_entry(entry);
    0.00 :   ffff8000101dc36c:       ldp     x4, x0, [x10]
         : 148              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000101dc370:       str     x0, [x4, #8]
         : 114              list_del():
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dc374:       mov     x9, #0x122                      // #290
         : 150              expand():
         : 2228             */
    0.00 :   ffff8000101dc378:       mov     w8, #0x1                        // #1
         : 2230             list_del():
    0.00 :   ffff8000101dc37c:       movk    x9, #0xdead, lsl #48
         : 149              expand():
    0.00 :   ffff8000101dc380:       lsl     w8, w8, w1
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc384:       cmp     w1, w21
         : 2232             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc388:       mov     w13, #0x68                      // #104
         : 930              expand():
         : 2228             */
    0.00 :   ffff8000101dc38c:       sxtw    x8, w8
         : 2230             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc390:       mov     x12, #0xf0                      // #240
         : 930              __list_del():
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000101dc394:       str     x4, [x0]
         : 115              list_del():
         : 147              entry->next = LIST_POISON1;
    0.00 :   ffff8000101dc398:       mov     x4, #0x100                      // #256
         : 149              del_page_from_free_list():
         : 965              if (order < pageblock_order && migratetype == MIGRATE_MOVABLE)
    0.00 :   ffff8000101dc39c:       add     x0, x2, x2, lsl #1
         : 967              list_del():
    0.00 :   ffff8000101dc3a0:       movk    x4, #0xdead, lsl #48
         : 148              entry->prev = LIST_POISON2;
    0.00 :   ffff8000101dc3a4:       stp     x4, x9, [x10]
         : 150              del_page_from_free_list():
    0.00 :   ffff8000101dc3a8:       add     x2, x2, x0, lsl #2
         : 966              __ClearPageBuddy():
    0.00 :   ffff8000101dc3ac:       ldr     w0, [x11, #48]
         : 743              del_page_from_free_list():
    0.00 :   ffff8000101dc3b0:       add     x2, x22, x2, lsl #3
         : 966              __ClearPageBuddy():
    0.00 :   ffff8000101dc3b4:       orr     w0, w0, #0x80
    0.00 :   ffff8000101dc3b8:       str     w0, [x11, #48]
         : 744              set_page_private():
    0.00 :   ffff8000101dc3bc:       str     xzr, [x10, #32]
         : 250              del_page_from_free_list():
    0.00 :   ffff8000101dc3c0:       ldr     x0, [x2, #288]
    0.00 :   ffff8000101dc3c4:       sub     x0, x0, #0x1
    0.00 :   ffff8000101dc3c8:       str     x0, [x2, #288]
         : 968              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc3cc:       b.le    ffff8000101dc42c <get_page_from_freelist+0xad4>
         : 2231             {
    0.00 :   ffff8000101dc3d0:       sub     w4, w1, #0x1
         : 2232             return deferred_grow_zone(zone, order);
    0.00 :   ffff8000101dc3d4:       lsr     x8, x8, #1
         : 2231             {
    0.00 :   ffff8000101dc3d8:       mov     x1, x4
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc3dc:       cmp     w4, w21
         : 2232             list_add():
         : 86               __list_add(new, head, head->next);
    0.00 :   ffff8000101dc3e0:       add     x0, x4, x4, lsl #1
         : 88               expand():
         :
    0.00 :   ffff8000101dc3e4:       add     x2, x11, x8, lsl #6
         : 2243             add_to_free_list():
         : 928              if (page_zone_id(page) != page_zone_id(buddy))
    0.00 :   ffff8000101dc3e8:       umaddl  x5, w4, w13, x12
    0.00 :   ffff8000101dc3ec:       add     x6, x2, #0x8
         : 931              list_add():
    0.00 :   ffff8000101dc3f0:       add     x0, x4, x0, lsl #2
         : 87               add_to_free_list():
    0.00 :   ffff8000101dc3f4:       add     x9, x22, x5
         : 929              list_add():
    0.00 :   ffff8000101dc3f8:       add     x0, x22, x0, lsl #3
    0.00 :   ffff8000101dc3fc:       ldr     x7, [x0, #240]
         : 88               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000101dc400:       str     x6, [x7, #8]
         : 72               new->prev = prev;
    0.00 :   ffff8000101dc404:       stp     x7, x9, [x2, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000101dc408:       str     x6, [x22, x5]
         : 75               add_to_free_list():
         : 929              return false;
    0.00 :   ffff8000101dc40c:       ldr     x5, [x0, #288]
    0.00 :   ffff8000101dc410:       add     x5, x5, #0x1
    0.00 :   ffff8000101dc414:       str     x5, [x0, #288]
         : 933              set_page_private():
    0.00 :   ffff8000101dc418:       str     x4, [x2, #40]
         : 250              __SetPageBuddy():
    0.00 :   ffff8000101dc41c:       ldr     w0, [x2, #48]
    0.00 :   ffff8000101dc420:       and     w0, w0, #0xffffff7f
    0.00 :   ffff8000101dc424:       str     w0, [x2, #48]
         : 745              expand():
         : 2230             _deferred_grow_zone(struct zone *zone, unsigned int order)
    0.00 :   ffff8000101dc428:       b.ne    ffff8000101dc3d0 <get_page_from_freelist+0xa78>  // b.any
         : 2232             set_pcppage_migratetype():
         : 218              }
    0.00 :   ffff8000101dc42c:       mov     x0, #0x3                        // #3
    0.00 :   ffff8000101dc430:       str     x0, [x10, #24]
         : 221              rmqueue():
         : 3555             * exists.
    0.00 :   ffff8000101dc434:       b       ffff8000101dbf18 <get_page_from_freelist+0x5c0>
         : 3557             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101dc438:       add     w1, w1, #0x1
    0.00 :   ffff8000101dc43c:       add     x4, x4, #0x68
    0.00 :   ffff8000101dc440:       cmp     w1, #0xb
    0.00 :   ffff8000101dc444:       b.ne    ffff8000101dbfdc <get_page_from_freelist+0x684>  // b.any
    0.00 :   ffff8000101dc448:       b       ffff8000101dbdf8 <get_page_from_freelist+0x4a0>
         : 2394             __rmqueue_fallback():
         : 2845             * pageblock is exhausted.
    0.00 :   ffff8000101dc44c:       ldr     w0, [sp, #136]
    0.00 :   ffff8000101dc450:       cbnz    w0, ffff8000101dc5b0 <get_page_from_freelist+0xc58>
         : 2853             struct zone *zone;
    0.00 :   ffff8000101dc454:       cmp     w21, #0xa
    0.00 :   ffff8000101dc458:       b.gt    ffff8000101dc6a0 <get_page_from_freelist+0xd48>
    0.00 :   ffff8000101dc45c:       mov     w14, w21
         : 2845             * pageblock is exhausted.
    0.00 :   ffff8000101dc460:       mov     w15, #0xa                       // #10
         : 2855             int order;
    0.00 :   ffff8000101dc464:       mov     w13, #0x68                      // #104
    0.00 :   ffff8000101dc468:       mov     x12, #0xc0                      // #192
    0.00 :   ffff8000101dc46c:       smaddl  x11, w15, w13, x12
         : 2856             bool ret;
    0.00 :   ffff8000101dc470:       ldr     w2, [sp, #140]
    0.00 :   ffff8000101dc474:       add     x4, sp, #0xf7
    0.00 :   ffff8000101dc478:       mov     w3, #0x0                        // #0
         : 2855             int order;
    0.00 :   ffff8000101dc47c:       add     x11, x22, x11
         : 2856             bool ret;
    0.00 :   ffff8000101dc480:       mov     w1, w15
    0.00 :   ffff8000101dc484:       mov     x0, x11
    0.00 :   ffff8000101dc488:       bl      ffff8000101d9d30 <find_suitable_fallback>
         : 2858             for_each_zone_zonelist_nodemask(zone, z, zonelist, ac->highest_zoneidx,
    0.00 :   ffff8000101dc48c:       cmn     w0, #0x1
    0.00 :   ffff8000101dc490:       b.eq    ffff8000101dc690 <get_page_from_freelist+0xd38>  // b.none
         : 2869             for (order = 0; order < MAX_ORDER; order++) {
    0.00 :   ffff8000101dc494:       ldrb    w4, [sp, #247]
    0.00 :   ffff8000101dc498:       cbnz    w4, ffff8000101dc580 <get_page_from_freelist+0xc28>
    0.00 :   ffff8000101dc49c:       ldr     w1, [sp, #140]
    0.00 :   ffff8000101dc4a0:       cmp     w1, #0x1
    0.00 :   ffff8000101dc4a4:       cset    w2, eq  // eq = none
         : 2870             struct free_area *area = &(zone->free_area[order]);
    0.00 :   ffff8000101dc4a8:       cmp     w15, w21
    0.00 :   ffff8000101dc4ac:       cset    w1, gt
    0.00 :   ffff8000101dc4b0:       tst     w2, w1
    0.00 :   ffff8000101dc4b4:       b.eq    ffff8000101dc580 <get_page_from_freelist+0xc28>  // b.none
         : 2879             * in this loop although we changed the pageblock type
    0.00 :   ffff8000101dc4b8:       cmp     w21, #0xa
    0.00 :   ffff8000101dc4bc:       mov     w12, w21
    0.00 :   ffff8000101dc4c0:       ldr     x1, [sp, #192]
    0.00 :   ffff8000101dc4c4:       b.le    ffff8000101dc4dc <get_page_from_freelist+0xb84>
    0.00 :   ffff8000101dc4c8:       b       ffff8000101dc580 <get_page_from_freelist+0xc28>
         : 2880             * from highatomic to ac->migratetype. So we should
    0.00 :   ffff8000101dc4cc:       add     w12, w12, #0x1
    0.00 :   ffff8000101dc4d0:       add     x1, x11, #0x68
         : 2879             * in this loop although we changed the pageblock type
    0.00 :   ffff8000101dc4d4:       cmp     w12, #0xb
    0.00 :   ffff8000101dc4d8:       b.eq    ffff8000101dc72c <get_page_from_freelist+0xdd4>  // b.none
         : 2881             * adjust the count once.
    0.00 :   ffff8000101dc4dc:       mov     x11, x1
         : 2882             */
    0.00 :   ffff8000101dc4e0:       mov     x0, x1
    0.00 :   ffff8000101dc4e4:       add     x4, sp, #0xf7
    0.00 :   ffff8000101dc4e8:       mov     w3, #0x0                        // #0
    0.00 :   ffff8000101dc4ec:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000101dc4f0:       mov     w1, w12
    0.00 :   ffff8000101dc4f4:       bl      ffff8000101d9d30 <find_suitable_fallback>
         : 2884             /*
    0.00 :   ffff8000101dc4f8:       cmn     w0, #0x1
    0.00 :   ffff8000101dc4fc:       b.eq    ffff8000101dc4cc <get_page_from_freelist+0xb74>  // b.none
    0.00 :   ffff8000101dc500:       sxtw    x0, w0
    0.00 :   ffff8000101dc504:       ldrb    w4, [sp, #247]
    0.00 :   ffff8000101dc508:       lsl     x5, x0, #4
    0.00 :   ffff8000101dc50c:       nop
         : 2891             get_page_from_free_area():
    0.00 :   ffff8000101dc510:       lsl     x0, x0, #4
    0.00 :   ffff8000101dc514:       add     x5, x11, x5
         : 106              __rmqueue_fallback():
         : 2897             * Convert to ac->migratetype and avoid the normal
    0.00 :   ffff8000101dc518:       ldr     w3, [sp, #140]
    0.00 :   ffff8000101dc51c:       mov     w2, w24
         : 2900             get_page_from_free_area():
    0.00 :   ffff8000101dc520:       ldr     x1, [x11, x0]
         : 105              __rmqueue_fallback():
    0.00 :   ffff8000101dc524:       mov     x0, x22
         : 2898             get_page_from_free_area():
    0.00 :   ffff8000101dc528:       cmp     x1, x5
    0.00 :   ffff8000101dc52c:       sub     x1, x1, #0x8
         : 106              __rmqueue_fallback():
    0.00 :   ffff8000101dc530:       csel    x1, x1, xzr, ne  // ne = any
    0.00 :   ffff8000101dc534:       bl      ffff8000101d98f8 <steal_suitable_fallback>
         : 2899             __rmqueue():
         :
    0.00 :   ffff8000101dc538:       b       ffff8000101dbdfc <get_page_from_freelist+0x4a4>
         : 2941             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101dc53c:       add     w1, w1, #0x1
    0.00 :   ffff8000101dc540:       add     x4, x4, #0x68
    0.00 :   ffff8000101dc544:       cmp     w1, #0xb
    0.00 :   ffff8000101dc548:       b.ne    ffff8000101dc340 <get_page_from_freelist+0x9e8>  // b.any
    0.00 :   ffff8000101dc54c:       b       ffff8000101dbdf0 <get_page_from_freelist+0x498>
         : 2394             test_bit():
    0.00 :   ffff8000101dc550:       ldur    x0, [x10, #-8]
         : 107              page_reported():
    0.00 :   ffff8000101dc554:       tbz     w0, #2, ffff8000101dc008 <get_page_from_freelist+0x6b0>
         : 22               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101dc558:       ldur    x0, [x10, #-8]
    0.00 :   ffff8000101dc55c:       and     x0, x0, #0xfffffffffffffffb
    0.00 :   ffff8000101dc560:       stur    x0, [x10, #-8]
    0.00 :   ffff8000101dc564:       b       ffff8000101dc008 <get_page_from_freelist+0x6b0>
         : 34               test_bit():
         : 106              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101dc568:       ldur    x0, [x10, #-8]
         : 108              page_reported():
    0.00 :   ffff8000101dc56c:       tbz     w0, #2, ffff8000101dc36c <get_page_from_freelist+0xa14>
         : 22               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101dc570:       ldur    x0, [x10, #-8]
    0.00 :   ffff8000101dc574:       and     x0, x0, #0xfffffffffffffffb
    0.00 :   ffff8000101dc578:       stur    x0, [x10, #-8]
    0.00 :   ffff8000101dc57c:       b       ffff8000101dc36c <get_page_from_freelist+0xa14>
    0.00 :   ffff8000101dc580:       sxtw    x0, w0
    0.00 :   ffff8000101dc584:       lsl     x5, x0, #4
    0.00 :   ffff8000101dc588:       b       ffff8000101dc510 <get_page_from_freelist+0xbb8>
         : 37               rmqueue():
         : 3527             int i;
    0.00 :   ffff8000101dc58c:       mov     x28, #0x1                       // #1
    0.00 :   ffff8000101dc590:       mov     x23, #0x10                      // #16
    0.00 :   ffff8000101dc594:       mov     w19, w28
    0.00 :   ffff8000101dc598:       b       ffff8000101dbd68 <get_page_from_freelist+0x410>
         : 3532             get_page_from_freelist():
         :
    0.00 :   ffff8000101dc59c:       ldr     x0, [x25, #80]
    0.00 :   ffff8000101dc5a0:       str     x0, [sp, #152]
         : 3927             #ifdef CONFIG_CMA
    0.00 :   ffff8000101dc5a4:       b       ffff8000101dbc18 <get_page_from_freelist+0x2c0>
         : 3929             arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff8000101dc5a8:       dsb     sy
   82.63 :   ffff8000101dc5ac:       b       ffff8000101dbc0c <get_page_from_freelist+0x2b4>
         : 138              __rmqueue_fallback():
         : 2846             */
    0.00 :   ffff8000101dc5b0:       mov     w14, #0x9                       // #9
    0.00 :   ffff8000101dc5b4:       b       ffff8000101dc460 <get_page_from_freelist+0xb08>
         : 2849             __rmqueue_pcplist():
         : 3474             * Free isolated pages directly to the allocator, see
    0.00 :   ffff8000101dc5b8:       ldr     w1, [x0, #8]
         : 3473             /*
    0.00 :   ffff8000101dc5bc:       mov     w3, w19
    0.00 :   ffff8000101dc5c0:       mov     w4, w26
    0.00 :   ffff8000101dc5c4:       mov     x2, x24
    0.00 :   ffff8000101dc5c8:       mov     x0, x25
    0.00 :   ffff8000101dc5cc:       str     x5, [sp, #104]
    0.00 :   ffff8000101dc5d0:       sxtw    x1, w1
    0.00 :   ffff8000101dc5d4:       bl      ffff8000101d9dc8 <rmqueue_bulk.constprop.127>
    0.00 :   ffff8000101dc5d8:       ldr     w1, [x23, x28]
         : 3476             */
    0.00 :   ffff8000101dc5dc:       ldr     x5, [sp, #104]
         : 3473             /*
    0.00 :   ffff8000101dc5e0:       add     w0, w1, w0
    0.00 :   ffff8000101dc5e4:       str     w0, [x23, x28]
         : 3476             list_empty():
         : 282              return READ_ONCE(head->next) == head;
    0.00 :   ffff8000101dc5e8:       ldr     x0, [x20, #16]
         : 284              __rmqueue_pcplist():
         : 3476             */
    0.00 :   ffff8000101dc5ec:       cmp     x24, x0
    0.00 :   ffff8000101dc5f0:       b.ne    ffff8000101dbb34 <get_page_from_freelist+0x1dc>  // b.any
    0.00 :   ffff8000101dc5f4:       nop
         : 3477             migratetype = get_pcppage_migratetype(page);
    0.00 :   ffff8000101dc5f8:       mov     x24, #0x0                       // #0
    0.00 :   ffff8000101dc5fc:       b       ffff8000101dbc04 <get_page_from_freelist+0x2ac>
         : 3480             arch_local_irq_restore():
    0.00 :   ffff8000101dc600:       dsb     sy
         : 131              test_bit():
         : 106              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101dc604:       ldr     x0, [x25, #1336]
         : 108              rmqueue():
         : 3570             * pageblock
    0.00 :   ffff8000101dc608:       tbnz    w0, #0, ffff8000101dc2f8 <get_page_from_freelist+0x9a0>
         : 3572             get_page_from_freelist():
         : 3994             return __zone_watermark_ok(z, order, mark, highest_zoneidx, 0,
    0.00 :   ffff8000101dc60c:       ldr     w2, [sp, #184]
    0.00 :   ffff8000101dc610:       mov     w20, w26
    0.00 :   ffff8000101dc614:       mov     x27, x24
    0.00 :   ffff8000101dc618:       mov     w3, w20
    0.00 :   ffff8000101dc61c:       mov     w1, w22
    0.00 :   ffff8000101dc620:       mov     x0, x24
    0.00 :   ffff8000101dc624:       bl      ffff8000101d9288 <prep_new_page>
         : 4000             {
    0.00 :   ffff8000101dc628:       cbnz    w22, ffff8000101dc7c4 <get_page_from_freelist+0xe6c>
         : 4025             unsigned int alloc_flags;
         :
         : 4027             /*
         : 4028             * __GFP_KSWAPD_RECLAIM is assumed to be the same as ALLOC_KSWAPD
    0.00 :   ffff8000101dc62c:       ldr     x1, [sp, #232]
    0.00 :   ffff8000101dc630:       mov     x0, x27
    0.00 :   ffff8000101dc634:       ldr     x2, [sp, #248]
    0.00 :   ffff8000101dc638:       ldr     x1, [x1]
    0.00 :   ffff8000101dc63c:       eor     x1, x2, x1
    0.00 :   ffff8000101dc640:       cbnz    x1, ffff8000101dc884 <get_page_from_freelist+0xf2c>
    0.00 :   ffff8000101dc644:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101dc648:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101dc64c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000101dc650:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000101dc654:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000101dc658:       ldp     x29, x30, [sp], #256
    0.00 :   ffff8000101dc65c:       autiasp
    0.00 :   ffff8000101dc660:       ret
         : 4043             arch_static_branch():
    0.00 :   ffff8000101dc664:       nop
    0.00 :   ffff8000101dc668:       mov     x0, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101dc66c:       msr     daifset, #0x3
    0.00 :   ffff8000101dc670:       b       ffff8000101dbb0c <get_page_from_freelist+0x1b4>
         : 57               __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff8000101dc674:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000101dc678:       b       ffff8000101dfd54 <take_page_off_buddy+0x504>
    0.00 :   ffff8000101dc67c:       b       ffff8000101dc30c <get_page_from_freelist+0x9b4>
         : 238              zone_statistics():
         : 3453             free_unref_page_commit(page, pfn, migratetype, order);
    0.00 :   ffff8000101dc680:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101dc684:       mov     x0, x25
    0.00 :   ffff8000101dc688:       bl      ffff8000101a66b0 <__inc_numa_state>
    0.00 :   ffff8000101dc68c:       b       ffff8000101dc2d8 <get_page_from_freelist+0x980>
         : 3458             __rmqueue_fallback():
         : 2854             struct page *page;
    0.00 :   ffff8000101dc690:       sub     w15, w15, #0x1
         : 2853             struct zone *zone;
    0.00 :   ffff8000101dc694:       cmp     w15, w14
    0.00 :   ffff8000101dc698:       b.ge    ffff8000101dc46c <get_page_from_freelist+0xb14>  // b.tcont
    0.00 :   ffff8000101dc69c:       nop
         : 2857             spin_unlock():
    0.00 :   ffff8000101dc6a0:       ldr     x0, [sp, #168]
    0.00 :   ffff8000101dc6a4:       mov     w22, w21
    0.00 :   ffff8000101dc6a8:       mov     x21, x26
    0.00 :   ffff8000101dc6ac:       mov     w26, w24
    0.00 :   ffff8000101dc6b0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 399              arch_local_irq_restore():
         : 122              asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101dc6b4:       ldr     x0, [sp, #176]
    0.00 :   ffff8000101dc6b8:       msr     daif, x0
         : 125              arch_static_branch():
    0.00 :   ffff8000101dc6bc:       nop
         : 22               get_page_from_freelist():
         :
    0.00 :   ffff8000101dc6c0:       b       ffff8000101dbc18 <get_page_from_freelist+0x2c0>
         : 3995             __zone_watermark_unusable_free():
         : 3661             page = list_first_entry(list, struct page, lru);
    0.00 :   ffff8000101dc6c4:       mov     x0, #0x0                        // #0
    0.00 :   ffff8000101dc6c8:       b       ffff8000101dba90 <get_page_from_freelist+0x138>
         : 3664             get_page_from_freelist():
         : 3991             if (z->percpu_drift_mark && free_pages < z->percpu_drift_mark)
    0.00 :   ffff8000101dc6cc:       ldr     x0, [x21, #16]
    0.00 :   ffff8000101dc6d0:       ldr     w19, [x21, #24]
    0.00 :   ffff8000101dc6d4:       ldr     x0, [x0]
    0.00 :   ffff8000101dc6d8:       str     x0, [sp, #128]
    0.00 :   ffff8000101dc6dc:       b       ffff8000101dbd4c <get_page_from_freelist+0x3f4>
         : 3997             __rmqueue_smallest():
         : 2388             #else
    0.00 :   ffff8000101dc6e0:       add     w2, w2, #0x1
    0.00 :   ffff8000101dc6e4:       add     x4, x4, #0x68
    0.00 :   ffff8000101dc6e8:       cmp     w2, #0xb
    0.00 :   ffff8000101dc6ec:       b.ne    ffff8000101dc108 <get_page_from_freelist+0x7b0>  // b.any
         : 2393             __rmqueue_fallback():
         : 2845             * pageblock is exhausted.
    0.00 :   ffff8000101dc6f0:       ldr     w0, [sp, #136]
    0.00 :   ffff8000101dc6f4:       cmp     w0, #0x0
    0.00 :   ffff8000101dc6f8:       csel    w14, w21, w20, eq  // eq = none
    0.00 :   ffff8000101dc6fc:       b       ffff8000101dc460 <get_page_from_freelist+0xb08>
         : 2850             arch_static_branch():
    0.00 :   ffff8000101dc700:       mov     x0, #0xa0                       // #160
    0.00 :   ffff8000101dc704:       b       ffff8000101dc66c <get_page_from_freelist+0xd14>
         : 23               zone_watermark_fast():
         : 3787             static int __init setup_fail_page_alloc(char *str)
    0.00 :   ffff8000101dc708:       ldr     x0, [sp, #184]
    0.00 :   ffff8000101dc70c:       tbnz    w0, #9, ffff8000101dc768 <get_page_from_freelist+0xe10>
         : 3790             get_page_from_freelist():
         : 3965             }
    0.00 :   ffff8000101dc710:       tbnz    w26, #2, ffff8000101dbae4 <get_page_from_freelist+0x18c>
    0.00 :   ffff8000101dc714:       b       ffff8000101dbcb8 <get_page_from_freelist+0x360>
         : 3968             zone_statistics():
         : 3453             free_unref_page_commit(page, pfn, migratetype, order);
    0.00 :   ffff8000101dc718:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101dc71c:       mov     x0, x25
    0.00 :   ffff8000101dc720:       bl      ffff8000101a66b0 <__inc_numa_state>
    0.00 :   ffff8000101dc724:       ldr     x5, [sp, #104]
    0.00 :   ffff8000101dc728:       b       ffff8000101dbbf0 <get_page_from_freelist+0x298>
    0.00 :   ffff8000101dc72c:       ldrb    w4, [sp, #247]
         : 3460             __rmqueue_fallback():
         : 2879             * in this loop although we changed the pageblock type
    0.00 :   ffff8000101dc730:       mov     x5, #0xfffffffffffffff0         // #-16
    0.00 :   ffff8000101dc734:       mov     x0, #0xffffffffffffffff         // #-1
    0.00 :   ffff8000101dc738:       b       ffff8000101dc510 <get_page_from_freelist+0xbb8>
         : 2883             test_bit():
    0.00 :   ffff8000101dc73c:       ldur    x0, [x11, #-8]
         : 107              page_reported():
    0.00 :   ffff8000101dc740:       tbz     w0, #2, ffff8000101dc134 <get_page_from_freelist+0x7dc>
         : 22               __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff8000101dc744:       ldur    x0, [x11, #-8]
    0.00 :   ffff8000101dc748:       and     x0, x0, #0xfffffffffffffffb
    0.00 :   ffff8000101dc74c:       stur    x0, [x11, #-8]
    0.00 :   ffff8000101dc750:       b       ffff8000101dc134 <get_page_from_freelist+0x7dc>
         : 34               __mod_zone_freepage_state():
         : 410              static inline void refresh_zone_stat_thresholds(void) { }
    0.00 :   ffff8000101dc754:       mov     x2, x19
    0.00 :   ffff8000101dc758:       mov     w1, #0x9                        // #9
    0.00 :   ffff8000101dc75c:       mov     x0, x25
    0.00 :   ffff8000101dc760:       bl      ffff8000101a4ca0 <__mod_zone_page_state>
    0.00 :   ffff8000101dc764:       b       ffff8000101dc25c <get_page_from_freelist+0x904>
         : 416              zone_watermark_fast():
         : 3787             static int __init setup_fail_page_alloc(char *str)
    0.00 :   ffff8000101dc768:       ldr     x0, [x25, #24]
    0.00 :   ffff8000101dc76c:       cbz     x0, ffff8000101dc710 <get_page_from_freelist+0xdb8>
    0.00 :   ffff8000101dc770:       cbnz    w15, ffff8000101dc710 <get_page_from_freelist+0xdb8>
         : 3790             }
    0.00 :   ffff8000101dc774:       ldr     x2, [x25]
    0.00 :   ffff8000101dc778:       mov     x5, x13
    0.00 :   ffff8000101dc77c:       mov     w3, w14
    0.00 :   ffff8000101dc780:       mov     w4, w26
    0.00 :   ffff8000101dc784:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101dc788:       mov     x0, x25
    0.00 :   ffff8000101dc78c:       bl      ffff8000101db5c0 <__zone_watermark_ok>
         : 3798             get_page_from_freelist():
         : 3948             unsigned int alloc_flags, gfp_t gfp_mask)
    0.00 :   ffff8000101dc790:       tst     w0, #0xff
    0.00 :   ffff8000101dc794:       b.ne    ffff8000101dbae4 <get_page_from_freelist+0x18c>  // b.any
         : 3965             }
    0.00 :   ffff8000101dc798:       tbnz    w26, #2, ffff8000101dbae4 <get_page_from_freelist+0x18c>
    0.00 :   ffff8000101dc79c:       b       ffff8000101dbcb8 <get_page_from_freelist+0x360>
         : 3968             arch_local_irq_restore():
         : 130              pmr_sync();
    0.00 :   ffff8000101dc7a0:       dsb     sy
         : 132              get_page_from_freelist():
         :
    0.00 :   ffff8000101dc7a4:       b       ffff8000101dbc18 <get_page_from_freelist+0x2c0>
    0.00 :   ffff8000101dc7a8:       mov     w25, w22
         : 3942             return __zone_watermark_ok(z, order, mark, highest_zoneidx, alloc_flags,
    0.00 :   ffff8000101dc7ac:       and     w26, w26, #0xfffffeff
         : 3932             #endif
    0.00 :   ffff8000101dc7b0:       mov     x28, x0
    0.00 :   ffff8000101dc7b4:       mov     x27, x1
         : 3943             zone_page_state(z, NR_FREE_PAGES));
    0.00 :   ffff8000101dc7b8:       b       ffff8000101db9e8 <get_page_from_freelist+0x90>
         : 4024             /*
    0.00 :   ffff8000101dc7bc:       mov     x27, #0x0                       // #0
    0.00 :   ffff8000101dc7c0:       b       ffff8000101dc62c <get_page_from_freelist+0xcd4>
         : 4000             {
    0.00 :   ffff8000101dc7c4:       tbz     w20, #4, ffff8000101dc62c <get_page_from_freelist+0xcd4>
         : 4002             atomic64_read():
         : 838              }
    0.00 :   ffff8000101dc7c8:       ldr     x19, [x25, #112]
         : 840              reserve_highatomic_pageblock():
         : 2715             if (boost_watermark(zone) && (alloc_flags & ALLOC_KSWAPD))
    0.00 :   ffff8000101dc7cc:       mov     x1, #0xf5c3                     // #62915
    0.00 :   ffff8000101dc7d0:       movk    x1, #0x5c28, lsl #16
    0.00 :   ffff8000101dc7d4:       movk    x1, #0xc28f, lsl #32
    0.00 :   ffff8000101dc7d8:       lsr     x19, x19, #2
    0.00 :   ffff8000101dc7dc:       movk    x1, #0x28f5, lsl #48
         : 2716             set_bit(ZONE_BOOSTED_WATERMARK, &zone->flags);
    0.00 :   ffff8000101dc7e0:       ldr     x0, [x25, #32]
         : 2715             if (boost_watermark(zone) && (alloc_flags & ALLOC_KSWAPD))
    0.00 :   ffff8000101dc7e4:       umulh   x19, x19, x1
    0.00 :   ffff8000101dc7e8:       lsr     x19, x19, #2
    0.00 :   ffff8000101dc7ec:       add     x19, x19, #0x200
         : 2716             set_bit(ZONE_BOOSTED_WATERMARK, &zone->flags);
    0.00 :   ffff8000101dc7f0:       cmp     x19, x0
    0.00 :   ffff8000101dc7f4:       b.ls    ffff8000101dc62c <get_page_from_freelist+0xcd4>  // b.plast
         : 2719             spinlock_check():
         : 329              return &lock->rlock;
    0.00 :   ffff8000101dc7f8:       add     x20, x25, #0x540
         : 331              reserve_highatomic_pageblock():
         : 2719             if (!whole_block)
    0.00 :   ffff8000101dc7fc:       mov     x0, x20
    0.00 :   ffff8000101dc800:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 2722             free_pages = move_freepages_block(zone, page, start_type,
    0.00 :   ffff8000101dc804:       ldr     x7, [x25, #32]
         : 2719             if (!whole_block)
    0.00 :   ffff8000101dc808:       mov     x21, x0
         : 2722             free_pages = move_freepages_block(zone, page, start_type,
    0.00 :   ffff8000101dc80c:       cmp     x19, x7
    0.00 :   ffff8000101dc810:       b.ls    ffff8000101dc874 <get_page_from_freelist+0xf1c>  // b.plast
         : 2726             * For movable allocation, it's the number of movable pages which
    0.00 :   ffff8000101dc814:       adrp    x1, ffff800011571000 <rt_sched_class+0x10>
    0.00 :   ffff8000101dc818:       mov     x3, #0xfffffc0000000000         // #-4398046511104
    0.00 :   ffff8000101dc81c:       mov     x2, #0x7                        // #7
    0.00 :   ffff8000101dc820:       mov     x0, x24
    0.00 :   ffff8000101dc824:       ldr     x1, [x1, #3512]
    0.00 :   ffff8000101dc828:       asr     x1, x1, #12
    0.00 :   ffff8000101dc82c:       sub     x1, x3, x1, lsl #6
    0.00 :   ffff8000101dc830:       sub     x1, x24, x1
    0.00 :   ffff8000101dc834:       asr     x1, x1, #6
    0.00 :   ffff8000101dc838:       bl      ffff8000101d7ec8 <get_pfnblock_flags_mask>
         : 2728             */
    0.00 :   ffff8000101dc83c:       sub     w1, w0, #0x4
    0.00 :   ffff8000101dc840:       cmp     w1, #0x1
    0.00 :   ffff8000101dc844:       ccmp    w0, #0x3, #0x4, hi  // hi = pmore
    0.00 :   ffff8000101dc848:       b.eq    ffff8000101dc874 <get_page_from_freelist+0xf1c>  // b.none
         : 2729             if (start_type == MIGRATE_MOVABLE) {
    0.00 :   ffff8000101dc84c:       add     x7, x7, #0x200
    0.00 :   ffff8000101dc850:       str     x7, [x25, #32]
         : 2730             alike_pages = movable_pages;
    0.00 :   ffff8000101dc854:       mov     w1, #0x3                        // #3
    0.00 :   ffff8000101dc858:       mov     x0, x24
    0.00 :   ffff8000101dc85c:       bl      ffff8000101d9160 <set_pageblock_migratetype>
         : 2731             } else {
    0.00 :   ffff8000101dc860:       mov     x0, x25
    0.00 :   ffff8000101dc864:       mov     x3, #0x0                        // #0
    0.00 :   ffff8000101dc868:       mov     w2, #0x3                        // #3
    0.00 :   ffff8000101dc86c:       mov     x1, x24
    0.00 :   ffff8000101dc870:       bl      ffff8000101d9750 <move_freepages_block>
         : 2737             spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff8000101dc874:       mov     x1, x21
    0.00 :   ffff8000101dc878:       mov     x0, x20
    0.00 :   ffff8000101dc87c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
    0.00 :   ffff8000101dc880:       b       ffff8000101dc62c <get_page_from_freelist+0xcd4>
         : 419              get_page_from_freelist():
         : 4025             * __GFP_KSWAPD_RECLAIM is assumed to be the same as ALLOC_KSWAPD
    0.00 :   ffff8000101dc884:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (5 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102fba18 <__es_insert_extent>:
         : 6                __es_insert_extent():
         : 758              {
         : 759              }
         : 760              #endif
         :
         : 762              static int __es_insert_extent(struct inode *inode, struct extent_status *newes)
         : 763              {
    0.00 :   ffff8000102fba18:       paciasp
    0.00 :   ffff8000102fba1c:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff8000102fba20:       mov     x29, sp
    0.00 :   ffff8000102fba24:       stp     x23, x24, [sp, #48]
         : 760              struct ext4_es_tree *tree = &EXT4_I(inode)->i_es_tree;
         : 761              struct rb_node **p = &tree->root.rb_node;
    0.00 :   ffff8000102fba28:       add     x23, x0, #0x280
         : 761              struct rb_node *parent = NULL;
    0.00 :   ffff8000102fba2c:       mov     x24, #0x0                       // #0
         : 758              {
    0.00 :   ffff8000102fba30:       stp     x19, x20, [sp, #16]
         : 760              struct rb_node **p = &tree->root.rb_node;
    0.00 :   ffff8000102fba34:       mov     x20, x23
         : 758              {
    0.00 :   ffff8000102fba38:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000102fba3c:       mov     x21, x1
    0.00 :   ffff8000102fba40:       mov     x22, x0
         : 764              struct extent_status *es;
         :
         : 766              while (*p) {
    0.00 :   ffff8000102fba44:       ldr     x19, [x20]
    0.00 :   ffff8000102fba48:       ldr     w2, [x21, #24]
    0.00 :   ffff8000102fba4c:       cbz     x19, ffff8000102fbaa0 <__es_insert_extent+0x88>
         : 768              parent = *p;
         : 769              es = rb_entry(parent, struct extent_status, rb_node);
         :
         : 771              if (newes->es_lblk < es->es_lblk) {
    0.00 :   ffff8000102fba50:       ldr     w1, [x19, #24]
    0.00 :   ffff8000102fba54:       cmp     w1, w2
    0.00 :   ffff8000102fba58:       b.hi    ffff8000102fbb34 <__es_insert_extent+0x11c>  // b.pmore
         : 775              ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
   20.30 :   ffff8000102fba5c:       ldr     w0, [x19, #28]
    0.00 :   ffff8000102fba60:       add     w0, w1, w0
    0.00 :   ffff8000102fba64:       cmp     w1, w0
    0.00 :   ffff8000102fba68:       b.hi    ffff8000102fbb54 <__es_insert_extent+0x13c>  // b.pmore
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fba6c:       sub     w0, w0, #0x1
         : 205              __es_insert_extent():
         : 784              newes->es_pblk);
         : 785              es = ext4_es_try_to_merge_left(inode, es);
         : 786              goto out;
         : 787              }
         : 788              p = &(*p)->rb_left;
         : 789              } else if (newes->es_lblk > ext4_es_end(es)) {
    0.00 :   ffff8000102fba70:       cmp     w0, w2
    0.00 :   ffff8000102fba74:       b.cs    ffff8000102fbd28 <__es_insert_extent+0x310>  // b.hs, b.nlast
         : 785              if (ext4_es_can_be_merged(es, newes)) {
    0.00 :   ffff8000102fba78:       mov     x1, x21
    0.00 :   ffff8000102fba7c:       mov     x0, x19
    0.00 :   ffff8000102fba80:       bl      ffff8000102fb778 <ext4_es_can_be_merged>
    0.00 :   ffff8000102fba84:       cbnz    w0, ffff8000102fbb60 <__es_insert_extent+0x148>
         : 790              es->es_len += newes->es_len;
         : 791              es = ext4_es_try_to_merge_right(inode, es);
         : 792              goto out;
         : 793              }
         : 794              p = &(*p)->rb_right;
    0.00 :   ffff8000102fba88:       ldr     x20, [x20]
         : 758              {
    0.00 :   ffff8000102fba8c:       mov     x24, x19
         : 790              p = &(*p)->rb_right;
    0.00 :   ffff8000102fba90:       add     x20, x20, #0x8
         : 764              while (*p) {
   19.82 :   ffff8000102fba94:       ldr     x19, [x20]
    0.00 :   ffff8000102fba98:       ldr     w2, [x21, #24]
    0.00 :   ffff8000102fba9c:       cbnz    x19, ffff8000102fba50 <__es_insert_extent+0x38>
         : 768              ext4_es_alloc_extent():
         : 458              es = kmem_cache_alloc(ext4_es_cachep, GFP_ATOMIC);
    0.00 :   ffff8000102fbaa0:       adrp    x0, ffff800011f64000 <kernfs_pr_cont_buf+0xcd0>
    0.00 :   ffff8000102fbaa4:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000102fbaa8:       mov     w1, #0xa20                      // #2592
    0.00 :   ffff8000102fbaac:       ldr     x0, [x0, #912]
         : 463              __es_insert_extent():
         : 797              BUG();
         : 798              return -EINVAL;
         : 799              }
         : 800              }
         :
         : 802              es = ext4_es_alloc_extent(inode, newes->es_lblk, newes->es_len,
    0.00 :   ffff8000102fbab0:       ldp     x25, x21, [x21, #24]
         : 804              ext4_es_alloc_extent():
         : 458              es = kmem_cache_alloc(ext4_es_cachep, GFP_ATOMIC);
    0.00 :   ffff8000102fbab4:       bl      ffff800010208a10 <kmem_cache_alloc>
    0.00 :   ffff8000102fbab8:       mov     x19, x0
         : 459              if (es == NULL)
    0.00 :   ffff8000102fbabc:       cbz     x0, ffff8000102fbcb8 <__es_insert_extent+0x2a0>
         : 463              es->es_pblk = pblk;
    0.00 :   ffff8000102fbac0:       stp     x25, x21, [x0, #24]
         : 465              ext4_es_type():
         : 159              return es->es_pblk >> ES_SHIFT;
         : 160              }
         :
         : 162              static inline unsigned int ext4_es_type(struct extent_status *es)
         : 163              {
         : 164              return (es->es_pblk & ES_TYPE_MASK) >> ES_SHIFT;
    0.00 :   ffff8000102fbac4:       ldr     x3, [x22, #40]
         : 166              ext4_es_alloc_extent():
         : 468              if (!ext4_es_is_delayed(es)) {
    0.00 :   ffff8000102fbac8:       tbz     x21, #61, ffff8000102fbbd8 <__es_insert_extent+0x1c0>
    0.00 :   ffff8000102fbacc:       sub     x25, x22, #0x140
    0.00 :   ffff8000102fbad0:       add     x21, x22, #0x200
    0.00 :   ffff8000102fbad4:       adrp    x26, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
         : 475              EXT4_I(inode)->i_es_all_nr++;
    0.00 :   ffff8000102fbad8:       ldr     w0, [x25, #1000]
         : 477              percpu_counter_add():
         : 56               return __percpu_counter_compare(fbc, rhs, percpu_counter_batch);
         : 57               }
         :
         : 59               static inline void percpu_counter_add(struct percpu_counter *fbc, s64 amount)
         : 60               {
         : 61               percpu_counter_add_batch(fbc, amount, percpu_counter_batch);
    0.00 :   ffff8000102fbadc:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000102fbae0:       ldr     w2, [x26, #656]
         : 64               ext4_es_alloc_extent():
    0.00 :   ffff8000102fbae4:       add     w0, w0, #0x1
    0.00 :   ffff8000102fbae8:       str     w0, [x25, #1000]
         : 476              percpu_counter_inc(&EXT4_SB(inode->i_sb)->s_es_stats.es_stats_all_cnt);
    0.00 :   ffff8000102fbaec:       ldr     x0, [x3, #880]
         : 478              percpu_counter_add():
    0.00 :   ffff8000102fbaf0:       add     x0, x0, #0x540
    0.00 :   ffff8000102fbaf4:       bl      ffff800010495ba0 <percpu_counter_add_batch>
         : 58               rb_link_node():
         :
         : 74               static inline void rb_link_node(struct rb_node *node, struct rb_node *parent,
         : 75               struct rb_node **rb_link)
         : 76               {
         : 77               node->__rb_parent_color = (unsigned long)parent;
         : 78               node->rb_left = node->rb_right = NULL;
    0.00 :   ffff8000102fbaf8:       stp     x24, xzr, [x19]
         : 80               __es_insert_extent():
         : 802              newes->es_pblk);
         : 803              if (!es)
         : 804              return -ENOMEM;
         : 805              rb_link_node(&es->rb_node, parent, p);
         : 806              rb_insert_color(&es->rb_node, &tree->root);
    0.00 :   ffff8000102fbafc:       mov     x1, x23
    0.00 :   ffff8000102fbb00:       mov     x0, x19
         : 809              rb_link_node():
    0.00 :   ffff8000102fbb04:       str     xzr, [x19, #16]
         :
         : 76               *rb_link = node;
    0.00 :   ffff8000102fbb08:       str     x19, [x20]
         : 78               __es_insert_extent():
    0.00 :   ffff8000102fbb0c:       bl      ffff8000104b3240 <rb_insert_color>
    0.00 :   ffff8000102fbb10:       ldp     x25, x26, [sp, #64]
         :
         : 807              out:
         : 808              tree->cache_es = es;
         : 809              return 0;
    0.00 :   ffff8000102fbb14:       mov     w0, #0x0                        // #0
         : 805              tree->cache_es = es;
    0.00 :   ffff8000102fbb18:       str     x19, [x21, #136]
         : 807              }
    0.00 :   ffff8000102fbb1c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102fbb20:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102fbb24:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000102fbb28:       ldp     x29, x30, [sp], #96
    0.00 :   ffff8000102fbb2c:       autiasp
    0.00 :   ffff8000102fbb30:       ret
         : 769              if (ext4_es_can_be_merged(newes, es)) {
    0.00 :   ffff8000102fbb34:       mov     x1, x19
    0.00 :   ffff8000102fbb38:       mov     x0, x21
    0.00 :   ffff8000102fbb3c:       bl      ffff8000102fb778 <ext4_es_can_be_merged>
   19.52 :   ffff8000102fbb40:       cbnz    w0, ffff8000102fbc18 <__es_insert_extent+0x200>
         : 783              p = &(*p)->rb_left;
    0.00 :   ffff8000102fbb44:       ldr     x20, [x20]
         : 758              {
    0.00 :   ffff8000102fbb48:       mov     x24, x19
         : 783              p = &(*p)->rb_left;
    0.00 :   ffff8000102fbb4c:       add     x20, x20, #0x10
    0.00 :   ffff8000102fbb50:       b       ffff8000102fba94 <__es_insert_extent+0x7c>
    0.00 :   ffff8000102fbb54:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000102fbb58:       stp     x27, x28, [sp, #80]
         : 788              ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fbb5c:       brk     #0x800
         : 204              __es_insert_extent():
         : 786              es->es_len += newes->es_len;
    0.00 :   ffff8000102fbb60:       ldr     w2, [x21, #28]
         : 788              ext4_es_try_to_merge_right():
         : 568              node = rb_next(&es->rb_node);
    0.00 :   ffff8000102fbb64:       mov     x0, x19
         : 570              __es_insert_extent():
         : 786              es->es_len += newes->es_len;
   20.16 :   ffff8000102fbb68:       ldr     w1, [x19, #28]
    0.00 :   ffff8000102fbb6c:       add     x21, x22, #0x200
    0.00 :   ffff8000102fbb70:       add     w1, w1, w2
    0.00 :   ffff8000102fbb74:       str     w1, [x19, #28]
         : 791              ext4_es_try_to_merge_right():
         : 568              node = rb_next(&es->rb_node);
    0.00 :   ffff8000102fbb78:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000102fbb7c:       mov     x20, x0
         : 569              if (!node)
    0.00 :   ffff8000102fbb80:       cbz     x0, ffff8000102fbb14 <__es_insert_extent+0xfc>
         : 573              if (ext4_es_can_be_merged(es, es1)) {
    0.00 :   ffff8000102fbb84:       mov     x1, x0
    0.00 :   ffff8000102fbb88:       mov     x0, x19
    0.00 :   ffff8000102fbb8c:       bl      ffff8000102fb778 <ext4_es_can_be_merged>
   20.20 :   ffff8000102fbb90:       cbz     w0, ffff8000102fbb14 <__es_insert_extent+0xfc>
         : 574              es->es_len += es1->es_len;
    0.00 :   ffff8000102fbb94:       ldr     w0, [x19, #28]
    0.00 :   ffff8000102fbb98:       ldr     w1, [x20, #28]
    0.00 :   ffff8000102fbb9c:       add     w0, w0, w1
    0.00 :   ffff8000102fbba0:       str     w0, [x19, #28]
         : 579              ext4_es_status():
         : 154              return es->es_pblk >> ES_SHIFT;
    0.00 :   ffff8000102fbba4:       ldr     x0, [x20, #32]
         : 156              ext4_es_try_to_merge_right():
         : 575              if (ext4_es_is_referenced(es1))
    0.00 :   ffff8000102fbba8:       tbz     x0, #63, ffff8000102fbbb8 <__es_insert_extent+0x1a0>
         : 577              ext4_es_set_referenced():
         : 194              return (ext4_es_is_delayed(es) && !ext4_es_is_unwritten(es));
         : 195              }
         :
         : 197              static inline void ext4_es_set_referenced(struct extent_status *es)
         : 198              {
         : 199              es->es_pblk |= ((ext4_fsblk_t)EXTENT_STATUS_REFERENCED) << ES_SHIFT;
    0.00 :   ffff8000102fbbac:       ldr     x0, [x19, #32]
    0.00 :   ffff8000102fbbb0:       orr     x0, x0, #0x8000000000000000
    0.00 :   ffff8000102fbbb4:       str     x0, [x19, #32]
         : 203              ext4_es_try_to_merge_right():
         : 577              rb_erase(node, &tree->root);
    0.00 :   ffff8000102fbbb8:       mov     x1, x23
    0.00 :   ffff8000102fbbbc:       mov     x0, x20
    0.00 :   ffff8000102fbbc0:       bl      ffff8000104b33a8 <rb_erase>
         : 578              ext4_es_free_extent(inode, es1);
    0.00 :   ffff8000102fbbc4:       add     x21, x22, #0x200
    0.00 :   ffff8000102fbbc8:       mov     x1, x20
    0.00 :   ffff8000102fbbcc:       mov     x0, x22
    0.00 :   ffff8000102fbbd0:       bl      ffff8000102fb908 <ext4_es_free_extent>
    0.00 :   ffff8000102fbbd4:       b       ffff8000102fbb14 <__es_insert_extent+0xfc>
         : 584              ext4_es_alloc_extent():
         : 469              if (!EXT4_I(inode)->i_es_shk_nr++)
    0.00 :   ffff8000102fbbd8:       sub     x25, x22, #0x140
    0.00 :   ffff8000102fbbdc:       stp     x27, x28, [sp, #80]
         : 472              list_empty():
         : 282              * list_empty - tests whether a list is empty
         : 283              * @head: the list to test.
         : 284              */
         : 285              static inline int list_empty(const struct list_head *head)
         : 286              {
         : 287              return READ_ONCE(head->next) == head;
    0.00 :   ffff8000102fbbe0:       add     x21, x22, #0x200
         : 289              ext4_es_alloc_extent():
    0.00 :   ffff8000102fbbe4:       ldr     w0, [x25, #1004]
    0.00 :   ffff8000102fbbe8:       add     w1, w0, #0x1
    0.00 :   ffff8000102fbbec:       str     w1, [x25, #1004]
    0.00 :   ffff8000102fbbf0:       cbz     w0, ffff8000102fbcc4 <__es_insert_extent+0x2ac>
    0.00 :   ffff8000102fbbf4:       ldr     x27, [x3, #880]
         : 474              percpu_counter_add():
    0.00 :   ffff8000102fbbf8:       adrp    x26, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
    0.00 :   ffff8000102fbbfc:       add     x0, x27, #0x568
    0.00 :   ffff8000102fbc00:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000102fbc04:       ldr     w2, [x26, #656]
    0.00 :   ffff8000102fbc08:       bl      ffff800010495ba0 <percpu_counter_add_batch>
    0.00 :   ffff8000102fbc0c:       ldr     x3, [x22, #40]
    0.00 :   ffff8000102fbc10:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000102fbc14:       b       ffff8000102fbad8 <__es_insert_extent+0xc0>
         : 64               __es_insert_extent():
         : 774              es->es_lblk = newes->es_lblk;
    0.00 :   ffff8000102fbc18:       ldr     w0, [x21, #24]
    0.00 :   ffff8000102fbc1c:       str     w0, [x19, #24]
         : 775              es->es_len += newes->es_len;
    0.00 :   ffff8000102fbc20:       ldr     w0, [x19, #28]
    0.00 :   ffff8000102fbc24:       ldr     w2, [x21, #28]
         : 778              ext4_es_is_written():
         : 164              return (ext4_es_type(es) & EXTENT_STATUS_WRITTEN) != 0;
    0.00 :   ffff8000102fbc28:       ldr     x1, [x19, #32]
         : 166              __es_insert_extent():
    0.00 :   ffff8000102fbc2c:       add     w0, w0, w2
    0.00 :   ffff8000102fbc30:       str     w0, [x19, #28]
         : 776              if (ext4_es_is_written(es) ||
    0.00 :   ffff8000102fbc34:       tst     x1, #0x1800000000000000
    0.00 :   ffff8000102fbc38:       b.eq    ffff8000102fbc50 <__es_insert_extent+0x238>  // b.none
         : 779              ext4_es_store_pblock():
         : 223              static inline void ext4_es_store_pblock(struct extent_status *es,
         : 224              ext4_fsblk_t pb)
         : 225              {
         : 226              ext4_fsblk_t block;
         :
         : 228              block = (pb & ~ES_MASK) | (es->es_pblk & ES_MASK);
    0.00 :   ffff8000102fbc3c:       ldr     x0, [x21, #32]
    0.00 :   ffff8000102fbc40:       and     x1, x1, #0xf800000000000000
    0.00 :   ffff8000102fbc44:       and     x0, x0, #0x7ffffffffffffff
    0.00 :   ffff8000102fbc48:       orr     x0, x0, x1
         : 224              es->es_pblk = block;
    0.00 :   ffff8000102fbc4c:       str     x0, [x19, #32]
         : 226              ext4_es_try_to_merge_left():
         : 544              node = rb_prev(&es->rb_node);
    0.00 :   ffff8000102fbc50:       mov     x0, x19
    0.00 :   ffff8000102fbc54:       add     x21, x22, #0x200
    0.00 :   ffff8000102fbc58:       bl      ffff8000104b3dc0 <rb_prev>
    0.00 :   ffff8000102fbc5c:       mov     x20, x0
         : 545              if (!node)
    0.00 :   ffff8000102fbc60:       cbz     x0, ffff8000102fbb14 <__es_insert_extent+0xfc>
         : 549              if (ext4_es_can_be_merged(es1, es)) {
    0.00 :   ffff8000102fbc64:       mov     x1, x19
    0.00 :   ffff8000102fbc68:       bl      ffff8000102fb778 <ext4_es_can_be_merged>
    0.00 :   ffff8000102fbc6c:       cbz     w0, ffff8000102fbb14 <__es_insert_extent+0xfc>
         : 550              es1->es_len += es->es_len;
    0.00 :   ffff8000102fbc70:       ldr     w1, [x19, #28]
    0.00 :   ffff8000102fbc74:       ldr     w0, [x20, #28]
    0.00 :   ffff8000102fbc78:       add     w0, w0, w1
    0.00 :   ffff8000102fbc7c:       str     w0, [x20, #28]
         : 555              ext4_es_status():
         : 154              return es->es_pblk >> ES_SHIFT;
    0.00 :   ffff8000102fbc80:       ldr     x0, [x19, #32]
         : 156              ext4_es_try_to_merge_left():
         : 551              if (ext4_es_is_referenced(es))
    0.00 :   ffff8000102fbc84:       tbz     x0, #63, ffff8000102fbc94 <__es_insert_extent+0x27c>
         : 553              ext4_es_set_referenced():
         : 194              es->es_pblk |= ((ext4_fsblk_t)EXTENT_STATUS_REFERENCED) << ES_SHIFT;
    0.00 :   ffff8000102fbc88:       ldr     x0, [x20, #32]
    0.00 :   ffff8000102fbc8c:       orr     x0, x0, #0x8000000000000000
    0.00 :   ffff8000102fbc90:       str     x0, [x20, #32]
         : 198              ext4_es_try_to_merge_left():
         : 553              rb_erase(&es->rb_node, &tree->root);
    0.00 :   ffff8000102fbc94:       mov     x1, x23
    0.00 :   ffff8000102fbc98:       mov     x0, x19
    0.00 :   ffff8000102fbc9c:       bl      ffff8000104b33a8 <rb_erase>
         : 554              ext4_es_free_extent(inode, es);
    0.00 :   ffff8000102fbca0:       add     x21, x22, #0x200
    0.00 :   ffff8000102fbca4:       mov     x1, x19
    0.00 :   ffff8000102fbca8:       mov     x0, x22
    0.00 :   ffff8000102fbcac:       mov     x19, x20
    0.00 :   ffff8000102fbcb0:       bl      ffff8000102fb908 <ext4_es_free_extent>
         : 555              es = es1;
    0.00 :   ffff8000102fbcb4:       b       ffff8000102fbb14 <__es_insert_extent+0xfc>
         : 557              __es_insert_extent():
         : 800              return -ENOMEM;
    0.00 :   ffff8000102fbcb8:       mov     w0, #0xfffffff4                 // #-12
    0.00 :   ffff8000102fbcbc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000102fbcc0:       b       ffff8000102fbb1c <__es_insert_extent+0x104>
         : 804              list_empty():
    0.00 :   ffff8000102fbcc4:       ldr     x0, [x21, #152]
         : 283              ext4_es_list_add():
         : 428              if (!list_empty(&ei->i_es_list))
    0.00 :   ffff8000102fbcc8:       add     x26, x22, #0x298
         : 426              struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff8000102fbccc:       ldr     x27, [x3, #880]
         : 428              if (!list_empty(&ei->i_es_list))
    0.00 :   ffff8000102fbcd0:       cmp     x26, x0
    0.00 :   ffff8000102fbcd4:       b.ne    ffff8000102fbbf8 <__es_insert_extent+0x1e0>  // b.any
         : 431              spin_lock():
         : 354              # define spin_lock_init(_lock)                  \
         : 355              do {                                            \
         : 356              spinlock_check(_lock);                  \
         : 357              *(_lock) = __SPIN_LOCK_UNLOCKED(_lock); \
         : 358              } while (0)
         :
    0.00 :   ffff8000102fbcd8:       add     x28, x27, #0x5c0
    0.00 :   ffff8000102fbcdc:       mov     x0, x28
    0.00 :   ffff8000102fbce0:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 363              list_empty():
    0.00 :   ffff8000102fbce4:       ldr     x0, [x21, #152]
         : 283              ext4_es_list_add():
         : 432              if (list_empty(&ei->i_es_list)) {
    0.00 :   ffff8000102fbce8:       cmp     x26, x0
    0.00 :   ffff8000102fbcec:       b.eq    ffff8000102fbd04 <__es_insert_extent+0x2ec>  // b.none
         : 435              spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000102fbcf0:       mov     x0, x28
    0.00 :   ffff8000102fbcf4:       bl      ffff800010e349f0 <_raw_spin_unlock>
    0.00 :   ffff8000102fbcf8:       ldr     x0, [x22, #40]
    0.00 :   ffff8000102fbcfc:       ldr     x27, [x0, #880]
    0.00 :   ffff8000102fbd00:       b       ffff8000102fbbf8 <__es_insert_extent+0x1e0>
         : 405              list_add_tail():
         : 100              __list_add(new, head->prev, head);
    0.00 :   ffff8000102fbd04:       ldr     x0, [x27, #1224]
         : 102              __list_add():
         : 70               next->prev = new;
    0.00 :   ffff8000102fbd08:       str     x26, [x27, #1224]
         : 72               ext4_es_list_add():
         : 433              list_add_tail(&ei->i_es_list, &sbi->s_es_list);
    0.00 :   ffff8000102fbd0c:       add     x2, x27, #0x4c0
         : 435              __list_add():
         : 72               new->prev = prev;
    0.00 :   ffff8000102fbd10:       stp     x2, x0, [x21, #152]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000102fbd14:       str     x26, [x0]
         : 75               ext4_es_list_add():
         : 434              sbi->s_es_nr_inode++;
    0.00 :   ffff8000102fbd18:       ldr     x0, [x27, #1232]
    0.00 :   ffff8000102fbd1c:       add     x0, x0, #0x1
    0.00 :   ffff8000102fbd20:       str     x0, [x27, #1232]
    0.00 :   ffff8000102fbd24:       b       ffff8000102fbcf0 <__es_insert_extent+0x2d8>
    0.00 :   ffff8000102fbd28:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000102fbd2c:       stp     x27, x28, [sp, #80]
         : 441              __es_insert_extent():
         : 792              BUG();
    0.00 :   ffff8000102fbd30:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (9 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100fd6f8 <__rcu_read_lock>:
         : 6                get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
   20.42 :   ffff8000100fd6f8:       mrs     x1, sp_el0
         : 26               rcu_preempt_read_enter():
         : 418              */
         : 419              void __rcu_read_unlock(void)
         : 420              {
         : 421              struct task_struct *t = current;
         :
         : 423              barrier();  // critical section before exit code.
    0.00 :   ffff8000100fd6fc:       ldr     w0, [x1, #732]
         : 425              __rcu_read_lock():
         : 437              /*
         : 438              * Advance a ->blkd_tasks-list pointer to the next entry, instead
         : 439              * returning NULL if at the end of the list.
         : 440              */
         : 441              static struct list_head *rcu_next_node_entry(struct task_struct *t,
         : 442              struct rcu_node *rnp)
    0.00 :   ffff8000100fd700:       paciasp
         : 444              rcu_preempt_read_enter():
         : 418              barrier();  // critical section before exit code.
   79.10 :   ffff8000100fd704:       add     w0, w0, #0x1
    0.00 :   ffff8000100fd708:       str     w0, [x1, #732]
         : 421              __rcu_read_lock():
         : 444              struct list_head *np;
         :
         : 446              np = t->rcu_node_entry.next;
         : 447              if (np == &rnp->blkd_tasks)
         : 448              np = NULL;
         : 449              return np;
    0.00 :   ffff8000100fd70c:       autiasp
    0.47 :   ffff8000100fd710:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (5 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010310530 <ext4_mark_iloc_dirty>:
         : 6                ext4_mark_iloc_dirty():
         : 5708             * The caller must have previously called ext4_reserve_inode_write().
         : 5709             * Give this, we know that the caller already has write access to iloc->bh.
         : 5710             */
         : 5711             int ext4_mark_iloc_dirty(handle_t *handle,
         : 5712             struct inode *inode, struct ext4_iloc *iloc)
         : 5713             {
    0.00 :   ffff800010310530:       paciasp
    0.00 :   ffff800010310534:       stp     x29, x30, [sp, #-160]!
    0.00 :   ffff800010310538:       mov     x29, sp
    0.00 :   ffff80001031053c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010310540:       mov     x20, x2
    0.00 :   ffff800010310544:       stp     x21, x22, [sp, #32]
         : 5711             int err = 0;
         :
         : 5713             if (unlikely(ext4_forced_shutdown(EXT4_SB(inode->i_sb)))) {
    0.00 :   ffff800010310548:       ldr     x2, [x1, #40]
         : 5708             {
    0.00 :   ffff80001031054c:       str     x0, [sp, #96]
         : 5711             if (unlikely(ext4_forced_shutdown(EXT4_SB(inode->i_sb)))) {
    0.00 :   ffff800010310550:       ldr     x2, [x2, #880]
         : 5713             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010310554:       ldr     x19, [x2, #600]
    0.00 :   ffff800010310558:       ubfx    w19, w19, #1, #1
         : 114              ext4_mark_iloc_dirty():
    0.00 :   ffff80001031055c:       cbnz    w19, ffff800010310d58 <ext4_mark_iloc_dirty+0x828>
         : 5715             put_bh(iloc->bh);
         : 5716             return -EIO;
         : 5717             }
         : 5718             ext4_fc_track_inode(handle, inode);
   20.93 :   ffff800010310560:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010310564:       mov     x25, x1
    0.00 :   ffff800010310568:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001031056c:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010310570:       bl      ffff800010347940 <ext4_fc_track_inode>
         :
         : 5718             if (IS_I_VERSION(inode))
    0.00 :   ffff800010310574:       ldr     x0, [x25, #40]
    0.00 :   ffff800010310578:       ldr     x0, [x0, #80]
    0.00 :   ffff80001031057c:       tbnz    w0, #23, ffff800010310af8 <ext4_mark_iloc_dirty+0x5c8>
         : 5722             get_bh():
         : 279              * inline definitions
         : 280              */
         :
         : 282              static inline void get_bh(struct buffer_head *bh)
         : 283              {
         : 284              atomic_inc(&bh->b_count);
    0.00 :   ffff800010310580:       ldr     x0, [x20]
    0.00 :   ffff800010310584:       add     x2, x0, #0x60
         : 287              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010310588:       b       ffff8000103105a0 <ext4_mark_iloc_dirty+0x70>
    0.00 :   ffff80001031058c:       b       ffff8000103105a0 <ext4_mark_iloc_dirty+0x70>
         : 46               __lse_atomic_add():
         : 26               }
         :
         : 28               ATOMIC_OP(andnot, stclr)
         : 29               ATOMIC_OP(or, stset)
         : 30               ATOMIC_OP(xor, steor)
         : 31               ATOMIC_OP(add, stadd)
    0.00 :   ffff800010310590:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010310594:       add     x0, x0, #0x60
    0.00 :   ffff800010310598:       stadd   w1, [x0]
    0.00 :   ffff80001031059c:       b       ffff8000103105a8 <ext4_mark_iloc_dirty+0x78>
         : 36               __ll_sc_atomic_add():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff8000103105a0:       add     x0, x0, #0x60
    0.00 :   ffff8000103105a4:       b       ffff800010315b3c <ext4_filemap_fault+0x3ec>
         : 119              ext4_raw_inode():
         : 2433             #define fname_len(p)  ((p)->disk_name.len)
         :
         : 2435             /*
         : 2436             * Describe an inode's exact location on disk and in memory
         : 2437             */
         : 2438             struct ext4_iloc
    0.00 :   ffff8000103105a8:       ldp     x21, x23, [x20]
         : 2440             spin_lock():
         : 354              # define spin_lock_init(_lock)                  \
         : 355              do {                                            \
         : 356              spinlock_check(_lock);                  \
         : 357              *(_lock) = __SPIN_LOCK_UNLOCKED(_lock); \
         : 358              } while (0)
         :
    0.00 :   ffff8000103105ac:       add     x26, x25, #0x248
         : 361              ext4_do_update_inode():
         : 5026             struct super_block *sb = inode->i_sb;
    0.00 :   ffff8000103105b0:       ldr     x1, [x25, #40]
         : 5028             spin_lock():
    0.00 :   ffff8000103105b4:       mov     x0, x26
         : 355              ext4_do_update_inode():
    0.00 :   ffff8000103105b8:       str     x1, [sp, #104]
         : 5027             ext4_raw_inode():
    0.00 :   ffff8000103105bc:       ldr     x27, [x21, #40]
         : 2434             spin_lock():
    0.00 :   ffff8000103105c0:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 355              test_bit():
    0.00 :   ffff8000103105c4:       ldur    x0, [x25, #-240]
         : 107              ext4_raw_inode():
    0.00 :   ffff8000103105c8:       add     x22, x27, x23
         : 2434             ext4_do_update_inode():
         : 5037             if (ext4_test_inode_state(inode, EXT4_STATE_NEW))
    0.00 :   ffff8000103105cc:       tbnz    x0, #33, ffff800010310aa4 <ext4_mark_iloc_dirty+0x574>
         : 5039             ext4_inode_blocks_set():
         : 4918             u64 i_blocks = READ_ONCE(inode->i_blocks);
    0.00 :   ffff8000103105d0:       ldr     x1, [x25, #144]
         : 4921             if (i_blocks <= ~0U) {
    0.00 :   ffff8000103105d4:       mov     x0, #0xffffffff                 // #4294967295
    0.00 :   ffff8000103105d8:       cmp     x1, x0
    0.00 :   ffff8000103105dc:       b.ls    ffff800010310acc <ext4_mark_iloc_dirty+0x59c>  // b.plast
         : 4925             ext4_has_feature_huge_file():
         : 2036             EXT4_FEATURE_COMPAT_FUNCS(resize_inode,         RESIZE_INODE)
    0.00 :   ffff8000103105e0:       ldr     x0, [x25, #40]
    0.00 :   ffff8000103105e4:       ldr     x0, [x0, #880]
    0.00 :   ffff8000103105e8:       ldr     x0, [x0, #104]
    0.00 :   ffff8000103105ec:       ldr     w0, [x0, #100]
         : 2041             ext4_inode_blocks_set():
         : 4931             if (!ext4_has_feature_huge_file(sb))
    0.00 :   ffff8000103105f0:       tbz     w0, #3, ffff800010310964 <ext4_mark_iloc_dirty+0x434>
         : 4934             if (i_blocks <= 0xffffffffffffULL) {
    0.00 :   ffff8000103105f4:       sub     x24, x25, #0x140
    0.00 :   ffff8000103105f8:       mov     x0, #0xffffffffffff             // #281474976710655
    0.00 :   ffff8000103105fc:       add     x2, x24, #0x50
    0.00 :   ffff800010310600:       cmp     x1, x0
    0.00 :   ffff800010310604:       b.hi    ffff800010310934 <ext4_mark_iloc_dirty+0x404>  // b.pmore
         : 4940             raw_inode->i_blocks_high = cpu_to_le16(i_blocks >> 32);
    0.00 :   ffff800010310608:       lsr     x0, x1, #32
         : 4939             raw_inode->i_blocks_lo   = cpu_to_le32(i_blocks);
    0.00 :   ffff80001031060c:       str     w1, [x22, #28]
         : 4940             raw_inode->i_blocks_high = cpu_to_le16(i_blocks >> 32);
    0.00 :   ffff800010310610:       strh    w0, [x22, #116]
         : 4942             arch_atomic64_andnot():
         : 64               static __always_inline void arch_##op(long i, atomic64_t *v)            \
         : 65               {                                                                       \
         : 66               __lse_ll_sc_body(op, i, v);                                     \
         : 67               }
         :
         : 69               ATOMIC64_OP(atomic64_andnot)
    0.00 :   ffff800010310614:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff800010310618:       tst     w0, #0xff
         : 72               __lse_atomic64_andnot():
         : 176              "       " #asm_op "     %[i], %[v]\n"                                   \
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff80001031061c:       mov     x0, #0x40000                    // #262144
         : 183              arch_atomic64_andnot():
    0.00 :   ffff800010310620:       b.ne    ffff800010310b48 <ext4_mark_iloc_dirty+0x618>  // b.any
         : 65               __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff800010310624:       sub     x3, x25, #0xf0
    0.00 :   ffff800010310628:       b       ffff800010315b54 <ext4_filemap_fault+0x404>
         : 237              ext4_do_update_inode():
         : 5046             raw_inode->i_mode = cpu_to_le16(inode->i_mode);
    0.00 :   ffff80001031062c:       ldrh    w0, [x25]
    0.00 :   ffff800010310630:       strh    w0, [x27, x23]
         : 5047             i_uid = i_uid_read(inode);
    0.00 :   ffff800010310634:       ldr     x0, [x25, #40]
         : 5049             i_uid_read():
         : 1562             * instead deal with the raw numeric values that are stored
         : 1563             * in the filesystem.
         : 1564             */
         : 1565             static inline uid_t i_uid_read(const struct inode *inode)
         : 1566             {
         : 1567             return from_kuid(inode->i_sb->s_user_ns, inode->i_uid);
    0.00 :   ffff800010310638:       ldr     w1, [x25, #4]
    0.00 :   ffff80001031063c:       ldr     x0, [x0, #1144]
    0.00 :   ffff800010310640:       bl      ffff800010148718 <from_kuid>
    0.00 :   ffff800010310644:       mov     w2, w0
         : 1572             ext4_do_update_inode():
         : 5048             i_gid = i_gid_read(inode);
    0.00 :   ffff800010310648:       ldr     x0, [x25, #40]
         : 5050             i_uid_read():
    0.00 :   ffff80001031064c:       str     w2, [sp, #112]
         : 1563             i_gid_read():
         : 1567             }
         :
         : 1569             static inline gid_t i_gid_read(const struct inode *inode)
         : 1570             {
         : 1571             return from_kgid(inode->i_sb->s_user_ns, inode->i_gid);
    0.00 :   ffff800010310650:       ldr     w1, [x25, #8]
    0.00 :   ffff800010310654:       ldr     x0, [x0, #1144]
    0.00 :   ffff800010310658:       bl      ffff800010148768 <from_kgid>
    0.00 :   ffff80001031065c:       mov     w28, w0
         : 1576             ext4_do_update_inode():
         : 5049             i_projid = from_kprojid(&init_user_ns, ei->i_projid);
    0.00 :   ffff800010310660:       ldr     w1, [x24, #1148]
    0.00 :   ffff800010310664:       adrp    x0, ffff800011c3f000 <kern_table+0x10>
    0.00 :   ffff800010310668:       add     x0, x0, #0xf40
    0.00 :   ffff80001031066c:       bl      ffff8000101487b8 <from_kprojid>
         : 5050             if (!(test_opt(inode->i_sb, NO_UID32))) {
    0.00 :   ffff800010310670:       ldr     w2, [sp, #112]
    0.00 :   ffff800010310674:       ldr     x1, [x25, #40]
    0.00 :   ffff800010310678:       ldr     x1, [x1, #880]
    0.00 :   ffff80001031067c:       ldr     w1, [x1, #120]
   21.20 :   ffff800010310680:       tbnz    w1, #13, ffff80001031099c <ext4_mark_iloc_dirty+0x46c>
         : 5051             raw_inode->i_uid_low = cpu_to_le16(low_16_bits(i_uid));
    0.00 :   ffff800010310684:       strh    w2, [x22, #2]
         : 5052             raw_inode->i_gid_low = cpu_to_le16(low_16_bits(i_gid));
    0.00 :   ffff800010310688:       strh    w28, [x22, #24]
         : 5057             if (ei->i_dtime && list_empty(&ei->i_orphan)) {
    0.00 :   ffff80001031068c:       ldr     w1, [x24, #60]
    0.00 :   ffff800010310690:       cbnz    w1, ffff800010310b90 <ext4_mark_iloc_dirty+0x660>
         : 5062             cpu_to_le16(high_16_bits(i_uid));
    0.00 :   ffff800010310694:       lsr     w2, w2, #16
         : 5064             cpu_to_le16(high_16_bits(i_gid));
    0.00 :   ffff800010310698:       lsr     w28, w28, #16
         : 5062             cpu_to_le16(high_16_bits(i_uid));
    0.00 :   ffff80001031069c:       strh    w2, [x22, #120]
         : 5064             cpu_to_le16(high_16_bits(i_gid));
    0.00 :   ffff8000103106a0:       strh    w28, [x22, #122]
         : 5072             raw_inode->i_links_count = cpu_to_le16(inode->i_nlink);
    0.00 :   ffff8000103106a4:       ldr     w1, [x25, #72]
    0.00 :   ffff8000103106a8:       strh    w1, [x22, #26]
         : 5074             EXT4_INODE_SET_XTIME(i_ctime, inode, raw_inode);
    0.00 :   ffff8000103106ac:       ldrh    w1, [x24, #1032]
    0.00 :   ffff8000103106b0:       add     w1, w1, #0x80
    0.00 :   ffff8000103106b4:       cmp     w1, #0x87
    0.00 :   ffff8000103106b8:       ldr     x1, [x25, #120]
    0.00 :   ffff8000103106bc:       str     w1, [x22, #12]
    0.00 :   ffff8000103106c0:       b.le    ffff8000103106d8 <ext4_mark_iloc_dirty+0x1a8>
         : 5081             ext4_encode_extra_time():
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff8000103106c4:       ldp     x1, x2, [x25, #120]
         : 886              *
    0.00 :   ffff8000103106c8:       sub     x1, x1, w1, sxtw
    0.00 :   ffff8000103106cc:       ubfx    x1, x1, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff8000103106d0:       orr     w1, w1, w2, lsl #2
         : 889              ext4_do_update_inode():
   16.19 :   ffff8000103106d4:       str     w1, [x22, #132]
         : 5075             EXT4_INODE_SET_XTIME(i_mtime, inode, raw_inode);
    0.00 :   ffff8000103106d8:       ldrh    w1, [x24, #1032]
    0.00 :   ffff8000103106dc:       ldr     x2, [x25, #104]
    0.00 :   ffff8000103106e0:       str     w2, [x22, #16]
    0.00 :   ffff8000103106e4:       add     w1, w1, #0x80
    0.00 :   ffff8000103106e8:       cmp     w1, #0x8b
    0.00 :   ffff8000103106ec:       b.le    ffff800010310704 <ext4_mark_iloc_dirty+0x1d4>
         : 5082             ext4_encode_extra_time():
    0.00 :   ffff8000103106f0:       ldp     x1, x2, [x25, #104]
         : 886              *
    0.00 :   ffff8000103106f4:       sub     x1, x1, w1, sxtw
    0.00 :   ffff8000103106f8:       ubfx    x1, x1, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff8000103106fc:       orr     w1, w1, w2, lsl #2
         : 889              ext4_do_update_inode():
    0.00 :   ffff800010310700:       str     w1, [x22, #136]
         : 5076             EXT4_INODE_SET_XTIME(i_atime, inode, raw_inode);
    0.00 :   ffff800010310704:       ldrh    w1, [x24, #1032]
    0.00 :   ffff800010310708:       ldr     x2, [x25, #88]
    0.00 :   ffff80001031070c:       str     w2, [x22, #8]
    0.00 :   ffff800010310710:       add     w1, w1, #0x80
    0.00 :   ffff800010310714:       cmp     w1, #0x8f
    0.00 :   ffff800010310718:       b.le    ffff800010310730 <ext4_mark_iloc_dirty+0x200>
         : 5083             ext4_encode_extra_time():
    0.00 :   ffff80001031071c:       ldp     x1, x2, [x25, #88]
         : 886              *
    0.00 :   ffff800010310720:       sub     x1, x1, w1, sxtw
    0.00 :   ffff800010310724:       ubfx    x1, x1, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff800010310728:       orr     w1, w1, w2, lsl #2
         : 889              ext4_do_update_inode():
    0.00 :   ffff80001031072c:       str     w1, [x22, #140]
         : 5077             EXT4_EINODE_SET_XTIME(i_crtime, ei, raw_inode);
    0.00 :   ffff800010310730:       ldrh    w1, [x24, #1032]
    0.00 :   ffff800010310734:       add     w1, w1, #0x80
    0.00 :   ffff800010310738:       cmp     w1, #0x93
    0.00 :   ffff80001031073c:       b.le    ffff800010310770 <ext4_mark_iloc_dirty+0x240>
    0.00 :   ffff800010310740:       ldr     x1, [x24, #912]
    0.00 :   ffff800010310744:       str     w1, [x22, #144]
    0.00 :   ffff800010310748:       ldrh    w1, [x24, #1032]
    0.00 :   ffff80001031074c:       add     w1, w1, #0x80
    0.00 :   ffff800010310750:       cmp     w1, #0x97
    0.00 :   ffff800010310754:       b.le    ffff800010310770 <ext4_mark_iloc_dirty+0x240>
    0.00 :   ffff800010310758:       ldr     x1, [x25, #592]
         : 5089             ext4_encode_extra_time():
    0.00 :   ffff80001031075c:       ldr     x2, [x25, #600]
         : 886              *
    0.00 :   ffff800010310760:       sub     x1, x1, w1, sxtw
    0.00 :   ffff800010310764:       ubfx    x1, x1, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff800010310768:       orr     w1, w1, w2, lsl #2
         : 889              ext4_do_update_inode():
    0.00 :   ffff80001031076c:       str     w1, [x22, #148]
         : 5079             raw_inode->i_dtime = cpu_to_le32(ei->i_dtime);
    0.00 :   ffff800010310770:       ldr     w1, [x24, #60]
    0.00 :   ffff800010310774:       str     w1, [x22, #20]
         : 5080             raw_inode->i_flags = cpu_to_le32(ei->i_flags & 0xFFFFFFFF);
    0.00 :   ffff800010310778:       ldur    x1, [x25, #-240]
    0.00 :   ffff80001031077c:       str     w1, [x22, #32]
         : 5081             if (likely(!test_opt2(inode->i_sb, HURD_COMPAT)))
    0.00 :   ffff800010310780:       ldr     x1, [x25, #40]
    0.00 :   ffff800010310784:       ldr     x1, [x1, #880]
    0.00 :   ffff800010310788:       ldr     w1, [x1, #124]
    0.00 :   ffff80001031078c:       tbnz    w1, #2, ffff800010310798 <ext4_mark_iloc_dirty+0x268>
         : 5083             cpu_to_le16(ei->i_file_acl >> 32);
    0.00 :   ffff800010310790:       ldur    w1, [x25, #-252]
    0.00 :   ffff800010310794:       strh    w1, [x22, #118]
         : 5084             raw_inode->i_file_acl_lo = cpu_to_le32(ei->i_file_acl);
    0.00 :   ffff800010310798:       ldur    x1, [x25, #-256]
    0.00 :   ffff80001031079c:       str     w1, [x22, #104]
         : 5085             if (READ_ONCE(ei->i_disksize) != ext4_isize(inode->i_sb, raw_inode)) {
    0.00 :   ffff8000103107a0:       ldr     w1, [x22, #4]
         : 5087             ext4_has_feature_largedir():
         : 2059             EXT4_FEATURE_INCOMPAT_FUNCS(journal_dev,        JOURNAL_DEV)
    0.00 :   ffff8000103107a4:       ldr     x2, [x25, #40]
         : 2061             ext4_do_update_inode():
    0.00 :   ffff8000103107a8:       ldur    x3, [x25, #-88]
         : 5086             ext4_has_feature_largedir():
    0.00 :   ffff8000103107ac:       ldr     x2, [x2, #880]
    0.00 :   ffff8000103107b0:       ldr     x2, [x2, #104]
    0.00 :   ffff8000103107b4:       ldr     w2, [x2, #96]
         : 2062             ext4_isize():
         : 3265             es->s_free_blocks_count_lo = cpu_to_le32((u32)blk);
         : 3266             es->s_free_blocks_count_hi = cpu_to_le32(blk >> 32);
         : 3267             }
         :
         : 3269             static inline void ext4_r_blocks_count_set(struct ext4_super_block *es,
         : 3270             ext4_fsblk_t blk)
    0.00 :   ffff8000103107b8:       tbnz    w2, #14, ffff800010310b2c <ext4_mark_iloc_dirty+0x5fc>
    0.00 :   ffff8000103107bc:       ldrh    w2, [x27, x23]
    0.00 :   ffff8000103107c0:       and     w2, w2, #0xf000
    0.00 :   ffff8000103107c4:       cmp     w2, #0x8, lsl #12
    0.00 :   ffff8000103107c8:       b.eq    ffff800010310b2c <ext4_mark_iloc_dirty+0x5fc>  // b.none
         : 3276             ext4_do_update_inode():
         : 5028             int need_datasync = 0, set_large_file = 0;
    0.00 :   ffff8000103107cc:       str     wzr, [sp, #132]
         : 5085             if (READ_ONCE(ei->i_disksize) != ext4_isize(inode->i_sb, raw_inode)) {
    0.00 :   ffff8000103107d0:       cmp     x3, x1
    0.00 :   ffff8000103107d4:       ldur    x1, [x25, #-88]
    0.00 :   ffff8000103107d8:       b.eq    ffff8000103107f4 <ext4_mark_iloc_dirty+0x2c4>  // b.none
         : 5089             ext4_isize_set():
         : 3276             static inline loff_t ext4_isize(struct super_block *sb,
         : 3277             struct ext4_inode *raw_inode)
         : 3278             {
         : 3279             if (ext4_has_feature_largedir(sb) ||
         : 3280             S_ISREG(le16_to_cpu(raw_inode->i_mode)))
         : 3281             return ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |
    0.00 :   ffff8000103107dc:       asr     x2, x1, #32
         : 3275             S_ISREG(le16_to_cpu(raw_inode->i_mode)))
    0.00 :   ffff8000103107e0:       str     w1, [x22, #4]
         : 3276             return ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |
    0.00 :   ffff8000103107e4:       str     w2, [x22, #108]
         : 3278             ext4_do_update_inode():
         : 5087             need_datasync = 1;
    0.00 :   ffff8000103107e8:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000103107ec:       str     w1, [sp, #132]
    0.00 :   ffff8000103107f0:       ldur    x1, [x25, #-88]
         : 5089             if (ei->i_disksize > 0x7fffffffULL) {
    0.00 :   ffff8000103107f4:       mov     x2, #0x7fffffff                 // #2147483647
    0.00 :   ffff8000103107f8:       cmp     x1, x2
    0.00 :   ffff8000103107fc:       b.ls    ffff800010310818 <ext4_mark_iloc_dirty+0x2e8>  // b.plast
         : 5093             ext4_has_feature_large_file():
         : 2034             EXT4_FEATURE_COMPAT_FUNCS(journal,              HAS_JOURNAL)
    0.00 :   ffff800010310800:       ldr     x1, [sp, #104]
         : 2036             ext4_do_update_inode():
         : 5093             set_large_file = 1;
    0.00 :   ffff800010310804:       mov     w19, #0x1                       // #1
         : 5095             ext4_has_feature_large_file():
    0.00 :   ffff800010310808:       ldr     x1, [x1, #880]
    0.00 :   ffff80001031080c:       ldr     x1, [x1, #104]
    0.00 :   ffff800010310810:       ldr     w2, [x1, #100]
         : 2037             ext4_do_update_inode():
         : 5090             if (!ext4_has_feature_large_file(sb) ||
    0.00 :   ffff800010310814:       tbnz    w2, #1, ffff800010310ba8 <ext4_mark_iloc_dirty+0x678>
         : 5095             raw_inode->i_generation = cpu_to_le32(inode->i_generation);
    0.00 :   ffff800010310818:       ldr     w1, [x25, #552]
         : 5096             if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {
    0.00 :   ffff80001031081c:       mov     w2, #0xb000                     // #45056
         : 5095             raw_inode->i_generation = cpu_to_le32(inode->i_generation);
    0.00 :   ffff800010310820:       str     w1, [x22, #100]
         : 5096             if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {
    0.00 :   ffff800010310824:       ldrh    w1, [x25]
    0.00 :   ffff800010310828:       and     w1, w1, w2
    0.00 :   ffff80001031082c:       cmp     w1, #0x2, lsl #12
    0.00 :   ffff800010310830:       b.ne    ffff8000103109d4 <ext4_mark_iloc_dirty+0x4a4>  // b.any
         : 5097             if (old_valid_dev(inode->i_rdev)) {
    0.00 :   ffff800010310834:       ldr     w2, [x25, #76]
         : 5099             old_valid_dev():
         : 26               })
         :
         : 28               /* acceptable for old filesystems */
         : 29               static __always_inline bool old_valid_dev(dev_t dev)
         : 30               {
         : 31               return MAJOR(dev) < 256 && MINOR(dev) < 256;
    0.00 :   ffff800010310838:       lsr     w1, w2, #20
    0.00 :   ffff80001031083c:       cmp     w1, #0xff
    0.00 :   ffff800010310840:       b.hi    ffff800010310b68 <ext4_mark_iloc_dirty+0x638>  // b.pmore
    0.00 :   ffff800010310844:       tst     w2, #0xfff00
    0.00 :   ffff800010310848:       b.ne    ffff800010310b68 <ext4_mark_iloc_dirty+0x638>  // b.any
         : 37               old_encode_dev():
         : 31               }
         :
         : 33               static __always_inline u16 old_encode_dev(dev_t dev)
         : 34               {
         : 35               return (MAJOR(dev) << 8) | MINOR(dev);
    0.00 :   ffff80001031084c:       orr     w1, w2, w1, lsl #8
         : 37               ext4_do_update_inode():
         : 5099             cpu_to_le32(old_encode_dev(inode->i_rdev));
    0.00 :   ffff800010310850:       and     w1, w1, #0xffff
         : 5100             raw_inode->i_block[1] = 0;
    0.00 :   ffff800010310854:       stp     w1, wzr, [x22, #40]
         : 5112             if (likely(!test_opt2(inode->i_sb, HURD_COMPAT))) {
    0.00 :   ffff800010310858:       ldr     x1, [x25, #40]
    0.00 :   ffff80001031085c:       ldr     x1, [x1, #880]
    0.00 :   ffff800010310860:       ldr     w2, [x1, #124]
    0.00 :   ffff800010310864:       tbnz    w2, #2, ffff80001031089c <ext4_mark_iloc_dirty+0x36c>
         : 5117             ext4_inode_peek_iversion():
         : 4593             if (unlikely(EXT4_I(inode)->i_flags & EXT4_EA_INODE_FL))
    0.00 :   ffff800010310868:       ldur    x1, [x25, #-240]
    0.00 :   ffff80001031086c:       tbnz    w1, #21, ffff800010310e4c <ext4_mark_iloc_dirty+0x91c>
         : 4596             atomic64_read():
         : 838              static __always_inline s64
         : 839              atomic64_dec_return_acquire(atomic64_t *v)
         : 840              {
         : 841              instrument_atomic_read_write(v, sizeof(*v));
         : 842              return arch_atomic64_dec_return_acquire(v);
         : 843              }
    0.00 :   ffff800010310870:       ldr     x1, [x25, #328]
         : 845              inode_peek_iversion():
         : 288              * viewed, as the result won't be used to gauge changes from that point.
         : 289              */
         : 290              static inline u64
         : 291              inode_peek_iversion(const struct inode *inode)
         : 292              {
         : 293              return inode_peek_iversion_raw(inode) >> I_VERSION_QUERIED_SHIFT;
    0.00 :   ffff800010310874:       lsr     x1, x1, #1
         : 295              ext4_do_update_inode():
         : 5115             raw_inode->i_disk_version = cpu_to_le32(ivers);
    0.00 :   ffff800010310878:       str     w1, [x22, #36]
         : 5116             if (ei->i_extra_isize) {
    0.00 :   ffff80001031087c:       ldrh    w2, [x24, #1032]
    0.00 :   ffff800010310880:       cbz     w2, ffff800010310894 <ext4_mark_iloc_dirty+0x364>
         : 5117             if (EXT4_FITS_IN_INODE(raw_inode, ei, i_version_hi))
    0.00 :   ffff800010310884:       add     w3, w2, #0x80
    0.00 :   ffff800010310888:       cmp     w3, #0x9b
    0.00 :   ffff80001031088c:       b.gt    ffff800010310c5c <ext4_mark_iloc_dirty+0x72c>
         : 5120             raw_inode->i_extra_isize =
    0.00 :   ffff800010310890:       strh    w2, [x22, #128]
    0.00 :   ffff800010310894:       ldr     x1, [x25, #40]
    0.00 :   ffff800010310898:       ldr     x1, [x1, #880]
         : 5124             ext4_has_feature_project():
         : 2044             EXT4_FEATURE_RO_COMPAT_FUNCS(btree_dir,         BTREE_DIR)
    0.00 :   ffff80001031089c:       ldr     x2, [x1, #104]
    0.00 :   ffff8000103108a0:       ldr     w2, [x2, #100]
         : 2047             ext4_do_update_inode():
         : 5125             BUG_ON(!ext4_has_feature_project(inode->i_sb) &&
    0.00 :   ffff8000103108a4:       tst     x2, #0x2000
    0.00 :   ffff8000103108a8:       ccmp    w0, #0x0, #0x4, eq  // eq = none
    0.00 :   ffff8000103108ac:       b.ne    ffff800010310f10 <ext4_mark_iloc_dirty+0x9e0>  // b.any
         : 5128             if (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE &&
   21.29 :   ffff8000103108b0:       ldr     w1, [x1, #180]
    0.00 :   ffff8000103108b4:       cmp     w1, #0x80
    0.00 :   ffff8000103108b8:       b.le    ffff8000103108cc <ext4_mark_iloc_dirty+0x39c>
         : 5129             EXT4_FITS_IN_INODE(raw_inode, ei, i_projid))
    0.00 :   ffff8000103108bc:       ldrh    w1, [x24, #1032]
    0.00 :   ffff8000103108c0:       add     w1, w1, #0x80
         : 5128             if (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE &&
    0.00 :   ffff8000103108c4:       cmp     w1, #0x9f
    0.00 :   ffff8000103108c8:       b.gt    ffff800010310bc4 <ext4_mark_iloc_dirty+0x694>
         : 5132             ext4_inode_csum_set(inode, raw_inode, ei);
    0.00 :   ffff8000103108cc:       mov     x1, x22
    0.00 :   ffff8000103108d0:       mov     x2, x24
    0.00 :   ffff8000103108d4:       mov     x0, x25
    0.00 :   ffff8000103108d8:       bl      ffff80001030d690 <ext4_inode_csum_set>
         : 5137             spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000103108dc:       mov     x0, x26
    0.00 :   ffff8000103108e0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 402              ext4_do_update_inode():
         : 5134             if (inode->i_sb->s_flags & SB_LAZYTIME)
    0.00 :   ffff8000103108e4:       ldr     x23, [x25, #40]
    0.00 :   ffff8000103108e8:       ldr     x0, [x23, #80]
    0.00 :   ffff8000103108ec:       tbnz    w0, #25, ffff800010310c6c <ext4_mark_iloc_dirty+0x73c>
         : 5139             err = ext4_handle_dirty_metadata(handle, NULL, bh);
    0.00 :   ffff8000103108f0:       ldr     x2, [sp, #96]
    0.00 :   ffff8000103108f4:       adrp    x23, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff8000103108f8:       add     x23, x23, #0x30
    0.00 :   ffff8000103108fc:       mov     x4, x21
    0.00 :   ffff800010310900:       add     x0, x23, #0x388
    0.00 :   ffff800010310904:       mov     x3, #0x0                        // #0
    0.00 :   ffff800010310908:       mov     w1, #0x1413                     // #5139
    0.00 :   ffff80001031090c:       bl      ffff8000102f2638 <__ext4_handle_dirty_metadata>
    0.00 :   ffff800010310910:       mov     w22, w0
         : 5140             if (err)
    0.00 :   ffff800010310914:       cbnz    w0, ffff800010310a20 <ext4_mark_iloc_dirty+0x4f0>
         : 5142             ext4_clear_inode_state():
         : 1864             static inline void ext4_clear_inode_state(struct inode *inode, int bit);
    0.00 :   ffff800010310918:       add     x1, x24, #0x50
         : 1866             arch_static_branch_jump():
    0.00 :   ffff80001031091c:       b       ffff800010310bcc <ext4_mark_iloc_dirty+0x69c>
    0.00 :   ffff800010310920:       b       ffff800010310bcc <ext4_mark_iloc_dirty+0x69c>
         : 40               __lse_atomic64_andnot():
    0.00 :   ffff800010310924:       mov     x0, #0x200000000                // #8589934592
    0.00 :   ffff800010310928:       sub     x2, x25, #0xf0
    0.00 :   ffff80001031092c:       stclr   x0, [x2]
    0.00 :   ffff800010310930:       b       ffff800010310bd8 <ext4_mark_iloc_dirty+0x6a8>
         : 180              arch_atomic64_or():
         : 65               ATOMIC64_OP(atomic64_or)
    0.00 :   ffff800010310934:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff800010310938:       tst     w0, #0xff
    0.00 :   ffff80001031093c:       b.ne    ffff800010310b38 <ext4_mark_iloc_dirty+0x608>  // b.any
         : 69               __ll_sc_atomic64_or():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010310940:       sub     x3, x25, #0xf0
    0.00 :   ffff800010310944:       b       ffff800010315b6c <ext4_filemap_fault+0x41c>
         : 225              ext4_inode_blocks_set():
         : 4945             i_blocks = i_blocks >> (inode->i_blkbits - 9);
    0.00 :   ffff800010310948:       ldrb    w0, [x25, #142]
    0.00 :   ffff80001031094c:       sub     w0, w0, #0x9
    0.00 :   ffff800010310950:       lsr     x1, x1, x0
         : 4946             raw_inode->i_blocks_lo   = cpu_to_le32(i_blocks);
    0.00 :   ffff800010310954:       str     w1, [x22, #28]
         : 4947             raw_inode->i_blocks_high = cpu_to_le16(i_blocks >> 32);
    0.00 :   ffff800010310958:       lsr     x1, x1, #32
    0.00 :   ffff80001031095c:       strh    w1, [x22, #116]
         : 4950             ext4_do_update_inode():
         : 5041             if (err) {
    0.00 :   ffff800010310960:       b       ffff80001031062c <ext4_mark_iloc_dirty+0xfc>
         : 5043             spin_unlock():
    0.00 :   ffff800010310964:       mov     x0, x26
    0.00 :   ffff800010310968:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 396              brelse():
         : 290              atomic_dec(&bh->b_count);
         : 291              }
         :
         : 293              static inline void brelse(struct buffer_head *bh)
         : 294              {
         : 295              if (bh)
    0.00 :   ffff80001031096c:       cbz     x21, ffff800010310c38 <ext4_mark_iloc_dirty+0x708>
         : 291              __brelse(bh);
    0.00 :   ffff800010310970:       adrp    x23, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff800010310974:       add     x23, x23, #0x30
         : 294              ext4_inode_blocks_set():
         : 4932             return -EFBIG;
    0.00 :   ffff800010310978:       mov     w22, #0xffffffe5                // #-27
         : 4934             brelse():
    0.00 :   ffff80001031097c:       mov     x0, x21
    0.00 :   ffff800010310980:       bl      ffff80001027a690 <__brelse>
         : 293              ext4_do_update_inode():
         : 5159             ext4_std_error(inode->i_sb, err);
    0.00 :   ffff800010310984:       ldr     x0, [x25, #40]
    0.00 :   ffff800010310988:       add     x1, x23, #0x388
    0.00 :   ffff80001031098c:       mov     w3, w22
    0.00 :   ffff800010310990:       mov     w2, #0x1427                     // #5159
    0.00 :   ffff800010310994:       bl      ffff800010337a98 <__ext4_std_error>
    0.00 :   ffff800010310998:       b       ffff800010310a30 <ext4_mark_iloc_dirty+0x500>
         : 5067             raw_inode->i_uid_low = cpu_to_le16(fs_high2lowuid(i_uid));
    0.00 :   ffff80001031099c:       tst     w2, #0xffff0000
    0.00 :   ffff8000103109a0:       and     w2, w2, #0xffff
    0.00 :   ffff8000103109a4:       b.eq    ffff8000103109b0 <ext4_mark_iloc_dirty+0x480>  // b.none
    0.00 :   ffff8000103109a8:       adrp    x1, ffff800011c40000 <init_user_ns+0xc0>
    0.00 :   ffff8000103109ac:       ldrh    w2, [x1, #428]
    0.00 :   ffff8000103109b0:       strh    w2, [x22, #2]
         : 5068             raw_inode->i_gid_low = cpu_to_le16(fs_high2lowgid(i_gid));
    0.00 :   ffff8000103109b4:       tst     w28, #0xffff0000
    0.00 :   ffff8000103109b8:       and     w28, w28, #0xffff
    0.00 :   ffff8000103109bc:       b.eq    ffff8000103109c8 <ext4_mark_iloc_dirty+0x498>  // b.none
    0.00 :   ffff8000103109c0:       adrp    x1, ffff800011c40000 <init_user_ns+0xc0>
    0.00 :   ffff8000103109c4:       ldrh    w28, [x1, #424]
    0.00 :   ffff8000103109c8:       strh    w28, [x22, #24]
         : 5069             raw_inode->i_uid_high = 0;
    0.00 :   ffff8000103109cc:       str     wzr, [x22, #120]
    0.00 :   ffff8000103109d0:       b       ffff8000103106a4 <ext4_mark_iloc_dirty+0x174>
         : 5072             test_bit():
    0.00 :   ffff8000103109d4:       ldur    x1, [x25, #-240]
         : 107              ext4_has_inline_data():
         : 3566             int *retval);
         : 3567             extern int ext4_inline_data_fiemap(struct inode *inode,
         : 3568             struct fiemap_extent_info *fieinfo,
         : 3569             int *has_inline, __u64 start, __u64 len);
         :
         : 3571             struct iomap;
    0.00 :   ffff8000103109d8:       tst     w1, #0x10000000
    0.00 :   ffff8000103109dc:       b.ne    ffff800010310bb8 <ext4_mark_iloc_dirty+0x688>  // b.any
    0.00 :   ffff8000103109e0:       add     x3, x22, #0x28
    0.00 :   ffff8000103109e4:       mov     x1, #0x0                        // #0
         : 3576             ext4_do_update_inode():
         : 5109             raw_inode->i_block[block] = ei->i_data[block];
    0.00 :   ffff8000103109e8:       ldr     w2, [x24, x1]
    0.00 :   ffff8000103109ec:       str     w2, [x3, x1]
    0.00 :   ffff8000103109f0:       add     x1, x1, #0x4
         : 5108             for (block = 0; block < EXT4_N_BLOCKS; block++)
    0.00 :   ffff8000103109f4:       cmp     x1, #0x3c
    0.00 :   ffff8000103109f8:       b.ne    ffff8000103109e8 <ext4_mark_iloc_dirty+0x4b8>  // b.any
    0.00 :   ffff8000103109fc:       b       ffff800010310858 <ext4_mark_iloc_dirty+0x328>
         : 5145             err = ext4_journal_get_write_access(handle, EXT4_SB(sb)->s_sbh);
    0.00 :   ffff800010310a00:       ldp     x2, x19, [sp, #96]
    0.00 :   ffff800010310a04:       mov     w1, #0x1419                     // #5145
    0.00 :   ffff800010310a08:       add     x0, x23, #0x388
    0.00 :   ffff800010310a0c:       ldr     x3, [x19, #880]
    0.00 :   ffff800010310a10:       ldr     x3, [x3, #96]
    0.00 :   ffff800010310a14:       bl      ffff8000102f22f0 <__ext4_journal_get_write_access>
    0.00 :   ffff800010310a18:       mov     w22, w0
         : 5146             if (err)
    0.00 :   ffff800010310a1c:       cbz     w0, ffff800010310e54 <ext4_mark_iloc_dirty+0x924>
         : 5148             brelse():
         : 290              if (bh)
    0.00 :   ffff800010310a20:       cbz     x21, ffff800010310984 <ext4_mark_iloc_dirty+0x454>
         : 291              __brelse(bh);
    0.00 :   ffff800010310a24:       mov     x0, x21
    0.00 :   ffff800010310a28:       bl      ffff80001027a690 <__brelse>
         : 294              ext4_do_update_inode():
         : 5159             ext4_std_error(inode->i_sb, err);
    0.00 :   ffff800010310a2c:       cbnz    w22, ffff800010310984 <ext4_mark_iloc_dirty+0x454>
         : 5161             ext4_mark_iloc_dirty():
         : 5725             /* the do_update_inode consumes one bh->b_count */
         : 5726             get_bh(iloc->bh);
         :
         : 5728             /* ext4_do_update_inode() does jbd2_journal_dirty_metadata */
         : 5729             err = ext4_do_update_inode(handle, inode, iloc);
         : 5730             put_bh(iloc->bh);
    0.00 :   ffff800010310a30:       ldr     x0, [x20]
         : 5732             put_bh():
         : 284              smp_mb__before_atomic();
    0.00 :   ffff800010310a34:       dmb     ish
         : 285              atomic_dec(&bh->b_count);
    0.00 :   ffff800010310a38:       add     x2, x0, #0x60
         : 287              arch_static_branch_jump():
    0.00 :   ffff800010310a3c:       b       ffff800010310a74 <ext4_mark_iloc_dirty+0x544>
    0.00 :   ffff800010310a40:       b       ffff800010310a74 <ext4_mark_iloc_dirty+0x544>
         : 40               __lse_atomic_sub():
         : 113              asm volatile(
    0.00 :   ffff800010310a44:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010310a48:       neg     w1, w1
    0.00 :   ffff800010310a4c:       stadd   w1, [x2]
    0.00 :   ffff800010310a50:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010310a54:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010310a58:       ldp     x27, x28, [sp, #80]
         : 120              ext4_mark_iloc_dirty():
         : 5727             return err;
         : 5728             }
    0.00 :   ffff800010310a5c:       mov     w0, w22
    0.00 :   ffff800010310a60:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010310a64:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010310a68:       ldp     x29, x30, [sp], #160
    0.00 :   ffff800010310a6c:       autiasp
    0.00 :   ffff800010310a70:       ret
         : 5735             __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010310a74:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010310a78:       add     x0, x0, #0x60
    0.00 :   ffff800010310a7c:       b       ffff800010315b84 <ext4_filemap_fault+0x434>
         : 116              ext4_mark_iloc_dirty():
    0.00 :   ffff800010310a80:       mov     w0, w22
    0.00 :   ffff800010310a84:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010310a88:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010310a8c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010310a90:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010310a94:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010310a98:       ldp     x29, x30, [sp], #160
    0.00 :   ffff800010310a9c:       autiasp
    0.00 :   ffff800010310aa0:       ret
         : 5736             ext4_do_update_inode():
         : 5038             memset(raw_inode, 0, EXT4_SB(inode->i_sb)->s_inode_size);
    0.00 :   ffff800010310aa4:       ldr     x2, [x25, #40]
    0.00 :   ffff800010310aa8:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010310aac:       mov     x0, x22
    0.00 :   ffff800010310ab0:       ldr     x2, [x2, #880]
    0.00 :   ffff800010310ab4:       ldrsw   x2, [x2, #180]
    0.00 :   ffff800010310ab8:       bl      ffff8000104a5e40 <__memset>
         : 5045             ext4_inode_blocks_set():
         : 4918             u64 i_blocks = READ_ONCE(inode->i_blocks);
    0.00 :   ffff800010310abc:       ldr     x1, [x25, #144]
         : 4921             if (i_blocks <= ~0U) {
    0.00 :   ffff800010310ac0:       mov     x0, #0xffffffff                 // #4294967295
    0.00 :   ffff800010310ac4:       cmp     x1, x0
    0.00 :   ffff800010310ac8:       b.hi    ffff8000103105e0 <ext4_mark_iloc_dirty+0xb0>  // b.pmore
         : 4925             ext4_clear_inode_flag():
         : 1849             {                                                                       \
    0.00 :   ffff800010310acc:       sub     x24, x25, #0x140
         : 1851             ext4_inode_blocks_set():
         : 4926             raw_inode->i_blocks_lo   = cpu_to_le32(i_blocks);
    0.00 :   ffff800010310ad0:       str     w1, [x22, #28]
         : 4928             ext4_clear_inode_flag():
    0.00 :   ffff800010310ad4:       add     x1, x24, #0x50
         : 1850             ext4_inode_blocks_set():
         : 4927             raw_inode->i_blocks_high = 0;
    0.00 :   ffff800010310ad8:       strh    wzr, [x22, #116]
         : 4929             arch_atomic64_andnot():
         : 64               ATOMIC64_OP(atomic64_andnot)
    0.00 :   ffff800010310adc:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff800010310ae0:       tst     w0, #0xff
         : 67               __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff800010310ae4:       mov     x0, #0x40000                    // #262144
         : 178              arch_atomic64_andnot():
    0.00 :   ffff800010310ae8:       b.eq    ffff800010310624 <ext4_mark_iloc_dirty+0xf4>  // b.none
         : 65               __lse_atomic64_andnot():
    0.00 :   ffff800010310aec:       sub     x2, x25, #0xf0
    0.00 :   ffff800010310af0:       stclr   x0, [x2]
         : 178              ext4_do_update_inode():
         : 5041             if (err) {
   20.39 :   ffff800010310af4:       b       ffff80001031062c <ext4_mark_iloc_dirty+0xfc>
         : 5043             inode_maybe_inc_iversion():
         : 212              smp_mb();
    0.00 :   ffff800010310af8:       dmb     ish
         : 214              atomic64_read():
    0.00 :   ffff800010310afc:       ldr     x4, [x25, #328]
    0.00 :   ffff800010310b00:       add     x3, x25, #0x148
         : 840              inode_maybe_inc_iversion():
         : 220              new = (cur & ~I_VERSION_QUERIED) + I_VERSION_INCREMENT;
    0.00 :   ffff800010310b04:       and     x2, x4, #0xfffffffffffffffe
    0.00 :   ffff800010310b08:       add     x2, x2, #0x2
         : 223              arch_static_branch_jump():
    0.00 :   ffff800010310b0c:       b       ffff800010310b54 <ext4_mark_iloc_dirty+0x624>
    0.00 :   ffff800010310b10:       b       ffff800010310b54 <ext4_mark_iloc_dirty+0x624>
         : 40               __lse__cmpxchg_case_mb_64():
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
         : 381              __CMPXCHG_CASE(w, b,  mb_,  8, al, "memory")
         : 382              __CMPXCHG_CASE(w, h,  mb_, 16, al, "memory")
         : 383              __CMPXCHG_CASE(w,  ,  mb_, 32, al, "memory")
         : 384              __CMPXCHG_CASE(x,  ,  mb_, 64, al, "memory")
    0.00 :   ffff800010310b14:       mov     x0, x3
    0.00 :   ffff800010310b18:       mov     x1, x4
    0.00 :   ffff800010310b1c:       mov     x5, x1
    0.00 :   ffff800010310b20:       casal   x5, x2, [x3]
    0.00 :   ffff800010310b24:       mov     x0, x5
    0.00 :   ffff800010310b28:       b       ffff800010310b58 <ext4_mark_iloc_dirty+0x628>
         : 391              ext4_isize():
         : 3267             es->s_r_blocks_count_lo = cpu_to_le32((u32)blk);
    0.00 :   ffff800010310b2c:       ldr     w2, [x22, #108]
    0.00 :   ffff800010310b30:       orr     x1, x1, x2, lsl #32
    0.00 :   ffff800010310b34:       b       ffff8000103107cc <ext4_mark_iloc_dirty+0x29c>
         : 3271             __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010310b38:       mov     x0, #0x40000                    // #262144
    0.00 :   ffff800010310b3c:       sub     x3, x25, #0xf0
    0.00 :   ffff800010310b40:       stset   x0, [x3]
    0.00 :   ffff800010310b44:       b       ffff800010310948 <ext4_mark_iloc_dirty+0x418>
         : 182              __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff800010310b48:       sub     x1, x25, #0xf0
    0.00 :   ffff800010310b4c:       stclr   x0, [x1]
         : 179              ext4_do_update_inode():
    0.00 :   ffff800010310b50:       b       ffff80001031062c <ext4_mark_iloc_dirty+0xfc>
         : 5042             __ll_sc__cmpxchg_case_mb_64():
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
         : 316              __CMPXCHG_CASE(w, b,  mb_,  8, dmb ish,  , l, "memory", K)
         : 317              __CMPXCHG_CASE(w, h,  mb_, 16, dmb ish,  , l, "memory", K)
         : 318              __CMPXCHG_CASE(w,  ,  mb_, 32, dmb ish,  , l, "memory", K)
         : 319              __CMPXCHG_CASE( ,  ,  mb_, 64, dmb ish,  , l, "memory", L)
    0.00 :   ffff800010310b54:       b       ffff800010315b9c <ext4_filemap_fault+0x44c>
         : 321              inode_maybe_inc_iversion():
         : 223              if (likely(old == cur))
    0.00 :   ffff800010310b58:       cmp     x4, x0
    0.00 :   ffff800010310b5c:       b.eq    ffff800010310580 <ext4_mark_iloc_dirty+0x50>  // b.none
    0.00 :   ffff800010310b60:       mov     x4, x0
    0.00 :   ffff800010310b64:       b       ffff800010310b04 <ext4_mark_iloc_dirty+0x5d4>
         : 228              ext4_do_update_inode():
         : 5102             raw_inode->i_block[0] = 0;
    0.00 :   ffff800010310b68:       str     wzr, [x22, #40]
         : 5104             cpu_to_le32(new_encode_dev(inode->i_rdev));
    0.00 :   ffff800010310b6c:       ldr     w1, [x25, #76]
         : 5106             new_encode_dev():
         :
         : 44               static __always_inline u32 new_encode_dev(dev_t dev)
         : 45               {
         : 46               unsigned major = MAJOR(dev);
         : 47               unsigned minor = MINOR(dev);
         : 48               return (minor & 0xff) | (major << 8) | ((minor & ~0xff) << 12);
    0.00 :   ffff800010310b70:       and     w3, w1, #0xff
    0.00 :   ffff800010310b74:       lsl     w2, w1, #12
         : 41               unsigned major = MAJOR(dev);
    0.00 :   ffff800010310b78:       lsr     w1, w1, #20
         : 43               return (minor & 0xff) | (major << 8) | ((minor & ~0xff) << 12);
    0.00 :   ffff800010310b7c:       and     w2, w2, #0xfff00000
    0.00 :   ffff800010310b80:       orr     w1, w2, w1, lsl #8
    0.00 :   ffff800010310b84:       orr     w1, w1, w3
         : 47               ext4_do_update_inode():
         : 5105             raw_inode->i_block[2] = 0;
    0.00 :   ffff800010310b88:       stp     w1, wzr, [x22, #44]
    0.00 :   ffff800010310b8c:       b       ffff800010310858 <ext4_mark_iloc_dirty+0x328>
         : 5108             list_empty():
         : 282              * list_empty - tests whether a list is empty
         : 283              * @head: the list to test.
         : 284              */
         : 285              static inline int list_empty(const struct list_head *head)
         : 286              {
         : 287              return READ_ONCE(head->next) == head;
    0.00 :   ffff800010310b90:       ldur    x3, [x25, #-192]
         : 289              ext4_do_update_inode():
         : 5057             if (ei->i_dtime && list_empty(&ei->i_orphan)) {
    0.00 :   ffff800010310b94:       add     x1, x24, #0x80
    0.00 :   ffff800010310b98:       cmp     x3, x1
    0.00 :   ffff800010310b9c:       b.ne    ffff800010310694 <ext4_mark_iloc_dirty+0x164>  // b.any
         : 5069             raw_inode->i_uid_high = 0;
    0.00 :   ffff800010310ba0:       str     wzr, [x22, #120]
    0.00 :   ffff800010310ba4:       b       ffff8000103106a4 <ext4_mark_iloc_dirty+0x174>
         : 5090             if (!ext4_has_feature_large_file(sb) ||
    0.00 :   ffff800010310ba8:       ldr     w1, [x1, #76]
    0.00 :   ffff800010310bac:       cmp     w1, #0x0
    0.00 :   ffff800010310bb0:       cset    w19, eq  // eq = none
    0.00 :   ffff800010310bb4:       b       ffff800010310818 <ext4_mark_iloc_dirty+0x2e8>
         : 5095             ext4_has_inline_data():
         : 3566             struct iomap;
    0.00 :   ffff800010310bb8:       ldrh    w1, [x24, #1034]
    0.00 :   ffff800010310bbc:       cbz     w1, ffff8000103109e0 <ext4_mark_iloc_dirty+0x4b0>
    0.00 :   ffff800010310bc0:       b       ffff800010310858 <ext4_mark_iloc_dirty+0x328>
         : 3570             ext4_do_update_inode():
         : 5130             raw_inode->i_projid = cpu_to_le32(i_projid);
    0.00 :   ffff800010310bc4:       str     w0, [x22, #156]
    0.00 :   ffff800010310bc8:       b       ffff8000103108cc <ext4_mark_iloc_dirty+0x39c>
         : 5133             __ll_sc_atomic64_andnot():
         : 229              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff800010310bcc:       mov     x0, #0x200000000                // #8589934592
    0.00 :   ffff800010310bd0:       sub     x3, x25, #0xf0
    0.00 :   ffff800010310bd4:       b       ffff800010315bbc <ext4_filemap_fault+0x46c>
         : 233              ext4_do_update_inode():
         : 5139             err = ext4_handle_dirty_metadata(handle, NULL, bh);
    0.00 :   ffff800010310bd8:       mov     w22, #0x0                       // #0
         : 5143             if (set_large_file) {
    0.00 :   ffff800010310bdc:       cbnz    w19, ffff800010310a00 <ext4_mark_iloc_dirty+0x4d0>
         : 5145             ext4_handle_valid():
         :
         : 270              /* Note:  Do not use this for NULL handles.  This is only to determine if
         : 271              * a properly allocated handle is using a journal or not. */
         : 272              static inline int ext4_handle_valid(handle_t *handle)
         : 273              {
         : 274              if ((unsigned long)handle < EXT4_NOJOURNAL_MAX_REF_COUNT)
    0.00 :   ffff800010310be0:       ldr     x2, [sp, #96]
    0.00 :   ffff800010310be4:       cmp     x2, #0xfff
    0.00 :   ffff800010310be8:       b.ls    ffff800010310c28 <ext4_mark_iloc_dirty+0x6f8>  // b.plast
         : 278              is_handle_aborted():
         : 1661             */
         :
         : 1663             static inline int is_journal_aborted(journal_t *journal)
         : 1664             {
         : 1665             return journal->j_flags & JBD2_ABORT;
         : 1666             }
    0.00 :   ffff800010310bec:       ldrb    w0, [x2, #36]
    0.00 :   ffff800010310bf0:       tbnz    w0, #3, ffff800010310c28 <ext4_mark_iloc_dirty+0x6f8>
    0.00 :   ffff800010310bf4:       ldr     x0, [x2]
    0.00 :   ffff800010310bf8:       cbz     x0, ffff800010310c28 <ext4_mark_iloc_dirty+0x6f8>
         :
         : 1664             static inline int is_handle_aborted(handle_t *handle)
    0.00 :   ffff800010310bfc:       ldr     x1, [x0]
         : 1666             is_journal_aborted():
         : 1656             */
    0.00 :   ffff800010310c00:       ldr     x1, [x1]
         : 1658             ext4_update_inode_fsync_trans():
         : 438              struct inode *inode,
         : 439              int datasync)
         : 440              {
         : 441              struct ext4_inode_info *ei = EXT4_I(inode);
         :
         : 443              if (ext4_handle_valid(handle) && !is_handle_aborted(handle)) {
    0.00 :   ffff800010310c04:       tbnz    w1, #1, ffff800010310c28 <ext4_mark_iloc_dirty+0x6f8>
         : 439              ei->i_sync_tid = handle->h_transaction->t_tid;
    0.00 :   ffff800010310c08:       ldr     w0, [x0, #8]
    0.00 :   ffff800010310c0c:       str     w0, [x24, #1112]
         : 440              if (datasync)
    0.00 :   ffff800010310c10:       ldr     w0, [sp, #132]
    0.00 :   ffff800010310c14:       cbz     w0, ffff800010310c28 <ext4_mark_iloc_dirty+0x6f8>
         : 441              ei->i_datasync_tid = handle->h_transaction->t_tid;
    0.00 :   ffff800010310c18:       ldr     x0, [x2]
    0.00 :   ffff800010310c1c:       ldr     w0, [x0, #8]
    0.00 :   ffff800010310c20:       str     w0, [x24, #1116]
    0.00 :   ffff800010310c24:       nop
         : 446              brelse():
         : 290              if (bh)
    0.00 :   ffff800010310c28:       cbz     x21, ffff800010310a2c <ext4_mark_iloc_dirty+0x4fc>
         : 291              __brelse(bh);
    0.00 :   ffff800010310c2c:       mov     x0, x21
    0.00 :   ffff800010310c30:       bl      ffff80001027a690 <__brelse>
    0.00 :   ffff800010310c34:       b       ffff800010310a2c <ext4_mark_iloc_dirty+0x4fc>
         : 295              ext4_do_update_inode():
         : 5159             ext4_std_error(inode->i_sb, err);
    0.00 :   ffff800010310c38:       ldr     x0, [x25, #40]
    0.00 :   ffff800010310c3c:       adrp    x23, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff800010310c40:       add     x23, x23, #0x30
         : 5163             ext4_inode_blocks_set():
         : 4932             return -EFBIG;
    0.00 :   ffff800010310c44:       mov     w22, #0xffffffe5                // #-27
         : 4934             ext4_do_update_inode():
         : 5159             ext4_std_error(inode->i_sb, err);
    0.00 :   ffff800010310c48:       add     x1, x23, #0x388
    0.00 :   ffff800010310c4c:       mov     w3, w22
    0.00 :   ffff800010310c50:       mov     w2, #0x1427                     // #5159
    0.00 :   ffff800010310c54:       bl      ffff800010337a98 <__ext4_std_error>
    0.00 :   ffff800010310c58:       b       ffff800010310a30 <ext4_mark_iloc_dirty+0x500>
         : 5119             cpu_to_le32(ivers >> 32);
    0.00 :   ffff800010310c5c:       lsr     x1, x1, #32
    0.00 :   ffff800010310c60:       str     w1, [x22, #152]
    0.00 :   ffff800010310c64:       ldrh    w2, [x24, #1032]
    0.00 :   ffff800010310c68:       b       ffff800010310890 <ext4_mark_iloc_dirty+0x360>
         : 5124             ext4_update_other_inodes_time():
         : 4993             int i, inodes_per_block = EXT4_SB(sb)->s_inodes_per_block;
    0.00 :   ffff800010310c6c:       ldr     x2, [x23, #880]
         : 4995             ext4_do_update_inode():
         : 5135             ext4_update_other_inodes_time(inode->i_sb, inode->i_ino,
    0.00 :   ffff800010310c70:       ldr     x0, [x25, #64]
    0.00 :   ffff800010310c74:       str     x0, [sp, #112]
         : 5138             ext4_update_other_inodes_time():
         : 4993             int i, inodes_per_block = EXT4_SB(sb)->s_inodes_per_block;
    0.00 :   ffff800010310c78:       ldr     x28, [x2, #8]
         : 5001             ino = ((orig_ino - 1) & ~(inodes_per_block - 1)) + 1;
    0.00 :   ffff800010310c7c:       sub     x1, x0, #0x1
         : 4994             int inode_size = EXT4_INODE_SIZE(sb);
    0.00 :   ffff800010310c80:       ldr     w26, [x2, #180]
         : 5001             ino = ((orig_ino - 1) & ~(inodes_per_block - 1)) + 1;
    0.00 :   ffff800010310c84:       neg     w0, w28
         : 5003             ext4_do_update_inode():
         : 5135             ext4_update_other_inodes_time(inode->i_sb, inode->i_ino,
    0.00 :   ffff800010310c88:       ldr     x22, [x21, #40]
         : 5137             ext4_update_other_inodes_time():
         : 5001             ino = ((orig_ino - 1) & ~(inodes_per_block - 1)) + 1;
    0.00 :   ffff800010310c8c:       sxtw    x0, w0
    0.00 :   ffff800010310c90:       and     x1, x1, x0
    0.00 :   ffff800010310c94:       str     x1, [sp, #120]
         : 5005             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010310c98:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              ext4_update_other_inodes_time():
    0.00 :   ffff800010310c9c:       ldr     x1, [sp, #120]
         : 5003             for (i = 0; i < inodes_per_block; i++, ino++, buf += inode_size) {
    0.00 :   ffff800010310ca0:       cmp     w28, #0x0
         : 5001             ino = ((orig_ino - 1) & ~(inodes_per_block - 1)) + 1;
    0.00 :   ffff800010310ca4:       add     x27, x1, #0x1
         : 5003             for (i = 0; i < inodes_per_block; i++, ino++, buf += inode_size) {
    0.00 :   ffff800010310ca8:       b.le    ffff800010310d50 <ext4_mark_iloc_dirty+0x820>
    0.00 :   ffff800010310cac:       sub     w28, w28, #0x1
    0.00 :   ffff800010310cb0:       sxtw    x26, w26
    0.00 :   ffff800010310cb4:       add     x0, x28, #0x2
         : 5008             inode_is_dirtytime_only():
         : 2423             * if the given inode is in need of such an opportunistic update.  Requires
         : 2424             * i_lock, or at least later re-checking under i_lock.
         : 2425             */
         : 2426             static inline bool inode_is_dirtytime_only(struct inode *inode)
         : 2427             {
         : 2428             return (inode->i_state & (I_DIRTY_TIME | I_NEW |
    0.00 :   ffff800010310cb8:       mov     x28, #0x838                     // #2104
    0.00 :   ffff800010310cbc:       add     x0, x0, x1
    0.00 :   ffff800010310cc0:       str     x0, [sp, #120]
    0.00 :   ffff800010310cc4:       b       ffff800010310cdc <ext4_mark_iloc_dirty+0x7ac>
         : 2433             ext4_update_other_inodes_time():
    0.00 :   ffff800010310cc8:       ldr     x0, [sp, #120]
    0.00 :   ffff800010310ccc:       add     x27, x27, #0x1
    0.00 :   ffff800010310cd0:       add     x22, x22, x26
    0.00 :   ffff800010310cd4:       cmp     x27, x0
    0.00 :   ffff800010310cd8:       b.eq    ffff800010310d50 <ext4_mark_iloc_dirty+0x820>  // b.none
         : 5004             if (ino == orig_ino)
    0.00 :   ffff800010310cdc:       ldr     x0, [sp, #112]
    0.00 :   ffff800010310ce0:       cmp     x27, x0
    0.00 :   ffff800010310ce4:       b.eq    ffff800010310cc8 <ext4_mark_iloc_dirty+0x798>  // b.none
         : 5008             __ext4_update_other_inode_time():
         : 4959             inode = find_inode_by_ino_rcu(sb, ino);
    0.00 :   ffff800010310ce8:       mov     x1, x27
    0.00 :   ffff800010310cec:       mov     x0, x23
    0.00 :   ffff800010310cf0:       bl      ffff800010254cc8 <find_inode_by_ino_rcu>
    0.00 :   ffff800010310cf4:       mov     x4, x0
         : 4960             if (!inode)
    0.00 :   ffff800010310cf8:       cbz     x0, ffff800010310cc8 <ext4_mark_iloc_dirty+0x798>
         : 4962             inode_is_dirtytime_only():
    0.00 :   ffff800010310cfc:       ldr     x0, [x0, #152]
    0.00 :   ffff800010310d00:       and     x0, x0, x28
         : 2425             __ext4_update_other_inode_time():
         : 4963             if (!inode_is_dirtytime_only(inode))
    0.00 :   ffff800010310d04:       cmp     x0, #0x800
    0.00 :   ffff800010310d08:       b.ne    ffff800010310cc8 <ext4_mark_iloc_dirty+0x798>  // b.any
         : 4966             spin_lock():
         :
    0.00 :   ffff800010310d0c:       add     x1, x4, #0x88
    0.00 :   ffff800010310d10:       stp     x1, x4, [sp, #136]
    0.00 :   ffff800010310d14:       mov     x0, x1
    0.00 :   ffff800010310d18:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 359              __ext4_update_other_inode_time():
         : 4967             if (inode_is_dirtytime_only(inode)) {
    0.00 :   ffff800010310d1c:       ldp     x1, x4, [sp, #136]
    0.00 :   ffff800010310d20:       ldr     x0, [x4, #152]
         : 4970             inode_is_dirtytime_only():
    0.00 :   ffff800010310d24:       and     x2, x0, x28
         : 2424             __ext4_update_other_inode_time():
    0.00 :   ffff800010310d28:       cmp     x2, #0x800
    0.00 :   ffff800010310d2c:       b.eq    ffff800010310d84 <ext4_mark_iloc_dirty+0x854>  // b.none
         : 4969             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff800010310d30:       mov     x0, x1
    0.00 :   ffff800010310d34:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 397              ext4_update_other_inodes_time():
         : 5003             for (i = 0; i < inodes_per_block; i++, ino++, buf += inode_size) {
    0.00 :   ffff800010310d38:       ldr     x0, [sp, #120]
    0.00 :   ffff800010310d3c:       add     x27, x27, #0x1
    0.00 :   ffff800010310d40:       add     x22, x22, x26
    0.00 :   ffff800010310d44:       cmp     x27, x0
    0.00 :   ffff800010310d48:       b.ne    ffff800010310cdc <ext4_mark_iloc_dirty+0x7ac>  // b.any
    0.00 :   ffff800010310d4c:       nop
         : 5010             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010310d50:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              *
    0.00 :   ffff800010310d54:       b       ffff8000103108f0 <ext4_mark_iloc_dirty+0x3c0>
         : 713              ext4_mark_iloc_dirty():
         : 5712             put_bh(iloc->bh);
    0.00 :   ffff800010310d58:       ldr     x1, [x20]
         : 5714             put_bh():
         : 284              smp_mb__before_atomic();
    0.00 :   ffff800010310d5c:       dmb     ish
         : 286              arch_atomic_sub():
         : 30               ATOMIC_OP(atomic_sub)
    0.00 :   ffff800010310d60:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff800010310d64:       tst     w0, #0xff
         : 33               put_bh():
         : 285              atomic_dec(&bh->b_count);
    0.00 :   ffff800010310d68:       add     x2, x1, #0x60
         : 287              __lse_atomic_sub():
         : 113              asm volatile(
    0.00 :   ffff800010310d6c:       mov     w0, #0x1                        // #1
         : 115              arch_atomic_sub():
    0.00 :   ffff800010310d70:       b.eq    ffff800010310eec <ext4_mark_iloc_dirty+0x9bc>  // b.none
         : 31               __lse_atomic_sub():
    0.00 :   ffff800010310d74:       neg     w0, w0
    0.00 :   ffff800010310d78:       stadd   w0, [x2]
         : 115              ext4_mark_iloc_dirty():
         : 5713             return -EIO;
    0.00 :   ffff800010310d7c:       mov     w22, #0xfffffffb                // #-5
    0.00 :   ffff800010310d80:       b       ffff800010310a5c <ext4_mark_iloc_dirty+0x52c>
         : 5716             __ext4_update_other_inode_time():
         : 4970             inode->i_state &= ~I_DIRTY_TIME;
    0.00 :   ffff800010310d84:       and     x0, x0, #0xfffffffffffff7ff
         : 4968             struct ext4_inode_info  *ei = EXT4_I(inode);
    0.00 :   ffff800010310d88:       sub     x2, x4, #0x140
         : 4970             inode->i_state &= ~I_DIRTY_TIME;
    0.00 :   ffff800010310d8c:       str     x0, [x4, #152]
         : 4972             spin_unlock():
    0.00 :   ffff800010310d90:       mov     x0, x1
         : 395              spin_lock():
         :
    0.00 :   ffff800010310d94:       add     x1, x4, #0x248
    0.00 :   ffff800010310d98:       str     x1, [sp, #136]
         : 357              __ext4_update_other_inode_time():
         : 4968             struct ext4_inode_info  *ei = EXT4_I(inode);
    0.00 :   ffff800010310d9c:       str     x2, [sp, #152]
         : 4970             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff800010310da0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 396              spin_lock():
         :
    0.00 :   ffff800010310da4:       ldr     x0, [sp, #136]
    0.00 :   ffff800010310da8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 357              __ext4_update_other_inode_time():
         : 4974             EXT4_INODE_SET_XTIME(i_ctime, inode, raw_inode);
    0.00 :   ffff800010310dac:       ldp     x4, x2, [sp, #144]
    0.00 :   ffff800010310db0:       ldrh    w0, [x2, #1032]
    0.00 :   ffff800010310db4:       add     w0, w0, #0x80
    0.00 :   ffff800010310db8:       cmp     w0, #0x87
    0.00 :   ffff800010310dbc:       ldr     x0, [x4, #120]
    0.00 :   ffff800010310dc0:       str     w0, [x22, #12]
    0.00 :   ffff800010310dc4:       b.le    ffff800010310ddc <ext4_mark_iloc_dirty+0x8ac>
         : 4982             ext4_encode_extra_time():
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff800010310dc8:       ldp     x0, x1, [x4, #120]
         : 886              *
    0.00 :   ffff800010310dcc:       sub     x0, x0, w0, sxtw
    0.00 :   ffff800010310dd0:       ubfx    x0, x0, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff800010310dd4:       orr     w0, w0, w1, lsl #2
         : 889              __ext4_update_other_inode_time():
    0.00 :   ffff800010310dd8:       str     w0, [x22, #132]
         : 4975             EXT4_INODE_SET_XTIME(i_mtime, inode, raw_inode);
    0.00 :   ffff800010310ddc:       ldrh    w0, [x2, #1032]
    0.00 :   ffff800010310de0:       ldr     x1, [x4, #104]
    0.00 :   ffff800010310de4:       str     w1, [x22, #16]
    0.00 :   ffff800010310de8:       add     w0, w0, #0x80
    0.00 :   ffff800010310dec:       cmp     w0, #0x8b
    0.00 :   ffff800010310df0:       b.le    ffff800010310e08 <ext4_mark_iloc_dirty+0x8d8>
         : 4982             ext4_encode_extra_time():
    0.00 :   ffff800010310df4:       ldp     x0, x1, [x4, #104]
         : 886              *
    0.00 :   ffff800010310df8:       sub     x0, x0, w0, sxtw
    0.00 :   ffff800010310dfc:       ubfx    x0, x0, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff800010310e00:       orr     w0, w0, w1, lsl #2
         : 889              __ext4_update_other_inode_time():
    0.00 :   ffff800010310e04:       str     w0, [x22, #136]
         : 4976             EXT4_INODE_SET_XTIME(i_atime, inode, raw_inode);
    0.00 :   ffff800010310e08:       ldrh    w0, [x2, #1032]
    0.00 :   ffff800010310e0c:       ldr     x1, [x4, #88]
    0.00 :   ffff800010310e10:       str     w1, [x22, #8]
    0.00 :   ffff800010310e14:       add     w0, w0, #0x80
    0.00 :   ffff800010310e18:       cmp     w0, #0x8f
    0.00 :   ffff800010310e1c:       b.le    ffff800010310e34 <ext4_mark_iloc_dirty+0x904>
         : 4983             ext4_encode_extra_time():
    0.00 :   ffff800010310e20:       ldp     x0, x1, [x4, #88]
         : 886              *
    0.00 :   ffff800010310e24:       sub     x0, x0, w0, sxtw
    0.00 :   ffff800010310e28:       ubfx    x0, x0, #32, #2
         : 887              * Note that previous versions of the kernel on 64-bit systems would
    0.00 :   ffff800010310e2c:       orr     w0, w0, w1, lsl #2
         : 889              __ext4_update_other_inode_time():
    0.00 :   ffff800010310e30:       str     w0, [x22, #140]
         : 4977             ext4_inode_csum_set(inode, raw_inode, ei);
    0.00 :   ffff800010310e34:       mov     x0, x4
    0.00 :   ffff800010310e38:       mov     x1, x22
    0.00 :   ffff800010310e3c:       bl      ffff80001030d690 <ext4_inode_csum_set>
         : 4981             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff800010310e40:       ldr     x0, [sp, #136]
    0.00 :   ffff800010310e44:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 397              __ext4_update_other_inode_time():
         : 4980             return;
    0.00 :   ffff800010310e48:       b       ffff800010310cc8 <ext4_mark_iloc_dirty+0x798>
         : 4982             atomic64_read():
    0.00 :   ffff800010310e4c:       ldr     x1, [x25, #328]
    0.00 :   ffff800010310e50:       b       ffff800010310878 <ext4_mark_iloc_dirty+0x348>
         : 840              ext4_do_update_inode():
         : 5148             lock_buffer(EXT4_SB(sb)->s_sbh);
    0.00 :   ffff800010310e54:       ldr     x0, [x19, #880]
    0.00 :   ffff800010310e58:       ldr     x1, [x0, #96]
         : 5151             test_and_set_bit_lock():
         : 25               {
         : 26               long old;
         : 27               unsigned long mask = BIT_MASK(nr);
         :
         : 29               p += BIT_WORD(nr);
         : 30               if (READ_ONCE(*p) & mask)
    0.00 :   ffff800010310e5c:       ldr     x0, [x1]
    0.00 :   ffff800010310e60:       tbnz    w0, #2, ffff800010310efc <ext4_mark_iloc_dirty+0x9cc>
         : 33               arch_atomic64_fetch_or_acquire():
         : 86               ATOMIC64_FETCH_OP(_acquire, op)                                 \
         : 87               ATOMIC64_FETCH_OP(_release, op)                                 \
         : 88               ATOMIC64_FETCH_OP(        , op)
         :
         : 90               ATOMIC64_FETCH_OPS(atomic64_fetch_andnot)
         : 91               ATOMIC64_FETCH_OPS(atomic64_fetch_or)
    0.00 :   ffff800010310e64:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff800010310e68:       tst     w0, #0xff
    0.00 :   ffff800010310e6c:       b.eq    ffff800010310f08 <ext4_mark_iloc_dirty+0x9d8>  // b.none
         : 95               __lse_atomic64_fetch_or_acquire():
         : 203              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff800010310e70:       mov     x0, #0x4                        // #4
    0.00 :   ffff800010310e74:       ldseta  x0, x0, [x1]
         : 206              lock_buffer():
         : 367              }
         :
         : 369              static inline void lock_buffer(struct buffer_head *bh)
         : 370              {
         : 371              might_sleep();
         : 372              if (!trylock_buffer(bh))
    0.00 :   ffff800010310e78:       tbnz    w0, #2, ffff800010310efc <ext4_mark_iloc_dirty+0x9cc>
         : 374              ext4_set_feature_large_file():
         : 2034             EXT4_FEATURE_COMPAT_FUNCS(journal,              HAS_JOURNAL)
    0.00 :   ffff800010310e7c:       ldr     x19, [sp, #104]
    0.00 :   ffff800010310e80:       mov     x0, x19
    0.00 :   ffff800010310e84:       bl      ffff800010339ee0 <ext4_update_dynamic_rev>
    0.00 :   ffff800010310e88:       ldr     x1, [x19, #880]
         : 2039             ext4_do_update_inode():
         : 5150             ext4_superblock_csum_set(sb);
    0.00 :   ffff800010310e8c:       mov     x0, x19
         : 5152             ext4_set_feature_large_file():
    0.00 :   ffff800010310e90:       ldr     x2, [x1, #104]
    0.00 :   ffff800010310e94:       ldr     w1, [x2, #100]
    0.00 :   ffff800010310e98:       orr     w1, w1, #0x2
    0.00 :   ffff800010310e9c:       str     w1, [x2, #100]
         : 2038             ext4_do_update_inode():
    0.00 :   ffff800010310ea0:       bl      ffff800010336908 <ext4_superblock_csum_set>
         : 5151             unlock_buffer(EXT4_SB(sb)->s_sbh);
    0.00 :   ffff800010310ea4:       ldr     x0, [x19, #880]
    0.00 :   ffff800010310ea8:       ldr     x0, [x0, #96]
    0.00 :   ffff800010310eac:       bl      ffff80001027a190 <unlock_buffer>
         : 5155             ext4_handle_valid():
         : 269              if ((unsigned long)handle < EXT4_NOJOURNAL_MAX_REF_COUNT)
    0.00 :   ffff800010310eb0:       ldr     x1, [sp, #96]
    0.00 :   ffff800010310eb4:       cmp     x1, #0xfff
    0.00 :   ffff800010310eb8:       b.ls    ffff800010310ec8 <ext4_mark_iloc_dirty+0x998>  // b.plast
         : 273              ext4_handle_sync():
         : 277              handle->h_sync = 1;
    0.00 :   ffff800010310ebc:       ldrb    w0, [x1, #36]
    0.00 :   ffff800010310ec0:       orr     w0, w0, #0x1
    0.00 :   ffff800010310ec4:       strb    w0, [x1, #36]
         : 281              ext4_do_update_inode():
         : 5153             err = ext4_handle_dirty_metadata(handle, NULL,
    0.00 :   ffff800010310ec8:       ldp     x2, x0, [sp, #96]
    0.00 :   ffff800010310ecc:       mov     x3, #0x0                        // #0
    0.00 :   ffff800010310ed0:       mov     w1, #0x1422                     // #5154
    0.00 :   ffff800010310ed4:       ldr     x4, [x0, #880]
    0.00 :   ffff800010310ed8:       add     x0, x23, #0x388
    0.00 :   ffff800010310edc:       ldr     x4, [x4, #96]
    0.00 :   ffff800010310ee0:       bl      ffff8000102f2638 <__ext4_handle_dirty_metadata>
    0.00 :   ffff800010310ee4:       mov     w22, w0
    0.00 :   ffff800010310ee8:       b       ffff800010310be0 <ext4_mark_iloc_dirty+0x6b0>
         : 5163             __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010310eec:       add     x1, x1, #0x60
    0.00 :   ffff800010310ef0:       b       ffff800010315bd4 <ext4_filemap_fault+0x484>
         : 115              ext4_mark_iloc_dirty():
         : 5713             return -EIO;
    0.00 :   ffff800010310ef4:       mov     w22, #0xfffffffb                // #-5
    0.00 :   ffff800010310ef8:       b       ffff800010310a5c <ext4_mark_iloc_dirty+0x52c>
         : 5716             lock_buffer():
         : 368              __lock_buffer(bh);
    0.00 :   ffff800010310efc:       mov     x0, x1
    0.00 :   ffff800010310f00:       bl      ffff80001027a470 <__lock_buffer>
    0.00 :   ffff800010310f04:       b       ffff800010310e7c <ext4_mark_iloc_dirty+0x94c>
         : 372              __ll_sc_atomic64_fetch_or_acquire():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010310f08:       b       ffff800010315bec <ext4_filemap_fault+0x49c>
    0.00 :   ffff800010310f0c:       b       ffff800010310e78 <ext4_mark_iloc_dirty+0x948>
         : 225              ext4_do_update_inode():
         : 5125             BUG_ON(!ext4_has_feature_project(inode->i_sb) &&
    0.00 :   ffff800010310f10:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (5 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e34a38 <_raw_spin_unlock_irq>:
         : 6                _raw_spin_unlock_irq():
         : 198              EXPORT_SYMBOL(_raw_spin_unlock_irqrestore);
         : 199              #endif
         :
         : 201              #ifndef CONFIG_INLINE_SPIN_UNLOCK_IRQ
         : 202              void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)
         : 203              {
    0.00 :   ffff800010e34a38:       paciasp
    0.00 :   ffff800010e34a3c:       stp     x29, x30, [sp, #-16]!
         : 206              queued_spin_unlock():
         : 99               static __always_inline void queued_spin_unlock(struct qspinlock *lock)
         : 100              {
         : 101              /*
         : 102              * unlock() needs release semantics:
         : 103              */
         : 104              smp_store_release(&lock->locked, 0);
    0.00 :   ffff800010e34a40:       mov     w1, #0x0                        // #0
         : 106              _raw_spin_unlock_irq():
    0.00 :   ffff800010e34a44:       mov     x29, sp
         : 199              queued_spin_unlock():
    0.00 :   ffff800010e34a48:       stlrb   w1, [x0]
         : 100              arch_local_irq_enable():
         : 35               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 37               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 38               }
         :
         : 40               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010e34a4c:       mov     x0, #0xe0                       // #224
    0.00 :   ffff800010e34a50:       msr     daifclr, #0x3
         : 43               arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.19 :   ffff800010e34a54:       nop
         : 28               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e34a58:       mrs     x1, sp_el0
         : 26               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34a5c:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e34a60:       sub     x0, x0, #0x1
    0.00 :   ffff800010e34a64:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34a68:       cbnz    x0, ffff800010e34a94 <_raw_spin_unlock_irq+0x5c>
         : 80               __raw_spin_unlock_irq():
         : 169              static inline void __raw_spin_unlock_irq(raw_spinlock_t *lock)
         : 170              {
         : 171              spin_release(&lock->dep_map, _RET_IP_);
         : 172              do_raw_spin_unlock(lock);
         : 173              local_irq_enable();
         : 174              preempt_enable();
    0.00 :   ffff800010e34a6c:       bl      ffff800010e2e620 <preempt_schedule>
         : 176              _raw_spin_unlock_irq():
         : 200              __raw_spin_unlock_irq(lock);
         : 201              }
    0.00 :   ffff800010e34a70:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e34a74:       autiasp
    0.00 :   ffff800010e34a78:       ret
         : 205              arch_local_irq_enable():
         : 43               ARM64_HAS_IRQ_PRIO_MASKING)
         : 44               :
         : 45               : "r" ((unsigned long) GIC_PRIO_IRQON)
         : 46               : "memory");
         :
         : 48               pmr_sync();
    0.00 :   ffff800010e34a7c:       dsb     sy
         : 50               get_current():
   99.61 :   ffff800010e34a80:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34a84:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e34a88:       sub     x0, x0, #0x1
    0.20 :   ffff800010e34a8c:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34a90:       cbz     x0, ffff800010e34a6c <_raw_spin_unlock_irq+0x34>
    0.00 :   ffff800010e34a94:       ldr     x0, [x1, #8]
    0.00 :   ffff800010e34a98:       cbnz    x0, ffff800010e34a70 <_raw_spin_unlock_irq+0x38>
         : 77               __raw_spin_unlock_irq():
    0.00 :   ffff800010e34a9c:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010e34aa0:       b       ffff800010e34a70 <_raw_spin_unlock_irq+0x38>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100d50e8 <__update_load_avg_cfs_rq>:
         : 6                __update_load_avg_cfs_rq():
         : 327              }
         :
         : 329              int __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)
         : 330              {
         : 331              if (___update_load_sum(now, &cfs_rq->avg,
         : 332              scale_load_down(cfs_rq->load.weight),
    0.00 :   ffff8000100d50e8:       ldr     x8, [x1]
    0.00 :   ffff8000100d50ec:       cbz     x8, ffff8000100d5100 <__update_load_avg_cfs_rq+0x18>
    0.00 :   ffff8000100d50f0:       lsr     x8, x8, #10
    0.00 :   ffff8000100d50f4:       mov     x2, #0x2                        // #2
    0.00 :   ffff8000100d50f8:       cmp     x8, x2
    0.00 :   ffff8000100d50fc:       csel    x8, x8, x2, cs  // cs = hs, nlast
         : 331              ___update_load_sum():
         : 189              delta = now - sa->last_update_time;
    0.00 :   ffff8000100d5100:       ldr     x3, [x1, #128]
    0.00 :   ffff8000100d5104:       add     x7, x1, #0x80
         : 194              if ((s64)delta < 0) {
    0.00 :   ffff8000100d5108:       subs    x2, x0, x3
    0.00 :   ffff8000100d510c:       b.mi    ffff8000100d5164 <__update_load_avg_cfs_rq+0x7c>  // b.first
         : 203              delta >>= 10;
  100.00 :   ffff8000100d5110:       lsr     x4, x2, #10
         : 204              if (!delta)
    0.00 :   ffff8000100d5114:       cbz     x4, ffff8000100d5208 <__update_load_avg_cfs_rq+0x120>
    0.00 :   ffff8000100d5118:       mov     x6, x1
         : 207              __update_load_avg_cfs_rq():
         : 325              {
    0.00 :   ffff8000100d511c:       paciasp
    0.00 :   ffff8000100d5120:       stp     x29, x30, [sp, #-16]!
         : 328              ___update_load_sum():
         : 207              sa->last_update_time += delta << 10;
    0.00 :   ffff8000100d5124:       and     x2, x2, #0xfffffffffffffc00
    0.00 :   ffff8000100d5128:       add     x2, x2, x3
         : 210              __update_load_avg_cfs_rq():
         : 325              {
    0.00 :   ffff8000100d512c:       mov     x29, sp
         : 328              cfs_rq->h_nr_running,
    0.00 :   ffff8000100d5130:       ldr     w1, [x1, #20]
    0.00 :   ffff8000100d5134:       mov     w0, w4
         : 331              ___update_load_sum():
         : 207              sa->last_update_time += delta << 10;
    0.00 :   ffff8000100d5138:       str     x2, [x6, #128]
         : 209              __update_load_avg_cfs_rq():
         : 329              cfs_rq->curr != NULL)) {
    0.00 :   ffff8000100d513c:       ldr     x2, [x6, #64]
         : 331              ___update_load_sum():
         : 220              if (!load)
    0.00 :   ffff8000100d5140:       ldr     w14, [x7, #28]
    0.00 :   ffff8000100d5144:       add     x4, x4, w14, uxtw
    0.00 :   ffff8000100d5148:       lsr     x11, x4, #10
    0.00 :   ffff8000100d514c:       cbnz    x8, ffff8000100d5174 <__update_load_avg_cfs_rq+0x8c>
         : 225              accumulate_sum():
         : 118              if (periods) {
    0.00 :   ffff8000100d5150:       cmp     x4, #0x3ff
    0.00 :   ffff8000100d5154:       b.hi    ffff8000100d5214 <__update_load_avg_cfs_rq+0x12c>  // b.pmore
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5158:       mov     w9, w4
    0.00 :   ffff8000100d515c:       str     w4, [x7, #28]
         : 149              if (running)
    0.00 :   ffff8000100d5160:       b       ffff8000100d51c8 <__update_load_avg_cfs_rq+0xe0>
         : 151              __update_load_avg_cfs_rq():
         : 336              ___update_load_avg(&cfs_rq->avg, 1);
         : 337              trace_pelt_cfs_tp(cfs_rq);
         : 338              return 1;
         : 339              }
         :
         : 341              return 0;
    0.00 :   ffff8000100d5164:       mov     w2, #0x0                        // #0
         : 343              ___update_load_sum():
         : 195              sa->last_update_time = now;
    0.00 :   ffff8000100d5168:       str     x0, [x1, #128]
         : 197              __update_load_avg_cfs_rq():
         : 337              }
    0.00 :   ffff8000100d516c:       mov     w0, w2
    0.00 :   ffff8000100d5170:       ret
         : 326              if (___update_load_sum(now, &cfs_rq->avg,
    0.00 :   ffff8000100d5174:       cmp     x2, #0x0
    0.00 :   ffff8000100d5178:       mov     w10, w1
    0.00 :   ffff8000100d517c:       cset    w12, ne  // ne = any
         : 330              accumulate_sum():
         : 118              if (periods) {
    0.00 :   ffff8000100d5180:       cmp     x4, #0x3ff
    0.00 :   ffff8000100d5184:       b.hi    ffff8000100d521c <__update_load_avg_cfs_rq+0x134>  // b.pmore
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5188:       mov     w9, w4
    0.00 :   ffff8000100d518c:       str     w4, [x7, #28]
         : 146              sa->load_sum += load * contrib;
    0.00 :   ffff8000100d5190:       ldr     x2, [x7, #8]
    0.00 :   ffff8000100d5194:       mov     w1, w0
    0.00 :   ffff8000100d5198:       madd    x8, x1, x8, x2
    0.00 :   ffff8000100d519c:       str     x8, [x7, #8]
         : 147              if (runnable)
    0.00 :   ffff8000100d51a0:       cbz     x10, ffff8000100d51b8 <__update_load_avg_cfs_rq+0xd0>
         : 148              sa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100d51a4:       mov     w1, w0
    0.00 :   ffff8000100d51a8:       ldr     x2, [x7, #16]
    0.00 :   ffff8000100d51ac:       mul     x1, x1, x10
    0.00 :   ffff8000100d51b0:       add     x1, x2, x1, lsl #10
    0.00 :   ffff8000100d51b4:       str     x1, [x7, #16]
         : 149              if (running)
    0.00 :   ffff8000100d51b8:       cbz     w12, ffff8000100d51c8 <__update_load_avg_cfs_rq+0xe0>
         : 150              sa->util_sum += contrib << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100d51bc:       ldr     w1, [x7, #24]
    0.00 :   ffff8000100d51c0:       add     w0, w1, w0, lsl #10
    0.00 :   ffff8000100d51c4:       str     w0, [x7, #24]
         : 154              __update_load_avg_cfs_rq():
         : 336              return 0;
    0.00 :   ffff8000100d51c8:       mov     w2, #0x0                        // #0
         : 338              ___update_load_sum():
         : 230              if (!accumulate_sum(delta, sa, load, runnable, running))
    0.00 :   ffff8000100d51cc:       cbz     w11, ffff8000100d51f8 <__update_load_avg_cfs_rq+0x110>
         : 232              div_u64_rem():
         : 28               * divide.
         : 29               */
         : 30               static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
         : 31               {
         : 32               *remainder = dividend % divisor;
         : 33               return dividend / divisor;
    0.00 :   ffff8000100d51d0:       ldp     x4, x3, [x7, #8]
         : 35               get_pelt_divider():
         : 42               }
         : 43               #endif
         :
         : 45               static inline u32 get_pelt_divider(struct sched_avg *avg)
         : 46               {
         : 47               return LOAD_AVG_MAX - 1024 + avg->period_contrib;
    0.00 :   ffff8000100d51d4:       mov     w0, #0xb67e                     // #46718
         : 49               ___update_load_avg():
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d51d8:       ldr     w1, [x7, #24]
         : 272              get_pelt_divider():
    0.00 :   ffff8000100d51dc:       add     w5, w9, w0
         : 43               __update_load_avg_cfs_rq():
         : 333              return 1;
    0.00 :   ffff8000100d51e0:       mov     w2, #0x1                        // #1
         : 335              div_u64_rem():
    0.00 :   ffff8000100d51e4:       udiv    x4, x4, x5
    0.00 :   ffff8000100d51e8:       udiv    x3, x3, x5
         : 30               ___update_load_avg():
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d51ec:       udiv    w0, w1, w5
         : 269              sa->runnable_avg = div_u64(sa->runnable_sum, divider);
    0.00 :   ffff8000100d51f0:       stp     x4, x3, [x7, #32]
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d51f4:       str     x0, [x6, #176]
         : 272              __update_load_avg_cfs_rq():
         : 337              }
    0.00 :   ffff8000100d51f8:       mov     w0, w2
    0.00 :   ffff8000100d51fc:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000100d5200:       autiasp
    0.00 :   ffff8000100d5204:       ret
         : 336              return 0;
    0.00 :   ffff8000100d5208:       mov     w2, #0x0                        // #0
         : 337              }
    0.00 :   ffff8000100d520c:       mov     w0, w2
    0.00 :   ffff8000100d5210:       ret
         : 340              ___update_load_sum():
         : 221              runnable = running = 0;
    0.00 :   ffff8000100d5214:       mov     x10, #0x0                       // #0
    0.00 :   ffff8000100d5218:       mov     w12, #0x0                       // #0
         : 224              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d521c:       mov     x1, #0x83ff                     // #33791
    0.00 :   ffff8000100d5220:       movk    x1, #0x1f, lsl #16
    0.00 :   ffff8000100d5224:       cmp     x4, x1
         : 43               accumulate_sum():
         : 119              sa->load_sum = decay_load(sa->load_sum, periods);
    0.00 :   ffff8000100d5228:       ldr     x2, [x7, #8]
         : 121              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d522c:       b.hi    ffff8000100d52a4 <__update_load_avg_cfs_rq+0x1bc>  // b.pmore
         : 52               if (unlikely(local_n >= LOAD_AVG_PERIOD)) {
    0.00 :   ffff8000100d5230:       cmp     w11, #0x1f
    0.00 :   ffff8000100d5234:       b.hi    ffff8000100d52b0 <__update_load_avg_cfs_rq+0x1c8>  // b.pmore
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d5238:       adrp    x1, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d523c:       add     x1, x1, #0xb98
         : 60               mul_u64_u32_shr():
         : 161              #if defined(CONFIG_ARCH_SUPPORTS_INT128) && defined(__SIZEOF_INT128__)
         :
         : 163              #ifndef mul_u64_u32_shr
         : 164              static inline u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)
         : 165              {
         : 166              return (u64)(((unsigned __int128)a * mul) >> shift);
    0.00 :   ffff8000100d5240:       ldr     x5, [x7, #16]
    0.00 :   ffff8000100d5244:       ldr     w9, [x1, w11, uxtw #2]
         : 169              accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d5248:       ldr     w3, [x7, #24]
         : 124              mul_u64_u32_shr():
    0.00 :   ffff8000100d524c:       mul     x13, x9, x2
    0.00 :   ffff8000100d5250:       mul     x1, x9, x5
    0.00 :   ffff8000100d5254:       umulh   x2, x9, x2
    0.00 :   ffff8000100d5258:       umulh   x5, x9, x5
    0.00 :   ffff8000100d525c:       extr    x2, x2, x13, #32
    0.00 :   ffff8000100d5260:       extr    x5, x5, x1, #32
    0.00 :   ffff8000100d5264:       stp     x2, x5, [x7, #8]
    0.00 :   ffff8000100d5268:       mul     x2, x3, x9
    0.00 :   ffff8000100d526c:       lsr     x2, x2, #32
         : 170              accumulate_sum():
    0.00 :   ffff8000100d5270:       str     w2, [x7, #24]
         : 127              delta %= 1024;
    0.00 :   ffff8000100d5274:       and     x13, x4, #0x3ff
    0.00 :   ffff8000100d5278:       mov     w9, w13
         : 128              if (load) {
    0.00 :   ffff8000100d527c:       cbnz    x8, ffff8000100d5288 <__update_load_avg_cfs_rq+0x1a0>
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5280:       str     w13, [x7, #28]
         : 145              if (load)
    0.00 :   ffff8000100d5284:       b       ffff8000100d51a0 <__update_load_avg_cfs_rq+0xb8>
         : 139              contrib = __accumulate_pelt_segments(periods,
    0.00 :   ffff8000100d5288:       mov     w1, #0x400                      // #1024
    0.00 :   ffff8000100d528c:       mov     w2, w13
    0.00 :   ffff8000100d5290:       sub     w1, w1, w14
    0.00 :   ffff8000100d5294:       mov     x0, x11
    0.00 :   ffff8000100d5298:       bl      ffff8000100d4ca8 <__accumulate_pelt_segments>
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d529c:       str     w13, [x7, #28]
         : 145              if (load)
    0.00 :   ffff8000100d52a0:       b       ffff8000100d5190 <__update_load_avg_cfs_rq+0xa8>
         : 120              sa->runnable_sum =
    0.00 :   ffff8000100d52a4:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100d52a8:       stp     xzr, xzr, [x7, #8]
         : 123              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d52ac:       b       ffff8000100d5270 <__update_load_avg_cfs_rq+0x188>
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d52b0:       and     x13, x11, #0x1f
    0.00 :   ffff8000100d52b4:       adrp    x9, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d52b8:       add     x9, x9, #0xb98
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d52bc:       lsr     w3, w11, #5
    0.00 :   ffff8000100d52c0:       ldr     x1, [x7, #16]
    0.00 :   ffff8000100d52c4:       mov     w5, w3
         : 57               mul_u64_u32_shr():
    0.00 :   ffff8000100d52c8:       ldr     w9, [x9, x13, lsl #2]
         : 162              decay_load():
    0.00 :   ffff8000100d52cc:       lsr     x2, x2, x3
         : 54               accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d52d0:       ldr     w3, [x7, #24]
         : 124              decay_load():
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d52d4:       lsr     x1, x1, x5
         : 55               mul_u64_u32_shr():
    0.00 :   ffff8000100d52d8:       mul     x13, x2, x9
         : 162              decay_load():
    0.00 :   ffff8000100d52dc:       lsr     x3, x3, x5
         : 54               mul_u64_u32_shr():
    0.00 :   ffff8000100d52e0:       umulh   x2, x2, x9
    0.00 :   ffff8000100d52e4:       mul     x5, x1, x9
    0.00 :   ffff8000100d52e8:       umulh   x1, x1, x9
    0.00 :   ffff8000100d52ec:       extr    x2, x2, x13, #32
    0.00 :   ffff8000100d52f0:       extr    x1, x1, x5, #32
    0.00 :   ffff8000100d52f4:       stp     x2, x1, [x7, #8]
         : 167              decay_load():
         : 54               local_n %= LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d52f8:       b       ffff8000100d5268 <__update_load_avg_cfs_rq+0x180>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bb340 <do_idle>:
         : 6                do_idle():
         : 262              * Generic idle loop implementation
         : 263              *
         : 264              * Called with polling cleared.
         : 265              */
         : 266              static void do_idle(void)
         : 267              {
    0.00 :   ffff8000100bb340:       paciasp
    0.00 :   ffff8000100bb344:       stp     x29, x30, [sp, #-112]!
         : 263              int cpu = smp_processor_id();
    0.00 :   ffff8000100bb348:       adrp    x0, ffff80001176d000 <cpu_number>
         : 262              {
    0.00 :   ffff8000100bb34c:       mov     x29, sp
    0.00 :   ffff8000100bb350:       stp     x19, x20, [sp, #16]
         : 263              int cpu = smp_processor_id();
    0.00 :   ffff8000100bb354:       add     x0, x0, #0x0
         : 265              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100bb358:       mrs     x1, tpidr_el1
         : 46               do_idle():
         : 262              {
    0.00 :   ffff8000100bb35c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bb360:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100bb364:       add     x22, x22, #0x948
         : 263              int cpu = smp_processor_id();
    0.00 :   ffff8000100bb368:       ldr     w20, [x0, x1]
         : 262              {
    0.00 :   ffff8000100bb36c:       ldr     x0, [x22]
    0.00 :   ffff8000100bb370:       str     x0, [sp, #104]
    0.00 :   ffff8000100bb374:       mov     x0, #0x0                        // #0
         :
         : 269              /*
         : 270              * Check if we need to update blocked load
         : 271              */
         : 272              nohz_run_idle_balance(cpu);
    0.00 :   ffff8000100bb378:       mov     w0, w20
    0.00 :   ffff8000100bb37c:       bl      ffff8000100c7258 <nohz_run_idle_balance>
         : 280              * then setting need_resched is guaranteed to cause the CPU to
         : 281              * reschedule.
         : 282              */
         :
         : 284              __current_set_polling();
         : 285              tick_nohz_idle_enter();
    0.00 :   ffff8000100bb380:       bl      ffff800010120ec0 <tick_nohz_idle_enter>
         : 287              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100bb384:       mrs     x0, sp_el0
         : 26               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100bb388:       ldr     x0, [x0]
         : 113              do_idle():
         :
         : 283              while (!need_resched()) {
    0.00 :   ffff8000100bb38c:       tst     w0, #0x2
    0.00 :   ffff8000100bb390:       b.ne    ffff8000100bb4d4 <do_idle+0x194>  // b.any
         : 286              test_bit():
    0.00 :   ffff8000100bb394:       cmp     w20, #0x0
    0.00 :   ffff8000100bb398:       add     w19, w20, #0x3f
    0.00 :   ffff8000100bb39c:       csel    w19, w19, w20, lt  // lt = tstop
    0.00 :   ffff8000100bb3a0:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100bb3a4:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000100bb3a8:       add     x0, x0, #0x9e8
    0.00 :   ffff8000100bb3ac:       asr     w19, w19, #6
    0.00 :   ffff8000100bb3b0:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100bb3b4:       lsl     x20, x1, x20
    0.00 :   ffff8000100bb3b8:       add     x21, x21, #0xae0
    0.00 :   ffff8000100bb3bc:       add     x19, x0, w19, sxtw #3
    0.00 :   ffff8000100bb3c0:       stp     x23, x24, [sp, #48]
         : 118              cpuidle_get_device():
         : 174              extern void cpuidle_disable_device(struct cpuidle_device *dev);
         : 175              extern int cpuidle_play_dead(void);
         :
         : 177              extern struct cpuidle_driver *cpuidle_get_cpu_driver(struct cpuidle_device *dev);
         : 178              static inline struct cpuidle_device *cpuidle_get_device(void)
         : 179              {return __this_cpu_read(cpuidle_devices); }
    0.00 :   ffff8000100bb3c4:       adrp    x23, ffff800011778000 <ipi_to_irq>
         : 181              idle_should_enter_s2idle():
         :
         : 306              extern enum s2idle_states __read_mostly s2idle_state;
         :
         : 308              static inline bool idle_should_enter_s2idle(void)
         : 309              {
         : 310              return unlikely(s2idle_state == S2IDLE_STATE_ENTER);
    0.00 :   ffff8000100bb3c8:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
         : 312              cpuidle_get_device():
    0.00 :   ffff8000100bb3cc:       add     x23, x23, #0x938
         : 175              idle_should_enter_s2idle():
    0.00 :   ffff8000100bb3d0:       add     x24, x24, #0xb04
    0.00 :   ffff8000100bb3d4:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bb3d8:       str     x27, [sp, #80]
    0.00 :   ffff8000100bb3dc:       b       ffff8000100bb3f8 <do_idle+0xb8>
         : 309              do_idle():
         : 303              * detected in the wakeup from idle path that the tick
         : 304              * broadcast device expired for us, we don't want to go deep
         : 305              * idle as we know that the IPI is going to arrive right away.
         : 306              */
         : 307              if (cpu_idle_force_poll || tick_check_broadcast_expired()) {
         : 308              tick_nohz_idle_restart_tick();
    0.00 :   ffff8000100bb3e0:       bl      ffff800010121128 <tick_nohz_idle_restart_tick>
         : 304              cpu_idle_poll();
    0.00 :   ffff8000100bb3e4:       bl      ffff800010e34900 <cpu_idle_poll>
         : 308              } else {
         : 309              cpuidle_idle_call();
         : 310              }
         : 311              arch_cpu_idle_exit();
    0.00 :   ffff8000100bb3e8:       bl      ffff8000100bb2f0 <arch_cpu_idle_exit>
         : 313              get_current():
    0.00 :   ffff8000100bb3ec:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff8000100bb3f0:       ldr     x0, [x0]
         : 107              do_idle():
         : 282              while (!need_resched()) {
    0.00 :   ffff8000100bb3f4:       tbnz    w0, #1, ffff8000100bb4c8 <do_idle+0x188>
         : 283              rmb();
    0.00 :   ffff8000100bb3f8:       dsb     ld
         : 285              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000100bb3fc:       nop
    0.00 :   ffff8000100bb400:       mov     x0, #0x60                       // #96
         : 29               arch_local_irq_disable():
         : 54               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 56               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 57               }
         :
         : 59               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000100bb404:       msr     daifset, #0x3
         : 61               test_bit():
    0.00 :   ffff8000100bb408:       ldr     x0, [x19]
         : 107              do_idle():
         : 287              if (cpu_is_offline(cpu)) {
    0.00 :   ffff8000100bb40c:       tst     x0, x20
    0.00 :   ffff8000100bb410:       b.eq    ffff8000100bb518 <do_idle+0x1d8>  // b.none
         : 293              arch_cpu_idle_enter();
    0.00 :   ffff8000100bb414:       bl      ffff8000100bb2e0 <arch_cpu_idle_enter>
         : 302              if (cpu_idle_force_poll || tick_check_broadcast_expired()) {
    0.00 :   ffff8000100bb418:       ldr     w0, [x21]
    0.00 :   ffff8000100bb41c:       cbnz    w0, ffff8000100bb3e0 <do_idle+0xa0>
    0.00 :   ffff8000100bb420:       bl      ffff80001011f208 <tick_check_broadcast_expired>
    0.00 :   ffff8000100bb424:       cbnz    w0, ffff8000100bb3e0 <do_idle+0xa0>
         : 304              __kern_my_cpu_offset():
    0.00 :   ffff8000100bb428:       mrs     x1, tpidr_el1
         : 40               cpuidle_get_device():
    0.00 :   ffff8000100bb42c:       mov     x0, x23
    0.00 :   ffff8000100bb430:       ldr     x25, [x0, x1]
         : 176              get_current():
    0.00 :   ffff8000100bb434:       mrs     x26, sp_el0
         : 20               cpuidle_idle_call():
         : 173              struct cpuidle_driver *drv = cpuidle_get_cpu_driver(dev);
    0.00 :   ffff8000100bb438:       mov     x0, x25
    0.00 :   ffff8000100bb43c:       bl      ffff800010b915f0 <cpuidle_get_cpu_driver>
         : 176              test_bit():
    0.00 :   ffff8000100bb440:       ldr     x1, [x26]
         : 107              cpuidle_idle_call():
    0.00 :   ffff8000100bb444:       mov     x27, x0
         : 180              if (need_resched()) {
    0.00 :   ffff8000100bb448:       tbnz    w1, #1, ffff8000100bb4a8 <do_idle+0x168>
         : 191              if (cpuidle_not_available(drv, dev)) {
    0.00 :   ffff8000100bb44c:       mov     x1, x25
    0.00 :   ffff8000100bb450:       bl      ffff800010b90a60 <cpuidle_not_available>
    0.00 :   ffff8000100bb454:       tst     w0, #0xff
    0.00 :   ffff8000100bb458:       b.ne    ffff8000100bb554 <do_idle+0x214>  // b.any
         : 208              if (idle_should_enter_s2idle() || dev->forced_idle_latency_limit_ns) {
    0.00 :   ffff8000100bb45c:       ldr     w0, [x24]
    0.00 :   ffff8000100bb460:       cmp     w0, #0x1
    0.00 :   ffff8000100bb464:       b.eq    ffff8000100bb530 <do_idle+0x1f0>  // b.none
    0.00 :   ffff8000100bb468:       ldr     x26, [x25, #40]
    0.00 :   ffff8000100bb46c:       cbz     x26, ffff8000100bb560 <do_idle+0x220>
         : 222              tick_nohz_idle_stop_tick();
    0.00 :   ffff8000100bb470:       bl      ffff800010120c50 <tick_nohz_idle_stop_tick>
         : 224              next_state = cpuidle_find_deepest_state(drv, dev, max_latency_ns);
    0.00 :   ffff8000100bb474:       mov     x2, x26
    0.00 :   ffff8000100bb478:       mov     x1, x25
    0.00 :   ffff8000100bb47c:       mov     x0, x27
    0.00 :   ffff8000100bb480:       bl      ffff800010b90bd8 <cpuidle_find_deepest_state>
         : 225              call_cpuidle(drv, dev, next_state);
    0.00 :   ffff8000100bb484:       mov     x1, x25
    0.00 :   ffff8000100bb488:       mov     w2, w0
    0.00 :   ffff8000100bb48c:       mov     x0, x27
    0.00 :   ffff8000100bb490:       bl      ffff8000100bb0f8 <call_cpuidle>
         : 230              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000100bb494:       mrs     x1, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000100bb498:       and     w0, w1, #0x80
         : 92               cpuidle_idle_call():
         : 252              if (WARN_ON_ONCE(irqs_disabled()))
    0.00 :   ffff8000100bb49c:       cbz     w0, ffff8000100bb3e8 <do_idle+0xa8>
    0.00 :   ffff8000100bb4a0:       brk     #0x800
    0.00 :   ffff8000100bb4a4:       nop
         : 256              arch_local_irq_enable():
         : 35               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000100bb4a8:       mov     x0, #0xe0                       // #224
    0.00 :   ffff8000100bb4ac:       msr     daifclr, #0x3
         : 38               arch_static_branch():
    0.00 :   ffff8000100bb4b0:       nop
         : 22               do_idle():
         : 308              arch_cpu_idle_exit();
    0.00 :   ffff8000100bb4b4:       bl      ffff8000100bb2f0 <arch_cpu_idle_exit>
         : 310              get_current():
    0.00 :   ffff8000100bb4b8:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff8000100bb4bc:       ldr     x0, [x0]
         : 107              do_idle():
         : 282              while (!need_resched()) {
    0.00 :   ffff8000100bb4c0:       tbz     w0, #1, ffff8000100bb3f8 <do_idle+0xb8>
    0.00 :   ffff8000100bb4c4:       nop
    0.00 :   ffff8000100bb4c8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100bb4cc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bb4d0:       ldr     x27, [sp, #80]
         : 288              get_current():
    0.00 :   ffff8000100bb4d4:       mrs     x0, sp_el0
         : 20               set_preempt_need_resched():
         : 31               task_thread_info(p)->preempt_count = PREEMPT_DISABLED; \
         : 32               } while (0)
         :
         : 34               static inline void set_preempt_need_resched(void)
         : 35               {
         : 36               current_thread_info()->preempt.need_resched = 0;
    0.00 :   ffff8000100bb4d8:       str     wzr, [x0, #12]
         : 38               do_idle():
         : 319              *
         : 320              * This is required because for polling idle loops we will not have had
         : 321              * an IPI to fold the state for us.
         : 322              */
         : 323              preempt_set_need_resched();
         : 324              tick_nohz_idle_exit();
    0.00 :   ffff8000100bb4dc:       bl      ffff800010121180 <tick_nohz_idle_exit>
         : 327              /*
         : 328              * We promise to call sched_ttwu_pending() and reschedule if
         : 329              * need_resched() is set while polling is set. That means that clearing
         : 330              * polling needs to be visible before doing these things.
         : 331              */
         : 332              smp_mb__after_atomic();
    0.00 :   ffff8000100bb4e0:       dmb     ish
         :
         : 334              /*
         : 335              * RCU relies on this call to be done outside of an RCU read-side
         : 336              * critical section.
         : 337              */
         : 338              flush_smp_call_function_from_idle();
    0.00 :   ffff8000100bb4e4:       bl      ffff8000101285f8 <flush_smp_call_function_from_idle>
         : 334              schedule_idle();
    0.00 :   ffff8000100bb4e8:       bl      ffff800010e2e920 <schedule_idle>
         :
         : 339              if (unlikely(klp_patch_pending(current)))
         : 340              klp_update_patch_state(current);
         : 341              }
    0.00 :   ffff8000100bb4ec:       ldr     x1, [sp, #104]
    0.00 :   ffff8000100bb4f0:       ldr     x0, [x22]
    0.00 :   ffff8000100bb4f4:       eor     x0, x1, x0
    0.00 :   ffff8000100bb4f8:       cbnz    x0, ffff8000100bb5bc <do_idle+0x27c>
    0.00 :   ffff8000100bb4fc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bb500:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bb504:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000100bb508:       autiasp
    0.00 :   ffff8000100bb50c:       ret
         : 351              arch_static_branch():
    0.00 :   ffff8000100bb510:       mov     x0, #0xa0                       // #160
    0.00 :   ffff8000100bb514:       b       ffff8000100bb404 <do_idle+0xc4>
         : 23               do_idle():
         : 288              tick_nohz_idle_stop_tick();
    0.00 :   ffff8000100bb518:       bl      ffff800010120c50 <tick_nohz_idle_stop_tick>
         : 289              cpuhp_report_idle_dead();
    0.00 :   ffff8000100bb51c:       bl      ffff8000100842d0 <cpuhp_report_idle_dead>
         : 290              arch_cpu_idle_dead();
    0.00 :   ffff8000100bb520:       bl      ffff8000100167a8 <arch_cpu_idle_dead>
    0.00 :   ffff8000100bb524:       b       ffff8000100bb414 <do_idle+0xd4>
         : 293              arch_local_irq_enable():
         : 43               pmr_sync();
    0.00 :   ffff8000100bb528:       dsb     sy
    0.00 :   ffff8000100bb52c:       b       ffff8000100bb3e8 <do_idle+0xa8>
         : 46               test_bit():
    0.00 :   ffff8000100bb530:       ldr     x0, [x26]
         : 107              call_cpuidle_s2idle():
         : 134              if (current_clr_polling_and_test())
    0.00 :   ffff8000100bb534:       tbnz    w0, #1, ffff8000100bb54c <do_idle+0x20c>
         : 137              return cpuidle_enter_s2idle(drv, dev);
    0.00 :   ffff8000100bb538:       mov     x1, x25
    0.00 :   ffff8000100bb53c:       mov     x0, x27
    0.00 :   ffff8000100bb540:       bl      ffff800010b90c48 <cpuidle_enter_s2idle>
         : 141              cpuidle_idle_call():
         : 214              if (entered_state > 0)
    0.00 :   ffff8000100bb544:       cmp     w0, #0x0
    0.00 :   ffff8000100bb548:       b.gt    ffff8000100bb494 <do_idle+0x154>
         : 217              max_latency_ns = U64_MAX;
    0.00 :   ffff8000100bb54c:       mov     x26, #0xffffffffffffffff        // #-1
    0.00 :   ffff8000100bb550:       b       ffff8000100bb470 <do_idle+0x130>
         : 192              tick_nohz_idle_stop_tick();
  100.00 :   ffff8000100bb554:       bl      ffff800010120c50 <tick_nohz_idle_stop_tick>
         : 194              default_idle_call();
    0.00 :   ffff8000100bb558:       bl      ffff800010e34980 <default_idle_call>
         : 195              goto exit_idle;
    0.00 :   ffff8000100bb55c:       b       ffff8000100bb494 <do_idle+0x154>
         : 227              bool stop_tick = true;
    0.00 :   ffff8000100bb560:       mov     w3, #0x1                        // #1
         : 232              next_state = cpuidle_select(drv, dev, &stop_tick);
    0.00 :   ffff8000100bb564:       add     x2, sp, #0x67
    0.00 :   ffff8000100bb568:       mov     x1, x25
    0.00 :   ffff8000100bb56c:       mov     x0, x27
         : 227              bool stop_tick = true;
    0.00 :   ffff8000100bb570:       strb    w3, [sp, #103]
         : 232              next_state = cpuidle_select(drv, dev, &stop_tick);
    0.00 :   ffff8000100bb574:       bl      ffff800010b91118 <cpuidle_select>
    0.00 :   ffff8000100bb578:       mov     w26, w0
         : 234              if (stop_tick || tick_nohz_tick_stopped())
    0.00 :   ffff8000100bb57c:       ldrb    w0, [sp, #103]
    0.00 :   ffff8000100bb580:       cbnz    w0, ffff8000100bb590 <do_idle+0x250>
    0.00 :   ffff8000100bb584:       bl      ffff800010120bf8 <tick_nohz_tick_stopped>
    0.00 :   ffff8000100bb588:       tst     w0, #0xff
    0.00 :   ffff8000100bb58c:       b.eq    ffff8000100bb5b4 <do_idle+0x274>  // b.none
         : 235              tick_nohz_idle_stop_tick();
    0.00 :   ffff8000100bb590:       bl      ffff800010120c50 <tick_nohz_idle_stop_tick>
         : 239              entered_state = call_cpuidle(drv, dev, next_state);
    0.00 :   ffff8000100bb594:       mov     w2, w26
    0.00 :   ffff8000100bb598:       mov     x1, x25
    0.00 :   ffff8000100bb59c:       mov     x0, x27
    0.00 :   ffff8000100bb5a0:       bl      ffff8000100bb0f8 <call_cpuidle>
         : 243              cpuidle_reflect(dev, entered_state);
    0.00 :   ffff8000100bb5a4:       mov     w1, w0
    0.00 :   ffff8000100bb5a8:       mov     x0, x25
    0.00 :   ffff8000100bb5ac:       bl      ffff800010b91190 <cpuidle_reflect>
    0.00 :   ffff8000100bb5b0:       b       ffff8000100bb494 <do_idle+0x154>
         : 237              tick_nohz_idle_retain_tick();
    0.00 :   ffff8000100bb5b4:       bl      ffff800010120e90 <tick_nohz_idle_retain_tick>
    0.00 :   ffff8000100bb5b8:       b       ffff8000100bb594 <do_idle+0x254>
    0.00 :   ffff8000100bb5bc:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100bb5c0:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bb5c4:       str     x27, [sp, #80]
         : 243              do_idle():
         : 338              }
    0.00 :   ffff8000100bb5c8:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c6a40 <rebalance_domains>:
         : 6                rebalance_domains():
         : 10012            rcu_read_unlock();
         : 10013            out_unlock:
         : 10014            busiest_rq->active_balance = 0;
         : 10015            rq_unlock(busiest_rq, &rf);
         :
         : 10017            if (p)
    0.00 :   ffff8000100c6a40:       paciasp
    0.00 :   ffff8000100c6a44:       stp     x29, x30, [sp, #-176]!
    0.00 :   ffff8000100c6a48:       mov     x29, sp
    0.00 :   ffff8000100c6a4c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c6a50:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c6a54:       add     x20, x20, #0x948
    0.00 :   ffff8000100c6a58:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c6a5c:       mov     x24, x0
    0.00 :   ffff8000100c6a60:       ldr     x0, [x20]
    0.00 :   ffff8000100c6a64:       str     x0, [sp, #168]
    0.00 :   ffff8000100c6a68:       mov     x0, #0x0                        // #0
    0.00 :   ffff8000100c6a6c:       stp     x21, x22, [sp, #32]
         : 10013            attach_one_task(target_rq, p);
    0.00 :   ffff8000100c6a70:       mov     w0, #0x1                        // #1
         : 10012            if (p)
    0.00 :   ffff8000100c6a74:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c6a78:       stp     x27, x28, [sp, #80]
         : 10013            attach_one_task(target_rq, p);
    0.00 :   ffff8000100c6a7c:       str     w0, [sp, #164]
         :
    0.00 :   ffff8000100c6a80:       ldr     w0, [x24, #2576]
    0.00 :   ffff8000100c6a84:       str     w0, [sp, #120]
         : 10012            if (p)
    0.00 :   ffff8000100c6a88:       str     w1, [sp, #124]
         : 10015            local_irq_enable();
    0.00 :   ffff8000100c6a8c:       cbz     w1, ffff8000100c6c34 <rebalance_domains+0x1f4>
         : 10017            sched_idle_cpu():
         : 5502             cfs_rq->idle_h_nr_running += idle_h_nr_running;
    0.00 :   ffff8000100c6a90:       sxtw    x27, w0
    0.00 :   ffff8000100c6a94:       adrp    x21, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c6a98:       add     x21, x21, #0x760
    0.00 :   ffff8000100c6a9c:       adrp    x22, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c6aa0:       add     x0, x22, #0xc40
    0.00 :   ffff8000100c6aa4:       str     x0, [sp, #112]
    0.00 :   ffff8000100c6aa8:       ldr     x1, [x21, x27, lsl #3]
    0.00 :   ffff8000100c6aac:       add     x0, x0, x1
    0.00 :   ffff8000100c6ab0:       ldr     w1, [x0, #4]
         : 5512             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c6ab4:       ldr     w0, [x0, #152]
    0.00 :   ffff8000100c6ab8:       cmp     w1, #0x0
    0.00 :   ffff8000100c6abc:       ccmp    w0, w1, #0x0, ne  // ne = any
         : 5499             rebalance_domains():
         : 10015            local_irq_enable();
    0.00 :   ffff8000100c6ac0:       cset    w0, ne  // ne = any
    0.00 :   ffff8000100c6ac4:       str     w0, [sp, #108]
         :
         : 10020            return 0;
         : 10021            }
         :
    0.00 :   ffff8000100c6ac8:       adrp    x22, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000100c6acc:       mov     x0, #0x3a98                     // #15000
    0.00 :   ffff8000100c6ad0:       ldr     x19, [x22, #2432]
    0.00 :   ffff8000100c6ad4:       add     x19, x19, x0
         : 10027            rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100c6ad8:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              rebalance_domains():
         : 10025            static DEFINE_SPINLOCK(balancing);
         :
         : 10027            /*
         : 10028            * Scale the max load_balance interval with the number of CPUs in the system.
         : 10029            * This trades load-balance latency on larger machines for less cross talk.
         : 10030            */
    0.00 :   ffff8000100c6adc:       ldr     x1, [x21, x27, lsl #3]
    0.00 :   ffff8000100c6ae0:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100c6ae4:       add     x0, x0, x1
    0.00 :   ffff8000100c6ae8:       ldr     x26, [x0, #2472]
    0.00 :   ffff8000100c6aec:       cbz     x26, ffff8000100c6d64 <rebalance_domains+0x324>
    0.00 :   ffff8000100c6af0:       adrp    x0, ffff800011f28000 <ucounts_hashtable+0x1a88>
         : 10037            get_sd_balance_interval():
         : 9892             sd->balance_interval < MAX_PINNED_INTERVAL) ||
    0.00 :   ffff8000100c6af4:       adrp    x23, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c6af8:       add     x0, x0, #0x7c0
    0.00 :   ffff8000100c6afc:       add     x22, x22, #0x980
    0.00 :   ffff8000100c6b00:       add     x23, x23, #0xae8
         : 9897             rebalance_domains():
         : 10022            /*
    0.00 :   ffff8000100c6b04:       mov     x28, #0x0                       // #0
         : 10020            static DEFINE_SPINLOCK(balancing);
    0.00 :   ffff8000100c6b08:       mov     w25, #0x0                       // #0
         :
    0.00 :   ffff8000100c6b0c:       str     wzr, [sp, #104]
    0.00 :   ffff8000100c6b10:       str     x0, [sp, #136]
         : 10024            spin_trylock():
         : 364              raw_spin_lock(&lock->rlock);
         : 365              }
         :
         : 367              static __always_inline void spin_lock_bh(spinlock_t *lock)
         : 368              {
         : 369              raw_spin_lock_bh(&lock->rlock);
    0.00 :   ffff8000100c6b14:       add     x0, x0, #0x78
    0.00 :   ffff8000100c6b18:       str     x0, [sp, #128]
         : 372              rebalance_domains():
         : 10030            void update_max_interval(void)
         : 10031            {
         : 10032            max_load_balance_interval = HZ*num_online_cpus()/10;
         : 10033            }
         :
    0.00 :   ffff8000100c6b1c:       ldr     x0, [x22]
    0.00 :   ffff8000100c6b20:       ldr     x1, [x26, #88]
  100.00 :   ffff8000100c6b24:       ldr     w2, [sp, #164]
    0.00 :   ffff8000100c6b28:       cmp     x1, x0
    0.00 :   ffff8000100c6b2c:       ldr     x1, [x26, #80]
    0.00 :   ffff8000100c6b30:       b.mi    ffff8000100c6b80 <rebalance_domains+0x140>  // b.first
         : 10036            /*
         : 10037            * It checks each scheduling domain to see if it is due to be balanced,
         : 10038            * and initiates a balancing operation if so.
         : 10039            *
         : 10040            * Balancing parameters are set up in init_sched_domains.
         : 10041            */
    0.00 :   ffff8000100c6b34:       add     x28, x28, x1
         : 10043            {
         : 10044            int continue_balancing = 1;
         : 10045            int cpu = rq->cpu;
         : 10046            int busy = idle != CPU_IDLE && !sched_idle_cpu(cpu);
         : 10047            unsigned long interval;
         : 10048            struct sched_domain *sd;
    0.00 :   ffff8000100c6b38:       cbnz    w2, ffff8000100c6bb0 <rebalance_domains+0x170>
         : 10044            /* Earliest time when we have to do rebalance again */
    0.00 :   ffff8000100c6b3c:       ldr     w0, [sp, #104]
    0.00 :   ffff8000100c6b40:       cbnz    w0, ffff8000100c6c0c <rebalance_domains+0x1cc>
         : 10047            rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100c6b44:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              rebalance_domains():
         : 10093            * state even if we migrated tasks. Update it.
         : 10094            */
         : 10095            idle = idle_cpu(cpu) ? CPU_IDLE : CPU_NOT_IDLE;
         : 10096            busy = idle != CPU_IDLE && !sched_idle_cpu(cpu);
         : 10097            }
         : 10098            sd->last_balance = jiffies;
    0.00 :   ffff8000100c6b48:       cbz     w25, ffff8000100c6b50 <rebalance_domains+0x110>
         : 10094            interval = get_sd_balance_interval(sd, busy);
    0.00 :   ffff8000100c6b4c:       str     x19, [x24, #2376]
         : 10096            }
         : 10097            if (need_serialize)
    0.00 :   ffff8000100c6b50:       ldr     x1, [sp, #168]
    0.00 :   ffff8000100c6b54:       ldr     x0, [x20]
    0.00 :   ffff8000100c6b58:       eor     x0, x1, x0
    0.00 :   ffff8000100c6b5c:       cbnz    x0, ffff8000100c6da4 <rebalance_domains+0x364>
    0.00 :   ffff8000100c6b60:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c6b64:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c6b68:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c6b6c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c6b70:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c6b74:       ldp     x29, x30, [sp], #176
    0.00 :   ffff8000100c6b78:       autiasp
    0.00 :   ffff8000100c6b7c:       ret
         : 10032            * It checks each scheduling domain to see if it is due to be balanced,
    0.00 :   ffff8000100c6b80:       lsl     x0, x1, #6
         : 10034            *
    0.00 :   ffff8000100c6b84:       mov     w3, #0x1                        // #1
         : 10032            * It checks each scheduling domain to see if it is due to be balanced,
    0.00 :   ffff8000100c6b88:       sub     x0, x0, x1
         : 10034            *
    0.00 :   ffff8000100c6b8c:       str     w3, [sp, #104]
         : 10033            * and initiates a balancing operation if so.
    0.00 :   ffff8000100c6b90:       ldr     x3, [x22]
         : 10032            * It checks each scheduling domain to see if it is due to be balanced,
    0.00 :   ffff8000100c6b94:       add     x0, x1, x0, lsl #2
         : 10033            * and initiates a balancing operation if so.
    0.00 :   ffff8000100c6b98:       add     x1, x3, #0xfa
         : 10032            * It checks each scheduling domain to see if it is due to be balanced,
    0.00 :   ffff8000100c6b9c:       lsr     x0, x0, #8
         : 10031            /*
    0.00 :   ffff8000100c6ba0:       str     x0, [x26, #80]
         : 10036            */
    0.00 :   ffff8000100c6ba4:       add     x28, x28, x0
         : 10033            * and initiates a balancing operation if so.
    0.00 :   ffff8000100c6ba8:       str     x1, [x26, #88]
         : 10043            struct sched_domain *sd;
    0.00 :   ffff8000100c6bac:       cbz     w2, ffff8000100c6c0c <rebalance_domains+0x1cc>
         : 10045            get_sd_balance_interval():
         : 9878             out_one_pinned:
    0.00 :   ffff8000100c6bb0:       ldr     w1, [sp, #108]
         : 9876             sd->nr_balance_failed = 0;
    0.00 :   ffff8000100c6bb4:       ldr     w0, [x26, #72]
         : 9878             out_one_pinned:
    0.00 :   ffff8000100c6bb8:       cbnz    w1, ffff8000100c6c54 <rebalance_domains+0x214>
         : 9880             msecs_to_jiffies():
         : 370              if (__builtin_constant_p(m)) {
         : 371              if ((int)m < 0)
         : 372              return MAX_JIFFY_OFFSET;
         : 373              return _msecs_to_jiffies(m);
         : 374              } else {
         : 375              return __msecs_to_jiffies(m);
    0.00 :   ffff8000100c6bbc:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 377              get_sd_balance_interval():
         : 9892             sd->balance_interval < MAX_PINNED_INTERVAL) ||
    0.00 :   ffff8000100c6bc0:       ldr     x1, [x23, #8]
    0.00 :   ffff8000100c6bc4:       cmp     x0, #0x0
    0.00 :   ffff8000100c6bc8:       csinc   x0, x0, xzr, ne  // ne = any
         : 9896             rebalance_domains():
         : 10051            for_each_domain(cpu, sd) {
    0.00 :   ffff8000100c6bcc:       ldr     w2, [x26, #56]
         : 10053            get_sd_balance_interval():
         : 9892             sd->balance_interval < MAX_PINNED_INTERVAL) ||
    0.00 :   ffff8000100c6bd0:       cmp     x0, x1
    0.00 :   ffff8000100c6bd4:       csel    x1, x0, x1, ls  // ls = plast
         : 9895             rebalance_domains():
         : 10052            /*
    0.00 :   ffff8000100c6bd8:       and     w0, w2, #0x100
    0.00 :   ffff8000100c6bdc:       str     w0, [sp, #144]
    0.00 :   ffff8000100c6be0:       tbnz    w2, #8, ffff8000100c6c68 <rebalance_domains+0x228>
         : 10057            sd->max_newidle_lb_cost =
    0.00 :   ffff8000100c6be4:       ldr     x2, [x22]
    0.00 :   ffff8000100c6be8:       ldr     x0, [x26, #64]
    0.00 :   ffff8000100c6bec:       sub     x2, x2, x0
    0.00 :   ffff8000100c6bf0:       cmp     x2, x1
    0.00 :   ffff8000100c6bf4:       b.pl    ffff8000100c6c90 <rebalance_domains+0x250>  // b.nfrst
         : 10073            }
    0.00 :   ffff8000100c6bf8:       add     x0, x1, x0
         :
    0.00 :   ffff8000100c6bfc:       subs    x1, x0, x19
    0.00 :   ffff8000100c6c00:       csel    x19, x19, x0, pl  // pl = nfrst
    0.00 :   ffff8000100c6c04:       cmp     x1, #0x0
    0.00 :   ffff8000100c6c08:       csinc   w25, w25, wzr, ge  // ge = tcont
         : 10025            */
    0.00 :   ffff8000100c6c0c:       ldr     x26, [x26]
    0.00 :   ffff8000100c6c10:       cbnz    x26, ffff8000100c6b1c <rebalance_domains+0xdc>
         : 10078            if (need_serialize) {
    0.00 :   ffff8000100c6c14:       ldr     w0, [sp, #104]
    0.00 :   ffff8000100c6c18:       cbz     w0, ffff8000100c6b44 <rebalance_domains+0x104>
         : 10084            if (load_balance(cpu, rq, sd, idle, &continue_balancing)) {
    0.00 :   ffff8000100c6c1c:       mov     x0, #0xa120                     // #41248
    0.00 :   ffff8000100c6c20:       movk    x0, #0x7, lsl #16
    0.00 :   ffff8000100c6c24:       cmp     x28, x0
    0.00 :   ffff8000100c6c28:       csel    x7, x28, x0, cs  // cs = hs, nlast
         : 10083            if (time_after_eq(jiffies, sd->last_balance + interval)) {
    0.00 :   ffff8000100c6c2c:       str     x7, [x24, #2896]
    0.00 :   ffff8000100c6c30:       b       ffff8000100c6b44 <rebalance_domains+0x104>
    0.00 :   ffff8000100c6c34:       adrp    x22, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c6c38:       adrp    x21, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c6c3c:       add     x0, x22, #0xc40
    0.00 :   ffff8000100c6c40:       add     x21, x21, #0x760
    0.00 :   ffff8000100c6c44:       ldrsw   x27, [sp, #120]
         : 10015            local_irq_enable();
    0.00 :   ffff8000100c6c48:       str     wzr, [sp, #108]
    0.00 :   ffff8000100c6c4c:       str     x0, [sp, #112]
    0.00 :   ffff8000100c6c50:       b       ffff8000100c6ac8 <rebalance_domains+0x88>
         : 10019            get_sd_balance_interval():
         : 9879             ld_moved = 0;
    0.00 :   ffff8000100c6c54:       ldr     w1, [x26, #40]
         : 9881             msecs_to_jiffies():
    0.00 :   ffff8000100c6c58:       mul     w0, w0, w1
    0.00 :   ffff8000100c6c5c:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 372              get_sd_balance_interval():
         : 9890             /* tune up the balancing interval */
    0.00 :   ffff8000100c6c60:       sub     x0, x0, #0x1
    0.00 :   ffff8000100c6c64:       b       ffff8000100c6bc0 <rebalance_domains+0x180>
         : 9893             spin_trylock():
    0.00 :   ffff8000100c6c68:       ldr     x0, [sp, #128]
    0.00 :   ffff8000100c6c6c:       str     x1, [sp, #152]
    0.00 :   ffff8000100c6c70:       bl      ffff800010e34eb0 <_raw_spin_trylock>
         : 367              rebalance_domains():
         : 10053            * Decay the newidle max times here because this is a regular
    0.00 :   ffff8000100c6c74:       ldr     x1, [sp, #152]
    0.00 :   ffff8000100c6c78:       cbz     w0, ffff8000100c6cfc <rebalance_domains+0x2bc>
         : 10057            sd->max_newidle_lb_cost =
    0.00 :   ffff8000100c6c7c:       ldr     x0, [x22]
    0.00 :   ffff8000100c6c80:       ldr     x2, [x26, #64]
    0.00 :   ffff8000100c6c84:       sub     x0, x0, x2
    0.00 :   ffff8000100c6c88:       cmp     x0, x1
    0.00 :   ffff8000100c6c8c:       b.mi    ffff8000100c6ce0 <rebalance_domains+0x2a0>  // b.first
         : 10058            (sd->max_newidle_lb_cost * 253) / 256;
    0.00 :   ffff8000100c6c90:       ldp     w0, w3, [sp, #120]
    0.00 :   ffff8000100c6c94:       add     x4, sp, #0xa4
    0.00 :   ffff8000100c6c98:       mov     x2, x26
    0.00 :   ffff8000100c6c9c:       mov     x1, x24
    0.00 :   ffff8000100c6ca0:       bl      ffff8000100c5880 <load_balance>
    0.00 :   ffff8000100c6ca4:       cbnz    w0, ffff8000100c6d04 <rebalance_domains+0x2c4>
         : 10065            get_sd_balance_interval():
         : 9878             out_one_pinned:
    0.00 :   ffff8000100c6ca8:       ldr     w2, [sp, #108]
         : 9880             rebalance_domains():
         : 10067            * actively.
    0.00 :   ffff8000100c6cac:       ldr     x0, [x22]
    0.00 :   ffff8000100c6cb0:       str     x0, [x26, #64]
         : 10070            get_sd_balance_interval():
         : 9876             sd->nr_balance_failed = 0;
    0.00 :   ffff8000100c6cb4:       ldr     w0, [x26, #72]
    0.00 :   ffff8000100c6cb8:       mov     w1, w0
         : 9878             out_one_pinned:
    0.00 :   ffff8000100c6cbc:       cbnz    w2, ffff8000100c6d48 <rebalance_domains+0x308>
         : 9880             msecs_to_jiffies():
    0.00 :   ffff8000100c6cc0:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 371              get_sd_balance_interval():
         : 9892             sd->balance_interval < MAX_PINNED_INTERVAL) ||
    0.00 :   ffff8000100c6cc4:       ldr     x1, [x23, #8]
    0.00 :   ffff8000100c6cc8:       cmp     x0, #0x0
    0.00 :   ffff8000100c6ccc:       csinc   x0, x0, xzr, ne  // ne = any
    0.00 :   ffff8000100c6cd0:       cmp     x0, x1
    0.00 :   ffff8000100c6cd4:       csel    x1, x0, x1, ls  // ls = plast
         : 9898             rebalance_domains():
         : 10070            if (need_decay)
    0.00 :   ffff8000100c6cd8:       ldr     w0, [sp, #144]
    0.00 :   ffff8000100c6cdc:       cbz     w0, ffff8000100c6cfc <rebalance_domains+0x2bc>
         : 10073            spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000100c6ce0:       ldr     x0, [sp, #136]
    0.00 :   ffff8000100c6ce4:       str     x1, [sp, #144]
    0.00 :   ffff8000100c6ce8:       add     x0, x0, #0x78
    0.00 :   ffff8000100c6cec:       bl      ffff800010e349f0 <_raw_spin_unlock>
    0.00 :   ffff8000100c6cf0:       ldr     x0, [x26, #64]
    0.00 :   ffff8000100c6cf4:       ldr     x1, [sp, #144]
    0.00 :   ffff8000100c6cf8:       b       ffff8000100c6bf8 <rebalance_domains+0x1b8>
    0.00 :   ffff8000100c6cfc:       ldr     x0, [x26, #64]
    0.00 :   ffff8000100c6d00:       b       ffff8000100c6bf8 <rebalance_domains+0x1b8>
         : 409              rebalance_domains():
         : 10064            /*
    0.00 :   ffff8000100c6d04:       ldr     w0, [sp, #120]
    0.00 :   ffff8000100c6d08:       bl      ffff8000100b75b8 <idle_cpu>
    0.00 :   ffff8000100c6d0c:       str     w0, [sp, #108]
         : 10065            * Stop the load balance at this level. There is another
    0.00 :   ffff8000100c6d10:       cbnz    w0, ffff8000100c6d6c <rebalance_domains+0x32c>
         : 10067            sched_idle_cpu():
         : 5502             cfs_rq->idle_h_nr_running += idle_h_nr_running;
    0.00 :   ffff8000100c6d14:       ldr     x1, [x21, x27, lsl #3]
    0.00 :   ffff8000100c6d18:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100c6d1c:       add     x0, x0, x1
    0.00 :   ffff8000100c6d20:       ldr     w2, [x26, #72]
    0.00 :   ffff8000100c6d24:       ldr     w3, [x0, #4]
         : 5508             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c6d28:       mov     w1, w2
    0.00 :   ffff8000100c6d2c:       ldr     w0, [x0, #152]
    0.00 :   ffff8000100c6d30:       cmp     w3, w0
         : 5499             rebalance_domains():
         : 10067            * actively.
    0.00 :   ffff8000100c6d34:       ldr     x0, [x22]
         : 10069            sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c6d38:       b.eq    ffff8000100c6d88 <rebalance_domains+0x348>  // b.none
         : 5497             rebalance_domains():
         : 10064            /*
    0.00 :   ffff8000100c6d3c:       mov     w2, #0x1                        // #1
         : 10067            * actively.
    0.00 :   ffff8000100c6d40:       str     x0, [x26, #64]
         : 10064            /*
    0.00 :   ffff8000100c6d44:       str     w2, [sp, #124]
         : 10066            get_sd_balance_interval():
         : 9879             ld_moved = 0;
    0.00 :   ffff8000100c6d48:       ldr     w0, [x26, #40]
         : 9890             /* tune up the balancing interval */
    0.00 :   ffff8000100c6d4c:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000100c6d50:       str     w2, [sp, #108]
         : 9893             msecs_to_jiffies():
    0.00 :   ffff8000100c6d54:       mul     w0, w0, w1
    0.00 :   ffff8000100c6d58:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 372              get_sd_balance_interval():
    0.00 :   ffff8000100c6d5c:       sub     x0, x0, #0x1
    0.00 :   ffff8000100c6d60:       b       ffff8000100c6cc4 <rebalance_domains+0x284>
         : 9892             rcu_read_unlock():
    0.00 :   ffff8000100c6d64:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              rebalance_domains():
         : 10093            sd->last_balance = jiffies;
    0.00 :   ffff8000100c6d68:       b       ffff8000100c6b50 <rebalance_domains+0x110>
         : 10095            msecs_to_jiffies():
    0.00 :   ffff8000100c6d6c:       ldr     w0, [x26, #72]
         : 371              rebalance_domains():
         : 10067            * actively.
    0.00 :   ffff8000100c6d70:       ldr     x1, [x22]
    0.00 :   ffff8000100c6d74:       str     x1, [x26, #64]
         : 10065            * Stop the load balance at this level. There is another
    0.00 :   ffff8000100c6d78:       str     wzr, [sp, #108]
         : 10064            /*
    0.00 :   ffff8000100c6d7c:       str     wzr, [sp, #124]
         : 10066            msecs_to_jiffies():
    0.00 :   ffff8000100c6d80:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 371              get_sd_balance_interval():
         :
    0.00 :   ffff8000100c6d84:       b       ffff8000100c6cc4 <rebalance_domains+0x284>
         : 9891             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c6d88:       cbz     w3, ffff8000100c6d3c <rebalance_domains+0x2fc>
         : 5497             rebalance_domains():
         : 10064            /*
    0.00 :   ffff8000100c6d8c:       mov     w1, #0x1                        // #1
         : 10067            * actively.
    0.00 :   ffff8000100c6d90:       str     x0, [x26, #64]
         : 10069            msecs_to_jiffies():
    0.00 :   ffff8000100c6d94:       mov     w0, w2
         : 371              rebalance_domains():
         : 10064            /*
    0.00 :   ffff8000100c6d98:       str     w1, [sp, #124]
         : 10066            msecs_to_jiffies():
    0.00 :   ffff8000100c6d9c:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 371              get_sd_balance_interval():
         :
    0.00 :   ffff8000100c6da0:       b       ffff8000100c6cc4 <rebalance_domains+0x284>
         : 9891             rebalance_domains():
         : 10096            if (need_serialize)
    0.00 :   ffff8000100c6da4:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c4c20 <update_group_capacity>:
         : 6                update_group_capacity():
         :
         : 8245             if (unlikely(used >= max))
         : 8246             return 1;
         :
         : 8248             free = max - used;
         :
    0.00 :   ffff8000100c4c20:       paciasp
    0.00 :   ffff8000100c4c24:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff8000100c4c28:       mov     x29, sp
    0.00 :   ffff8000100c4c2c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c4c30:       mov     x19, x0
    0.00 :   ffff8000100c4c34:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c4c38:       sxtw    x21, w1
    0.00 :   ffff8000100c4c3c:       stp     x23, x24, [sp, #48]
         : 8258             msecs_to_jiffies():
         : 370              if (__builtin_constant_p(m)) {
         : 371              if ((int)m < 0)
         : 372              return MAX_JIFFY_OFFSET;
         : 373              return _msecs_to_jiffies(m);
         : 374              } else {
         : 375              return __msecs_to_jiffies(m);
    0.00 :   ffff8000100c4c40:       ldr     w0, [x0, #72]
         : 377              update_group_capacity():
         : 8246             return scale_irq_capacity(free, irq, max);
         : 8247             }
    0.00 :   ffff8000100c4c44:       ldp     x20, x23, [x19, #8]
         : 8249             msecs_to_jiffies():
    0.00 :   ffff8000100c4c48:       bl      ffff80001010b700 <__msecs_to_jiffies>
         : 371              update_group_capacity():
         :
         : 8252             static void update_cpu_capacity(struct sched_domain *sd, int cpu)
         : 8253             {
         : 8254             unsigned long capacity = scale_rt_capacity(cpu);
         : 8255             struct sched_group *sdg = sd->groups;
    0.00 :   ffff8000100c4c4c:       cmp     x0, #0x0
    0.00 :   ffff8000100c4c50:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
         :
    0.00 :   ffff8000100c4c54:       adrp    x4, ffff800011c27000 <bit_wait_table+0xe80>
         : 8251             struct sched_group *sdg = sd->groups;
    0.00 :   ffff8000100c4c58:       mov     x2, #0x1                        // #1
    0.00 :   ffff8000100c4c5c:       csel    x0, x0, x2, ne  // ne = any
    0.00 :   ffff8000100c4c60:       ldr     x1, [x1, #2800]
         :
    0.00 :   ffff8000100c4c64:       ldr     x3, [x23, #16]
         : 8251             struct sched_group *sdg = sd->groups;
    0.00 :   ffff8000100c4c68:       cmp     x0, x1
         :
    0.00 :   ffff8000100c4c6c:       ldr     x4, [x4, #2432]
         : 8251             struct sched_group *sdg = sd->groups;
    0.00 :   ffff8000100c4c70:       csel    x0, x0, x1, ls  // ls = plast
         :
    0.00 :   ffff8000100c4c74:       add     x0, x0, x4
    0.00 :   ffff8000100c4c78:       str     x0, [x3, #32]
         : 8254             cpu_rq(cpu)->cpu_capacity_orig = arch_scale_cpu_capacity(cpu);
         :
    0.00 :   ffff8000100c4c7c:       cbz     x20, ffff8000100c4d68 <update_group_capacity+0x148>
         : 8263             cpu_rq(cpu)->cpu_capacity = capacity;
         : 8264             trace_sched_cpu_capacity_tp(cpu_rq(cpu));
         :
         : 8266             sdg->sgc->capacity = capacity;
         : 8267             sdg->sgc->min_capacity = capacity;
         : 8268             sdg->sgc->max_capacity = capacity;
    0.00 :   ffff8000100c4c80:       ldr     w0, [x20, #56]
    0.00 :   ffff8000100c4c84:       tbz     w0, #11, ffff8000100c4d24 <update_group_capacity+0x104>
         : 8269             }
         :
         : 8271             void update_group_capacity(struct sched_domain *sd, int cpu)
         : 8272             {
         : 8273             struct sched_domain *child = sd->child;
         : 8274             struct sched_group *group, *sdg = sd->groups;
    0.00 :   ffff8000100c4c88:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
         :
    0.00 :   ffff8000100c4c8c:       mov     x19, #0xffffffffffffffff        // #-1
         : 8262             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c4c90:       adrp    x22, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c4c94:       adrp    x24, ffff800011c2d000 <xen_lateeoi_chip+0x68>
         : 5767             update_group_capacity():
         : 8269             struct sched_group *group, *sdg = sd->groups;
    0.00 :   ffff8000100c4c98:       mov     w0, w19
         : 8271             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c4c9c:       add     x22, x22, #0xc40
    0.00 :   ffff8000100c4ca0:       add     x24, x24, #0x760
         : 5767             update_group_capacity():
         : 8261             sdg->sgc->capacity = capacity;
    0.00 :   ffff8000100c4ca4:       mov     x20, #0x0                       // #0
         : 8259             trace_sched_cpu_capacity_tp(cpu_rq(cpu));
    0.00 :   ffff8000100c4ca8:       mov     x21, #0x0                       // #0
    0.00 :   ffff8000100c4cac:       stp     x25, x26, [sp, #64]
         : 8269             struct sched_group *group, *sdg = sd->groups;
    0.00 :   ffff8000100c4cb0:       ldr     w26, [x1, #3120]
    0.00 :   ffff8000100c4cb4:       add     x25, x23, #0x20
    0.00 :   ffff8000100c4cb8:       b       ffff8000100c4cdc <update_group_capacity+0xbc>
         : 8273             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c4cbc:       ldr     x2, [x24, w0, sxtw #3]
    0.00 :   ffff8000100c4cc0:       add     x1, x2, x1
    0.00 :   ffff8000100c4cc4:       ldr     x1, [x1, #2480]
         : 5768             update_group_capacity():
         : 8273             unsigned long capacity, min_capacity, max_capacity;
         : 8274             unsigned long interval;
         :
         : 8276             interval = msecs_to_jiffies(sd->balance_interval);
    0.00 :   ffff8000100c4cc8:       cmp     x19, x1
         :
    0.00 :   ffff8000100c4ccc:       add     x21, x21, x1
         : 8273             interval = msecs_to_jiffies(sd->balance_interval);
    0.00 :   ffff8000100c4cd0:       csel    x19, x19, x1, ls  // ls = plast
         : 8274             interval = clamp(interval, 1UL, max_load_balance_interval);
    0.00 :   ffff8000100c4cd4:       cmp     x20, x1
    0.00 :   ffff8000100c4cd8:       csel    x20, x20, x1, cs  // cs = hs, nlast
         : 8269             struct sched_group *group, *sdg = sd->groups;
    0.00 :   ffff8000100c4cdc:       mov     x1, x25
    0.00 :   ffff8000100c4ce0:       bl      ffff8000104a7778 <cpumask_next>
         : 8272             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c4ce4:       mov     x1, x22
         : 5766             update_group_capacity():
         : 8269             struct sched_group *group, *sdg = sd->groups;
    0.00 :   ffff8000100c4ce8:       cmp     w0, w26
    0.00 :   ffff8000100c4cec:       b.cc    ffff8000100c4cbc <update_group_capacity+0x9c>  // b.lo, b.ul, b.last
    0.00 :   ffff8000100c4cf0:       ldp     x25, x26, [sp, #64]
         : 8293             * SD_OVERLAP domains cannot assume that child groups
         : 8294             * span the current group.
         : 8295             */
         :
         : 8297             for_each_cpu(cpu, sched_group_span(sdg)) {
         : 8298             unsigned long cpu_cap = capacity_of(cpu);
    0.00 :   ffff8000100c4cf4:       ldr     x0, [x23, #16]
    0.00 :   ffff8000100c4cf8:       str     x21, [x0, #8]
         :
    0.00 :   ffff8000100c4cfc:       ldr     x0, [x23, #16]
    0.00 :   ffff8000100c4d00:       str     x19, [x0, #16]
         : 8295             capacity += cpu_cap;
    0.00 :   ffff8000100c4d04:       ldr     x0, [x23, #16]
    0.00 :   ffff8000100c4d08:       str     x20, [x0, #24]
         : 8296             min_capacity = min(cpu_cap, min_capacity);
    0.00 :   ffff8000100c4d0c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c4d10:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c4d14:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c4d18:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000100c4d1c:       autiasp
    0.00 :   ffff8000100c4d20:       ret
         : 8282             capacity = 0;
    0.00 :   ffff8000100c4d24:       ldr     x4, [x20, #16]
         :
    0.00 :   ffff8000100c4d28:       mov     x19, #0xffffffffffffffff        // #-1
         : 8259             trace_sched_cpu_capacity_tp(cpu_rq(cpu));
    0.00 :   ffff8000100c4d2c:       mov     x21, #0x0                       // #0
         : 8261             sdg->sgc->capacity = capacity;
    0.00 :   ffff8000100c4d30:       mov     x20, #0x0                       // #0
         : 8282             capacity = 0;
    0.00 :   ffff8000100c4d34:       mov     x0, x4
         : 8284             max_capacity = 0;
    0.00 :   ffff8000100c4d38:       ldr     x1, [x0, #16]
         : 8289             * span the current group.
    0.00 :   ffff8000100c4d3c:       ldr     x0, [x0]
         : 8288             * SD_OVERLAP domains cannot assume that child groups
    0.00 :   ffff8000100c4d40:       ldp     x3, x2, [x1, #16]
         : 8286             if (child->flags & SD_OVERLAP) {
    0.00 :   ffff8000100c4d44:       ldr     x1, [x1, #8]
    0.00 :   ffff8000100c4d48:       add     x21, x21, x1
         : 8287             /*
    0.00 :   ffff8000100c4d4c:       cmp     x19, x3
    0.00 :   ffff8000100c4d50:       csel    x19, x19, x3, ls  // ls = plast
         : 8288             * SD_OVERLAP domains cannot assume that child groups
    0.00 :   ffff8000100c4d54:       cmp     x20, x2
    0.00 :   ffff8000100c4d58:       csel    x20, x20, x2, cs  // cs = hs, nlast
         : 8290             */
    0.00 :   ffff8000100c4d5c:       cmp     x4, x0
    0.00 :   ffff8000100c4d60:       b.ne    ffff8000100c4d38 <update_group_capacity+0x118>  // b.any
    0.00 :   ffff8000100c4d64:       b       ffff8000100c4cf4 <update_group_capacity+0xd4>
         : 8294             scale_rt_capacity():
         : 8197             static inline void init_sd_lb_stats(struct sd_lb_stats *sds)
    0.00 :   ffff8000100c4d68:       adrp    x5, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c4d6c:       add     x5, x5, #0x760
    0.00 :   ffff8000100c4d70:       adrp    x0, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c4d74:       add     x3, x0, #0xc40
    0.00 :   ffff8000100c4d78:       mov     x1, x3
         : 8203             topology_get_cpu_scale():
         :
         : 22               DECLARE_PER_CPU(unsigned long, cpu_scale);
         :
         : 24               static inline unsigned long topology_get_cpu_scale(int cpu)
         : 25               {
         : 26               return per_cpu(cpu_scale, cpu);
    0.00 :   ffff8000100c4d7c:       adrp    x0, ffff800011778000 <ipi_to_irq>
         : 28               scale_rt_capacity():
    0.00 :   ffff8000100c4d80:       ldr     x4, [x5, x21, lsl #3]
         : 8198             topology_get_cpu_scale():
    0.00 :   ffff8000100c4d84:       add     x0, x0, #0x700
         : 22               scale_rt_capacity():
    0.00 :   ffff8000100c4d88:       add     x1, x1, x4
         : 8198             topology_get_cpu_scale():
    0.00 :   ffff8000100c4d8c:       ldr     x4, [x4, x0]
         : 22               scale_rt_capacity():
         : 8202             * We must however set busiest_stat::group_type and
    0.00 :   ffff8000100c4d90:       ldr     x6, [x1, #2800]
         : 8204             * update_sd_pick_busiest() reads these before assignment.
  100.00 :   ffff8000100c4d94:       ldr     x7, [x19, #16]
    0.00 :   ffff8000100c4d98:       cmp     x4, x6
    0.00 :   ffff8000100c4d9c:       b.ls    ffff8000100c4e04 <update_group_capacity+0x1e4>  // b.plast
         : 8213             .group_type = group_has_spare,
    0.00 :   ffff8000100c4da0:       ldr     x0, [x1, #2672]
         : 8214             },
    0.00 :   ffff8000100c4da4:       ldr     x9, [x1, #2736]
         : 8216             thermal_load_avg():
         : 15               #ifdef CONFIG_SCHED_THERMAL_PRESSURE
         : 16               int update_thermal_load_avg(u64 now, struct rq *rq, u64 capacity);
         :
         : 18               static inline u64 thermal_load_avg(struct rq *rq)
         : 19               {
         : 20               return READ_ONCE(rq->avg_thermal.load_avg);
    0.00 :   ffff8000100c4da8:       ldr     x8, [x1, #2848]
         : 22               scale_rt_capacity():
    0.00 :   ffff8000100c4dac:       add     x0, x0, x9
         : 8215             };
    0.00 :   ffff8000100c4db0:       add     x0, x0, x8
         :
    0.00 :   ffff8000100c4db4:       cmp     x4, x0
    0.00 :   ffff8000100c4db8:       b.ls    ffff8000100c4e04 <update_group_capacity+0x1e4>  // b.plast
         : 8220             struct rq *rq = cpu_rq(cpu);
    0.00 :   ffff8000100c4dbc:       sub     x0, x4, x0
         : 8222             scale_irq_capacity():
         : 2663             extern void resched_latency_warn(int cpu, u64 latency);
         : 2664             #ifdef CONFIG_NUMA_BALANCING
         : 2665             extern void
         : 2666             show_numa_stats(struct task_struct *p, struct seq_file *m);
         : 2667             extern void
         : 2668             print_numa_stats(struct seq_file *m, int node, unsigned long tsf,
    0.00 :   ffff8000100c4dc0:       sub     x6, x4, x6
         : 2670             update_cpu_capacity():
         : 8230             /*
    0.00 :   ffff8000100c4dc4:       str     x4, [x1, #2488]
         : 8232             scale_irq_capacity():
    0.00 :   ffff8000100c4dc8:       mul     x0, x0, x6
         : 2664             update_cpu_capacity():
         : 8232             * (running and not running) with weights 0 and 1024 respectively.
    0.00 :   ffff8000100c4dcc:       cmp     x4, x0
    0.00 :   ffff8000100c4dd0:       b.hi    ffff8000100c4dd8 <update_group_capacity+0x1b8>  // b.pmore
         : 8235             scale_irq_capacity():
         : 2664             unsigned long tpf, unsigned long gsf, unsigned long gpf);
    0.00 :   ffff8000100c4dd4:       udiv    x2, x0, x4
         : 2666             update_cpu_capacity():
         : 8235             */
    0.00 :   ffff8000100c4dd8:       ldr     x1, [x5, x21, lsl #3]
    0.00 :   ffff8000100c4ddc:       mov     x0, x3
    0.00 :   ffff8000100c4de0:       add     x0, x1, x0
    0.00 :   ffff8000100c4de4:       str     x2, [x0, #2480]
         : 8238             used += thermal_load_avg(rq);
    0.00 :   ffff8000100c4de8:       ldr     x0, [x7, #16]
    0.00 :   ffff8000100c4dec:       str     x2, [x0, #8]
         :
    0.00 :   ffff8000100c4df0:       ldr     x0, [x7, #16]
    0.00 :   ffff8000100c4df4:       str     x2, [x0, #16]
         : 8240             if (unlikely(used >= max))
    0.00 :   ffff8000100c4df8:       ldr     x0, [x7, #16]
    0.00 :   ffff8000100c4dfc:       str     x2, [x0, #24]
    0.00 :   ffff8000100c4e00:       b       ffff8000100c4d0c <update_group_capacity+0xec>
         : 8230             /*
    0.00 :   ffff8000100c4e04:       str     x4, [x1, #2488]
         : 8232             * (running and not running) with weights 0 and 1024 respectively.
    0.00 :   ffff8000100c4e08:       b       ffff8000100c4dd8 <update_group_capacity+0x1b8>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001017e088 <next_uptodate_page>:
         : 6                next_uptodate_page():
         : 3119             }
         :
         : 3121             static struct page *next_uptodate_page(struct page *page,
         : 3122             struct address_space *mapping,
         : 3123             struct xa_state *xas, pgoff_t end_pgoff)
         : 3124             {
    0.00 :   ffff80001017e088:       paciasp
    0.00 :   ffff80001017e08c:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff80001017e090:       mov     x29, sp
    0.00 :   ffff80001017e094:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001017e098:       mov     x19, x0
    0.00 :   ffff80001017e09c:       mov     x20, x2
    0.00 :   ffff80001017e0a0:       stp     x21, x22, [sp, #32]
         : 3132             __ll_sc_atomic_sub_return():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001017e0a4:       mov     w22, #0x1                       // #1
         : 119              xas_reset():
         : 1471             *
         : 1472             * Context: Any context.
         : 1473             */
         : 1474             static inline void xas_reset(struct xa_state *xas)
         : 1475             {
         : 1476             xas->xa_node = XAS_RESTART;
    0.00 :   ffff80001017e0a8:       mov     x21, #0x3                       // #3
         : 1478             next_uptodate_page():
    0.00 :   ffff80001017e0ac:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001017e0b0:       mov     x23, x1
         : 3121             __lse_atomic64_fetch_or_acquire():
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
         : 208              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff80001017e0b4:       mov     x24, #0x1                       // #1
         : 210              next_uptodate_page():
    0.00 :   ffff80001017e0b8:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001017e0bc:       mov     x26, x3
         : 3123             unsigned long max_idx;
         :
         : 3125             do {
         : 3126             if (!page)
    0.00 :   ffff80001017e0c0:       cbz     x0, ffff80001017e2a4 <next_uptodate_page+0x21c>
    0.00 :   ffff80001017e0c4:       nop
         : 3129             xas_retry():
         : 1488             * Context: Any context.
         : 1489             * Return: true if the operation needs to be retried.
         : 1490             */
         : 1491             static inline bool xas_retry(struct xa_state *xas, const void *entry)
         : 1492             {
         : 1493             if (xa_is_zero(entry))
    0.00 :   ffff80001017e0c8:       cmp     x19, #0x406
    0.00 :   ffff80001017e0cc:       b.eq    ffff80001017e208 <next_uptodate_page+0x180>  // b.none
         : 1490             return true;
         : 1491             if (!xa_is_retry(entry))
    0.00 :   ffff80001017e0d0:       cmp     x19, #0x402
    0.00 :   ffff80001017e0d4:       b.eq    ffff80001017e2dc <next_uptodate_page+0x254>  // b.none
         : 1494             next_uptodate_page():
         : 3127             return NULL;
         : 3128             if (xas_retry(xas, page))
         : 3129             continue;
         : 3130             if (xa_is_value(page))
    0.00 :   ffff80001017e0d8:       tbnz    w19, #0, ffff80001017e208 <next_uptodate_page+0x180>
         : 3132             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff80001017e0dc:       ldr     x1, [x19, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff80001017e0e0:       sub     x0, x1, #0x1
    0.00 :   ffff80001017e0e4:       tst     x1, #0x1
    0.00 :   ffff80001017e0e8:       csel    x0, x0, x19, ne  // ne = any
         : 193              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001017e0ec:       ldr     x0, [x0]
         : 113              next_uptodate_page():
         : 3129             continue;
         : 3130             if (PageLocked(page))
    0.00 :   ffff80001017e0f0:       tbnz    w0, #0, ffff80001017e208 <next_uptodate_page+0x180>
         : 3132             arch_atomic_fetch_add_unless():
         : 1158             * Returns original value of @v
         : 1159             */
         : 1160             static __always_inline int
         : 1161             arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
         : 1162             {
         : 1163             int c = arch_atomic_read(v);
    0.00 :   ffff80001017e0f4:       ldr     w4, [x19, #52]
         :
         : 1162             do {
         : 1163             if (unlikely(c == u))
    0.00 :   ffff80001017e0f8:       cbz     w4, ffff80001017e208 <next_uptodate_page+0x180>
    0.00 :   ffff80001017e0fc:       add     x25, x19, #0x34
         : 1166             arch_atomic_try_cmpxchg():
         : 990              r = arch_atomic_cmpxchg(v, o, new);
    0.00 :   ffff80001017e100:       sxtw    x1, w4
         : 992              arch_atomic_fetch_add_unless():
         : 1163             break;
         : 1164             } while (!arch_atomic_try_cmpxchg(v, &c, c + a));
    0.00 :   ffff80001017e104:       add     w2, w4, #0x1
         : 1166             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001017e108:       b       ffff80001017e2d0 <next_uptodate_page+0x248>
    0.00 :   ffff80001017e10c:       b       ffff80001017e2d0 <next_uptodate_page+0x248>
         : 46               __lse__cmpxchg_case_mb_32():
         : 378              __CMPXCHG_CASE(w, h, rel_, 16,  l, "memory")
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
         : 381              __CMPXCHG_CASE(w, b,  mb_,  8, al, "memory")
         : 382              __CMPXCHG_CASE(w, h,  mb_, 16, al, "memory")
         : 383              __CMPXCHG_CASE(w,  ,  mb_, 32, al, "memory")
    0.00 :   ffff80001017e110:       mov     x0, x25
    0.00 :   ffff80001017e114:       mov     w3, w1
    0.00 :   ffff80001017e118:       casal   w3, w2, [x25]
    0.00 :   ffff80001017e11c:       mov     w0, w3
         : 388              arch_atomic_try_cmpxchg():
         : 991              if (unlikely(r != o))
    0.00 :   ffff80001017e120:       cmp     w0, w4
    0.00 :   ffff80001017e124:       b.ne    ffff80001017e2c4 <next_uptodate_page+0x23c>  // b.any
         : 994              page_ref_add_unless():
         : 170              {
         : 171              int ret = atomic_add_unless(&page->_refcount, nr, u);
         :
         : 173              if (page_ref_tracepoint_active(page_ref_mod_unless))
         : 174              __page_ref_mod_unless(page, nr, ret);
         : 175              return ret;
    0.00 :   ffff80001017e128:       ldr     x1, [x20, #24]
         : 177              xas_reload():
         : 1554             {
         : 1555             struct xa_node *node = xas->xa_node;
         : 1556             void *entry;
         : 1557             char offset;
         :
         : 1559             if (!node)
    0.00 :   ffff80001017e12c:       cbz     x1, ffff80001017e30c <next_uptodate_page+0x284>
         : 1557             return xa_head(xas->xa);
         : 1558             if (IS_ENABLED(CONFIG_XARRAY_MULTI)) {
         : 1559             offset = (xas->xa_index >> node->shift) & XA_CHUNK_MASK;
    0.00 :   ffff80001017e130:       ldr     x0, [x20, #8]
    0.00 :   ffff80001017e134:       ldrb    w2, [x1]
    0.00 :   ffff80001017e138:       lsr     x0, x0, x2
         : 1563             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff80001017e13c:       ubfiz   x0, x0, #3, #6
    0.00 :   ffff80001017e140:       add     x0, x0, #0x20
    0.00 :   ffff80001017e144:       add     x0, x1, x0
    0.00 :   ffff80001017e148:       ldr     x0, [x0, #8]
         : 1187             xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff80001017e14c:       cmp     x0, #0xfd
         : 1251             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff80001017e150:       and     x2, x0, #0x3
         : 171              xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff80001017e154:       ccmp    x2, #0x2, #0x0, ls  // ls = plast
    0.00 :   ffff80001017e158:       b.ne    ffff80001017e16c <next_uptodate_page+0xe4>  // b.any
         : 1252             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff80001017e15c:       ubfx    x0, x0, #2, #8
    0.00 :   ffff80001017e160:       add     x0, x0, #0x4
    0.00 :   ffff80001017e164:       add     x0, x1, x0, lsl #3
    0.00 :   ffff80001017e168:       ldr     x0, [x0, #8]
         : 1187             next_uptodate_page():
         : 3134             continue;
         : 3135             if (!page_cache_get_speculative(page))
         : 3136             continue;
         : 3137             /* Has the page moved or been split? */
         : 3138             if (unlikely(page != xas_reload(xas)))
    0.00 :   ffff80001017e16c:       cmp     x0, x19
    0.00 :   ffff80001017e170:       b.ne    ffff80001017e1e0 <next_uptodate_page+0x158>  // b.any
         : 3141             compound_head():
         : 184              {
    0.00 :   ffff80001017e174:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001017e178:       sub     x0, x1, #0x1
    0.00 :   ffff80001017e17c:       tst     x1, #0x1
    0.00 :   ffff80001017e180:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
  100.00 :   ffff80001017e184:       ldr     x0, [x0]
         : 107              PageUptodate():
         :
         : 526              static inline int PageUptodate(struct page *page)
         : 527              {
         : 528              int ret;
         : 529              page = compound_head(page);
         : 530              ret = test_bit(PG_uptodate, &(page)->flags);
    0.00 :   ffff80001017e188:       tbz     w0, #2, ffff80001017e1e0 <next_uptodate_page+0x158>
         : 526              /*
    0.00 :   ffff80001017e18c:       dmb     ishld
         : 528              test_bit():
    0.00 :   ffff80001017e190:       ldr     x0, [x19]
         : 107              next_uptodate_page():
         : 3136             goto skip;
         : 3137             if (!PageUptodate(page) || PageReadahead(page))
    0.00 :   ffff80001017e194:       tbnz    w0, #18, ffff80001017e1e0 <next_uptodate_page+0x158>
         : 3139             test_bit():
    0.00 :   ffff80001017e198:       ldr     x0, [x19]
         : 107              next_uptodate_page():
         : 3138             goto skip;
         : 3139             if (PageHWPoison(page))
    0.00 :   ffff80001017e19c:       tbnz    w0, #22, ffff80001017e1e0 <next_uptodate_page+0x158>
         : 3141             compound_head():
         : 184              {
    0.00 :   ffff80001017e1a0:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001017e1a4:       sub     x0, x1, #0x1
    0.00 :   ffff80001017e1a8:       tst     x1, #0x1
    0.00 :   ffff80001017e1ac:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_and_set_bit_lock():
         : 25               {
         : 26               long old;
         : 27               unsigned long mask = BIT_MASK(nr);
         :
         : 29               p += BIT_WORD(nr);
         : 30               if (READ_ONCE(*p) & mask)
    0.00 :   ffff80001017e1b0:       ldr     x1, [x0]
    0.00 :   ffff80001017e1b4:       tbnz    w1, #0, ffff80001017e1e0 <next_uptodate_page+0x158>
         : 33               arch_static_branch_jump():
    0.00 :   ffff80001017e1b8:       b       ffff80001017e324 <next_uptodate_page+0x29c>
    0.00 :   ffff80001017e1bc:       b       ffff80001017e324 <next_uptodate_page+0x29c>
         : 40               __lse_atomic64_fetch_or_acquire():
         : 203              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff80001017e1c0:       mov     x1, x24
    0.00 :   ffff80001017e1c4:       ldseta  x1, x1, [x0]
         : 206              next_uptodate_page():
         : 3140             goto skip;
         : 3141             if (!trylock_page(page))
    0.00 :   ffff80001017e1c8:       tbnz    w1, #0, ffff80001017e1e0 <next_uptodate_page+0x158>
         : 3142             goto skip;
         : 3143             if (page->mapping != mapping)
    0.00 :   ffff80001017e1cc:       ldr     x0, [x19, #24]
    0.00 :   ffff80001017e1d0:       cmp     x0, x23
    0.00 :   ffff80001017e1d4:       b.eq    ffff80001017e32c <next_uptodate_page+0x2a4>  // b.none
         : 3151             max_idx = DIV_ROUND_UP(i_size_read(mapping->host), PAGE_SIZE);
         : 3152             if (xas->xa_index >= max_idx)
         : 3153             goto unlock;
         : 3154             return page;
         : 3155             unlock:
         : 3156             unlock_page(page);
    0.00 :   ffff80001017e1d8:       mov     x0, x19
    0.00 :   ffff80001017e1dc:       bl      ffff80001017d860 <unlock_page>
         : 3159             compound_head():
         : 184              {
    0.00 :   ffff80001017e1e0:       ldr     x0, [x19, #8]
         :
    0.00 :   ffff80001017e1e4:       tbnz    w0, #0, ffff80001017e318 <next_uptodate_page+0x290>
         : 188              arch_static_branch_jump():
    0.00 :   ffff80001017e1e8:       b       ffff80001017e2f8 <next_uptodate_page+0x270>
    0.00 :   ffff80001017e1ec:       b       ffff80001017e2f8 <next_uptodate_page+0x270>
         : 40               __lse_atomic_sub_return():
         : 141              ATOMIC_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff80001017e1f0:       mov     w0, w22
    0.00 :   ffff80001017e1f4:       neg     w0, w0
    0.00 :   ffff80001017e1f8:       ldaddal w0, w1, [x25]
    0.00 :   ffff80001017e1fc:       add     w0, w0, w1
         : 146              put_page():
         : 1242             put_devmap_managed_page(page);
         : 1243             return;
         : 1244             }
         :
         : 1246             if (put_page_testzero(page))
         : 1247             __put_page(page);
    0.00 :   ffff80001017e200:       cbz     w0, ffff80001017e300 <next_uptodate_page+0x278>
    0.00 :   ffff80001017e204:       nop
         : 1250             xas_not_node():
         : 1444             return ((unsigned long)node & 3) || !node;
    0.00 :   ffff80001017e208:       ldr     x2, [x20, #24]
    0.00 :   ffff80001017e20c:       tst     x2, #0x3
    0.00 :   ffff80001017e210:       cset    w0, ne  // ne = any
    0.00 :   ffff80001017e214:       cmp     x2, #0x0
    0.00 :   ffff80001017e218:       csinc   w0, w0, wzr, ne  // ne = any
    0.00 :   ffff80001017e21c:       cbnz    w0, ffff80001017e290 <next_uptodate_page+0x208>
         : 1451             xas_next_entry():
         : 1632             static inline void *xas_next_entry(struct xa_state *xas, unsigned long max)
         : 1633             {
         : 1634             struct xa_node *node = xas->xa_node;
         : 1635             void *entry;
         :
         : 1637             if (unlikely(xas_not_node(node) || node->shift ||
    0.00 :   ffff80001017e220:       ldrb    w0, [x2]
    0.00 :   ffff80001017e224:       cbnz    w0, ffff80001017e290 <next_uptodate_page+0x208>
    0.00 :   ffff80001017e228:       ldr     x1, [x20, #8]
    0.00 :   ffff80001017e22c:       ldrb    w3, [x20, #18]
    0.00 :   ffff80001017e230:       and     x0, x1, #0x3f
    0.00 :   ffff80001017e234:       cmp     x3, x0
    0.00 :   ffff80001017e238:       b.ne    ffff80001017e290 <next_uptodate_page+0x208>  // b.any
         : 1637             xas->xa_offset != (xas->xa_index & XA_CHUNK_MASK)))
         : 1638             return xas_find(xas, max);
         :
         : 1640             do {
         : 1641             if (unlikely(xas->xa_index >= max))
    0.00 :   ffff80001017e23c:       cmp     x26, x1
         : 1645             return xas_find(xas, max);
         : 1646             entry = xa_entry(xas->xa, node, xas->xa_offset + 1);
         : 1647             if (unlikely(xa_is_internal(entry)))
         : 1648             return xas_find(xas, max);
         : 1649             xas->xa_offset++;
         : 1650             xas->xa_index++;
    0.00 :   ffff80001017e240:       add     x1, x1, #0x1
         : 1637             if (unlikely(xas->xa_index >= max))
    0.00 :   ffff80001017e244:       b.ls    ffff80001017e290 <next_uptodate_page+0x208>  // b.plast
         : 1639             if (unlikely(xas->xa_offset == XA_CHUNK_MASK))
    0.00 :   ffff80001017e248:       ldrb    w0, [x20, #18]
         : 1641             entry = xa_entry(xas->xa, node, xas->xa_offset + 1);
    0.00 :   ffff80001017e24c:       add     w4, w0, #0x1
         : 1639             if (unlikely(xas->xa_offset == XA_CHUNK_MASK))
    0.00 :   ffff80001017e250:       cmp     w0, #0x3f
    0.00 :   ffff80001017e254:       b.eq    ffff80001017e290 <next_uptodate_page+0x208>  // b.none
         : 1642             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff80001017e258:       ubfiz   x0, x4, #3, #9
    0.00 :   ffff80001017e25c:       add     x0, x0, #0x20
    0.00 :   ffff80001017e260:       add     x0, x2, x0
    0.00 :   ffff80001017e264:       ldr     x19, [x0, #8]
         : 1187             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff80001017e268:       and     x0, x19, #0x3
         : 171              xas_next_entry():
         : 1642             if (unlikely(xa_is_internal(entry)))
    0.00 :   ffff80001017e26c:       cmp     x0, #0x2
    0.00 :   ffff80001017e270:       b.eq    ffff80001017e290 <next_uptodate_page+0x208>  // b.none
         : 1645             xas->xa_index++;
    0.00 :   ffff80001017e274:       str     x1, [x20, #8]
         : 1644             xas->xa_offset++;
    0.00 :   ffff80001017e278:       strb    w4, [x20, #18]
         : 1646             } while (!entry);
    0.00 :   ffff80001017e27c:       cbnz    x19, ffff80001017e0c8 <next_uptodate_page+0x40>
         : 1637             if (unlikely(xas->xa_index >= max))
    0.00 :   ffff80001017e280:       cmp     x26, x1
         : 1645             xas->xa_index++;
    0.00 :   ffff80001017e284:       add     x1, x1, #0x1
         : 1637             if (unlikely(xas->xa_index >= max))
    0.00 :   ffff80001017e288:       b.hi    ffff80001017e248 <next_uptodate_page+0x1c0>  // b.pmore
    0.00 :   ffff80001017e28c:       nop
         : 1638             return xas_find(xas, max);
    0.00 :   ffff80001017e290:       mov     x1, x26
    0.00 :   ffff80001017e294:       mov     x0, x20
    0.00 :   ffff80001017e298:       bl      ffff8000104bd3f0 <xas_find>
    0.00 :   ffff80001017e29c:       mov     x19, x0
         : 1643             next_uptodate_page():
         : 3154             skip:
         : 3155             put_page(page);
         : 3156             } while ((page = xas_next_entry(xas, end_pgoff)) != NULL);
    0.00 :   ffff80001017e2a0:       cbnz    x0, ffff80001017e0c8 <next_uptodate_page+0x40>
         : 3124             return NULL;
    0.00 :   ffff80001017e2a4:       mov     x0, #0x0                        // #0
         :
         : 3158             return NULL;
         : 3159             }
    0.00 :   ffff80001017e2a8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001017e2ac:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001017e2b0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001017e2b4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001017e2b8:       ldp     x29, x30, [sp], #80
    0.00 :   ffff80001017e2bc:       autiasp
    0.00 :   ffff80001017e2c0:       ret
         : 3167             arch_atomic_fetch_add_unless():
         : 1161             if (unlikely(c == u))
    0.00 :   ffff80001017e2c4:       mov     w4, w0
    0.00 :   ffff80001017e2c8:       cbnz    w0, ffff80001017e100 <next_uptodate_page+0x78>
    0.00 :   ffff80001017e2cc:       b       ffff80001017e208 <next_uptodate_page+0x180>
         : 1165             __ll_sc__cmpxchg_case_mb_32():
         : 313              __CMPXCHG_CASE(w, h, rel_, 16,        ,  , l, "memory", K)
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
         : 316              __CMPXCHG_CASE(w, b,  mb_,  8, dmb ish,  , l, "memory", K)
         : 317              __CMPXCHG_CASE(w, h,  mb_, 16, dmb ish,  , l, "memory", K)
         : 318              __CMPXCHG_CASE(w,  ,  mb_, 32, dmb ish,  , l, "memory", K)
    0.00 :   ffff80001017e2d0:       and     x1, x1, #0xffffffff
    0.00 :   ffff80001017e2d4:       b       ffff800010184494 <generic_file_write_iter+0x33c>
    0.00 :   ffff80001017e2d8:       b       ffff80001017e120 <next_uptodate_page+0x98>
         : 322              xas_reset():
         : 1471             xas->xa_node = XAS_RESTART;
    0.00 :   ffff80001017e2dc:       str     x21, [x20, #24]
         : 1473             xas_next_entry():
         : 1638             return xas_find(xas, max);
    0.00 :   ffff80001017e2e0:       mov     x1, x26
    0.00 :   ffff80001017e2e4:       mov     x0, x20
    0.00 :   ffff80001017e2e8:       bl      ffff8000104bd3f0 <xas_find>
    0.00 :   ffff80001017e2ec:       mov     x19, x0
         : 1643             next_uptodate_page():
         : 3154             } while ((page = xas_next_entry(xas, end_pgoff)) != NULL);
    0.00 :   ffff80001017e2f0:       cbnz    x0, ffff80001017e0c8 <next_uptodate_page+0x40>
    0.00 :   ffff80001017e2f4:       b       ffff80001017e2a4 <next_uptodate_page+0x21c>
         : 3157             __ll_sc_atomic_sub_return():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001017e2f8:       b       ffff8000101844b4 <generic_file_write_iter+0x35c>
         : 114              put_page():
    0.00 :   ffff80001017e2fc:       cbnz    w0, ffff80001017e208 <next_uptodate_page+0x180>
         : 1243             }
    0.00 :   ffff80001017e300:       mov     x0, x19
    0.00 :   ffff80001017e304:       bl      ffff80001018d6f0 <__put_page>
    0.00 :   ffff80001017e308:       b       ffff80001017e208 <next_uptodate_page+0x180>
         : 1247             xas_reload():
         : 1555             return xa_head(xas->xa);
    0.00 :   ffff80001017e30c:       ldr     x0, [x20]
         : 1557             xa_head():
         : 1166             return rcu_dereference_check(xa->xa_head,
    0.00 :   ffff80001017e310:       ldr     x0, [x0, #8]
    0.00 :   ffff80001017e314:       b       ffff80001017e16c <next_uptodate_page+0xe4>
         : 1169             compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001017e318:       sub     x19, x0, #0x1
    0.00 :   ffff80001017e31c:       add     x25, x0, #0x33
    0.00 :   ffff80001017e320:       b       ffff80001017e1e8 <next_uptodate_page+0x160>
         : 191              __ll_sc_atomic64_fetch_or_acquire():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001017e324:       b       ffff8000101844d0 <generic_file_write_iter+0x378>
    0.00 :   ffff80001017e328:       b       ffff80001017e1c8 <next_uptodate_page+0x140>
         : 225              compound_head():
         : 184              {
    0.00 :   ffff80001017e32c:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001017e330:       sub     x0, x1, #0x1
    0.00 :   ffff80001017e334:       tst     x1, #0x1
    0.00 :   ffff80001017e338:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001017e33c:       ldr     x0, [x0]
         : 107              PageUptodate():
         : 525              ret = test_bit(PG_uptodate, &(page)->flags);
    0.00 :   ffff80001017e340:       tbz     w0, #2, ffff80001017e1d8 <next_uptodate_page+0x150>
         : 526              /*
    0.00 :   ffff80001017e344:       dmb     ishld
         : 528              next_uptodate_page():
         : 3146             max_idx = DIV_ROUND_UP(i_size_read(mapping->host), PAGE_SIZE);
    0.00 :   ffff80001017e348:       ldr     x0, [x23]
         : 3147             if (xas->xa_index >= max_idx)
    0.00 :   ffff80001017e34c:       ldr     x1, [x20, #8]
         : 3146             max_idx = DIV_ROUND_UP(i_size_read(mapping->host), PAGE_SIZE);
    0.00 :   ffff80001017e350:       ldr     x0, [x0, #80]
    0.00 :   ffff80001017e354:       add     x0, x0, #0xfff
         : 3147             if (xas->xa_index >= max_idx)
    0.00 :   ffff80001017e358:       cmp     x1, x0, lsr #12
    0.00 :   ffff80001017e35c:       b.cs    ffff80001017e1d8 <next_uptodate_page+0x150>  // b.hs, b.nlast
    0.00 :   ffff80001017e360:       mov     x0, x19
    0.00 :   ffff80001017e364:       b       ffff80001017e2a8 <next_uptodate_page+0x220>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010120a48 <tick_nohz_next_event>:
         : 6                tick_nohz_next_event():
         : 734              if (ts->idle_active && nr_iowait_cpu(cpu) > 0) {
         : 735              ktime_t delta = ktime_sub(now, ts->idle_entrytime);
         :
         : 737              iowait = ktime_add(ts->iowait_sleeptime, delta);
         : 738              } else {
         : 739              iowait = ts->iowait_sleeptime;
    0.00 :   ffff800010120a48:       paciasp
    0.00 :   ffff800010120a4c:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff800010120a50:       adrp    x4, ffff800011f4e000 <posix_timers_hashtable+0xc18>
    0.00 :   ffff800010120a54:       mov     x29, sp
    0.00 :   ffff800010120a58:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010120a5c:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010120a60:       add     x21, x21, #0x948
    0.00 :   ffff800010120a64:       mov     w22, w1
    0.00 :   ffff800010120a68:       adrp    x3, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010120a6c:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010120a70:       add     x4, x4, #0x578
    0.00 :   ffff800010120a74:       add     x1, x1, #0x9c0
    0.00 :   ffff800010120a78:       add     x3, x3, #0x980
    0.00 :   ffff800010120a7c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010120a80:       mov     x20, x0
    0.00 :   ffff800010120a84:       ldr     x0, [x21]
    0.00 :   ffff800010120a88:       str     x0, [sp, #72]
    0.00 :   ffff800010120a8c:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010120a90:       str     x23, [sp, #48]
    0.00 :   ffff800010120a94:       b       ffff800010120a9c <tick_nohz_next_event+0x54>
         : 760              cpu_relax():
         :
         : 13               #ifndef __ASSEMBLY__
         :
         : 15               static inline void cpu_relax(void)
         : 16               {
         : 17               asm volatile("yield" ::: "memory");
    0.00 :   ffff800010120a98:       yield
         : 19               __seqprop_raw_spinlock_sequence():
         : 276              lockdep_assert_preemption_disabled();
         : 277              }
         :
         : 279              #define __SEQ_RT        IS_ENABLED(CONFIG_PREEMPT_RT)
         :
         : 281              SEQCOUNT_LOCKNAME(raw_spinlock, raw_spinlock_t,  false,    s->lock,        raw_spin, raw_spin_lock(s->lock))
    0.00 :   ffff800010120a9c:       ldr     w0, [x1]
         : 283              tick_nohz_next_event():
         : 741              }
         :
         : 743              return ktime_to_us(iowait);
         : 744              }
         : 745              EXPORT_SYMBOL_GPL(get_cpu_iowait_time_us);
         :
    0.00 :   ffff800010120aa0:       tbnz    w0, #0, ffff800010120a98 <tick_nohz_next_event+0x50>
    0.00 :   ffff800010120aa4:       dmb     ishld
         : 743              static void tick_nohz_restart(struct tick_sched *ts, ktime_t now)
         : 744              {
    0.00 :   ffff800010120aa8:       ldr     x23, [x3]
         : 742              static void tick_nohz_restart(struct tick_sched *ts, ktime_t now)
    0.00 :   ffff800010120aac:       ldr     x19, [x4]
         : 744              do_read_seqcount_retry():
         : 452              #define read_seqcount_retry(s, start)                                   \
         : 453              do_read_seqcount_retry(seqprop_ptr(s), start)
         :
         : 455              static inline int do_read_seqcount_retry(const seqcount_t *s, unsigned start)
         : 456              {
         : 457              smp_rmb();
  100.00 :   ffff800010120ab0:       dmb     ishld
         : 459              do___read_seqcount_retry():
         : 433              return unlikely(READ_ONCE(s->sequence) != start);
    0.00 :   ffff800010120ab4:       ldr     w2, [x1]
         : 435              tick_nohz_next_event():
         : 744              hrtimer_cancel(&ts->sched_timer);
    0.00 :   ffff800010120ab8:       cmp     w2, w0
    0.00 :   ffff800010120abc:       b.ne    ffff800010120a9c <tick_nohz_next_event+0x54>  // b.any
         : 745              hrtimer_set_expires(&ts->sched_timer, ts->last_tick);
    0.00 :   ffff800010120ac0:       str     x23, [x20, #160]
         : 758              } else {
         : 759              tick_program_event(hrtimer_get_expires(&ts->sched_timer), 1);
         : 760              }
         :
         : 762              /*
         : 763              * Reset to make sure next tick stop doesn't get fooled by past
    0.00 :   ffff800010120ac4:       add     x1, sp, #0x40
         :
    0.00 :   ffff800010120ac8:       str     x19, [x20, #176]
         : 758              * Reset to make sure next tick stop doesn't get fooled by past
    0.00 :   ffff800010120acc:       mov     x0, x19
    0.00 :   ffff800010120ad0:       bl      ffff800010104378 <rcu_needs_cpu>
    0.00 :   ffff800010120ad4:       cbz     w0, ffff800010120b54 <tick_nohz_next_event+0x10c>
         : 760              * cached clock deadline.
         : 761              */
    0.00 :   ffff800010120ad8:       add     x23, x19, #0x3d0, lsl #12
    0.00 :   ffff800010120adc:       add     x23, x23, #0x900
         : 785              } while (read_seqcount_retry(&jiffies_seq, seq));
         : 786              ts->last_jiffies = basejiff;
         : 787              ts->timer_expires_base = basemono;
         :
         : 789              /*
         : 790              * Keep the periodic tick, when RCU, architecture or irq_work
    0.00 :   ffff800010120ae0:       bl      ffff80001010ef10 <timer_clear_idle>
         : 790              * requests it.
         : 791              * Aside of that check whether the local timer softirq is
         : 792              * pending. If so its a bad idea to call get_next_timer_interrupt()
         : 793              * because there is an already expired timer, so it will request
         : 794              * immediate expiry, which rearms the hardware timer with a
    0.00 :   ffff800010120ae4:       ldrb    w0, [x20, #76]
    0.00 :   ffff800010120ae8:       tbz     w0, #1, ffff800010120bbc <tick_nohz_next_event+0x174>
         : 801              next_tick = basemono + TICK_NSEC;
         : 802              } else {
         : 803              /*
         : 804              * Get the next pending timer. If high resolution
         : 805              * timers are enabled this only takes the timer wheel
         : 806              * timers into account. If high resolution timers are
    0.00 :   ffff800010120aec:       bl      ffff800010112d30 <timekeeping_max_deferment>
         : 802              * disabled this also looks at the next expiring
    0.00 :   ffff800010120af0:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010120af4:       ldr     w1, [x1, #3072]
    0.00 :   ffff800010120af8:       cmp     w1, w22
    0.00 :   ffff800010120afc:       b.eq    ffff800010120b0c <tick_nohz_next_event+0xc4>  // b.none
    0.00 :   ffff800010120b00:       cmn     w1, #0x1
    0.00 :   ffff800010120b04:       b.eq    ffff800010120ba8 <tick_nohz_next_event+0x160>  // b.none
         : 804              * hrtimer.
         : 805              */
    0.00 :   ffff800010120b08:       mov     x0, #0x7fffffffffffffff         // #9223372036854775807
         : 807              next_tmr = get_next_timer_interrupt(basejiff, basemono);
         : 808              ts->next_timer = next_tmr;
         : 809              /* Take the next rcu event into account */
    0.00 :   ffff800010120b0c:       mov     x1, #0x7fffffffffffffff         // #9223372036854775807
    0.00 :   ffff800010120b10:       sub     x2, x1, x19
         : 808              next_tick = next_rcu < next_tmr ? next_rcu : next_tmr;
    0.00 :   ffff800010120b14:       cmp     x2, x0
    0.00 :   ffff800010120b18:       add     x0, x0, x19
    0.00 :   ffff800010120b1c:       csel    x0, x0, x1, hi  // hi = pmore
         : 812              }
         :
         : 814              /*
         : 815              * If the tick is due in the next period, keep it ticking or
    0.00 :   ffff800010120b20:       cmp     x0, x23
    0.00 :   ffff800010120b24:       csel    x0, x0, x23, ls  // ls = plast
    0.00 :   ffff800010120b28:       str     x0, [x20, #168]
         : 816              * force prod the timer.
         : 817              */
         : 818              delta = next_tick - basemono;
         : 819              if (delta <= (u64)TICK_NSEC) {
    0.00 :   ffff800010120b2c:       ldr     x2, [sp, #72]
    0.00 :   ffff800010120b30:       ldr     x1, [x21]
    0.00 :   ffff800010120b34:       eor     x1, x2, x1
    0.00 :   ffff800010120b38:       cbnz    x1, ffff800010120bc8 <tick_nohz_next_event+0x180>
    0.00 :   ffff800010120b3c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010120b40:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010120b44:       ldr     x23, [sp, #48]
    0.00 :   ffff800010120b48:       ldp     x29, x30, [sp], #80
    0.00 :   ffff800010120b4c:       autiasp
    0.00 :   ffff800010120b50:       ret
         : 759              * cached clock deadline.
    0.00 :   ffff800010120b54:       bl      ffff80001015da70 <irq_work_needs_cpu>
         : 758              * Reset to make sure next tick stop doesn't get fooled by past
    0.00 :   ffff800010120b58:       tst     w0, #0xff
    0.00 :   ffff800010120b5c:       b.ne    ffff800010120ad8 <tick_nohz_next_event+0x90>  // b.any
         : 761              local_timer_softirq_pending():
         : 730              ktime_t delta = ktime_sub(now, ts->idle_entrytime);
    0.00 :   ffff800010120b60:       adrp    x0, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff800010120b64:       add     x0, x0, #0x580
         : 733              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010120b68:       mrs     x1, tpidr_el1
         : 46               tick_nohz_next_event():
         : 759              * cached clock deadline.
    0.00 :   ffff800010120b6c:       ldr     w0, [x0, x1]
    0.00 :   ffff800010120b70:       tbnz    w0, #1, ffff800010120ad8 <tick_nohz_next_event+0x90>
         : 769              static ktime_t tick_nohz_next_event(struct tick_sched *ts, int cpu)
    0.00 :   ffff800010120b74:       mov     x0, x23
    0.00 :   ffff800010120b78:       mov     x1, x19
    0.00 :   ffff800010120b7c:       bl      ffff80001010ed78 <get_next_timer_interrupt>
         : 770              {
    0.00 :   ffff800010120b80:       str     x0, [x20, #184]
         : 772              unsigned long basejiff;
    0.00 :   ffff800010120b84:       ldr     x23, [sp, #64]
         : 780              } while (read_seqcount_retry(&jiffies_seq, seq));
    0.00 :   ffff800010120b88:       mov     x1, #0x900                      // #2304
    0.00 :   ffff800010120b8c:       movk    x1, #0x3d, lsl #16
         : 772              unsigned long basejiff;
    0.00 :   ffff800010120b90:       cmp     x23, x0
    0.00 :   ffff800010120b94:       csel    x23, x23, x0, ls  // ls = plast
         : 779              basejiff = jiffies;
    0.00 :   ffff800010120b98:       sub     x0, x23, x19
         : 780              } while (read_seqcount_retry(&jiffies_seq, seq));
    0.00 :   ffff800010120b9c:       cmp     x0, x1
    0.00 :   ffff800010120ba0:       b.hi    ffff800010120aec <tick_nohz_next_event+0xa4>  // b.pmore
    0.00 :   ffff800010120ba4:       b       ffff800010120ae0 <tick_nohz_next_event+0x98>
         : 803              * hrtimer.
    0.00 :   ffff800010120ba8:       ldrb    w2, [x20, #76]
         : 804              */
    0.00 :   ffff800010120bac:       mov     x1, #0x7fffffffffffffff         // #9223372036854775807
    0.00 :   ffff800010120bb0:       tst     x2, #0x8
    0.00 :   ffff800010120bb4:       csel    x0, x0, x1, ne  // ne = any
    0.00 :   ffff800010120bb8:       b       ffff800010120b0c <tick_nohz_next_event+0xc4>
         : 792              * immediately. Lather, rinse and repeat...
    0.00 :   ffff800010120bbc:       mov     x0, #0x0                        // #0
         : 791              * minimal delta which brings us back to this place
    0.00 :   ffff800010120bc0:       str     xzr, [x20, #168]
         : 792              * immediately. Lather, rinse and repeat...
    0.00 :   ffff800010120bc4:       b       ffff800010120b2c <tick_nohz_next_event+0xe4>
         : 816              if (delta <= (u64)TICK_NSEC) {
    0.00 :   ffff800010120bc8:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (259 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e349f0 <_raw_spin_unlock>:
         : 6                _raw_spin_unlock():
         : 182              EXPORT_SYMBOL(_raw_spin_lock_bh);
         : 183              #endif
         :
         : 185              #ifdef CONFIG_UNINLINE_SPIN_UNLOCK
         : 186              void __lockfunc _raw_spin_unlock(raw_spinlock_t *lock)
         : 187              {
   25.46 :   ffff800010e349f0:       paciasp
    0.00 :   ffff800010e349f4:       stp     x29, x30, [sp, #-16]!
         : 190              queued_spin_unlock():
         : 99               static __always_inline void queued_spin_unlock(struct qspinlock *lock)
         : 100              {
         : 101              /*
         : 102              * unlock() needs release semantics:
         : 103              */
         : 104              smp_store_release(&lock->locked, 0);
    0.00 :   ffff800010e349f8:       mov     w1, #0x0                        // #0
         : 106              _raw_spin_unlock():
    0.00 :   ffff800010e349fc:       mov     x29, sp
         : 183              queued_spin_unlock():
    0.00 :   ffff800010e34a00:       stlrb   w1, [x0]
         : 100              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
   74.17 :   ffff800010e34a04:       mrs     x1, sp_el0
         : 26               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34a08:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e34a0c:       sub     x0, x0, #0x1
    0.00 :   ffff800010e34a10:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34a14:       cbnz    x0, ffff800010e34a28 <_raw_spin_unlock+0x38>
         : 80               __raw_spin_unlock():
         :
         : 153              static inline void __raw_spin_unlock(raw_spinlock_t *lock)
         : 154              {
         : 155              spin_release(&lock->dep_map, _RET_IP_);
         : 156              do_raw_spin_unlock(lock);
         : 157              preempt_enable();
    0.00 :   ffff800010e34a18:       bl      ffff800010e2e620 <preempt_schedule>
         : 159              _raw_spin_unlock():
         : 184              __raw_spin_unlock(lock);
         : 185              }
    0.07 :   ffff800010e34a1c:       ldp     x29, x30, [sp], #16
    0.30 :   ffff800010e34a20:       autiasp
    0.00 :   ffff800010e34a24:       ret
         : 189              __preempt_count_dec_and_test():
    0.00 :   ffff800010e34a28:       ldr     x0, [x1, #8]
    0.00 :   ffff800010e34a2c:       cbnz    x0, ffff800010e34a1c <_raw_spin_unlock+0x2c>
         : 75               __raw_spin_unlock():
    0.00 :   ffff800010e34a30:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010e34a34:       b       ffff800010e34a1c <_raw_spin_unlock+0x2c>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000103132b8 <ext4_da_write_begin>:
         : 6                ext4_da_write_begin():
         : 2945             }
         :
         : 2947             static int ext4_da_write_begin(struct file *file, struct address_space *mapping,
         : 2948             loff_t pos, unsigned len, unsigned flags,
         : 2949             struct page **pagep, void **fsdata)
         : 2950             {
    0.00 :   ffff8000103132b8:       paciasp
    0.00 :   ffff8000103132bc:       stp     x29, x30, [sp, #-144]!
    0.00 :   ffff8000103132c0:       mov     x29, sp
    0.00 :   ffff8000103132c4:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000103132c8:       mov     x25, x1
    0.00 :   ffff8000103132cc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000103132d0:       mov     x19, x0
    0.00 :   ffff8000103132d4:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000103132d8:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000103132dc:       adrp    x27, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000103132e0:       add     x27, x27, #0x948
         : 2949             int ret, retries = 0;
         : 2950             struct page *page;
         : 2951             pgoff_t index;
         : 2952             struct inode *inode = mapping->host;
    0.00 :   ffff8000103132e4:       ldr     x20, [x25]
         : 2945             {
    0.00 :   ffff8000103132e8:       ldr     x1, [x27]
    0.00 :   ffff8000103132ec:       str     x1, [sp, #136]
    0.00 :   ffff8000103132f0:       mov     x1, #0x0                        // #0
    0.00 :   ffff8000103132f4:       str     w4, [sp, #100]
    0.00 :   ffff8000103132f8:       str     x5, [sp, #104]
         : 2952             handle_t *handle;
         :
         : 2954             if (unlikely(ext4_forced_shutdown(EXT4_SB(inode->i_sb))))
    0.00 :   ffff8000103132fc:       ldr     x0, [x20, #40]
         : 2946             int ret, retries = 0;
    0.00 :   ffff800010313300:       str     wzr, [sp, #132]
         : 2952             if (unlikely(ext4_forced_shutdown(EXT4_SB(inode->i_sb))))
    0.00 :   ffff800010313304:       ldr     x1, [x0, #880]
         : 2954             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010313308:       ldr     x1, [x1, #600]
         : 113              ext4_da_write_begin():
    0.00 :   ffff80001031330c:       tst     w1, #0x2
    0.00 :   ffff800010313310:       b.ne    ffff8000103135b4 <ext4_da_write_begin+0x2fc>  // b.any
         : 2957             return -EIO;
         :
         : 2959             index = pos >> PAGE_SHIFT;
         :
         : 2961             if (ext4_nonda_switch(inode->i_sb) || S_ISLNK(inode->i_mode) ||
    0.00 :   ffff800010313314:       mov     x21, x6
    0.00 :   ffff800010313318:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001031331c:       mov     x23, x2
    0.00 :   ffff800010313320:       mov     w24, w3
    0.00 :   ffff800010313324:       bl      ffff80001030b6a8 <ext4_nonda_switch>
    0.00 :   ffff800010313328:       cbnz    w0, ffff800010313520 <ext4_da_write_begin+0x268>
    0.00 :   ffff80001031332c:       ldrh    w0, [x20]
    0.00 :   ffff800010313330:       and     w0, w0, #0xf000
    0.00 :   ffff800010313334:       cmp     w0, #0xa, lsl #12
    0.00 :   ffff800010313338:       b.eq    ffff800010313520 <ext4_da_write_begin+0x268>  // b.none
         : 2963             ext4_verity_in_progress(inode)) {
         : 2964             *fsdata = (void *)FALL_BACK_TO_NONDELALLOC;
         : 2965             return ext4_write_begin(file, mapping, pos,
         : 2966             len, flags, pagep, fsdata);
         : 2967             }
         : 2968             *fsdata = (void *)0;
    0.00 :   ffff80001031333c:       str     xzr, [x21]
         : 2970             test_bit():
    0.00 :   ffff800010313340:       ldur    x0, [x20, #-240]
         : 107              ext4_da_write_begin():
         : 2966             trace_ext4_da_write_begin(inode, pos, len, flags);
         :
         : 2968             if (ext4_test_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA)) {
    0.00 :   ffff800010313344:       tbnz    x0, #39, ffff800010313554 <ext4_da_write_begin+0x29c>
         : 3022             #else
         : 3023             ret = __block_write_begin(page, pos, len, ext4_da_get_block_prep);
         : 3024             #endif
         : 3025             if (ret < 0) {
         : 3026             unlock_page(page);
         : 3027             ext4_journal_stop(handle);
    0.00 :   ffff800010313348:       adrp    x26, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff80001031334c:       add     x26, x26, #0x30
         : 2955             index = pos >> PAGE_SHIFT;
    0.00 :   ffff800010313350:       asr     x0, x23, #12
         : 3022             ext4_journal_stop(handle);
    0.00 :   ffff800010313354:       add     x26, x26, #0x488
         : 2955             index = pos >> PAGE_SHIFT;
    0.00 :   ffff800010313358:       str     x0, [sp, #112]
         : 2957             ext4_truncate_failed_write():
         : 18               {
         : 19               /*
         : 20               * We don't need to call ext4_break_layouts() because the blocks we
         : 21               * are truncating were never visible to userspace.
         : 22               */
         : 23               down_write(&EXT4_I(inode)->i_mmap_sem);
    0.00 :   ffff80001031335c:       sub     x0, x20, #0x140
    0.00 :   ffff800010313360:       str     x0, [sp, #120]
         : 26               ext4_da_write_begin():
         : 2984             page = grab_cache_page_write_begin(mapping, index, flags);
    0.00 :   ffff800010313364:       ldr     w2, [sp, #100]
    0.00 :   ffff800010313368:       mov     x0, x25
   20.75 :   ffff80001031336c:       ldr     x1, [sp, #112]
    0.00 :   ffff800010313370:       bl      ffff8000101816f8 <grab_cache_page_write_begin>
   27.84 :   ffff800010313374:       mov     x19, x0
         : 2985             if (!page)
    0.00 :   ffff800010313378:       cbz     x0, ffff8000103135c4 <ext4_da_write_begin+0x30c>
         : 2987             ext4_truncate_failed_write():
    0.00 :   ffff80001031337c:       ldr     x1, [sp, #120]
    0.00 :   ffff800010313380:       add     x28, x1, #0x118
         : 20               ext4_da_write_begin():
         : 2987             unlock_page(page);
    0.00 :   ffff800010313384:       bl      ffff80001017d860 <unlock_page>
         : 2996             handle = ext4_journal_start(inode, EXT4_HT_WRITE_PAGE,
    0.00 :   ffff800010313388:       ldr     x0, [x20, #40]
         : 2998             ext4_da_write_credits():
         : 2936             return 1;
    0.00 :   ffff80001031338c:       mov     w3, #0x1                        // #1
         : 2938             ext4_has_feature_large_file():
         : 2034             ~cpu_to_le32(EXT4_FEATURE_INCOMPAT_##flagname); \
         : 2035             }
         :
         : 2037             EXT4_FEATURE_COMPAT_FUNCS(dir_prealloc,         DIR_PREALLOC)
         : 2038             EXT4_FEATURE_COMPAT_FUNCS(imagic_inodes,        IMAGIC_INODES)
         : 2039             EXT4_FEATURE_COMPAT_FUNCS(journal,              HAS_JOURNAL)
    0.00 :   ffff800010313390:       ldr     x1, [x0, #880]
    0.00 :   ffff800010313394:       ldr     x2, [x1, #104]
    0.00 :   ffff800010313398:       ldr     w2, [x2, #100]
         : 2043             ext4_da_write_credits():
         : 2932             if (likely(ext4_has_feature_large_file(inode->i_sb)))
    0.00 :   ffff80001031339c:       tbz     w2, #1, ffff800010313508 <ext4_da_write_begin+0x250>
         : 2934             ext4_free_metadata_revoke_credits():
         :
         : 292              static inline int ext4_free_metadata_revoke_credits(struct super_block *sb,
         : 293              int blocks)
         : 294              {
         : 295              /* Freeing each metadata block can result in freeing one cluster */
         : 296              return blocks * EXT4_SB(sb)->s_cluster_ratio;
    0.00 :   ffff8000103133a0:       ldr     w5, [x1, #80]
         : 298              __ext4_journal_start():
         : 320              static inline handle_t *__ext4_journal_start(struct inode *inode,
         : 321              unsigned int line, int type,
         : 322              int blocks, int rsv_blocks,
         : 323              int revoke_creds)
         : 324              {
         : 325              return __ext4_journal_start_sb(inode->i_sb, line, type, blocks,
    0.00 :   ffff8000103133a4:       mov     w4, #0x0                        // #0
    0.00 :   ffff8000103133a8:       mov     w2, #0x2                        // #2
    0.00 :   ffff8000103133ac:       mov     w1, #0xbb5                      // #2997
    0.00 :   ffff8000103133b0:       lsl     w5, w5, #3
    0.00 :   ffff8000103133b4:       bl      ffff8000102f1ff8 <__ext4_journal_start_sb>
    0.00 :   ffff8000103133b8:       mov     x22, x0
         : 332              ext4_da_write_begin():
         : 2998             if (IS_ERR(handle)) {
    0.00 :   ffff8000103133bc:       cmn     x0, #0x1, lsl #12
    0.00 :   ffff8000103133c0:       b.hi    ffff800010313590 <ext4_da_write_begin+0x2d8>  // b.pmore
         : 3001             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff8000103133c4:       ldr     x1, [x19, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff8000103133c8:       sub     x0, x1, #0x1
    0.00 :   ffff8000103133cc:       tst     x1, #0x1
    0.00 :   ffff8000103133d0:       csel    x0, x0, x19, ne  // ne = any
         : 193              test_and_set_bit_lock():
         : 25               {
         : 26               long old;
         : 27               unsigned long mask = BIT_MASK(nr);
         :
         : 29               p += BIT_WORD(nr);
         : 30               if (READ_ONCE(*p) & mask)
    0.00 :   ffff8000103133d4:       ldr     x1, [x0]
    0.00 :   ffff8000103133d8:       tbnz    w1, #0, ffff8000103134a0 <ext4_da_write_begin+0x1e8>
         : 33               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000103133dc:       b       ffff800010313500 <ext4_da_write_begin+0x248>
    0.00 :   ffff8000103133e0:       b       ffff800010313500 <ext4_da_write_begin+0x248>
         : 46               __lse_atomic64_fetch_or_acquire():
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
         : 208              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff8000103133e4:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000103133e8:       ldseta  x1, x1, [x0]
         : 211              lock_page():
         : 624              * lock_page may only be called if we have the page's inode pinned.
         : 625              */
         : 626              static inline void lock_page(struct page *page)
         : 627              {
         : 628              might_sleep();
         : 629              if (!trylock_page(page))
    0.00 :   ffff8000103133ec:       tbnz    w1, #0, ffff8000103134a0 <ext4_da_write_begin+0x1e8>
         : 631              ext4_da_write_begin():
         : 3004             if (page->mapping != mapping) {
   25.65 :   ffff8000103133f0:       ldr     x0, [x19, #24]
    0.00 :   ffff8000103133f4:       cmp     x0, x25
         : 3006             unlock_page(page);
    0.00 :   ffff8000103133f8:       mov     x0, x19
         : 3004             if (page->mapping != mapping) {
    0.00 :   ffff8000103133fc:       b.ne    ffff8000103134b8 <ext4_da_write_begin+0x200>  // b.any
         : 3012             wait_for_stable_page(page);
   25.77 :   ffff800010313400:       bl      ffff8000101886d8 <wait_for_stable_page>
         : 3018             ret = __block_write_begin(page, pos, len, ext4_da_get_block_prep);
    0.00 :   ffff800010313404:       mov     w2, w24
    0.00 :   ffff800010313408:       adrp    x3, ffff80001030c000 <__ext4_get_inode_loc+0x350>
    0.00 :   ffff80001031340c:       mov     x1, x23
    0.00 :   ffff800010313410:       add     x3, x3, #0x610
    0.00 :   ffff800010313414:       mov     x0, x19
    0.00 :   ffff800010313418:       bl      ffff80001027f478 <__block_write_begin>
    0.00 :   ffff80001031341c:       mov     w21, w0
         : 3020             if (ret < 0) {
    0.00 :   ffff800010313420:       tbz     w0, #31, ffff8000103135a4 <ext4_da_write_begin+0x2ec>
         : 3021             unlock_page(page);
    0.00 :   ffff800010313424:       mov     x0, x19
    0.00 :   ffff800010313428:       bl      ffff80001017d860 <unlock_page>
         : 3022             ext4_journal_stop(handle);
    0.00 :   ffff80001031342c:       mov     w1, #0xbce                      // #3022
    0.00 :   ffff800010313430:       mov     x2, x22
    0.00 :   ffff800010313434:       mov     x0, x26
    0.00 :   ffff800010313438:       bl      ffff8000102f20c8 <__ext4_journal_stop>
         : 3028             /*
         : 3029             * block_write_begin may have instantiated a few blocks
         : 3030             * outside i_size.  Trim these off again. Don't need
         : 3031             * i_size_read because we hold i_mutex.
         : 3032             */
         : 3033             if (pos + len > inode->i_size)
    0.00 :   ffff80001031343c:       ldr     x0, [x20, #80]
    0.00 :   ffff800010313440:       add     x1, x23, w24, uxtw
    0.00 :   ffff800010313444:       cmp     x1, x0
    0.00 :   ffff800010313448:       b.gt    ffff8000103134d8 <ext4_da_write_begin+0x220>
         : 3031             ext4_truncate_failed_write(inode);
         :
         : 3033             if (ret == -ENOSPC &&
    0.00 :   ffff80001031344c:       cmn     w21, #0x1c
    0.00 :   ffff800010313450:       b.ne    ffff800010313464 <ext4_da_write_begin+0x1ac>  // b.any
         : 3032             ext4_should_retry_alloc(inode->i_sb, &retries))
    0.00 :   ffff800010313454:       ldr     x0, [x20, #40]
    0.00 :   ffff800010313458:       add     x1, sp, #0x84
    0.00 :   ffff80001031345c:       bl      ffff8000102eed38 <ext4_should_retry_alloc>
         : 3031             if (ret == -ENOSPC &&
    0.00 :   ffff800010313460:       cbnz    w0, ffff800010313388 <ext4_da_write_begin+0xd0>
         : 3035             goto retry_journal;
         :
         : 3037             put_page(page);
    0.00 :   ffff800010313464:       mov     x0, x19
    0.00 :   ffff800010313468:       bl      ffff80001030c4f8 <put_page>
         : 3036             return ret;
    0.00 :   ffff80001031346c:       ldp     x23, x24, [sp, #48]
         : 3041             }
         :
         : 3043             *pagep = page;
         : 3044             return ret;
         : 3045             }
    0.00 :   ffff800010313470:       mov     w0, w21
    0.00 :   ffff800010313474:       ldr     x2, [sp, #136]
    0.00 :   ffff800010313478:       ldr     x1, [x27]
    0.00 :   ffff80001031347c:       eor     x1, x2, x1
    0.00 :   ffff800010313480:       cbnz    x1, ffff8000103135d0 <ext4_da_write_begin+0x318>
    0.00 :   ffff800010313484:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010313488:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001031348c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010313490:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010313494:       ldp     x29, x30, [sp], #144
    0.00 :   ffff800010313498:       autiasp
    0.00 :   ffff80001031349c:       ret
         : 3058             lock_page():
         : 625              __lock_page(page);
    0.00 :   ffff8000103134a0:       mov     x0, x19
    0.00 :   ffff8000103134a4:       bl      ffff80001017eb08 <__lock_page>
         : 628              ext4_da_write_begin():
         : 3004             if (page->mapping != mapping) {
    0.00 :   ffff8000103134a8:       ldr     x0, [x19, #24]
    0.00 :   ffff8000103134ac:       cmp     x0, x25
         : 3006             unlock_page(page);
    0.00 :   ffff8000103134b0:       mov     x0, x19
         : 3004             if (page->mapping != mapping) {
    0.00 :   ffff8000103134b4:       b.eq    ffff800010313400 <ext4_da_write_begin+0x148>  // b.none
         : 3006             unlock_page(page);
    0.00 :   ffff8000103134b8:       bl      ffff80001017d860 <unlock_page>
         : 3007             put_page(page);
    0.00 :   ffff8000103134bc:       mov     x0, x19
    0.00 :   ffff8000103134c0:       bl      ffff80001030c4f8 <put_page>
         : 3008             ext4_journal_stop(handle);
    0.00 :   ffff8000103134c4:       mov     x2, x22
    0.00 :   ffff8000103134c8:       mov     w1, #0xbc0                      // #3008
    0.00 :   ffff8000103134cc:       mov     x0, x26
    0.00 :   ffff8000103134d0:       bl      ffff8000102f20c8 <__ext4_journal_stop>
         : 3009             goto retry_grab;
    0.00 :   ffff8000103134d4:       b       ffff800010313364 <ext4_da_write_begin+0xac>
         : 3011             ext4_truncate_failed_write():
    0.00 :   ffff8000103134d8:       mov     x0, x28
    0.00 :   ffff8000103134dc:       bl      ffff800010e315d0 <down_write>
         : 19               truncate_inode_pages(inode->i_mapping, inode->i_size);
    0.00 :   ffff8000103134e0:       ldr     x0, [x20, #48]
    0.00 :   ffff8000103134e4:       ldr     x1, [x20, #80]
    0.00 :   ffff8000103134e8:       bl      ffff800010191d30 <truncate_inode_pages>
         : 20               ext4_truncate(inode);
    0.00 :   ffff8000103134ec:       mov     x0, x20
    0.00 :   ffff8000103134f0:       bl      ffff800010312ad8 <ext4_truncate>
         : 21               up_write(&EXT4_I(inode)->i_mmap_sem);
    0.00 :   ffff8000103134f4:       mov     x0, x28
    0.00 :   ffff8000103134f8:       bl      ffff8000100d97f8 <up_write>
    0.00 :   ffff8000103134fc:       b       ffff80001031344c <ext4_da_write_begin+0x194>
         : 25               __ll_sc_atomic64_fetch_or_acquire():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010313500:       b       ffff800010315d38 <ext4_filemap_fault+0x5e8>
    0.00 :   ffff800010313504:       b       ffff8000103133ec <ext4_da_write_begin+0x134>
         : 230              ext4_da_write_credits():
         : 2935             if (pos + len <= 0x7fffffffULL)
    0.00 :   ffff800010313508:       add     x2, x23, w24, uxtw
    0.00 :   ffff80001031350c:       mov     x3, #0x7fffffff                 // #2147483647
         : 2939             return 2;
    0.00 :   ffff800010313510:       cmp     x2, x3
    0.00 :   ffff800010313514:       cset    w3, hi  // hi = pmore
    0.00 :   ffff800010313518:       add     w3, w3, #0x1
    0.00 :   ffff80001031351c:       b       ffff8000103133a0 <ext4_da_write_begin+0xe8>
         : 2944             ext4_da_write_begin():
         : 2960             return ext4_write_begin(file, mapping, pos,
    0.00 :   ffff800010313520:       ldr     w4, [sp, #100]
         : 2959             *fsdata = (void *)FALL_BACK_TO_NONDELALLOC;
    0.00 :   ffff800010313524:       mov     x0, #0x1                        // #1
         : 2960             return ext4_write_begin(file, mapping, pos,
    0.00 :   ffff800010313528:       ldr     x5, [sp, #104]
         : 2959             *fsdata = (void *)FALL_BACK_TO_NONDELALLOC;
    0.00 :   ffff80001031352c:       str     x0, [x21]
         : 2960             return ext4_write_begin(file, mapping, pos,
    0.00 :   ffff800010313530:       mov     w3, w24
    0.00 :   ffff800010313534:       mov     x2, x23
    0.00 :   ffff800010313538:       mov     x6, x21
    0.00 :   ffff80001031353c:       mov     x1, x25
    0.00 :   ffff800010313540:       mov     x0, x19
    0.00 :   ffff800010313544:       bl      ffff800010312e58 <ext4_write_begin>
    0.00 :   ffff800010313548:       mov     w21, w0
    0.00 :   ffff80001031354c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010313550:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
         : 2967             ret = ext4_da_write_inline_data_begin(mapping, inode,
    0.00 :   ffff800010313554:       ldr     w4, [sp, #100]
    0.00 :   ffff800010313558:       mov     x6, x21
    0.00 :   ffff80001031355c:       ldr     x5, [sp, #104]
    0.00 :   ffff800010313560:       mov     w3, w24
    0.00 :   ffff800010313564:       mov     x2, x23
    0.00 :   ffff800010313568:       mov     x1, x20
    0.00 :   ffff80001031356c:       mov     x0, x25
    0.00 :   ffff800010313570:       bl      ffff800010308bd0 <ext4_da_write_inline_data_begin>
    0.00 :   ffff800010313574:       mov     w21, w0
         : 2970             if (ret < 0)
    0.00 :   ffff800010313578:       tbnz    w0, #31, ffff8000103135bc <ext4_da_write_begin+0x304>
         : 2972             if (ret == 1)
    0.00 :   ffff80001031357c:       cmp     w0, #0x1
    0.00 :   ffff800010313580:       b.ne    ffff800010313348 <ext4_da_write_begin+0x90>  // b.any
         : 2973             return 0;
    0.00 :   ffff800010313584:       mov     w21, #0x0                       // #0
    0.00 :   ffff800010313588:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001031358c:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
         : 2999             put_page(page);
    0.00 :   ffff800010313590:       mov     x0, x19
         : 3000             return PTR_ERR(handle);
    0.00 :   ffff800010313594:       mov     w21, w22
         : 2999             put_page(page);
    0.00 :   ffff800010313598:       bl      ffff80001030c4f8 <put_page>
         : 3000             return PTR_ERR(handle);
    0.00 :   ffff80001031359c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000103135a0:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
         : 3039             *pagep = page;
    0.00 :   ffff8000103135a4:       ldr     x0, [sp, #104]
    0.00 :   ffff8000103135a8:       str     x19, [x0]
         : 3040             return ret;
    0.00 :   ffff8000103135ac:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000103135b0:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
         : 2953             return -EIO;
    0.00 :   ffff8000103135b4:       mov     w21, #0xfffffffb                // #-5
    0.00 :   ffff8000103135b8:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
    0.00 :   ffff8000103135bc:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000103135c0:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
         : 2986             return -ENOMEM;
    0.00 :   ffff8000103135c4:       mov     w21, #0xfffffff4                // #-12
    0.00 :   ffff8000103135c8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000103135cc:       b       ffff800010313470 <ext4_da_write_begin+0x1b8>
    0.00 :   ffff8000103135d0:       stp     x23, x24, [sp, #48]
         : 3041             }
    0.00 :   ffff8000103135d4:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e354e0 <_raw_spin_lock_irq>:
         : 6                _raw_spin_lock_irq():
         : 166              EXPORT_SYMBOL(_raw_spin_lock_irqsave);
         : 167              #endif
         :
         : 169              #ifndef CONFIG_INLINE_SPIN_LOCK_IRQ
         : 170              void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)
         : 171              {
    0.00 :   ffff800010e354e0:       paciasp
    0.00 :   ffff800010e354e4:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e354e8:       mov     x3, x0
    0.00 :   ffff800010e354ec:       mov     x29, sp
         : 176              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010e354f0:       nop
    0.00 :   ffff800010e354f4:       mov     x0, #0x60                       // #96
         : 29               arch_local_irq_disable():
         : 54               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 56               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 57               }
         :
         : 59               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010e354f8:       msr     daifset, #0x3
         : 61               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
   24.99 :   ffff800010e354fc:       mrs     x1, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
   25.07 :   ffff800010e35500:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff800010e35504:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
   25.03 :   ffff800010e35508:       str     w0, [x1, #8]
         : 50               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e3550c:       b       ffff800010e3553c <_raw_spin_lock_irq+0x5c>
    0.00 :   ffff800010e35510:       b       ffff800010e3553c <_raw_spin_lock_irq+0x5c>
         : 46               __lse__cmpxchg_case_acq_32():
         : 370              __CMPXCHG_CASE(w, h,     , 16,   )
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
         : 372              __CMPXCHG_CASE(x,  ,     , 64,   )
         : 373              __CMPXCHG_CASE(w, b, acq_,  8,  a, "memory")
         : 374              __CMPXCHG_CASE(w, h, acq_, 16,  a, "memory")
         : 375              __CMPXCHG_CASE(w,  , acq_, 32,  a, "memory")
    0.00 :   ffff800010e35514:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010e35518:       mov     x0, x3
    0.00 :   ffff800010e3551c:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e35520:       mov     w4, w1
    0.00 :   ffff800010e35524:       casa    w4, w2, [x3]
   24.91 :   ffff800010e35528:       mov     w0, w4
         : 382              arch_atomic_try_cmpxchg_acquire():
         : 1004             static __always_inline bool
         : 1005             arch_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
         : 1006             {
         : 1007             int r, o = *old;
         : 1008             r = arch_atomic_cmpxchg_acquire(v, o, new);
         : 1009             if (unlikely(r != o))
    0.00 :   ffff800010e3552c:       cbnz    w0, ffff800010e3554c <_raw_spin_lock_irq+0x6c>
         : 1011             _raw_spin_lock_irq():
         : 168              __raw_spin_lock_irq(lock);
         : 169              }
    0.00 :   ffff800010e35530:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e35534:       autiasp
    0.00 :   ffff800010e35538:       ret
         : 173              __ll_sc__cmpxchg_case_acq_32():
         : 305              __CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
         : 307              __CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
         : 308              __CMPXCHG_CASE(w, b, acq_,  8,        , a,  , "memory", K)
         : 309              __CMPXCHG_CASE(w, h, acq_, 16,        , a,  , "memory", K)
         : 310              __CMPXCHG_CASE(w,  , acq_, 32,        , a,  , "memory", K)
    0.00 :   ffff800010e3553c:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010e35540:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e35544:       b       ffff800010e35948 <_raw_read_lock_irqsave+0x250>
         : 314              arch_atomic_try_cmpxchg_acquire():
    0.00 :   ffff800010e35548:       cbz     w0, ffff800010e35530 <_raw_spin_lock_irq+0x50>
         : 1005             queued_spin_lock():
         : 85               int val = 0;
         :
         : 87               if (likely(atomic_try_cmpxchg_acquire(&lock->val, &val, _Q_LOCKED_VAL)))
         : 88               return;
         :
         : 90               queued_spin_lock_slowpath(lock, val);
    0.00 :   ffff800010e3554c:       mov     w1, w0
    0.00 :   ffff800010e35550:       mov     x0, x3
    0.00 :   ffff800010e35554:       bl      ffff8000100dac80 <queued_spin_lock_slowpath>
    0.00 :   ffff800010e35558:       b       ffff800010e35530 <_raw_spin_lock_irq+0x50>
         : 95               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010e3555c:       mov     x0, #0xa0                       // #160
    0.00 :   ffff800010e35560:       b       ffff800010e354f8 <_raw_spin_lock_irq+0x18>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104c6938 <gic_handle_irq>:
         : 6                gic_handle_irq():
         : 646              if (irqs_enabled)
         : 647              nmi_exit();
         : 648              }
         :
         : 650              static asmlinkage void __exception_irq_entry gic_handle_irq(struct pt_regs *regs)
         : 651              {
    0.00 :   ffff8000104c6938:       paciasp
    0.00 :   ffff8000104c693c:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff8000104c6940:       mov     x29, sp
    0.00 :   ffff8000104c6944:       stp     x19, x20, [sp, #16]
         : 656              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000104c6948:       b       ffff8000104c6978 <gic_handle_irq+0x40>
         : 45               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff8000104c694c:       nop
         : 23               gic_read_iar_common():
         :
         : 46               static inline u64 gic_read_iar_common(void)
         : 47               {
         : 48               u64 irqstat;
         :
         : 50               irqstat = read_sysreg_s(SYS_ICC_IAR1_EL1);
    0.00 :   ffff8000104c6950:       mrs     x19, s3_0_c12_c12_0
         : 46               dsb(sy);
    0.00 :   ffff8000104c6954:       dsb     sy
         : 48               gic_handle_irq():
         : 652              u32 irqnr;
         :
         : 654              irqnr = gic_read_iar();
         :
         : 656              /* Check for special IDs first */
         : 657              if ((irqnr >= 1020 && irqnr <= 1023))
    0.00 :   ffff8000104c6958:       sub     w1, w19, #0x3fc
         : 649              irqnr = gic_read_iar();
    0.00 :   ffff8000104c695c:       mov     w20, w19
         : 652              if ((irqnr >= 1020 && irqnr <= 1023))
    0.00 :   ffff8000104c6960:       cmp     w1, #0x3
    0.00 :   ffff8000104c6964:       b.hi    ffff8000104c69cc <gic_handle_irq+0x94>  // b.pmore
         :
         : 676              if (handle_domain_irq(gic_data.domain, irqnr, regs)) {
         : 677              WARN_ONCE(true, "Unexpected interrupt received!\n");
         : 678              gic_deactivate_unhandled(irqnr);
         : 679              }
         : 680              }
    0.00 :   ffff8000104c6968:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104c696c:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000104c6970:       autiasp
    0.00 :   ffff8000104c6974:       ret
         : 685              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000104c6978:       adrp    x1, ffff800011f1e000 <reset_devices>
    0.00 :   ffff8000104c697c:       ldr     x1, [x1, #1296]
         : 114              gic_read_iar():
         : 219              if (cpus_have_const_cap(ARM64_WORKAROUND_CAVIUM_23154))
    0.00 :   ffff8000104c6980:       tbz     x1, #50, ffff8000104c6950 <gic_handle_irq+0x18>
         : 221              gic_read_iar_cavium_thunderx():
         : 61               */
         : 62               static inline u64 gic_read_iar_cavium_thunderx(void)
         : 63               {
         : 64               u64 irqstat;
         :
         : 66               nops(8);
    0.00 :   ffff8000104c6984:       nop
    0.00 :   ffff8000104c6988:       nop
    0.00 :   ffff8000104c698c:       nop
    0.00 :   ffff8000104c6990:       nop
    0.00 :   ffff8000104c6994:       nop
    0.00 :   ffff8000104c6998:       nop
    0.00 :   ffff8000104c699c:       nop
    0.00 :   ffff8000104c69a0:       nop
         : 62               irqstat = read_sysreg_s(SYS_ICC_IAR1_EL1);
    0.00 :   ffff8000104c69a4:       mrs     x19, s3_0_c12_c12_0
         : 63               nops(4);
    0.00 :   ffff8000104c69a8:       nop
    0.00 :   ffff8000104c69ac:       nop
    0.00 :   ffff8000104c69b0:       nop
    0.00 :   ffff8000104c69b4:       nop
         : 64               mb();
    0.00 :   ffff8000104c69b8:       dsb     sy
         : 66               gic_handle_irq():
         : 652              if ((irqnr >= 1020 && irqnr <= 1023))
    0.00 :   ffff8000104c69bc:       sub     w1, w19, #0x3fc
         : 649              irqnr = gic_read_iar();
    0.00 :   ffff8000104c69c0:       mov     w20, w19
         : 652              if ((irqnr >= 1020 && irqnr <= 1023))
    0.00 :   ffff8000104c69c4:       cmp     w1, #0x3
    0.00 :   ffff8000104c69c8:       b.ls    ffff8000104c6968 <gic_handle_irq+0x30>  // b.plast
    0.00 :   ffff8000104c69cc:       mov     x3, x0
         : 656              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff8000104c69d0:       b       ffff8000104c69e0 <gic_handle_irq+0xa8>
         : 40               gic_read_rpr():
         : 119              write_sysreg_s(val, SYS_ICC_PMR_EL1);
         : 120              }
         :
         : 122              static inline u32 gic_read_rpr(void)
         : 123              {
         : 124              return read_sysreg_s(SYS_ICC_RPR_EL1);
    0.00 :   ffff8000104c69d4:       mrs     x1, s3_0_c12_c11_3
         : 126              gic_handle_irq():
         : 655              if (gic_supports_nmi() &&
    0.00 :   ffff8000104c69d8:       cmp     w1, #0x20
    0.00 :   ffff8000104c69dc:       b.eq    ffff8000104c6a6c <gic_handle_irq+0x134>  // b.none
         : 658              arch_static_branch_jump():
    0.00 :   ffff8000104c69e0:       b       ffff8000104c6a38 <gic_handle_irq+0x100>
         : 39               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff8000104c69e4:       nop
    0.00 :   ffff8000104c69e8:       nop
         : 22               gic_write_eoir():
         : 31               write_sysreg_s(irq, SYS_ICC_EOIR1_EL1);
    0.00 :   ffff8000104c69ec:       and     x19, x19, #0xffffffff
    0.00 :   ffff8000104c69f0:       msr     s3_0_c12_c12_1, x19
         : 32               isb();
    0.00 :   ffff8000104c69f4:       isb
         : 34               gic_handle_irq():
         : 671              if (handle_domain_irq(gic_data.domain, irqnr, regs)) {
   49.99 :   ffff8000104c69f8:       adrp    x4, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
         : 673              handle_domain_irq():
         :
         : 177              #ifdef CONFIG_HANDLE_DOMAIN_IRQ
         : 178              int handle_domain_irq(struct irq_domain *domain,
         : 179              unsigned int hwirq, struct pt_regs *regs);
         :
         : 181              int handle_domain_nmi(struct irq_domain *domain, unsigned int hwirq,
    0.00 :   ffff8000104c69fc:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000104c6a00:       mov     w1, w20
    0.00 :   ffff8000104c6a04:       ldr     x0, [x4, #2768]
    0.00 :   ffff8000104c6a08:       bl      ffff8000100eb950 <__handle_domain_irq>
         : 186              gic_handle_irq():
    0.00 :   ffff8000104c6a0c:       cbz     w0, ffff8000104c6968 <gic_handle_irq+0x30>
         : 672              WARN_ONCE(true, "Unexpected interrupt received!\n");
    0.00 :   ffff8000104c6a10:       adrp    x1, ffff800011efe000 <errmap+0xc38>
    0.00 :   ffff8000104c6a14:       add     x1, x1, #0xb52
    0.00 :   ffff8000104c6a18:       ldrb    w0, [x1, #1]
    0.00 :   ffff8000104c6a1c:       cbz     w0, ffff8000104c6b74 <gic_handle_irq+0x23c>
         : 673              gic_deactivate_unhandled(irqnr);
    0.00 :   ffff8000104c6a20:       mov     w0, w20
    0.00 :   ffff8000104c6a24:       bl      ffff8000104c5418 <gic_deactivate_unhandled>
         : 675              }
    0.00 :   ffff8000104c6a28:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104c6a2c:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000104c6a30:       autiasp
    0.00 :   ffff8000104c6a34:       ret
         : 680              test_bit():
    0.00 :   ffff8000104c6a38:       adrp    x1, ffff800011f1e000 <reset_devices>
    0.00 :   ffff8000104c6a3c:       ldr     x1, [x1, #1296]
         : 108              gic_handle_irq():
         : 661              if (gic_prio_masking_enabled()) {
    0.00 :   ffff8000104c6a40:       tst     w1, #0x80000
    0.00 :   ffff8000104c6a44:       b.eq    ffff8000104c69e8 <gic_handle_irq+0xb0>  // b.none
         : 664              arch_static_branch():
    0.00 :   ffff8000104c6a48:       nop
    0.00 :   ffff8000104c6a4c:       mov     x1, #0x60                       // #96
         : 23               gic_write_pmr():
         : 114              write_sysreg_s(val, SYS_ICC_PMR_EL1);
    0.00 :   ffff8000104c6a50:       msr     s3_0_c4_c6_0, x1
         : 116              gic_arch_enable_irqs():
         : 176              GIC_PRIO_PSR_I_SET));
         : 177              gic_write_pmr(GIC_PRIO_IRQOFF);
         : 178              }
         :
         : 180              static inline void gic_arch_enable_irqs(void)
         : 181              {
    0.00 :   ffff8000104c6a54:       msr     daifclr, #0x3
   50.01 :   ffff8000104c6a58:       b       ffff8000104c69e8 <gic_handle_irq+0xb0>
         : 184              gic_handle_irq():
         : 669              isb();
    0.00 :   ffff8000104c6a5c:       isb
    0.00 :   ffff8000104c6a60:       b       ffff8000104c69f8 <gic_handle_irq+0xc0>
         : 672              arch_static_branch():
    0.00 :   ffff8000104c6a64:       mov     x1, #0xa0                       // #160
    0.00 :   ffff8000104c6a68:       b       ffff8000104c6a50 <gic_handle_irq+0x118>
         : 23               gic_handle_nmi():
         : 623              bool irqs_enabled = interrupts_enabled(regs);
    0.00 :   ffff8000104c6a6c:       str     x21, [sp, #32]
    0.00 :   ffff8000104c6a70:       ldr     x1, [x0, #264]
    0.00 :   ffff8000104c6a74:       tbnz    w1, #7, ffff8000104c6bac <gic_handle_irq+0x274>
         : 627              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff8000104c6a78:       b       ffff8000104c6b90 <gic_handle_irq+0x258>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff8000104c6a7c:       nop
         : 23               is_kernel_in_hyp_mode():
         : 106              return __boot_cpu_mode[0] != __boot_cpu_mode[1];
         : 107              }
         :
         : 109              static inline bool is_kernel_in_hyp_mode(void)
         : 110              {
         : 111              return read_sysreg(CurrentEL) == CurrentEL_EL2;
    0.00 :   ffff8000104c6a80:       mrs     x0, currentel
         : 113              gic_handle_nmi():
         : 627              nmi_enter();
    0.00 :   ffff8000104c6a84:       cmp     x0, #0x8
    0.00 :   ffff8000104c6a88:       b.eq    ffff8000104c6bb4 <gic_handle_irq+0x27c>  // b.none
    0.00 :   ffff8000104c6a8c:       str     x3, [sp, #56]
    0.00 :   ffff8000104c6a90:       bl      ffff800010e2b908 <printk_nmi_enter>
         : 632              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000104c6a94:       mrs     x4, sp_el0
         : 26               preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000104c6a98:       ldr     w1, [x4, #8]
         : 19               gic_handle_nmi():
    0.00 :   ffff8000104c6a9c:       ldr     x3, [sp, #56]
    0.00 :   ffff8000104c6aa0:       and     w1, w1, #0xf00000
    0.00 :   ffff8000104c6aa4:       cmp     w1, #0xf00, lsl #12
    0.00 :   ffff8000104c6aa8:       b.eq    ffff8000104c6bfc <gic_handle_irq+0x2c4>  // b.none
         : 631              __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000104c6aac:       ldr     w1, [x4, #8]
         : 53               gic_handle_nmi():
    0.00 :   ffff8000104c6ab0:       mov     w21, #0x1                       // #1
    0.00 :   ffff8000104c6ab4:       str     x3, [sp, #56]
         : 629              __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff8000104c6ab8:       add     w1, w1, #0x110, lsl #12
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000104c6abc:       str     w1, [x4, #8]
         : 50               gic_handle_nmi():
    0.00 :   ffff8000104c6ac0:       bl      ffff800010e2bc80 <rcu_nmi_enter>
    0.00 :   ffff8000104c6ac4:       ldr     x3, [sp, #56]
         : 629              arch_static_branch():
    0.00 :   ffff8000104c6ac8:       nop
         : 22               gic_write_eoir():
         : 31               write_sysreg_s(irq, SYS_ICC_EOIR1_EL1);
    0.00 :   ffff8000104c6acc:       and     x19, x19, #0xffffffff
    0.00 :   ffff8000104c6ad0:       msr     s3_0_c12_c12_1, x19
         : 32               isb();
    0.00 :   ffff8000104c6ad4:       isb
         : 34               gic_handle_nmi():
         : 637              err = handle_domain_nmi(gic_data.domain, irqnr, regs);
    0.00 :   ffff8000104c6ad8:       adrp    x4, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
    0.00 :   ffff8000104c6adc:       mov     x2, x3
    0.00 :   ffff8000104c6ae0:       mov     w1, w20
    0.00 :   ffff8000104c6ae4:       ldr     x0, [x4, #2768]
    0.00 :   ffff8000104c6ae8:       bl      ffff8000100eba10 <handle_domain_nmi>
         : 638              if (err)
    0.00 :   ffff8000104c6aec:       cbnz    w0, ffff8000104c6b64 <gic_handle_irq+0x22c>
         : 641              if (irqs_enabled)
    0.00 :   ffff8000104c6af0:       cbnz    w21, ffff8000104c6afc <gic_handle_irq+0x1c4>
    0.00 :   ffff8000104c6af4:       ldr     x21, [sp, #32]
    0.00 :   ffff8000104c6af8:       b       ffff8000104c6968 <gic_handle_irq+0x30>
         : 642              nmi_exit();
    0.00 :   ffff8000104c6afc:       bl      ffff800010e2bbc8 <rcu_nmi_exit>
         : 644              get_current():
    0.00 :   ffff8000104c6b00:       mrs     x0, sp_el0
         : 20               preempt_count():
         : 12               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000104c6b04:       ldr     w1, [x0, #8]
         : 14               gic_handle_nmi():
    0.00 :   ffff8000104c6b08:       tst     w1, #0xf00000
    0.00 :   ffff8000104c6b0c:       b.eq    ffff8000104c6c00 <gic_handle_irq+0x2c8>  // b.none
         : 644              __preempt_count_sub():
         : 53               }
         :
         : 55               static inline void __preempt_count_sub(int val)
         : 56               {
         : 57               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000104c6b10:       ldr     w1, [x0, #8]
         : 54               pc -= val;
    0.00 :   ffff8000104c6b14:       sub     w1, w1, #0x110, lsl #12
         : 55               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000104c6b18:       str     w1, [x0, #8]
         : 57               gic_handle_nmi():
    0.00 :   ffff8000104c6b1c:       bl      ffff800010e2b978 <printk_nmi_exit>
         : 643              is_kernel_in_hyp_mode():
    0.00 :   ffff8000104c6b20:       mrs     x0, currentel
         : 107              gic_handle_nmi():
    0.00 :   ffff8000104c6b24:       cmp     x0, #0x8
    0.00 :   ffff8000104c6b28:       b.ne    ffff8000104c6af4 <gic_handle_irq+0x1bc>  // b.any
         : 644              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000104c6b2c:       mrs     x2, tpidr_el1
         : 46               gic_handle_nmi():
    0.00 :   ffff8000104c6b30:       adrp    x0, ffff80001176d000 <cpu_number>
    0.00 :   ffff8000104c6b34:       add     x0, x0, #0x60
    0.00 :   ffff8000104c6b38:       add     x1, x0, x2
    0.00 :   ffff8000104c6b3c:       ldr     x2, [x0, x2]
    0.00 :   ffff8000104c6b40:       ldr     w0, [x1, #8]
    0.00 :   ffff8000104c6b44:       sub     w0, w0, #0x1
    0.00 :   ffff8000104c6b48:       str     w0, [x1, #8]
    0.00 :   ffff8000104c6b4c:       ldr     w0, [x1, #8]
    0.00 :   ffff8000104c6b50:       cbnz    w0, ffff8000104c6af4 <gic_handle_irq+0x1bc>
    0.00 :   ffff8000104c6b54:       tbnz    w2, #27, ffff8000104c6af4 <gic_handle_irq+0x1bc>
    0.00 :   ffff8000104c6b58:       msr     hcr_el2, x2
    0.00 :   ffff8000104c6b5c:       ldr     x21, [sp, #32]
    0.00 :   ffff8000104c6b60:       b       ffff8000104c6968 <gic_handle_irq+0x30>
         : 639              gic_deactivate_unhandled(irqnr);
    0.00 :   ffff8000104c6b64:       mov     w0, w20
    0.00 :   ffff8000104c6b68:       bl      ffff8000104c5418 <gic_deactivate_unhandled>
         : 641              if (irqs_enabled)
    0.00 :   ffff8000104c6b6c:       cbz     w21, ffff8000104c6af4 <gic_handle_irq+0x1bc>
    0.00 :   ffff8000104c6b70:       b       ffff8000104c6afc <gic_handle_irq+0x1c4>
         : 644              gic_handle_irq():
         : 672              WARN_ONCE(true, "Unexpected interrupt received!\n");
    0.00 :   ffff8000104c6b74:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000104c6b78:       adrp    x0, ffff800011449000 <kallsyms_token_index+0x3e7a0>
    0.00 :   ffff8000104c6b7c:       add     x0, x0, #0x1a0
    0.00 :   ffff8000104c6b80:       strb    w2, [x1, #1]
    0.00 :   ffff8000104c6b84:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff8000104c6b88:       brk     #0x800
    0.00 :   ffff8000104c6b8c:       b       ffff8000104c6a20 <gic_handle_irq+0xe8>
         : 680              test_bit():
    0.00 :   ffff8000104c6b90:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff8000104c6b94:       ldr     x0, [x0, #1296]
         : 108              gic_handle_nmi():
         : 623              bool irqs_enabled = interrupts_enabled(regs);
    0.00 :   ffff8000104c6b98:       tst     w0, #0x80000
    0.00 :   ffff8000104c6b9c:       b.eq    ffff8000104c6a80 <gic_handle_irq+0x148>  // b.none
    0.00 :   ffff8000104c6ba0:       ldr     x0, [x3, #296]
    0.00 :   ffff8000104c6ba4:       cmp     x0, #0xe0
    0.00 :   ffff8000104c6ba8:       b.eq    ffff8000104c6a80 <gic_handle_irq+0x148>  // b.none
    0.00 :   ffff8000104c6bac:       mov     w21, #0x0                       // #0
    0.00 :   ffff8000104c6bb0:       b       ffff8000104c6ac8 <gic_handle_irq+0x190>
         : 627              nmi_enter();
    0.00 :   ffff8000104c6bb4:       adrp    x0, ffff80001176d000 <cpu_number>
    0.00 :   ffff8000104c6bb8:       add     x0, x0, #0x60
         : 630              __kern_my_cpu_offset():
    0.00 :   ffff8000104c6bbc:       mrs     x4, tpidr_el1
         : 40               gic_handle_nmi():
    0.00 :   ffff8000104c6bc0:       add     x2, x0, x4
    0.00 :   ffff8000104c6bc4:       ldr     w1, [x2, #8]
    0.00 :   ffff8000104c6bc8:       cbz     w1, ffff8000104c6bd8 <gic_handle_irq+0x2a0>
    0.00 :   ffff8000104c6bcc:       add     w1, w1, #0x1
    0.00 :   ffff8000104c6bd0:       str     w1, [x2, #8]
    0.00 :   ffff8000104c6bd4:       b       ffff8000104c6a8c <gic_handle_irq+0x154>
    0.00 :   ffff8000104c6bd8:       mrs     x1, hcr_el2
    0.00 :   ffff8000104c6bdc:       tbnz    w1, #27, ffff8000104c6bec <gic_handle_irq+0x2b4>
    0.00 :   ffff8000104c6be0:       orr     x5, x1, #0x8000000
    0.00 :   ffff8000104c6be4:       msr     hcr_el2, x5
    0.00 :   ffff8000104c6be8:       isb
    0.00 :   ffff8000104c6bec:       mov     w5, #0x1                        // #1
    0.00 :   ffff8000104c6bf0:       str     w5, [x2, #8]
    0.00 :   ffff8000104c6bf4:       str     x1, [x0, x4]
    0.00 :   ffff8000104c6bf8:       b       ffff8000104c6a8c <gic_handle_irq+0x154>
    0.00 :   ffff8000104c6bfc:       brk     #0x800
         : 642              nmi_exit();
    0.00 :   ffff8000104c6c00:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010f860 <__hrtimer_run_queues>:
         : 6                __hrtimer_run_queues():
         :
         : 1574             static void __hrtimer_run_queues(struct hrtimer_cpu_base *cpu_base, ktime_t now,
         : 1575             unsigned long flags, unsigned int active_mask)
         : 1576             {
         : 1577             struct hrtimer_clock_base *base;
         : 1578             unsigned int active = cpu_base->active_bases & active_mask;
    0.00 :   ffff80001010f860:       ldr     w4, [x0, #8]
         : 1580             __next_base():
         : 490              if (!*active)
    0.00 :   ffff80001010f864:       ands    w3, w3, w4
    0.00 :   ffff80001010f868:       b.eq    ffff80001010fa0c <__hrtimer_run_queues+0x1ac>  // b.none
         : 493              __hrtimer_run_queues():
         : 1571             {
    0.00 :   ffff80001010f86c:       paciasp
    0.00 :   ffff80001010f870:       stp     x29, x30, [sp, #-112]!
         : 1574             __next_base():
         : 493              idx = __ffs(*active);
    0.00 :   ffff80001010f874:       mov     w4, w3
         : 495              __hrtimer_run_queues():
         : 1571             {
    0.00 :   ffff80001010f878:       mov     x29, sp
    0.00 :   ffff80001010f87c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001010f880:       mov     x21, x0
         : 1575             __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff80001010f884:       rbit    x0, x4
    0.00 :   ffff80001010f888:       clz     x0, x0
         : 21               __hrtimer_run_queues():
    0.00 :   ffff80001010f88c:       stp     x19, x20, [sp, #16]
         : 1572             __next_base():
         : 496              return &cpu_base->clock_base[idx];
    0.00 :   ffff80001010f890:       add     x19, x0, #0x1
         : 498              __hrtimer_run_queues():
         : 1571             {
    0.00 :   ffff80001010f894:       stp     x25, x26, [sp, #64]
         : 1573             __next_base():
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f898:       mov     w25, #0x1                       // #1
    0.00 :   ffff80001010f89c:       lsl     w26, w25, w0
         : 497              __hrtimer_run_queues():
         :
         : 1576             for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f8a0:       adds    x19, x21, x19, lsl #6
         : 1578             __next_base():
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f8a4:       bic     w26, w3, w26
         : 496              __hrtimer_run_queues():
         : 1575             for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f8a8:       b.eq    ffff80001010f9ec <__hrtimer_run_queues+0x18c>  // b.none
    0.00 :   ffff80001010f8ac:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001010f8b0:       mov     x24, x2
    0.00 :   ffff80001010f8b4:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001010f8b8:       str     x1, [sp, #104]
         : 1579             struct timerqueue_node *node;
         : 1580             ktime_t basenow;
         :
         : 1582             basenow = ktime_add(now, base->offset);
    0.00 :   ffff80001010f8bc:       mov     w0, w0
         :
         : 1582             while ((node = timerqueue_getnext(&base->active))) {
    0.00 :   ffff80001010f8c0:       ldr     x20, [x19, #40]
    0.00 :   ffff80001010f8c4:       add     x28, x21, x0, lsl #6
         : 1579             basenow = ktime_add(now, base->offset);
    0.00 :   ffff80001010f8c8:       ldr     x1, [sp, #104]
    0.00 :   ffff80001010f8cc:       ldr     x23, [x28, #120]
    0.00 :   ffff80001010f8d0:       add     x23, x1, x23
         : 1581             while ((node = timerqueue_getnext(&base->active))) {
    0.00 :   ffff80001010f8d4:       cbz     x20, ffff80001010f9c0 <__hrtimer_run_queues+0x160>
         : 1598             * BST we already have.
         : 1599             * We don't add extra wakeups by delaying timers that
         : 1600             * are right-of a not yet expired timer, because that
         : 1601             * timer will have to trigger a wakeup anyway.
         : 1602             */
         : 1603             if (basenow < hrtimer_get_softexpires_tv64(timer))
    0.00 :   ffff80001010f8d8:       ldr     x1, [x20, #32]
    0.00 :   ffff80001010f8dc:       cmp     x23, x1
    0.00 :   ffff80001010f8e0:       b.lt    ffff80001010f9c0 <__hrtimer_run_queues+0x160>  // b.tstop
         : 1607             enqueue_hrtimer():
         : 989              return timerqueue_add(&base->active, &timer->node);
    0.00 :   ffff80001010f8e4:       add     x0, x21, x0, lsl #6
    0.00 :   ffff80001010f8e8:       add     x22, x0, #0x60
    0.00 :   ffff80001010f8ec:       b       ffff80001010f930 <__hrtimer_run_queues+0xd0>
         : 993              do_raw_write_seqcount_barrier():
         : 616              do_raw_write_seqcount_barrier(seqprop_ptr(s))
         :
         : 618              static inline void do_raw_write_seqcount_barrier(seqcount_t *s)
         : 619              {
         : 620              kcsan_nestable_atomic_begin();
         : 621              s->sequence++;
    0.00 :   ffff80001010f8f0:       ldr     w0, [x19, #16]
    0.00 :   ffff80001010f8f4:       add     w0, w0, #0x1
    0.00 :   ffff80001010f8f8:       str     w0, [x19, #16]
         : 617              smp_wmb();
    0.00 :   ffff80001010f8fc:       dmb     ishst
         : 618              s->sequence++;
   25.13 :   ffff80001010f900:       ldr     w3, [x19, #16]
    0.00 :   ffff80001010f904:       add     w3, w3, #0x1
    0.00 :   ffff80001010f908:       str     w3, [x19, #16]
         : 622              __run_hrtimer():
         : 1565             WARN_ON_ONCE(base->running != timer);
    0.00 :   ffff80001010f90c:       ldr     x0, [x28, #88]
    0.00 :   ffff80001010f910:       cmp     x0, x20
    0.00 :   ffff80001010f914:       b.ne    ffff80001010fa04 <__hrtimer_run_queues+0x1a4>  // b.any
         : 1566             base->running = NULL;
    0.00 :   ffff80001010f918:       str     xzr, [x28, #88]
         : 1568             __hrtimer_run_queues():
         : 1581             while ((node = timerqueue_getnext(&base->active))) {
    0.00 :   ffff80001010f91c:       ldr     x20, [x19, #40]
    0.00 :   ffff80001010f920:       cbz     x20, ffff80001010f9c0 <__hrtimer_run_queues+0x160>
         : 1598             if (basenow < hrtimer_get_softexpires_tv64(timer))
    0.00 :   ffff80001010f924:       ldr     x0, [x20, #32]
    0.00 :   ffff80001010f928:       cmp     x23, x0
    0.00 :   ffff80001010f92c:       b.lt    ffff80001010f9c0 <__hrtimer_run_queues+0x160>  // b.tstop
         : 1602             __run_hrtimer():
         : 1506             base->running = timer;
    0.00 :   ffff80001010f930:       str     x20, [x28, #88]
         : 1508             do_raw_write_seqcount_barrier():
         : 616              s->sequence++;
    0.00 :   ffff80001010f934:       ldr     w0, [x19, #16]
    0.00 :   ffff80001010f938:       add     w0, w0, #0x1
    0.00 :   ffff80001010f93c:       str     w0, [x19, #16]
         : 617              smp_wmb();
    0.00 :   ffff80001010f940:       dmb     ishst
         : 618              s->sequence++;
   74.87 :   ffff80001010f944:       ldr     w2, [x19, #16]
         : 620              __run_hrtimer():
         : 1517             __remove_hrtimer(timer, base, HRTIMER_STATE_INACTIVE, 0);
    0.00 :   ffff80001010f948:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001010f94c:       mov     x1, x19
    0.00 :   ffff80001010f950:       mov     x0, x20
         : 1521             do_raw_write_seqcount_barrier():
    0.00 :   ffff80001010f954:       add     w2, w2, #0x1
    0.00 :   ffff80001010f958:       str     w2, [x19, #16]
         : 620              __run_hrtimer():
    0.00 :   ffff80001010f95c:       mov     w2, #0x0                        // #0
    0.00 :   ffff80001010f960:       bl      ffff80001010f700 <__remove_hrtimer>
         : 1518             fn = timer->function;
    0.00 :   ffff80001010f964:       ldr     x27, [x20, #40]
         : 1533             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff80001010f968:       mov     x1, x24
    0.00 :   ffff80001010f96c:       mov     x0, x21
    0.00 :   ffff80001010f970:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1537             restart = fn(timer);
    0.00 :   ffff80001010f974:       mov     x0, x20
    0.00 :   ffff80001010f978:       blr     x27
    0.00 :   ffff80001010f97c:       mov     w27, w0
         : 1541             raw_spin_lock_irq(&cpu_base->lock);
    0.00 :   ffff80001010f980:       mov     x0, x21
    0.00 :   ffff80001010f984:       bl      ffff800010e354e0 <_raw_spin_lock_irq>
         : 1552             if (restart != HRTIMER_NORESTART &&
    0.00 :   ffff80001010f988:       cbz     w27, ffff80001010f8f0 <__hrtimer_run_queues+0x90>
    0.00 :   ffff80001010f98c:       ldrb    w0, [x20, #56]
    0.00 :   ffff80001010f990:       tbnz    w0, #0, ffff80001010f8f0 <__hrtimer_run_queues+0x90>
         : 1556             enqueue_hrtimer():
         : 984              base->cpu_base->active_bases |= 1 << base->index;
    0.00 :   ffff80001010f994:       ldr     x4, [x28, #64]
         : 989              return timerqueue_add(&base->active, &timer->node);
    0.00 :   ffff80001010f998:       mov     x1, x20
         : 984              base->cpu_base->active_bases |= 1 << base->index;
    0.00 :   ffff80001010f99c:       ldr     w3, [x28, #72]
         : 989              return timerqueue_add(&base->active, &timer->node);
    0.00 :   ffff80001010f9a0:       mov     x0, x22
         : 984              base->cpu_base->active_bases |= 1 << base->index;
    0.00 :   ffff80001010f9a4:       ldr     w2, [x4, #8]
    0.00 :   ffff80001010f9a8:       lsl     w3, w25, w3
    0.00 :   ffff80001010f9ac:       orr     w2, w2, w3
    0.00 :   ffff80001010f9b0:       str     w2, [x4, #8]
         : 987              WRITE_ONCE(timer->state, HRTIMER_STATE_ENQUEUED);
    0.00 :   ffff80001010f9b4:       strb    w25, [x20, #56]
         : 989              return timerqueue_add(&base->active, &timer->node);
    0.00 :   ffff80001010f9b8:       bl      ffff8000104b7878 <timerqueue_add>
    0.00 :   ffff80001010f9bc:       b       ffff80001010f8f0 <__hrtimer_run_queues+0x90>
         : 992              __next_base():
         : 490              if (!*active)
    0.00 :   ffff80001010f9c0:       cbz     w26, ffff80001010f9e4 <__hrtimer_run_queues+0x184>
         : 493              idx = __ffs(*active);
    0.00 :   ffff80001010f9c4:       mov     w0, w26
         : 495              __ffs():
    0.00 :   ffff80001010f9c8:       rbit    x0, x0
    0.00 :   ffff80001010f9cc:       clz     x0, x0
         : 15               __next_base():
         : 496              return &cpu_base->clock_base[idx];
    0.00 :   ffff80001010f9d0:       add     x19, x0, #0x1
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f9d4:       lsl     w1, w25, w0
    0.00 :   ffff80001010f9d8:       bic     w26, w26, w1
         : 497              __hrtimer_run_queues():
         : 1575             for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f9dc:       adds    x19, x21, x19, lsl #6
    0.00 :   ffff80001010f9e0:       b.ne    ffff80001010f8bc <__hrtimer_run_queues+0x5c>  // b.any
    0.00 :   ffff80001010f9e4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001010f9e8:       ldp     x27, x28, [sp, #80]
         : 1606             __run_hrtimer(cpu_base, base, timer, &basenow, flags);
         : 1607             if (active_mask == HRTIMER_ACTIVE_SOFT)
         : 1608             hrtimer_sync_wait_running(cpu_base, flags);
         : 1609             }
         : 1610             }
         : 1611             }
    0.00 :   ffff80001010f9ec:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001010f9f0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001010f9f4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001010f9f8:       ldp     x29, x30, [sp], #112
    0.00 :   ffff80001010f9fc:       autiasp
    0.00 :   ffff80001010fa00:       ret
         : 1618             __run_hrtimer():
         : 1565             WARN_ON_ONCE(base->running != timer);
    0.00 :   ffff80001010fa04:       brk     #0x800
    0.00 :   ffff80001010fa08:       b       ffff80001010f918 <__hrtimer_run_queues+0xb8>
    0.00 :   ffff80001010fa0c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100ba8d0 <irqtime_account_process_tick>:
         : 6                irqtime_account_process_tick():
         : 360              * p->stime and friends are only updated on system time and not on irq
         : 361              * softirq as those do not count in task exec_runtime any more.
         : 362              */
         : 363              static void irqtime_account_process_tick(struct task_struct *p, int user_tick,
         : 364              int ticks)
         : 365              {
    0.00 :   ffff8000100ba8d0:       paciasp
    0.00 :   ffff8000100ba8d4:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000100ba8d8:       mov     x29, sp
    0.00 :   ffff8000100ba8dc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100ba8e0:       mov     x20, x0
    0.00 :   ffff8000100ba8e4:       mov     w19, w2
    0.00 :   ffff8000100ba8e8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100ba8ec:       mov     w21, w1
         : 374              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000100ba8f0:       nop
         : 28               account_other_time():
         : 264              if (accounted < max)
    0.00 :   ffff8000100ba8f4:       mov     x0, sp
         : 266              arch_static_branch():
    0.00 :   ffff8000100ba8f8:       mov     x5, #0xffffffffffffffff         // #-1
         : 22               steal_account_process_time():
         : 250              return 0;
    0.00 :   ffff8000100ba8fc:       mov     x4, #0x0                        // #0
         : 252              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100ba900:       mrs     x0, tpidr_el1
         : 46               irqtime_tick_accounted():
         : 79               struct irqtime *irqtime = this_cpu_ptr(&cpu_irqtime);
    0.00 :   ffff8000100ba904:       adrp    x3, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100ba908:       add     x3, x3, #0x7a8
    0.00 :   ffff8000100ba90c:       add     x3, x3, x0
         : 83               irqtime_account_process_tick():
         : 361              u64 other, cputime = TICK_NSEC * ticks;
    0.00 :   ffff8000100ba910:       mov     w2, #0x900                      // #2304
    0.00 :   ffff8000100ba914:       movk    w2, #0x3d, lsl #16
         : 364              irqtime_tick_accounted():
         : 82               delta = min(irqtime->tick_delta, maxtime);
    0.00 :   ffff8000100ba918:       ldr     x0, [x3, #8]
         : 84               irqtime_account_process_tick():
         : 361              u64 other, cputime = TICK_NSEC * ticks;
    0.00 :   ffff8000100ba91c:       smull   x2, w19, w2
         : 363              irqtime_tick_accounted():
         : 82               delta = min(irqtime->tick_delta, maxtime);
    0.00 :   ffff8000100ba920:       cmp     x0, x5
    0.00 :   ffff8000100ba924:       csel    x5, x0, x5, ls  // ls = plast
         : 83               irqtime->tick_delta -= delta;
   74.95 :   ffff8000100ba928:       sub     x0, x0, x5
    0.00 :   ffff8000100ba92c:       str     x0, [x3, #8]
         : 86               account_other_time():
         : 265              accounted += irqtime_tick_accounted(max - accounted);
    0.00 :   ffff8000100ba930:       add     x4, x4, x5
         : 267              irqtime_account_process_tick():
         : 371              * Subtract those ticks from the amount of time accounted to
         : 372              * idle, or potentially user or system time. Due to rounding,
         : 373              * other time can exceed ticks occasionally.
         : 374              */
         : 375              other = account_other_time(ULONG_MAX);
         : 376              if (other >= cputime)
    0.00 :   ffff8000100ba934:       cmp     x2, x4
    0.00 :   ffff8000100ba938:       b.ls    ffff8000100ba9b4 <irqtime_account_process_tick+0xe4>  // b.plast
         : 379              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100ba93c:       mrs     x1, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000100ba940:       ldr     w0, [x1, #8]
         : 53               irqtime_account_process_tick():
         : 374              return;
         :
         : 376              cputime -= other;
    0.00 :   ffff8000100ba944:       sub     x19, x2, x4
         : 378              __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff8000100ba948:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000100ba94c:       str     w0, [x1, #8]
         : 50               this_cpu_ksoftirqd():
         : 587              he makes it with spinlocks.
         : 588              */
         :
         : 590              struct tasklet_struct
         : 591              {
         : 592              struct tasklet_struct *next;
    0.00 :   ffff8000100ba950:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100ba954:       add     x0, x0, #0x6b8
         : 595              __kern_my_cpu_offset():
    0.00 :   ffff8000100ba958:       mrs     x2, tpidr_el1
         : 40               __percpu_read_64():
         : 125              __PERCPU_RET_OP_CASE( ,  , name, 64, op_llsc, op_lse)
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
    0.00 :   ffff8000100ba95c:       ldr     x22, [x0, x2]
         : 132              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000100ba960:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000100ba964:       sub     x0, x0, #0x1
    0.00 :   ffff8000100ba968:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000100ba96c:       cbnz    x0, ffff8000100baa3c <irqtime_account_process_tick+0x16c>
         : 80               this_cpu_ksoftirqd():
    0.00 :   ffff8000100ba970:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff8000100ba974:       nop
         : 589              irqtime_account_process_tick():
         :
         : 377              if (this_cpu_ksoftirqd() == p) {
    0.00 :   ffff8000100ba978:       cmp     x20, x22
    0.00 :   ffff8000100ba97c:       b.eq    ffff8000100baa8c <irqtime_account_process_tick+0x1bc>  // b.none
         : 383              * ksoftirqd time do not get accounted in cpu_softirq_time.
         : 384              * So, we have to handle it separately here.
         : 385              * Also, p->stime needs to be updated for ksoftirqd.
         : 386              */
         : 387              account_system_index_time(p, cputime, CPUTIME_SOFTIRQ);
         : 388              } else if (user_tick) {
    0.00 :   ffff8000100ba980:       cbnz    w21, ffff8000100baa6c <irqtime_account_process_tick+0x19c>
         : 385              account_user_time(p, cputime);
         : 386              } else if (p == this_rq()->idle) {
    0.00 :   ffff8000100ba984:       adrp    x0, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100ba988:       add     x0, x0, #0xc40
         : 389              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100ba98c:       mrs     x1, tpidr_el1
         : 41               irqtime_account_process_tick():
    0.00 :   ffff8000100ba990:       add     x0, x0, x1
    0.00 :   ffff8000100ba994:       ldr     x0, [x0, #2360]
    0.00 :   ffff8000100ba998:       cmp     x0, x20
    0.00 :   ffff8000100ba99c:       b.eq    ffff8000100baaa0 <irqtime_account_process_tick+0x1d0>  // b.none
         : 387              account_idle_time(cputime);
         : 388              } else if (p->flags & PF_VCPU) { /* System time or guest time */
    0.00 :   ffff8000100ba9a0:       ldr     w0, [x20, #36]
         : 388              account_guest_time(p, cputime);
    0.00 :   ffff8000100ba9a4:       mov     x1, x19
         : 387              } else if (p->flags & PF_VCPU) { /* System time or guest time */
    0.00 :   ffff8000100ba9a8:       tbz     w0, #0, ffff8000100baa4c <irqtime_account_process_tick+0x17c>
         : 388              account_guest_time(p, cputime);
    0.00 :   ffff8000100ba9ac:       mov     x0, x20
    0.00 :   ffff8000100ba9b0:       bl      ffff8000100ba610 <account_guest_time>
         : 392              } else {
         : 393              account_system_index_time(p, cputime, CPUTIME_SYSTEM);
         : 394              }
         : 395              }
    0.00 :   ffff8000100ba9b4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100ba9b8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100ba9bc:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100ba9c0:       autiasp
    0.00 :   ffff8000100ba9c4:       ret
         : 401              paravirt_steal_clock():
         :
         : 19               DECLARE_STATIC_CALL(pv_steal_clock, dummy_steal_clock);
         :
         : 21               static inline u64 paravirt_steal_clock(int cpu)
         : 22               {
         : 23               return static_call(pv_steal_clock)(cpu);
    0.00 :   ffff8000100ba9c8:       adrp    x1, ffff800011c37000 <__compound_literal.32+0x20>
         : 25               steal_account_process_time():
         : 241              steal = paravirt_steal_clock(smp_processor_id());
    0.00 :   ffff8000100ba9cc:       adrp    x0, ffff80001176d000 <cpu_number>
         : 243              __kern_my_cpu_offset():
    0.00 :   ffff8000100ba9d0:       mrs     x2, tpidr_el1
         : 40               paravirt_steal_clock():
    0.00 :   ffff8000100ba9d4:       ldr     x1, [x1, #1720]
         : 19               steal_account_process_time():
    0.00 :   ffff8000100ba9d8:       add     x0, x0, #0x0
         : 242              paravirt_steal_clock():
    0.00 :   ffff8000100ba9dc:       ldr     w0, [x0, x2]
    0.00 :   ffff8000100ba9e0:       blr     x1
         : 20               steal_account_process_time():
         : 242              steal -= this_rq()->prev_steal_time;
    0.00 :   ffff8000100ba9e4:       adrp    x3, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100ba9e8:       add     x3, x3, #0xc40
         : 245              __kern_my_cpu_offset():
    0.00 :   ffff8000100ba9ec:       mrs     x1, tpidr_el1
         : 40               steal_account_process_time():
    0.00 :   ffff8000100ba9f0:       add     x1, x3, x1
    0.00 :   ffff8000100ba9f4:       ldr     x4, [x1, #2920]
    0.00 :   ffff8000100ba9f8:       sub     x4, x0, x4
         : 244              account_steal_time(steal);
    0.00 :   ffff8000100ba9fc:       mov     x0, x4
    0.00 :   ffff8000100baa00:       bl      ffff8000100ba850 <account_steal_time>
         : 247              __kern_my_cpu_offset():
         : 43               "Q" (*(const unsigned long *)current_stack_pointer));
    0.00 :   ffff8000100baa04:       mov     x0, sp
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100baa08:       mrs     x1, tpidr_el1
         : 41               steal_account_process_time():
         : 245              this_rq()->prev_steal_time += steal;
    0.00 :   ffff8000100baa0c:       add     x3, x3, x1
    0.00 :   ffff8000100baa10:       mvn     x5, x4
         : 248              account_other_time():
         : 264              if (accounted < max)
    0.00 :   ffff8000100baa14:       cmn     x4, #0x1
         : 266              steal_account_process_time():
         : 245              this_rq()->prev_steal_time += steal;
    0.00 :   ffff8000100baa18:       ldr     x1, [x3, #2920]
    0.00 :   ffff8000100baa1c:       add     x1, x1, x4
    0.00 :   ffff8000100baa20:       str     x1, [x3, #2920]
         : 249              account_other_time():
         : 264              if (accounted < max)
    0.00 :   ffff8000100baa24:       b.ne    ffff8000100ba900 <irqtime_account_process_tick+0x30>  // b.any
         : 266              irqtime_account_process_tick():
         : 392              }
    0.00 :   ffff8000100baa28:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100baa2c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100baa30:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100baa34:       autiasp
    0.00 :   ffff8000100baa38:       ret
         : 398              __preempt_count_dec_and_test():
    0.00 :   ffff8000100baa3c:       ldr     x0, [x1, #8]
    0.00 :   ffff8000100baa40:       cbnz    x0, ffff8000100ba978 <irqtime_account_process_tick+0xa8>
         : 75               this_cpu_ksoftirqd():
    0.00 :   ffff8000100baa44:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff8000100baa48:       b       ffff8000100ba978 <irqtime_account_process_tick+0xa8>
         : 589              irqtime_account_process_tick():
         : 390              account_system_index_time(p, cputime, CPUTIME_SYSTEM);
    0.00 :   ffff8000100baa4c:       mov     x0, x20
    0.00 :   ffff8000100baa50:       mov     w2, #0x2                        // #2
    0.00 :   ffff8000100baa54:       bl      ffff8000100ba6e0 <account_system_index_time>
         : 392              }
    0.00 :   ffff8000100baa58:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100baa5c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100baa60:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100baa64:       autiasp
   25.05 :   ffff8000100baa68:       ret
         : 384              account_user_time(p, cputime);
    0.00 :   ffff8000100baa6c:       mov     x1, x19
    0.00 :   ffff8000100baa70:       mov     x0, x20
    0.00 :   ffff8000100baa74:       bl      ffff8000100ba528 <account_user_time>
         : 392              }
    0.00 :   ffff8000100baa78:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100baa7c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100baa80:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100baa84:       autiasp
    0.00 :   ffff8000100baa88:       ret
         : 382              account_system_index_time(p, cputime, CPUTIME_SOFTIRQ);
    0.00 :   ffff8000100baa8c:       mov     x1, x19
    0.00 :   ffff8000100baa90:       mov     x0, x20
    0.00 :   ffff8000100baa94:       mov     w2, #0x3                        // #3
    0.00 :   ffff8000100baa98:       bl      ffff8000100ba6e0 <account_system_index_time>
    0.00 :   ffff8000100baa9c:       b       ffff8000100ba9b4 <irqtime_account_process_tick+0xe4>
         : 386              account_idle_time(cputime);
    0.00 :   ffff8000100baaa0:       mov     x0, x19
    0.00 :   ffff8000100baaa4:       bl      ffff8000100ba878 <account_idle_time>
    0.00 :   ffff8000100baaa8:       b       ffff8000100ba9b4 <irqtime_account_process_tick+0xe4>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101a1610 <page_mapping>:
         : 6                compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
   22.18 :   ffff8000101a1610:       ldr     x1, [x0, #8]
         : 191              page_mapping():
         : 690              return NULL;
         : 691              return __page_rmapping(page);
         : 692              }
         :
         : 694              struct address_space *page_mapping(struct page *page)
         : 695              {
    0.00 :   ffff8000101a1614:       paciasp
         : 697              compound_head():
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
   77.82 :   ffff8000101a1618:       sub     x2, x1, #0x1
    0.00 :   ffff8000101a161c:       tst     x1, #0x1
    0.00 :   ffff8000101a1620:       csel    x0, x2, x0, ne  // ne = any
         : 184              {
    0.00 :   ffff8000101a1624:       ldr     x2, [x0, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101a1628:       sub     x1, x2, #0x1
    0.00 :   ffff8000101a162c:       tst     x2, #0x1
    0.00 :   ffff8000101a1630:       csel    x1, x1, x0, ne  // ne = any
         : 191              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101a1634:       ldr     x1, [x1]
         : 113              page_mapping():
         : 696              struct address_space *mapping;
         :
         : 698              page = compound_head(page);
         :
         : 700              /* This happens if someone calls flush_dcache_page on slab page */
         : 701              if (unlikely(PageSlab(page)))
    0.00 :   ffff8000101a1638:       tst     w1, #0x200
    0.00 :   ffff8000101a163c:       b.ne    ffff8000101a16b0 <page_mapping+0xa0>  // b.any
         : 704              compound_head():
         : 184              {
    0.00 :   ffff8000101a1640:       ldr     x2, [x0, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101a1644:       sub     x1, x2, #0x1
    0.00 :   ffff8000101a1648:       tst     x2, #0x1
    0.00 :   ffff8000101a164c:       csel    x1, x1, x0, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff8000101a1650:       ldr     x1, [x1]
         : 107              PageSwapCache():
         : 401              #endif
         :
         : 403              #ifdef CONFIG_SWAP
         : 404              static __always_inline int PageSwapCache(struct page *page)
         : 405              {
         : 406              #ifdef CONFIG_THP_SWAP
    0.00 :   ffff8000101a1654:       tst     w1, #0x80000
    0.00 :   ffff8000101a1658:       b.ne    ffff8000101a1674 <page_mapping+0x64>  // b.any
         : 409              page_mapping():
         : 707              entry.val = page_private(page);
         : 708              return swap_address_space(entry);
         : 709              }
         :
         : 711              mapping = page->mapping;
         : 712              if ((unsigned long)mapping & PAGE_MAPPING_ANON)
    0.00 :   ffff8000101a165c:       ldr     x1, [x0, #24]
         : 711              return NULL;
         :
         : 713              return (void *)((unsigned long)mapping & ~PAGE_MAPPING_FLAGS);
         : 714              }
    0.00 :   ffff8000101a1660:       autiasp
         : 710              return (void *)((unsigned long)mapping & ~PAGE_MAPPING_FLAGS);
    0.00 :   ffff8000101a1664:       and     x0, x1, #0xfffffffffffffffc
    0.00 :   ffff8000101a1668:       tst     x1, #0x1
    0.00 :   ffff8000101a166c:       csel    x0, x0, xzr, eq  // eq = none
         : 711              }
    0.00 :   ffff8000101a1670:       ret
         : 713              test_bit():
    0.00 :   ffff8000101a1674:       ldr     x1, [x0]
         : 107              PageSwapCache():
    0.00 :   ffff8000101a1678:       tst     w1, #0x400
    0.00 :   ffff8000101a167c:       b.eq    ffff8000101a165c <page_mapping+0x4c>  // b.none
         : 403              page_mapping():
         : 702              entry.val = page_private(page);
    0.00 :   ffff8000101a1680:       ldr     x1, [x0, #40]
         : 711              }
    0.00 :   ffff8000101a1684:       autiasp
         : 703              return swap_address_space(entry);
    0.00 :   ffff8000101a1688:       adrp    x3, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101a168c:       add     x3, x3, #0xdd8
    0.00 :   ffff8000101a1690:       ubfx    x2, x1, #14, #44
    0.00 :   ffff8000101a1694:       lsr     x1, x1, #58
    0.00 :   ffff8000101a1698:       add     x0, x2, x2, lsl #2
    0.00 :   ffff8000101a169c:       ldr     x1, [x3, x1, lsl #3]
    0.00 :   ffff8000101a16a0:       lsl     x0, x0, #2
    0.00 :   ffff8000101a16a4:       sub     x0, x0, x2
    0.00 :   ffff8000101a16a8:       add     x0, x1, x0, lsl #3
         : 711              }
    0.00 :   ffff8000101a16ac:       ret
         : 697              return NULL;
    0.00 :   ffff8000101a16b0:       mov     x0, #0x0                        // #0
         : 711              }
    0.00 :   ffff8000101a16b4:       autiasp
    0.00 :   ffff8000101a16b8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (5 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010208a10 <kmem_cache_alloc>:
         : 6                kmem_cache_alloc():
         : 2925             * of fetching cpu_slab's data. tid should be fetched before anything
         : 2926             * on c to guarantee that object and page associated with previous tid
         : 2927             * won't be used with current tid. If we fetch tid first, object and
         : 2928             * page could be one associated with next tid and our alloc/free
         : 2929             * request will be failed. In this case, we will retry. So, no problem.
         : 2930             */
    0.00 :   ffff800010208a10:       paciasp
    0.00 :   ffff800010208a14:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff800010208a18:       mov     x29, sp
    0.00 :   ffff800010208a1c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010208a20:       mov     x19, x0
         : 2926             barrier();
    0.00 :   ffff800010208a24:       adrp    x0, ffff800011f17000 <__boot_cpu_mode>
         : 2925             */
    0.00 :   ffff800010208a28:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010208a2c:       add     x20, x20, #0x948
         : 2926             barrier();
    0.00 :   ffff800010208a30:       ldr     x0, [x0, #16]
         : 2925             */
    0.00 :   ffff800010208a34:       ldr     x2, [x20]
    0.00 :   ffff800010208a38:       str     x2, [sp, #104]
    0.00 :   ffff800010208a3c:       mov     x2, #0x0                        // #0
    0.00 :   ffff800010208a40:       stp     x21, x22, [sp, #32]
         : 2926             barrier();
    0.00 :   ffff800010208a44:       mov     x21, #0xffffffffffffffff        // #-1
         : 2925             */
    0.00 :   ffff800010208a48:       mov     w22, w1
    0.00 :   ffff800010208a4c:       stp     x23, x24, [sp, #48]
         : 2926             barrier();
    0.00 :   ffff800010208a50:       lsl     x21, x21, x0
    0.00 :   ffff800010208a54:       tbz     x30, #55, ffff800010208bf4 <kmem_cache_alloc+0x1e4>
         : 2929             slab_pre_alloc_hook():
         : 495              if (!memcg_slab_pre_alloc_hook(s, objcgp, size, flags))
         : 496              return NULL;
         :
         : 498              return s;
         : 499              }
         :
    0.00 :   ffff800010208a58:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
         : 502              kmem_cache_alloc():
    0.00 :   ffff800010208a5c:       orr     x21, x30, x21
         : 2927             slab_pre_alloc_hook():
         : 499              static inline void slab_post_alloc_hook(struct kmem_cache *s,
         : 500              struct obj_cgroup *objcg, gfp_t flags,
         : 501              size_t size, void **p, bool init)
         : 502              {
    0.00 :   ffff800010208a60:       mov     x0, x19
         :
    0.00 :   ffff800010208a64:       ldr     w24, [x1, #3512]
    0.00 :   ffff800010208a68:       and     w24, w22, w24
         : 499              {
    0.00 :   ffff800010208a6c:       mov     w1, w24
    0.00 :   ffff800010208a70:       bl      ffff8000101ad7a0 <should_failslab>
    0.00 :   ffff800010208a74:       cbnz    w0, ffff800010208c18 <kmem_cache_alloc+0x208>
         : 503              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010208a78:       b       ffff800010208bd8 <kmem_cache_alloc+0x1c8>
         : 45               memcg_slab_pre_alloc_hook():
         : 270              if (!memcg_kmem_enabled())
    0.00 :   ffff800010208a7c:       tbnz    w24, #22, ffff800010208a88 <kmem_cache_alloc+0x78>
    0.00 :   ffff800010208a80:       ldr     w0, [x19, #8]
    0.00 :   ffff800010208a84:       tbz     w0, #26, ffff800010208bd8 <kmem_cache_alloc+0x1c8>
         : 273              if (!(flags & __GFP_ACCOUNT) && !(s->flags & SLAB_ACCOUNT))
    0.00 :   ffff800010208a88:       bl      ffff8000102246b0 <get_obj_cgroup_from_current>
    0.00 :   ffff800010208a8c:       mov     x23, x0
         : 274              return true;
    0.00 :   ffff800010208a90:       cbz     x0, ffff800010208bd8 <kmem_cache_alloc+0x1c8>
         : 276              obj_full_size():
         : 255              * For each accounted object there is an extra space which is used
    0.00 :   ffff800010208a94:       ldr     w2, [x19, #24]
         : 257              memcg_slab_pre_alloc_hook():
         : 277              if (!objcg)
    0.00 :   ffff800010208a98:       mov     w1, w24
    0.00 :   ffff800010208a9c:       add     x2, x2, #0x8
    0.00 :   ffff800010208aa0:       bl      ffff800010224d28 <obj_cgroup_charge>
    0.00 :   ffff800010208aa4:       cbnz    w0, ffff800010208ca8 <kmem_cache_alloc+0x298>
    0.00 :   ffff800010208aa8:       str     x25, [sp, #64]
         : 283              slab_alloc_node():
         :
    0.00 :   ffff800010208aac:       cbz     x19, ffff800010208cd4 <kmem_cache_alloc+0x2c4>
         : 2838             * cpu changes by refetching the per cpu area pointer.
    0.00 :   ffff800010208ab0:       str     xzr, [sp, #96]
         : 2840             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
   27.93 :   ffff800010208ab4:       mrs     x2, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010208ab8:       ldr     w0, [x2, #8]
         : 47               pc += val;
    0.00 :   ffff800010208abc:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010208ac0:       str     w0, [x2, #8]
         : 50               slab_alloc_node():
         : 2854             #endif
    0.00 :   ffff800010208ac4:       ldr     x1, [x19]
    0.00 :   ffff800010208ac8:       add     x1, x1, #0x8
    0.00 :   ffff800010208acc:       bl      ffff800010202198 <__kern_my_cpu_offset>
         : 2858             __percpu_read_64():
         : 125              __PERCPU_RET_OP_CASE( ,  , name, 64, op_llsc, op_lse)
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
    0.00 :   ffff800010208ad0:       ldr     x24, [x1, x0]
         : 132              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
   43.30 :   ffff800010208ad4:       ldr     x0, [x2, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010208ad8:       sub     x0, x0, #0x1
    0.00 :   ffff800010208adc:       str     w0, [x2, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010208ae0:       cbnz    x0, ffff800010208be4 <kmem_cache_alloc+0x1d4>
         : 80               slab_alloc_node():
    0.00 :   ffff800010208ae4:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         :
    0.00 :   ffff800010208ae8:       ldr     x1, [x19]
    0.00 :   ffff800010208aec:       bl      ffff800010202198 <__kern_my_cpu_offset>
    0.00 :   ffff800010208af0:       add     x2, x1, x0
         : 2857             local_irq_restore(flags);
    0.00 :   ffff800010208af4:       ldr     x3, [x2, #8]
    0.00 :   ffff800010208af8:       cmp     x3, x24
    0.00 :   ffff800010208afc:       b.ne    ffff800010208ab4 <kmem_cache_alloc+0xa4>  // b.any
         : 2878             * The fastpath works by first checking if the lockless freelist can be used.
    0.00 :   ffff800010208b00:       ldr     x2, [x2, #16]
         : 2876             * overhead for requests that can be satisfied on the fastpath.
    0.00 :   ffff800010208b04:       ldr     x0, [x1, x0]
    0.00 :   ffff800010208b08:       str     x0, [sp, #96]
         : 2878             * The fastpath works by first checking if the lockless freelist can be used.
    0.00 :   ffff800010208b0c:       cmp     x2, #0x0
    0.00 :   ffff800010208b10:       ccmp    x0, #0x0, #0x4, ne  // ne = any
    0.00 :   ffff800010208b14:       b.eq    ffff800010208cb8 <kmem_cache_alloc+0x2a8>  // b.none
         : 2882             get_freepointer():
         : 288              }
    0.00 :   ffff800010208b18:       ldr     w3, [x19, #40]
         : 290              get_current():
    0.00 :   ffff800010208b1c:       mrs     x2, sp_el0
         : 20               __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010208b20:       ldr     w1, [x2, #8]
         : 47               pc += val;
    0.00 :   ffff800010208b24:       add     w1, w1, #0x1
         : 49               freelist_dereference():
         : 281              * freepointer to be restored incorrectly.
    0.00 :   ffff800010208b28:       ldr     x25, [x0, x3]
         : 283              __preempt_count_add():
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    6.44 :   ffff800010208b2c:       str     w1, [x2, #8]
         : 50               slab_alloc_node():
         : 2897             object = kfence_alloc(s, orig_size, gfpflags);
    0.00 :   ffff800010208b30:       ldr     x4, [x19]
         : 2899             next_tid():
         :
    0.00 :   ffff800010208b34:       add     x3, x24, #0x100
         : 2125             slab_alloc_node():
         : 2897             object = kfence_alloc(s, orig_size, gfpflags);
    0.00 :   ffff800010208b38:       bl      ffff800010202198 <__kern_my_cpu_offset>
    0.00 :   ffff800010208b3c:       ldr     x5, [sp, #96]
    0.00 :   ffff800010208b40:       add     x4, x4, x0
         : 2901             __cmpxchg_double():
         : 145              {                                                                       \
         : 146              return __lse_ll_sc_body(_cmpxchg_double##name,                  \
         : 147              old1, old2, new1, new2, ptr);           \
         : 148              }
         :
         : 150              __CMPXCHG_DBL(   )
    0.00 :   ffff800010208b44:       bl      ffff800010202150 <system_uses_lse_atomics>
    0.00 :   ffff800010208b48:       tst     w0, #0xff
    0.00 :   ffff800010208b4c:       b.ne    ffff800010208c20 <kmem_cache_alloc+0x210>  // b.any
         : 154              __ll_sc__cmpxchg_double():
         : 347              : cl);                                                          \
         : 348              \
         : 349              return ret;                                                     \
         : 350              }
         :
         : 352              __CMPXCHG_DBL(   ,        ,  ,         )
    0.00 :   ffff800010208b50:       b       ffff80001020b854 <slabinfo_write+0x404>
         : 354              get_current():
    0.00 :   ffff800010208b54:       mrs     x2, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010208b58:       ldr     x1, [x2, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010208b5c:       sub     x1, x1, #0x1
    0.00 :   ffff800010208b60:       str     w1, [x2, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010208b64:       cbnz    x1, ffff800010208c50 <kmem_cache_alloc+0x240>
    0.00 :   ffff800010208b68:       str     x0, [sp, #88]
         : 76               slab_alloc_node():
    0.00 :   ffff800010208b6c:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010208b70:       ldr     x0, [sp, #88]
    0.00 :   ffff800010208b74:       cbnz    x0, ffff800010208ab4 <kmem_cache_alloc+0xa4>
         : 2900             prefetch_freepointer():
         : 293              {
    0.00 :   ffff800010208b78:       ldr     w0, [x19, #40]
         : 295              prefetch():
         : 274              #define ARCH_HAS_PREFETCH
         : 275              static inline void prefetch(const void *ptr)
         : 276              {
         : 277              asm volatile("prfm pldl1keep, %a0\n" : : "p" (ptr));
         : 278              }
         :
    0.00 :   ffff800010208b7c:       prfm    pldl1keep, [x25, x0]
    0.00 :   ffff800010208b80:       ldr     x0, [sp, #96]
         : 282              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010208b84:       nop
    0.00 :   ffff800010208b88:       nop
         : 24               slab_want_init_on_alloc():
         : 621              return !(c->ctor ||
         : 622              (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON)));
         : 623              return false;
         : 624              }
         :
         : 626              #ifdef CONFIG_PRINTK
    0.00 :   ffff800010208b8c:       ubfx    x5, x22, #8, #1
         : 628              slab_alloc_node():
         : 2913             tid = this_cpu_read(s->cpu_slab->tid);
    0.00 :   ffff800010208b90:       mov     x0, x19
    0.00 :   ffff800010208b94:       mov     w2, w22
    0.00 :   ffff800010208b98:       mov     x1, x23
    0.00 :   ffff800010208b9c:       add     x4, sp, #0x60
    0.00 :   ffff800010208ba0:       mov     x3, #0x1                        // #1
    0.00 :   ffff800010208ba4:       bl      ffff800010203eb0 <slab_post_alloc_hook>
         : 2920             kmem_cache_alloc():
         :
         : 2932             /*
         : 2933             * The transaction ids are globally unique per cpu and per operation on
         : 2934             * a per cpu queue. Thus they can be guarantee that the cmpxchg_double
         : 2935             * occurs on the right processor and that there was no operation on the
    0.00 :   ffff800010208ba8:       ldr     x25, [sp, #64]
         : 2937             slab_alloc_node():
         : 2915             } while (IS_ENABLED(CONFIG_PREEMPTION) &&
    0.00 :   ffff800010208bac:       ldr     x0, [sp, #96]
         : 2917             kmem_cache_alloc():
         : 2932             * linked list in between.
    0.00 :   ffff800010208bb0:       ldr     x2, [sp, #104]
    0.00 :   ffff800010208bb4:       ldr     x1, [x20]
    0.00 :   ffff800010208bb8:       eor     x1, x2, x1
    0.00 :   ffff800010208bbc:       cbnz    x1, ffff800010208ce0 <kmem_cache_alloc+0x2d0>
    0.00 :   ffff800010208bc0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010208bc4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010208bc8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010208bcc:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010208bd0:       autiasp
    0.00 :   ffff800010208bd4:       ret
         : 2943             slab_alloc_node():
         :
    0.00 :   ffff800010208bd8:       mov     x23, #0x0                       // #0
    0.00 :   ffff800010208bdc:       str     x25, [sp, #64]
    0.00 :   ffff800010208be0:       b       ffff800010208aac <kmem_cache_alloc+0x9c>
         : 2835             __preempt_count_dec_and_test():
    0.00 :   ffff800010208be4:       ldr     x0, [x2, #8]
    0.00 :   ffff800010208be8:       cbnz    x0, ffff800010208ae8 <kmem_cache_alloc+0xd8>
         : 75               slab_alloc_node():
         : 2854             #endif
    0.00 :   ffff800010208bec:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010208bf0:       b       ffff800010208ae8 <kmem_cache_alloc+0xd8>
         : 2857             slab_pre_alloc_hook():
         :
    0.00 :   ffff800010208bf4:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
         : 497              kmem_cache_alloc():
         : 2926             barrier();
    0.00 :   ffff800010208bf8:       and     x21, x21, #0x7fffffffffffff
    0.00 :   ffff800010208bfc:       bic     x21, x30, x21
         : 2929             slab_pre_alloc_hook():
         : 499              {
    0.00 :   ffff800010208c00:       mov     x0, x19
         :
    0.00 :   ffff800010208c04:       ldr     w24, [x1, #3512]
    0.00 :   ffff800010208c08:       and     w24, w22, w24
         : 499              {
    0.00 :   ffff800010208c0c:       mov     w1, w24
    0.00 :   ffff800010208c10:       bl      ffff8000101ad7a0 <should_failslab>
    0.00 :   ffff800010208c14:       cbz     w0, ffff800010208a78 <kmem_cache_alloc+0x68>
         : 503              slab_alloc_node():
         : 2836             /*
    0.00 :   ffff800010208c18:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010208c1c:       b       ffff800010208bb0 <kmem_cache_alloc+0x1a0>
         : 2839             __lse__cmpxchg_double():
         : 414              : cl);                                                          \
         : 415              \
         : 416              return x0;                                                      \
         : 417              }
         :
         : 419              __CMPXCHG_DBL(   ,   )
    0.00 :   ffff800010208c20:       mov     x0, x5
    0.00 :   ffff800010208c24:       mov     x1, x24
    0.00 :   ffff800010208c28:       mov     x2, x25
    0.00 :   ffff800010208c2c:       casp    x0, x1, x2, x3, [x4]
   22.33 :   ffff800010208c30:       eor     x0, x0, x5
    0.00 :   ffff800010208c34:       eor     x1, x1, x24
    0.00 :   ffff800010208c38:       orr     x0, x0, x1
         : 427              get_current():
    0.00 :   ffff800010208c3c:       mrs     x2, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010208c40:       ldr     x1, [x2, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010208c44:       sub     x1, x1, #0x1
    0.00 :   ffff800010208c48:       str     w1, [x2, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010208c4c:       cbz     x1, ffff800010208b68 <kmem_cache_alloc+0x158>
    0.00 :   ffff800010208c50:       ldr     x1, [x2, #8]
    0.00 :   ffff800010208c54:       cbz     x1, ffff800010208b68 <kmem_cache_alloc+0x158>
    0.00 :   ffff800010208c58:       b       ffff800010208b74 <kmem_cache_alloc+0x164>
         : 78               slab_want_init_on_free():
         : 628              struct kmem_obj_info {
         : 629              void *kp_ptr;
         : 630              struct page *kp_page;
         : 631              void *kp_objp;
         : 632              unsigned long kp_data_offset;
         : 633              struct kmem_cache *kp_slab_cache;
    0.00 :   ffff800010208c5c:       ldr     x1, [x19, #72]
    0.00 :   ffff800010208c60:       cbnz    x1, ffff800010208b88 <kmem_cache_alloc+0x178>
         : 629              void *kp_ret;
    0.00 :   ffff800010208c64:       ldr     w1, [x19, #8]
    0.00 :   ffff800010208c68:       and     w1, w1, #0xff800
    0.00 :   ffff800010208c6c:       and     w1, w1, #0xfff80fff
         : 628              struct kmem_cache *kp_slab_cache;
    0.00 :   ffff800010208c70:       cbnz    w1, ffff800010208b88 <kmem_cache_alloc+0x178>
         : 630              maybe_wipe_obj_freeptr():
         : 2809             if (slub_percpu_partial(c)) {
    0.00 :   ffff800010208c74:       cbz     x0, ffff800010208b88 <kmem_cache_alloc+0x178>
         : 2810             page = c->page = slub_percpu_partial(c);
    0.00 :   ffff800010208c78:       ldr     w1, [x19, #40]
    0.00 :   ffff800010208c7c:       str     xzr, [x0, x1]
    0.00 :   ffff800010208c80:       b       ffff800010208b88 <kmem_cache_alloc+0x178>
         : 2814             slab_want_init_on_alloc():
         : 615              &init_on_free))
    0.00 :   ffff800010208c84:       ldr     x0, [x19, #72]
         : 616              return !(c->ctor ||
    0.00 :   ffff800010208c88:       mov     w5, #0x0                        // #0
         : 615              &init_on_free))
    0.00 :   ffff800010208c8c:       cbnz    x0, ffff800010208b90 <kmem_cache_alloc+0x180>
         : 617              (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON)));
    0.00 :   ffff800010208c90:       ldr     w0, [x19, #8]
         : 618              return false;
    0.00 :   ffff800010208c94:       ubfx    x5, x22, #8, #1
         : 617              (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON)));
    0.00 :   ffff800010208c98:       and     w0, w0, #0xff800
    0.00 :   ffff800010208c9c:       ands    w0, w0, #0xfff80fff
         : 618              return false;
    0.00 :   ffff800010208ca0:       csinc   w5, w5, wzr, ne  // ne = any
    0.00 :   ffff800010208ca4:       b       ffff800010208b90 <kmem_cache_alloc+0x180>
         : 621              percpu_ref_put():
         : 338              *
         : 339              * This function is safe to call as long as @ref is between init and exit.
         : 340              */
         : 341              static inline void percpu_ref_put(struct percpu_ref *ref)
         : 342              {
         : 343              percpu_ref_put_many(ref, 1);
    0.00 :   ffff800010208ca8:       mov     x0, x23
    0.00 :   ffff800010208cac:       bl      ffff800010203de0 <percpu_ref_put_many.constprop.111>
         : 346              slab_alloc_node():
         : 2836             /*
    0.00 :   ffff800010208cb0:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010208cb4:       b       ffff800010208bb0 <kmem_cache_alloc+0x1a0>
         : 2879             * If not then __slab_alloc is called for slow processing.
    0.00 :   ffff800010208cb8:       mov     x3, x21
    0.00 :   ffff800010208cbc:       mov     w2, #0xffffffff                 // #-1
    0.00 :   ffff800010208cc0:       mov     w1, w22
    0.00 :   ffff800010208cc4:       mov     x0, x19
    0.00 :   ffff800010208cc8:       bl      ffff800010207b20 <__slab_alloc.isra.102>
    0.00 :   ffff800010208ccc:       str     x0, [sp, #96]
    0.00 :   ffff800010208cd0:       b       ffff800010208b84 <kmem_cache_alloc+0x174>
         : 2836             /*
    0.00 :   ffff800010208cd4:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010208cd8:       ldr     x25, [sp, #64]
         :
    0.00 :   ffff800010208cdc:       b       ffff800010208bb0 <kmem_cache_alloc+0x1a0>
    0.00 :   ffff800010208ce0:       str     x25, [sp, #64]
         : 2838             kmem_cache_alloc():
         : 2932             * linked list in between.
    0.00 :   ffff800010208ce4:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (11 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100d5900 <update_irq_load_avg>:
         : 6                update_irq_load_avg():
         : 435              *   load_avg and runnable_avg are not supported and meaningless.
         : 436              *
         : 437              */
         :
         : 439              int update_irq_load_avg(struct rq *rq, u64 running)
         : 440              {
    0.37 :   ffff8000100d5900:       mov     x7, x0
    0.00 :   ffff8000100d5904:       paciasp
    0.00 :   ffff8000100d5908:       stp     x29, x30, [sp, #-16]!
         : 444              topology_get_freq_scale():
         :
         : 31               DECLARE_PER_CPU(unsigned long, arch_freq_scale);
         :
         : 33               static inline unsigned long topology_get_freq_scale(int cpu)
         : 34               {
         : 35               return per_cpu(arch_freq_scale, cpu);
    0.00 :   ffff8000100d590c:       adrp    x3, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100d5910:       add     x3, x3, #0x760
         : 38               update_irq_load_avg():
    0.00 :   ffff8000100d5914:       mov     x29, sp
         : 436              topology_get_freq_scale():
    0.00 :   ffff8000100d5918:       ldrsw   x4, [x7, #2576]
    0.00 :   ffff8000100d591c:       adrp    x0, ffff800011778000 <ipi_to_irq>
    0.00 :   ffff8000100d5920:       add     x0, x0, #0x710
         : 33               topology_get_cpu_scale():
         : 21               return per_cpu(cpu_scale, cpu);
    0.00 :   ffff8000100d5924:       adrp    x2, ffff800011778000 <ipi_to_irq>
    0.00 :   ffff8000100d5928:       add     x2, x2, #0x700
         : 24               ___update_load_sum():
         : 189              delta = now - sa->last_update_time;
    0.00 :   ffff8000100d592c:       add     x6, x7, #0xac0
         : 191              topology_get_freq_scale():
         : 30               return per_cpu(arch_freq_scale, cpu);
    0.00 :   ffff8000100d5930:       ldr     x3, [x3, x4, lsl #3]
         : 32               update_irq_load_avg():
         : 457              * We start to decay with normal context time and then we add the
         : 458              * interrupt context time.
         : 459              * We can safely remove running from rq->clock because
         : 460              * rq->clock += delta with delta >= running
         : 461              */
         : 462              ret = ___update_load_sum(rq->clock - running, &rq->avg_irq,
    0.00 :   ffff8000100d5934:       ldr     x4, [x7, #2400]
         : 443              running = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));
    0.00 :   ffff8000100d5938:       ldr     x0, [x0, x3]
         : 444              running = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));
    0.00 :   ffff8000100d593c:       ldr     x2, [x2, x3]
         : 443              running = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));
    0.00 :   ffff8000100d5940:       mul     x1, x1, x0
         : 445              ___update_load_sum():
         : 189              delta = now - sa->last_update_time;
    0.00 :   ffff8000100d5944:       ldr     x3, [x7, #2752]
         : 191              update_irq_load_avg():
         : 443              running = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));
    0.00 :   ffff8000100d5948:       lsr     x1, x1, #10
         : 444              running = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));
    0.00 :   ffff8000100d594c:       mul     x1, x1, x2
    0.00 :   ffff8000100d5950:       lsr     x1, x1, #10
         : 457              ret = ___update_load_sum(rq->clock - running, &rq->avg_irq,
    1.20 :   ffff8000100d5954:       sub     x2, x4, x1
         : 459              ___update_load_sum():
         : 194              if ((s64)delta < 0) {
    0.00 :   ffff8000100d5958:       subs    x5, x2, x3
    0.00 :   ffff8000100d595c:       b.mi    ffff8000100d5a4c <update_irq_load_avg+0x14c>  // b.first
         : 203              delta >>= 10;
    0.00 :   ffff8000100d5960:       lsr     x0, x5, #10
         : 204              if (!delta)
    0.00 :   ffff8000100d5964:       cbz     x0, ffff8000100d5a30 <update_irq_load_avg+0x130>
         : 207              sa->last_update_time += delta << 10;
   28.74 :   ffff8000100d5968:       and     x1, x5, #0xfffffffffffffc00
    0.00 :   ffff8000100d596c:       add     x2, x1, x3
    0.00 :   ffff8000100d5970:       str     x2, [x7, #2752]
         : 211              accumulate_sum():
         : 112              delta += sa->period_contrib;
    0.00 :   ffff8000100d5974:       ldr     w1, [x6, #28]
    0.00 :   ffff8000100d5978:       add     x0, x1, x0
         : 118              if (periods) {
    0.00 :   ffff8000100d597c:       cmp     x0, #0x3ff
         : 113              periods = delta / 1024; /* A period is 1024us (~1ms) */
    0.00 :   ffff8000100d5980:       lsr     x3, x0, #10
         : 118              if (periods) {
    0.00 :   ffff8000100d5984:       b.hi    ffff8000100d5ad4 <update_irq_load_avg+0x1d4>  // b.pmore
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5988:       str     w0, [x6, #28]
         : 145              ___update_load_sum():
         : 230              if (!accumulate_sum(delta, sa, load, runnable, running))
    0.00 :   ffff8000100d598c:       cmp     w3, #0x0
    0.00 :   ffff8000100d5990:       cset    w8, ne  // ne = any
         : 194              if ((s64)delta < 0) {
    0.00 :   ffff8000100d5994:       subs    x1, x4, x2
    0.00 :   ffff8000100d5998:       b.mi    ffff8000100d5b44 <update_irq_load_avg+0x244>  // b.first
         : 203              delta >>= 10;
    0.00 :   ffff8000100d599c:       lsr     x0, x1, #10
         : 204              if (!delta)
    0.00 :   ffff8000100d59a0:       cbz     x0, ffff8000100d59f4 <update_irq_load_avg+0xf4>
         : 207              sa->last_update_time += delta << 10;
    0.00 :   ffff8000100d59a4:       and     x1, x1, #0xfffffffffffffc00
    0.00 :   ffff8000100d59a8:       add     x1, x1, x2
    0.00 :   ffff8000100d59ac:       str     x1, [x7, #2752]
         : 211              accumulate_sum():
         : 112              delta += sa->period_contrib;
    0.00 :   ffff8000100d59b0:       ldr     w5, [x6, #28]
    0.00 :   ffff8000100d59b4:       ldr     x12, [x6, #8]
    0.00 :   ffff8000100d59b8:       add     x2, x0, w5, uxtw
         : 118              if (periods) {
    0.00 :   ffff8000100d59bc:       cmp     x2, #0x3ff
         : 113              periods = delta / 1024; /* A period is 1024us (~1ms) */
    0.00 :   ffff8000100d59c0:       lsr     x13, x2, #10
         : 118              if (periods) {
   57.63 :   ffff8000100d59c4:       b.hi    ffff8000100d5a6c <update_irq_load_avg+0x16c>  // b.pmore
    0.00 :   ffff8000100d59c8:       ldr     w10, [x6, #24]
    0.00 :   ffff8000100d59cc:       mov     w11, w2
    0.00 :   ffff8000100d59d0:       ldr     x9, [x6, #16]
         : 146              sa->load_sum += load * contrib;
    0.00 :   ffff8000100d59d4:       mov     w1, w0
         : 148              ___update_load_sum():
         : 230              if (!accumulate_sum(delta, sa, load, runnable, running))
    0.00 :   ffff8000100d59d8:       cmp     w13, #0x0
         : 232              accumulate_sum():
         : 146              sa->load_sum += load * contrib;
    0.00 :   ffff8000100d59dc:       add     x2, x1, x12
    0.00 :   ffff8000100d59e0:       cinc    w8, w8, ne  // ne = any
         : 150              sa->util_sum += contrib << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100d59e4:       add     w0, w10, w0, lsl #10
         : 148              sa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100d59e8:       add     x1, x9, x1, lsl #10
    0.00 :   ffff8000100d59ec:       stp     x2, x1, [x6, #8]
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d59f0:       stp     w0, w11, [x6, #24]
         : 145              update_irq_load_avg():
         : 466              ret += ___update_load_sum(rq->clock, &rq->avg_irq,
         : 467              1,
         : 468              1,
         : 469              1);
         :
         : 471              if (ret) {
    0.00 :   ffff8000100d59f4:       cbz     w8, ffff8000100d5a20 <update_irq_load_avg+0x120>
         : 473              get_pelt_divider():
         : 42               }
         : 43               #endif
         :
         : 45               static inline u32 get_pelt_divider(struct sched_avg *avg)
         : 46               {
         : 47               return LOAD_AVG_MAX - 1024 + avg->period_contrib;
    0.00 :   ffff8000100d59f8:       ldr     w0, [x7, #2780]
    0.00 :   ffff8000100d59fc:       mov     w2, #0xb67e                     // #46718
         : 50               ___update_load_avg():
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d5a00:       ldr     w1, [x6, #24]
         : 272              get_pelt_divider():
    0.00 :   ffff8000100d5a04:       add     w4, w0, w2
         : 43               div_u64_rem():
         : 28               * divide.
         : 29               */
         : 30               static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
         : 31               {
         : 32               *remainder = dividend % divisor;
         : 33               return dividend / divisor;
    0.00 :   ffff8000100d5a08:       ldp     x3, x2, [x6, #8]
         : 35               ___update_load_avg():
    0.00 :   ffff8000100d5a0c:       udiv    w0, w1, w4
         : 271              div_u64_rem():
    0.00 :   ffff8000100d5a10:       udiv    x3, x3, x4
    0.00 :   ffff8000100d5a14:       udiv    x2, x2, x4
         : 30               ___update_load_avg():
         : 269              sa->runnable_avg = div_u64(sa->runnable_sum, divider);
    0.00 :   ffff8000100d5a18:       stp     x3, x2, [x6, #32]
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d5a1c:       str     x0, [x7, #2800]
         : 272              update_irq_load_avg():
         : 472              ___update_load_avg(&rq->avg_irq, 1);
         : 473              trace_pelt_irq_tp(rq);
         : 474              }
         :
         : 476              return ret;
         : 477              }
    0.00 :   ffff8000100d5a20:       mov     w0, w8
    0.00 :   ffff8000100d5a24:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000100d5a28:       autiasp
    0.00 :   ffff8000100d5a2c:       ret
         : 482              ___update_load_sum():
         : 194              if ((s64)delta < 0) {
    0.00 :   ffff8000100d5a30:       mov     x2, x3
    0.00 :   ffff8000100d5a34:       subs    x1, x4, x3
    0.00 :   ffff8000100d5a38:       b.mi    ffff8000100d5a60 <update_irq_load_avg+0x160>  // b.first
         : 203              delta >>= 10;
    0.00 :   ffff8000100d5a3c:       lsr     x0, x1, #10
         : 204              if (!delta)
    0.00 :   ffff8000100d5a40:       mov     w8, #0x0                        // #0
    0.00 :   ffff8000100d5a44:       cbnz    x0, ffff8000100d59a4 <update_irq_load_avg+0xa4>
    0.00 :   ffff8000100d5a48:       b       ffff8000100d5a20 <update_irq_load_avg+0x120>
         : 195              sa->last_update_time = now;
    0.00 :   ffff8000100d5a4c:       str     x2, [x7, #2752]
         : 203              delta >>= 10;
    0.00 :   ffff8000100d5a50:       lsr     x0, x1, #10
         : 204              if (!delta)
    0.00 :   ffff8000100d5a54:       mov     w8, #0x0                        // #0
    0.00 :   ffff8000100d5a58:       cbnz    x0, ffff8000100d59a4 <update_irq_load_avg+0xa4>
    0.00 :   ffff8000100d5a5c:       b       ffff8000100d5a20 <update_irq_load_avg+0x120>
         : 205              return 0;
    0.00 :   ffff8000100d5a60:       mov     w8, #0x0                        // #0
         : 195              sa->last_update_time = now;
    0.00 :   ffff8000100d5a64:       str     x4, [x7, #2752]
         : 197              update_irq_load_avg():
         : 466              if (ret) {
    0.00 :   ffff8000100d5a68:       b       ffff8000100d5a20 <update_irq_load_avg+0x120>
         : 468              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d5a6c:       mov     x0, #0x83ff                     // #33791
    0.00 :   ffff8000100d5a70:       movk    x0, #0x1f, lsl #16
    0.00 :   ffff8000100d5a74:       cmp     x2, x0
    0.00 :   ffff8000100d5a78:       b.hi    ffff8000100d5b4c <update_irq_load_avg+0x24c>  // b.pmore
         : 52               if (unlikely(local_n >= LOAD_AVG_PERIOD)) {
    0.00 :   ffff8000100d5a7c:       cmp     w13, #0x1f
    0.00 :   ffff8000100d5a80:       b.hi    ffff8000100d5bb8 <update_irq_load_avg+0x2b8>  // b.pmore
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d5a84:       adrp    x0, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d5a88:       add     x0, x0, #0xb98
         : 60               mul_u64_u32_shr():
         : 161              #if defined(CONFIG_ARCH_SUPPORTS_INT128) && defined(__SIZEOF_INT128__)
         :
         : 163              #ifndef mul_u64_u32_shr
         : 164              static inline u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)
         : 165              {
         : 166              return (u64)(((unsigned __int128)a * mul) >> shift);
    0.00 :   ffff8000100d5a8c:       ldr     x3, [x6, #16]
    0.00 :   ffff8000100d5a90:       ldr     w10, [x0, w13, uxtw #2]
         : 169              accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d5a94:       ldr     w0, [x6, #24]
         : 124              mul_u64_u32_shr():
    0.00 :   ffff8000100d5a98:       mul     x4, x10, x12
    0.00 :   ffff8000100d5a9c:       mul     x1, x10, x3
    0.00 :   ffff8000100d5aa0:       umulh   x12, x10, x12
    0.00 :   ffff8000100d5aa4:       umulh   x3, x10, x3
    0.00 :   ffff8000100d5aa8:       extr    x12, x12, x4, #32
    0.00 :   ffff8000100d5aac:       extr    x9, x3, x1, #32
    0.00 :   ffff8000100d5ab0:       mul     x0, x0, x10
    0.00 :   ffff8000100d5ab4:       lsr     x10, x0, #32
         : 169              accumulate_sum():
         : 127              delta %= 1024;
    0.00 :   ffff8000100d5ab8:       and     x2, x2, #0x3ff
         : 139              contrib = __accumulate_pelt_segments(periods,
    0.00 :   ffff8000100d5abc:       mov     w1, #0x400                      // #1024
    0.00 :   ffff8000100d5ac0:       mov     w11, w2
    0.00 :   ffff8000100d5ac4:       sub     w1, w1, w5
    0.00 :   ffff8000100d5ac8:       mov     x0, x13
    0.00 :   ffff8000100d5acc:       bl      ffff8000100d4ca8 <__accumulate_pelt_segments>
    0.00 :   ffff8000100d5ad0:       b       ffff8000100d59d4 <update_irq_load_avg+0xd4>
         : 146              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
   10.91 :   ffff8000100d5ad4:       mov     x1, #0x83ff                     // #33791
    0.00 :   ffff8000100d5ad8:       movk    x1, #0x1f, lsl #16
    0.00 :   ffff8000100d5adc:       cmp     x0, x1
         : 43               accumulate_sum():
         : 119              sa->load_sum = decay_load(sa->load_sum, periods);
    0.00 :   ffff8000100d5ae0:       ldr     x1, [x6, #8]
         : 121              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d5ae4:       b.hi    ffff8000100d5b5c <update_irq_load_avg+0x25c>  // b.pmore
         : 52               if (unlikely(local_n >= LOAD_AVG_PERIOD)) {
    0.00 :   ffff8000100d5ae8:       cmp     w3, #0x1f
    0.00 :   ffff8000100d5aec:       b.hi    ffff8000100d5b68 <update_irq_load_avg+0x268>  // b.pmore
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d5af0:       adrp    x5, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d5af4:       add     x5, x5, #0xb98
         : 60               mul_u64_u32_shr():
    0.00 :   ffff8000100d5af8:       ldr     x8, [x6, #16]
    0.00 :   ffff8000100d5afc:       ldr     w9, [x5, w3, uxtw #2]
         : 163              accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d5b00:       ldr     w5, [x6, #24]
         : 124              mul_u64_u32_shr():
    0.00 :   ffff8000100d5b04:       mul     x11, x9, x1
    0.00 :   ffff8000100d5b08:       mul     x10, x9, x8
    0.00 :   ffff8000100d5b0c:       umulh   x1, x9, x1
    0.00 :   ffff8000100d5b10:       umulh   x8, x9, x8
    0.00 :   ffff8000100d5b14:       extr    x1, x1, x11, #32
    0.00 :   ffff8000100d5b18:       extr    x8, x8, x10, #32
    0.00 :   ffff8000100d5b1c:       stp     x1, x8, [x6, #8]
    0.00 :   ffff8000100d5b20:       mul     x1, x5, x9
    0.00 :   ffff8000100d5b24:       lsr     x1, x1, #32
         : 170              accumulate_sum():
         : 127              delta %= 1024;
    0.00 :   ffff8000100d5b28:       and     x0, x0, #0x3ff
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d5b2c:       str     w1, [x6, #24]
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5b30:       str     w0, [x6, #28]
         : 145              ___update_load_sum():
         : 230              if (!accumulate_sum(delta, sa, load, runnable, running))
    0.00 :   ffff8000100d5b34:       cmp     w3, #0x0
    0.00 :   ffff8000100d5b38:       cset    w8, ne  // ne = any
         : 194              if ((s64)delta < 0) {
    0.00 :   ffff8000100d5b3c:       subs    x1, x4, x2
    0.00 :   ffff8000100d5b40:       b.pl    ffff8000100d599c <update_irq_load_avg+0x9c>  // b.nfrst
         : 195              sa->last_update_time = now;
    0.00 :   ffff8000100d5b44:       str     x4, [x7, #2752]
         : 196              return 0;
    0.00 :   ffff8000100d5b48:       b       ffff8000100d59f4 <update_irq_load_avg+0xf4>
         : 198              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d5b4c:       mov     x9, #0x0                        // #0
    0.00 :   ffff8000100d5b50:       mov     x12, #0x0                       // #0
    0.00 :   ffff8000100d5b54:       mov     w10, #0x0                       // #0
    0.00 :   ffff8000100d5b58:       b       ffff8000100d5ab8 <update_irq_load_avg+0x1b8>
         : 44               accumulate_sum():
         : 120              sa->runnable_sum =
    0.00 :   ffff8000100d5b5c:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000100d5b60:       stp     xzr, xzr, [x6, #8]
         : 123              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d5b64:       b       ffff8000100d5b28 <update_irq_load_avg+0x228>
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d5b68:       and     x11, x3, #0x1f
    0.00 :   ffff8000100d5b6c:       adrp    x9, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d5b70:       add     x9, x9, #0xb98
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d5b74:       lsr     w5, w3, #5
    0.00 :   ffff8000100d5b78:       ldr     x8, [x6, #16]
    0.00 :   ffff8000100d5b7c:       mov     w10, w5
         : 57               mul_u64_u32_shr():
    0.00 :   ffff8000100d5b80:       ldr     w9, [x9, x11, lsl #2]
         : 162              decay_load():
    0.00 :   ffff8000100d5b84:       lsr     x1, x1, x5
         : 54               accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    1.15 :   ffff8000100d5b88:       ldr     w5, [x6, #24]
         : 124              decay_load():
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d5b8c:       lsr     x8, x8, x10
         : 55               mul_u64_u32_shr():
    0.00 :   ffff8000100d5b90:       mul     x11, x1, x9
         : 162              decay_load():
    0.00 :   ffff8000100d5b94:       lsr     x5, x5, x10
         : 54               mul_u64_u32_shr():
    0.00 :   ffff8000100d5b98:       umulh   x1, x1, x9
    0.00 :   ffff8000100d5b9c:       mul     x10, x8, x9
    0.00 :   ffff8000100d5ba0:       umulh   x8, x8, x9
    0.00 :   ffff8000100d5ba4:       extr    x1, x1, x11, #32
    0.00 :   ffff8000100d5ba8:       str     x1, [x6, #8]
    0.00 :   ffff8000100d5bac:       extr    x1, x8, x10, #32
    0.00 :   ffff8000100d5bb0:       str     x1, [x6, #16]
         : 168              decay_load():
         : 54               local_n %= LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d5bb4:       b       ffff8000100d5b20 <update_irq_load_avg+0x220>
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d5bb8:       and     x4, x13, #0x1f
    0.00 :   ffff8000100d5bbc:       adrp    x1, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d5bc0:       add     x1, x1, #0xb98
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d5bc4:       lsr     w0, w13, #5
    0.00 :   ffff8000100d5bc8:       ldr     x3, [x6, #16]
    0.00 :   ffff8000100d5bcc:       lsr     x12, x12, x0
         : 57               mul_u64_u32_shr():
    0.00 :   ffff8000100d5bd0:       ldr     w10, [x1, x4, lsl #2]
         : 162              accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d5bd4:       ldr     w4, [x6, #24]
         : 124              decay_load():
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d5bd8:       lsr     x3, x3, x0
         : 55               mul_u64_u32_shr():
    0.00 :   ffff8000100d5bdc:       mul     x9, x12, x10
         : 162              decay_load():
    0.00 :   ffff8000100d5be0:       lsr     x0, x4, x0
         : 54               mul_u64_u32_shr():
    0.00 :   ffff8000100d5be4:       mul     x1, x3, x10
    0.00 :   ffff8000100d5be8:       umulh   x12, x12, x10
    0.00 :   ffff8000100d5bec:       umulh   x3, x3, x10
    0.00 :   ffff8000100d5bf0:       extr    x12, x12, x9, #32
    0.00 :   ffff8000100d5bf4:       extr    x9, x3, x1, #32
         : 166              decay_load():
         : 54               local_n %= LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d5bf8:       b       ffff8000100d5ab0 <update_irq_load_avg+0x1b0>
 Percent |	Source code & Disassembly of bash for cycles (1 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      00000000004a96a0 <mbsmbchar@@Base>:
    0.00 :   4a96a0: stp     x29, x30, [sp, #-80]!
    0.00 :   4a96a4: mov     x29, sp
    0.00 :   4a96a8: stp     x21, x22, [sp, #32]
    0.00 :   4a96ac: adrp    x22, 4fe000 <bash_getcwd_errstr@@Base+0x2ae0>
    0.00 :   4a96b0: stp     x19, x20, [sp, #16]
    0.00 :   4a96b4: mov     x21, x0
    0.00 :   4a96b8: mov     x19, x0
    0.00 :   4a96bc: str     xzr, [x29, #64]
    0.00 :   4a96c0: ldr     x0, [x22, #1688]
    0.00 :   4a96c4: ldr     x1, [x0]
    0.00 :   4a96c8: str     x1, [x29, #72]
    0.00 :   4a96cc: mov     x1, #0x0                        // #0
    0.00 :   4a96d0: str     x23, [sp, #48]
    0.00 :   4a96d4: bl      422720 <__ctype_get_mb_cur_max@plt>
    0.00 :   4a96d8: ldrb    w1, [x21]
    0.00 :   4a96dc: cbz     w1, 4a9768 <mbsmbchar@@Base+0xc8>
    0.00 :   4a96e0: adrp    x23, 4e9000 <patch_level@@Base+0x13ad0>
    0.00 :   4a96e4: add     x21, x29, #0x40
    0.00 :   4a96e8: add     x23, x23, #0x480
    0.00 :   4a96ec: sxtw    x20, w0
    0.00 :   4a96f0: b       4a9700 <mbsmbchar@@Base+0x60>
    0.00 :   4a96f4: nop
    0.00 :   4a96f8: ldrb    w1, [x19, #1]!
    0.00 :   4a96fc: cbz     w1, 4a9768 <mbsmbchar@@Base+0xc8>
  100.00 :   4a9700: ubfx    x2, x1, #5, #3
    0.00 :   4a9704: and     w1, w1, #0x1f
    0.00 :   4a9708: ldr     w2, [x23, x2, lsl #2]
    0.00 :   4a970c: lsr     w1, w2, w1
    0.00 :   4a9710: tbnz    w1, #0, 4a96f8 <mbsmbchar@@Base+0x58>
    0.00 :   4a9714: mov     x3, x21
    0.00 :   4a9718: mov     x2, x20
    0.00 :   4a971c: mov     x1, x19
    0.00 :   4a9720: mov     x0, #0x0                        // #0
    0.00 :   4a9724: bl      421e80 <mbrtowc@plt>
    0.00 :   4a9728: cbz     x0, 4a9768 <mbsmbchar@@Base+0xc8>
    0.00 :   4a972c: add     x1, x0, #0x2
    0.00 :   4a9730: cmp     x1, #0x1
    0.00 :   4a9734: ccmp    x0, #0x1, #0x4, hi  // hi = pmore
    0.00 :   4a9738: b.eq    4a96f8 <mbsmbchar@@Base+0x58>  // b.none
    0.00 :   4a973c: ldr     x22, [x22, #1688]
    0.00 :   4a9740: mov     x0, x19
    0.00 :   4a9744: ldr     x2, [x29, #72]
    0.00 :   4a9748: ldr     x1, [x22]
    0.00 :   4a974c: eor     x1, x2, x1
    0.00 :   4a9750: cbnz    x1, 4a9770 <mbsmbchar@@Base+0xd0>
    0.00 :   4a9754: ldp     x19, x20, [sp, #16]
    0.00 :   4a9758: ldp     x21, x22, [sp, #32]
    0.00 :   4a975c: ldr     x23, [sp, #48]
    0.00 :   4a9760: ldp     x29, x30, [sp], #80
    0.00 :   4a9764: ret
    0.00 :   4a9768: mov     x19, #0x0                       // #0
    0.00 :   4a976c: b       4a973c <mbsmbchar@@Base+0x9c>
    0.00 :   4a9770: bl      422550 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010ef30 <update_process_times>:
         : 6                update_process_times():
         : 1788             #ifdef CONFIG_IRQ_WORK
         : 1789             if (in_irq())
         : 1790             irq_work_tick();
         : 1791             #endif
         : 1792             scheduler_tick();
         : 1793             if (IS_ENABLED(CONFIG_POSIX_TIMERS))
    0.00 :   ffff80001010ef30:       paciasp
    0.00 :   ffff80001010ef34:       stp     x29, x30, [sp, #-48]!
         : 1796             prandom_u32_add_noise():
         : 66               {
         : 67               /*
         : 68               * This is not used cryptographically; it's just
         : 69               * a convenient 4-word hash function. (3 xor, 2 add, 2 rol)
         : 70               */
         : 71               a ^= raw_cpu_read(net_rand_noise);
    0.00 :   ffff80001010ef38:       adrp    x3, ffff800011777000 <lru_pvecs+0x128>
         : 73               update_process_times():
    0.00 :   ffff80001010ef3c:       mov     x29, sp
    0.00 :   ffff80001010ef40:       stp     x19, x20, [sp, #16]
         : 1790             prandom_u32_add_noise():
    0.00 :   ffff80001010ef44:       add     x3, x3, #0xc88
         : 67               __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001010ef48:       mrs     x5, tpidr_el1
         : 46               update_process_times():
    0.00 :   ffff80001010ef4c:       str     x21, [sp, #32]
         : 1791             run_posix_cpu_timers();
         : 1792             }
         :
    0.00 :   ffff80001010ef50:       adrp    x21, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff80001010ef54:       ldr     x2, [x21, #2432]
         : 1788             if (IS_ENABLED(CONFIG_POSIX_TIMERS))
    0.00 :   ffff80001010ef58:       mov     w20, w0
         : 1790             prandom_u32_add_noise():
   38.97 :   ffff80001010ef5c:       ldr     x6, [x3, x5]
         : 67               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001010ef60:       mrs     x4, sp_el0
         : 26               update_process_times():
         : 1794             /*
         : 1795             * Since schedule_timeout()'s timer is defined on the stack, it must store
         : 1796             * the target task on the stack as well.
    0.00 :   ffff80001010ef64:       mov     w1, w0
    0.00 :   ffff80001010ef68:       mov     x0, x4
         : 1799             prandom_u32_add_noise():
    0.00 :   ffff80001010ef6c:       eor     x2, x2, x6
         : 67               PRND_SIPROUND(a, b, c, d);
    0.00 :   ffff80001010ef70:       add     x2, x2, w20, sxtw
         : 69               rol64():
         : 88               * @word: value to rotate
         : 89               * @shift: bits to roll
         : 90               */
         : 91               static inline __u64 rol64(__u64 word, unsigned int shift)
         : 92               {
         : 93               return (word << (shift & 63)) | (word >> ((-shift) & 63));
    0.00 :   ffff80001010ef74:       ror     x2, x2, #32
         : 95               prandom_u32_add_noise():
    0.00 :   ffff80001010ef78:       add     x2, x4, x2
    0.00 :   ffff80001010ef7c:       eor     x2, x2, x4, ror #43
         : 68               raw_cpu_write(net_rand_noise, d);
    0.00 :   ffff80001010ef80:       str     x2, [x3, x5]
         : 70               update_process_times():
    0.00 :   ffff80001010ef84:       bl      ffff8000100babc8 <account_process_tick>
         : 1795             run_local_timers():
         :
    0.00 :   ffff80001010ef88:       adrp    x0, ffff800011773000 <safe_print_seq+0x16c8>
    0.00 :   ffff80001010ef8c:       add     x0, x0, #0xc80
         : 1771             __kern_my_cpu_offset():
    0.00 :   ffff80001010ef90:       mrs     x19, tpidr_el1
         : 40               run_local_timers():
    0.00 :   ffff80001010ef94:       add     x19, x0, x19
         : 1770             * Called from the timer interrupt handler to charge one tick to the current
    0.00 :   ffff80001010ef98:       bl      ffff800010110580 <hrtimer_run_queues>
         : 1772             */
    0.00 :   ffff80001010ef9c:       ldr     x1, [x21, #2432]
    0.00 :   ffff80001010efa0:       ldr     x0, [x19, #24]
    0.00 :   ffff80001010efa4:       cmp     x1, x0
    0.00 :   ffff80001010efa8:       b.pl    ffff80001010efbc <update_process_times+0x8c>  // b.nfrst
         : 1777             PRANDOM_ADD_NOISE(jiffies, user_tick, p, 0);
   61.03 :   ffff80001010efac:       ldr     x1, [x21, #2432]
    0.00 :   ffff80001010efb0:       ldr     x0, [x19, #4760]
    0.00 :   ffff80001010efb4:       cmp     x1, x0
    0.00 :   ffff80001010efb8:       b.mi    ffff80001010efc4 <update_process_times+0x94>  // b.first
         : 1780             account_process_tick(p, user_tick);
    0.00 :   ffff80001010efbc:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001010efc0:       bl      ffff800010089418 <raise_softirq>
         : 1783             update_process_times():
         : 1796             */
         : 1797             struct process_timer {
    0.00 :   ffff80001010efc4:       mov     w0, w20
    0.00 :   ffff80001010efc8:       bl      ffff800010102e18 <rcu_sched_clock_irq>
         : 1800             get_current():
    0.00 :   ffff80001010efcc:       mrs     x0, sp_el0
         : 20               preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff80001010efd0:       ldr     w0, [x0, #8]
         : 19               update_process_times():
         : 1798             struct timer_list timer;
         : 1799             struct task_struct *task;
    0.00 :   ffff80001010efd4:       tst     w0, #0xf0000
    0.00 :   ffff80001010efd8:       b.ne    ffff80001010eff8 <update_process_times+0xc8>  // b.any
         : 1801             };
         :
         : 1803             static void process_timeout(struct timer_list *t)
    0.00 :   ffff80001010efdc:       bl      ffff8000100b6f78 <scheduler_tick>
         : 1803             {
         : 1804             struct process_timer *timeout = from_timer(timeout, t, timer);
    0.00 :   ffff80001010efe0:       bl      ffff80001011ae20 <run_posix_cpu_timers>
         :
    0.00 :   ffff80001010efe4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001010efe8:       ldr     x21, [sp, #32]
    0.00 :   ffff80001010efec:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001010eff0:       autiasp
    0.00 :   ffff80001010eff4:       ret
         : 1799             };
    0.00 :   ffff80001010eff8:       bl      ffff80001015dc28 <irq_work_tick>
         : 1801             static void process_timeout(struct timer_list *t)
    0.00 :   ffff80001010effc:       bl      ffff8000100b6f78 <scheduler_tick>
         : 1803             struct process_timer *timeout = from_timer(timeout, t, timer);
    0.00 :   ffff80001010f000:       bl      ffff80001011ae20 <run_posix_cpu_timers>
         :
    0.00 :   ffff80001010f004:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001010f008:       ldr     x21, [sp, #32]
    0.00 :   ffff80001010f00c:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001010f010:       autiasp
    0.00 :   ffff80001010f014:       ret
 Percent |	Source code & Disassembly of perf for cycles (3 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      000000000021b850 <perf_mmap__read_init>:
         : 6      perf_mmap__read_init():
         :
         : 176    return 0;
         : 177    }
         :
         : 179    int perf_mmap__read_init(struct perf_mmap *map)
         : 180    {
    0.00 :   21b850: stp     x29, x30, [sp, #-96]!
    0.00 :   21b854: adrp    x1, 34d000 <options+0x650>
    0.00 :   21b858: mov     x29, sp
    0.00 :   21b85c: ldr     x1, [x1, #2784]
    0.00 :   21b860: stp     x19, x20, [sp, #16]
    0.00 :   21b864: mov     x20, x0
    0.00 :   21b868: ldr     x0, [x1]
    0.00 :   21b86c: str     x0, [sp, #88]
    0.00 :   21b870: mov     x0, #0x0                        // #0
         : 190    __read_once_size():
         : 132    static __always_inline void __read_once_size(const volatile void *p, void *res, int size)
         : 133    {
         : 134    switch (size) {
         : 135    case 1: *(__u8_alias_t  *) res = *(volatile __u8_alias_t  *) p; break;
         : 136    case 2: *(__u16_alias_t *) res = *(volatile __u16_alias_t *) p; break;
         : 137    case 4: *(__u32_alias_t *) res = *(volatile __u32_alias_t *) p; break;
    0.00 :   21b874: ldr     w0, [x20, #20]
         : 139    perf_mmap__read_init():
         : 179    /*
         : 180    * Check if event was unmapped due to a POLLHUP/POLLERR.
         : 181    */
         : 182    if (!refcount_read(&map->refcnt))
    0.00 :   21b878: cbz     w0, 21b9f4 <perf_mmap__read_init+0x1a4>
         : 184    ring_buffer_read_head():
         : 59     * Architectures where smp_load_acquire() does not fallback to
         : 60     * READ_ONCE() + smp_mb() pair.
         : 61     */
         : 62     #if defined(__x86_64__) || defined(__aarch64__) || defined(__powerpc64__) || \
         : 63     defined(__ia64__) || defined(__sparc__) && defined(__arch64__)
         : 64     return smp_load_acquire(&base->data_head);
    0.00 :   21b87c: ldr     x0, [x20]
    0.00 :   21b880: stp     x21, x22, [sp, #32]
    0.00 :   21b884: add     x0, x0, #0x400
    0.00 :   21b888: stp     x23, x24, [sp, #48]
    0.00 :   21b88c: ldar    x21, [x0]
         : 70     __perf_mmap__read_init():
         : 144    unsigned char *data = md->base + page_size;
    0.00 :   21b890: adrp    x0, 34d000 <options+0x650>
         : 147    md->start = md->overwrite ? head : old;
    0.00 :   21b894: ldrb    w3, [x20, #48]
         : 143    u64 old = md->prev;
   32.93 :   21b898: ldr     x19, [x20, #24]
         : 147    md->start = md->overwrite ? head : old;
    0.00 :   21b89c: cmp     w3, #0x0
         : 144    unsigned char *data = md->base + page_size;
    0.00 :   21b8a0: ldr     x0, [x0, #3400]
         : 147    md->start = md->overwrite ? head : old;
    0.00 :   21b8a4: csel    x1, x21, x19, eq  // eq = none
         : 150    if ((md->end - md->start) < md->flush)
    0.00 :   21b8a8: ldr     x4, [x20, #56]
         : 147    md->start = md->overwrite ? head : old;
    0.00 :   21b8ac: csel    x19, x19, x21, eq  // eq = none
         : 150    if ((md->end - md->start) < md->flush)
    0.00 :   21b8b0: sub     x2, x1, x19
         : 148    md->end = md->overwrite ? old : head;
   33.73 :   21b8b4: stp     x19, x1, [x20, #32]
         : 144    unsigned char *data = md->base + page_size;
    0.00 :   21b8b8: ldr     w23, [x0]
    0.00 :   21b8bc: ldr     x5, [x20]
         : 150    if ((md->end - md->start) < md->flush)
    0.00 :   21b8c0: cmp     x2, x4
    0.00 :   21b8c4: b.cc    21b9fc <perf_mmap__read_init+0x1ac>  // b.lo, b.ul, b.last
         : 154    if (size > (unsigned long)(md->mask) + 1) {
    0.00 :   21b8c8: ldr     w22, [x20, #8]
         : 171    return 0;
    0.00 :   21b8cc: mov     w0, #0x0                        // #0
         : 154    if (size > (unsigned long)(md->mask) + 1) {
    0.00 :   21b8d0: sxtw    x24, w22
    0.00 :   21b8d4: add     x1, x24, #0x1
    0.00 :   21b8d8: cmp     x2, x1
    0.00 :   21b8dc: b.ls    21b98c <perf_mmap__read_init+0x13c>  // b.plast
         : 155    if (!md->overwrite) {
    0.00 :   21b8e0: cbz     w3, 21ba0c <perf_mmap__read_init+0x1bc>
         : 144    unsigned char *data = md->base + page_size;
    0.00 :   21b8e4: add     x23, x5, w23, uxtw
         : 146    overwrite_rb_find_range():
         : 111    pr_debug2("%s: buf=%p, start=%"PRIx64"\n", __func__, buf, *start);
    0.00 :   21b8e8: adrp    x2, 2d8000 <hugetlbfs__known_mountpoints+0x8a0>
    0.00 :   21b8ec: add     x2, x2, #0x230
    0.00 :   21b8f0: mov     w0, #0x4                        // #4
    0.00 :   21b8f4: mov     x3, x23
    0.00 :   21b8f8: add     x2, x2, #0x50
    0.00 :   21b8fc: mov     x4, x19
    0.00 :   21b900: adrp    x1, 2d8000 <hugetlbfs__known_mountpoints+0x8a0>
    0.00 :   21b904: add     x1, x1, #0x3e8
    0.00 :   21b908: str     x25, [sp, #64]
    0.00 :   21b90c: bl      216fd0 <libperf_print>
         : 114    if (evt_head - *start >= (unsigned int)size) {
    0.00 :   21b910: add     w22, w22, #0x1
         : 112    pheader = (struct perf_event_header *)(buf + (*start & mask));
    0.00 :   21b914: ldr     x21, [x20, #32]
         : 131    pr_debug3("move evt_head: %"PRIx64"\n", evt_head);
    0.00 :   21b918: adrp    x25, 2d8000 <hugetlbfs__known_mountpoints+0x8a0>
    0.00 :   21b91c: add     x25, x25, #0x488
         : 114    if (evt_head - *start >= (unsigned int)size) {
    0.00 :   21b920: sub     x0, x19, x21
    0.00 :   21b924: cmp     x0, x22
    0.00 :   21b928: b.cc    21b954 <perf_mmap__read_init+0x104>  // b.lo, b.ul, b.last
    0.00 :   21b92c: b       21b9bc <perf_mmap__read_init+0x16c>
         : 130    evt_head += pheader->size;
    0.00 :   21b930: add     x19, x19, w0, uxth
         : 131    pr_debug3("move evt_head: %"PRIx64"\n", evt_head);
    0.00 :   21b934: mov     x1, x25
    0.00 :   21b938: mov     w0, #0x5                        // #5
    0.00 :   21b93c: mov     x2, x19
    0.00 :   21b940: bl      216fd0 <libperf_print>
         : 114    if (evt_head - *start >= (unsigned int)size) {
    0.00 :   21b944: ldr     x0, [x20, #32]
    0.00 :   21b948: sub     x0, x19, x0
    0.00 :   21b94c: cmp     x0, x22
    0.00 :   21b950: b.cs    21b9c8 <perf_mmap__read_init+0x178>  // b.hs, b.nlast
         : 122    pheader = (struct perf_event_header *)(buf + (evt_head & mask));
    0.00 :   21b954: and     x21, x24, x19
    0.00 :   21b958: add     x21, x23, x21
         : 124    if (pheader->size == 0) {
    0.00 :   21b95c: ldrh    w0, [x21, #6]
    0.00 :   21b960: cbnz    w0, 21b930 <perf_mmap__read_init+0xe0>
         : 125    pr_debug("Finished reading overwrite ring buffer: get start\n");
    0.00 :   21b964: adrp    x1, 2d8000 <hugetlbfs__known_mountpoints+0x8a0>
    0.00 :   21b968: mov     w0, #0x3                        // #3
    0.00 :   21b96c: add     x1, x1, #0x448
    0.00 :   21b970: bl      216fd0 <libperf_print>
         : 130    __perf_mmap__read_init():
         : 171    return 0;
    0.00 :   21b974: mov     w0, #0x0                        // #0
         : 173    overwrite_rb_find_range():
         : 127    return 0;
    0.00 :   21b978: ldp     x21, x22, [sp, #32]
    0.00 :   21b97c: ldp     x23, x24, [sp, #48]
    0.00 :   21b980: ldr     x25, [sp, #64]
         : 126    *end = evt_head;
    0.00 :   21b984: str     x19, [x20, #40]
         : 127    return 0;
    0.00 :   21b988: b       21b994 <perf_mmap__read_init+0x144>
    0.00 :   21b98c: ldp     x21, x22, [sp, #32]
    0.00 :   21b990: ldp     x23, x24, [sp, #48]
         : 131    perf_mmap__read_init():
         : 183    return -ENOENT;
         :
         : 185    return __perf_mmap__read_init(map);
         : 186    }
   33.33 :   21b994: adrp    x1, 34d000 <options+0x650>
    0.00 :   21b998: ldr     x1, [x1, #2784]
    0.00 :   21b99c: ldr     x2, [sp, #88]
    0.00 :   21b9a0: ldr     x3, [x1]
    0.00 :   21b9a4: subs    x2, x2, x3
    0.00 :   21b9a8: mov     x3, #0x0                        // #0
    0.00 :   21b9ac: b.ne    21ba60 <perf_mmap__read_init+0x210>  // b.any
    0.00 :   21b9b0: ldp     x19, x20, [sp, #16]
    0.00 :   21b9b4: ldp     x29, x30, [sp], #96
    0.00 :   21b9b8: ret
         : 197    overwrite_rb_find_range():
         : 112    pheader = (struct perf_event_header *)(buf + (*start & mask));
    0.00 :   21b9bc: and     x21, x24, x21
    0.00 :   21b9c0: add     x21, x23, x21
    0.00 :   21b9c4: nop
         : 115    pr_debug("Finished reading overwrite ring buffer: rewind\n");
    0.00 :   21b9c8: mov     w0, #0x3                        // #3
    0.00 :   21b9cc: adrp    x1, 2d8000 <hugetlbfs__known_mountpoints+0x8a0>
    0.00 :   21b9d0: add     x1, x1, #0x408
    0.00 :   21b9d4: bl      216fd0 <libperf_print>
         : 116    if (evt_head - *start > (unsigned int)size)
    0.00 :   21b9d8: ldr     x0, [x20, #32]
    0.00 :   21b9dc: sub     x0, x19, x0
    0.00 :   21b9e0: cmp     x0, x22
    0.00 :   21b9e4: b.ls    21b974 <perf_mmap__read_init+0x124>  // b.plast
         : 117    evt_head -= pheader->size;
    0.00 :   21b9e8: ldrh    w0, [x21, #6]
    0.00 :   21b9ec: sub     x19, x19, x0
         : 118    *end = evt_head;
    0.00 :   21b9f0: b       21b974 <perf_mmap__read_init+0x124>
         : 120    perf_mmap__read_init():
         : 180    return -ENOENT;
    0.00 :   21b9f4: mov     w0, #0xfffffffe                 // #-2
    0.00 :   21b9f8: b       21b994 <perf_mmap__read_init+0x144>
         : 183    __perf_mmap__read_init():
         : 151    return -EAGAIN;
    0.00 :   21b9fc: mov     w0, #0xfffffff5                 // #-11
    0.00 :   21ba00: ldp     x21, x22, [sp, #32]
    0.00 :   21ba04: ldp     x23, x24, [sp, #48]
    0.00 :   21ba08: b       21b994 <perf_mmap__read_init+0x144>
         : 156    WARN_ONCE(1, "failed to keep up with mmap data. (warn only once)\n");
    0.00 :   21ba0c: adrp    x19, 3e3000 <buf.1+0x380>
    0.00 :   21ba10: ldr     w0, [x19, #3832]
    0.00 :   21ba14: cbz     w0, 21ba34 <perf_mmap__read_init+0x1e4>
         : 158    md->prev = head;
    0.00 :   21ba18: str     x21, [x20, #24]
         : 159    perf_mmap__consume(md);
    0.00 :   21ba1c: mov     x0, x20
    0.00 :   21ba20: bl      21b7a4 <perf_mmap__consume>
         : 160    return -EAGAIN;
    0.00 :   21ba24: mov     w0, #0xfffffff5                 // #-11
    0.00 :   21ba28: ldp     x21, x22, [sp, #32]
    0.00 :   21ba2c: ldp     x23, x24, [sp, #48]
    0.00 :   21ba30: b       21b994 <perf_mmap__read_init+0x144>
         : 156    WARN_ONCE(1, "failed to keep up with mmap data. (warn only once)\n");
    0.00 :   21ba34: adrp    x3, 34d000 <options+0x650>
         : 158    fprintf():
         :
         : 101    # ifdef __va_arg_pack
         : 102    __fortify_function int
         : 103    fprintf (FILE *__restrict __stream, const char *__restrict __fmt, ...)
         : 104    {
         : 105    return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
    0.00 :   21ba38: adrp    x0, 2d8000 <hugetlbfs__known_mountpoints+0x8a0>
    0.00 :   21ba3c: mov     x2, #0x33                       // #51
    0.00 :   21ba40: add     x0, x0, #0x3b0
         : 109    __perf_mmap__read_init():
    0.00 :   21ba44: ldr     x3, [x3, #3176]
         : 157    fprintf():
    0.00 :   21ba48: mov     x1, #0x1                        // #1
    0.00 :   21ba4c: ldr     x3, [x3]
    0.00 :   21ba50: bl      70ec0 <fwrite@plt>
         : 103    __perf_mmap__read_init():
    0.00 :   21ba54: mov     w0, #0x1                        // #1
    0.00 :   21ba58: str     w0, [x19, #3832]
    0.00 :   21ba5c: b       21ba18 <perf_mmap__read_init+0x1c8>
    0.00 :   21ba60: stp     x21, x22, [sp, #32]
    0.00 :   21ba64: stp     x23, x24, [sp, #48]
    0.00 :   21ba68: str     x25, [sp, #64]
         : 162    perf_mmap__read_init():
         : 183    }
    0.00 :   21ba6c: bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101204e0 <tick_do_update_jiffies64>:
         : 6                tick_do_update_jiffies64():
         :
         : 59               /*
         : 60               * Must be called with interrupts disabled !
         : 61               */
         : 62               static void tick_do_update_jiffies64(ktime_t now)
         : 63               {
    0.00 :   ffff8000101204e0:       paciasp
    0.00 :   ffff8000101204e4:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff8000101204e8:       mov     x29, sp
    0.00 :   ffff8000101204ec:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101204f0:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101204f4:       add     x20, x20, #0x948
    0.00 :   ffff8000101204f8:       mov     x19, x0
    0.00 :   ffff8000101204fc:       ldr     x0, [x20]
    0.00 :   ffff800010120500:       str     x0, [sp, #56]
    0.00 :   ffff800010120504:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010120508:       stp     x21, x22, [sp, #32]
         : 72               * 32bit cannot do that because the store of tick_next_period
         : 73               * consists of two 32bit stores and the first store could move it
         : 74               * to a random point in the future.
         : 75               */
         : 76               if (IS_ENABLED(CONFIG_64BIT)) {
         : 77               if (ktime_before(now, smp_load_acquire(&tick_next_period)))
    0.00 :   ffff80001012050c:       adrp    x21, ffff800011f4e000 <posix_timers_hashtable+0xc18>
    0.00 :   ffff800010120510:       add     x0, x21, #0x410
    0.00 :   ffff800010120514:       ldar    x0, [x0]
         : 81               ktime_compare():
         : 97               *   cmp1 == cmp2: return 0
         : 98               *   cmp1  > cmp2: return >0
         : 99               */
         : 100              static inline int ktime_compare(const ktime_t cmp1, const ktime_t cmp2)
         : 101              {
         : 102              if (cmp1 < cmp2)
    0.00 :   ffff800010120518:       cmp     x19, x0
    0.00 :   ffff80001012051c:       b.lt    ffff8000101205c0 <tick_do_update_jiffies64+0xe0>  // b.tstop
         : 105              tick_do_update_jiffies64():
         : 91               if (ktime_before(now, nextp))
         : 92               return;
         : 93               }
         :
         : 95               /* Quick check failed, i.e. update is required. */
         : 96               raw_spin_lock(&jiffies_lock);
    0.00 :   ffff800010120520:       adrp    x22, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010120524:       add     x22, x22, #0xa00
    0.00 :   ffff800010120528:       mov     x0, x22
    0.00 :   ffff80001012052c:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 101              ktime_compare():
    0.00 :   ffff800010120530:       ldr     x0, [x21, #1040]
    0.00 :   ffff800010120534:       cmp     x19, x0
    0.00 :   ffff800010120538:       b.lt    ffff8000101205e4 <tick_do_update_jiffies64+0x104>  // b.tstop
         : 100              do_raw_write_seqcount_begin():
         : 473              } while (0)
         :
         : 475              static inline void do_raw_write_seqcount_begin(seqcount_t *s)
         : 476              {
         : 477              kcsan_nestable_atomic_begin();
         : 478              s->sequence++;
    0.00 :   ffff80001012053c:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010120540:       ldr     w0, [x1, #2496]
    0.00 :   ffff800010120544:       add     w0, w0, #0x1
    0.00 :   ffff800010120548:       str     w0, [x1, #2496]
         : 474              smp_wmb();
    0.00 :   ffff80001012054c:       dmb     ishst
         : 476              tick_do_update_jiffies64():
         : 103              return;
         : 104              }
         :
         : 106              write_seqcount_begin(&jiffies_seq);
         :
         : 108              delta = ktime_sub(now, tick_next_period);
   33.14 :   ffff800010120550:       ldr     x2, [x21, #1040]
         : 104              if (unlikely(delta >= TICK_NSEC)) {
    0.00 :   ffff800010120554:       mov     x0, #0x8ff                      // #2303
    0.00 :   ffff800010120558:       movk    x0, #0x3d, lsl #16
         : 103              delta = ktime_sub(now, tick_next_period);
    0.00 :   ffff80001012055c:       sub     x19, x19, x2
         : 104              if (unlikely(delta >= TICK_NSEC)) {
    0.00 :   ffff800010120560:       cmp     x19, x0
    0.00 :   ffff800010120564:       b.gt    ffff8000101205f0 <tick_do_update_jiffies64+0x110>
         : 113              ticks += ktime_divns(delta, incr);
         :
         : 115              last_jiffies_update = ktime_add_ns(last_jiffies_update,
         : 116              incr * ticks);
         : 117              } else {
         : 118              last_jiffies_update = ktime_add_ns(last_jiffies_update,
    0.00 :   ffff800010120568:       adrp    x2, ffff800011f4e000 <posix_timers_hashtable+0xc18>
         : 59               unsigned long ticks = 1;
    0.00 :   ffff80001012056c:       mov     x19, #0x1                       // #1
         : 113              last_jiffies_update = ktime_add_ns(last_jiffies_update,
    0.00 :   ffff800010120570:       ldr     x0, [x2, #1400]
    0.00 :   ffff800010120574:       add     x0, x0, #0x3d0, lsl #12
    0.00 :   ffff800010120578:       add     x0, x0, #0x900
         : 118              TICK_NSEC);
         : 119              }
         :
         : 121              /* Advance jiffies to complete the jiffies_seq protected job */
         : 122              jiffies_64 += ticks;
    0.00 :   ffff80001012057c:       adrp    x3, ffff800011c27000 <bit_wait_table+0xe80>
   33.50 :   ffff800010120580:       str     x0, [x2, #1400]
         :
         : 124              /*
         : 125              * Keep the tick_next_period variable up to date.
         : 126              */
         : 127              nextp = ktime_add_ns(last_jiffies_update, TICK_NSEC);
    0.00 :   ffff800010120584:       add     x0, x0, #0x3d0, lsl #12
         : 118              jiffies_64 += ticks;
    0.00 :   ffff800010120588:       ldr     x2, [x3, #2432]
         : 123              nextp = ktime_add_ns(last_jiffies_update, TICK_NSEC);
    0.00 :   ffff80001012058c:       add     x0, x0, #0x900
         : 118              jiffies_64 += ticks;
    0.00 :   ffff800010120590:       add     x19, x2, x19
         : 132              * Pairs with smp_load_acquire() in the lockless quick
         : 133              * check above and ensures that the update to jiffies_64 is
         : 134              * not reordered vs. the store to tick_next_period, neither
         : 135              * by the compiler nor by the CPU.
         : 136              */
         : 137              smp_store_release(&tick_next_period, nextp);
    0.00 :   ffff800010120594:       add     x2, x21, #0x410
         : 118              jiffies_64 += ticks;
    0.00 :   ffff800010120598:       str     x19, [x3, #2432]
         : 132              smp_store_release(&tick_next_period, nextp);
    0.00 :   ffff80001012059c:       stlr    x0, [x2]
         : 134              do_raw_write_seqcount_end():
         : 493              preempt_enable();                                       \
         : 494              } while (0)
         :
         : 496              static inline void do_raw_write_seqcount_end(seqcount_t *s)
         : 497              {
         : 498              smp_wmb();
   33.36 :   ffff8000101205a0:       dmb     ishst
         : 494              s->sequence++;
    0.00 :   ffff8000101205a4:       ldr     w0, [x1, #2496]
    0.00 :   ffff8000101205a8:       add     w0, w0, #0x1
    0.00 :   ffff8000101205ac:       str     w0, [x1, #2496]
         : 498              tick_do_update_jiffies64():
         : 148              * protected by it, but jiffies_lock needs to be held to prevent
         : 149              * concurrent invocations.
         : 150              */
         : 151              write_seqcount_end(&jiffies_seq);
         :
         : 153              calc_global_load();
    0.00 :   ffff8000101205b0:       bl      ffff8000100ba028 <calc_global_load>
         :
         : 151              raw_spin_unlock(&jiffies_lock);
    0.00 :   ffff8000101205b4:       mov     x0, x22
    0.00 :   ffff8000101205b8:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 151              update_wall_time();
    0.00 :   ffff8000101205bc:       bl      ffff8000101131c8 <update_wall_time>
         : 152              }
    0.00 :   ffff8000101205c0:       ldr     x1, [sp, #56]
    0.00 :   ffff8000101205c4:       ldr     x0, [x20]
    0.00 :   ffff8000101205c8:       eor     x0, x1, x0
    0.00 :   ffff8000101205cc:       cbnz    x0, ffff800010120624 <tick_do_update_jiffies64+0x144>
    0.00 :   ffff8000101205d0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101205d4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101205d8:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000101205dc:       autiasp
    0.00 :   ffff8000101205e0:       ret
         : 97               raw_spin_unlock(&jiffies_lock);
    0.00 :   ffff8000101205e4:       mov     x0, x22
    0.00 :   ffff8000101205e8:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 98               return;
    0.00 :   ffff8000101205ec:       b       ffff8000101205c0 <tick_do_update_jiffies64+0xe0>
         : 100              ktime_divns():
         : 155              /*
         : 156              * 32-bit implementation cannot handle negative divisors,
         : 157              * so catch them on 64bit as well.
         : 158              */
         : 159              WARN_ON(div < 0);
         : 160              return kt / div;
    0.00 :   ffff8000101205f0:       mov     x3, #0x34db                     // #13531
         : 162              tick_do_update_jiffies64():
         : 110              last_jiffies_update = ktime_add_ns(last_jiffies_update,
    0.00 :   ffff8000101205f4:       adrp    x2, ffff800011f4e000 <posix_timers_hashtable+0xc18>
         : 112              ktime_divns():
    0.00 :   ffff8000101205f8:       movk    x3, #0xd7b6, lsl #16
         : 156              tick_do_update_jiffies64():
    0.00 :   ffff8000101205fc:       add     x0, x0, #0x1
         : 111              ktime_divns():
    0.00 :   ffff800010120600:       movk    x3, #0xde82, lsl #32
    0.00 :   ffff800010120604:       movk    x3, #0x431b, lsl #48
         : 157              tick_do_update_jiffies64():
    0.00 :   ffff800010120608:       ldr     x4, [x2, #1400]
         : 111              ktime_divns():
    0.00 :   ffff80001012060c:       smulh   x3, x19, x3
    0.00 :   ffff800010120610:       asr     x3, x3, #20
    0.00 :   ffff800010120614:       sub     x19, x3, x19, asr #63
         : 158              tick_do_update_jiffies64():
         : 108              ticks += ktime_divns(delta, incr);
    0.00 :   ffff800010120618:       add     x19, x19, #0x1
         : 110              last_jiffies_update = ktime_add_ns(last_jiffies_update,
    0.00 :   ffff80001012061c:       madd    x0, x19, x0, x4
    0.00 :   ffff800010120620:       b       ffff80001012057c <tick_do_update_jiffies64+0x9c>
         : 152              }
    0.00 :   ffff800010120624:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010f478 <hrtimer_active>:
         : 6                hrtimer_active():
         : 1457             * to another cpu.
         : 1458             *
         : 1459             * It is important for this function to not return a false negative.
         : 1460             */
         : 1461             bool hrtimer_active(const struct hrtimer *timer)
         : 1462             {
    0.00 :   ffff80001010f478:       paciasp
    0.00 :   ffff80001010f47c:       nop
         : 1462             struct hrtimer_clock_base *base;
         : 1463             unsigned int seq;
         :
         : 1465             do {
         : 1466             base = READ_ONCE(timer->base);
    0.00 :   ffff80001010f480:       ldr     x2, [x0, #48]
         : 1468             __seqprop_raw_spinlock_sequence():
         : 276              lockdep_assert_preemption_disabled();
         : 277              }
         :
         : 279              #define __SEQ_RT        IS_ENABLED(CONFIG_PREEMPT_RT)
         :
         : 281              SEQCOUNT_LOCKNAME(raw_spinlock, raw_spinlock_t,  false,    s->lock,        raw_spin, raw_spin_lock(s->lock))
    0.00 :   ffff80001010f484:       ldr     w1, [x2, #16]
         : 283              hrtimer_active():
         : 1463             seq = raw_read_seqcount_begin(&base->seq);
    0.00 :   ffff80001010f488:       tbz     w1, #0, ffff80001010f49c <hrtimer_active+0x24>
    0.00 :   ffff80001010f48c:       nop
         : 1466             cpu_relax():
         :
         : 13               #ifndef __ASSEMBLY__
         :
         : 15               static inline void cpu_relax(void)
         : 16               {
         : 17               asm volatile("yield" ::: "memory");
    0.00 :   ffff80001010f490:       yield
         : 19               __seqprop_raw_spinlock_sequence():
    0.00 :   ffff80001010f494:       ldr     w1, [x2, #16]
         : 277              hrtimer_active():
    0.00 :   ffff80001010f498:       tbnz    w1, #0, ffff80001010f490 <hrtimer_active+0x18>
  100.00 :   ffff80001010f49c:       dmb     ishld
         :
         : 1466             if (timer->state != HRTIMER_STATE_INACTIVE ||
    0.00 :   ffff80001010f4a0:       ldrb    w3, [x0, #56]
    0.00 :   ffff80001010f4a4:       cbnz    w3, ffff80001010f4dc <hrtimer_active+0x64>
    0.00 :   ffff80001010f4a8:       ldr     x3, [x2, #24]
    0.00 :   ffff80001010f4ac:       cmp     x3, x0
    0.00 :   ffff80001010f4b0:       b.eq    ffff80001010f4dc <hrtimer_active+0x64>  // b.none
         : 1468             do_read_seqcount_retry():
         : 452              #define read_seqcount_retry(s, start)                                   \
         : 453              do_read_seqcount_retry(seqprop_ptr(s), start)
         :
         : 455              static inline int do_read_seqcount_retry(const seqcount_t *s, unsigned start)
         : 456              {
         : 457              smp_rmb();
    0.00 :   ffff80001010f4b4:       dmb     ishld
         : 459              do___read_seqcount_retry():
         : 433              return unlikely(READ_ONCE(s->sequence) != start);
    0.00 :   ffff80001010f4b8:       ldr     w3, [x2, #16]
         : 435              hrtimer_active():
         : 1470             base->running == timer)
         : 1471             return true;
         :
         : 1473             } while (read_seqcount_retry(&base->seq, seq) ||
         : 1474             base != READ_ONCE(timer->base));
    0.00 :   ffff80001010f4bc:       cmp     w3, w1
    0.00 :   ffff80001010f4c0:       b.ne    ffff80001010f480 <hrtimer_active+0x8>  // b.any
    0.00 :   ffff80001010f4c4:       ldr     x1, [x0, #48]
         : 1469             } while (read_seqcount_retry(&base->seq, seq) ||
    0.00 :   ffff80001010f4c8:       cmp     x2, x1
    0.00 :   ffff80001010f4cc:       b.ne    ffff80001010f480 <hrtimer_active+0x8>  // b.any
         :
         : 1473             return false;
    0.00 :   ffff80001010f4d0:       mov     w0, #0x0                        // #0
         : 1473             }
    0.00 :   ffff80001010f4d4:       autiasp
    0.00 :   ffff80001010f4d8:       ret
         : 1467             return true;
    0.00 :   ffff80001010f4dc:       mov     w0, #0x1                        // #1
         : 1473             }
    0.00 :   ffff80001010f4e0:       autiasp
    0.00 :   ffff80001010f4e4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010148600 <map_id_up>:
         : 6                map_id_up():
         : 355              key.map_up = true;
         : 356              key.count = 1;
         : 357              key.id = id;
         :
         : 359              return bsearch(&key, map->reverse, extents,
         : 360              sizeof(struct uid_gid_extent), cmp_map_id);
    0.00 :   ffff800010148600:       paciasp
    0.00 :   ffff800010148604:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010148608:       mov     x29, sp
    0.00 :   ffff80001014860c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010148610:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010148614:       add     x20, x20, #0x948
    0.00 :   ffff800010148618:       mov     w19, w1
         : 357              }
         :
   32.23 :   ffff80001014861c:       ldr     w2, [x0]
         : 355              sizeof(struct uid_gid_extent), cmp_map_id);
    0.00 :   ffff800010148620:       ldr     x1, [x20]
    0.00 :   ffff800010148624:       str     x1, [sp, #56]
    0.00 :   ffff800010148628:       mov     x1, #0x0                        // #0
         : 358              static u32 map_id_up(struct uid_gid_map *map, u32 id)
   33.68 :   ffff80001014862c:       dmb     ishld
         : 360              {
         : 361              struct uid_gid_extent *extent;
    0.00 :   ffff800010148630:       cmp     w2, #0x5
    0.00 :   ffff800010148634:       b.hi    ffff8000101486b0 <map_id_up+0xb0>  // b.pmore
         : 364              map_id_up_base():
         : 328              unsigned idx;
    0.00 :   ffff800010148638:       cbz     w2, ffff80001014868c <map_id_up+0x8c>
         :
    0.00 :   ffff80001014863c:       ldp     w3, w1, [x0, #12]
    0.00 :   ffff800010148640:       add     x4, x0, #0x18
    0.00 :   ffff800010148644:       add     w1, w3, w1
    0.00 :   ffff800010148648:       sub     w1, w1, #0x1
         : 331              /* Find the matching extent */
    0.00 :   ffff80001014864c:       cmp     w19, w1
    0.00 :   ffff800010148650:       ccmp    w19, w3, #0x0, ls  // ls = plast
         : 328              unsigned idx;
    0.00 :   ffff800010148654:       mov     w3, #0x0                        // #0
         : 331              /* Find the matching extent */
    0.00 :   ffff800010148658:       b.cc    ffff800010148680 <map_id_up+0x80>  // b.lo, b.ul, b.last
    0.00 :   ffff80001014865c:       b       ffff800010148704 <map_id_up+0x104>
         : 329              u32 first, last;
    0.00 :   ffff800010148660:       mov     x1, x4
    0.00 :   ffff800010148664:       ldr     w5, [x4], #12
         :
    0.00 :   ffff800010148668:       ldr     w1, [x1, #4]
    0.00 :   ffff80001014866c:       add     w1, w5, w1
    0.00 :   ffff800010148670:       sub     w1, w1, #0x1
         : 331              /* Find the matching extent */
    0.00 :   ffff800010148674:       cmp     w19, w1
    0.00 :   ffff800010148678:       ccmp    w19, w5, #0x0, ls  // ls = plast
    0.00 :   ffff80001014867c:       b.cs    ffff8000101486f0 <map_id_up+0xf0>  // b.hs, b.nlast
         : 328              unsigned idx;
    0.00 :   ffff800010148680:       add     w3, w3, #0x1
    0.00 :   ffff800010148684:       cmp     w2, w3
    0.00 :   ffff800010148688:       b.ne    ffff800010148660 <map_id_up+0x60>  // b.any
         : 332              map_id_up():
         : 369              if (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)
         : 370              extent = map_id_up_base(extents, map, id);
         : 371              else
         : 372              extent = map_id_up_max(extents, map, id);
         :
         : 374              /* Map the id or note failure */
    0.00 :   ffff80001014868c:       mov     w0, #0xffffffff                 // #-1
         : 372              if (extent)
         : 373              id = (id - extent->lower_first) + extent->first;
         : 374              else
    0.00 :   ffff800010148690:       ldr     x2, [sp, #56]
    0.00 :   ffff800010148694:       ldr     x1, [x20]
    0.00 :   ffff800010148698:       eor     x1, x2, x1
    0.00 :   ffff80001014869c:       cbnz    x1, ffff800010148710 <map_id_up+0x110>
    0.00 :   ffff8000101486a0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101486a4:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000101486a8:       autiasp
    0.00 :   ffff8000101486ac:       ret
         : 383              map_id_up_max():
         : 350              key.map_up = true;
    0.00 :   ffff8000101486b0:       ldr     x1, [x0, #16]
         : 346              map_id_up_max(unsigned extents, struct uid_gid_map *map, u32 id)
    0.00 :   ffff8000101486b4:       mov     w6, #0x1                        // #1
         : 347              {
    0.00 :   ffff8000101486b8:       mov     w5, #0x1                        // #1
         : 350              key.map_up = true;
    0.00 :   ffff8000101486bc:       adrp    x4, ffff800010148000 <utsns_put+0x80>
    0.00 :   ffff8000101486c0:       mov     w2, w2
    0.00 :   ffff8000101486c4:       mov     x3, #0xc                        // #12
    0.00 :   ffff8000101486c8:       add     x4, x4, #0x1e8
    0.00 :   ffff8000101486cc:       add     x0, sp, #0x2c
         : 346              map_id_up_max(unsigned extents, struct uid_gid_map *map, u32 id)
    0.00 :   ffff8000101486d0:       strb    w6, [sp, #44]
         : 347              {
    0.00 :   ffff8000101486d4:       stp     w19, w5, [sp, #48]
         : 350              key.map_up = true;
    0.00 :   ffff8000101486d8:       bl      ffff80001046ce20 <bsearch>
         : 352              map_id_up():
         : 366              else
    0.00 :   ffff8000101486dc:       cbz     x0, ffff80001014868c <map_id_up+0x8c>
         : 367              extent = map_id_up_max(extents, map, id);
   34.09 :   ffff8000101486e0:       ldp     w1, w0, [x0]
    0.00 :   ffff8000101486e4:       add     w19, w19, w1
    0.00 :   ffff8000101486e8:       sub     w0, w19, w0
         : 371              id = (id - extent->lower_first) + extent->first;
    0.00 :   ffff8000101486ec:       b       ffff800010148690 <map_id_up+0x90>
    0.00 :   ffff8000101486f0:       mov     w2, #0xc                        // #12
    0.00 :   ffff8000101486f4:       mov     x1, #0x8                        // #8
    0.00 :   ffff8000101486f8:       umaddl  x3, w3, w2, x1
         : 376              map_id_up_base():
         : 332              for (idx = 0; idx < extents; idx++) {
    0.00 :   ffff8000101486fc:       add     x0, x0, x3
    0.00 :   ffff800010148700:       b       ffff8000101486dc <map_id_up+0xdc>
         : 331              /* Find the matching extent */
    0.00 :   ffff800010148704:       mov     x3, #0x8                        // #8
         : 332              for (idx = 0; idx < extents; idx++) {
    0.00 :   ffff800010148708:       add     x0, x0, x3
    0.00 :   ffff80001014870c:       b       ffff8000101486dc <map_id_up+0xdc>
         : 335              map_id_up():
         : 372              else
    0.00 :   ffff800010148710:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001016cce8 <perf_pmu_disable>:
         : 6                perf_pmu_disable():
         : 1196             raw_spin_unlock_irqrestore(&cpuctx->hrtimer_lock, flags);
         :
         : 1198             return 0;
         : 1199             }
         :
         : 1201             void perf_pmu_disable(struct pmu *pmu)
    0.00 :   ffff80001016cce8:       paciasp
    0.00 :   ffff80001016ccec:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001016ccf0:       mov     x29, sp
         : 1205             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001016ccf4:       mrs     x4, tpidr_el1
         : 46               perf_pmu_disable():
         : 1197             {
    0.00 :   ffff80001016ccf8:       ldr     x1, [x0, #64]
         : 1198             int *count = this_cpu_ptr(pmu->pmu_disable_count);
   66.76 :   ffff80001016ccfc:       ldr     w3, [x1, x4]
    0.00 :   ffff80001016cd00:       add     w5, w3, #0x1
   33.24 :   ffff80001016cd04:       str     w5, [x1, x4]
    0.00 :   ffff80001016cd08:       cbnz    w3, ffff80001016cd14 <perf_pmu_disable+0x2c>
         : 1199             if (!(*count)++)
    0.00 :   ffff80001016cd0c:       ldr     x1, [x0, #104]
    0.00 :   ffff80001016cd10:       blr     x1
         : 1200             pmu->pmu_disable(pmu);
    0.00 :   ffff80001016cd14:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001016cd18:       autiasp
    0.00 :   ffff80001016cd1c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000103537e8 <add_transaction_credits>:
         : 6                add_transaction_credits():
         : 229              * transaction. Returns 1 if we had to wait, j_state_lock is dropped, and
         : 230              * caller must retry.
         : 231              */
         : 232              static int add_transaction_credits(journal_t *journal, int blocks,
         : 233              int rsv_blocks)
         : 234              {
    0.00 :   ffff8000103537e8:       paciasp
    0.00 :   ffff8000103537ec:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff8000103537f0:       mov     x29, sp
    0.00 :   ffff8000103537f4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000103537f8:       mov     x19, x0
    0.00 :   ffff8000103537fc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010353800:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010353804:       add     x21, x21, #0x948
         : 230              transaction_t *t = journal->j_running_transaction;
    0.00 :   ffff800010353808:       ldr     x20, [x19, #112]
         : 229              {
    0.00 :   ffff80001035380c:       ldr     x0, [x21]
    0.00 :   ffff800010353810:       str     x0, [sp, #104]
    0.00 :   ffff800010353814:       mov     x0, #0x0                        // #0
         :
         : 239              /*
         : 240              * If the current transaction is locked down for commit, wait
         : 241              * for the lock to be released.
         : 242              */
         : 243              if (t->t_state != T_RUNNING) {
    0.00 :   ffff800010353818:       ldr     w0, [x20, #12]
    0.00 :   ffff80001035381c:       cbz     w0, ffff800010353858 <add_transaction_credits+0x70>
         : 239              WARN_ON_ONCE(t->t_state >= T_FLUSH);
    0.00 :   ffff800010353820:       cmp     w0, #0x2
    0.00 :   ffff800010353824:       b.hi    ffff8000103539ec <add_transaction_credits+0x204>  // b.pmore
         : 240              wait_transaction_locked(journal);
    0.00 :   ffff800010353828:       mov     x0, x19
    0.00 :   ffff80001035382c:       bl      ffff8000103531f8 <wait_transaction_locked>
         : 241              return 1;
    0.00 :   ffff800010353830:       mov     w0, #0x1                        // #1
         : 316              atomic_read(&journal->j_reserved_credits) + rsv_blocks
         : 317              <= journal->j_max_transaction_buffers / 2);
         : 318              return 1;
         : 319              }
         : 320              return 0;
         : 321              }
    0.00 :   ffff800010353834:       ldr     x2, [sp, #104]
    0.00 :   ffff800010353838:       ldr     x1, [x21]
    0.00 :   ffff80001035383c:       eor     x1, x2, x1
    0.00 :   ffff800010353840:       cbnz    x1, ffff800010353af0 <add_transaction_credits+0x308>
    0.00 :   ffff800010353844:       ldp     x19, x20, [sp, #16]
   35.23 :   ffff800010353848:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001035384c:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010353850:       autiasp
    0.00 :   ffff800010353854:       ret
         : 232              int total = blocks + rsv_blocks;
    0.00 :   ffff800010353858:       add     w22, w1, w2
         : 249              needed = atomic_add_return(total, &t->t_outstanding_credits);
   30.98 :   ffff80001035385c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010353860:       mov     w23, w2
    0.00 :   ffff800010353864:       add     x24, x20, #0x9c
         : 253              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010353868:       b       ffff8000103538c0 <add_transaction_credits+0xd8>
    0.00 :   ffff80001035386c:       b       ffff8000103538c0 <add_transaction_credits+0xd8>
         : 46               __lse_atomic_add_return():
         : 76               }
         :
         : 78               ATOMIC_OP_ADD_RETURN(_relaxed,   )
         : 79               ATOMIC_OP_ADD_RETURN(_acquire,  a, "memory")
         : 80               ATOMIC_OP_ADD_RETURN(_release,  l, "memory")
         : 81               ATOMIC_OP_ADD_RETURN(        , al, "memory")
    0.00 :   ffff800010353870:       mov     w0, w22
    0.00 :   ffff800010353874:       ldaddal w0, w1, [x24]
   33.80 :   ffff800010353878:       add     w0, w0, w1
         : 85               add_transaction_credits():
         : 250              if (needed > journal->j_max_transaction_buffers) {
    0.00 :   ffff80001035387c:       ldr     w1, [x19, #1040]
    0.00 :   ffff800010353880:       cmp     w1, w0
    0.00 :   ffff800010353884:       b.lt    ffff8000103538d4 <add_transaction_credits+0xec>  // b.tstop
         : 287              if (jbd2_log_space_left(journal) < journal->j_max_transaction_buffers) {
    0.00 :   ffff800010353888:       ldr     x2, [x19, #120]
         : 289              jbd2_log_space_left():
         : 1717             return num_fc_blocks ? num_fc_blocks : JBD2_DEFAULT_FAST_COMMIT_BLOCKS;
         : 1718             }
         :
         : 1720             /*
         : 1721             * Return number of free blocks in the log. Must be called under j_state_lock.
         : 1722             */
    0.00 :   ffff80001035388c:       ldr     x0, [x19, #840]
    0.00 :   ffff800010353890:       sub     x0, x0, #0x20
         : 1719             static inline unsigned long jbd2_log_space_left(journal_t *journal)
         : 1720             {
    0.00 :   ffff800010353894:       cbz     x2, ffff8000103538a0 <add_transaction_credits+0xb8>
         : 1722             atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff800010353898:       ldr     w2, [x2, #156]
         : 35               jbd2_log_space_left():
         : 1720             /* Allow for rounding errors */
    0.00 :   ffff80001035389c:       sub     x0, x0, w2, sxtw
         : 1723             long free = journal->j_free - 32;
         :
         : 1725             if (journal->j_committing_transaction) {
    0.00 :   ffff8000103538a0:       cmp     x0, #0x0
    0.00 :   ffff8000103538a4:       csel    x0, x0, xzr, ge  // ge = tcont
         : 1728             add_transaction_credits():
    0.00 :   ffff8000103538a8:       cmp     x0, w1, sxtw
    0.00 :   ffff8000103538ac:       b.cc    ffff800010353a08 <add_transaction_credits+0x220>  // b.lo, b.ul, b.last
         : 300              if (!rsv_blocks)
    0.00 :   ffff8000103538b0:       cbnz    w23, ffff800010353928 <add_transaction_credits+0x140>
         : 301              return 0;
    0.00 :   ffff8000103538b4:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000103538b8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000103538bc:       b       ffff800010353834 <add_transaction_credits+0x4c>
         : 305              __ll_sc_atomic_add_return():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff8000103538c0:       add     x2, x20, #0x9c
    0.00 :   ffff8000103538c4:       b       ffff800010356558 <jbd2_journal_begin_ordered_truncate+0x178>
         : 119              add_transaction_credits():
         : 250              if (needed > journal->j_max_transaction_buffers) {
    0.00 :   ffff8000103538c8:       ldr     w1, [x19, #1040]
    0.00 :   ffff8000103538cc:       cmp     w1, w0
    0.00 :   ffff8000103538d0:       b.ge    ffff800010353888 <add_transaction_credits+0xa0>  // b.tcont
         : 254              arch_static_branch_jump():
    0.00 :   ffff8000103538d4:       b       ffff8000103539f4 <add_transaction_credits+0x20c>
    0.00 :   ffff8000103538d8:       b       ffff8000103539f4 <add_transaction_credits+0x20c>
         : 40               __lse_atomic_sub():
         :
         : 114              #undef ATOMIC_FETCH_OP_AND
         :
         : 116              static inline void __lse_atomic_sub(int i, atomic_t *v)
         : 117              {
         : 118              asm volatile(
    0.00 :   ffff8000103538dc:       mov     w0, w22
    0.00 :   ffff8000103538e0:       add     x1, x20, #0x9c
    0.00 :   ffff8000103538e4:       neg     w0, w0
    0.00 :   ffff8000103538e8:       stadd   w0, [x1]
         : 123              atomic_read():
    0.00 :   ffff8000103538ec:       ldr     w0, [x19, #980]
         : 29               add_transaction_credits():
         : 262              if (atomic_read(&journal->j_reserved_credits) + total >
    0.00 :   ffff8000103538f0:       ldr     w1, [x19, #1040]
    0.00 :   ffff8000103538f4:       add     w0, w22, w0
    0.00 :   ffff8000103538f8:       cmp     w0, w1
    0.00 :   ffff8000103538fc:       b.le    ffff800010353a00 <add_transaction_credits+0x218>
         : 264              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353900:       add     x0, x19, #0x44
    0.00 :   ffff800010353904:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 267              atomic_read():
    0.00 :   ffff800010353908:       ldr     w0, [x19, #980]
         : 29               add_transaction_credits():
         : 266              wait_event(journal->j_wait_reserved,
    0.00 :   ffff80001035390c:       ldr     w1, [x19, #1040]
    0.00 :   ffff800010353910:       add     w0, w22, w0
    0.00 :   ffff800010353914:       cmp     w0, w1
    0.00 :   ffff800010353918:       b.gt    ffff800010353a80 <add_transaction_credits+0x298>
         : 296              return 1;
    0.00 :   ffff80001035391c:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010353920:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010353924:       b       ffff800010353834 <add_transaction_credits+0x4c>
         : 303              needed = atomic_add_return(rsv_blocks, &journal->j_reserved_credits);
    0.00 :   ffff800010353928:       add     x1, x19, #0x3d4
         : 305              arch_static_branch_jump():
    0.00 :   ffff80001035392c:       b       ffff800010353a20 <add_transaction_credits+0x238>
    0.00 :   ffff800010353930:       b       ffff800010353a20 <add_transaction_credits+0x238>
         : 40               __lse_atomic_add_return():
         : 76               ATOMIC_OP_ADD_RETURN(        , al, "memory")
    0.00 :   ffff800010353934:       mov     w0, w23
    0.00 :   ffff800010353938:       ldaddal w0, w2, [x1]
    0.00 :   ffff80001035393c:       add     w0, w0, w2
         : 80               add_transaction_credits():
         : 305              if (needed > journal->j_max_transaction_buffers / 2) {
    0.00 :   ffff800010353940:       ldr     w1, [x19, #1040]
    0.00 :   ffff800010353944:       add     w1, w1, w1, lsr #31
    0.00 :   ffff800010353948:       cmp     w0, w1, asr #1
    0.00 :   ffff80001035394c:       b.le    ffff8000103538b4 <add_transaction_credits+0xcc>
         : 306              sub_reserved_credits(journal, rsv_blocks);
    0.00 :   ffff800010353950:       mov     w1, w23
    0.00 :   ffff800010353954:       mov     x0, x19
    0.00 :   ffff800010353958:       bl      ffff800010353370 <sub_reserved_credits>
         : 310              arch_static_branch_jump():
    0.00 :   ffff80001035395c:       b       ffff800010353ae4 <add_transaction_credits+0x2fc>
    0.00 :   ffff800010353960:       b       ffff800010353ae4 <add_transaction_credits+0x2fc>
         : 40               __lse_atomic_sub():
         : 113              asm volatile(
    0.00 :   ffff800010353964:       add     x0, x20, #0x9c
    0.00 :   ffff800010353968:       neg     w22, w22
    0.00 :   ffff80001035396c:       stadd   w22, [x0]
         : 117              add_transaction_credits():
         : 308              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353970:       add     x0, x19, #0x44
    0.00 :   ffff800010353974:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 310              wait_event(journal->j_wait_reserved,
    0.00 :   ffff800010353978:       ldr     w0, [x19, #1040]
         : 312              atomic_read():
    0.00 :   ffff80001035397c:       ldr     w1, [x19, #980]
         : 29               add_transaction_credits():
    0.00 :   ffff800010353980:       add     w0, w0, w0, lsr #31
    0.00 :   ffff800010353984:       add     w1, w23, w1
    0.00 :   ffff800010353988:       cmp     w1, w0, asr #1
    0.00 :   ffff80001035398c:       b.le    ffff80001035391c <add_transaction_credits+0x134>
    0.00 :   ffff800010353990:       add     x20, sp, #0x40
    0.00 :   ffff800010353994:       add     x22, x19, #0xe8
    0.00 :   ffff800010353998:       mov     x0, x20
    0.00 :   ffff80001035399c:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000103539a0:       bl      ffff8000100cfd50 <init_wait_entry>
    0.00 :   ffff8000103539a4:       b       ffff8000103539ac <add_transaction_credits+0x1c4>
    0.00 :   ffff8000103539a8:       bl      ffff800010e2e4a0 <schedule>
    0.00 :   ffff8000103539ac:       mov     x1, x20
    0.00 :   ffff8000103539b0:       mov     w2, #0x2                        // #2
    0.00 :   ffff8000103539b4:       mov     x0, x22
    0.00 :   ffff8000103539b8:       bl      ffff8000100cfd80 <prepare_to_wait_event>
    0.00 :   ffff8000103539bc:       ldr     w0, [x19, #1040]
         : 315              atomic_read():
    0.00 :   ffff8000103539c0:       ldr     w1, [x19, #980]
         : 29               add_transaction_credits():
    0.00 :   ffff8000103539c4:       add     w0, w0, w0, lsr #31
    0.00 :   ffff8000103539c8:       add     w1, w23, w1
    0.00 :   ffff8000103539cc:       cmp     w1, w0, asr #1
    0.00 :   ffff8000103539d0:       b.gt    ffff8000103539a8 <add_transaction_credits+0x1c0>
    0.00 :   ffff8000103539d4:       mov     x0, x22
    0.00 :   ffff8000103539d8:       mov     x1, x20
    0.00 :   ffff8000103539dc:       bl      ffff8000100cfec8 <finish_wait>
         : 313              return 1;
    0.00 :   ffff8000103539e0:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000103539e4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000103539e8:       b       ffff800010353834 <add_transaction_credits+0x4c>
         : 239              WARN_ON_ONCE(t->t_state >= T_FLUSH);
    0.00 :   ffff8000103539ec:       brk     #0x800
    0.00 :   ffff8000103539f0:       b       ffff800010353828 <add_transaction_credits+0x40>
         : 242              __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000103539f4:       add     x2, x20, #0x9c
    0.00 :   ffff8000103539f8:       b       ffff800010356574 <jbd2_journal_begin_ordered_truncate+0x194>
    0.00 :   ffff8000103539fc:       b       ffff8000103538ec <add_transaction_credits+0x104>
    0.00 :   ffff800010353a00:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010353a04:       b       ffff800010353828 <add_transaction_credits+0x40>
         : 118              arch_static_branch_jump():
    0.00 :   ffff800010353a08:       b       ffff800010353a2c <add_transaction_credits+0x244>
    0.00 :   ffff800010353a0c:       b       ffff800010353a2c <add_transaction_credits+0x244>
         : 40               __lse_atomic_sub():
    0.00 :   ffff800010353a10:       add     x0, x20, #0x9c
    0.00 :   ffff800010353a14:       neg     w22, w22
    0.00 :   ffff800010353a18:       stadd   w22, [x0]
    0.00 :   ffff800010353a1c:       b       ffff800010353a34 <add_transaction_credits+0x24c>
         : 117              __ll_sc_atomic_add_return():
         : 111              ATOMIC_OPS(add, add, I)
    0.00 :   ffff800010353a20:       add     x2, x19, #0x3d4
    0.00 :   ffff800010353a24:       b       ffff80001035658c <jbd2_journal_begin_ordered_truncate+0x1ac>
    0.00 :   ffff800010353a28:       b       ffff800010353940 <add_transaction_credits+0x158>
         : 115              __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010353a2c:       add     x2, x20, #0x9c
    0.00 :   ffff800010353a30:       b       ffff8000103565a8 <jbd2_journal_begin_ordered_truncate+0x1c8>
         : 115              add_transaction_credits():
         : 289              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353a34:       add     x20, x19, #0x44
    0.00 :   ffff800010353a38:       mov     x0, x20
    0.00 :   ffff800010353a3c:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 291              write_lock(&journal->j_state_lock);
    0.00 :   ffff800010353a40:       mov     x0, x20
    0.00 :   ffff800010353a44:       bl      ffff800010e35190 <_raw_write_lock>
         : 292              if (jbd2_log_space_left(journal) <
    0.00 :   ffff800010353a48:       ldr     x1, [x19, #120]
         : 294              jbd2_log_space_left():
         : 1717             */
    0.00 :   ffff800010353a4c:       ldr     x0, [x19, #840]
    0.00 :   ffff800010353a50:       sub     x0, x0, #0x20
         : 1719             {
    0.00 :   ffff800010353a54:       cbz     x1, ffff800010353a60 <add_transaction_credits+0x278>
         : 1721             atomic_read():
    0.00 :   ffff800010353a58:       ldr     w1, [x1, #156]
         : 29               jbd2_log_space_left():
         : 1720             /* Allow for rounding errors */
    0.00 :   ffff800010353a5c:       sub     x0, x0, w1, sxtw
         : 1723             if (journal->j_committing_transaction) {
    0.00 :   ffff800010353a60:       cmp     x0, #0x0
         : 1725             add_transaction_credits():
         : 293              journal->j_max_transaction_buffers)
    0.00 :   ffff800010353a64:       ldrsw   x1, [x19, #1040]
         : 295              jbd2_log_space_left():
    0.00 :   ffff800010353a68:       csel    x0, x0, xzr, ge  // ge = tcont
         : 1724             add_transaction_credits():
         : 292              if (jbd2_log_space_left(journal) <
    0.00 :   ffff800010353a6c:       cmp     x1, x0
    0.00 :   ffff800010353a70:       b.hi    ffff800010353ad8 <add_transaction_credits+0x2f0>  // b.pmore
         : 295              write_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353a74:       mov     x0, x20
    0.00 :   ffff800010353a78:       bl      ffff800010e34aa8 <_raw_write_unlock>
    0.00 :   ffff800010353a7c:       b       ffff80001035391c <add_transaction_credits+0x134>
         : 266              wait_event(journal->j_wait_reserved,
    0.00 :   ffff800010353a80:       add     x20, sp, #0x40
    0.00 :   ffff800010353a84:       add     x23, x19, #0xe8
    0.00 :   ffff800010353a88:       mov     x0, x20
    0.00 :   ffff800010353a8c:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010353a90:       bl      ffff8000100cfd50 <init_wait_entry>
    0.00 :   ffff800010353a94:       b       ffff800010353a9c <add_transaction_credits+0x2b4>
    0.00 :   ffff800010353a98:       bl      ffff800010e2e4a0 <schedule>
    0.00 :   ffff800010353a9c:       mov     x1, x20
    0.00 :   ffff800010353aa0:       mov     w2, #0x2                        // #2
    0.00 :   ffff800010353aa4:       mov     x0, x23
    0.00 :   ffff800010353aa8:       bl      ffff8000100cfd80 <prepare_to_wait_event>
         : 270              atomic_read():
    0.00 :   ffff800010353aac:       ldr     w0, [x19, #980]
         : 29               add_transaction_credits():
    0.00 :   ffff800010353ab0:       ldr     w1, [x19, #1040]
    0.00 :   ffff800010353ab4:       add     w0, w22, w0
    0.00 :   ffff800010353ab8:       cmp     w0, w1
    0.00 :   ffff800010353abc:       b.gt    ffff800010353a98 <add_transaction_credits+0x2b0>
    0.00 :   ffff800010353ac0:       mov     x0, x23
    0.00 :   ffff800010353ac4:       mov     x1, x20
    0.00 :   ffff800010353ac8:       bl      ffff8000100cfec8 <finish_wait>
         : 269              return 1;
    0.00 :   ffff800010353acc:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010353ad0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010353ad4:       b       ffff800010353834 <add_transaction_credits+0x4c>
         : 294              __jbd2_log_wait_for_space(journal);
    0.00 :   ffff800010353ad8:       mov     x0, x19
    0.00 :   ffff800010353adc:       bl      ffff80001035a188 <__jbd2_log_wait_for_space>
    0.00 :   ffff800010353ae0:       b       ffff800010353a74 <add_transaction_credits+0x28c>
         : 298              __ll_sc_atomic_sub():
    0.00 :   ffff800010353ae4:       add     x2, x20, #0x9c
    0.00 :   ffff800010353ae8:       b       ffff8000103565c0 <jbd2_journal_begin_ordered_truncate+0x1e0>
    0.00 :   ffff800010353aec:       b       ffff800010353970 <add_transaction_credits+0x188>
    0.00 :   ffff800010353af0:       stp     x23, x24, [sp, #48]
         : 116              add_transaction_credits():
         : 316              }
    0.00 :   ffff800010353af4:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010223ac8 <__mem_cgroup_charge>:
         : 6                __mem_cgroup_charge():
         : 6518             .legacy_cftypes = mem_cgroup_legacy_files,
         : 6519             .early_init = 0,
         : 6520             };
         :
         : 6522             /*
         : 6523             * This function calculates an individual cgroup's effective
    0.00 :   ffff800010223ac8:       paciasp
    0.00 :   ffff800010223acc:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010223ad0:       mov     x29, sp
    0.00 :   ffff800010223ad4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010223ad8:       mov     x20, x0
    0.00 :   ffff800010223adc:       mov     x19, x1
    0.00 :   ffff800010223ae0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010223ae4:       mov     w1, w2
         : 6532             thp_nr_pages():
         : 276              return 0;
         : 277              }
         :
         : 279              /**
         : 280              * thp_nr_pages - The number of regular pages in this huge page.
         : 281              * @page: The head page of a huge page.
    0.00 :   ffff800010223ae8:       mov     w2, #0x200                      // #512
         : 283              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010223aec:       ldr     x0, [x0]
         : 113              thp_nr_pages():
         : 277              */
    0.00 :   ffff800010223af0:       mov     w22, w2
         : 276              * @page: The head page of a huge page.
    0.00 :   ffff800010223af4:       tst     w0, #0x10000
    0.00 :   ffff800010223af8:       b.ne    ffff800010223b04 <__mem_cgroup_charge+0x3c>  // b.any
    0.00 :   ffff800010223afc:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010223b00:       mov     w22, w2
         : 281              __mem_cgroup_charge():
         : 6522             * protection which is derived from its own memory.min/low, its
         : 6523             * parent's and siblings' settings, as well as the actual memory
         : 6524             * distribution in the tree.
         : 6525             *
    0.00 :   ffff800010223b04:       mov     x0, x19
    0.00 :   ffff800010223b08:       bl      ffff800010222c10 <try_charge>
    0.00 :   ffff800010223b0c:       mov     w21, w0
         : 6523             * The following rules apply to the effective protection values:
    0.00 :   ffff800010223b10:       cbnz    w0, ffff800010223b50 <__mem_cgroup_charge+0x88>
         : 6525             css_get():
         : 323              *
         : 324              * The caller must already have a reference.
         : 325              */
         : 326              static inline void css_get(struct cgroup_subsys_state *css)
         : 327              {
         : 328              if (!(css->flags & CSS_NO_REF))
    0.00 :   ffff800010223b14:       ldr     w0, [x19, #84]
    0.00 :   ffff800010223b18:       tbz     w0, #0, ffff800010223b70 <__mem_cgroup_charge+0xa8>
         : 331              commit_charge():
         : 2724             */
    0.00 :   ffff800010223b1c:       str     x19, [x20, #56]
         : 2726             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010223b20:       nop
    0.00 :   ffff800010223b24:       mov     x0, #0x60                       // #96
         : 29               arch_local_irq_disable():
         : 54               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 56               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 57               }
         :
         : 59               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010223b28:       msr     daifset, #0x3
         : 61               __mem_cgroup_charge():
         : 6530             * 1. At the first level of reclaim, effective protection is equal to
         : 6531             *    the declared protection in memory.min and memory.low.
         : 6532             *
         : 6533             * 2. To enable safe delegation of the protection configuration, at
         : 6534             *    subsequent levels the effective protection is capped to the
         : 6535             *    parent's effective protection.
    0.00 :   ffff800010223b2c:       mov     w1, w22
    0.00 :   ffff800010223b30:       mov     x0, x19
    0.00 :   ffff800010223b34:       bl      ffff8000102209b8 <mem_cgroup_charge_statistics.isra.89>
         : 6531             *
    0.00 :   ffff800010223b38:       mov     x0, x19
    0.00 :   ffff800010223b3c:       mov     x1, x20
    0.00 :   ffff800010223b40:       bl      ffff800010220260 <memcg_check_events>
         : 6535             arch_local_irq_enable():
         : 35               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010223b44:       mov     x0, #0xe0                       // #224
    0.00 :   ffff800010223b48:       msr     daifclr, #0x3
         : 38               arch_static_branch():
    0.00 :   ffff800010223b4c:       nop
         : 22               __mem_cgroup_charge():
         : 6535             * 3. To make complex and dynamic subtrees easier to configure, the
         : 6536             *    user is allowed to overcommit the declared protection at a given
         : 6537             *    level. If that is the case, the parent's effective protection is
         : 6538             *    distributed to the children in proportion to how much protection
    0.00 :   ffff800010223b50:       mov     w0, w21
    0.00 :   ffff800010223b54:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010223b58:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010223b5c:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010223b60:       autiasp
    0.00 :   ffff800010223b64:       ret
         : 6545             arch_static_branch():
    0.00 :   ffff800010223b68:       mov     x0, #0xa0                       // #160
    0.00 :   ffff800010223b6c:       b       ffff800010223b28 <__mem_cgroup_charge+0x60>
         : 23               percpu_ref_get():
         : 222              *
         : 223              * This function is safe to call as long as @ref is between init and exit.
         : 224              */
         : 225              static inline void percpu_ref_get(struct percpu_ref *ref)
         : 226              {
         : 227              percpu_ref_get_many(ref, 1);
    0.00 :   ffff800010223b70:       mov     x1, #0x1                        // #1
    0.00 :   ffff800010223b74:       add     x0, x19, #0x10
    0.00 :   ffff800010223b78:       bl      ffff80001021f108 <percpu_ref_get_many>
         : 231              commit_charge():
         : 2724             */
    0.00 :   ffff800010223b7c:       str     x19, [x20, #56]
         : 2726             arch_static_branch():
    0.00 :   ffff800010223b80:       nop
    0.00 :   ffff800010223b84:       b       ffff800010223b24 <__mem_cgroup_charge+0x5c>
         : 23               arch_local_irq_enable():
         : 43               pmr_sync();
    0.00 :   ffff800010223b88:       dsb     sy
         : 45               __mem_cgroup_charge():
         : 6535             *    distributed to the children in proportion to how much protection
   71.45 :   ffff800010223b8c:       mov     w0, w21
    0.00 :   ffff800010223b90:       ldp     x19, x20, [sp, #16]
   28.55 :   ffff800010223b94:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010223b98:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010223b9c:       autiasp
    0.00 :   ffff800010223ba0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010353af8 <start_this_handle>:
         : 6                start_this_handle():
         : 327              * transaction's buffer credits.
         : 328              */
         :
         : 330              static int start_this_handle(journal_t *journal, handle_t *handle,
         : 331              gfp_t gfp_mask)
         : 332              {
    0.00 :   ffff800010353af8:       paciasp
    0.00 :   ffff800010353afc:       stp     x29, x30, [sp, #-160]!
    0.00 :   ffff800010353b00:       adrp    x3, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010353b04:       mov     x29, sp
    0.00 :   ffff800010353b08:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010353b0c:       add     x3, x3, #0x948
    0.00 :   ffff800010353b10:       mov     x20, x1
    0.00 :   ffff800010353b14:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010353b18:       mov     x26, x0
         : 331              transaction_t   *transaction, *new_transaction = NULL;
         : 332              int             blocks = handle->h_total_credits;
         : 333              int             rsv_blocks = 0;
         : 334              unsigned long ts = jiffies;
    0.00 :   ffff800010353b1c:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
         : 327              {
    0.00 :   ffff800010353b20:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010353b24:       mov     w25, #0x0                       // #0
    0.00 :   ffff800010353b28:       ldr     x1, [x3]
    0.00 :   ffff800010353b2c:       str     x1, [sp, #152]
    0.00 :   ffff800010353b30:       mov     x1, #0x0                        // #0
    0.00 :   ffff800010353b34:       str     x3, [sp, #104]
         : 329              int             blocks = handle->h_total_credits;
    0.00 :   ffff800010353b38:       ldr     w1, [x20, #16]
         : 327              {
    0.00 :   ffff800010353b3c:       stp     w1, w2, [sp, #96]
         : 331              unsigned long ts = jiffies;
    0.00 :   ffff800010353b40:       ldr     x0, [x0, #2432]
         :
         : 334              if (handle->h_rsv_handle)
    0.00 :   ffff800010353b44:       ldr     x0, [x20, #8]
    0.00 :   ffff800010353b48:       cbz     x0, ffff800010353b50 <start_this_handle+0x58>
         : 334              rsv_blocks = handle->h_rsv_handle->h_total_credits;
    0.00 :   ffff800010353b4c:       ldr     w25, [x0, #16]
         : 341              /*
         : 342              * Limit the number of reserved credits to 1/2 of maximum transaction
         : 343              * size and limit the number of total credits to not exceed maximum
         : 344              * transaction size per operation.
         : 345              */
         : 346              if ((rsv_blocks > journal->j_max_transaction_buffers / 2) ||
    0.00 :   ffff800010353b50:       ldr     w4, [x26, #1040]
    0.00 :   ffff800010353b54:       add     w0, w4, w4, lsr #31
    0.00 :   ffff800010353b58:       cmp     w25, w0, asr #1
    0.00 :   ffff800010353b5c:       b.gt    ffff800010353f58 <start_this_handle+0x460>
         : 342              (rsv_blocks + blocks > journal->j_max_transaction_buffers)) {
    0.00 :   ffff800010353b60:       ldr     w0, [sp, #96]
    0.00 :   ffff800010353b64:       add     w0, w25, w0
         : 341              if ((rsv_blocks > journal->j_max_transaction_buffers / 2) ||
    0.00 :   ffff800010353b68:       cmp     w4, w0
    0.00 :   ffff800010353b6c:       b.lt    ffff800010353f58 <start_this_handle+0x460>  // b.tstop
    0.00 :   ffff800010353b70:       stp     x23, x24, [sp, #48]
         : 345              wait_transaction_switching():
         : 195              DEFINE_WAIT(wait);
    0.00 :   ffff800010353b74:       adrp    x24, ffff8000100d0000 <do_wait_intr_irq+0x18>
    0.00 :   ffff800010353b78:       add     x23, sp, #0x88
    0.00 :   ffff800010353b7c:       add     x24, x24, #0x140
    0.00 :   ffff800010353b80:       stp     x21, x22, [sp, #32]
         : 200              start_this_handle():
         : 357              /*
         : 358              * This check is racy but it is just an optimization of allocating new
         : 359              * transaction early if there are high chances we'll need it. If we
         : 360              * guess wrong, we'll retry or free unused transaction.
         : 361              */
         : 362              if (!data_race(journal->j_running_transaction)) {
    0.00 :   ffff800010353b84:       mov     x22, #0x0                       // #0
    0.00 :   ffff800010353b88:       ldr     x0, [x26, #112]
    0.00 :   ffff800010353b8c:       cbz     x0, ffff800010353d00 <start_this_handle+0x208>
         : 370              gfp_mask);
         : 371              if (!new_transaction)
         : 372              return -ENOMEM;
         : 373              }
         :
         : 375              jbd_debug(3, "New handle %p going live.\n", handle);
    0.00 :   ffff800010353b90:       add     x19, x26, #0x44
         : 377              wait_transaction_switching():
         : 202              prepare_to_wait(&journal->j_wait_transaction_locked, &wait,
    0.00 :   ffff800010353b94:       add     x21, x26, #0x88
         : 204              start_this_handle():
         : 377              /*
         : 378              * We need to hold j_state_lock until t_updates has been incremented,
         : 379              * for proper journal barrier handling
         : 380              */
         : 381              repeat:
         : 382              read_lock(&journal->j_state_lock);
    0.00 :   ffff800010353b98:       mov     x0, x19
    0.00 :   ffff800010353b9c:       bl      ffff800010e352c0 <_raw_read_lock>
         : 378              BUG_ON(journal->j_flags & JBD2_UNMOUNT);
    0.00 :   ffff800010353ba0:       ldr     x0, [x26]
    0.00 :   ffff800010353ba4:       tbnz    w0, #0, ffff800010353c6c <start_this_handle+0x174>
         : 379              if (is_journal_aborted(journal) ||
    0.00 :   ffff800010353ba8:       and     w28, w0, #0x2
    0.00 :   ffff800010353bac:       tbnz    w0, #1, ffff800010353e40 <start_this_handle+0x348>
    0.00 :   ffff800010353bb0:       ldr     w1, [x26, #8]
    0.00 :   ffff800010353bb4:       cbz     w1, ffff800010353bbc <start_this_handle+0xc4>
         : 380              (journal->j_errno != 0 && !(journal->j_flags & JBD2_ACK_ERR))) {
    0.00 :   ffff800010353bb8:       tbz     w0, #2, ffff800010353e40 <start_this_handle+0x348>
         : 391              /*
         : 392              * Wait on the journal's transaction barrier if necessary. Specifically
         : 393              * we allow reserved handles to proceed because otherwise commit could
         : 394              * deadlock on page writeback not being able to complete.
         : 395              */
         : 396              if (!handle->h_reserved && journal->j_barrier_count) {
    0.00 :   ffff800010353bbc:       ldrb    w0, [x20, #36]
    0.00 :   ffff800010353bc0:       tbnz    w0, #2, ffff800010353c20 <start_this_handle+0x128>
   62.74 :   ffff800010353bc4:       ldr     w0, [x26, #76]
    0.00 :   ffff800010353bc8:       cbnz    w0, ffff800010353cc0 <start_this_handle+0x1c8>
         : 398              wait_event(journal->j_wait_transaction_locked,
         : 399              journal->j_barrier_count == 0);
         : 400              goto repeat;
         : 401              }
         :
         : 403              if (!journal->j_running_transaction) {
    0.00 :   ffff800010353bcc:       ldr     x27, [x26, #112]
    0.00 :   ffff800010353bd0:       cbz     x27, ffff800010353c98 <start_this_handle+0x1a0>
         :
         : 417              transaction = journal->j_running_transaction;
         :
         : 419              if (!handle->h_reserved) {
         : 420              /* We may have dropped j_state_lock - restart in that case */
         : 421              if (add_transaction_credits(journal, blocks, rsv_blocks))
    0.00 :   ffff800010353bd4:       ldr     w1, [sp, #96]
    0.00 :   ffff800010353bd8:       mov     w2, w25
    0.00 :   ffff800010353bdc:       mov     x0, x26
    0.00 :   ffff800010353be0:       bl      ffff8000103537e8 <add_transaction_credits>
    0.00 :   ffff800010353be4:       cbnz    w0, ffff800010353b98 <start_this_handle+0xa0>
         : 441              */
         : 442              update_t_max_wait(transaction, ts);
         : 443              handle->h_transaction = transaction;
         : 444              handle->h_requested_credits = blocks;
         : 445              handle->h_revoke_credits_requested = handle->h_revoke_credits;
         : 446              handle->h_start_jiffies = jiffies;
    0.00 :   ffff800010353be8:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
         : 438              handle->h_transaction = transaction;
    0.00 :   ffff800010353bec:       str     x27, [x20]
         : 440              handle->h_revoke_credits_requested = handle->h_revoke_credits;
    0.00 :   ffff800010353bf0:       ldr     w2, [x20, #20]
         : 442              atomic_inc(&transaction->t_updates);
    0.00 :   ffff800010353bf4:       add     x0, x27, #0x98
         : 441              handle->h_start_jiffies = jiffies;
    0.00 :   ffff800010353bf8:       ldr     x1, [x1, #2432]
    0.00 :   ffff800010353bfc:       str     x1, [x20, #40]
         : 439              handle->h_requested_credits = blocks;
    0.00 :   ffff800010353c00:       ldr     w1, [sp, #96]
         : 440              handle->h_revoke_credits_requested = handle->h_revoke_credits;
    0.00 :   ffff800010353c04:       str     w2, [x20, #24]
         : 439              handle->h_requested_credits = blocks;
    0.00 :   ffff800010353c08:       str     w1, [x20, #48]
         : 441              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010353c0c:       b       ffff800010353ecc <start_this_handle+0x3d4>
    0.00 :   ffff800010353c10:       b       ffff800010353ecc <start_this_handle+0x3d4>
         : 46               __lse_atomic_add():
         : 26               }
         :
         : 28               ATOMIC_OP(andnot, stclr)
         : 29               ATOMIC_OP(or, stset)
         : 30               ATOMIC_OP(xor, steor)
         : 31               ATOMIC_OP(add, stadd)
    0.00 :   ffff800010353c14:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010353c18:       stadd   w1, [x0]
   37.26 :   ffff800010353c1c:       b       ffff800010353ed0 <start_this_handle+0x3d8>
         : 35               start_this_handle():
         : 398              if (!journal->j_running_transaction) {
    0.00 :   ffff800010353c20:       ldr     x27, [x26, #112]
    0.00 :   ffff800010353c24:       cbz     x27, ffff800010353c98 <start_this_handle+0x1a0>
         : 426              if (transaction->t_state == T_SWITCH) {
    0.00 :   ffff800010353c28:       ldr     w0, [x27, #12]
    0.00 :   ffff800010353c2c:       cmp     w0, #0x2
    0.00 :   ffff800010353c30:       b.ne    ffff800010353eb0 <start_this_handle+0x3b8>  // b.any
         : 430              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010353c34:       mrs     x0, sp_el0
         : 26               wait_transaction_switching():
         : 195              DEFINE_WAIT(wait);
    0.00 :   ffff800010353c38:       stp     xzr, x0, [sp, #112]
    0.00 :   ffff800010353c3c:       stp     x24, x23, [sp, #128]
    0.00 :   ffff800010353c40:       str     x23, [sp, #144]
         : 197              if (WARN_ON(!journal->j_running_transaction ||
    0.00 :   ffff800010353c44:       ldr     w2, [x27, #12]
    0.00 :   ffff800010353c48:       cmp     w2, #0x2
    0.00 :   ffff800010353c4c:       b.eq    ffff800010353c70 <start_this_handle+0x178>  // b.none
    0.00 :   ffff800010353c50:       brk     #0x800
         : 199              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353c54:       mov     x0, x19
    0.00 :   ffff800010353c58:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 202              start_this_handle():
         : 377              read_lock(&journal->j_state_lock);
    0.00 :   ffff800010353c5c:       mov     x0, x19
    0.00 :   ffff800010353c60:       bl      ffff800010e352c0 <_raw_read_lock>
         : 378              BUG_ON(journal->j_flags & JBD2_UNMOUNT);
    0.00 :   ffff800010353c64:       ldr     x0, [x26]
    0.00 :   ffff800010353c68:       tbz     w0, #0, ffff800010353ba8 <start_this_handle+0xb0>
    0.00 :   ffff800010353c6c:       brk     #0x800
         : 379              wait_transaction_switching():
         : 202              prepare_to_wait(&journal->j_wait_transaction_locked, &wait,
    0.00 :   ffff800010353c70:       add     x1, sp, #0x70
    0.00 :   ffff800010353c74:       mov     x0, x21
    0.00 :   ffff800010353c78:       bl      ffff8000100cfbf8 <prepare_to_wait>
         : 204              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353c7c:       mov     x0, x19
    0.00 :   ffff800010353c80:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 211              schedule();
    0.00 :   ffff800010353c84:       bl      ffff800010e2e4a0 <schedule>
         : 212              finish_wait(&journal->j_wait_transaction_locked, &wait);
    0.00 :   ffff800010353c88:       add     x1, sp, #0x70
    0.00 :   ffff800010353c8c:       mov     x0, x21
    0.00 :   ffff800010353c90:       bl      ffff8000100cfec8 <finish_wait>
    0.00 :   ffff800010353c94:       b       ffff800010353b98 <start_this_handle+0xa0>
         : 217              start_this_handle():
         : 399              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353c98:       mov     x0, x19
    0.00 :   ffff800010353c9c:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 400              if (!new_transaction)
    0.00 :   ffff800010353ca0:       cbz     x22, ffff800010353b84 <start_this_handle+0x8c>
         : 402              write_lock(&journal->j_state_lock);
    0.00 :   ffff800010353ca4:       mov     x0, x19
    0.00 :   ffff800010353ca8:       bl      ffff800010e35190 <_raw_write_lock>
         : 403              if (!journal->j_running_transaction &&
    0.00 :   ffff800010353cac:       ldr     x0, [x26, #112]
    0.00 :   ffff800010353cb0:       cbz     x0, ffff800010353d3c <start_this_handle+0x244>
         : 408              write_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353cb4:       mov     x0, x19
    0.00 :   ffff800010353cb8:       bl      ffff800010e34aa8 <_raw_write_unlock>
         : 409              goto repeat;
    0.00 :   ffff800010353cbc:       b       ffff800010353b98 <start_this_handle+0xa0>
         : 392              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353cc0:       mov     x0, x19
    0.00 :   ffff800010353cc4:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 393              wait_event(journal->j_wait_transaction_locked,
    0.00 :   ffff800010353cc8:       ldr     w0, [x26, #76]
    0.00 :   ffff800010353ccc:       cbz     w0, ffff800010353b98 <start_this_handle+0xa0>
    0.00 :   ffff800010353cd0:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010353cd4:       add     x0, sp, #0x70
    0.00 :   ffff800010353cd8:       bl      ffff8000100cfd50 <init_wait_entry>
    0.00 :   ffff800010353cdc:       b       ffff800010353ce4 <start_this_handle+0x1ec>
    0.00 :   ffff800010353ce0:       bl      ffff800010e2e4a0 <schedule>
    0.00 :   ffff800010353ce4:       mov     w2, #0x2                        // #2
    0.00 :   ffff800010353ce8:       add     x1, sp, #0x70
    0.00 :   ffff800010353cec:       mov     x0, x21
    0.00 :   ffff800010353cf0:       bl      ffff8000100cfd80 <prepare_to_wait_event>
    0.00 :   ffff800010353cf4:       ldr     w0, [x26, #76]
    0.00 :   ffff800010353cf8:       cbnz    w0, ffff800010353ce0 <start_this_handle+0x1e8>
    0.00 :   ffff800010353cfc:       b       ffff800010353c88 <start_this_handle+0x190>
         : 363              gfp_mask |= __GFP_NOFAIL;
    0.00 :   ffff800010353d00:       ldr     w2, [sp, #100]
         : 364              new_transaction = kmem_cache_zalloc(transaction_cache,
    0.00 :   ffff800010353d04:       adrp    x0, ffff800011f64000 <kernfs_pr_cont_buf+0xcd0>
         : 366              kmem_cache_zalloc():
         : 676              #define kmalloc_track_caller(size, flags) \
         : 677              __kmalloc_track_caller(size, flags, _RET_IP_)
         :
         : 679              static inline void *kmalloc_array_node(size_t n, size_t size, gfp_t flags,
         : 680              int node)
         : 681              {
    0.00 :   ffff800010353d08:       ldr     x0, [x0, #2040]
         : 683              start_this_handle():
         : 363              gfp_mask |= __GFP_NOFAIL;
    0.00 :   ffff800010353d0c:       tst     x2, #0x80
    0.00 :   ffff800010353d10:       orr     w1, w2, #0x8000
    0.00 :   ffff800010353d14:       csel    w1, w1, w2, eq  // eq = none
    0.00 :   ffff800010353d18:       str     w1, [sp, #100]
         : 368              kmem_cache_zalloc():
    0.00 :   ffff800010353d1c:       orr     w1, w1, #0x100
    0.00 :   ffff800010353d20:       bl      ffff800010208a10 <kmem_cache_alloc>
    0.00 :   ffff800010353d24:       mov     x22, x0
         : 679              start_this_handle():
         : 366              if (!new_transaction)
    0.00 :   ffff800010353d28:       cbnz    x0, ffff800010353b90 <start_this_handle+0x98>
         : 367              return -ENOMEM;
    0.00 :   ffff800010353d2c:       mov     w28, #0xfffffff4                // #-12
    0.00 :   ffff800010353d30:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010353d34:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010353d38:       b       ffff800010353e6c <start_this_handle+0x374>
         : 404              (handle->h_reserved || !journal->j_barrier_count)) {
    0.00 :   ffff800010353d3c:       ldrb    w0, [x20, #36]
         : 403              if (!journal->j_running_transaction &&
    0.00 :   ffff800010353d40:       tbnz    w0, #2, ffff800010353d4c <start_this_handle+0x254>
         : 404              (handle->h_reserved || !journal->j_barrier_count)) {
    0.00 :   ffff800010353d44:       ldr     w0, [x26, #76]
    0.00 :   ffff800010353d48:       cbnz    w0, ffff800010353cb4 <start_this_handle+0x1bc>
         : 407              jbd2_get_transaction():
         : 105              transaction->t_journal = journal;
    0.00 :   ffff800010353d4c:       str     x26, [x22]
         : 106              transaction->t_state = T_RUNNING;
    0.00 :   ffff800010353d50:       str     wzr, [x22, #12]
         : 107              transaction->t_start_time = ktime_get();
    0.00 :   ffff800010353d54:       bl      ffff800010110e30 <ktime_get>
    0.00 :   ffff800010353d58:       str     x0, [x22, #192]
         : 109              transaction->t_expires = jiffies + journal->j_commit_interval;
    0.00 :   ffff800010353d5c:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010353d60:       ldr     x1, [x0, #2432]
         : 108              transaction->t_tid = journal->j_transaction_sequence++;
    0.00 :   ffff800010353d64:       ldr     w0, [x26, #1004]
    0.00 :   ffff800010353d68:       add     w2, w0, #0x1
    0.00 :   ffff800010353d6c:       str     w2, [x26, #1004]
    0.00 :   ffff800010353d70:       str     w0, [x22, #8]
         : 109              transaction->t_expires = jiffies + journal->j_commit_interval;
    0.00 :   ffff800010353d74:       ldr     x0, [x26, #1048]
         : 110              spin_lock_init(&transaction->t_handle_lock);
    0.00 :   ffff800010353d78:       str     wzr, [x22, #96]
         : 112              atomic_set():
         : 46               instrument_atomic_write(v, sizeof(*v));
         : 47               arch_atomic_set(v, i);
         : 48               }
         :
         : 50               static __always_inline void
         : 51               atomic_set_release(atomic_t *v, int i)
    0.00 :   ffff800010353d7c:       str     wzr, [x22, #152]
         : 53               jbd2_get_transaction():
         : 109              transaction->t_expires = jiffies + journal->j_commit_interval;
    0.00 :   ffff800010353d80:       add     x0, x0, x1
    0.00 :   ffff800010353d84:       str     x0, [x22, #184]
         : 112              jbd2_has_feature_csum2():
         : 1355             JBD2_FEATURE_COMPAT_FUNCS(checksum,             CHECKSUM)
         :
         : 1357             JBD2_FEATURE_INCOMPAT_FUNCS(revoke,             REVOKE)
         : 1358             JBD2_FEATURE_INCOMPAT_FUNCS(64bit,              64BIT)
         : 1359             JBD2_FEATURE_INCOMPAT_FUNCS(async_commit,       ASYNC_COMMIT)
         : 1360             JBD2_FEATURE_INCOMPAT_FUNCS(csum2,              CSUM_V2)
    0.00 :   ffff800010353d88:       ldr     w0, [x26, #64]
         : 1362             jbd2_descriptor_blocks_per_trans():
         : 70               int tag_space = journal->j_blocksize - sizeof(journal_header_t);
    0.00 :   ffff800010353d8c:       ldr     w1, [x26, #896]
         : 72               jbd2_has_feature_csum2():
    0.00 :   ffff800010353d90:       cmp     w0, #0x1
    0.00 :   ffff800010353d94:       b.le    ffff800010353ea0 <start_this_handle+0x3a8>
    0.00 :   ffff800010353d98:       ldr     x0, [x26, #56]
         : 1358             jbd2_has_feature_csum3():
         : 1356             JBD2_FEATURE_INCOMPAT_FUNCS(csum3,              CSUM_V3)
    0.00 :   ffff800010353d9c:       ldr     w0, [x0, #40]
    0.00 :   ffff800010353da0:       tst     w0, #0x18000000
    0.00 :   ffff800010353da4:       b.eq    ffff800010353ea0 <start_this_handle+0x3a8>  // b.none
         : 1360             jbd2_journal_has_csum_v2or3():
         : 1698             extern size_t journal_tag_bytes(journal_t *journal);
         :
         : 1700             static inline bool jbd2_journal_has_csum_v2or3_feature(journal_t *j)
         : 1701             {
         : 1702             return jbd2_has_feature_csum2(j) || jbd2_has_feature_csum3(j);
         : 1703             }
    0.00 :   ffff800010353da8:       ldr     x0, [x26, #1312]
    0.00 :   ffff800010353dac:       cbz     x0, ffff800010353e9c <start_this_handle+0x3a4>
         : 1706             jbd2_descriptor_blocks_per_trans():
         : 76               tag_space -= sizeof(struct jbd2_journal_block_tail);
    0.00 :   ffff800010353db0:       sub     w27, w1, #0x20
         : 78               tags_per_block = (tag_space - 16) / journal_tag_bytes(journal);
    0.00 :   ffff800010353db4:       mov     x0, x26
    0.00 :   ffff800010353db8:       bl      ffff80001035e8d0 <journal_tag_bytes>
    0.00 :   ffff800010353dbc:       sub     w1, w27, #0x10
         : 83               return 1 + DIV_ROUND_UP(journal->j_max_transaction_buffers,
    0.00 :   ffff800010353dc0:       ldr     w2, [x26, #1040]
         : 85               atomic_read():
         : 28               return arch_atomic_read(v);
    0.00 :   ffff800010353dc4:       ldr     w6, [x26, #980]
         : 30               jbd2_get_transaction():
         : 117              INIT_LIST_HEAD(&transaction->t_inode_list);
    0.00 :   ffff800010353dc8:       add     x5, x22, #0x50
         : 119              jbd2_descriptor_blocks_per_trans():
         : 78               tags_per_block = (tag_space - 16) / journal_tag_bytes(journal);
    0.00 :   ffff800010353dcc:       sxtw    x1, w1
         : 83               return 1 + DIV_ROUND_UP(journal->j_max_transaction_buffers,
    0.00 :   ffff800010353dd0:       sub     w2, w2, #0x1
         : 85               jbd2_get_transaction():
         : 112              atomic_set(&transaction->t_outstanding_credits,
    0.00 :   ffff800010353dd4:       add     w6, w6, #0x1
         : 118              INIT_LIST_HEAD(&transaction->t_private_list);
    0.00 :   ffff800010353dd8:       add     x4, x22, #0xd0
         : 120              INIT_LIST_HEAD():
         : 36               * the result is an empty list.
         : 37               */
         : 38               static inline void INIT_LIST_HEAD(struct list_head *list)
         : 39               {
         : 40               WRITE_ONCE(list->next, list);
         : 41               list->prev = list;
    0.00 :   ffff800010353ddc:       str     x5, [x22, #88]
         : 43               jbd2_descriptor_blocks_per_trans():
         : 78               tags_per_block = (tag_space - 16) / journal_tag_bytes(journal);
    0.00 :   ffff800010353de0:       udiv    x1, x1, x0
         : 80               INIT_LIST_HEAD():
    0.00 :   ffff800010353de4:       str     x4, [x22, #216]
         : 37               jbd2_get_transaction():
         : 121              journal->j_commit_timer.expires = round_jiffies_up(transaction->t_expires);
    0.00 :   ffff800010353de8:       ldr     x0, [x22, #184]
         : 123              jbd2_descriptor_blocks_per_trans():
         : 83               return 1 + DIV_ROUND_UP(journal->j_max_transaction_buffers,
    0.00 :   ffff800010353dec:       add     w2, w2, w1
    0.00 :   ffff800010353df0:       sdiv    w1, w2, w1
         : 86               jbd2_get_transaction():
         : 112              atomic_set(&transaction->t_outstanding_credits,
    0.00 :   ffff800010353df4:       add     w1, w1, w6
         : 114              atomic_set():
         : 46               atomic_set_release(atomic_t *v, int i)
    0.00 :   ffff800010353df8:       str     w1, [x22, #156]
    0.00 :   ffff800010353dfc:       str     wzr, [x22, #160]
    0.00 :   ffff800010353e00:       str     wzr, [x22, #164]
         : 50               INIT_LIST_HEAD():
         : 35               WRITE_ONCE(list->next, list);
    0.00 :   ffff800010353e04:       str     x5, [x22, #80]
    0.00 :   ffff800010353e08:       str     x4, [x22, #208]
         : 38               jbd2_get_transaction():
         : 121              journal->j_commit_timer.expires = round_jiffies_up(transaction->t_expires);
    0.00 :   ffff800010353e0c:       bl      ffff80001010da78 <round_jiffies_up>
    0.00 :   ffff800010353e10:       str     x0, [x26, #1072]
         : 122              add_timer(&journal->j_commit_timer);
    0.00 :   ffff800010353e14:       add     x0, x26, #0x420
    0.00 :   ffff800010353e18:       bl      ffff80001010e0a0 <add_timer>
         : 124              J_ASSERT(journal->j_running_transaction == NULL);
    0.00 :   ffff800010353e1c:       ldr     x0, [x26, #112]
    0.00 :   ffff800010353e20:       cbnz    x0, ffff800010353f38 <start_this_handle+0x440>
         : 127              transaction->t_start = jiffies;
    0.00 :   ffff800010353e24:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
         : 125              journal->j_running_transaction = transaction;
    0.00 :   ffff800010353e28:       str     x22, [x26, #112]
         : 128              transaction->t_requested = 0;
    0.00 :   ffff800010353e2c:       str     xzr, [x22, #120]
         : 127              transaction->t_start = jiffies;
    0.00 :   ffff800010353e30:       ldr     x0, [x0, #2432]
    0.00 :   ffff800010353e34:       stp     xzr, x0, [x22, #104]
         : 130              start_this_handle():
         : 406              new_transaction = NULL;
    0.00 :   ffff800010353e38:       mov     x22, #0x0                       // #0
    0.00 :   ffff800010353e3c:       b       ffff800010353cb4 <start_this_handle+0x1bc>
         : 381              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353e40:       mov     x0, x19
    0.00 :   ffff800010353e44:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 384              jbd2_journal_free_transaction():
         : 60               if (unlikely(ZERO_OR_NULL_PTR(transaction)))
    0.00 :   ffff800010353e48:       cmp     x22, #0x10
    0.00 :   ffff800010353e4c:       b.ls    ffff800010353f3c <start_this_handle+0x444>  // b.plast
         : 62               kmem_cache_free(transaction_cache, transaction);
    0.00 :   ffff800010353e50:       adrp    x0, ffff800011f64000 <kernfs_pr_cont_buf+0xcd0>
    0.00 :   ffff800010353e54:       mov     x1, x22
         : 65               start_this_handle():
         : 383              return -EROFS;
    0.00 :   ffff800010353e58:       mov     w28, #0xffffffe2                // #-30
         : 385              jbd2_journal_free_transaction():
         : 62               kmem_cache_free(transaction_cache, transaction);
    0.00 :   ffff800010353e5c:       ldr     x0, [x0, #2040]
    0.00 :   ffff800010353e60:       bl      ffff8000102097f0 <kmem_cache_free>
    0.00 :   ffff800010353e64:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010353e68:       ldp     x23, x24, [sp, #48]
         : 67               start_this_handle():
         : 459              * Ensure that no allocations done while the transaction is open are
         : 460              * going to recurse back to the fs layer.
         : 461              */
         : 462              handle->saved_alloc_context = memalloc_nofs_save();
         : 463              return 0;
         : 464              }
    0.00 :   ffff800010353e6c:       mov     w0, w28
    0.00 :   ffff800010353e70:       ldr     x1, [sp, #104]
    0.00 :   ffff800010353e74:       ldr     x2, [sp, #152]
    0.00 :   ffff800010353e78:       ldr     x1, [x1]
    0.00 :   ffff800010353e7c:       eor     x1, x2, x1
    0.00 :   ffff800010353e80:       cbnz    x1, ffff800010353f4c <start_this_handle+0x454>
    0.00 :   ffff800010353e84:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010353e88:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010353e8c:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010353e90:       ldp     x29, x30, [sp], #160
    0.00 :   ffff800010353e94:       autiasp
    0.00 :   ffff800010353e98:       ret
         : 477              jbd2_journal_has_csum_v2or3():
    0.00 :   ffff800010353e9c:       brk     #0x800
         : 1699             jbd2_descriptor_blocks_per_trans():
         : 75               if (jbd2_journal_has_csum_v2or3(journal))
    0.00 :   ffff800010353ea0:       ldr     x0, [x26, #1312]
    0.00 :   ffff800010353ea4:       cbnz    x0, ffff800010353db0 <start_this_handle+0x2b8>
         : 74               tag_space -= 16;
    0.00 :   ffff800010353ea8:       sub     w27, w1, #0x1c
    0.00 :   ffff800010353eac:       b       ffff800010353db4 <start_this_handle+0x2bc>
         : 77               start_this_handle():
         : 430              sub_reserved_credits(journal, blocks);
    0.00 :   ffff800010353eb0:       ldr     w1, [sp, #96]
    0.00 :   ffff800010353eb4:       mov     x0, x26
    0.00 :   ffff800010353eb8:       bl      ffff800010353370 <sub_reserved_credits>
         : 431              handle->h_reserved = 0;
    0.00 :   ffff800010353ebc:       ldrb    w0, [x20, #36]
    0.00 :   ffff800010353ec0:       and     w0, w0, #0xfffffffb
    0.00 :   ffff800010353ec4:       strb    w0, [x20, #36]
    0.00 :   ffff800010353ec8:       b       ffff800010353be8 <start_this_handle+0xf0>
         : 436              __ll_sc_atomic_add():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff800010353ecc:       b       ffff8000103565d8 <jbd2_journal_begin_ordered_truncate+0x1f8>
         : 118              start_this_handle():
         : 443              atomic_inc(&transaction->t_handle_count);
    0.00 :   ffff800010353ed0:       add     x4, x27, #0xa4
         : 445              arch_static_branch_jump():
    0.00 :   ffff800010353ed4:       b       ffff800010353f30 <start_this_handle+0x438>
    0.00 :   ffff800010353ed8:       b       ffff800010353f30 <start_this_handle+0x438>
         : 40               __lse_atomic_add():
    0.00 :   ffff800010353edc:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010353ee0:       stadd   w0, [x4]
         : 28               start_this_handle():
         : 448              read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010353ee4:       mov     x0, x19
    0.00 :   ffff800010353ee8:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 451              get_current():
    0.00 :   ffff800010353eec:       mrs     x0, sp_el0
         : 20               start_this_handle():
         : 449              current->journal_info = handle;
    0.00 :   ffff800010353ef0:       str     x20, [x0, #1824]
         : 451              jbd2_journal_free_transaction():
         : 60               if (unlikely(ZERO_OR_NULL_PTR(transaction)))
    0.00 :   ffff800010353ef4:       cmp     x22, #0x10
    0.00 :   ffff800010353ef8:       b.ls    ffff800010353f0c <start_this_handle+0x414>  // b.plast
         : 62               kmem_cache_free(transaction_cache, transaction);
    0.00 :   ffff800010353efc:       adrp    x0, ffff800011f64000 <kernfs_pr_cont_buf+0xcd0>
    0.00 :   ffff800010353f00:       mov     x1, x22
    0.00 :   ffff800010353f04:       ldr     x0, [x0, #2040]
    0.00 :   ffff800010353f08:       bl      ffff8000102097f0 <kmem_cache_free>
         : 67               get_current():
    0.00 :   ffff800010353f0c:       mrs     x1, sp_el0
         : 20               memalloc_nofs_save():
         : 248              /**
         : 249              * memalloc_noio_restore - Ends the implicit GFP_NOIO scope.
         : 250              * @flags: Flags to restore.
         : 251              *
         : 252              * Ends the implicit GFP_NOIO scope started by memalloc_noio_save function.
         : 253              * Always make sure that the given flags is the return value from the
    0.00 :   ffff800010353f10:       ldr     w0, [x1, #36]
         : 249              * pairing memalloc_noio_save call.
    0.00 :   ffff800010353f14:       orr     w2, w0, #0x40000
    0.00 :   ffff800010353f18:       str     w2, [x1, #36]
         : 248              * Always make sure that the given flags is the return value from the
    0.00 :   ffff800010353f1c:       and     w0, w0, #0x40000
         : 250              start_this_handle():
         : 457              handle->saved_alloc_context = memalloc_nofs_save();
    0.00 :   ffff800010353f20:       str     w0, [x20, #52]
         : 458              return 0;
    0.00 :   ffff800010353f24:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010353f28:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010353f2c:       b       ffff800010353e6c <start_this_handle+0x374>
         : 462              __ll_sc_atomic_add():
    0.00 :   ffff800010353f30:       b       ffff8000103565f0 <jbd2_journal_begin_ordered_truncate+0x210>
    0.00 :   ffff800010353f34:       b       ffff800010353ee4 <start_this_handle+0x3ec>
         : 113              jbd2_get_transaction():
         : 124              J_ASSERT(journal->j_running_transaction == NULL);
    0.00 :   ffff800010353f38:       brk     #0x800
         : 126              start_this_handle():
         : 383              return -EROFS;
    0.00 :   ffff800010353f3c:       mov     w28, #0xffffffe2                // #-30
    0.00 :   ffff800010353f40:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010353f44:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010353f48:       b       ffff800010353e6c <start_this_handle+0x374>
    0.00 :   ffff800010353f4c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010353f50:       stp     x23, x24, [sp, #48]
         : 459              }
    0.00 :   ffff800010353f54:       bl      ffff800010e2b8c8 <__stack_chk_fail>
         : 343              printk(KERN_ERR "JBD2: %s wants too many credits "
    0.00 :   ffff800010353f58:       ldr     w2, [sp, #96]
    0.00 :   ffff800010353f5c:       mov     w3, w25
    0.00 :   ffff800010353f60:       adrp    x0, ffff800011439000 <kallsyms_token_index+0x2e7a0>
    0.00 :   ffff800010353f64:       add     x0, x0, #0xc28
         : 348              get_current():
    0.00 :   ffff800010353f68:       mrs     x1, sp_el0
         : 20               start_this_handle():
    0.00 :   ffff800010353f6c:       add     x1, x1, #0x608
    0.00 :   ffff800010353f70:       bl      ffff800010e19544 <printk>
         : 347              WARN_ON(1);
    0.00 :   ffff800010353f74:       brk     #0x800
         : 348              return -ENOSPC;
    0.00 :   ffff800010353f78:       mov     w28, #0xffffffe4                // #-28
    0.00 :   ffff800010353f7c:       b       ffff800010353e6c <start_this_handle+0x374>
 Percent |	Source code & Disassembly of perf for cycles (3 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      000000000021b754 <perf_mmap__read_head>:
         : 6      perf_mmap__read_head():
         : 82     {
         : 83     ring_buffer_write_tail(md->base, tail);
         : 84     }
         :
         : 86     u64 perf_mmap__read_head(struct perf_mmap *map)
         : 87     {
    0.00 :   21b754: stp     x29, x30, [sp, #-32]!
    0.00 :   21b758: adrp    x1, 34d000 <options+0x650>
    0.00 :   21b75c: mov     x29, sp
    0.00 :   21b760: ldr     x1, [x1, #2784]
         : 92     ring_buffer_read_head():
         : 59     * Architectures where smp_load_acquire() does not fallback to
         : 60     * READ_ONCE() + smp_mb() pair.
         : 61     */
         : 62     #if defined(__x86_64__) || defined(__aarch64__) || defined(__powerpc64__) || \
         : 63     defined(__ia64__) || defined(__sparc__) && defined(__arch64__)
         : 64     return smp_load_acquire(&base->data_head);
    0.00 :   21b764: ldr     x0, [x0]
         : 66     perf_mmap__read_head():
    0.00 :   21b768: ldr     x2, [x1]
    0.00 :   21b76c: str     x2, [sp, #24]
    0.00 :   21b770: mov     x2, #0x0                        // #0
         : 85     ring_buffer_read_head():
    0.00 :   21b774: add     x0, x0, #0x400
    0.00 :   21b778: ldar    x0, [x0]
         : 61     perf_mmap__read_head():
         : 84     return ring_buffer_read_head(map->base);
         : 85     }
    0.00 :   21b77c: adrp    x1, 34d000 <options+0x650>
  100.00 :   21b780: ldr     x1, [x1, #2784]
    0.00 :   21b784: ldr     x2, [sp, #24]
    0.00 :   21b788: ldr     x3, [x1]
    0.00 :   21b78c: subs    x2, x2, x3
    0.00 :   21b790: mov     x3, #0x0                        // #0
    0.00 :   21b794: b.ne    21b7a0 <perf_mmap__read_head+0x4c>  // b.any
    0.00 :   21b798: ldp     x29, x30, [sp], #32
    0.00 :   21b79c: ret
    0.00 :   21b7a0: bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001018b5c0 <account_page_dirtied>:
         : 6                account_page_dirtied():
         :
         : 2422             /*
         : 2423             * Helper function for set_page_dirty family.
         : 2424             *
         : 2425             * Caller must hold lock_page_memcg().
         : 2426             *
    0.00 :   ffff80001018b5c0:       paciasp
    0.00 :   ffff80001018b5c4:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff80001018b5c8:       mov     x29, sp
    0.00 :   ffff80001018b5cc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001018b5d0:       mov     x20, x0
         : 2422             * NOTE: This relies on being atomic wrt interrupts.
    0.00 :   ffff80001018b5d4:       ldr     x19, [x1]
         : 2424             inode_to_bdi():
         :
         : 141              static inline struct backing_dev_info *inode_to_bdi(struct inode *inode)
         : 142              {
         : 143              struct super_block *sb;
         :
         : 145              if (!inode)
    0.00 :   ffff80001018b5d8:       cbz     x19, ffff80001018b724 <account_page_dirtied+0x164>
         : 147              sb_is_blkdev_sb():
         : 2804             extern void __init vfs_caches_init_early(void);
         : 2805             extern void __init vfs_caches_init(void);
         :
         : 2807             extern struct kmem_cache *names_cachep;
         :
         : 2809             #define __getname()             kmem_cache_alloc(names_cachep, GFP_KERNEL)
   30.32 :   ffff80001018b5dc:       adrp    x1, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
         : 2811             inode_to_bdi():
         : 143              return &noop_backing_dev_info;
         :
         : 145              sb = inode->i_sb;
    0.00 :   ffff80001018b5e0:       ldr     x0, [x19, #40]
         : 145              #ifdef CONFIG_BLOCK
         : 146              if (sb_is_blkdev_sb(sb))
    0.00 :   ffff80001018b5e4:       ldr     x1, [x1, #368]
    0.00 :   ffff80001018b5e8:       cmp     x0, x1
    0.00 :   ffff80001018b5ec:       b.eq    ffff80001018b744 <account_page_dirtied+0x184>  // b.none
         : 148              return I_BDEV(inode)->bd_bdi;
         : 149              #endif
         : 150              return sb->s_bdi;
    0.00 :   ffff80001018b5f0:       ldr     x0, [x0, #208]
         : 152              mapping_can_writeback():
         : 161              long congestion_wait(int sync, long timeout);
         : 162              long wait_iff_congested(int sync, long timeout);
         :
         : 164              static inline bool mapping_can_writeback(struct address_space *mapping)
         : 165              {
         : 166              return inode_to_bdi(mapping->host)->capabilities & BDI_CAP_WRITEBACK;
   33.11 :   ffff80001018b5f4:       ldr     w0, [x0, #68]
         : 168              account_page_dirtied():
         : 2426             */
         : 2427             void account_page_dirtied(struct page *page, struct address_space *mapping)
         : 2428             {
         : 2429             struct inode *inode = mapping->host;
    0.00 :   ffff80001018b5f8:       tbz     w0, #0, ffff80001018b704 <account_page_dirtied+0x144>
         : 2431             inode_attach_wb():
         : 236              * memcg of @page or, if @page is NULL, %current.  May be called w/ or w/o
         : 237              * @inode->i_lock.
         : 238              */
         : 239              static inline void inode_attach_wb(struct inode *inode, struct page *page)
         : 240              {
         : 241              if (!inode->i_wb)
    0.00 :   ffff80001018b5fc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001018b600:       ldr     x21, [x19, #248]
    0.00 :   ffff80001018b604:       cbz     x21, ffff80001018b730 <account_page_dirtied+0x170>
         : 245              __inc_lruvec_page_state():
         :
         : 525              static inline void mod_lruvec_page_state(struct page *page,
         : 526              enum node_stat_item idx, int val)
         : 527              {
         : 528              mod_node_page_state(page_pgdat(page), idx, val);
         : 529              }
    0.00 :   ffff80001018b608:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001018b60c:       mov     x0, x20
    0.00 :   ffff80001018b610:       mov     w1, #0x14                       // #20
    0.00 :   ffff80001018b614:       bl      ffff800010222048 <__mod_lruvec_page_state>
         : 534              __add_wb_stat():
         : 70               percpu_counter_add_batch(&wb->stat[item], amount, WB_STAT_BATCH);
    0.00 :   ffff80001018b618:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
         : 72               account_page_dirtied():
         : 2433             trace_writeback_dirty_page(page, mapping);
         :
         : 2435             if (mapping_can_writeback(mapping)) {
         : 2436             struct bdi_writeback *wb;
         :
         : 2438             inode_attach_wb(inode, page);
    0.00 :   ffff80001018b61c:       mov     x0, x20
    0.00 :   ffff80001018b620:       mov     w1, #0x6                        // #6
    0.00 :   ffff80001018b624:       bl      ffff8000101a5e38 <__inc_zone_page_state>
         : 2434             wb = inode_to_wb(inode);
    0.00 :   ffff80001018b628:       mov     x0, x20
    0.00 :   ffff80001018b62c:       mov     w1, #0x1f                       // #31
    0.00 :   ffff80001018b630:       bl      ffff8000101a5f28 <__inc_node_page_state>
         : 2438             __add_wb_stat():
    0.00 :   ffff80001018b634:       mov     w19, #0x20                      // #32
    0.00 :   ffff80001018b638:       ldr     w3, [x22, #3120]
    0.00 :   ffff80001018b63c:       add     x0, x21, #0x60
    0.00 :   ffff80001018b640:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001018b644:       clz     w2, w3
    0.00 :   ffff80001018b648:       cmp     w3, #0x0
    0.00 :   ffff80001018b64c:       sub     w2, w19, w2
    0.00 :   ffff80001018b650:       lsl     w2, w2, #3
    0.00 :   ffff80001018b654:       csel    w2, w2, wzr, ne  // ne = any
    0.00 :   ffff80001018b658:       bl      ffff800010495ba0 <percpu_counter_add_batch>
    0.00 :   ffff80001018b65c:       ldr     w3, [x22, #3120]
    0.00 :   ffff80001018b660:       add     x0, x21, #0xb0
    0.00 :   ffff80001018b664:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001018b668:       clz     w2, w3
   36.57 :   ffff80001018b66c:       cmp     w3, #0x0
    0.00 :   ffff80001018b670:       sub     w2, w19, w2
    0.00 :   ffff80001018b674:       lsl     w2, w2, #3
    0.00 :   ffff80001018b678:       csel    w2, w2, wzr, ne  // ne = any
    0.00 :   ffff80001018b67c:       bl      ffff800010495ba0 <percpu_counter_add_batch>
         : 89               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001018b680:       mrs     x1, sp_el0
         : 26               task_io_account_write():
         : 27               return p->ioac.read_bytes >> 9;
         : 28               }
         :
         : 30               static inline void task_io_account_write(size_t bytes)
         : 31               {
         : 32               current->ioac.write_bytes += bytes;
    0.00 :   ffff80001018b684:       ldr     x2, [x1, #1936]
         : 34               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff80001018b688:       ldr     w3, [x1, #8]
         : 53               account_page_dirtied():
         :
         : 2439             __inc_lruvec_page_state(page, NR_FILE_DIRTY);
         : 2440             __inc_zone_page_state(page, NR_ZONE_WRITE_PENDING);
         : 2441             __inc_node_page_state(page, NR_DIRTIED);
    0.00 :   ffff80001018b68c:       ldr     w0, [x1, #2376]
         : 2443             task_io_account_write():
    0.00 :   ffff80001018b690:       add     x2, x2, #0x1, lsl #12
         : 28               __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff80001018b694:       add     w3, w3, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff80001018b698:       str     w3, [x1, #8]
         : 50               account_page_dirtied():
    0.00 :   ffff80001018b69c:       add     w0, w0, #0x1
         : 2439             task_io_account_write():
    0.00 :   ffff80001018b6a0:       str     x2, [x1, #1936]
         : 28               account_page_dirtied():
    0.00 :   ffff80001018b6a4:       str     w0, [x1, #2376]
         : 2439             inc_wb_stat(wb, WB_RECLAIMABLE);
    0.00 :   ffff80001018b6a8:       adrp    x0, ffff800011776000 <timer_bases+0x2380>
         : 2441             __percpu_add_case_32():
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
         : 131              PERCPU_OP(add, add, stadd)
    0.00 :   ffff80001018b6ac:       mov     w3, #0x1                        // #1
         : 133              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001018b6b0:       mrs     x2, tpidr_el1
         : 41               account_page_dirtied():
    0.00 :   ffff80001018b6b4:       add     x0, x0, #0xed0
         : 2440             __percpu_add_case_32():
         : 126              PERCPU_OP(add, add, stadd)
    0.00 :   ffff80001018b6b8:       add     x0, x0, x2
    0.00 :   ffff80001018b6bc:       ldxr    w5, [x0]
    0.00 :   ffff80001018b6c0:       add     w5, w5, w3
    0.00 :   ffff80001018b6c4:       stxr    w4, w5, [x0]
    0.00 :   ffff80001018b6c8:       cbnz    w4, ffff80001018b6bc <account_page_dirtied+0xfc>
         : 132              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001018b6cc:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001018b6d0:       sub     x0, x0, #0x1
    0.00 :   ffff80001018b6d4:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001018b6d8:       cbnz    x0, ffff80001018b714 <account_page_dirtied+0x154>
         : 80               account_page_dirtied():
    0.00 :   ffff80001018b6dc:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         : 2440             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff80001018b6e0:       nop
         : 28               page_memcg():
         : 453              * associated with a kmem page from being released.
         : 454              */
         : 455              static inline struct mem_cgroup *page_memcg(struct page *page)
         : 456              {
         : 457              if (PageMemcgKmem(page))
         : 458              return obj_cgroup_memcg(__page_objcg(page));
    0.00 :   ffff80001018b6e4:       ldr     x1, [x20, #56]
         : 460              PageMemcgKmem():
         : 539              */
         : 540              static inline bool PageMemcgKmem(struct page *page)
         : 541              {
         : 542              VM_BUG_ON_PAGE(page->memcg_data & MEMCG_DATA_OBJCGS, page);
         : 543              return page->memcg_data & MEMCG_DATA_KMEM;
         : 544              }
    0.00 :   ffff80001018b6e8:       and     x0, x1, #0xfffffffffffffffc
         : 546              page_memcg():
         : 453              return obj_cgroup_memcg(__page_objcg(page));
    0.00 :   ffff80001018b6ec:       tbz     w1, #1, ffff80001018b6f4 <account_page_dirtied+0x134>
         : 455              obj_cgroup_memcg():
         : 386              }
    0.00 :   ffff80001018b6f0:       ldr     x0, [x0, #16]
         : 388              mem_cgroup_track_foreign_dirty():
         : 1563             static inline void mem_cgroup_wb_stats(struct bdi_writeback *wb,
         : 1564             unsigned long *pfilepages,
         : 1565             unsigned long *pheadroom,
         : 1566             unsigned long *pdirty,
         : 1567             unsigned long *pwriteback)
         : 1568             {
    0.00 :   ffff80001018b6f4:       ldr     x1, [x21, #576]
    0.00 :   ffff80001018b6f8:       cmp     x0, x1
    0.00 :   ffff80001018b6fc:       b.ne    ffff80001018b754 <account_page_dirtied+0x194>  // b.any
    0.00 :   ffff80001018b700:       ldp     x21, x22, [sp, #32]
         : 1573             account_page_dirtied():
         : 2443             inc_wb_stat(wb, WB_DIRTIED);
         : 2444             task_io_account_write(PAGE_SIZE);
         : 2445             current->nr_dirtied++;
         : 2446             __this_cpu_inc(bdp_ratelimits);
    0.00 :   ffff80001018b704:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001018b708:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001018b70c:       autiasp
    0.00 :   ffff80001018b710:       ret
         : 2451             __preempt_count_dec_and_test():
    0.00 :   ffff80001018b714:       ldr     x0, [x1, #8]
    0.00 :   ffff80001018b718:       cbnz    x0, ffff80001018b6e0 <account_page_dirtied+0x120>
         : 75               account_page_dirtied():
         : 2439             inc_wb_stat(wb, WB_RECLAIMABLE);
    0.00 :   ffff80001018b71c:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff80001018b720:       b       ffff80001018b6e0 <account_page_dirtied+0x120>
         : 2442             inode_to_bdi():
         : 141              return &noop_backing_dev_info;
    0.00 :   ffff80001018b724:       adrp    x0, ffff800011f52000 <pmus_srcu+0x2c8>
    0.00 :   ffff80001018b728:       add     x0, x0, #0x7b8
    0.00 :   ffff80001018b72c:       b       ffff80001018b5f4 <account_page_dirtied+0x34>
         : 145              inode_attach_wb():
         : 237              __inode_attach_wb(inode, page);
    0.00 :   ffff80001018b730:       mov     x1, x20
    0.00 :   ffff80001018b734:       mov     x0, x19
    0.00 :   ffff80001018b738:       bl      ffff80001026bbc0 <__inode_attach_wb>
    0.00 :   ffff80001018b73c:       ldr     x21, [x19, #248]
    0.00 :   ffff80001018b740:       b       ffff80001018b608 <account_page_dirtied+0x48>
         : 243              inode_to_bdi():
         : 146              return I_BDEV(inode)->bd_bdi;
    0.00 :   ffff80001018b744:       mov     x0, x19
    0.00 :   ffff80001018b748:       bl      ffff800010280d50 <I_BDEV>
    0.00 :   ffff80001018b74c:       ldr     x0, [x0, #904]
    0.00 :   ffff80001018b750:       b       ffff80001018b5f4 <account_page_dirtied+0x34>
         : 151              mem_cgroup_track_foreign_dirty():
         : 1564             }
    0.00 :   ffff80001018b754:       mov     x1, x21
    0.00 :   ffff80001018b758:       mov     x0, x20
    0.00 :   ffff80001018b75c:       bl      ffff8000102252d0 <mem_cgroup_track_foreign_dirty_slowpath>
         : 1568             account_page_dirtied():
         : 2443             __this_cpu_inc(bdp_ratelimits);
    0.00 :   ffff80001018b760:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001018b764:       b       ffff80001018b704 <account_page_dirtied+0x144>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102fc580 <__es_remove_extent>:
         : 6                __es_remove_extent():
         : 1305             * enabled cancels pending reservations as needed. Returns 0 on success,
         : 1306             * error code on failure.
         : 1307             */
         : 1308             static int __es_remove_extent(struct inode *inode, ext4_lblk_t lblk,
         : 1309             ext4_lblk_t end, int *reserved)
         : 1310             {
    0.00 :   ffff8000102fc580:       paciasp
    0.00 :   ffff8000102fc584:       stp     x29, x30, [sp, #-256]!
    0.00 :   ffff8000102fc588:       mov     x29, sp
    0.00 :   ffff8000102fc58c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000102fc590:       mov     w20, w1
    0.00 :   ffff8000102fc594:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000102fc598:       mov     w21, w2
    0.00 :   ffff8000102fc59c:       mov     w22, #0x0                       // #0
    0.00 :   ffff8000102fc5a0:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000102fc5a4:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000102fc5a8:       adrp    x26, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000102fc5ac:       add     x4, x26, #0x948
    0.00 :   ffff8000102fc5b0:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000102fc5b4:       mov     x25, x0
    0.00 :   ffff8000102fc5b8:       ldr     x5, [x4]
    0.00 :   ffff8000102fc5bc:       str     x5, [sp, #248]
    0.00 :   ffff8000102fc5c0:       mov     x5, #0x0                        // #0
    0.00 :   ffff8000102fc5c4:       stp     x4, x3, [sp, #112]
         : 1316             ext4_fsblk_t block;
         : 1317             int err;
         : 1318             bool count_reserved = true;
         : 1319             struct rsvd_count rc;
         :
         : 1321             if (reserved == NULL || !test_opt(inode->i_sb, DELALLOC))
    0.00 :   ffff8000102fc5c8:       cbz     x3, ffff8000102fc5dc <__es_remove_extent+0x5c>
    0.00 :   ffff8000102fc5cc:       ldr     x0, [x0, #40]
    0.00 :   ffff8000102fc5d0:       ldr     x0, [x0, #880]
    0.00 :   ffff8000102fc5d4:       ldr     w22, [x0, #120]
    0.00 :   ffff8000102fc5d8:       ubfx    x22, x22, #27, #1
    0.00 :   ffff8000102fc5dc:       mov     x24, #0xbeef                    // #48879
    0.00 :   ffff8000102fc5e0:       add     w23, w21, #0x1
    0.00 :   ffff8000102fc5e4:       movk    x24, #0xdead, lsl #16
         : 1359             if (err) {
         : 1360             es->es_lblk = orig_es.es_lblk;
         : 1361             es->es_len = orig_es.es_len;
         : 1362             if ((err == -ENOMEM) &&
         : 1363             __es_shrink(EXT4_SB(inode->i_sb),
         : 1364             128, EXT4_I(inode)))
    0.00 :   ffff8000102fc5e8:       sub     x0, x25, #0x140
    0.00 :   ffff8000102fc5ec:       movk    x24, #0x7f, lsl #32
    0.00 :   ffff8000102fc5f0:       str     x0, [sp, #104]
         : 1321             es = __es_tree_search(&tree->root, lblk);
    0.00 :   ffff8000102fc5f4:       ldr     x0, [x25, #640]
    0.00 :   ffff8000102fc5f8:       mov     w1, w20
    0.00 :   ffff8000102fc5fc:       bl      ffff8000102fbd38 <__es_tree_search.isra.29>
    0.00 :   ffff8000102fc600:       mov     x19, x0
         : 1322             if (!es)
    0.00 :   ffff8000102fc604:       cbz     x0, ffff8000102fc934 <__es_remove_extent+0x3b4>
         : 1324             if (es->es_lblk > end)
    0.00 :   ffff8000102fc608:       ldr     w1, [x0, #24]
    0.00 :   ffff8000102fc60c:       cmp     w1, w21
    0.00 :   ffff8000102fc610:       b.hi    ffff8000102fc934 <__es_remove_extent+0x3b4>  // b.pmore
         : 1328             tree->cache_es = NULL;
    0.00 :   ffff8000102fc614:       str     xzr, [x25, #648]
         : 1329             if (count_reserved)
    0.00 :   ffff8000102fc618:       cbnz    w22, ffff8000102fc6f8 <__es_remove_extent+0x178>
    0.00 :   ffff8000102fc61c:       ldr     w1, [x19, #24]
         : 1333             orig_es.es_len = es->es_len;
    0.00 :   ffff8000102fc620:       ldr     w2, [x19, #28]
         : 1334             orig_es.es_pblk = es->es_pblk;
    0.00 :   ffff8000102fc624:       ldr     x0, [x19, #32]
         : 1333             orig_es.es_len = es->es_len;
    0.00 :   ffff8000102fc628:       stp     w1, w2, [sp, #192]
         : 1334             orig_es.es_pblk = es->es_pblk;
    0.00 :   ffff8000102fc62c:       str     x0, [sp, #200]
         : 1337             len2 = ext4_es_end(es) > end ? ext4_es_end(es) - end : 0;
    0.00 :   ffff8000102fc630:       ldp     w1, w2, [x19, #24]
         : 1336             len1 = lblk > es->es_lblk ? lblk - es->es_lblk : 0;
    0.00 :   ffff8000102fc634:       cmp     w1, w20
    0.00 :   ffff8000102fc638:       sub     w5, w20, w1
         : 1339             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc63c:       add     w0, w1, w2
         : 204              __es_remove_extent():
         : 1336             len1 = lblk > es->es_lblk ? lblk - es->es_lblk : 0;
    0.00 :   ffff8000102fc640:       csel    w26, w5, wzr, cc  // cc = lo, ul, last
         : 1338             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc644:       cmp     w1, w0
    0.00 :   ffff8000102fc648:       b.hi    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.pmore
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fc64c:       sub     w28, w0, #0x1
         : 205              __es_remove_extent():
         : 1337             len2 = ext4_es_end(es) > end ? ext4_es_end(es) - end : 0;
    0.00 :   ffff8000102fc650:       cmp     w21, w28
    0.00 :   ffff8000102fc654:       b.cs    ffff8000102fc7ac <__es_remove_extent+0x22c>  // b.hs, b.nlast
    0.00 :   ffff8000102fc658:       sub     w1, w28, w21
         : 1338             if (len1 > 0)
    0.00 :   ffff8000102fc65c:       cbnz    w26, ffff8000102fc72c <__es_remove_extent+0x1ac>
         : 1340             ext4_es_is_written():
         : 164              return (es->es_pblk & ES_TYPE_MASK) >> ES_SHIFT;
         : 165              }
         :
         : 167              static inline int ext4_es_is_written(struct extent_status *es)
         : 168              {
         : 169              return (ext4_es_type(es) & EXTENT_STATUS_WRITTEN) != 0;
   33.98 :   ffff8000102fc660:       ldr     x0, [x19, #32]
         : 171              __es_remove_extent():
         : 1365             goto retry;
         : 1366             goto out;
         : 1367             }
         : 1368             } else {
         : 1369             es->es_lblk = end + 1;
         : 1370             es->es_len = len2;
    0.00 :   ffff8000102fc664:       stp     w23, w1, [x19, #24]
         : 1366             if (ext4_es_is_written(es) ||
    0.00 :   ffff8000102fc668:       tst     x0, #0x1800000000000000
    0.00 :   ffff8000102fc66c:       b.eq    ffff8000102fc690 <__es_remove_extent+0x110>  // b.none
         : 1368             ext4_es_is_unwritten(es)) {
         : 1369             block = orig_es.es_pblk + orig_es.es_len - len2;
    0.00 :   ffff8000102fc670:       ldr     x3, [sp, #200]
         : 1371             ext4_es_store_pblock():
         : 223              static inline void ext4_es_store_pblock(struct extent_status *es,
         : 224              ext4_fsblk_t pb)
         : 225              {
         : 226              ext4_fsblk_t block;
         :
         : 228              block = (pb & ~ES_MASK) | (es->es_pblk & ES_MASK);
    0.00 :   ffff8000102fc674:       and     x2, x0, #0xf800000000000000
         : 230              __es_remove_extent():
    0.00 :   ffff8000102fc678:       ldr     w0, [sp, #196]
    0.00 :   ffff8000102fc67c:       add     x0, x0, x3
    0.00 :   ffff8000102fc680:       sub     x0, x0, w1, uxtw
         : 1371             ext4_es_store_pblock():
    0.00 :   ffff8000102fc684:       and     x0, x0, #0x7ffffffffffffff
    0.00 :   ffff8000102fc688:       orr     x0, x0, x2
         : 224              es->es_pblk = block;
    0.00 :   ffff8000102fc68c:       str     x0, [x19, #32]
         : 226              __es_remove_extent():
         : 1372             ext4_es_store_pblock(es, block);
         : 1373             }
         : 1374             }
         : 1375             if (count_reserved)
    0.00 :   ffff8000102fc690:       cbz     w22, ffff8000102fc934 <__es_remove_extent+0x3b4>
         : 1373             count_rsvd(inode, lblk, orig_es.es_len - len1 - len2,
    0.00 :   ffff8000102fc694:       ldr     w5, [sp, #196]
    0.00 :   ffff8000102fc698:       add     w2, w28, w26
    0.00 :   ffff8000102fc69c:       ldr     x0, [x25, #40]
    0.00 :   ffff8000102fc6a0:       add     w21, w21, w5
    0.00 :   ffff8000102fc6a4:       mov     w1, w20
    0.00 :   ffff8000102fc6a8:       add     x4, sp, #0x88
    0.00 :   ffff8000102fc6ac:       add     x3, sp, #0xa8
    0.00 :   ffff8000102fc6b0:       mov     w27, #0x0                       // #0
    0.00 :   ffff8000102fc6b4:       sub     w2, w21, w2
    0.00 :   ffff8000102fc6b8:       bl      ffff8000102fc420 <count_rsvd.isra.30>
    0.00 :   ffff8000102fc6bc:       nop
         :
         : 1422             if (count_reserved)
         : 1423             *reserved = get_rsvd(inode, end, es, &rc);
         : 1424             out:
         : 1425             return err;
         : 1426             }
    0.00 :   ffff8000102fc6c0:       ldr     x1, [sp, #112]
    0.00 :   ffff8000102fc6c4:       mov     w0, w27
    0.00 :   ffff8000102fc6c8:       ldr     x2, [sp, #248]
    0.00 :   ffff8000102fc6cc:       ldr     x1, [x1]
    0.00 :   ffff8000102fc6d0:       eor     x1, x2, x1
    0.00 :   ffff8000102fc6d4:       cbnz    x1, ffff8000102fcb44 <__es_remove_extent+0x5c4>
   34.89 :   ffff8000102fc6d8:       ldp     x19, x20, [sp, #16]
   31.13 :   ffff8000102fc6dc:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102fc6e0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000102fc6e4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000102fc6e8:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000102fc6ec:       ldp     x29, x30, [sp], #256
    0.00 :   ffff8000102fc6f0:       autiasp
    0.00 :   ffff8000102fc6f4:       ret
         : 1441             init_rsvd():
         : 1013             struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff8000102fc6f8:       ldr     x2, [x25, #40]
         : 1016             rc->ndelonly = 0;
    0.00 :   ffff8000102fc6fc:       str     wzr, [sp, #136]
    0.00 :   ffff8000102fc700:       ldr     w1, [x0, #24]
         : 1013             struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff8000102fc704:       ldr     x2, [x2, #880]
         : 1024             if (sbi->s_cluster_ratio > 1) {
    0.00 :   ffff8000102fc708:       ldr     w2, [x2, #80]
    0.00 :   ffff8000102fc70c:       cmp     w2, #0x1
    0.00 :   ffff8000102fc710:       b.ls    ffff8000102fc620 <__es_remove_extent+0xa0>  // b.plast
         : 1025             rc->first_do_lblk_found = false;
    0.00 :   ffff8000102fc714:       strb    wzr, [sp, #140]
         : 1026             if (lblk > es->es_lblk) {
    0.00 :   ffff8000102fc718:       cmp     w20, w1
    0.00 :   ffff8000102fc71c:       b.ls    ffff8000102fc93c <__es_remove_extent+0x3bc>  // b.plast
         : 1027             rc->left_es = es;
    0.00 :   ffff8000102fc720:       str     x0, [sp, #152]
         : 1034             rc->partial = false;
    0.00 :   ffff8000102fc724:       strb    wzr, [sp, #160]
    0.00 :   ffff8000102fc728:       b       ffff8000102fc61c <__es_remove_extent+0x9c>
         : 1037             __es_remove_extent():
         : 1339             es->es_len = len1;
    0.00 :   ffff8000102fc72c:       str     w26, [x19, #28]
         : 1344             newes.es_lblk = end + 1;
    0.00 :   ffff8000102fc730:       mov     x3, x24
         : 1345             newes.es_len = len2;
    0.00 :   ffff8000102fc734:       stp     w23, w1, [sp, #232]
         : 1347             ext4_es_is_written():
         : 164              return (ext4_es_type(es) & EXTENT_STATUS_WRITTEN) != 0;
    0.00 :   ffff8000102fc738:       ldr     x0, [sp, #200]
         : 166              __es_remove_extent():
         : 1347             if (ext4_es_is_written(&orig_es) ||
    0.00 :   ffff8000102fc73c:       tst     x0, #0x1800000000000000
    0.00 :   ffff8000102fc740:       b.eq    ffff8000102fc758 <__es_remove_extent+0x1d8>  // b.none
         : 1350             orig_es.es_len - len2;
    0.00 :   ffff8000102fc744:       ldr     w3, [sp, #196]
         : 1352             ext4_es_pblock():
         : 209              return es->es_pblk & ~ES_MASK;
    0.00 :   ffff8000102fc748:       and     x2, x0, #0x7ffffffffffffff
         : 211              __es_remove_extent():
         : 1349             block = ext4_es_pblock(&orig_es) +
    0.00 :   ffff8000102fc74c:       add     x3, x3, x2
    0.00 :   ffff8000102fc750:       sub     x3, x3, w1, uxtw
    0.00 :   ffff8000102fc754:       and     x3, x3, #0x7ffffffffffffff
         : 1353             ext4_es_store_pblock_status():
         :
         : 239              static inline void ext4_es_store_pblock_status(struct extent_status *es,
         : 240              ext4_fsblk_t pb,
         : 241              unsigned int status)
         : 242              {
         : 243              es->es_pblk = (((ext4_fsblk_t)status << ES_SHIFT) & ES_MASK) |
    0.00 :   ffff8000102fc758:       and     x0, x0, #0xf800000000000000
         : 245              __es_remove_extent():
         : 1353             err = __es_insert_extent(inode, &newes);
    0.00 :   ffff8000102fc75c:       add     x1, sp, #0xd0
         : 1355             ext4_es_store_pblock_status():
    0.00 :   ffff8000102fc760:       orr     x3, x0, x3
         : 239              __es_remove_extent():
    0.00 :   ffff8000102fc764:       mov     x0, x25
         : 1354             ext4_es_store_pblock_status():
    0.00 :   ffff8000102fc768:       str     x3, [sp, #240]
         : 239              __es_remove_extent():
    0.00 :   ffff8000102fc76c:       bl      ffff8000102fba18 <__es_insert_extent>
    0.00 :   ffff8000102fc770:       mov     w27, w0
         : 1354             if (err) {
    0.00 :   ffff8000102fc774:       cbz     w0, ffff8000102fc690 <__es_remove_extent+0x110>
         : 1357             if ((err == -ENOMEM) &&
    0.00 :   ffff8000102fc778:       cmn     w0, #0xc
         : 1355             es->es_lblk = orig_es.es_lblk;
    0.00 :   ffff8000102fc77c:       ldr     w0, [sp, #192]
    0.00 :   ffff8000102fc780:       str     w0, [x19, #24]
         : 1356             es->es_len = orig_es.es_len;
    0.00 :   ffff8000102fc784:       ldr     w0, [sp, #196]
    0.00 :   ffff8000102fc788:       str     w0, [x19, #28]
         : 1357             if ((err == -ENOMEM) &&
    0.00 :   ffff8000102fc78c:       b.ne    ffff8000102fc6c0 <__es_remove_extent+0x140>  // b.any
         : 1358             __es_shrink(EXT4_SB(inode->i_sb),
    0.00 :   ffff8000102fc790:       ldr     x0, [x25, #40]
    0.00 :   ffff8000102fc794:       mov     w1, #0x80                       // #128
    0.00 :   ffff8000102fc798:       ldr     x2, [sp, #104]
    0.00 :   ffff8000102fc79c:       ldr     x0, [x0, #880]
    0.00 :   ffff8000102fc7a0:       bl      ffff8000102fc1e8 <__es_shrink>
         : 1357             if ((err == -ENOMEM) &&
    0.00 :   ffff8000102fc7a4:       cbnz    w0, ffff8000102fc5f4 <__es_remove_extent+0x74>
    0.00 :   ffff8000102fc7a8:       b       ffff8000102fc6c0 <__es_remove_extent+0x140>
         : 1338             if (len1 > 0)
    0.00 :   ffff8000102fc7ac:       cbnz    w26, ffff8000102fc900 <__es_remove_extent+0x380>
         : 1389             while (es && ext4_es_end(es) <= end) {
    0.00 :   ffff8000102fc7b0:       mov     x20, x19
    0.00 :   ffff8000102fc7b4:       cmp     w21, w28
    0.00 :   ffff8000102fc7b8:       add     x23, x25, #0x280
    0.00 :   ffff8000102fc7bc:       b.cc    ffff8000102fc80c <__es_remove_extent+0x28c>  // b.lo, b.ul, b.last
         : 1390             if (count_reserved)
    0.00 :   ffff8000102fc7c0:       cbnz    w22, ffff8000102fc94c <__es_remove_extent+0x3cc>
         : 1392             node = rb_next(&es->rb_node);
    0.00 :   ffff8000102fc7c4:       mov     x0, x19
    0.00 :   ffff8000102fc7c8:       bl      ffff8000104b3d50 <rb_next>
         : 1393             rb_erase(&es->rb_node, &tree->root);
    0.00 :   ffff8000102fc7cc:       mov     x1, x23
         : 1392             node = rb_next(&es->rb_node);
    0.00 :   ffff8000102fc7d0:       mov     x20, x0
         : 1393             rb_erase(&es->rb_node, &tree->root);
    0.00 :   ffff8000102fc7d4:       mov     x0, x19
    0.00 :   ffff8000102fc7d8:       bl      ffff8000104b33a8 <rb_erase>
         : 1394             ext4_es_free_extent(inode, es);
    0.00 :   ffff8000102fc7dc:       mov     x1, x19
    0.00 :   ffff8000102fc7e0:       mov     x0, x25
    0.00 :   ffff8000102fc7e4:       bl      ffff8000102fb908 <ext4_es_free_extent>
         : 1395             if (!node) {
    0.00 :   ffff8000102fc7e8:       cbz     x20, ffff8000102fc984 <__es_remove_extent+0x404>
         : 1389             while (es && ext4_es_end(es) <= end) {
    0.00 :   ffff8000102fc7ec:       ldp     w1, w2, [x20, #24]
         : 1391             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc7f0:       add     w0, w1, w2
    0.00 :   ffff8000102fc7f4:       cmp     w1, w0
    0.00 :   ffff8000102fc7f8:       b.hi    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.pmore
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fc7fc:       sub     w0, w0, #0x1
    0.00 :   ffff8000102fc800:       mov     x19, x20
         : 206              __es_remove_extent():
         : 1389             while (es && ext4_es_end(es) <= end) {
    0.00 :   ffff8000102fc804:       cmp     w21, w0
    0.00 :   ffff8000102fc808:       b.cs    ffff8000102fc7c0 <__es_remove_extent+0x240>  // b.hs, b.nlast
         : 1402             if (es && es->es_lblk < end + 1) {
    0.00 :   ffff8000102fc80c:       add     w9, w21, #0x1
    0.00 :   ffff8000102fc810:       cmp     w9, w1
    0.00 :   ffff8000102fc814:       b.ls    ffff8000102fc85c <__es_remove_extent+0x2dc>  // b.plast
         : 1403             ext4_lblk_t orig_len = es->es_len;
    0.00 :   ffff8000102fc818:       ldr     w8, [x20, #28]
         : 1405             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc81c:       add     w0, w8, w1
    0.00 :   ffff8000102fc820:       cmp     w0, w1
    0.00 :   ffff8000102fc824:       b.cc    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.lo, b.ul, b.last
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fc828:       sub     w2, w0, #0x1
         : 205              __es_remove_extent():
         : 1405             len1 = ext4_es_end(es) - end;
    0.00 :   ffff8000102fc82c:       sub     w10, w2, w21
         : 1406             if (count_reserved)
    0.00 :   ffff8000102fc830:       cbnz    w22, ffff8000102fca34 <__es_remove_extent+0x4b4>
         : 1408             ext4_es_is_written():
         : 164              return (ext4_es_type(es) & EXTENT_STATUS_WRITTEN) != 0;
    0.00 :   ffff8000102fc834:       ldr     x1, [x20, #32]
         : 166              __es_remove_extent():
         : 1410             es->es_len = len1;
    0.00 :   ffff8000102fc838:       stp     w9, w10, [x20, #24]
         : 1411             if (ext4_es_is_written(es) || ext4_es_is_unwritten(es)) {
    0.00 :   ffff8000102fc83c:       tst     x1, #0x1800000000000000
    0.00 :   ffff8000102fc840:       b.eq    ffff8000102fc85c <__es_remove_extent+0x2dc>  // b.none
         : 1412             block = es->es_pblk + orig_len - len1;
    0.00 :   ffff8000102fc844:       add     x0, x1, w8, uxtw
         : 1414             ext4_es_store_pblock():
         : 223              block = (pb & ~ES_MASK) | (es->es_pblk & ES_MASK);
    0.00 :   ffff8000102fc848:       and     x1, x1, #0xf800000000000000
         : 225              __es_remove_extent():
    0.00 :   ffff8000102fc84c:       sub     x0, x0, w10, uxtw
         : 1413             ext4_es_store_pblock():
    0.00 :   ffff8000102fc850:       and     x0, x0, #0x7ffffffffffffff
    0.00 :   ffff8000102fc854:       orr     x0, x0, x1
         : 224              es->es_pblk = block;
    0.00 :   ffff8000102fc858:       str     x0, [x20, #32]
         : 226              __es_remove_extent():
         : 1417             if (count_reserved)
    0.00 :   ffff8000102fc85c:       cbz     w22, ffff8000102fc934 <__es_remove_extent+0x3b4>
         : 1419             get_rsvd():
         : 1179             struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff8000102fc860:       ldr     x1, [x25, #40]
    0.00 :   ffff8000102fc864:       ldr     w0, [sp, #136]
    0.00 :   ffff8000102fc868:       ldr     x19, [x1, #880]
         : 1187             if (sbi->s_cluster_ratio > 1) {
    0.00 :   ffff8000102fc86c:       ldr     w1, [x19, #80]
    0.00 :   ffff8000102fc870:       cmp     w1, #0x1
    0.00 :   ffff8000102fc874:       b.ls    ffff8000102fc8f0 <__es_remove_extent+0x370>  // b.plast
         : 1189             if (rc->partial)
    0.00 :   ffff8000102fc878:       ldrb    w2, [sp, #160]
    0.00 :   ffff8000102fc87c:       cbz     w2, ffff8000102fc888 <__es_remove_extent+0x308>
         : 1190             rc->ndelonly++;
    0.00 :   ffff8000102fc880:       add     w0, w0, #0x1
    0.00 :   ffff8000102fc884:       str     w0, [sp, #136]
         : 1192             if (rc->ndelonly == 0)
    0.00 :   ffff8000102fc888:       cbz     w0, ffff8000102fc8f0 <__es_remove_extent+0x370>
         : 1196             last_lclu = EXT4_B2C(sbi, rc->last_do_lblk);
    0.00 :   ffff8000102fc88c:       ldp     w3, w24, [sp, #144]
         : 1205             es = rc->left_es;
    0.00 :   ffff8000102fc890:       ldr     x0, [sp, #152]
         : 1195             first_lclu = EXT4_B2C(sbi, rc->first_do_lblk);
    0.00 :   ffff8000102fc894:       ldr     w2, [x19, #84]
    0.00 :   ffff8000102fc898:       lsr     w23, w3, w2
         : 1196             last_lclu = EXT4_B2C(sbi, rc->last_do_lblk);
    0.00 :   ffff8000102fc89c:       lsr     w24, w24, w2
         : 1206             while (es && ext4_es_end(es) >=
    0.00 :   ffff8000102fc8a0:       cbz     x0, ffff8000102fc9c0 <__es_remove_extent+0x440>
         : 1208             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc8a4:       ldp     w4, w2, [x0, #24]
    0.00 :   ffff8000102fc8a8:       add     w2, w4, w2
    0.00 :   ffff8000102fc8ac:       cmp     w2, w4
    0.00 :   ffff8000102fc8b0:       b.cc    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.lo, b.ul, b.last
         : 207              get_rsvd():
         : 1207             EXT4_LBLK_CMASK(sbi, rc->first_do_lblk)) {
    0.00 :   ffff8000102fc8b4:       neg     w1, w1
         : 1209             ext4_es_end():
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fc8b8:       sub     w2, w2, #0x1
         : 205              get_rsvd():
         : 1207             EXT4_LBLK_CMASK(sbi, rc->first_do_lblk)) {
    0.00 :   ffff8000102fc8bc:       and     w1, w1, w3
         : 1206             while (es && ext4_es_end(es) >=
    0.00 :   ffff8000102fc8c0:       cmp     w2, w1
    0.00 :   ffff8000102fc8c4:       b.cc    ffff8000102fc9c0 <__es_remove_extent+0x440>  // b.lo, b.ul, b.last
         : 1209             ext4_es_type():
         : 159              return (es->es_pblk & ES_TYPE_MASK) >> ES_SHIFT;
    0.00 :   ffff8000102fc8c8:       ldr     x1, [x0, #32]
    0.00 :   ffff8000102fc8cc:       lsr     x1, x1, #59
         : 162              ext4_es_is_delonly():
         : 189              return (ext4_es_is_delayed(es) && !ext4_es_is_unwritten(es));
    0.00 :   ffff8000102fc8d0:       tbz     w1, #2, ffff8000102fc98c <__es_remove_extent+0x40c>
    0.00 :   ffff8000102fc8d4:       tbnz    w1, #1, ffff8000102fc98c <__es_remove_extent+0x40c>
         : 192              get_rsvd():
         : 1209             rc->ndelonly--;
    0.00 :   ffff8000102fc8d8:       ldr     w0, [sp, #136]
    0.00 :   ffff8000102fc8dc:       sub     w0, w0, #0x1
    0.00 :   ffff8000102fc8e0:       str     w0, [sp, #136]
         : 1218             if (right_es && (!left_delonly || first_lclu != last_lclu)) {
    0.00 :   ffff8000102fc8e4:       cbz     x20, ffff8000102fca50 <__es_remove_extent+0x4d0>
    0.00 :   ffff8000102fc8e8:       cmp     w23, w24
    0.00 :   ffff8000102fc8ec:       b.ne    ffff8000102fc9c8 <__es_remove_extent+0x448>  // b.any
         : 1222             __es_remove_extent():
         : 1418             *reserved = get_rsvd(inode, end, es, &rc);
    0.00 :   ffff8000102fc8f0:       ldr     x1, [sp, #120]
         : 1319             err = 0;
    0.00 :   ffff8000102fc8f4:       mov     w27, #0x0                       // #0
         : 1418             *reserved = get_rsvd(inode, end, es, &rc);
    0.00 :   ffff8000102fc8f8:       str     w0, [x1]
         : 1420             return err;
    0.00 :   ffff8000102fc8fc:       b       ffff8000102fc6c0 <__es_remove_extent+0x140>
         : 1339             es->es_len = len1;
    0.00 :   ffff8000102fc900:       str     w26, [x19, #28]
         : 1379             if (count_reserved)
    0.00 :   ffff8000102fc904:       cbnz    w22, ffff8000102fc964 <__es_remove_extent+0x3e4>
         : 1382             node = rb_next(&es->rb_node);
    0.00 :   ffff8000102fc908:       mov     x0, x19
    0.00 :   ffff8000102fc90c:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000102fc910:       mov     x19, x0
         : 1383             if (node)
    0.00 :   ffff8000102fc914:       cbz     x0, ffff8000102fc984 <__es_remove_extent+0x404>
    0.00 :   ffff8000102fc918:       ldp     w1, w2, [x0, #24]
    0.00 :   ffff8000102fc91c:       add     w0, w2, w1
         : 1387             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc920:       cmp     w1, w0
    0.00 :   ffff8000102fc924:       b.hi    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.pmore
    0.00 :   ffff8000102fc928:       sub     w28, w0, #0x1
    0.00 :   ffff8000102fc92c:       b       ffff8000102fc7b0 <__es_remove_extent+0x230>
    0.00 :   ffff8000102fc930:       brk     #0x800
         : 208              __es_remove_extent():
         : 1319             err = 0;
    0.00 :   ffff8000102fc934:       mov     w27, #0x0                       // #0
    0.00 :   ffff8000102fc938:       b       ffff8000102fc6c0 <__es_remove_extent+0x140>
         : 1322             init_rsvd():
         : 1029             node = rb_prev(&es->rb_node);
    0.00 :   ffff8000102fc93c:       bl      ffff8000104b3dc0 <rb_prev>
         : 1030             rc->left_es = node ? rb_entry(node,
    0.00 :   ffff8000102fc940:       str     x0, [sp, #152]
         : 1034             rc->partial = false;
    0.00 :   ffff8000102fc944:       strb    wzr, [sp, #160]
    0.00 :   ffff8000102fc948:       b       ffff8000102fc61c <__es_remove_extent+0x9c>
         : 1037             __es_remove_extent():
         : 1391             count_rsvd(inode, es->es_lblk, es->es_len, es, &rc);
    0.00 :   ffff8000102fc94c:       ldr     x0, [x25, #40]
    0.00 :   ffff8000102fc950:       mov     w2, w2
    0.00 :   ffff8000102fc954:       add     x4, sp, #0x88
    0.00 :   ffff8000102fc958:       mov     x3, x19
    0.00 :   ffff8000102fc95c:       bl      ffff8000102fc420 <count_rsvd.isra.30>
    0.00 :   ffff8000102fc960:       b       ffff8000102fc7c4 <__es_remove_extent+0x244>
         : 1380             count_rsvd(inode, lblk, orig_es.es_len - len1,
    0.00 :   ffff8000102fc964:       ldr     x0, [x25, #40]
    0.00 :   ffff8000102fc968:       mov     w1, w20
    0.00 :   ffff8000102fc96c:       ldr     w2, [sp, #196]
    0.00 :   ffff8000102fc970:       add     x4, sp, #0x88
    0.00 :   ffff8000102fc974:       add     x3, sp, #0xa8
    0.00 :   ffff8000102fc978:       sub     w2, w2, w26
    0.00 :   ffff8000102fc97c:       bl      ffff8000102fc420 <count_rsvd.isra.30>
    0.00 :   ffff8000102fc980:       b       ffff8000102fc908 <__es_remove_extent+0x388>
    0.00 :   ffff8000102fc984:       mov     x20, #0x0                       // #0
    0.00 :   ffff8000102fc988:       b       ffff8000102fc85c <__es_remove_extent+0x2dc>
         : 1391             get_rsvd():
         : 1213             node = rb_prev(&es->rb_node);
    0.00 :   ffff8000102fc98c:       bl      ffff8000104b3dc0 <rb_prev>
         : 1214             if (!node)
    0.00 :   ffff8000102fc990:       cbz     x0, ffff8000102fc9c0 <__es_remove_extent+0x440>
         : 1216             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc994:       ldp     w2, w1, [x0, #24]
    0.00 :   ffff8000102fc998:       add     w1, w2, w1
    0.00 :   ffff8000102fc99c:       cmp     w2, w1
    0.00 :   ffff8000102fc9a0:       b.hi    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.pmore
         : 207              get_rsvd():
         : 1207             EXT4_LBLK_CMASK(sbi, rc->first_do_lblk)) {
    0.00 :   ffff8000102fc9a4:       ldr     w2, [x19, #80]
         : 1209             ext4_es_end():
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fc9a8:       sub     w1, w1, #0x1
         : 205              get_rsvd():
         : 1207             EXT4_LBLK_CMASK(sbi, rc->first_do_lblk)) {
    0.00 :   ffff8000102fc9ac:       ldr     w3, [sp, #144]
    0.00 :   ffff8000102fc9b0:       neg     w2, w2
    0.00 :   ffff8000102fc9b4:       and     w2, w2, w3
         : 1206             while (es && ext4_es_end(es) >=
    0.00 :   ffff8000102fc9b8:       cmp     w1, w2
    0.00 :   ffff8000102fc9bc:       b.cs    ffff8000102fc8c8 <__es_remove_extent+0x348>  // b.hs, b.nlast
         : 1218             if (right_es && (!left_delonly || first_lclu != last_lclu)) {
    0.00 :   ffff8000102fc9c0:       cbz     x20, ffff8000102fcb48 <__es_remove_extent+0x5c8>
    0.00 :   ffff8000102fc9c4:       mov     w22, #0x0                       // #0
         : 1221             ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fc9c8:       ldp     w1, w0, [x20, #24]
    0.00 :   ffff8000102fc9cc:       add     w0, w1, w0
    0.00 :   ffff8000102fc9d0:       cmp     w1, w0
    0.00 :   ffff8000102fc9d4:       b.hi    ffff8000102fc930 <__es_remove_extent+0x3b0>  // b.pmore
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fc9d8:       sub     w0, w0, #0x1
         : 205              get_rsvd():
         : 1219             if (end < ext4_es_end(right_es)) {
    0.00 :   ffff8000102fc9dc:       cmp     w21, w0
    0.00 :   ffff8000102fc9e0:       b.cs    ffff8000102fcb18 <__es_remove_extent+0x598>  // b.hs, b.nlast
         : 1226             while (es && es->es_lblk <=
    0.00 :   ffff8000102fc9e4:       cbz     x20, ffff8000102fcb28 <__es_remove_extent+0x5a8>
         : 1227             EXT4_LBLK_CFILL(sbi, rc->last_do_lblk)) {
    0.00 :   ffff8000102fc9e8:       ldr     w0, [x19, #80]
    0.00 :   ffff8000102fc9ec:       ldr     w2, [sp, #148]
    0.00 :   ffff8000102fc9f0:       sub     w0, w0, #0x1
         : 1226             while (es && es->es_lblk <=
    0.00 :   ffff8000102fc9f4:       ldr     w1, [x20, #24]
         : 1227             EXT4_LBLK_CFILL(sbi, rc->last_do_lblk)) {
    0.00 :   ffff8000102fc9f8:       orr     w0, w0, w2
         : 1226             while (es && es->es_lblk <=
    0.00 :   ffff8000102fc9fc:       cmp     w1, w0
    0.00 :   ffff8000102fca00:       b.hi    ffff8000102fcb28 <__es_remove_extent+0x5a8>  // b.pmore
         : 1229             ext4_es_type():
         : 159              return (es->es_pblk & ES_TYPE_MASK) >> ES_SHIFT;
    0.00 :   ffff8000102fca04:       ldr     x0, [x20, #32]
    0.00 :   ffff8000102fca08:       lsr     x0, x0, #59
         : 162              ext4_es_is_delonly():
         : 189              return (ext4_es_is_delayed(es) && !ext4_es_is_unwritten(es));
    0.00 :   ffff8000102fca0c:       tbz     w0, #2, ffff8000102fcb18 <__es_remove_extent+0x598>
    0.00 :   ffff8000102fca10:       tbnz    w0, #1, ffff8000102fcb18 <__es_remove_extent+0x598>
         : 192              get_rsvd():
         : 1229             rc->ndelonly--;
    0.00 :   ffff8000102fca14:       ldr     w0, [sp, #136]
         : 1250             if (first_lclu == last_lclu) {
    0.00 :   ffff8000102fca18:       cmp     w23, w24
         : 1229             rc->ndelonly--;
    0.00 :   ffff8000102fca1c:       sub     w0, w0, #0x1
    0.00 :   ffff8000102fca20:       str     w0, [sp, #136]
         : 1250             if (first_lclu == last_lclu) {
    0.00 :   ffff8000102fca24:       b.eq    ffff8000102fc8f0 <__es_remove_extent+0x370>  // b.none
         : 1257             first_lclu++;
    0.00 :   ffff8000102fca28:       add     w23, w23, w22
         : 1259             last_lclu--;
    0.00 :   ffff8000102fca2c:       sub     w24, w24, #0x1
    0.00 :   ffff8000102fca30:       b       ffff8000102fca5c <__es_remove_extent+0x4dc>
         : 1262             __es_remove_extent():
         : 1407             count_rsvd(inode, es->es_lblk, orig_len - len1,
    0.00 :   ffff8000102fca34:       ldr     x0, [x25, #40]
    0.00 :   ffff8000102fca38:       add     w3, w21, w8
    0.00 :   ffff8000102fca3c:       sub     w2, w3, w2
    0.00 :   ffff8000102fca40:       add     x4, sp, #0x88
    0.00 :   ffff8000102fca44:       mov     x3, x20
    0.00 :   ffff8000102fca48:       bl      ffff8000102fc420 <count_rsvd.isra.30>
    0.00 :   ffff8000102fca4c:       b       ffff8000102fc834 <__es_remove_extent+0x2b4>
         : 1415             get_rsvd():
         : 1250             if (first_lclu == last_lclu) {
    0.00 :   ffff8000102fca50:       cmp     w23, w24
    0.00 :   ffff8000102fca54:       b.eq    ffff8000102fc8f0 <__es_remove_extent+0x370>  // b.none
         : 1257             first_lclu++;
    0.00 :   ffff8000102fca58:       add     w23, w23, #0x1
         : 1260             if (first_lclu <= last_lclu)
    0.00 :   ffff8000102fca5c:       cmp     w24, w23
    0.00 :   ffff8000102fca60:       b.cc    ffff8000102fcb10 <__es_remove_extent+0x590>  // b.lo, b.ul, b.last
         : 1273             pr = __pr_tree_search(&tree->root, first_lclu);
    0.00 :   ffff8000102fca64:       ldr     x19, [x25, #704]
         : 1275             __pr_tree_search():
         : 1140             while (node) {
    0.00 :   ffff8000102fca68:       cbz     x19, ffff8000102fcb10 <__es_remove_extent+0x590>
         : 1142             if (lclu < pr->lclu)
    0.00 :   ffff8000102fca6c:       ldr     w1, [x19, #24]
    0.00 :   ffff8000102fca70:       cmp     w23, w1
    0.00 :   ffff8000102fca74:       b.cs    ffff8000102fca88 <__es_remove_extent+0x508>  // b.hs, b.nlast
         : 1143             node = node->rb_left;
    0.00 :   ffff8000102fca78:       ldr     x0, [x19, #16]
         : 1140             while (node) {
    0.00 :   ffff8000102fca7c:       cbz     x0, ffff8000102fca94 <__es_remove_extent+0x514>
    0.00 :   ffff8000102fca80:       mov     x19, x0
    0.00 :   ffff8000102fca84:       b       ffff8000102fca6c <__es_remove_extent+0x4ec>
         : 1144             else if (lclu > pr->lclu)
    0.00 :   ffff8000102fca88:       b.ls    ffff8000102fcab0 <__es_remove_extent+0x530>  // b.plast
         : 1145             node = node->rb_right;
    0.00 :   ffff8000102fca8c:       ldr     x0, [x19, #8]
    0.00 :   ffff8000102fca90:       b       ffff8000102fca7c <__es_remove_extent+0x4fc>
         : 1149             if (pr && lclu < pr->lclu)
    0.00 :   ffff8000102fca94:       cmp     w23, w1
    0.00 :   ffff8000102fca98:       b.cc    ffff8000102fcab0 <__es_remove_extent+0x530>  // b.lo, b.ul, b.last
         : 1151             if (pr && lclu > pr->lclu) {
    0.00 :   ffff8000102fca9c:       b.ls    ffff8000102fcb10 <__es_remove_extent+0x590>  // b.plast
         : 1152             node = rb_next(&pr->rb_node);
    0.00 :   ffff8000102fcaa0:       mov     x0, x19
    0.00 :   ffff8000102fcaa4:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000102fcaa8:       mov     x19, x0
         : 1154             rb_node) : NULL;
    0.00 :   ffff8000102fcaac:       cbz     x0, ffff8000102fcb10 <__es_remove_extent+0x590>
         : 1156             get_rsvd():
         : 1274             while (pr && pr->lclu <= last_lclu) {
    0.00 :   ffff8000102fcab0:       ldr     w0, [x19, #24]
    0.00 :   ffff8000102fcab4:       cmp     w24, w0
    0.00 :   ffff8000102fcab8:       b.cc    ffff8000102fcb10 <__es_remove_extent+0x590>  // b.lo, b.ul, b.last
    0.00 :   ffff8000102fcabc:       adrp    x20, ffff800011f64000 <kernfs_pr_cont_buf+0xcd0>
    0.00 :   ffff8000102fcac0:       add     x25, x25, #0x2c0
    0.00 :   ffff8000102fcac4:       add     x20, x20, #0x388
    0.00 :   ffff8000102fcac8:       b       ffff8000102fcadc <__es_remove_extent+0x55c>
    0.00 :   ffff8000102fcacc:       ldr     w0, [x21, #24]
    0.00 :   ffff8000102fcad0:       mov     x19, x21
    0.00 :   ffff8000102fcad4:       cmp     w24, w0
    0.00 :   ffff8000102fcad8:       b.cc    ffff8000102fcb10 <__es_remove_extent+0x590>  // b.lo, b.ul, b.last
         : 1275             rc->ndelonly--;
    0.00 :   ffff8000102fcadc:       ldr     w1, [sp, #136]
         : 1276             node = rb_next(&pr->rb_node);
    0.00 :   ffff8000102fcae0:       mov     x0, x19
         : 1275             rc->ndelonly--;
    0.00 :   ffff8000102fcae4:       sub     w1, w1, #0x1
    0.00 :   ffff8000102fcae8:       str     w1, [sp, #136]
         : 1276             node = rb_next(&pr->rb_node);
    0.00 :   ffff8000102fcaec:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000102fcaf0:       mov     x21, x0
         : 1277             rb_erase(&pr->rb_node, &tree->root);
    0.00 :   ffff8000102fcaf4:       mov     x1, x25
    0.00 :   ffff8000102fcaf8:       mov     x0, x19
    0.00 :   ffff8000102fcafc:       bl      ffff8000104b33a8 <rb_erase>
         : 1278             kmem_cache_free(ext4_pending_cachep, pr);
    0.00 :   ffff8000102fcb00:       ldr     x0, [x20]
    0.00 :   ffff8000102fcb04:       mov     x1, x19
    0.00 :   ffff8000102fcb08:       bl      ffff8000102097f0 <kmem_cache_free>
         : 1279             if (!node)
    0.00 :   ffff8000102fcb0c:       cbnz    x21, ffff8000102fcacc <__es_remove_extent+0x54c>
    0.00 :   ffff8000102fcb10:       ldr     w0, [sp, #136]
    0.00 :   ffff8000102fcb14:       b       ffff8000102fc8f0 <__es_remove_extent+0x370>
         : 1233             node = rb_next(&es->rb_node);
    0.00 :   ffff8000102fcb18:       mov     x0, x20
    0.00 :   ffff8000102fcb1c:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000102fcb20:       mov     x20, x0
         : 1234             if (!node)
    0.00 :   ffff8000102fcb24:       cbnz    x0, ffff8000102fc9e8 <__es_remove_extent+0x468>
         : 1250             if (first_lclu == last_lclu) {
    0.00 :   ffff8000102fcb28:       cmp     w23, w24
    0.00 :   ffff8000102fcb2c:       b.eq    ffff8000102fcb38 <__es_remove_extent+0x5b8>  // b.none
         : 1256             if (left_delonly)
    0.00 :   ffff8000102fcb30:       cbz     w22, ffff8000102fca5c <__es_remove_extent+0x4dc>
    0.00 :   ffff8000102fcb34:       b       ffff8000102fca58 <__es_remove_extent+0x4d8>
         : 1251             if (left_delonly | right_delonly)
    0.00 :   ffff8000102fcb38:       cbz     w22, ffff8000102fca64 <__es_remove_extent+0x4e4>
    0.00 :   ffff8000102fcb3c:       ldr     w0, [sp, #136]
    0.00 :   ffff8000102fcb40:       b       ffff8000102fc8f0 <__es_remove_extent+0x370>
         : 1255             __es_remove_extent():
         : 1421             }
    0.00 :   ffff8000102fcb44:       bl      ffff800010e2b8c8 <__stack_chk_fail>
         : 1423             get_rsvd():
         : 1250             if (first_lclu == last_lclu) {
    0.00 :   ffff8000102fcb48:       cmp     w23, w24
    0.00 :   ffff8000102fcb4c:       b.ne    ffff8000102fca5c <__es_remove_extent+0x4dc>  // b.any
    0.00 :   ffff8000102fcb50:       b       ffff8000102fca64 <__es_remove_extent+0x4e4>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100fe868 <force_qs_rnp>:
         : 6                force_qs_rnp():
         : 2664             /* Nothing to do here, so just drop the lock. */
         : 2665             raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
         : 2666             }
         : 2667             }
         : 2668             }
         :
    0.00 :   ffff8000100fe868:       paciasp
         : 2673             */
         : 2674             void rcu_force_quiescent_state(void)
         : 2675             {
         : 2676             unsigned long flags;
         : 2677             bool ret;
         : 2678             struct rcu_node *rnp;
    0.00 :   ffff8000100fe86c:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
         :
    0.00 :   ffff8000100fe870:       stp     x29, x30, [sp, #-112]!
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe874:       adrp    x2, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100fe878:       add     x2, x2, #0xb50
         :
    0.00 :   ffff8000100fe87c:       mov     x29, sp
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe880:       ldr     w1, [x1, #2896]
         :
    0.00 :   ffff8000100fe884:       stp     x25, x26, [sp, #64]
         : 2671             unsigned long flags;
    0.00 :   ffff8000100fe888:       adrp    x26, ffff800011cb3000 <_rs.29273+0x20>
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe88c:       sub     w1, w1, #0x1
         : 2671             unsigned long flags;
    0.00 :   ffff8000100fe890:       add     x4, x26, #0xa80
         :
    0.00 :   ffff8000100fe894:       stp     x23, x24, [sp, #48]
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe898:       add     x1, x4, w1, sxtw #3
         : 2671             unsigned long flags;
    0.00 :   ffff8000100fe89c:       add     x23, x4, #0x2, lsl #12
         :
    0.00 :   ffff8000100fe8a0:       stp     x27, x28, [sp, #80]
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe8a4:       ldrsw   x2, [x2, #4]
         : 2671             unsigned long flags;
    0.00 :   ffff8000100fe8a8:       ldrb    w3, [x23, #845]
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe8ac:       ldr     x28, [x1, #8704]
         : 2671             unsigned long flags;
    0.00 :   ffff8000100fe8b0:       str     x4, [sp, #104]
    0.00 :   ffff8000100fe8b4:       strb    w3, [x23, #844]
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe8b8:       add     x2, x4, x2, lsl #9
         : 2672             bool ret;
    0.00 :   ffff8000100fe8bc:       strb    wzr, [x23, #845]
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe8c0:       cmp     x28, x2
    0.00 :   ffff8000100fe8c4:       b.cs    ffff8000100fea50 <force_qs_rnp+0x1e8>  // b.hs, b.nlast
         : 2692             /* rnp_old == rcu_get_root(), rnp == NULL. */
         :
         : 2694             /* Reached the root of the rcu_node tree, acquire lock. */
         : 2695             raw_spin_lock_irqsave_rcu_node(rnp_old, flags);
         : 2696             raw_spin_unlock(&rnp_old->fqslock);
         : 2697             if (READ_ONCE(rcu_state.gp_flags) & RCU_GP_FLAG_FQS) {
    0.00 :   ffff8000100fe8c8:       mov     w24, #0x1                       // #1
    0.00 :   ffff8000100fe8cc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100fe8d0:       mov     x20, x0
    0.00 :   ffff8000100fe8d4:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100fe8d8:       adrp    x22, ffff80001177a000 <runqueues+0x3c0>
    0.00 :   ffff8000100fe8dc:       adrp    x21, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100fe8e0:       add     x22, x22, #0x900
    0.00 :   ffff8000100fe8e4:       add     x21, x21, #0x760
    0.00 :   ffff8000100fe8e8:       b       ffff8000100fe91c <force_qs_rnp+0xb4>
         : 2707             rcu_preempt_blocked_readers_cgp():
         : 410              EXPORT_SYMBOL_GPL(__rcu_read_lock);
         :
         : 412              /*
         : 413              * Preemptible RCU implementation for rcu_read_unlock().
         : 414              * Decrement ->rcu_read_lock_nesting.  If the result is zero (outermost
         : 415              * rcu_read_unlock()) and ->rcu_read_unlock_special is non-zero, then
    0.00 :   ffff8000100fe8ec:       ldr     x0, [x28, #160]
         : 417              rcu_initiate_boost():
         : 1285             {
         : 1286             }
         :
         : 1288             /*
         : 1289             * Do the idle-entry grace-period work, which, because CONFIG_RCU_FAST_NO_HZ=n,
         : 1290             * is nothing.
    0.00 :   ffff8000100fe8f0:       mov     x1, x25
         : 1292             force_qs_rnp():
         : 2704             rcu_gp_kthread_wake();
         : 2705             }
         : 2706             EXPORT_SYMBOL_GPL(rcu_force_quiescent_state);
         :
         : 2708             // Workqueue handler for an RCU reader for kernels enforcing struct RCU
         : 2709             // grace periods.
    0.00 :   ffff8000100fe8f4:       mov     x0, x28
    0.00 :   ffff8000100fe8f8:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fe8fc:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100fe900:       add     x0, x0, #0xb50
    0.00 :   ffff8000100fe904:       ldr     x1, [sp, #104]
    0.00 :   ffff8000100fe908:       add     x28, x28, #0x200
    0.00 :   ffff8000100fe90c:       ldrsw   x0, [x0, #4]
    0.00 :   ffff8000100fe910:       add     x0, x1, x0, lsl #9
    0.00 :   ffff8000100fe914:       cmp     x28, x0
    0.00 :   ffff8000100fe918:       b.cs    ffff8000100fea48 <force_qs_rnp+0x1e0>  // b.hs, b.nlast
         : 2682             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100fe91c:       mrs     x0, sp_el0
         : 26               force_qs_rnp():
         : 2674             struct rcu_node *rnp_old = NULL;
    0.00 :   ffff8000100fe920:       ldrb    w1, [x0, #776]
    0.00 :   ffff8000100fe924:       tst     w1, #0xff
    0.00 :   ffff8000100fe928:       b.eq    ffff8000100fe930 <force_qs_rnp+0xc8>  // b.none
    0.00 :   ffff8000100fe92c:       strb    wzr, [x0, #776]
         : 2676             /* Funnel through hierarchy to reduce memory contention. */
    0.00 :   ffff8000100fe930:       mov     x0, x28
    0.00 :   ffff8000100fe934:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff8000100fe938:       mov     x25, x0
         : 2677             rnp = __this_cpu_read(rcu_data.mynode);
    0.00 :   ffff8000100fe93c:       ldrb    w1, [x23, #845]
    0.00 :   ffff8000100fe940:       ldr     x0, [x28, #96]
    0.00 :   ffff8000100fe944:       cmp     x0, #0x0
    0.00 :   ffff8000100fe948:       cset    w0, ne  // ne = any
    0.00 :   ffff8000100fe94c:       orr     w0, w0, w1
    0.00 :   ffff8000100fe950:       strb    w0, [x23, #845]
         : 2678             for (; rnp != NULL; rnp = rnp->parent) {
    0.00 :   ffff8000100fe954:       ldr     x1, [x28, #32]
    0.00 :   ffff8000100fe958:       cbz     x1, ffff8000100fe8ec <force_qs_rnp+0x84>
         : 2692             if (READ_ONCE(rcu_state.gp_flags) & RCU_GP_FLAG_FQS) {
    0.00 :   ffff8000100fe95c:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100fe960:       add     x0, x0, #0xb50
    0.00 :   ffff8000100fe964:       ldrb    w2, [x28, #129]
    0.00 :   ffff8000100fe968:       ldr     w0, [x0]
    0.00 :   ffff8000100fe96c:       sub     w0, w0, #0x1
    0.00 :   ffff8000100fe970:       cmp     w2, w0
    0.00 :   ffff8000100fe974:       b.ne    ffff8000100fea78 <force_qs_rnp+0x210>  // b.any
    0.00 :   ffff8000100fe978:       ldr     w0, [x28, #120]
         : 2701             __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff8000100fe97c:       rbit    x2, x1
    0.00 :   ffff8000100fe980:       clz     x2, x2
         : 21               force_qs_rnp():
    0.00 :   ffff8000100fe984:       ldr     w1, [x28, #124]
    0.00 :   ffff8000100fe988:       add     w26, w0, w2
    0.00 :   ffff8000100fe98c:       cmp     w26, w1
    0.00 :   ffff8000100fe990:       b.gt    ffff8000100fea70 <force_qs_rnp+0x208>
         :
    0.00 :   ffff8000100fe994:       mov     x19, #0x0                       // #0
         : 2693             raw_spin_unlock_irqrestore_rcu_node(rnp_old, flags);
    0.00 :   ffff8000100fe998:       ldr     x0, [x21, w26, sxtw #3]
    0.00 :   ffff8000100fe99c:       mov     x1, x22
    0.00 :   ffff8000100fe9a0:       add     x27, x1, x0
         : 2694             return;  /* Someone beat us to it. */
    0.00 :   ffff8000100fe9a4:       mov     x0, x27
    0.00 :   ffff8000100fe9a8:       blr     x20
    0.00 :   ffff8000100fe9ac:       cbz     w0, ffff8000100fe9c0 <force_qs_rnp+0x158>
         : 2695             }
    0.00 :   ffff8000100fe9b0:       ldr     x0, [x27, #32]
         : 2697             rcu_disable_urgency_upon_qs():
         : 1144             barrier();
    0.00 :   ffff8000100fe9b4:       strb    wzr, [x27, #293]
         : 1145             cpu = task_cpu(t);
    0.00 :   ffff8000100fe9b8:       strb    wzr, [x27, #292]
         : 1147             force_qs_rnp():
         : 2695             }
    0.00 :   ffff8000100fe9bc:       orr     x19, x19, x0
         : 2692             if (READ_ONCE(rcu_state.gp_flags) & RCU_GP_FLAG_FQS) {
    0.00 :   ffff8000100fe9c0:       ldr     w3, [x28, #120]
    0.00 :   ffff8000100fe9c4:       sub     w0, w24, w3
    0.00 :   ffff8000100fe9c8:       add     w0, w0, w26
    0.00 :   ffff8000100fe9cc:       sxtw    x0, w0
         : 2697             find_next_bit():
         : 29               unsigned long offset)
         : 30               {
         : 31               if (small_const_nbits(size)) {
         : 32               unsigned long val;
         :
         : 34               if (unlikely(offset >= size))
  100.00 :   ffff8000100fe9d0:       cmp     x0, #0x3f
    0.00 :   ffff8000100fe9d4:       b.hi    ffff8000100fea68 <force_qs_rnp+0x200>  // b.pmore
         : 32               return size;
         :
         : 34               val = *addr & GENMASK(size - 1, offset);
    0.00 :   ffff8000100fe9d8:       ldr     x2, [x28, #32]
    0.00 :   ffff8000100fe9dc:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000100fe9e0:       lsl     x1, x1, x0
    0.00 :   ffff8000100fe9e4:       neg     x1, x1
    0.00 :   ffff8000100fe9e8:       ands    x1, x1, x2
         : 33               return val ? __ffs(val) : size;
    0.00 :   ffff8000100fe9ec:       rbit    x0, x1
    0.00 :   ffff8000100fe9f0:       mov     w1, #0x40                       // #64
    0.00 :   ffff8000100fe9f4:       clz     x0, x0
    0.00 :   ffff8000100fe9f8:       csel    w0, w1, w0, eq  // eq = none
         : 38               force_qs_rnp():
    0.00 :   ffff8000100fe9fc:       ldr     w1, [x28, #124]
    0.00 :   ffff8000100fea00:       add     w26, w3, w0
    0.00 :   ffff8000100fea04:       cmp     w1, w26
    0.00 :   ffff8000100fea08:       b.ge    ffff8000100fe998 <force_qs_rnp+0x130>  // b.tcont
         : 2699             rcu_gp_kthread_wake();
    0.00 :   ffff8000100fea0c:       cbz     x19, ffff8000100fea70 <force_qs_rnp+0x208>
         : 2701             EXPORT_SYMBOL_GPL(rcu_force_quiescent_state);
    0.00 :   ffff8000100fea10:       ldr     x2, [x28, #8]
    0.00 :   ffff8000100fea14:       mov     x1, x28
    0.00 :   ffff8000100fea18:       mov     x0, x19
    0.00 :   ffff8000100fea1c:       mov     x3, x25
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fea20:       add     x28, x28, #0x200
         : 2701             EXPORT_SYMBOL_GPL(rcu_force_quiescent_state);
    0.00 :   ffff8000100fea24:       bl      ffff8000100fdc30 <rcu_report_qs_rnp>
         : 2673             struct rcu_node *rnp;
    0.00 :   ffff8000100fea28:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100fea2c:       add     x0, x0, #0xb50
    0.00 :   ffff8000100fea30:       ldr     x1, [sp, #104]
    0.00 :   ffff8000100fea34:       ldrsw   x0, [x0, #4]
    0.00 :   ffff8000100fea38:       add     x0, x1, x0, lsl #9
    0.00 :   ffff8000100fea3c:       cmp     x28, x0
    0.00 :   ffff8000100fea40:       b.cc    ffff8000100fe91c <force_qs_rnp+0xb4>  // b.lo, b.ul, b.last
    0.00 :   ffff8000100fea44:       nop
    0.00 :   ffff8000100fea48:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100fea4c:       ldp     x21, x22, [sp, #32]
         : 2707             static void strict_work_handler(struct work_struct *work)
         : 2708             {
         : 2709             rcu_read_lock();
    0.00 :   ffff8000100fea50:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100fea54:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100fea58:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100fea5c:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000100fea60:       autiasp
    0.00 :   ffff8000100fea64:       ret
         : 2716             find_next_bit():
         : 29               if (unlikely(offset >= size))
    0.00 :   ffff8000100fea68:       mov     w0, #0x40                       // #64
    0.00 :   ffff8000100fea6c:       b       ffff8000100fe9fc <force_qs_rnp+0x194>
         : 32               force_qs_rnp():
         : 2704             // grace periods.
    0.00 :   ffff8000100fea70:       mov     x1, x25
    0.00 :   ffff8000100fea74:       b       ffff8000100fe8f4 <force_qs_rnp+0x8c>
         : 2692             if (READ_ONCE(rcu_state.gp_flags) & RCU_GP_FLAG_FQS) {
    0.00 :   ffff8000100fea78:       brk     #0x800
    0.00 :   ffff8000100fea7c:       ldr     x1, [x28, #32]
         : 2695             find_next_bit():
         : 33               return val ? __ffs(val) : size;
    0.00 :   ffff8000100fea80:       mov     w2, #0x40                       // #64
         : 35               force_qs_rnp():
    0.00 :   ffff8000100fea84:       ldr     w0, [x28, #120]
         : 2693             find_next_bit():
    0.00 :   ffff8000100fea88:       cbz     x1, ffff8000100fe984 <force_qs_rnp+0x11c>
    0.00 :   ffff8000100fea8c:       b       ffff8000100fe97c <force_qs_rnp+0x114>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bc248 <find_idlest_group>:
         : 6                find_idlest_group():
         : 8838             if (idlest_sgs->idle_cpus == sgs->idle_cpus &&
         : 8839             idlest_sgs->group_util <= sgs->group_util)
         : 8840             return false;
         :
         : 8842             break;
         : 8843             }
    0.00 :   ffff8000100bc248:       paciasp
    0.00 :   ffff8000100bc24c:       stp     x29, x30, [sp, #-336]!
         : 8846             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100bc250:       cmp     w2, #0x0
         : 113              find_idlest_group():
    0.00 :   ffff8000100bc254:       mov     x29, sp
    0.00 :   ffff8000100bc258:       stp     x23, x24, [sp, #48]
         : 8840             test_bit():
    0.00 :   ffff8000100bc25c:       add     w24, w2, #0x3f
    0.00 :   ffff8000100bc260:       csel    w24, w24, w2, lt  // lt = tstop
         : 108              find_idlest_group():
    0.00 :   ffff8000100bc264:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bc268:       mov     x22, x0
         : 8840             test_bit():
    0.00 :   ffff8000100bc26c:       asr     w24, w24, #6
         : 107              find_idlest_group():
    0.00 :   ffff8000100bc270:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bc274:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100bc278:       add     x0, x0, #0x948
    0.00 :   ffff8000100bc27c:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bc280:       adrp    x23, ffff800011c29000 <page_wait_table+0x14c0>
         : 8843             update_sg_wakeup_stats():
         : 8727             return 0;
    0.00 :   ffff8000100bc284:       adrp    x4, ffff800011779000 <cpu_armpmu>
         : 8729             find_idlest_group():
         : 8838             }
    0.00 :   ffff8000100bc288:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000100bc28c:       mov     x28, x1
    0.00 :   ffff8000100bc290:       add     x23, x23, #0xc30
    0.00 :   ffff8000100bc294:       ldr     x1, [x0]
    0.00 :   ffff8000100bc298:       str     x1, [sp, #328]
    0.00 :   ffff8000100bc29c:       mov     x1, #0x0                        // #0
    0.00 :   ffff8000100bc2a0:       stp     xzr, x0, [sp, #144]
         : 8846             test_bit():
    0.00 :   ffff8000100bc2a4:       sbfiz   x0, x24, #3, #32
         : 107              find_idlest_group():
         :
    0.00 :   ffff8000100bc2a8:       ldr     x19, [x22, #16]
         : 8841             update_sg_wakeup_stats():
         : 8727             return 0;
    0.00 :   ffff8000100bc2ac:       add     x27, x4, #0xc40
         : 8729             test_bit():
    0.00 :   ffff8000100bc2b0:       str     x0, [sp, #104]
         : 107              find_idlest_group():
         : 8843             return true;
         : 8844             }
         :
         : 8846             /*
    0.00 :   ffff8000100bc2b4:       mov     w0, #0x5                        // #5
         : 8838             }
    0.00 :   ffff8000100bc2b8:       str     w2, [sp, #100]
         :
    0.00 :   ffff8000100bc2bc:       stp     xzr, xzr, [sp, #112]
         : 8843             /*
    0.00 :   ffff8000100bc2c0:       str     w0, [sp, #136]
    0.00 :   ffff8000100bc2c4:       mov     x0, #0xffffffff                 // #4294967295
    0.00 :   ffff8000100bc2c8:       str     x0, [sp, #128]
    0.00 :   ffff8000100bc2cc:       str     wzr, [sp, #140]
         : 8848             bitmap_intersects():
         : 368              const unsigned long *src2, unsigned int nbits)
         : 369              {
         : 370              if (small_const_nbits(nbits))
         : 371              return ((*src1 & *src2) & BITMAP_LAST_WORD_MASK(nbits)) != 0;
         : 372              else
         : 373              return __bitmap_intersects(src1, src2, nbits);
    0.00 :   ffff8000100bc2d0:       ldr     x1, [x28, #680]
         : 375              cpumask_intersects():
         : 498              * @src2p: the second input
         : 499              */
         : 500              static inline bool cpumask_intersects(const struct cpumask *src1p,
         : 501              const struct cpumask *src2p)
         : 502              {
         : 503              return bitmap_intersects(cpumask_bits(src1p), cpumask_bits(src2p),
    0.00 :   ffff8000100bc2d4:       add     x21, x19, #0x20
         : 505              bitmap_intersects():
    0.00 :   ffff8000100bc2d8:       mov     x0, x21
    0.00 :   ffff8000100bc2dc:       mov     w2, #0x100                      // #256
    0.00 :   ffff8000100bc2e0:       bl      ffff800010461ef0 <__bitmap_intersects>
         : 371              find_idlest_group():
         : 8852             */
         : 8853             static inline bool allow_numa_imbalance(int dst_running, int dst_weight)
         : 8854             {
         : 8855             return (dst_running < (dst_weight >> 2));
         : 8856             }
         :
    0.00 :   ffff8000100bc2e4:       cbz     w0, ffff8000100bc680 <find_idlest_group+0x438>
         : 8859             test_bit():
    0.00 :   ffff8000100bc2e8:       ldr     x0, [sp, #104]
         : 107              find_idlest_group():
         : 8863             */
         : 8864             static struct sched_group *
         : 8865             find_idlest_group(struct sched_domain *sd, struct task_struct *p, int this_cpu)
         : 8866             {
         : 8867             struct sched_group *idlest = NULL, *local = NULL, *group = sd->groups;
         : 8868             struct sg_lb_stats local_sgs, tmp_sgs;
    0.00 :   ffff8000100bc2ec:       add     x24, sp, #0xf8
         : 8870             test_bit():
    0.00 :   ffff8000100bc2f0:       ldrb    w1, [sp, #100]
    0.00 :   ffff8000100bc2f4:       ldr     x0, [x21, x0]
    0.00 :   ffff8000100bc2f8:       lsr     x0, x0, x1
         : 109              find_idlest_group():
         : 8859             static struct sched_group *
    0.00 :   ffff8000100bc2fc:       and     w1, w0, #0x1
    0.00 :   ffff8000100bc300:       str     w1, [sp, #96]
    0.00 :   ffff8000100bc304:       tbz     w0, #0, ffff8000100bc310 <find_idlest_group+0xc8>
         : 8860             find_idlest_group(struct sched_domain *sd, struct task_struct *p, int this_cpu)
    0.00 :   ffff8000100bc308:       add     x24, sp, #0xa8
         : 8861             {
    0.00 :   ffff8000100bc30c:       str     x19, [sp, #120]
         : 8863             update_sg_wakeup_stats():
         :
    0.00 :   ffff8000100bc310:       stp     xzr, xzr, [x24, #32]
         : 8727             return 0;
    0.00 :   ffff8000100bc314:       adrp    x20, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100bc318:       ldr     w25, [x23]
    0.00 :   ffff8000100bc31c:       ldr     w26, [x24, #40]
    0.00 :   ffff8000100bc320:       add     x20, x20, #0x760
         : 8726             if (rq->ttwu_pending)
    0.00 :   ffff8000100bc324:       mov     w8, #0xffffffff                 // #-1
         :
    0.00 :   ffff8000100bc328:       stp     xzr, xzr, [x24]
    0.00 :   ffff8000100bc32c:       stp     xzr, xzr, [x24, #16]
    0.00 :   ffff8000100bc330:       stp     xzr, xzr, [x24, #48]
    0.00 :   ffff8000100bc334:       stp     xzr, xzr, [x24, #64]
         : 8726             if (rq->ttwu_pending)
    0.00 :   ffff8000100bc338:       mov     w0, w8
    0.00 :   ffff8000100bc33c:       mov     x1, x21
    0.00 :   ffff8000100bc340:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff8000100bc344:       mov     w8, w0
    0.00 :   ffff8000100bc348:       cmp     w0, w25
    0.00 :   ffff8000100bc34c:       b.cs    ffff8000100bc500 <find_idlest_group+0x2b8>  // b.hs, b.nlast
         : 8727             return 0;
    0.00 :   ffff8000100bc350:       sxtw    x12, w8
    0.00 :   ffff8000100bc354:       mov     x6, x27
         : 8730             task_cpu():
         : 1993             * Returns non-zero if there is another task waiting on the rwlock.
         : 1994             * Returns zero if the lock is not contended or the system / underlying
         : 1995             * rwlock implementation does not support contention detection.
         : 1996             * Technically does not depend on CONFIG_PREEMPTION, but a general need
         : 1997             * for low latency.
         : 1998             */
    0.00 :   ffff8000100bc358:       ldr     w0, [x28, #64]
         : 2000             update_sg_wakeup_stats():
    0.00 :   ffff8000100bc35c:       ldr     x9, [x20, x12, lsl #3]
    0.00 :   ffff8000100bc360:       add     x6, x6, x9
         : 8729             cpu_load_without():
         : 5727             static void record_wakee(struct task_struct *p)
    0.00 :   ffff8000100bc364:       ldr     w10, [x6, #2576]
    0.00 :   ffff8000100bc368:       cmp     w10, w0
    0.00 :   ffff8000100bc36c:       b.ne    ffff8000100bc7d4 <find_idlest_group+0x58c>  // b.any
    0.00 :   ffff8000100bc370:       ldr     x0, [x28, #320]
    0.00 :   ffff8000100bc374:       cbz     x0, ffff8000100bc7d4 <find_idlest_group+0x58c>
         : 5733             task_cfs_rq():
         : 283              else if (cfs_rq && cfs_rq->tg->css.cgroup)
    0.00 :   ffff8000100bc378:       ldr     x7, [x28, #248]
         : 285              cpu_load_without():
         : 5731             * jiffy will not have built up many flips.
    0.00 :   ffff8000100bc37c:       ldr     x11, [x6, #288]
         : 5733             task_h_load():
         : 8092             if (cfs_rq->last_h_load_update == now)
    0.00 :   ffff8000100bc380:       mov     x0, x7
    0.00 :   ffff8000100bc384:       bl      ffff8000100bba60 <update_cfs_rq_h_load>
         : 8095             cpu_load_without():
         : 5736             }
    0.00 :   ffff8000100bc388:       ldr     w25, [x23]
         : 5738             task_h_load():
         : 8093             break;
    0.00 :   ffff8000100bc38c:       ldr     x9, [x7, #280]
    0.00 :   ffff8000100bc390:       ldr     x0, [x28, #352]
    0.00 :   ffff8000100bc394:       ldr     x1, [x7, #160]
    0.00 :   ffff8000100bc398:       mul     x0, x0, x9
    0.00 :   ffff8000100bc39c:       ldr     w10, [x6, #2576]
    0.00 :   ffff8000100bc3a0:       add     x1, x1, #0x1
    0.00 :   ffff8000100bc3a4:       ldr     x9, [x20, x12, lsl #3]
         : 8101             div64_u64():
         : 68               *
         : 69               * Return: dividend / divisor
         : 70               */
         : 71               static inline u64 div64_u64(u64 dividend, u64 divisor)
         : 72               {
         : 73               return dividend / divisor;
    0.00 :   ffff8000100bc3a8:       udiv    x0, x0, x1
         : 75               cpu_load_without():
         : 5734             current->wakee_flips >>= 1;
    0.00 :   ffff8000100bc3ac:       cmp     w11, w0
    0.00 :   ffff8000100bc3b0:       csel    w0, w11, w0, cc  // cc = lo, ul, last
         : 5736             }
    0.00 :   ffff8000100bc3b4:       sub     w0, w11, w0
         : 5738             update_sg_wakeup_stats():
         : 8730             return 1;
    0.00 :   ffff8000100bc3b8:       ldr     x11, [x24, #8]
         : 8732             task_cpu():
    0.00 :   ffff8000100bc3bc:       ldr     w1, [x28, #64]
         : 1994             update_sg_wakeup_stats():
    0.00 :   ffff8000100bc3c0:       add     x0, x11, x0
    0.00 :   ffff8000100bc3c4:       str     x0, [x24, #8]
         : 8732             cpu_util_without():
         : 6445             *
    0.00 :   ffff8000100bc3c8:       cmp     w8, w1
    0.00 :   ffff8000100bc3cc:       b.ne    ffff8000100bc78c <find_idlest_group+0x544>  // b.any
    0.00 :   ffff8000100bc3d0:       ldr     x0, [x28, #320]
    0.00 :   ffff8000100bc3d4:       cbz     x0, ffff8000100bc78c <find_idlest_group+0x544>
         : 6448             * enabled.
    0.00 :   ffff8000100bc3d8:       mov     x0, x27
         : 6501             lsub_positive(&util, task_util(p));
    0.00 :   ffff8000100bc3dc:       ldr     w13, [x28, #96]
         : 6448             * enabled.
    0.00 :   ffff8000100bc3e0:       add     x0, x0, x9
         : 6449             */
    0.00 :   ffff8000100bc3e4:       add     x1, x0, #0x80
    0.00 :   ffff8000100bc3e8:       ldr     x0, [x0, #304]
         : 6452             task_util():
         :
    0.00 :   ffff8000100bc3ec:       ldr     x11, [x28, #368]
         : 3900             cpu_util_without():
         : 6482             return min_t(unsigned long, util, capacity_orig_of(cpu));
    0.00 :   ffff8000100bc3f0:       ldr     w12, [x1, #184]
         : 6452             READ_ONCE(cfs_rq->avg.util_est.enqueued);
    0.00 :   ffff8000100bc3f4:       cmp     w0, w11
    0.00 :   ffff8000100bc3f8:       csel    w11, w0, w11, cc  // cc = lo, ul, last
         : 6501             lsub_positive(&util, task_util(p));
    0.00 :   ffff8000100bc3fc:       cmp     w13, #0x1
         : 6452             READ_ONCE(cfs_rq->avg.util_est.enqueued);
    0.00 :   ffff8000100bc400:       sub     w0, w0, w11
         : 6501             lsub_positive(&util, task_util(p));
    0.00 :   ffff8000100bc404:       b.eq    ffff8000100bc7dc <find_idlest_group+0x594>  // b.none
         : 6503             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100bc408:       mrs     x1, sp_el0
         : 26               cpu_util_without():
    0.00 :   ffff8000100bc40c:       cmp     x28, x1
    0.00 :   ffff8000100bc410:       b.eq    ffff8000100bc7dc <find_idlest_group+0x594>  // b.none
         : 6503             capacity_orig_of():
         : 2604             if (__rq_lockp(rq1) != __rq_lockp(rq2))
         : 2605             raw_spin_rq_unlock(rq2);
         : 2606             else
         : 2607             __release(rq2->lock);
         : 2608             raw_spin_rq_unlock(rq1);
         : 2609             }
    0.00 :   ffff8000100bc414:       mov     x1, x27
         : 2611             cpu_util_without():
         :
    0.00 :   ffff8000100bc418:       cmp     w0, w12
         : 6506             capacity_orig_of():
    0.00 :   ffff8000100bc41c:       add     x1, x1, x9
         : 2605             cpu_util_without():
         : 6512             * cpu_util() after the task has been enqueued.
    0.00 :   ffff8000100bc420:       csel    w0, w0, w12, cs  // cs = hs, nlast
    0.00 :   ffff8000100bc424:       ldr     x1, [x1, #2488]
    0.00 :   ffff8000100bc428:       cmp     x1, x0
    0.00 :   ffff8000100bc42c:       csel    x0, x1, x0, ls  // ls = plast
         : 6517             update_sg_wakeup_stats():
         : 8731             }
    0.00 :   ffff8000100bc430:       ldr     x1, [x24, #24]
         : 8733             task_cpu():
    0.00 :   ffff8000100bc434:       ldr     w11, [x28, #64]
         : 1994             update_sg_wakeup_stats():
    0.00 :   ffff8000100bc438:       add     x0, x1, x0
    0.00 :   ffff8000100bc43c:       str     x0, [x24, #24]
         : 8733             cpu_runnable_without():
         : 5750             * In order to determine whether we should let the load spread vs consolidating
    0.00 :   ffff8000100bc440:       cmp     w11, w10
    0.00 :   ffff8000100bc444:       b.ne    ffff8000100bc784 <find_idlest_group+0x53c>  // b.any
    0.00 :   ffff8000100bc448:       ldr     x0, [x28, #320]
    0.00 :   ffff8000100bc44c:       cbz     x0, ffff8000100bc784 <find_idlest_group+0x53c>
         : 5754             * With both conditions met, we can be relatively sure that the relationship is
    0.00 :   ffff8000100bc450:       ldr     x0, [x6, #296]
         : 5757             * Waker/wakee being client/server, worker/dispatcher, interrupt source or
    0.00 :   ffff8000100bc454:       ldr     x1, [x28, #360]
    0.00 :   ffff8000100bc458:       cmp     w0, w1
    0.00 :   ffff8000100bc45c:       csel    w1, w0, w1, cc  // cc = lo, ul, last
         : 5759             * socket size.
    0.00 :   ffff8000100bc460:       sub     w0, w0, w1
         : 5761             update_sg_wakeup_stats():
         :
    0.00 :   ffff8000100bc464:       ldr     x1, [x24, #32]
         : 8734             task_running_on_cpu():
         : 8674             #else
    0.00 :   ffff8000100bc468:       mov     w10, #0x0                       // #0
         : 8676             task_cpu():
    0.00 :   ffff8000100bc46c:       ldr     w11, [x28, #64]
         : 1994             update_sg_wakeup_stats():
         :
    0.00 :   ffff8000100bc470:       add     x0, x1, x0
    0.00 :   ffff8000100bc474:       str     x0, [x24, #32]
         : 8735             task_running_on_cpu():
         : 8673             }
    0.00 :   ffff8000100bc478:       cmp     w11, w8
    0.00 :   ffff8000100bc47c:       b.ne    ffff8000100bc494 <find_idlest_group+0x24c>  // b.any
    0.00 :   ffff8000100bc480:       ldr     x0, [x28, #320]
    0.00 :   ffff8000100bc484:       cbz     x0, ffff8000100bc494 <find_idlest_group+0x24c>
         : 8676             {
    0.00 :   ffff8000100bc488:       ldr     w0, [x28, #96]
    0.00 :   ffff8000100bc48c:       cmp     w0, #0x1
    0.00 :   ffff8000100bc490:       cset    w10, eq  // eq = none
         : 8680             update_sg_wakeup_stats():
         : 8736             * @group: sched_group whose statistics are to be updated.
    0.00 :   ffff8000100bc494:       ldr     w1, [x6, #4]
         : 8734             * update_sg_wakeup_stats - Update sched_group's statistics for wakeup.
    0.00 :   ffff8000100bc498:       ldr     w0, [x24, #44]
    0.00 :   ffff8000100bc49c:       ldr     w6, [x6, #148]
         : 8736             * @group: sched_group whose statistics are to be updated.
    0.00 :   ffff8000100bc4a0:       sub     w1, w1, w10
         : 8737             * @sgs: variable to hold the statistics for this group.
    0.00 :   ffff8000100bc4a4:       add     w26, w26, w1
         : 8734             * update_sg_wakeup_stats - Update sched_group's statistics for wakeup.
    0.00 :   ffff8000100bc4a8:       add     w0, w0, w6
    0.00 :   ffff8000100bc4ac:       sub     w0, w0, w10
    0.00 :   ffff8000100bc4b0:       stp     w26, w0, [x24, #40]
         : 8742             struct sg_lb_stats *sgs,
    0.00 :   ffff8000100bc4b4:       cbnz    w1, ffff8000100bc338 <find_idlest_group+0xf0>
         : 8744             idle_cpu_without():
         : 8691             */
    0.00 :   ffff8000100bc4b8:       mov     x0, x27
    0.00 :   ffff8000100bc4bc:       add     x9, x0, x9
         : 8693             static unsigned int task_running_on_cpu(int cpu, struct task_struct *p)
    0.00 :   ffff8000100bc4c0:       ldr     x0, [x9, #2352]
    0.00 :   ffff8000100bc4c4:       ldr     x1, [x9, #2360]
    0.00 :   ffff8000100bc4c8:       cmp     x1, x0
    0.00 :   ffff8000100bc4cc:       ccmp    x28, x0, #0x4, ne  // ne = any
    0.00 :   ffff8000100bc4d0:       b.ne    ffff8000100bc338 <find_idlest_group+0xf0>  // b.any
         : 8703             }
    0.00 :   ffff8000100bc4d4:       ldr     w0, [x9, #104]
    0.00 :   ffff8000100bc4d8:       cbnz    w0, ffff8000100bc338 <find_idlest_group+0xf0>
         : 8706             update_sg_wakeup_stats():
         : 8743             struct task_struct *p)
    0.00 :   ffff8000100bc4dc:       ldr     w0, [x24, #48]
         : 8726             if (rq->ttwu_pending)
    0.00 :   ffff8000100bc4e0:       mov     x1, x21
         : 8743             struct task_struct *p)
    0.00 :   ffff8000100bc4e4:       add     w0, w0, #0x1
    0.00 :   ffff8000100bc4e8:       str     w0, [x24, #48]
         : 8726             if (rq->ttwu_pending)
    0.00 :   ffff8000100bc4ec:       mov     w0, w8
    0.00 :   ffff8000100bc4f0:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff8000100bc4f4:       mov     w8, w0
    0.00 :   ffff8000100bc4f8:       cmp     w0, w25
    0.00 :   ffff8000100bc4fc:       b.cc    ffff8000100bc350 <find_idlest_group+0x108>  // b.lo, b.ul, b.last
         :
    0.00 :   ffff8000100bc500:       ldr     w0, [x22, #56]
    0.00 :   ffff8000100bc504:       ldr     x7, [x19, #16]
    0.00 :   ffff8000100bc508:       tbz     w0, #5, ffff8000100bc548 <find_idlest_group+0x300>
         : 8752             task_util():
         :
    0.00 :   ffff8000100bc50c:       ldr     x6, [x28, #368]
         : 3900             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100bc510:       ldr     x0, [x28, #376]
         : 3905             update_sg_wakeup_stats():
         : 8749             for_each_cpu(i, sched_group_span(group)) {
    0.00 :   ffff8000100bc514:       ldr     x1, [x7, #24]
         : 8751             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100bc518:       lsr     x8, x0, #32
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100bc51c:       cmp     w0, w8
    0.00 :   ffff8000100bc520:       csel    w0, w0, w8, hi  // hi = pmore
         : 3908             task_fits_capacity():
         : 4061             static inline void
    0.00 :   ffff8000100bc524:       lsl     x1, x1, #10
         : 4063             _task_util_est():
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100bc528:       orr     w0, w0, #0x1
         : 3907             task_util_est():
         : 3910             /* Update root cfs_rq's estimated utilization */
    0.00 :   ffff8000100bc52c:       cmp     x0, x6
    0.00 :   ffff8000100bc530:       csel    x0, x0, x6, cs  // cs = hs, nlast
         : 3913             task_fits_capacity():
         : 4061             static inline void
    0.00 :   ffff8000100bc534:       add     x0, x0, x0, lsl #2
         : 4063             update_sg_wakeup_stats():
         :
    0.00 :   ffff8000100bc538:       cmp     x1, x0, lsl #8
    0.00 :   ffff8000100bc53c:       b.hi    ffff8000100bc548 <find_idlest_group+0x300>  // b.pmore
         : 8750             struct rq *rq = cpu_rq(i);
    0.00 :   ffff8000100bc540:       mov     x0, #0x1                        // #1
    0.00 :   ffff8000100bc544:       str     x0, [x24, #64]
         : 8755             sgs->group_runnable += cpu_runnable_without(rq, p);
    0.00 :   ffff8000100bc548:       ldr     w6, [x19, #12]
         : 8753             sgs->group_load += cpu_load_without(rq, p);
    0.00 :   ffff8000100bc54c:       ldr     x0, [x7, #8]
    0.00 :   ffff8000100bc550:       str     x0, [x24, #16]
         : 8755             sgs->group_runnable += cpu_runnable_without(rq, p);
    0.00 :   ffff8000100bc554:       str     w6, [x24, #52]
         : 8757             group_is_overloaded():
         :
    0.00 :   ffff8000100bc558:       cmp     w26, w6
         : 8398             update_sg_wakeup_stats():
         : 8757             sgs->sum_h_nr_running += rq->cfs.h_nr_running - local;
    0.00 :   ffff8000100bc55c:       ldr     w8, [x22, #44]
         : 8759             group_is_overloaded():
         :
    0.00 :   ffff8000100bc560:       b.ls    ffff8000100bc598 <find_idlest_group+0x350>  // b.plast
         :
    0.00 :   ffff8000100bc564:       ldr     x9, [x24, #24]
    0.00 :   ffff8000100bc568:       mov     w10, w8
         : 8399             return false;
    0.00 :   ffff8000100bc56c:       add     x1, x0, x0, lsl #1
         :
    0.00 :   ffff8000100bc570:       mul     x9, x10, x9
         : 8399             return false;
    0.00 :   ffff8000100bc574:       add     x1, x0, x1, lsl #3
    0.00 :   ffff8000100bc578:       cmp     x9, x1, lsl #2
    0.00 :   ffff8000100bc57c:       b.hi    ffff8000100bc800 <find_idlest_group+0x5b8>  // b.pmore
         :
    0.00 :   ffff8000100bc580:       ldr     x9, [x24, #32]
         : 8403             return true;
    0.00 :   ffff8000100bc584:       mul     x10, x0, x10
         :
    0.00 :   ffff8000100bc588:       add     x1, x9, x9, lsl #1
    0.00 :   ffff8000100bc58c:       add     x1, x9, x1, lsl #3
         : 8403             return true;
    0.00 :   ffff8000100bc590:       cmp     x10, x1, lsl #2
    0.00 :   ffff8000100bc594:       b.cc    ffff8000100bc800 <find_idlest_group+0x5b8>  // b.lo, b.ul, b.last
         : 8406             group_classify():
         : 8418             {
    0.00 :   ffff8000100bc598:       ldr     w1, [x7, #40]
    0.00 :   ffff8000100bc59c:       cbnz    w1, ffff8000100bc778 <find_idlest_group+0x530>
         :
    0.00 :   ffff8000100bc5a0:       ldr     w1, [x24, #60]
    0.00 :   ffff8000100bc5a4:       cbnz    w1, ffff8000100bc838 <find_idlest_group+0x5f0>
         : 8424             return true;
    0.00 :   ffff8000100bc5a8:       ldr     x9, [x24, #64]
    0.00 :   ffff8000100bc5ac:       cbnz    x9, ffff8000100bc844 <find_idlest_group+0x5fc>
         : 8427             group_has_capacity():
         : 8371             * subtle and fragile situation.
    0.00 :   ffff8000100bc5b0:       cmp     w26, w6
    0.00 :   ffff8000100bc5b4:       b.cc    ffff8000100bc77c <find_idlest_group+0x534>  // b.lo, b.ul, b.last
         : 8375             {
    0.00 :   ffff8000100bc5b8:       ldr     x6, [x24, #32]
         : 8374             static inline int sg_imbalanced(struct sched_group *group)
    0.00 :   ffff8000100bc5bc:       mov     w8, w8
         : 8375             {
    0.00 :   ffff8000100bc5c0:       add     x5, x6, x6, lsl #1
         : 8374             static inline int sg_imbalanced(struct sched_group *group)
    0.00 :   ffff8000100bc5c4:       mul     x9, x0, x8
         : 8375             {
    0.00 :   ffff8000100bc5c8:       add     x5, x6, x5, lsl #3
         : 8374             static inline int sg_imbalanced(struct sched_group *group)
    0.00 :   ffff8000100bc5cc:       cmp     x9, x5, lsl #2
    0.00 :   ffff8000100bc5d0:       b.cc    ffff8000100bc5ec <find_idlest_group+0x3a4>  // b.lo, b.ul, b.last
         : 8379             /*
    0.00 :   ffff8000100bc5d4:       ldr     x6, [x24, #24]
         :
    0.00 :   ffff8000100bc5d8:       add     x5, x0, x0, lsl #1
    0.00 :   ffff8000100bc5dc:       add     x5, x0, x5, lsl #3
         : 8379             /*
    0.00 :   ffff8000100bc5e0:       mul     x8, x8, x6
         :
    0.00 :   ffff8000100bc5e4:       cmp     x8, x5, lsl #2
    0.00 :   ffff8000100bc5e8:       b.cc    ffff8000100bc77c <find_idlest_group+0x534>  // b.lo, b.ul, b.last
         : 8381             group_classify():
         : 8428             return true;
    0.00 :   ffff8000100bc5ec:       mov     w1, #0x1                        // #1
         : 8430             update_sg_wakeup_stats():
         : 8765             if (!nr_running && idle_cpu_without(i, p))
    0.00 :   ffff8000100bc5f0:       ldr     x5, [x24, #8]
         : 8757             sgs->sum_h_nr_running += rq->cfs.h_nr_running - local;
    0.00 :   ffff8000100bc5f4:       str     w1, [x24, #56]
         : 8765             if (!nr_running && idle_cpu_without(i, p))
    0.00 :   ffff8000100bc5f8:       lsl     x5, x5, #10
    0.00 :   ffff8000100bc5fc:       udiv    x0, x5, x0
    0.00 :   ffff8000100bc600:       str     x0, [x24]
         : 8769             find_idlest_group():
         : 8868             struct sg_lb_stats *sgs;
         : 8869             unsigned long imbalance;
         : 8870             struct sg_lb_stats idlest_sgs = {
         : 8871             .avg_load = UINT_MAX,
         : 8872             .group_type = group_overloaded,
    0.00 :   ffff8000100bc604:       ldr     w0, [sp, #96]
    0.00 :   ffff8000100bc608:       cbnz    w0, ffff8000100bc680 <find_idlest_group+0x438>
         : 8875             update_pick_idlest():
         : 8774             }
    0.00 :   ffff8000100bc60c:       ldr     w0, [sp, #136]
    0.00 :   ffff8000100bc610:       cmp     w0, w1
    0.00 :   ffff8000100bc614:       b.hi    ffff8000100bc658 <find_idlest_group+0x410>  // b.pmore
         :
    0.00 :   ffff8000100bc618:       b.cc    ffff8000100bc680 <find_idlest_group+0x438>  // b.lo, b.ul, b.last
         : 8785             */
    0.00 :   ffff8000100bc61c:       cmp     w1, #0x4
    0.00 :   ffff8000100bc620:       b.hi    ffff8000100bc808 <find_idlest_group+0x5c0>  // b.pmore
    0.00 :   ffff8000100bc624:       cmp     w1, #0x3
    0.00 :   ffff8000100bc628:       b.cs    ffff8000100bc680 <find_idlest_group+0x438>  // b.hs, b.nlast
    0.00 :   ffff8000100bc62c:       cmp     w1, #0x1
    0.00 :   ffff8000100bc630:       b.eq    ffff8000100bc810 <find_idlest_group+0x5c8>  // b.none
    0.00 :   ffff8000100bc634:       cmp     w1, #0x2
    0.00 :   ffff8000100bc638:       b.ne    ffff8000100bc8dc <find_idlest_group+0x694>  // b.any
         : 8800             if (sgs->group_type > idlest_sgs->group_type)
    0.00 :   ffff8000100bc63c:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100bc640:       ldr     x1, [x0, #16]
    0.00 :   ffff8000100bc644:       ldr     x0, [x7, #24]
    0.00 :   ffff8000100bc648:       ldr     x1, [x1, #24]
    0.00 :   ffff8000100bc64c:       cmp     x1, x0
    0.00 :   ffff8000100bc650:       b.cs    ffff8000100bc680 <find_idlest_group+0x438>  // b.hs, b.nlast
    0.00 :   ffff8000100bc654:       nop
    0.00 :   ffff8000100bc658:       ldr     x0, [x24]
    0.00 :   ffff8000100bc65c:       str     x0, [sp, #128]
    0.00 :   ffff8000100bc660:       ldr     x0, [x24, #24]
    0.00 :   ffff8000100bc664:       str     x0, [sp, #144]
    0.00 :   ffff8000100bc668:       ldr     w0, [x24, #48]
    0.00 :   ffff8000100bc66c:       str     w0, [sp, #140]
         : 8814             find_idlest_group():
         : 8870             };
         :
    0.00 :   ffff8000100bc670:       ldr     w0, [x24, #56]
         : 8869             };
    0.00 :   ffff8000100bc674:       str     x19, [sp, #112]
         :
    0.00 :   ffff8000100bc678:       str     w0, [sp, #136]
    0.00 :   ffff8000100bc67c:       nop
         : 8873             do {
         : 8874             int local_group;
         :
    0.00 :   ffff8000100bc680:       ldr     x19, [x19]
    0.00 :   ffff8000100bc684:       ldr     x0, [x22, #16]
    0.00 :   ffff8000100bc688:       cmp     x0, x19
    0.00 :   ffff8000100bc68c:       b.ne    ffff8000100bc2d0 <find_idlest_group+0x88>  // b.any
         : 8877             /* Skip over this group if it has no CPUs allowed */
         : 8878             if (!cpumask_intersects(sched_group_span(group),
         : 8879             p->cpus_ptr))
         : 8880             continue;
    0.00 :   ffff8000100bc690:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100bc694:       cbz     x0, ffff8000100bc8c0 <find_idlest_group+0x678>
         :
         : 8882             /* Skip over this group if no cookie matched */
         : 8883             if (!sched_group_cookie_match(cpu_rq(this_cpu), p, group))
         : 8884             continue;
    0.00 :   ffff8000100bc698:       ldr     x0, [sp, #120]
    0.00 :   ffff8000100bc69c:       cbz     x0, ffff8000100bc740 <find_idlest_group+0x4f8>
         : 8888             local_group = cpumask_test_cpu(this_cpu,
         : 8889             sched_group_span(group));
         :
         : 8891             if (local_group) {
         : 8892             sgs = &local_sgs;
         : 8893             local = group;
    0.00 :   ffff8000100bc6a0:       ldr     w1, [sp, #136]
    0.00 :   ffff8000100bc6a4:       ldr     w0, [sp, #224]
    0.00 :   ffff8000100bc6a8:       cmp     w0, w1
    0.00 :   ffff8000100bc6ac:       b.cc    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.lo, b.ul, b.last
         : 8895             sgs = &tmp_sgs;
         : 8896             }
         :
         : 8898             update_sg_wakeup_stats(sd, group, sgs, p);
         :
         : 8900             if (!local_group && update_pick_idlest(idlest, &idlest_sgs, group, sgs)) {
    0.00 :   ffff8000100bc6b0:       b.hi    ffff8000100bc740 <find_idlest_group+0x4f8>  // b.pmore
         : 8898             idlest = group;
         : 8899             idlest_sgs = *sgs;
         : 8900             }
    0.00 :   ffff8000100bc6b4:       cmp     w0, #0x2
    0.00 :   ffff8000100bc6b8:       b.eq    ffff8000100bc908 <find_idlest_group+0x6c0>  // b.none
    0.00 :   ffff8000100bc6bc:       b.hi    ffff8000100bc8c8 <find_idlest_group+0x680>  // b.pmore
    0.00 :   ffff8000100bc6c0:       cbnz    w0, ffff8000100bc850 <find_idlest_group+0x608>
         : 8942             * remote CPUs look much more favourable. When considering
         : 8943             * cross-domain, add imbalance to the load on the remote node
         : 8944             * and consider staying local.
         : 8945             */
         :
         : 8947             if ((sd->flags & SD_NUMA) &&
    0.00 :   ffff8000100bc6c4:       ldr     w0, [x22, #56]
    0.00 :   ffff8000100bc6c8:       tbz     w0, #12, ffff8000100bc730 <find_idlest_group+0x4e8>
         : 8950             cpu_to_node():
         : 96               #endif
         :
         : 98               #ifndef cpu_to_node
         : 99               static inline int cpu_to_node(int cpu)
         : 100              {
         : 101              return per_cpu(numa_node, cpu);
    0.00 :   ffff8000100bc6cc:       ldr     w2, [sp, #100]
    0.00 :   ffff8000100bc6d0:       adrp    x20, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100bc6d4:       add     x20, x20, #0x760
    0.00 :   ffff8000100bc6d8:       adrp    x1, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000100bc6dc:       add     x19, x1, #0x610
         : 107              find_idlest_group():
         : 8949             return NULL;
         :
         : 8951             /*
         : 8952             * If the local group is less loaded than the selected
         : 8953             * idlest group don't try and push any tasks.
         : 8954             */
    0.00 :   ffff8000100bc6e0:       ldr     w1, [x28, #2192]
         : 8956             cpu_to_node():
    0.00 :   ffff8000100bc6e4:       mov     x0, x19
    0.00 :   ffff8000100bc6e8:       ldr     x2, [x20, w2, sxtw #3]
         : 98               find_idlest_group():
    0.00 :   ffff8000100bc6ec:       ldr     w0, [x2, x0]
    0.00 :   ffff8000100bc6f0:       cmp     w1, w0
    0.00 :   ffff8000100bc6f4:       b.eq    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.none
         : 8952             find_first_bit():
         : 117              unsigned long val = *addr & GENMASK(size - 1, 0);
         :
         : 119              return val ? __ffs(val) : size;
         : 120              }
         :
         : 122              return _find_first_bit(addr, size);
    0.00 :   ffff8000100bc6f8:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100bc6fc:       mov     x1, #0x100                      // #256
    0.00 :   ffff8000100bc700:       add     x0, x0, #0x20
    0.00 :   ffff8000100bc704:       bl      ffff80001046ced8 <_find_first_bit>
         : 127              cpu_to_node():
    0.00 :   ffff8000100bc708:       ldr     x0, [x20, w0, sxtw #3]
    0.00 :   ffff8000100bc70c:       mov     x1, x19
         : 98               find_idlest_group():
         : 8953             if (idlest_sgs.avg_load >= (local_sgs.avg_load + imbalance))
         : 8954             return NULL;
         :
         : 8956             if (100 * local_sgs.avg_load <= sd->imbalance_pct * idlest_sgs.avg_load)
    0.00 :   ffff8000100bc710:       ldr     w2, [x28, #2192]
    0.00 :   ffff8000100bc714:       ldr     w0, [x0, x1]
    0.00 :   ffff8000100bc718:       cmp     w2, w0
    0.00 :   ffff8000100bc71c:       b.eq    ffff8000100bc740 <find_idlest_group+0x4f8>  // b.none
         : 8961             allow_numa_imbalance():
         : 8827             case group_has_spare:
    0.00 :   ffff8000100bc720:       ldr     w1, [x22, #128]
         : 8829             find_idlest_group():
         : 8962             case group_imbalanced:
         : 8963             case group_asym_packing:
         : 8964             /* Those type are not used in the slow wakeup path */
         : 8965             return NULL;
         :
         : 8967             case group_misfit_task:
    0.00 :   ffff8000100bc724:       ldr     w0, [sp, #208]
    0.00 :   ffff8000100bc728:       cmp     w0, w1, asr #2
    0.00 :   ffff8000100bc72c:       b.lt    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.tstop
         :
         : 8973             case group_has_spare:
         : 8974             if (sd->flags & SD_NUMA) {
         : 8975             #ifdef CONFIG_NUMA_BALANCING
         : 8976             int idlest_cpu;
         : 8977             /*
    0.00 :   ffff8000100bc730:       ldr     w1, [sp, #140]
    0.00 :   ffff8000100bc734:       ldr     w0, [sp, #216]
    0.00 :   ffff8000100bc738:       cmp     w0, w1
    0.00 :   ffff8000100bc73c:       b.cs    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.hs, b.nlast
         : 8978             * If there is spare capacity at NUMA, try to select
         : 8979             * the preferred node
         : 8980             */
         : 8981             if (cpu_to_node(this_cpu) == p->numa_preferred_nid)
         : 8982             return NULL;
         :
    0.00 :   ffff8000100bc740:       ldr     x1, [sp, #152]
    0.00 :   ffff8000100bc744:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100bc748:       ldr     x2, [sp, #328]
    0.00 :   ffff8000100bc74c:       ldr     x1, [x1]
    0.00 :   ffff8000100bc750:       eor     x1, x2, x1
    0.00 :   ffff8000100bc754:       cbnz    x1, ffff8000100bc94c <find_idlest_group+0x704>
    0.00 :   ffff8000100bc758:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bc75c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bc760:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100bc764:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bc768:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100bc76c:       ldp     x29, x30, [sp], #336
    0.00 :   ffff8000100bc770:       autiasp
    0.00 :   ffff8000100bc774:       ret
         : 8998             group_classify():
         : 8419             if (sgs->sum_nr_running <= sgs->group_weight)
    0.00 :   ffff8000100bc778:       mov     w1, #0x4                        // #4
         : 8421             update_sg_wakeup_stats():
         : 8757             sgs->sum_h_nr_running += rq->cfs.h_nr_running - local;
    0.00 :   ffff8000100bc77c:       str     w1, [x24, #56]
         : 8763             * No need to call idle_cpu_without() if nr_running is not 0
    0.00 :   ffff8000100bc780:       b       ffff8000100bc604 <find_idlest_group+0x3bc>
         : 8765             cpu_runnable():
         : 5741             }
  100.00 :   ffff8000100bc784:       ldr     x0, [x6, #296]
         : 5743             find_idlest_group():
         : 3886             static inline void util_est_enqueue(struct cfs_rq *cfs_rq,
    0.00 :   ffff8000100bc788:       b       ffff8000100bc464 <find_idlest_group+0x21c>
         : 3888             cpu_util():
         :
    0.00 :   ffff8000100bc78c:       mov     x0, x27
    0.00 :   ffff8000100bc790:       add     x0, x0, x9
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100bc794:       add     x0, x0, #0x80
    0.00 :   ffff8000100bc798:       ldr     x1, [x0, #176]
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100bc79c:       ldr     w0, [x0, #184]
    0.00 :   ffff8000100bc7a0:       str     w0, [sp, #164]
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100bc7a4:       mov     w0, w1
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100bc7a8:       ldr     w11, [sp, #164]
    0.00 :   ffff8000100bc7ac:       cmp     w1, w11
    0.00 :   ffff8000100bc7b0:       b.hi    ffff8000100bc7b8 <find_idlest_group+0x570>  // b.pmore
    0.00 :   ffff8000100bc7b4:       ldr     w0, [sp, #164]
         : 6426             capacity_orig_of():
    0.00 :   ffff8000100bc7b8:       mov     x11, x27
         : 2605             cpu_util():
         :
    0.00 :   ffff8000100bc7bc:       mov     w1, w0
         : 6425             capacity_orig_of():
    0.00 :   ffff8000100bc7c0:       add     x11, x11, x9
         : 2605             cpu_util():
    0.00 :   ffff8000100bc7c4:       ldr     x0, [x11, #2488]
    0.00 :   ffff8000100bc7c8:       cmp     x0, x1
    0.00 :   ffff8000100bc7cc:       csel    x0, x0, x1, ls  // ls = plast
    0.00 :   ffff8000100bc7d0:       b       ffff8000100bc430 <find_idlest_group+0x1e8>
         : 6427             cpu_load():
         : 5705             {
    0.00 :   ffff8000100bc7d4:       ldr     x0, [x6, #288]
         : 5707             find_idlest_group():
         : 3891             if (!sched_feat(UTIL_EST))
    0.00 :   ffff8000100bc7d8:       b       ffff8000100bc3b8 <find_idlest_group+0x170>
         : 3893             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100bc7dc:       ldr     x11, [x28, #376]
    0.00 :   ffff8000100bc7e0:       lsr     x1, x11, #32
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100bc7e4:       cmp     w1, w11
    0.00 :   ffff8000100bc7e8:       csel    w1, w1, w11, hi  // hi = pmore
    0.00 :   ffff8000100bc7ec:       orr     w1, w1, #0x1
         : 3909             cpu_util_without():
         : 6502             else if (task_cpu(p) != cpu && dst_cpu == cpu)
    0.00 :   ffff8000100bc7f0:       cmp     w1, w12
    0.00 :   ffff8000100bc7f4:       csel    w1, w1, w12, ls  // ls = plast
    0.00 :   ffff8000100bc7f8:       sub     w12, w12, w1
    0.00 :   ffff8000100bc7fc:       b       ffff8000100bc414 <find_idlest_group+0x1cc>
         : 6507             group_classify():
         : 8416             static inline bool
    0.00 :   ffff8000100bc800:       mov     w1, #0x5                        // #5
    0.00 :   ffff8000100bc804:       b       ffff8000100bc5f0 <find_idlest_group+0x3a8>
         : 8419             update_pick_idlest():
         : 8785             */
    0.00 :   ffff8000100bc808:       cmp     w1, #0x5
    0.00 :   ffff8000100bc80c:       b.ne    ffff8000100bc8dc <find_idlest_group+0x694>  // b.any
         : 8789             sgs->group_capacity;
    0.00 :   ffff8000100bc810:       ldr     x0, [x24]
    0.00 :   ffff8000100bc814:       ldr     x1, [sp, #128]
    0.00 :   ffff8000100bc818:       cmp     x0, x1
    0.00 :   ffff8000100bc81c:       b.cs    ffff8000100bc680 <find_idlest_group+0x438>  // b.hs, b.nlast
    0.00 :   ffff8000100bc820:       str     x0, [sp, #128]
    0.00 :   ffff8000100bc824:       ldr     w0, [x24, #48]
    0.00 :   ffff8000100bc828:       str     w0, [sp, #140]
    0.00 :   ffff8000100bc82c:       ldr     x0, [x24, #24]
    0.00 :   ffff8000100bc830:       str     x0, [sp, #144]
    0.00 :   ffff8000100bc834:       b       ffff8000100bc670 <find_idlest_group+0x428>
         : 8800             group_classify():
         : 8422             if ((sgs->group_capacity * 100) <
    0.00 :   ffff8000100bc838:       mov     w1, #0x3                        // #3
         : 8424             update_sg_wakeup_stats():
         : 8757             sgs->sum_h_nr_running += rq->cfs.h_nr_running - local;
    0.00 :   ffff8000100bc83c:       str     w1, [x24, #56]
         : 8763             * No need to call idle_cpu_without() if nr_running is not 0
    0.00 :   ffff8000100bc840:       b       ffff8000100bc604 <find_idlest_group+0x3bc>
         : 8765             group_classify():
         :
    0.00 :   ffff8000100bc844:       mov     w1, #0x2                        // #2
         : 8427             update_sg_wakeup_stats():
         : 8757             sgs->sum_h_nr_running += rq->cfs.h_nr_running - local;
    0.00 :   ffff8000100bc848:       str     w1, [x24, #56]
         : 8763             * No need to call idle_cpu_without() if nr_running is not 0
    0.00 :   ffff8000100bc84c:       b       ffff8000100bc604 <find_idlest_group+0x3bc>
         : 8765             find_idlest_group():
         : 8898             }
    0.00 :   ffff8000100bc850:       cmp     w0, #0x1
    0.00 :   ffff8000100bc854:       b.ne    ffff8000100bc740 <find_idlest_group+0x4f8>  // b.any
         : 8904             if (!idlest)
    0.00 :   ffff8000100bc858:       ldr     w1, [x22, #44]
         : 8903             /* There is no idlest group to push tasks to */
    0.00 :   ffff8000100bc85c:       mov     x4, #0xf5c3                     // #62915
    0.00 :   ffff8000100bc860:       movk    x4, #0x5c28, lsl #16
         : 8915             if (local_sgs.group_type < idlest_sgs.group_type)
    0.00 :   ffff8000100bc864:       ldr     w3, [x22, #56]
         : 8903             /* There is no idlest group to push tasks to */
    0.00 :   ffff8000100bc868:       sub     w0, w1, #0x64
    0.00 :   ffff8000100bc86c:       movk    x4, #0xc28f, lsl #32
    0.00 :   ffff8000100bc870:       movk    x4, #0x28f5, lsl #48
    0.00 :   ffff8000100bc874:       lsl     x0, x0, #8
    0.00 :   ffff8000100bc878:       ldr     x2, [sp, #168]
    0.00 :   ffff8000100bc87c:       umulh   x0, x0, x4
    0.00 :   ffff8000100bc880:       lsr     x0, x0, #2
         : 8915             if (local_sgs.group_type < idlest_sgs.group_type)
    0.00 :   ffff8000100bc884:       tbz     w3, #12, ffff8000100bc898 <find_idlest_group+0x650>
         : 8916             return NULL;
    0.00 :   ffff8000100bc888:       ldr     x3, [sp, #128]
    0.00 :   ffff8000100bc88c:       add     x3, x0, x3
         : 8915             if (local_sgs.group_type < idlest_sgs.group_type)
    0.00 :   ffff8000100bc890:       cmp     x3, x2
    0.00 :   ffff8000100bc894:       b.cs    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.hs, b.nlast
         : 8923             return idlest;
    0.00 :   ffff8000100bc898:       ldr     x3, [sp, #128]
    0.00 :   ffff8000100bc89c:       add     x0, x0, x2
    0.00 :   ffff8000100bc8a0:       cmp     x0, x3
    0.00 :   ffff8000100bc8a4:       b.ls    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.plast
         : 8926             case group_overloaded:
    0.00 :   ffff8000100bc8a8:       mov     w0, w1
    0.00 :   ffff8000100bc8ac:       add     x1, x2, x2, lsl #1
    0.00 :   ffff8000100bc8b0:       add     x2, x2, x1, lsl #3
    0.00 :   ffff8000100bc8b4:       mul     x0, x0, x3
    0.00 :   ffff8000100bc8b8:       cmp     x0, x2, lsl #2
    0.00 :   ffff8000100bc8bc:       b.cc    ffff8000100bc740 <find_idlest_group+0x4f8>  // b.lo, b.ul, b.last
         : 8933             /*
    0.00 :   ffff8000100bc8c0:       str     xzr, [sp, #112]
    0.00 :   ffff8000100bc8c4:       b       ffff8000100bc740 <find_idlest_group+0x4f8>
         : 8898             }
    0.00 :   ffff8000100bc8c8:       cmp     w0, #0x4
    0.00 :   ffff8000100bc8cc:       b.ls    ffff8000100bc8c0 <find_idlest_group+0x678>  // b.plast
    0.00 :   ffff8000100bc8d0:       cmp     w0, #0x5
    0.00 :   ffff8000100bc8d4:       b.ne    ffff8000100bc740 <find_idlest_group+0x4f8>  // b.any
    0.00 :   ffff8000100bc8d8:       b       ffff8000100bc858 <find_idlest_group+0x610>
         : 8904             update_pick_idlest():
         : 8806             */
    0.00 :   ffff8000100bc8dc:       ldr     w0, [x24, #48]
    0.00 :   ffff8000100bc8e0:       ldr     w1, [sp, #140]
    0.00 :   ffff8000100bc8e4:       cmp     w1, w0
    0.00 :   ffff8000100bc8e8:       b.hi    ffff8000100bc680 <find_idlest_group+0x438>  // b.pmore
         : 8810             case group_fully_busy:
    0.00 :   ffff8000100bc8ec:       ldr     x1, [x24, #24]
    0.00 :   ffff8000100bc8f0:       b.eq    ffff8000100bc930 <find_idlest_group+0x6e8>  // b.none
    0.00 :   ffff8000100bc8f4:       str     w0, [sp, #140]
    0.00 :   ffff8000100bc8f8:       ldr     x0, [x24]
    0.00 :   ffff8000100bc8fc:       str     x0, [sp, #128]
    0.00 :   ffff8000100bc900:       str     x1, [sp, #144]
    0.00 :   ffff8000100bc904:       b       ffff8000100bc670 <find_idlest_group+0x428>
         : 8818             find_idlest_group():
         : 8937             * remote CPUs look much more favourable. When considering
    0.00 :   ffff8000100bc908:       ldr     x0, [sp, #120]
    0.00 :   ffff8000100bc90c:       ldr     x1, [x0, #16]
    0.00 :   ffff8000100bc910:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100bc914:       ldr     x1, [x1, #24]
    0.00 :   ffff8000100bc918:       ldr     x0, [x0, #16]
    0.00 :   ffff8000100bc91c:       ldr     x0, [x0, #24]
    0.00 :   ffff8000100bc920:       cmp     x1, x0
    0.00 :   ffff8000100bc924:       b.cc    ffff8000100bc740 <find_idlest_group+0x4f8>  // b.lo, b.ul, b.last
         : 8933             /*
    0.00 :   ffff8000100bc928:       str     xzr, [sp, #112]
    0.00 :   ffff8000100bc92c:       b       ffff8000100bc740 <find_idlest_group+0x4f8>
         : 8936             update_pick_idlest():
         : 8810             case group_fully_busy:
    0.00 :   ffff8000100bc930:       ldr     x0, [sp, #144]
    0.00 :   ffff8000100bc934:       cmp     x1, x0
    0.00 :   ffff8000100bc938:       b.cs    ffff8000100bc680 <find_idlest_group+0x438>  // b.hs, b.nlast
    0.00 :   ffff8000100bc93c:       ldr     x0, [x24]
    0.00 :   ffff8000100bc940:       str     x0, [sp, #128]
    0.00 :   ffff8000100bc944:       str     x1, [sp, #144]
    0.00 :   ffff8000100bc948:       b       ffff8000100bc670 <find_idlest_group+0x428>
         : 8818             find_idlest_group():
         :
    0.00 :   ffff8000100bc94c:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b41f8 <ttwu_do_wakeup.isra.110>:
         : 6                ttwu_do_wakeup():
         : 2955             ret = stop_two_cpus(arg.dst_cpu, arg.src_cpu, migrate_swap_stop, &arg);
         :
         : 2957             out:
         : 2958             return ret;
         : 2959             }
         : 2960             #endif /* CONFIG_NUMA_BALANCING */
    0.00 :   ffff8000100b41f8:       paciasp
    0.00 :   ffff8000100b41fc:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000100b4200:       mov     x29, sp
    0.00 :   ffff8000100b4204:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b4208:       mov     x20, x1
    0.00 :   ffff8000100b420c:       mov     x19, x0
         :
         : 2959             /*
         : 2960             * wait_task_inactive - wait for a thread to unschedule.
    0.00 :   ffff8000100b4210:       bl      ffff8000100b4160 <check_preempt_curr>
         : 2963             *
         : 2964             * If @match_state is nonzero, it's the @p->state value just checked and
         : 2965             * not expected to change.  If it changes, i.e. @p might have woken up,
         : 2966             * then return zero.  When we succeed in waiting for @p to be off its CPU,
         : 2967             * we return a positive number (its total switch count).  If a second call
    0.00 :   ffff8000100b4214:       ldr     x0, [x20, #120]
         : 2959             *
    0.00 :   ffff8000100b4218:       str     xzr, [x20, #16]
         : 2963             * we return a positive number (its total switch count).  If a second call
    0.00 :   ffff8000100b421c:       ldr     x2, [x0, #88]
    0.00 :   ffff8000100b4220:       cbz     x2, ffff8000100b4230 <ttwu_do_wakeup.isra.110+0x38>
         : 2969             * a short while later returns the same number, the caller can be sure that
         : 2970             * @p has remained unscheduled the whole time.
         : 2971             *
         : 2972             * The caller must ensure that the task *will* unschedule sometime soon,
         : 2973             * else this function might spin for a *long* time. This function can't
         : 2974             * be called with interrupts off, or it may introduce deadlock with
    0.00 :   ffff8000100b4224:       mov     x1, x20
    0.00 :   ffff8000100b4228:       mov     x0, x19
    0.00 :   ffff8000100b422c:       blr     x2
         : 2973             * smp_call_function() if an IPI is sent by the same process we are
         : 2974             * waiting to become inactive.
         : 2975             */
         : 2976             unsigned long wait_task_inactive(struct task_struct *p, long match_state)
    0.00 :   ffff8000100b4230:       ldr     x0, [x19, #2880]
    0.00 :   ffff8000100b4234:       cbz     x0, ffff8000100b426c <ttwu_do_wakeup.isra.110+0x74>
         : 2979             update_avg():
         :
         : 206              #define cap_scale(v, s) ((v)*(s) >> SCHED_CAPACITY_SHIFT)
         :
         : 208              static inline void update_avg(u64 *avg, u64 sample)
         : 209              {
         : 210              s64 diff = sample - *avg;
    0.00 :   ffff8000100b4238:       ldr     x3, [x19, #2888]
    0.00 :   ffff8000100b423c:       ldr     x1, [x19, #2400]
    0.00 :   ffff8000100b4240:       add     x0, x0, x3
         : 214              ttwu_do_wakeup():
         : 2975             {
         : 2976             int running, queued;
    0.00 :   ffff8000100b4244:       ldr     x2, [x19, #2896]
         : 2978             update_avg():
    0.00 :   ffff8000100b4248:       subs    x1, x1, x0
         : 206              *avg += diff / 8;
    0.00 :   ffff8000100b424c:       add     x0, x1, #0x7
    0.00 :   ffff8000100b4250:       csel    x0, x0, x1, mi  // mi = first
         : 209              ttwu_do_wakeup():
    0.00 :   ffff8000100b4254:       lsl     x1, x2, #1
         : 2976             update_avg():
    0.00 :   ffff8000100b4258:       add     x0, x3, x0, asr #3
         : 207              ttwu_do_wakeup():
         : 2979             struct rq_flags rf;
         : 2980             unsigned long ncsw;
         : 2981             struct rq *rq;
         :
    0.00 :   ffff8000100b425c:       cmp     x1, x0
    0.00 :   ffff8000100b4260:       b.cs    ffff8000100b427c <ttwu_do_wakeup.isra.110+0x84>  // b.hs, b.nlast
         : 2982             for (;;) {
         : 2983             /*
         : 2984             * We do the initial early heuristics without holding
    0.00 :   ffff8000100b4264:       str     xzr, [x19, #2880]
         : 2980             for (;;) {
    0.00 :   ffff8000100b4268:       str     x1, [x19, #2888]
         : 2985             * any task-queue locks at all. We'll only try to get
         : 2986             * the runqueue lock when things look like they will
         : 2987             * work out!
  100.00 :   ffff8000100b426c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b4270:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000100b4274:       autiasp
    0.00 :   ffff8000100b4278:       ret
         : 2982             * We do the initial early heuristics without holding
    0.00 :   ffff8000100b427c:       str     xzr, [x19, #2880]
         : 2984             update_avg():
    0.00 :   ffff8000100b4280:       str     x0, [x19, #2888]
         : 207              ttwu_do_wakeup():
    0.00 :   ffff8000100b4284:       b       ffff8000100b426c <ttwu_do_wakeup.isra.110+0x74>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104601a0 <__crc32c_le>:
         : 6                __crc32c_le():
         : 98               SYM_FUNC_END(crc32_le)
         :
         : 100              .align          5
         : 101              SYM_FUNC_START(__crc32c_le)
         : 102              alternative_if_not ARM64_HAS_CRC32
         : 103              b               __crc32c_le_base
    0.00 :   ffff8000104601a0:       b       ffff8000104793c0 <__crc32c_le_base>
         : 100              alternative_else_nop_endif
         : 101              __crc32         c
    0.00 :   ffff8000104601a4:       cmp     x2, #0x10
    0.00 :   ffff8000104601a8:       b.lt    ffff800010460248 <__crc32c_le+0xa8>  // b.tstop
    0.00 :   ffff8000104601ac:       and     x7, x2, #0x1f
    0.00 :   ffff8000104601b0:       and     x2, x2, #0xffffffffffffffe0
    0.00 :   ffff8000104601b4:       cbz     x7, ffff800010460224 <__crc32c_le+0x84>
    0.00 :   ffff8000104601b8:       and     x8, x7, #0xf
    0.00 :   ffff8000104601bc:       ldp     x3, x4, [x1]
    0.00 :   ffff8000104601c0:       add     x8, x8, x1
    0.00 :   ffff8000104601c4:       add     x1, x1, x7
   47.85 :   ffff8000104601c8:       ldp     x5, x6, [x8]
    0.00 :   ffff8000104601cc:       tst     x7, #0x8
    0.00 :   ffff8000104601d0:       crc32cx w8, w0, x3
    0.00 :   ffff8000104601d4:       csel    x3, x3, x4, eq  // eq = none
    0.00 :   ffff8000104601d8:       csel    w0, w0, w8, eq  // eq = none
    0.00 :   ffff8000104601dc:       tst     x7, #0x4
    0.00 :   ffff8000104601e0:       lsr     x4, x3, #32
    0.00 :   ffff8000104601e4:       crc32cw w8, w0, w3
    0.00 :   ffff8000104601e8:       csel    x3, x3, x4, eq  // eq = none
    0.00 :   ffff8000104601ec:       csel    w0, w0, w8, eq  // eq = none
    0.00 :   ffff8000104601f0:       tst     x7, #0x2
    0.00 :   ffff8000104601f4:       lsr     w4, w3, #16
    0.00 :   ffff8000104601f8:       crc32ch w8, w0, w3
    0.00 :   ffff8000104601fc:       csel    w3, w3, w4, eq  // eq = none
    0.00 :   ffff800010460200:       csel    w0, w0, w8, eq  // eq = none
    0.00 :   ffff800010460204:       tst     x7, #0x1
    0.00 :   ffff800010460208:       crc32cb w8, w0, w3
    0.00 :   ffff80001046020c:       csel    w0, w0, w8, eq  // eq = none
    0.00 :   ffff800010460210:       tst     x7, #0x10
    0.00 :   ffff800010460214:       crc32cx w8, w0, x5
    0.00 :   ffff800010460218:       crc32cx w8, w8, x6
    0.00 :   ffff80001046021c:       csel    w0, w0, w8, eq  // eq = none
    0.00 :   ffff800010460220:       cbz     x2, ffff800010460244 <__crc32c_le+0xa4>
    0.00 :   ffff800010460224:       ldp     x3, x4, [x1], #32
    0.00 :   ffff800010460228:       sub     x2, x2, #0x20
    0.00 :   ffff80001046022c:       ldp     x5, x6, [x1, #-16]
    0.00 :   ffff800010460230:       crc32cx w0, w0, x3
    0.00 :   ffff800010460234:       crc32cx w0, w0, x4
    0.00 :   ffff800010460238:       crc32cx w0, w0, x5
    0.00 :   ffff80001046023c:       crc32cx w0, w0, x6
    0.00 :   ffff800010460240:       cbnz    x2, ffff800010460224 <__crc32c_le+0x84>
    0.00 :   ffff800010460244:       ret
    0.00 :   ffff800010460248:       tbz     w2, #3, ffff800010460254 <__crc32c_le+0xb4>
    0.00 :   ffff80001046024c:       ldr     x3, [x1], #8
    0.00 :   ffff800010460250:       crc32cx w0, w0, x3
    0.00 :   ffff800010460254:       tbz     w2, #2, ffff800010460260 <__crc32c_le+0xc0>
    0.00 :   ffff800010460258:       ldr     w3, [x1], #4
    0.00 :   ffff80001046025c:       crc32cw w0, w0, w3
    0.00 :   ffff800010460260:       tbz     w2, #1, ffff80001046026c <__crc32c_le+0xcc>
   52.15 :   ffff800010460264:       ldrh    w3, [x1], #2
    0.00 :   ffff800010460268:       crc32ch w0, w0, w3
    0.00 :   ffff80001046026c:       tbz     w2, #0, ffff800010460278 <__crc32c_le+0xd8>
    0.00 :   ffff800010460270:       ldrb    w3, [x1]
    0.00 :   ffff800010460274:       crc32cb w0, w0, w3
    0.00 :   ffff800010460278:       ret
 Percent |	Source code & Disassembly of perf for cycles (2 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3     Disassembly of section .text:
         :
         : 5     0000000000085530 <record__mmap_read_evlist.constprop.0>:
         : 6     record__mmap_read_evlist():
         : 1102  session->bytes_compressed  += compressed;
         :
         : 1104  return compressed;
         : 1105  }
         :
         : 1107  static int record__mmap_read_evlist(struct record *rec, struct evlist *evlist,
    0.00 :   85530:  stp     x29, x30, [sp, #-224]!
    0.00 :   85534:  adrp    x3, 34d000 <options+0x650>
    0.00 :   85538:  mov     x29, sp
    0.00 :   8553c:  ldr     x3, [x3, #2784]
    0.00 :   85540:  stp     x19, x20, [sp, #16]
    0.00 :   85544:  stp     x23, x24, [sp, #48]
    0.00 :   85548:  mov     x24, x0
    0.00 :   8554c:  and     w0, w1, #0xff
    0.00 :   85550:  str     w0, [sp, #160]
    0.00 :   85554:  ldr     x1, [x3]
    0.00 :   85558:  str     x1, [sp, #216]
    0.00 :   8555c:  mov     x1, #0x0                        // #0
         : 1112  int rc = 0;
         : 1113  struct mmap *maps;
         : 1114  int trace_fd = rec->data.file.fd;
         : 1115  off_t off = 0;
         :
         : 1117  if (!evlist)
    0.00 :   85560:  cbz     x24, 85a64 <record__mmap_read_evlist.constprop.0+0x534>
         : 1115  return 0;
         :
         : 1117  maps = overwrite ? evlist->overwrite_mmap : evlist->mmap;
    0.00 :   85564:  stp     x25, x26, [sp, #64]
    0.00 :   85568:  and     w25, w2, #0xff
    0.00 :   8556c:  cbnz    w0, 856e4 <record__mmap_read_evlist.constprop.0+0x1b4>
    0.00 :   85570:  ldr     x20, [x24, #2216]
         : 1116  if (!maps)
    0.00 :   85574:  cbz     x20, 85a6c <record__mmap_read_evlist.constprop.0+0x53c>
    0.00 :   85578:  stp     x21, x22, [sp, #32]
         : 1105  u64 bytes_written = rec->bytes_written;
    0.00 :   8557c:  adrp    x22, 352000 <bad_path+0x20>
    0.00 :   85580:  add     x0, x22, #0x708
         : 1122  return 0;
         :
         : 1124  if (overwrite && evlist->bkw_mmap_state != BKW_MMAP_DATA_PENDING)
         : 1125  return 0;
         :
         : 1127  if (record__aio_enabled(rec))
    0.00 :   85584:  ldr     w1, [x0, #512]
         : 1105  u64 bytes_written = rec->bytes_written;
    0.00 :   85588:  ldr     x2, [x0, #544]
    0.00 :   8558c:  str     x2, [sp, #152]
         : 1109  int trace_fd = rec->data.file.fd;
    0.00 :   85590:  ldr     w0, [x0, #568]
    0.00 :   85594:  str     w0, [sp, #164]
         : 1122  if (record__aio_enabled(rec))
    0.00 :   85598:  cmp     w1, #0x0
    0.00 :   8559c:  b.gt    85a00 <record__mmap_read_evlist.constprop.0+0x4d0>
         : 1125  off = record__aio_get_pos(trace_fd);
         :
         : 1127  for (i = 0; i < evlist->core.nr_mmaps; i++) {
    0.00 :   855a0:  ldr     w0, [x24, #48]
         : 1107  int rc = 0;
    0.00 :   855a4:  mov     w19, #0x0                       // #0
         : 1110  off_t off = 0;
    0.00 :   855a8:  str     xzr, [sp, #112]
         : 1125  for (i = 0; i < evlist->core.nr_mmaps; i++) {
    0.00 :   855ac:  cmp     w0, #0x0
    0.00 :   855b0:  b.le    857c4 <record__mmap_read_evlist.constprop.0+0x294>
    0.00 :   855b4:  add     x19, x20, #0x10, lsl #12
    0.00 :   855b8:  mov     x23, #0xc8                      // #200
    0.00 :   855bc:  add     x19, x19, #0x50
         : 1131  record__aio_sync():
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   855c0:  adrp    x0, 28f000 <help.0+0x5080>
         : 285   record__mmap_read_evlist():
         : 1110  off_t off = 0;
    0.00 :   855c4:  mov     w21, #0x0                       // #0
         : 1112  record__aio_sync():
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   855c8:  add     x0, x0, #0x98
         : 285   record__mmap_read_evlist():
         : 1125  for (i = 0; i < evlist->core.nr_mmaps; i++) {
    0.00 :   855cc:  movk    x23, #0x1, lsl #16
    0.00 :   855d0:  stp     x27, x28, [sp, #80]
         : 1128  record__aio_sync():
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   855d4:  str     x0, [sp, #168]
         : 285   record__mmap_read_evlist():
         : 1129  u64 flush = 0;
         : 1130  struct mmap *map = &maps[i];
         :
         : 1132  if (map->core.base) {
    0.00 :   855d8:  ldr     x0, [x20]
    0.00 :   855dc:  cbz     x0, 8574c <record__mmap_read_evlist.constprop.0+0x21c>
         : 1135  record__adjust_affinity():
         : 1058  if (rec->opts.affinity != PERF_AFFINITY_SYS &&
   50.48 :   855e0:  add     x26, x22, #0x708
    0.00 :   855e4:  ldr     w0, [x26, #516]
    0.00 :   855e8:  cbnz    w0, 85930 <record__mmap_read_evlist.constprop.0+0x400>
         : 1062  record__mmap_read_evlist():
         : 1126  u64 flush = 0;
    0.00 :   855ec:  mov     x27, #0x0                       // #0
         : 1131  record__adjust_affinity(rec, map);
         : 1132  if (synch) {
    0.00 :   855f0:  cbz     w25, 85600 <record__mmap_read_evlist.constprop.0+0xd0>
         : 1133  flush = map->core.flush;
         : 1134  map->core.flush = 1;
    0.00 :   855f4:  mov     x0, #0x1                        // #1
         : 1132  flush = map->core.flush;
    0.00 :   855f8:  ldr     x27, [x20, #56]
         : 1133  map->core.flush = 1;
    0.00 :   855fc:  str     x0, [x20, #56]
         : 1135  record__aio_enabled():
         : 448   return rec->opts.nr_cblocks > 0;
    0.00 :   85600:  add     x1, x22, #0x708
         : 450   record__mmap_read_evlist():
         : 1135  }
         : 1136  if (!record__aio_enabled(rec)) {
    0.00 :   85604:  ldr     w0, [x1, #512]
    0.00 :   85608:  cmp     w0, #0x0
    0.00 :   8560c:  b.le    85730 <record__mmap_read_evlist.constprop.0+0x200>
         : 1140  record__aio_push():
         : 342   int trace_fd = rec->session->data->file.fd;
    0.00 :   85610:  ldr     x0, [x1, #632]
         : 344   record__aio_sync():
         : 257   struct timespec timeout = { 0, 1000 * 1000  * 1 }; /* 1ms */
    0.00 :   85614:  adrp    x3, 2c9000 <help.0+0x3f080>
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   85618:  adrp    x2, 34d000 <options+0x650>
         : 257   struct timespec timeout = { 0, 1000 * 1000  * 1 }; /* 1ms */
    0.00 :   8561c:  ldr     q0, [x3, #2896]
         : 259   record__aio_push():
         : 342   int trace_fd = rec->session->data->file.fd;
    0.00 :   85620:  ldr     x0, [x0, #27728]
    0.00 :   85624:  ldr     w0, [x0, #16]
         : 343   struct record_aio aio = { .rec = rec, .size = 0 };
    0.00 :   85628:  stp     xzr, xzr, [sp, #200]
         : 345   record__aio_sync():
         : 255   struct aiocb **aiocb = md->aio.aiocb;
    0.00 :   8562c:  ldp     x26, x28, [x19, #64]
         : 257   record__aio_push():
         : 343   struct record_aio aio = { .rec = rec, .size = 0 };
    0.00 :   85630:  str     x1, [sp, #192]
         : 345   record__aio_sync():
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   85634:  ldr     x1, [x2, #2728]
         : 285   record__aio_push():
         : 342   int trace_fd = rec->session->data->file.fd;
    0.00 :   85638:  str     w0, [sp, #108]
         : 344   record__aio_sync():
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   8563c:  str     x1, [sp, #136]
         : 257   struct timespec timeout = { 0, 1000 * 1000  * 1 }; /* 1ms */
    0.00 :   85640:  str     q0, [sp, #176]
         : 262   for (i = 0; i < md->aio.nr_cblocks; ++i) {
    0.00 :   85644:  ldr     w0, [x19, #80]
    0.00 :   85648:  cmp     w0, #0x0
    0.00 :   8564c:  b.le    857d4 <record__mmap_read_evlist.constprop.0+0x2a4>
    0.00 :   85650:  mov     x3, #0x0                        // #0
    0.00 :   85654:  mov     x2, #0x0                        // #0
         : 263   if (cblocks[i].aio_fildes == -1 || record__aio_complete(md, &cblocks[i])) {
    0.00 :   85658:  ldr     w0, [x26, x3]
    0.00 :   8565c:  add     x5, x26, x3
    0.00 :   85660:  str     x2, [sp, #96]
    0.00 :   85664:  lsl     x4, x2, #3
    0.00 :   85668:  cmn     w0, #0x1
    0.00 :   8566c:  b.eq    857e0 <record__mmap_read_evlist.constprop.0+0x2b0>  // b.none
    0.00 :   85670:  mov     x1, x5
    0.00 :   85674:  mov     x0, x20
    0.00 :   85678:  stp     x4, x3, [sp, #120]
    0.00 :   8567c:  str     x5, [sp, #144]
    0.00 :   85680:  bl      84660 <record__aio_complete>
    0.00 :   85684:  ldp     x4, x3, [sp, #120]
    0.00 :   85688:  cbnz    w0, 857e0 <record__mmap_read_evlist.constprop.0+0x2b0>
         : 274   aiocb[i] = &cblocks[i];
    0.00 :   8568c:  ldr     x2, [sp, #96]
         : 262   for (i = 0; i < md->aio.nr_cblocks; ++i) {
    0.00 :   85690:  add     x3, x3, #0xa8
    0.00 :   85694:  ldr     w1, [x19, #80]
         : 274   aiocb[i] = &cblocks[i];
    0.00 :   85698:  ldr     x5, [sp, #144]
    0.00 :   8569c:  str     x5, [x28, x2, lsl #3]
         : 262   for (i = 0; i < md->aio.nr_cblocks; ++i) {
    0.00 :   856a0:  add     x2, x2, #0x1
    0.00 :   856a4:  cmp     w1, w2
    0.00 :   856a8:  b.gt    85658 <record__mmap_read_evlist.constprop.0+0x128>
    0.00 :   856ac:  add     x0, sp, #0xb0
    0.00 :   856b0:  str     x0, [sp, #96]
    0.00 :   856b4:  nop
         : 281   while (aio_suspend((const struct aiocb **)aiocb, md->aio.nr_cblocks, &timeout)) {
    0.00 :   856b8:  ldr     x2, [sp, #96]
    0.00 :   856bc:  mov     x0, x28
    0.00 :   856c0:  bl      70b30 <aio_suspend64@plt>
    0.00 :   856c4:  cbz     w0, 85644 <record__mmap_read_evlist.constprop.0+0x114>
         : 282   if (!(errno == EAGAIN || errno == EINTR))
    0.00 :   856c8:  bl      70040 <__errno_location@plt>
    0.00 :   856cc:  ldr     w0, [x0]
    0.00 :   856d0:  cmp     w0, #0xb
    0.00 :   856d4:  ccmp    w0, #0x4, #0x4, ne  // ne = any
    0.00 :   856d8:  b.ne    85a48 <record__mmap_read_evlist.constprop.0+0x518>  // b.any
         : 281   while (aio_suspend((const struct aiocb **)aiocb, md->aio.nr_cblocks, &timeout)) {
    0.00 :   856dc:  ldr     w1, [x19, #80]
    0.00 :   856e0:  b       856b8 <record__mmap_read_evlist.constprop.0+0x188>
         : 284   record__mmap_read_evlist():
         : 1115  maps = overwrite ? evlist->overwrite_mmap : evlist->mmap;
    0.00 :   856e4:  ldr     x20, [x24, #2224]
         : 1116  if (!maps)
    0.00 :   856e8:  cbz     x20, 85a6c <record__mmap_read_evlist.constprop.0+0x53c>
         : 1119  if (overwrite && evlist->bkw_mmap_state != BKW_MMAP_DATA_PENDING)
    0.00 :   856ec:  ldr     w0, [x24, #2200]
         : 1113  return 0;
    0.00 :   856f0:  mov     w19, #0x0                       // #0
         : 1119  if (overwrite && evlist->bkw_mmap_state != BKW_MMAP_DATA_PENDING)
    0.00 :   856f4:  cmp     w0, #0x2
    0.00 :   856f8:  b.eq    85578 <record__mmap_read_evlist.constprop.0+0x48>  // b.none
    0.00 :   856fc:  ldp     x25, x26, [sp, #64]
         :
         : 1178  if (overwrite)
         : 1179  evlist__toggle_bkw_mmap(evlist, BKW_MMAP_EMPTY);
         : 1180  out:
         : 1181  return rc;
         : 1182  }
    0.00 :   85700:  adrp    x1, 34d000 <options+0x650>
    0.00 :   85704:  ldr     x1, [x1, #2784]
    0.00 :   85708:  ldr     x0, [sp, #216]
    0.00 :   8570c:  ldr     x2, [x1]
    0.00 :   85710:  subs    x0, x0, x2
    0.00 :   85714:  mov     x2, #0x0                        // #0
    0.00 :   85718:  b.ne    85ad8 <record__mmap_read_evlist.constprop.0+0x5a8>  // b.any
    0.00 :   8571c:  mov     w0, w19
    0.00 :   85720:  ldp     x19, x20, [sp, #16]
    0.00 :   85724:  ldp     x23, x24, [sp, #48]
    0.00 :   85728:  ldp     x29, x30, [sp], #224
    0.00 :   8572c:  ret
         : 1136  if (perf_mmap__push(map, rec, record__pushfn) < 0) {
    0.00 :   85730:  adrp    x2, 85000 <record__finish_output.constprop.0+0x9c>
    0.00 :   85734:  mov     x0, x20
    0.00 :   85738:  add     x2, x2, #0xfe0
    0.00 :   8573c:  bl      128540 <perf_mmap__push>
    0.00 :   85740:  tbnz    w0, #31, 85914 <record__mmap_read_evlist.constprop.0+0x3e4>
         : 1151  if (synch)
    0.00 :   85744:  cbz     w25, 8574c <record__mmap_read_evlist.constprop.0+0x21c>
         : 1152  map->core.flush = flush;
    0.00 :   85748:  str     x27, [x20, #56]
         : 1155  if (map->auxtrace_mmap.base && !rec->opts.auxtrace_snapshot_mode &&
    0.00 :   8574c:  ldr     x0, [x19]
    0.00 :   85750:  cbz     x0, 85768 <record__mmap_read_evlist.constprop.0+0x238>
    0.00 :   85754:  add     x26, x22, #0x708
    0.00 :   85758:  ldrb    w0, [x26, #387]
    0.00 :   8575c:  cbnz    w0, 85768 <record__mmap_read_evlist.constprop.0+0x238>
    0.00 :   85760:  ldrb    w0, [x26, #389]
    0.00 :   85764:  cbz     w0, 859b8 <record__mmap_read_evlist.constprop.0+0x488>
         : 1125  for (i = 0; i < evlist->core.nr_mmaps; i++) {
   49.52 :   85768:  ldr     w0, [x24, #48]
    0.00 :   8576c:  add     w21, w21, #0x1
    0.00 :   85770:  add     x20, x20, x23
    0.00 :   85774:  add     x19, x19, x23
    0.00 :   85778:  cmp     w21, w0
    0.00 :   8577c:  b.lt    855d8 <record__mmap_read_evlist.constprop.0+0xa8>  // b.tstop
    0.00 :   85780:  ldp     x27, x28, [sp, #80]
         : 1133  record__aio_enabled():
         : 448   return rec->opts.nr_cblocks > 0;
    0.00 :   85784:  add     x19, x22, #0x708
         : 450   record__mmap_read_evlist():
         : 1163  if (record__aio_enabled(rec))
    0.00 :   85788:  ldr     w0, [x19, #512]
    0.00 :   8578c:  cmp     w0, #0x0
    0.00 :   85790:  b.gt    85a20 <record__mmap_read_evlist.constprop.0+0x4f0>
         : 1170  if (bytes_written != rec->bytes_written)
    0.00 :   85794:  ldr     x1, [sp, #152]
    0.00 :   85798:  ldr     x0, [x19, #544]
         : 1107  int rc = 0;
    0.00 :   8579c:  mov     w19, #0x0                       // #0
         : 1170  if (bytes_written != rec->bytes_written)
    0.00 :   857a0:  cmp     x1, x0
    0.00 :   857a4:  b.eq    857c4 <record__mmap_read_evlist.constprop.0+0x294>  // b.none
         : 1171  rc = record__write(rec, NULL, &finished_round_event, sizeof(finished_round_event));
    0.00 :   857a8:  adrp    x1, 34f000 <bt_ctf_event_put>
    0.00 :   857ac:  add     x1, x1, #0xfc0
    0.00 :   857b0:  add     x0, x22, #0x708
    0.00 :   857b4:  add     x1, x1, #0x60
    0.00 :   857b8:  mov     x2, #0x8                        // #8
    0.00 :   857bc:  bl      853a0 <record__write.constprop.0>
    0.00 :   857c0:  mov     w19, w0
         : 1173  if (overwrite)
    0.00 :   857c4:  ldr     w0, [sp, #160]
    0.00 :   857c8:  cbnz    w0, 85a78 <record__mmap_read_evlist.constprop.0+0x548>
    0.00 :   857cc:  ldp     x21, x22, [sp, #32]
    0.00 :   857d0:  b       856fc <record__mmap_read_evlist.constprop.0+0x1cc>
         : 1178  record__aio_sync():
         : 262   for (i = 0; i < md->aio.nr_cblocks; ++i) {
    0.00 :   857d4:  mov     x3, #0xffffffffffffff58         // #-168
    0.00 :   857d8:  mov     x4, #0xfffffffffffffff8         // #-8
    0.00 :   857dc:  nop
         : 266   record__aio_push():
         : 351   aio.data = map->aio.data[idx];
    0.00 :   857e0:  ldr     x5, [x19, #56]
         : 352   ret = perf_mmap__push(map, &aio, record__aio_pushfn);
    0.00 :   857e4:  add     x1, sp, #0xc0
    0.00 :   857e8:  mov     x0, x20
    0.00 :   857ec:  adrp    x2, 84000 <record__parse_comp_level+0x50>
    0.00 :   857f0:  add     x2, x2, #0x540
    0.00 :   857f4:  str     x3, [sp, #96]
         : 351   aio.data = map->aio.data[idx];
    0.00 :   857f8:  ldr     x4, [x5, x4]
    0.00 :   857fc:  str     x4, [sp, #200]
         : 352   ret = perf_mmap__push(map, &aio, record__aio_pushfn);
    0.00 :   85800:  bl      128540 <perf_mmap__push>
    0.00 :   85804:  mov     w28, w0
         : 353   if (ret != 0) /* ret > 0 - no data, ret < 0 - error */
    0.00 :   85808:  cbnz    w0, 85900 <record__mmap_read_evlist.constprop.0+0x3d0>
         : 356   rec->samples++;
    0.00 :   8580c:  add     x2, x22, #0x708
         : 358   record__aio_write():
         : 191   cblock->aio_sigevent.sigev_notify = SIGEV_NONE;
    0.00 :   85810:  mov     w4, #0x1                        // #1
         : 193   record__aio_push():
         : 357   ret = record__aio_write(&(map->aio.cblocks[idx]), trace_fd, aio.data, aio.size, *off);
    0.00 :   85814:  ldr     x1, [x19, #64]
    0.00 :   85818:  ldr     x3, [sp, #96]
         : 356   rec->samples++;
    0.00 :   8581c:  ldr     x0, [x2, #728]
         : 357   ret = record__aio_write(&(map->aio.cblocks[idx]), trace_fd, aio.data, aio.size, *off);
    0.00 :   85820:  add     x26, x1, x3
    0.00 :   85824:  ldr     x5, [sp, #200]
         : 356   rec->samples++;
    0.00 :   85828:  add     x0, x0, #0x1
    0.00 :   8582c:  str     x0, [x2, #728]
         : 359   record__aio_write():
         : 187   cblock->aio_fildes = trace_fd;
    0.00 :   85830:  ldr     w2, [sp, #108]
         : 189   record__aio_push():
         : 357   ret = record__aio_write(&(map->aio.cblocks[idx]), trace_fd, aio.data, aio.size, *off);
    0.00 :   85834:  ldr     x0, [sp, #208]
         : 359   record__aio_write():
         : 187   cblock->aio_fildes = trace_fd;
    0.00 :   85838:  str     w2, [x1, x3]
         : 189   cblock->aio_nbytes = size;
    0.00 :   8583c:  stp     x5, x0, [x26, #16]
         : 190   cblock->aio_offset = off;
    0.00 :   85840:  ldr     x0, [sp, #112]
         : 191   cblock->aio_sigevent.sigev_notify = SIGEV_NONE;
    0.00 :   85844:  str     w4, [x26, #44]
         : 190   cblock->aio_offset = off;
    0.00 :   85848:  str     x0, [x26, #128]
         : 191   cblock->aio_sigevent.sigev_notify = SIGEV_NONE;
    0.00 :   8584c:  b       85860 <record__mmap_read_evlist.constprop.0+0x330>
         : 197   } else if (errno != EAGAIN) {
    0.00 :   85850:  bl      70040 <__errno_location@plt>
    0.00 :   85854:  ldr     w0, [x0]
    0.00 :   85858:  cmp     w0, #0xb
    0.00 :   8585c:  b.ne    858d4 <record__mmap_read_evlist.constprop.0+0x3a4>  // b.any
         : 194   rc = aio_write(cblock);
    0.00 :   85860:  mov     x0, x26
    0.00 :   85864:  bl      709a0 <aio_write64@plt>
    0.00 :   85868:  mov     w28, w0
         : 195   if (rc == 0) {
    0.00 :   8586c:  cbnz    w0, 85850 <record__mmap_read_evlist.constprop.0+0x320>
         : 197   record__aio_push():
         : 360   rec->bytes_written += aio.size;
    0.00 :   85870:  add     x1, x22, #0x708
         : 359   *off += aio.size;
    0.00 :   85874:  ldr     x2, [sp, #112]
    0.00 :   85878:  ldr     x0, [sp, #208]
         : 360   rec->bytes_written += aio.size;
    0.00 :   8587c:  ldr     x3, [x1, #544]
         : 359   *off += aio.size;
    0.00 :   85880:  add     x2, x2, x0
    0.00 :   85884:  str     x2, [sp, #112]
         : 362   switch_output_size():
         : 134   return rec->switch_output.size &&
    0.00 :   85888:  ldr     x2, [x1, #680]
         : 136   record__aio_push():
         : 360   rec->bytes_written += aio.size;
    0.00 :   8588c:  add     x0, x0, x3
    0.00 :   85890:  str     x0, [x1, #544]
         : 363   switch_output_size():
         : 135   trigger_is_ready(&switch_output_trigger) &&
    0.00 :   85894:  cbz     x2, 85744 <record__mmap_read_evlist.constprop.0+0x214>
         : 137   trigger_is_ready():
         : 85    t->state = TRIGGER_ERROR;
         : 86    }
         :
         : 88    static inline bool trigger_is_ready(struct trigger *t)
         : 89    {
         : 90    return t->state == TRIGGER_READY;
    0.00 :   85898:  adrp    x26, 35f000 <generic_tests+0xd88>
    0.00 :   8589c:  add     x1, x26, #0xd30
         : 93    switch_output_size():
    0.00 :   858a0:  cmp     x0, x2
         : 136   trigger_is_ready():
    0.00 :   858a4:  ldr     w0, [x1, #16]
         : 86    switch_output_size():
    0.00 :   858a8:  ccmp    w0, #0x1, #0x0, cs  // cs = hs, nlast
    0.00 :   858ac:  b.ne    85744 <record__mmap_read_evlist.constprop.0+0x214>  // b.any
         : 137   trigger_is_available():
         : 42    return t->state >= 0;
    0.00 :   858b0:  ldr     w0, [x1, #16]
         : 44    trigger_hit():
         : 65    if (!trigger_is_available(t))
    0.00 :   858b4:  tbnz    w0, #31, 85744 <record__mmap_read_evlist.constprop.0+0x214>
         : 67    TRIGGER_WARN_ONCE(t, TRIGGER_READY);
    0.00 :   858b8:  ldr     w0, [x1, #16]
    0.00 :   858bc:  cmp     w0, #0x1
    0.00 :   858c0:  b.ne    85a90 <record__mmap_read_evlist.constprop.0+0x560>  // b.any
         : 68    t->state = TRIGGER_HIT;
    0.00 :   858c4:  add     x26, x26, #0xd30
    0.00 :   858c8:  mov     w0, #0x2                        // #2
    0.00 :   858cc:  str     w0, [x26, #16]
    0.00 :   858d0:  b       85744 <record__mmap_read_evlist.constprop.0+0x214>
         : 73    record__aio_write():
         : 199   pr_err("failed to queue perf data, error: %m\n");
    0.00 :   858d4:  adrp    x1, 34d000 <options+0x650>
         : 198   cblock->aio_fildes = -1;
    0.00 :   858d8:  mov     w0, #0xffffffff                 // #-1
         : 199   pr_err("failed to queue perf data, error: %m\n");
    0.00 :   858dc:  adrp    x2, 28e000 <help.0+0x4080>
    0.00 :   858e0:  add     x2, x2, #0xfb8
    0.00 :   858e4:  ldr     x1, [x1, #2728]
    0.00 :   858e8:  ldr     w1, [x1]
         : 198   cblock->aio_fildes = -1;
    0.00 :   858ec:  str     w0, [x26]
         : 199   pr_err("failed to queue perf data, error: %m\n");
    0.00 :   858f0:  mov     w0, #0x0                        // #0
    0.00 :   858f4:  bl      154200 <eprintf>
         : 202   record__aio_push():
         : 370   perf_mmap__put(&map->core);
    0.00 :   858f8:  mov     x0, x20
    0.00 :   858fc:  bl      21b5f4 <perf_mmap__put>
         : 373   record__mmap_read_evlist():
         : 1143  if (record__aio_push(rec, map, &off) < 0) {
    0.00 :   85900:  tbz     w28, #31, 85744 <record__mmap_read_evlist.constprop.0+0x214>
         : 1145  record__aio_set_pos():
         : 383   lseek(trace_fd, pos, SEEK_SET);
    0.00 :   85904:  ldr     w0, [sp, #164]
    0.00 :   85908:  mov     w2, #0x0                        // #0
    0.00 :   8590c:  ldr     x1, [sp, #112]
    0.00 :   85910:  bl      6f370 <lseek64@plt>
         : 388   record__mmap_read_evlist():
         : 1145  if (synch)
    0.00 :   85914:  cbz     w25, 859ec <record__mmap_read_evlist.constprop.0+0x4bc>
         : 1147  rc = -1;
    0.00 :   85918:  mov     w19, #0xffffffff                // #-1
    0.00 :   8591c:  ldp     x21, x22, [sp, #32]
    0.00 :   85920:  ldp     x25, x26, [sp, #64]
         : 1146  map->core.flush = flush;
    0.00 :   85924:  str     x27, [x20, #56]
    0.00 :   85928:  ldp     x27, x28, [sp, #80]
    0.00 :   8592c:  b       85700 <record__mmap_read_evlist.constprop.0+0x1d0>
         : 1150  bitmap_equal():
         : 170   if (small_const_nbits(nbits))
         : 171   return !((*src1 ^ *src2) & BITMAP_LAST_WORD_MASK(nbits));
         : 172   if (__builtin_constant_p(nbits & BITMAP_MEM_MASK) &&
         : 173   IS_ALIGNED(nbits, BITMAP_MEM_ALIGNMENT))
         : 174   return !memcmp(src1, src2, nbits / 8);
         : 175   return __bitmap_equal(src1, src2, nbits);
    0.00 :   85930:  ldr     w2, [x26, #744]
    0.00 :   85934:  ldr     x1, [x19, #88]
    0.00 :   85938:  ldr     x0, [x26, #736]
    0.00 :   8593c:  bl      132d30 <__bitmap_equal>
         : 180   record__adjust_affinity():
         : 1058  if (rec->opts.affinity != PERF_AFFINITY_SYS &&
    0.00 :   85940:  cbnz    w0, 855ec <record__mmap_read_evlist.constprop.0+0xbc>
         : 1060  bitmap_zero():
         : 30    int len = BITS_TO_LONGS(nbits) * sizeof(unsigned long);
    0.00 :   85944:  ldr     w2, [x26, #744]
         : 32    memset():
         : 71    {
         : 72    __warn_memset_zero_len ();
         : 73    return __dest;
         : 74    }
         : 75    #endif
         : 76    return __builtin___memset_chk (__dest, __ch, __len, __bos0 (__dest));
    0.00 :   85948:  mov     w1, #0x0                        // #0
    0.00 :   8594c:  ldr     x0, [x26, #736]
         : 79    bitmap_zero():
    0.00 :   85950:  add     x2, x2, #0x3f
    0.00 :   85954:  lsr     x2, x2, #6
         : 32    memset():
    0.00 :   85958:  lsl     x2, x2, #3
    0.00 :   8595c:  bl      71290 <memset@plt>
         : 73    bitmap_or():
         : 74    __bitmap_or(dst, src1, src2, nbits);
    0.00 :   85960:  ldr     w3, [x26, #744]
    0.00 :   85964:  ldr     x2, [x19, #88]
         : 77    record__adjust_affinity():
         : 1062  bitmap_or(rec->affinity_mask.bits, rec->affinity_mask.bits,
    0.00 :   85968:  ldr     x1, [x26, #736]
         : 1064  bitmap_or():
    0.00 :   8596c:  mov     x0, x1
    0.00 :   85970:  bl      132944 <__bitmap_or>
         : 76    record__adjust_affinity():
         : 1064  sched_setaffinity(0, MMAP_CPU_MASK_BYTES(&rec->affinity_mask),
    0.00 :   85974:  ldr     x1, [x26, #744]
    0.00 :   85978:  mov     w0, #0x0                        // #0
    0.00 :   8597c:  ldr     x2, [x26, #736]
    0.00 :   85980:  add     x1, x1, #0x3f
    0.00 :   85984:  lsr     x1, x1, #6
    0.00 :   85988:  lsl     x1, x1, #3
    0.00 :   8598c:  bl      70790 <sched_setaffinity@plt>
         : 1066  if (verbose == 2)
    0.00 :   85990:  adrp    x0, 34d000 <options+0x650>
    0.00 :   85994:  ldr     x0, [x0, #2728]
    0.00 :   85998:  ldr     w0, [x0]
    0.00 :   8599c:  cmp     w0, #0x2
    0.00 :   859a0:  b.ne    855ec <record__mmap_read_evlist.constprop.0+0xbc>  // b.any
         : 1067  mmap_cpu_mask__scnprintf(&rec->affinity_mask, "thread");
    0.00 :   859a4:  add     x0, x26, #0x2e0
    0.00 :   859a8:  adrp    x1, 2a2000 <help.0+0x18080>
    0.00 :   859ac:  add     x1, x1, #0xa30
    0.00 :   859b0:  bl      127c10 <mmap_cpu_mask__scnprintf>
    0.00 :   859b4:  b       855ec <record__mmap_read_evlist.constprop.0+0xbc>
         : 1073  record__auxtrace_mmap_read():
         : 639   ret = auxtrace_mmap__read(map, rec->itr, &rec->tool,
    0.00 :   859b8:  ldr     x1, [x26, #616]
    0.00 :   859bc:  adrp    x3, 86000 <record__pushfn+0x20>
    0.00 :   859c0:  mov     x2, x26
    0.00 :   859c4:  add     x3, x3, #0x1f0
    0.00 :   859c8:  mov     x0, x20
    0.00 :   859cc:  bl      1ac6a0 <auxtrace_mmap__read>
         : 641   if (ret < 0)
    0.00 :   859d0:  cmp     w0, #0x0
    0.00 :   859d4:  b.lt    859ec <record__mmap_read_evlist.constprop.0+0x4bc>  // b.tstop
         : 644   if (ret)
    0.00 :   859d8:  b.eq    85768 <record__mmap_read_evlist.constprop.0+0x238>  // b.none
         : 645   rec->samples++;
    0.00 :   859dc:  ldr     x0, [x26, #728]
    0.00 :   859e0:  add     x0, x0, #0x1
    0.00 :   859e4:  str     x0, [x26, #728]
    0.00 :   859e8:  b       85768 <record__mmap_read_evlist.constprop.0+0x238>
         : 650   record__mmap_read_evlist():
         : 1139  rc = -1;
    0.00 :   859ec:  mov     w19, #0xffffffff                // #-1
    0.00 :   859f0:  ldp     x21, x22, [sp, #32]
    0.00 :   859f4:  ldp     x25, x26, [sp, #64]
    0.00 :   859f8:  ldp     x27, x28, [sp, #80]
    0.00 :   859fc:  b       85700 <record__mmap_read_evlist.constprop.0+0x1d0>
         : 1145  record__aio_get_pos():
         : 378   return lseek(trace_fd, 0, SEEK_CUR);
    0.00 :   85a00:  mov     x1, #0x0                        // #0
    0.00 :   85a04:  mov     w2, #0x1                        // #1
    0.00 :   85a08:  bl      6f370 <lseek64@plt>
    0.00 :   85a0c:  str     x0, [sp, #112]
         : 383   record__mmap_read_evlist():
         : 1125  for (i = 0; i < evlist->core.nr_mmaps; i++) {
    0.00 :   85a10:  ldr     w1, [x24, #48]
    0.00 :   85a14:  cmp     w1, #0x0
    0.00 :   85a18:  b.gt    855b4 <record__mmap_read_evlist.constprop.0+0x84>
    0.00 :   85a1c:  b       85784 <record__mmap_read_evlist.constprop.0+0x254>
         : 1130  record__aio_set_pos():
         : 383   lseek(trace_fd, pos, SEEK_SET);
    0.00 :   85a20:  ldr     w0, [sp, #164]
    0.00 :   85a24:  mov     w2, #0x0                        // #0
    0.00 :   85a28:  ldr     x1, [sp, #112]
    0.00 :   85a2c:  bl      6f370 <lseek64@plt>
         : 388   record__mmap_read_evlist():
         : 1170  if (bytes_written != rec->bytes_written)
    0.00 :   85a30:  ldr     x1, [sp, #152]
    0.00 :   85a34:  ldr     x0, [x19, #544]
         : 1107  int rc = 0;
    0.00 :   85a38:  mov     w19, #0x0                       // #0
         : 1170  if (bytes_written != rec->bytes_written)
    0.00 :   85a3c:  cmp     x1, x0
    0.00 :   85a40:  b.ne    857a8 <record__mmap_read_evlist.constprop.0+0x278>  // b.any
    0.00 :   85a44:  b       857c4 <record__mmap_read_evlist.constprop.0+0x294>
         : 1174  record__aio_sync():
         : 283   pr_err("failed to sync perf data, error: %m\n");
    0.00 :   85a48:  ldr     x0, [sp, #136]
    0.00 :   85a4c:  ldr     x2, [sp, #168]
    0.00 :   85a50:  ldr     w1, [x0]
    0.00 :   85a54:  mov     w0, #0x0                        // #0
    0.00 :   85a58:  bl      154200 <eprintf>
         : 281   while (aio_suspend((const struct aiocb **)aiocb, md->aio.nr_cblocks, &timeout)) {
    0.00 :   85a5c:  ldr     w1, [x19, #80]
    0.00 :   85a60:  b       856b8 <record__mmap_read_evlist.constprop.0+0x188>
         : 284   record__mmap_read_evlist():
         : 1113  return 0;
    0.00 :   85a64:  mov     w19, #0x0                       // #0
    0.00 :   85a68:  b       85700 <record__mmap_read_evlist.constprop.0+0x1d0>
    0.00 :   85a6c:  mov     w19, #0x0                       // #0
    0.00 :   85a70:  ldp     x25, x26, [sp, #64]
    0.00 :   85a74:  b       85700 <record__mmap_read_evlist.constprop.0+0x1d0>
         : 1174  evlist__toggle_bkw_mmap(evlist, BKW_MMAP_EMPTY);
    0.00 :   85a78:  mov     x0, x24
    0.00 :   85a7c:  mov     w1, #0x3                        // #3
    0.00 :   85a80:  bl      11bf44 <evlist__toggle_bkw_mmap>
    0.00 :   85a84:  ldp     x21, x22, [sp, #32]
    0.00 :   85a88:  ldp     x25, x26, [sp, #64]
    0.00 :   85a8c:  b       85700 <record__mmap_read_evlist.constprop.0+0x1d0>
         : 1181  trigger_hit():
         : 67    TRIGGER_WARN_ONCE(t, TRIGGER_READY);
    0.00 :   85a90:  adrp    x28, 396000 <fs__entries+0x5830>
    0.00 :   85a94:  add     x28, x28, #0xed8
    0.00 :   85a98:  ldr     w0, [x28, #12]
    0.00 :   85a9c:  cbnz    w0, 858c4 <record__mmap_read_evlist.constprop.0+0x394>
    0.00 :   85aa0:  adrp    x0, 34d000 <options+0x650>
    0.00 :   85aa4:  ldr     w4, [x1, #16]
         : 74    fprintf():
         :
         : 101   # ifdef __va_arg_pack
         : 102   __fortify_function int
         : 103   fprintf (FILE *__restrict __stream, const char *__restrict __fmt, ...)
         : 104   {
         : 105   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
    0.00 :   85aa8:  ldr     x3, [x1, #24]
    0.00 :   85aac:  adrp    x5, 26f000 <__PRETTY_FUNCTION__.2>
         : 108   trigger_hit():
    0.00 :   85ab0:  ldr     x0, [x0, #3176]
         : 68    fprintf():
    0.00 :   85ab4:  add     x5, x5, #0x290
    0.00 :   85ab8:  adrp    x2, 28f000 <help.0+0x5080>
    0.00 :   85abc:  mov     w1, #0x1                        // #1
    0.00 :   85ac0:  add     x2, x2, #0x160
    0.00 :   85ac4:  ldr     x0, [x0]
    0.00 :   85ac8:  bl      700f0 <__fprintf_chk@plt>
         : 106   trigger_hit():
    0.00 :   85acc:  mov     w0, #0x1                        // #1
    0.00 :   85ad0:  str     w0, [x28, #12]
    0.00 :   85ad4:  b       858c4 <record__mmap_read_evlist.constprop.0+0x394>
    0.00 :   85ad8:  stp     x21, x22, [sp, #32]
    0.00 :   85adc:  stp     x25, x26, [sp, #64]
    0.00 :   85ae0:  stp     x27, x28, [sp, #80]
         : 73    record__mmap_read_evlist():
         : 1177  }
    0.00 :   85ae4:  bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100cf658 <add_wait_queue>:
         : 6                add_wait_queue():
         : 19               }
         :
         : 21               EXPORT_SYMBOL(__init_waitqueue_head);
         :
         : 23               void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
         : 24               {
    0.00 :   ffff8000100cf658:       paciasp
    0.00 :   ffff8000100cf65c:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000100cf660:       mov     x29, sp
    0.00 :   ffff8000100cf664:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100cf668:       mov     x19, x1
    0.00 :   ffff8000100cf66c:       mov     x20, x0
         : 22               unsigned long flags;
         :
         : 24               wq_entry->flags &= ~WQ_FLAG_EXCLUSIVE;
    0.00 :   ffff8000100cf670:       ldr     w1, [x1]
    0.00 :   ffff8000100cf674:       and     w1, w1, #0xfffffffe
    0.00 :   ffff8000100cf678:       str     w1, [x19]
         : 23               spin_lock_irqsave(&wq_head->lock, flags);
    0.00 :   ffff8000100cf67c:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 25               __add_wait_queue():
         : 176              static inline void __add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)
         : 177              {
         : 178              struct list_head *head = &wq_head->head;
         : 179              struct wait_queue_entry *wq;
         :
         : 181              list_for_each_entry(wq, &wq_head->head, entry) {
   50.23 :   ffff8000100cf680:       ldr     x2, [x20, #8]
         : 173              struct list_head *head = &wq_head->head;
    0.00 :   ffff8000100cf684:       add     x6, x20, #0x8
         : 176              list_for_each_entry(wq, &wq_head->head, entry) {
    0.00 :   ffff8000100cf688:       mov     x5, x2
    0.00 :   ffff8000100cf68c:       cmp     x6, x2
   49.77 :   ffff8000100cf690:       b.eq    ffff8000100cf6f0 <add_wait_queue+0x98>  // b.none
         : 177              if (!(wq->flags & WQ_FLAG_PRIORITY))
    0.00 :   ffff8000100cf694:       ldur    w1, [x2, #-24]
    0.00 :   ffff8000100cf698:       sub     x3, x2, #0x18
    0.00 :   ffff8000100cf69c:       tbnz    w1, #5, ffff8000100cf6b0 <add_wait_queue+0x58>
    0.00 :   ffff8000100cf6a0:       b       ffff8000100cf6f8 <add_wait_queue+0xa0>
    0.00 :   ffff8000100cf6a4:       ldur    w4, [x2, #-24]
    0.00 :   ffff8000100cf6a8:       tbz     w4, #5, ffff8000100cf6c0 <add_wait_queue+0x68>
    0.00 :   ffff8000100cf6ac:       mov     x5, x2
         : 176              list_for_each_entry(wq, &wq_head->head, entry) {
    0.00 :   ffff8000100cf6b0:       ldr     x2, [x3, #24]
    0.00 :   ffff8000100cf6b4:       cmp     x6, x2
    0.00 :   ffff8000100cf6b8:       sub     x3, x2, #0x18
    0.00 :   ffff8000100cf6bc:       b.ne    ffff8000100cf6a4 <add_wait_queue+0x4c>  // b.any
    0.00 :   ffff8000100cf6c0:       ldr     x2, [x5]
         : 181              break;
         : 182              head = &wq->entry;
         : 183              }
         : 184              list_add(&wq_entry->entry, head);
    0.00 :   ffff8000100cf6c4:       add     x3, x19, #0x18
         : 186              __list_add():
         : 70               struct list_head *next)
         : 71               {
         : 72               if (!__list_add_valid(new, prev, next))
         : 73               return;
         :
         : 75               next->prev = new;
    0.00 :   ffff8000100cf6c8:       str     x3, [x2, #8]
         : 77               spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff8000100cf6cc:       mov     x1, x0
         : 416              __list_add():
         : 72               new->next = next;
         : 73               new->prev = prev;
    0.00 :   ffff8000100cf6d0:       stp     x2, x5, [x19, #24]
         : 75               spin_unlock_irqrestore():
    0.00 :   ffff8000100cf6d4:       mov     x0, x20
         : 410              __list_add():
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff8000100cf6d8:       str     x3, [x5]
         : 75               spin_unlock_irqrestore():
    0.00 :   ffff8000100cf6dc:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 410              add_wait_queue():
         : 26               __add_wait_queue(wq_head, wq_entry);
         : 27               spin_unlock_irqrestore(&wq_head->lock, flags);
         : 28               }
    0.00 :   ffff8000100cf6e0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100cf6e4:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000100cf6e8:       autiasp
    0.00 :   ffff8000100cf6ec:       ret
    0.00 :   ffff8000100cf6f0:       ldr     x2, [x2]
    0.00 :   ffff8000100cf6f4:       b       ffff8000100cf6c4 <add_wait_queue+0x6c>
         : 35               __add_wait_queue():
         : 177              if (!(wq->flags & WQ_FLAG_PRIORITY))
    0.00 :   ffff8000100cf6f8:       mov     x5, x6
    0.00 :   ffff8000100cf6fc:       b       ffff8000100cf6c4 <add_wait_queue+0x6c>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010222048 <__mod_lruvec_page_state>:
         : 6                __mod_lruvec_page_state():
         :
         : 741              void __mod_lruvec_page_state(struct page *page, enum node_stat_item idx,
         : 742              int val)
         : 743              {
         : 744              struct page *head = compound_head(page); /* rmap on tail pages */
         : 745              struct mem_cgroup *memcg;
    0.00 :   ffff800010222048:       paciasp
    0.00 :   ffff80001022204c:       stp     x29, x30, [sp, #-48]!
         : 748              page_pgdat():
         : 1542             }
         :
         : 1544             static inline pg_data_t *page_pgdat(const struct page *page)
         : 1545             {
         : 1546             return NODE_DATA(page_to_nid(page));
         : 1547             }
    0.00 :   ffff800010222050:       adrp    x3, ffff800011c2d000 <xen_lateeoi_chip+0x68>
         : 1549             __mod_lruvec_page_state():
    0.00 :   ffff800010222054:       mov     x29, sp
    0.00 :   ffff800010222058:       stp     x19, x20, [sp, #16]
         : 742              page_pgdat():
    0.00 :   ffff80001022205c:       add     x3, x3, #0xf60
         : 1543             __mod_lruvec_page_state():
    0.00 :   ffff800010222060:       mov     w20, w1
    0.00 :   ffff800010222064:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010222068:       mov     w21, w2
         : 743              page_to_nid():
         : 1374             }
   50.28 :   ffff80001022206c:       ldr     x4, [x0]
         : 1376             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010222070:       ldr     x5, [x0, #8]
         : 191              page_pgdat():
         : 1542             }
    0.00 :   ffff800010222074:       lsr     x4, x4, #60
         : 1544             compound_head():
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010222078:       sub     x19, x5, #0x1
    0.00 :   ffff80001022207c:       tst     x5, #0x1
    0.00 :   ffff800010222080:       csel    x19, x19, x0, ne  // ne = any
         : 193              page_pgdat():
    0.00 :   ffff800010222084:       ldr     x22, [x3, x4, lsl #3]
         : 1543             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010222088:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              page_memcg():
         : 453              * associated with a kmem page from being released.
         : 454              */
         : 455              static inline struct mem_cgroup *page_memcg(struct page *page)
         : 456              {
         : 457              if (PageMemcgKmem(page))
         : 458              return obj_cgroup_memcg(__page_objcg(page));
    0.00 :   ffff80001022208c:       ldr     x4, [x19, #56]
         : 460              __page_memcg():
         : 407              }
    0.00 :   ffff800010222090:       and     x3, x4, #0xfffffffffffffffc
         : 409              page_memcg():
         : 453              return obj_cgroup_memcg(__page_objcg(page));
    0.00 :   ffff800010222094:       tbz     w4, #1, ffff80001022209c <__mod_lruvec_page_state+0x54>
         : 455              obj_cgroup_memcg():
         : 386              }
    0.00 :   ffff800010222098:       ldr     x3, [x3, #16]
         : 388              __mod_lruvec_page_state():
         : 749              rcu_read_lock();
         : 750              memcg = page_memcg(head);
         : 751              /* Untracked pages have no memcg, no lruvec. Update only the node */
         : 752              if (!memcg) {
         : 753              rcu_read_unlock();
         : 754              __mod_node_page_state(pgdat, idx, val);
    0.00 :   ffff80001022209c:       cbz     x3, ffff8000102220ec <__mod_lruvec_page_state+0xa4>
         : 756              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000102220a0:       nop
         : 28               mem_cgroup_lruvec():
         :
         : 731              if (!memcg)
         : 732              memcg = root_mem_cgroup;
         :
         : 734              mz = memcg->nodeinfo[pgdat->node_id];
         : 735              lruvec = &mz->lruvec;
    0.00 :   ffff8000102220a4:       ldrsw   x0, [x22, #8512]
    0.00 :   ffff8000102220a8:       add     x3, x3, x0, lsl #3
         : 731              out:
    0.00 :   ffff8000102220ac:       ldr     x0, [x3, #3960]
         : 738              * Since a node can be onlined after the mem_cgroup was created,
         : 739              * we have to be prepared to initialize lruvec->pgdat here;
         : 740              * and if offlined then reonlined, we need to reinitialize it.
         : 741              */
         : 742              if (unlikely(lruvec->pgdat != pgdat))
         : 743              lruvec->pgdat = pgdat;
    0.00 :   ffff8000102220b0:       ldr     x1, [x0, #136]
    0.00 :   ffff8000102220b4:       cmp     x22, x1
    0.00 :   ffff8000102220b8:       b.ne    ffff800010222104 <__mod_lruvec_page_state+0xbc>  // b.any
         : 747              __mod_lruvec_page_state():
         : 756              }
         :
         : 758              lruvec = mem_cgroup_lruvec(memcg, pgdat);
         : 759              __mod_lruvec_state(lruvec, idx, val);
         : 760              rcu_read_unlock();
         : 761              }
   49.72 :   ffff8000102220bc:       mov     w2, w21
    0.00 :   ffff8000102220c0:       mov     w1, w20
    0.00 :   ffff8000102220c4:       bl      ffff800010221ff0 <__mod_lruvec_state>
         : 765              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000102220c8:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              __mod_lruvec_page_state():
         : 758              EXPORT_SYMBOL(__mod_lruvec_page_state);
         :
    0.00 :   ffff8000102220cc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102220d0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102220d4:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102220d8:       autiasp
    0.00 :   ffff8000102220dc:       ret
         : 765              mem_cgroup_lruvec():
         : 723              goto out;
    0.00 :   ffff8000102220e0:       mov     x0, #0x2220                     // #8736
    0.00 :   ffff8000102220e4:       add     x0, x22, x0
         : 724              }
    0.00 :   ffff8000102220e8:       b       ffff8000102220b0 <__mod_lruvec_page_state+0x68>
         : 726              rcu_read_unlock():
    0.00 :   ffff8000102220ec:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              __mod_lruvec_page_state():
         : 751              }
    0.00 :   ffff8000102220f0:       sxtw    x2, w21
    0.00 :   ffff8000102220f4:       mov     w1, w20
    0.00 :   ffff8000102220f8:       mov     x0, x22
    0.00 :   ffff8000102220fc:       bl      ffff8000101a4d50 <__mod_node_page_state>
         :
    0.00 :   ffff800010222100:       b       ffff8000102220cc <__mod_lruvec_page_state+0x84>
         : 754              mem_cgroup_lruvec():
         : 739              return lruvec;
    0.00 :   ffff800010222104:       str     x22, [x0, #136]
    0.00 :   ffff800010222108:       b       ffff8000102220bc <__mod_lruvec_page_state+0x74>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001027b6a0 <__block_commit_write.isra.49>:
         : 6                __block_commit_write():
         : 2085             mark_buffer_dirty(bh);
         : 2086             continue;
         : 2087             }
         : 2088             if (block_end > to || block_start < from)
         : 2089             zero_user_segments(page,
         : 2090             to, block_end,
    0.00 :   ffff80001027b6a0:       paciasp
    0.00 :   ffff80001027b6a4:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff80001027b6a8:       mov     x29, sp
    0.00 :   ffff80001027b6ac:       stp     x23, x24, [sp, #48]
         : 2095             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001027b6b0:       ldr     x23, [x0]
    0.00 :   ffff80001027b6b4:       stp     x19, x20, [sp, #16]
   49.57 :   ffff80001027b6b8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001027b6bc:       ubfx    w23, w23, #13, #1
    0.00 :   ffff80001027b6c0:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001027b6c4:       stp     x27, x28, [sp, #80]
         : 118              __block_commit_write():
         : 2093             }
         : 2094             }
         : 2095             if (PageUptodate(page)) {
         : 2096             if (!buffer_uptodate(bh))
         : 2097             set_buffer_uptodate(bh);
         : 2098             continue;
    0.00 :   ffff80001027b6c8:       cbz     w23, ffff80001027b7cc <__block_commit_write.isra.49+0x12c>
    0.00 :   ffff80001027b6cc:       ldr     x27, [x0, #40]
         : 2094             }
    0.00 :   ffff80001027b6d0:       mov     w22, w2
    0.00 :   ffff80001027b6d4:       mov     w21, w1
    0.00 :   ffff80001027b6d8:       mov     x25, x0
    0.00 :   ffff80001027b6dc:       mov     w3, #0x0                        // #0
         : 2089             }
    0.00 :   ffff80001027b6e0:       mov     w28, #0x0                       // #0
         : 2091             __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff80001027b6e4:       mov     x24, #0x20                      // #32
         : 236              __block_commit_write():
         : 2093             continue;
    0.00 :   ffff80001027b6e8:       mov     x19, x27
         : 2094             }
    0.00 :   ffff80001027b6ec:       ldr     w26, [x27, #32]
         : 2096             if (!buffer_uptodate(bh) && !buffer_delay(bh) &&
         : 2097             !buffer_unwritten(bh) &&
    0.00 :   ffff80001027b6f0:       b       ffff80001027b714 <__block_commit_write.isra.49+0x74>
         : 2099             test_bit():
    0.00 :   ffff80001027b6f4:       ldr     x3, [x19]
         : 107              __block_commit_write():
         : 2101             (block_start < from || block_end > to)) {
         : 2102             ll_rw_block(REQ_OP_READ, 0, 1, &bh);
         : 2103             *wait_bh++=bh;
         : 2104             }
         : 2105             }
    0.00 :   ffff80001027b6f8:       tst     x0, #0x1
    0.00 :   ffff80001027b6fc:       csel    w28, w28, w23, ne  // ne = any
         : 2106             /*
         : 2107             * If we issued read requests - let them complete.
         : 2108             */
         : 2109             while(wait_bh > wait) {
         : 2110             wait_on_buffer(*--wait_bh);
    0.00 :   ffff80001027b700:       tbnz    w3, #5, ffff80001027b73c <__block_commit_write.isra.49+0x9c>
         : 2110             if (!buffer_uptodate(*wait_bh))
         : 2111             err = -EIO;
         : 2112             }
         : 2113             if (unlikely(err))
    0.00 :   ffff80001027b704:       ldr     x19, [x19, #8]
    0.00 :   ffff80001027b708:       mov     w3, w20
         : 2111             page_zero_new_buffers(page, from, to);
    0.00 :   ffff80001027b70c:       cmp     x27, x19
    0.00 :   ffff80001027b710:       b.eq    ffff80001027b760 <__block_commit_write.isra.49+0xc0>  // b.none
         : 2114             test_bit():
    0.00 :   ffff80001027b714:       ldr     x0, [x19]
    0.00 :   ffff80001027b718:       add     w20, w26, w3
         : 108              __block_commit_write():
         : 2099             *wait_bh++=bh;
    0.00 :   ffff80001027b71c:       cmp     w21, w20
    0.00 :   ffff80001027b720:       ccmp    w22, w3, #0x0, cc  // cc = lo, ul, last
    0.00 :   ffff80001027b724:       b.ls    ffff80001027b6f4 <__block_commit_write.isra.49+0x54>  // b.plast
         : 2103             set_buffer_uptodate():
         : 120              /*
         : 121              * Emit the buffer bitops functions.   Note that there are also functions
         : 122              * of the form "mark_buffer_foo()".  These are higher-level functions which
         : 123              * do something in addition to setting a b_state bit.
         : 124              */
         : 125              BUFFER_FNS(Uptodate, uptodate)
    0.00 :   ffff80001027b728:       tbz     w0, #0, ffff80001027b788 <__block_commit_write.isra.49+0xe8>
         : 127              __block_commit_write():
         : 2104             */
    0.00 :   ffff80001027b72c:       mov     x0, x19
    0.00 :   ffff80001027b730:       bl      ffff80001027b4e0 <mark_buffer_dirty>
         : 2107             test_bit():
    0.00 :   ffff80001027b734:       ldr     x3, [x19]
         : 107              __block_commit_write():
         : 2106             wait_on_buffer(*--wait_bh);
    0.00 :   ffff80001027b738:       tbz     w3, #5, ffff80001027b704 <__block_commit_write.isra.49+0x64>
         : 2108             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001027b73c:       b       ffff80001027b79c <__block_commit_write.isra.49+0xfc>
    0.00 :   ffff80001027b740:       b       ffff80001027b79c <__block_commit_write.isra.49+0xfc>
         : 46               __lse_atomic64_andnot():
         : 176              "       " #asm_op "     %[i], %[v]\n"                                   \
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff80001027b744:       mov     x0, x24
    0.00 :   ffff80001027b748:       stclr   x0, [x19]
         : 184              __block_commit_write():
         : 2110             if (unlikely(err))
   50.43 :   ffff80001027b74c:       ldr     x19, [x19, #8]
    0.00 :   ffff80001027b750:       mov     w3, w20
         : 2111             page_zero_new_buffers(page, from, to);
    0.00 :   ffff80001027b754:       cmp     x27, x19
    0.00 :   ffff80001027b758:       b.ne    ffff80001027b714 <__block_commit_write.isra.49+0x74>  // b.any
    0.00 :   ffff80001027b75c:       nop
         :
         : 2120             int __block_write_begin(struct page *page, loff_t pos, unsigned len,
         : 2121             get_block_t *get_block)
         : 2122             {
         : 2123             return __block_write_begin_int(page, pos, len, get_block, NULL);
         : 2124             }
    0.00 :   ffff80001027b760:       cbz     w28, ffff80001027b7ac <__block_commit_write.isra.49+0x10c>
         : 2122             EXPORT_SYMBOL(__block_write_begin);
         :
         : 2124             static int __block_commit_write(struct inode *inode, struct page *page,
    0.00 :   ffff80001027b764:       mov     w0, #0x0                        // #0
    0.00 :   ffff80001027b768:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001027b76c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001027b770:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001027b774:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001027b778:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001027b77c:       ldp     x29, x30, [sp], #96
    0.00 :   ffff80001027b780:       autiasp
    0.00 :   ffff80001027b784:       ret
         : 2134             arch_static_branch_jump():
    0.00 :   ffff80001027b788:       b       ffff80001027b7a4 <__block_commit_write.isra.49+0x104>
    0.00 :   ffff80001027b78c:       b       ffff80001027b7a4 <__block_commit_write.isra.49+0x104>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff80001027b790:       mov     x0, #0x1                        // #1
    0.00 :   ffff80001027b794:       stset   x0, [x19]
    0.00 :   ffff80001027b798:       b       ffff80001027b72c <__block_commit_write.isra.49+0x8c>
         : 181              __ll_sc_atomic64_andnot():
    0.00 :   ffff80001027b79c:       b       ffff80001028024c <__arm64_sys_bdflush+0x414>
    0.00 :   ffff80001027b7a0:       b       ffff80001027b704 <__block_commit_write.isra.49+0x64>
         : 231              __ll_sc_atomic64_or():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001027b7a4:       b       ffff800010280264 <__arm64_sys_bdflush+0x42c>
    0.00 :   ffff80001027b7a8:       b       ffff80001027b72c <__block_commit_write.isra.49+0x8c>
         : 225              SetPageUptodate():
         : 546              {
         : 547              VM_BUG_ON_PAGE(PageTail(page), page);
         : 548              smp_wmb();
         : 549              __set_bit(PG_uptodate, &page->flags);
         : 550              }
         :
    0.00 :   ffff80001027b7ac:       dmb     ishst
         : 553              arch_static_branch_jump():
    0.00 :   ffff80001027b7b0:       b       ffff80001027b7c4 <__block_commit_write.isra.49+0x124>
    0.00 :   ffff80001027b7b4:       b       ffff80001027b7c4 <__block_commit_write.isra.49+0x124>
         : 40               __lse_atomic64_or():
    0.00 :   ffff80001027b7b8:       mov     x0, #0x4                        // #4
    0.00 :   ffff80001027b7bc:       stset   x0, [x25]
    0.00 :   ffff80001027b7c0:       b       ffff80001027b764 <__block_commit_write.isra.49+0xc4>
         : 180              __ll_sc_atomic64_or():
    0.00 :   ffff80001027b7c4:       b       ffff80001028027c <__arm64_sys_bdflush+0x444>
         : 223              __block_commit_write():
         :
    0.00 :   ffff80001027b7c8:       b       ffff80001027b764 <__block_commit_write.isra.49+0xc4>
         : 2093             continue;
    0.00 :   ffff80001027b7cc:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102fb778 <ext4_es_can_be_merged>:
         : 6                ext4_es_can_be_merged():
         : 508              *  - status is equal
         : 509              */
         : 510              static int ext4_es_can_be_merged(struct extent_status *es1,
         : 511              struct extent_status *es2)
         : 512              {
         : 513              if (ext4_es_type(es1) != ext4_es_type(es2))
    0.00 :   ffff8000102fb778:       ldr     x3, [x0, #32]
   44.73 :   ffff8000102fb77c:       ldr     x5, [x1, #32]
         : 516              ext4_es_type():
         : 159              return es->es_pblk >> ES_SHIFT;
         : 160              }
         :
         : 162              static inline unsigned int ext4_es_type(struct extent_status *es)
         : 163              {
         : 164              return (es->es_pblk & ES_TYPE_MASK) >> ES_SHIFT;
    0.00 :   ffff8000102fb780:       lsr     x4, x3, #59
    0.00 :   ffff8000102fb784:       and     w6, w4, #0xf
    0.00 :   ffff8000102fb788:       ubfx    x2, x5, #59, #4
         : 168              ext4_es_can_be_merged():
    0.00 :   ffff8000102fb78c:       cmp     w6, w2
    0.00 :   ffff8000102fb790:       b.ne    ffff8000102fb808 <ext4_es_can_be_merged+0x90>  // b.any
         : 511              return 0;
         :
         : 513              if (((__u64) es1->es_len) + es2->es_len > EXT_MAX_BLOCKS) {
    0.00 :   ffff8000102fb794:       ldr     w7, [x0, #28]
    0.00 :   ffff8000102fb798:       mov     x8, #0xffffffff                 // #4294967295
    0.00 :   ffff8000102fb79c:       ldr     w2, [x1, #28]
    0.00 :   ffff8000102fb7a0:       mov     w6, w7
    0.00 :   ffff8000102fb7a4:       add     x9, x6, w2, uxtw
    0.00 :   ffff8000102fb7a8:       cmp     x9, x8
    0.00 :   ffff8000102fb7ac:       b.hi    ffff8000102fb814 <ext4_es_can_be_merged+0x9c>  // b.pmore
         : 520              es1->es_len, es2->es_len, EXT_MAX_BLOCKS);
         : 521              WARN_ON(1);
         : 522              return 0;
         : 523              }
         :
         : 525              if (((__u64) es1->es_lblk) + es1->es_len != es2->es_lblk)
    0.00 :   ffff8000102fb7b0:       ldr     w2, [x0, #24]
         : 509              return 0;
    0.00 :   ffff8000102fb7b4:       mov     w0, #0x0                        // #0
         : 520              if (((__u64) es1->es_lblk) + es1->es_len != es2->es_lblk)
    0.00 :   ffff8000102fb7b8:       ldr     w1, [x1, #24]
    0.00 :   ffff8000102fb7bc:       add     x2, x2, x6
    0.00 :   ffff8000102fb7c0:       cmp     x2, x1
    0.00 :   ffff8000102fb7c4:       b.ne    ffff8000102fb810 <ext4_es_can_be_merged+0x98>  // b.any
         : 523              return 0;
         :
         : 525              if ((ext4_es_is_written(es1) || ext4_es_is_unwritten(es1)) &&
    0.00 :   ffff8000102fb7c8:       tst     x4, #0x3
    0.00 :   ffff8000102fb7cc:       b.eq    ffff8000102fb7e8 <ext4_es_can_be_merged+0x70>  // b.none
         : 528              ext4_es_pblock():
         : 209              return (ext4_es_status(es) & EXTENT_STATUS_REFERENCED) != 0;
         : 210              }
         :
         : 212              static inline ext4_fsblk_t ext4_es_pblock(struct extent_status *es)
         : 213              {
         : 214              return es->es_pblk & ~ES_MASK;
    0.00 :   ffff8000102fb7d0:       and     x3, x3, #0x7ffffffffffffff
    0.00 :   ffff8000102fb7d4:       and     x5, x5, #0x7ffffffffffffff
         : 217              ext4_es_can_be_merged():
         : 524              (ext4_es_pblock(es1) + es1->es_len == ext4_es_pblock(es2)))
    0.00 :   ffff8000102fb7d8:       add     x3, x3, x6
         : 525              return 1;
    0.00 :   ffff8000102fb7dc:       mov     w0, #0x1                        // #1
         : 523              if ((ext4_es_is_written(es1) || ext4_es_is_unwritten(es1)) &&
    0.00 :   ffff8000102fb7e0:       cmp     x3, x5
    0.00 :   ffff8000102fb7e4:       b.eq    ffff8000102fb810 <ext4_es_can_be_merged+0x98>  // b.none
         : 525              return 1;
    0.00 :   ffff8000102fb7e8:       mov     w0, #0x1                        // #1
         :
         : 528              if (ext4_es_is_hole(es1))
    0.00 :   ffff8000102fb7ec:       tbnz    w4, #3, ffff8000102fb810 <ext4_es_can_be_merged+0x98>
         : 531              return 1;
         :
         : 533              /* we need to check delayed extent is without unwritten status */
         : 534              if (ext4_es_is_delayed(es1) && !ext4_es_is_unwritten(es1))
    0.00 :   ffff8000102fb7f0:       lsr     w0, w4, #1
    0.00 :   ffff8000102fb7f4:       tst     x4, #0x4
    0.00 :   ffff8000102fb7f8:       eor     w0, w0, #0x1
    0.00 :   ffff8000102fb7fc:       and     w0, w0, #0x1
    0.00 :   ffff8000102fb800:       csel    w0, w0, wzr, ne  // ne = any
    0.00 :   ffff8000102fb804:       ret
         : 509              return 0;
   55.27 :   ffff8000102fb808:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000102fb80c:       ret
         : 535              return 1;
         :
         : 537              return 0;
         : 538              }
    0.00 :   ffff8000102fb810:       ret
         : 507              {
    0.00 :   ffff8000102fb814:       paciasp
    0.00 :   ffff8000102fb818:       stp     x29, x30, [sp, #-16]!
         : 512              pr_warn("ES assertion failed when merging extents. "
    0.00 :   ffff8000102fb81c:       mov     w1, w7
         : 507              {
    0.00 :   ffff8000102fb820:       mov     x29, sp
         : 512              pr_warn("ES assertion failed when merging extents. "
    0.00 :   ffff8000102fb824:       mov     w3, #0xffffffff                 // #-1
    0.00 :   ffff8000102fb828:       adrp    x0, ffff800011432000 <kallsyms_token_index+0x277a0>
    0.00 :   ffff8000102fb82c:       add     x0, x0, #0xc0
    0.00 :   ffff8000102fb830:       bl      ffff800010e19544 <printk>
         : 516              WARN_ON(1);
    0.00 :   ffff8000102fb834:       brk     #0x800
         : 517              return 0;
    0.00 :   ffff8000102fb838:       mov     w0, #0x0                        // #0
         : 535              }
    0.00 :   ffff8000102fb83c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000102fb840:       autiasp
    0.00 :   ffff8000102fb844:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010180af8 <pagecache_get_page>:
         : 6                pagecache_get_page():
         : 1835             *
         : 1836             * Return: The found page or %NULL otherwise.
         : 1837             */
         : 1838             struct page *pagecache_get_page(struct address_space *mapping, pgoff_t index,
         : 1839             int fgp_flags, gfp_t gfp_mask)
         : 1840             {
    0.00 :   ffff800010180af8:       paciasp
    0.00 :   ffff800010180afc:       stp     x29, x30, [sp, #-176]!
    0.00 :   ffff800010180b00:       mov     x29, sp
    0.00 :   ffff800010180b04:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010180b08:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010180b0c:       add     x21, x21, #0x948
    0.00 :   ffff800010180b10:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010180b14:       mov     x23, x0
    0.00 :   ffff800010180b18:       mov     x22, x1
    0.00 :   ffff800010180b1c:       ldr     x0, [x21]
    0.00 :   ffff800010180b20:       str     x0, [sp, #168]
    0.00 :   ffff800010180b24:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010180b28:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010180b2c:       mov     w19, w2
    0.00 :   ffff800010180b30:       mov     w20, w3
    0.00 :   ffff800010180b34:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010180b38:       add     x26, x23, #0x8
    0.00 :   ffff800010180b3c:       stp     x27, x28, [sp, #80]
         : 1859             find_subpage():
         : 465              {
         : 466              /* HugeTLBfs wants the head page regardless */
         : 467              if (PageHuge(head))
         : 468              return head;
         :
         : 470              return head + (index & (thp_nr_pages(head) - 1));
    0.00 :   ffff800010180b40:       ubfiz   x27, x1, #6, #9
         : 472              inode_to_bdi():
         : 141              static inline struct backing_dev_info *inode_to_bdi(struct inode *inode)
         : 142              {
         : 143              struct super_block *sb;
         :
         : 145              if (!inode)
         : 146              return &noop_backing_dev_info;
    0.00 :   ffff800010180b44:       adrp    x25, ffff800011f52000 <pmus_srcu+0x2c8>
         : 148              mapping_get_entry():
         : 1765             XA_STATE(xas, &mapping->i_pages, index);
    0.00 :   ffff800010180b48:       mov     x24, #0x3                       // #3
         : 1767             inode_to_bdi():
    0.00 :   ffff800010180b4c:       add     x0, x25, #0x7b8
    0.00 :   ffff800010180b50:       str     x0, [sp, #104]
         : 143              mapping_get_entry():
    0.00 :   ffff800010180b54:       stp     x26, x22, [sp, #120]
    0.00 :   ffff800010180b58:       str     wzr, [sp, #136]
    0.00 :   ffff800010180b5c:       stp     x24, xzr, [sp, #144]
    0.00 :   ffff800010180b60:       str     xzr, [sp, #160]
         : 1769             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010180b64:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              mapping_get_entry():
         : 1771             page = xas_load(&xas);
    0.00 :   ffff800010180b68:       add     x0, sp, #0x78
         : 1773             xas_reset():
         : 1471             *
         : 1472             * Context: Any context.
         : 1473             */
         : 1474             static inline void xas_reset(struct xa_state *xas)
         : 1475             {
         : 1476             xas->xa_node = XAS_RESTART;
    0.00 :   ffff800010180b6c:       str     x24, [sp, #144]
         : 1478             mapping_get_entry():
    0.00 :   ffff800010180b70:       bl      ffff8000104bd080 <xas_load>
    0.00 :   ffff800010180b74:       mov     x25, x0
         : 1773             xas_retry():
         : 1488             * Context: Any context.
         : 1489             * Return: true if the operation needs to be retried.
         : 1490             */
         : 1491             static inline bool xas_retry(struct xa_state *xas, const void *entry)
         : 1492             {
         : 1493             if (xa_is_zero(entry))
    0.00 :   ffff800010180b78:       cmp     x0, #0x406
    0.00 :   ffff800010180b7c:       b.eq    ffff800010180b68 <pagecache_get_page+0x70>  // b.none
         : 1490             return true;
         : 1491             if (!xa_is_retry(entry))
    0.00 :   ffff800010180b80:       cmp     x0, #0x402
    0.00 :   ffff800010180b84:       b.eq    ffff800010180b68 <pagecache_get_page+0x70>  // b.none
         : 1494             mapping_get_entry():
         : 1778             if (!page || xa_is_value(page))
    0.00 :   ffff800010180b88:       cbz     x0, ffff800010180f0c <pagecache_get_page+0x414>
    0.00 :   ffff800010180b8c:       tbnz    w0, #0, ffff800010180d54 <pagecache_get_page+0x25c>
         : 1781             arch_atomic_fetch_add_unless():
         : 1158             * Returns original value of @v
         : 1159             */
         : 1160             static __always_inline int
         : 1161             arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
         : 1162             {
         : 1163             int c = arch_atomic_read(v);
    0.00 :   ffff800010180b90:       ldr     w5, [x0, #52]
         :
         : 1162             do {
         : 1163             if (unlikely(c == u))
    0.00 :   ffff800010180b94:       cbz     w5, ffff800010180b68 <pagecache_get_page+0x70>
    0.00 :   ffff800010180b98:       add     x28, x0, #0x34
    0.00 :   ffff800010180b9c:       nop
         : 1167             arch_atomic_try_cmpxchg():
         : 990              r = arch_atomic_cmpxchg(v, o, new);
    0.00 :   ffff800010180ba0:       sxtw    x1, w5
         : 992              arch_atomic_fetch_add_unless():
         : 1163             break;
         : 1164             } while (!arch_atomic_try_cmpxchg(v, &c, c + a));
    0.00 :   ffff800010180ba4:       add     w2, w5, #0x1
         : 1166             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010180ba8:       b       ffff800010180ca8 <pagecache_get_page+0x1b0>
    0.00 :   ffff800010180bac:       b       ffff800010180ca8 <pagecache_get_page+0x1b0>
         : 46               __lse__cmpxchg_case_mb_32():
         : 378              __CMPXCHG_CASE(w, h, rel_, 16,  l, "memory")
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
         : 381              __CMPXCHG_CASE(w, b,  mb_,  8, al, "memory")
         : 382              __CMPXCHG_CASE(w, h,  mb_, 16, al, "memory")
         : 383              __CMPXCHG_CASE(w,  ,  mb_, 32, al, "memory")
    0.00 :   ffff800010180bb0:       mov     x0, x28
    0.00 :   ffff800010180bb4:       mov     w3, w1
    0.00 :   ffff800010180bb8:       casal   w3, w2, [x28]
   51.23 :   ffff800010180bbc:       mov     w0, w3
         : 388              arch_atomic_try_cmpxchg():
         : 991              if (unlikely(r != o))
    0.00 :   ffff800010180bc0:       cmp     w0, w5
    0.00 :   ffff800010180bc4:       b.ne    ffff800010180c9c <pagecache_get_page+0x1a4>  // b.any
         : 994              xas_reload():
         : 1550             *
         : 1551             * Return: The entry at this location in the xarray.
         : 1552             */
         : 1553             static inline void *xas_reload(struct xa_state *xas)
         : 1554             {
         : 1555             struct xa_node *node = xas->xa_node;
    0.00 :   ffff800010180bc8:       ldr     x1, [sp, #144]
         : 1554             void *entry;
         : 1555             char offset;
         :
         : 1557             if (!node)
    0.00 :   ffff800010180bcc:       cbz     x1, ffff800010180d94 <pagecache_get_page+0x29c>
         : 1557             return xa_head(xas->xa);
         : 1558             if (IS_ENABLED(CONFIG_XARRAY_MULTI)) {
         : 1559             offset = (xas->xa_index >> node->shift) & XA_CHUNK_MASK;
    0.00 :   ffff800010180bd0:       ldr     x0, [sp, #128]
    0.00 :   ffff800010180bd4:       ldrb    w2, [x1]
    0.00 :   ffff800010180bd8:       lsr     x0, x0, x2
         : 1563             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff800010180bdc:       ubfiz   x0, x0, #3, #6
    0.00 :   ffff800010180be0:       add     x0, x0, #0x20
    0.00 :   ffff800010180be4:       add     x0, x1, x0
    0.00 :   ffff800010180be8:       ldr     x0, [x0, #8]
         : 1187             xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff800010180bec:       cmp     x0, #0xfd
         : 1251             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff800010180bf0:       and     x2, x0, #0x3
         : 171              xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff800010180bf4:       ccmp    x2, #0x2, #0x0, ls  // ls = plast
    0.00 :   ffff800010180bf8:       b.ne    ffff800010180c0c <pagecache_get_page+0x114>  // b.any
         : 1252             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff800010180bfc:       ubfx    x0, x0, #2, #8
    0.00 :   ffff800010180c00:       add     x0, x0, #0x4
    0.00 :   ffff800010180c04:       add     x0, x1, x0, lsl #3
    0.00 :   ffff800010180c08:       ldr     x0, [x0, #8]
         : 1187             mapping_get_entry():
         : 1789             if (unlikely(page != xas_reload(&xas))) {
    0.00 :   ffff800010180c0c:       cmp     x25, x0
    0.00 :   ffff800010180c10:       b.ne    ffff800010180da8 <pagecache_get_page+0x2b0>  // b.any
         : 1792             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010180c14:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              pagecache_get_page():
         : 1848             page = NULL;
         : 1849             }
         : 1850             if (!page)
         : 1851             goto no_page;
         :
         : 1853             if (fgp_flags & FGP_LOCK) {
    0.00 :   ffff800010180c18:       tbz     w19, #1, ffff800010180cb4 <pagecache_get_page+0x1bc>
         : 1855             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
   48.77 :   ffff800010180c1c:       ldr     x1, [x25, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010180c20:       sub     x0, x1, #0x1
    0.00 :   ffff800010180c24:       tst     x1, #0x1
    0.00 :   ffff800010180c28:       csel    x0, x0, x25, ne  // ne = any
         : 193              test_and_set_bit_lock():
         : 25               {
         : 26               long old;
         : 27               unsigned long mask = BIT_MASK(nr);
         :
         : 29               p += BIT_WORD(nr);
         : 30               if (READ_ONCE(*p) & mask)
    0.00 :   ffff800010180c2c:       ldr     x1, [x0]
         : 32               pagecache_get_page():
         : 1849             if (fgp_flags & FGP_NOWAIT) {
    0.00 :   ffff800010180c30:       tbz     w19, #5, ffff800010180df4 <pagecache_get_page+0x2fc>
         : 1851             test_and_set_bit_lock():
    0.00 :   ffff800010180c34:       tbz     w1, #0, ffff800010180e94 <pagecache_get_page+0x39c>
         : 26               compound_head():
         : 184              {
    0.00 :   ffff800010180c38:       ldr     x0, [x25, #8]
         :
    0.00 :   ffff800010180c3c:       tbnz    w0, #0, ffff800010180ef4 <pagecache_get_page+0x3fc>
         : 188              arch_static_branch_jump():
    0.00 :   ffff800010180c40:       b       ffff800010180f44 <pagecache_get_page+0x44c>
    0.00 :   ffff800010180c44:       b       ffff800010180f44 <pagecache_get_page+0x44c>
         : 40               __lse_atomic_sub_return():
         : 141              ATOMIC_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff800010180c48:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010180c4c:       neg     w0, w0
    0.00 :   ffff800010180c50:       ldaddal w0, w1, [x28]
    0.00 :   ffff800010180c54:       add     w0, w0, w1
         : 146              put_page():
         : 1242             put_devmap_managed_page(page);
         : 1243             return;
         : 1244             }
         :
         : 1246             if (put_page_testzero(page))
         : 1247             __put_page(page);
    0.00 :   ffff800010180c58:       cbnz    w0, ffff800010180e80 <pagecache_get_page+0x388>
         : 1243             }
    0.00 :   ffff800010180c5c:       mov     x0, x25
         : 1245             pagecache_get_page():
         : 1852             if (!trylock_page(page)) {
         : 1853             put_page(page);
         : 1854             return NULL;
    0.00 :   ffff800010180c60:       mov     x25, #0x0                       // #0
         : 1856             put_page():
    0.00 :   ffff800010180c64:       bl      ffff80001018d6f0 <__put_page>
         : 1244             pagecache_get_page():
         : 1913             if (page && (fgp_flags & FGP_FOR_MMAP))
         : 1914             unlock_page(page);
         : 1915             }
         :
         : 1917             return page;
         : 1918             }
    0.00 :   ffff800010180c68:       mov     x0, x25
    0.00 :   ffff800010180c6c:       ldr     x2, [sp, #168]
    0.00 :   ffff800010180c70:       ldr     x1, [x21]
    0.00 :   ffff800010180c74:       eor     x1, x2, x1
    0.00 :   ffff800010180c78:       cbnz    x1, ffff800010180f50 <pagecache_get_page+0x458>
    0.00 :   ffff800010180c7c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010180c80:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010180c84:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010180c88:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010180c8c:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010180c90:       ldp     x29, x30, [sp], #176
    0.00 :   ffff800010180c94:       autiasp
    0.00 :   ffff800010180c98:       ret
         : 1932             arch_atomic_fetch_add_unless():
         : 1161             if (unlikely(c == u))
    0.00 :   ffff800010180c9c:       mov     w5, w0
    0.00 :   ffff800010180ca0:       cbnz    w0, ffff800010180ba0 <pagecache_get_page+0xa8>
    0.00 :   ffff800010180ca4:       b       ffff800010180b68 <pagecache_get_page+0x70>
         : 1165             __ll_sc__cmpxchg_case_mb_32():
         : 313              __CMPXCHG_CASE(w, h, rel_, 16,        ,  , l, "memory", K)
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
         : 316              __CMPXCHG_CASE(w, b,  mb_,  8, dmb ish,  , l, "memory", K)
         : 317              __CMPXCHG_CASE(w, h,  mb_, 16, dmb ish,  , l, "memory", K)
         : 318              __CMPXCHG_CASE(w,  ,  mb_, 32, dmb ish,  , l, "memory", K)
    0.00 :   ffff800010180ca8:       and     x1, x1, #0xffffffff
    0.00 :   ffff800010180cac:       b       ffff800010184838 <generic_file_write_iter+0x6e0>
    0.00 :   ffff800010180cb0:       b       ffff800010180bc0 <pagecache_get_page+0xc8>
         : 322              pagecache_get_page():
         : 1867             if (fgp_flags & FGP_ACCESSED)
    0.00 :   ffff800010180cb4:       tbnz    w19, #0, ffff800010180dd8 <pagecache_get_page+0x2e0>
         : 1874             if (!(fgp_flags & FGP_HEAD))
    0.00 :   ffff800010180cb8:       tbnz    w19, #7, ffff800010180c68 <pagecache_get_page+0x170>
         : 1876             find_subpage():
         : 462              if (PageHuge(head))
    0.00 :   ffff800010180cbc:       mov     x0, x25
    0.00 :   ffff800010180cc0:       bl      ffff8000101ee070 <PageHuge>
    0.00 :   ffff800010180cc4:       cbnz    w0, ffff800010180c68 <pagecache_get_page+0x170>
         : 466              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010180cc8:       ldr     x0, [x25]
         : 113              thp_nr_pages():
         : 276              return 0;
         : 277              }
         :
         : 279              /**
         : 280              * thp_nr_pages - The number of regular pages in this huge page.
         : 281              * @page: The head page of a huge page.
    0.00 :   ffff800010180ccc:       tbz     w0, #16, ffff800010180c68 <pagecache_get_page+0x170>
         : 283              pagecache_get_page():
         : 1878             if (!page && (fgp_flags & FGP_CREAT)) {
    0.00 :   ffff800010180cd0:       adds    x25, x25, x27
    0.00 :   ffff800010180cd4:       b.ne    ffff800010180c68 <pagecache_get_page+0x170>  // b.any
    0.00 :   ffff800010180cd8:       tbz     w19, #2, ffff800010180e80 <pagecache_get_page+0x388>
         : 1880             if ((fgp_flags & FGP_WRITE) && mapping_can_writeback(mapping))
    0.00 :   ffff800010180cdc:       tbnz    w19, #3, ffff800010180d60 <pagecache_get_page+0x268>
         : 1883             gfp_mask &= ~__GFP_FS;
    0.00 :   ffff800010180ce0:       tst     x19, #0x10
    0.00 :   ffff800010180ce4:       and     w0, w20, #0xffffff7f
    0.00 :   ffff800010180ce8:       csel    w20, w0, w20, ne  // ne = any
         : 1885             page = __page_cache_alloc(gfp_mask);
    0.00 :   ffff800010180cec:       mov     w0, w20
    0.00 :   ffff800010180cf0:       bl      ffff80001017c770 <__page_cache_alloc>
    0.00 :   ffff800010180cf4:       mov     x25, x0
         : 1886             if (!page)
    0.00 :   ffff800010180cf8:       cbz     x0, ffff800010180e80 <pagecache_get_page+0x388>
         : 1889             if (WARN_ON_ONCE(!(fgp_flags & (FGP_LOCK | FGP_FOR_MMAP))))
    0.00 :   ffff800010180cfc:       mov     w0, #0x42                       // #66
    0.00 :   ffff800010180d00:       tst     w19, w0
    0.00 :   ffff800010180d04:       b.eq    ffff800010180de8 <pagecache_get_page+0x2f0>  // b.none
         : 1893             if (fgp_flags & FGP_ACCESSED)
    0.00 :   ffff800010180d08:       tbz     w19, #0, ffff800010180d28 <pagecache_get_page+0x230>
         : 1895             compound_head():
         : 184              {
    0.00 :   ffff800010180d0c:       ldr     x1, [x25, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010180d10:       sub     x0, x1, #0x1
    0.00 :   ffff800010180d14:       tst     x1, #0x1
    0.00 :   ffff800010180d18:       csel    x0, x0, x25, ne  // ne = any
         : 191              __set_bit():
         : 21               *p  |= mask;
    0.00 :   ffff800010180d1c:       ldr     x1, [x0]
    0.00 :   ffff800010180d20:       orr     x1, x1, #0x2
    0.00 :   ffff800010180d24:       str     x1, [x0]
         : 25               pagecache_get_page():
         : 1896             err = add_to_page_cache_lru(page, mapping, index, gfp_mask);
    0.00 :   ffff800010180d28:       mov     w3, w20
    0.00 :   ffff800010180d2c:       mov     x2, x22
    0.00 :   ffff800010180d30:       mov     x1, x23
    0.00 :   ffff800010180d34:       mov     x0, x25
    0.00 :   ffff800010180d38:       bl      ffff800010180a00 <add_to_page_cache_lru>
    0.00 :   ffff800010180d3c:       mov     w28, w0
         : 1897             if (unlikely(err)) {
    0.00 :   ffff800010180d40:       cbnz    w0, ffff800010180e44 <pagecache_get_page+0x34c>
         : 1908             if (page && (fgp_flags & FGP_FOR_MMAP))
    0.00 :   ffff800010180d44:       tbz     w19, #6, ffff800010180c68 <pagecache_get_page+0x170>
         : 1909             unlock_page(page);
    0.00 :   ffff800010180d48:       mov     x0, x25
    0.00 :   ffff800010180d4c:       bl      ffff80001017d860 <unlock_page>
    0.00 :   ffff800010180d50:       b       ffff800010180c68 <pagecache_get_page+0x170>
         : 1913             rcu_read_unlock():
    0.00 :   ffff800010180d54:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              pagecache_get_page():
         : 1841             if (fgp_flags & FGP_ENTRY)
    0.00 :   ffff800010180d58:       tbz     w19, #8, ffff800010180cd8 <pagecache_get_page+0x1e0>
    0.00 :   ffff800010180d5c:       b       ffff800010180c68 <pagecache_get_page+0x170>
         : 1880             if ((fgp_flags & FGP_WRITE) && mapping_can_writeback(mapping))
    0.00 :   ffff800010180d60:       ldr     x0, [x23]
         : 1882             inode_to_bdi():
         : 140              if (!inode)
    0.00 :   ffff800010180d64:       cbz     x0, ffff800010180eac <pagecache_get_page+0x3b4>
         : 142              sb_is_blkdev_sb():
         : 2804             extern void __init vfs_caches_init_early(void);
         : 2805             extern void __init vfs_caches_init(void);
         :
         : 2807             extern struct kmem_cache *names_cachep;
         :
         : 2809             #define __getname()             kmem_cache_alloc(names_cachep, GFP_KERNEL)
    0.00 :   ffff800010180d68:       adrp    x2, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
         : 2811             inode_to_bdi():
         :
         : 144              sb = inode->i_sb;
    0.00 :   ffff800010180d6c:       ldr     x1, [x0, #40]
         : 145              #ifdef CONFIG_BLOCK
         : 146              if (sb_is_blkdev_sb(sb))
    0.00 :   ffff800010180d70:       ldr     x2, [x2, #368]
    0.00 :   ffff800010180d74:       cmp     x1, x2
    0.00 :   ffff800010180d78:       b.eq    ffff800010180f20 <pagecache_get_page+0x428>  // b.none
         : 148              return I_BDEV(inode)->bd_bdi;
         : 149              #endif
         : 150              return sb->s_bdi;
    0.00 :   ffff800010180d7c:       ldr     x0, [x1, #208]
         : 152              mapping_can_writeback():
         : 161              long congestion_wait(int sync, long timeout);
         : 162              long wait_iff_congested(int sync, long timeout);
         :
         : 164              static inline bool mapping_can_writeback(struct address_space *mapping)
         : 165              {
         : 166              return inode_to_bdi(mapping->host)->capabilities & BDI_CAP_WRITEBACK;
    0.00 :   ffff800010180d80:       ldr     w1, [x0, #68]
         : 168              pagecache_get_page():
         : 1881             gfp_mask |= __GFP_WRITE;
    0.00 :   ffff800010180d84:       orr     w0, w20, #0x1000
    0.00 :   ffff800010180d88:       tst     x1, #0x1
    0.00 :   ffff800010180d8c:       csel    w20, w0, w20, ne  // ne = any
    0.00 :   ffff800010180d90:       b       ffff800010180ce0 <pagecache_get_page+0x1e8>
         : 1886             xas_reload():
         : 1555             return xa_head(xas->xa);
    0.00 :   ffff800010180d94:       ldr     x0, [sp, #120]
         : 1557             xa_head():
         : 1166             return rcu_dereference_check(xa->xa_head,
    0.00 :   ffff800010180d98:       ldr     x0, [x0, #8]
         : 1168             mapping_get_entry():
         : 1789             if (unlikely(page != xas_reload(&xas))) {
    0.00 :   ffff800010180d9c:       cmp     x25, x0
    0.00 :   ffff800010180da0:       b.eq    ffff800010180c14 <pagecache_get_page+0x11c>  // b.none
    0.00 :   ffff800010180da4:       nop
         : 1793             compound_head():
         : 184              {
    0.00 :   ffff800010180da8:       ldr     x0, [x25, #8]
         :
    0.00 :   ffff800010180dac:       tbnz    w0, #0, ffff800010180ee8 <pagecache_get_page+0x3f0>
         : 188              arch_static_branch_jump():
    0.00 :   ffff800010180db0:       b       ffff800010180eb4 <pagecache_get_page+0x3bc>
    0.00 :   ffff800010180db4:       b       ffff800010180eb4 <pagecache_get_page+0x3bc>
         : 40               __lse_atomic_sub_return():
    0.00 :   ffff800010180db8:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010180dbc:       neg     w0, w0
    0.00 :   ffff800010180dc0:       ldaddal w0, w1, [x28]
    0.00 :   ffff800010180dc4:       add     w0, w0, w1
         : 145              put_page():
         : 1242             __put_page(page);
    0.00 :   ffff800010180dc8:       cbnz    w0, ffff800010180b68 <pagecache_get_page+0x70>
         : 1243             }
    0.00 :   ffff800010180dcc:       mov     x0, x25
    0.00 :   ffff800010180dd0:       bl      ffff80001018d6f0 <__put_page>
    0.00 :   ffff800010180dd4:       b       ffff800010180b68 <pagecache_get_page+0x70>
         : 1247             pagecache_get_page():
         : 1868             mark_page_accessed(page);
    0.00 :   ffff800010180dd8:       mov     x0, x25
    0.00 :   ffff800010180ddc:       bl      ffff80001018ec70 <mark_page_accessed>
         : 1874             if (!(fgp_flags & FGP_HEAD))
    0.00 :   ffff800010180de0:       tbnz    w19, #7, ffff800010180c68 <pagecache_get_page+0x170>
    0.00 :   ffff800010180de4:       b       ffff800010180cbc <pagecache_get_page+0x1c4>
         : 1889             if (WARN_ON_ONCE(!(fgp_flags & (FGP_LOCK | FGP_FOR_MMAP))))
    0.00 :   ffff800010180de8:       brk     #0x800
         : 1890             fgp_flags |= FGP_LOCK;
    0.00 :   ffff800010180dec:       orr     w19, w19, #0x2
    0.00 :   ffff800010180df0:       b       ffff800010180d08 <pagecache_get_page+0x210>
         : 1893             test_and_set_bit_lock():
    0.00 :   ffff800010180df4:       tbz     w1, #0, ffff800010180ed0 <pagecache_get_page+0x3d8>
         : 26               lock_page():
         : 625              */
         : 626              static inline void lock_page(struct page *page)
         : 627              {
         : 628              might_sleep();
         : 629              if (!trylock_page(page))
         : 630              __lock_page(page);
    0.00 :   ffff800010180df8:       mov     x0, x25
    0.00 :   ffff800010180dfc:       bl      ffff80001017eb08 <__lock_page>
         : 633              pagecache_get_page():
         : 1859             if (unlikely(page->mapping != mapping)) {
    0.00 :   ffff800010180e00:       ldr     x0, [x25, #24]
    0.00 :   ffff800010180e04:       cmp     x0, x23
    0.00 :   ffff800010180e08:       b.eq    ffff800010180cb4 <pagecache_get_page+0x1bc>  // b.none
         : 1860             unlock_page(page);
    0.00 :   ffff800010180e0c:       mov     x0, x25
    0.00 :   ffff800010180e10:       bl      ffff80001017d860 <unlock_page>
         : 1863             compound_head():
         : 184              {
    0.00 :   ffff800010180e14:       ldr     x0, [x25, #8]
         :
    0.00 :   ffff800010180e18:       tbnz    w0, #0, ffff800010180f00 <pagecache_get_page+0x408>
         : 188              arch_static_branch_jump():
    0.00 :   ffff800010180e1c:       b       ffff800010180f38 <pagecache_get_page+0x440>
    0.00 :   ffff800010180e20:       b       ffff800010180f38 <pagecache_get_page+0x440>
         : 40               __lse_atomic_sub_return():
    0.00 :   ffff800010180e24:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010180e28:       neg     w0, w0
    0.00 :   ffff800010180e2c:       ldaddal w0, w1, [x28]
    0.00 :   ffff800010180e30:       add     w0, w0, w1
         : 145              put_page():
         : 1242             __put_page(page);
    0.00 :   ffff800010180e34:       cbnz    w0, ffff800010180b54 <pagecache_get_page+0x5c>
         : 1243             }
    0.00 :   ffff800010180e38:       mov     x0, x25
    0.00 :   ffff800010180e3c:       bl      ffff80001018d6f0 <__put_page>
    0.00 :   ffff800010180e40:       b       ffff800010180b54 <pagecache_get_page+0x5c>
         : 1247             compound_head():
         : 184              {
    0.00 :   ffff800010180e44:       ldr     x0, [x25, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010180e48:       sub     x2, x0, #0x1
    0.00 :   ffff800010180e4c:       tst     x0, #0x1
    0.00 :   ffff800010180e50:       csel    x25, x2, x25, ne  // ne = any
         : 191              page_ref_dec_and_test():
         : 148              return ret;
         : 149              }
         :
         : 151              static inline int page_ref_dec_and_test(struct page *page)
         : 152              {
         : 153              int ret = atomic_dec_and_test(&page->_refcount);
    0.00 :   ffff800010180e54:       add     x0, x25, #0x34
         : 155              arch_static_branch_jump():
    0.00 :   ffff800010180e58:       b       ffff800010180e88 <pagecache_get_page+0x390>
    0.00 :   ffff800010180e5c:       b       ffff800010180e88 <pagecache_get_page+0x390>
         : 40               __lse_atomic_sub_return():
    0.00 :   ffff800010180e60:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010180e64:       neg     w2, w2
    0.00 :   ffff800010180e68:       ldaddal w2, w3, [x0]
    0.00 :   ffff800010180e6c:       add     w2, w2, w3
         : 145              put_page():
         : 1242             __put_page(page);
    0.00 :   ffff800010180e70:       cbz     w2, ffff800010180f14 <pagecache_get_page+0x41c>
         : 1244             pagecache_get_page():
         : 1900             if (err == -EEXIST)
    0.00 :   ffff800010180e74:       cmn     w28, #0x11
    0.00 :   ffff800010180e78:       b.eq    ffff800010180b54 <pagecache_get_page+0x5c>  // b.none
    0.00 :   ffff800010180e7c:       nop
         : 1852             return NULL;
    0.00 :   ffff800010180e80:       mov     x25, #0x0                       // #0
    0.00 :   ffff800010180e84:       b       ffff800010180c68 <pagecache_get_page+0x170>
         : 1855             __ll_sc_atomic_sub_return():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010180e88:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010180e8c:       b       ffff800010184858 <generic_file_write_iter+0x700>
    0.00 :   ffff800010180e90:       b       ffff800010180e70 <pagecache_get_page+0x378>
         : 116              arch_static_branch_jump():
    0.00 :   ffff800010180e94:       b       ffff800010180ec4 <pagecache_get_page+0x3cc>
    0.00 :   ffff800010180e98:       b       ffff800010180ec4 <pagecache_get_page+0x3cc>
         : 40               __lse_atomic64_fetch_or_acquire():
         : 203              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff800010180e9c:       mov     x1, #0x1                        // #1
    0.00 :   ffff800010180ea0:       ldseta  x1, x1, [x0]
         : 206              pagecache_get_page():
         : 1850             if (!trylock_page(page)) {
    0.00 :   ffff800010180ea4:       tbz     w1, #0, ffff800010180e00 <pagecache_get_page+0x308>
    0.00 :   ffff800010180ea8:       b       ffff800010180c38 <pagecache_get_page+0x140>
         : 1853             inode_to_bdi():
         : 141              return &noop_backing_dev_info;
    0.00 :   ffff800010180eac:       ldr     x0, [sp, #104]
    0.00 :   ffff800010180eb0:       b       ffff800010180d80 <pagecache_get_page+0x288>
         : 144              __ll_sc_atomic_sub_return():
    0.00 :   ffff800010180eb4:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010180eb8:       b       ffff800010184874 <generic_file_write_iter+0x71c>
         : 114              put_page():
    0.00 :   ffff800010180ebc:       cbnz    w0, ffff800010180b68 <pagecache_get_page+0x70>
    0.00 :   ffff800010180ec0:       b       ffff800010180dcc <pagecache_get_page+0x2d4>
         : 1244             __ll_sc_atomic64_fetch_or_acquire():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010180ec4:       b       ffff800010184890 <generic_file_write_iter+0x738>
         : 224              pagecache_get_page():
    0.00 :   ffff800010180ec8:       tbz     w1, #0, ffff800010180e00 <pagecache_get_page+0x308>
    0.00 :   ffff800010180ecc:       b       ffff800010180c38 <pagecache_get_page+0x140>
         : 1852             arch_static_branch_jump():
    0.00 :   ffff800010180ed0:       b       ffff800010180f2c <pagecache_get_page+0x434>
    0.00 :   ffff800010180ed4:       b       ffff800010180f2c <pagecache_get_page+0x434>
         : 40               __lse_atomic64_fetch_or_acquire():
    0.00 :   ffff800010180ed8:       mov     x1, #0x1                        // #1
    0.00 :   ffff800010180edc:       ldseta  x1, x1, [x0]
         : 205              lock_page():
         : 624              if (!trylock_page(page))
    0.00 :   ffff800010180ee0:       tbz     w1, #0, ffff800010180e00 <pagecache_get_page+0x308>
    0.00 :   ffff800010180ee4:       b       ffff800010180df8 <pagecache_get_page+0x300>
         : 627              compound_head():
    0.00 :   ffff800010180ee8:       sub     x25, x0, #0x1
    0.00 :   ffff800010180eec:       add     x28, x0, #0x33
    0.00 :   ffff800010180ef0:       b       ffff800010180db0 <pagecache_get_page+0x2b8>
    0.00 :   ffff800010180ef4:       sub     x25, x0, #0x1
    0.00 :   ffff800010180ef8:       add     x28, x0, #0x33
    0.00 :   ffff800010180efc:       b       ffff800010180c40 <pagecache_get_page+0x148>
    0.00 :   ffff800010180f00:       sub     x25, x0, #0x1
    0.00 :   ffff800010180f04:       add     x28, x0, #0x33
    0.00 :   ffff800010180f08:       b       ffff800010180e1c <pagecache_get_page+0x324>
         : 196              rcu_read_unlock():
    0.00 :   ffff800010180f0c:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              pagecache_get_page():
         : 79               return (unsigned long)entry & 1;
    0.00 :   ffff800010180f10:       b       ffff800010180cd8 <pagecache_get_page+0x1e0>
         : 81               put_page():
         : 1243             }
    0.00 :   ffff800010180f14:       mov     x0, x25
    0.00 :   ffff800010180f18:       bl      ffff80001018d6f0 <__put_page>
    0.00 :   ffff800010180f1c:       b       ffff800010180e74 <pagecache_get_page+0x37c>
         : 1247             inode_to_bdi():
         : 146              return I_BDEV(inode)->bd_bdi;
    0.00 :   ffff800010180f20:       bl      ffff800010280d50 <I_BDEV>
    0.00 :   ffff800010180f24:       ldr     x0, [x0, #904]
    0.00 :   ffff800010180f28:       b       ffff800010180d80 <pagecache_get_page+0x288>
         : 150              __ll_sc_atomic64_fetch_or_acquire():
    0.00 :   ffff800010180f2c:       b       ffff8000101848a8 <generic_file_write_iter+0x750>
         : 223              lock_page():
    0.00 :   ffff800010180f30:       tbz     w1, #0, ffff800010180e00 <pagecache_get_page+0x308>
    0.00 :   ffff800010180f34:       b       ffff800010180df8 <pagecache_get_page+0x300>
         : 626              __ll_sc_atomic_sub_return():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010180f38:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010180f3c:       b       ffff8000101848c0 <generic_file_write_iter+0x768>
    0.00 :   ffff800010180f40:       b       ffff800010180e34 <pagecache_get_page+0x33c>
    0.00 :   ffff800010180f44:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010180f48:       b       ffff8000101848dc <generic_file_write_iter+0x784>
    0.00 :   ffff800010180f4c:       b       ffff800010180c58 <pagecache_get_page+0x160>
         : 119              pagecache_get_page():
         : 1913             }
    0.00 :   ffff800010180f50:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of libpthread-2.31.so for cycles (2 samples, percent: local period)
-------------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3     Disassembly of section .text:
         :
         : 5     0000000000013410 <__write>:
         : 6     __libc_write():
    0.00 :   13410:  stp     x29, x30, [sp, #-48]!
    0.00 :   13414:  mov     x29, sp
    0.00 :   13418:  stp     x21, x22, [sp, #32]
    0.00 :   1341c:  mrs     x22, tpidr_el0
    0.00 :   13420:  sub     x3, x22, #0x700
    0.00 :   13424:  stp     x19, x20, [sp, #16]
    0.00 :   13428:  sxtw    x19, w0
    0.00 :   1342c:  ldr     w0, [x3]
    0.00 :   13430:  cbnz    w0, 13460 <__write+0x50>
    0.00 :   13434:  mov     x0, x19
    0.00 :   13438:  mov     x8, #0x40                       // #64
    0.00 :   1343c:  svc     #0x0
    0.00 :   13440:  mov     x19, x0
    0.00 :   13444:  cmn     x0, #0x1, lsl #12
    0.00 :   13448:  b.hi    134ac <__write+0x9c>  // b.pmore
    0.00 :   1344c:  mov     x0, x19
    0.00 :   13450:  ldp     x19, x20, [sp, #16]
    0.00 :   13454:  ldp     x21, x22, [sp, #32]
    0.00 :   13458:  ldp     x29, x30, [sp], #48
    0.00 :   1345c:  ret
    0.00 :   13460:  mov     x21, x1
    0.00 :   13464:  mov     x20, x2
    0.00 :   13468:  bl      13030 <__pthread_enable_asynccancel>
    0.00 :   1346c:  mov     w3, w0
    0.00 :   13470:  mov     x1, x21
    0.00 :   13474:  mov     x0, x19
    0.00 :   13478:  mov     x2, x20
    0.00 :   1347c:  mov     x8, #0x40                       // #64
    0.00 :   13480:  svc     #0x0
  100.00 :   13484:  mov     x19, x0
    0.00 :   13488:  cmn     x0, #0x1, lsl #12
    0.00 :   1348c:  b.hi    134c4 <__write+0xb4>  // b.pmore
    0.00 :   13490:  mov     w0, w3
    0.00 :   13494:  bl      130d4 <__pthread_disable_asynccancel>
    0.00 :   13498:  mov     x0, x19
    0.00 :   1349c:  ldp     x19, x20, [sp, #16]
    0.00 :   134a0:  ldp     x21, x22, [sp, #32]
    0.00 :   134a4:  ldp     x29, x30, [sp], #48
    0.00 :   134a8:  ret
    0.00 :   134ac:  adrp    x0, 2b000 <__FRAME_END__+0xf9b8>
    0.00 :   134b0:  ldr     x0, [x0, #3976]
    0.00 :   134b4:  neg     w1, w19
    0.00 :   134b8:  mov     x19, #0xffffffffffffffff        // #-1
    0.00 :   134bc:  str     w1, [x22, x0]
    0.00 :   134c0:  b       1344c <__write+0x3c>
    0.00 :   134c4:  adrp    x0, 2b000 <__FRAME_END__+0xf9b8>
    0.00 :   134c8:  ldr     x0, [x0, #3976]
    0.00 :   134cc:  neg     w1, w19
    0.00 :   134d0:  mov     x19, #0xffffffffffffffff        // #-1
    0.00 :   134d4:  str     w1, [x22, x0]
    0.00 :   134d8:  b       13490 <__write+0x80>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102097f0 <kmem_cache_free>:
         : 6                kmem_cache_free():
         : 3179             static __always_inline void do_slab_free(struct kmem_cache *s,
         : 3180             struct page *page, void *head, void *tail,
         : 3181             int cnt, unsigned long addr)
         : 3182             {
         : 3183             void *tail_obj = tail ? : head;
         : 3184             struct kmem_cache_cpu *c;
    0.00 :   ffff8000102097f0:       paciasp
    0.00 :   ffff8000102097f4:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff8000102097f8:       mov     x29, sp
    0.00 :   ffff8000102097fc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010209800:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010209804:       add     x22, x22, #0x948
    0.00 :   ffff800010209808:       mov     x21, x1
    0.00 :   ffff80001020980c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010209810:       mov     x19, x0
    0.00 :   ffff800010209814:       ldr     x0, [x22]
    0.00 :   ffff800010209818:       str     x0, [sp, #88]
    0.00 :   ffff80001020981c:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010209820:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010209824:       mov     x23, x30
         : 3199             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010209828:       nop
         : 28               kmem_cache_free():
         : 3181             unsigned long tid;
         :
    0.00 :   ffff80001020982c:       cbz     x19, ffff800010209948 <kmem_cache_free+0x158>
    0.00 :   ffff800010209830:       mov     x20, #0x1000000000000           // #281474976710656
    0.00 :   ffff800010209834:       add     x20, x21, x20
    0.00 :   ffff800010209838:       mov     x0, #0xfffffc0000000000         // #-4398046511104
    0.00 :   ffff80001020983c:       lsr     x20, x20, #12
    0.00 :   ffff800010209840:       add     x20, x0, x20, lsl #6
         : 3189             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010209844:       ldr     x0, [x20, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010209848:       sub     x1, x0, #0x1
    0.00 :   ffff80001020984c:       tst     x0, #0x1
         : 192              kmem_cache_free():
         : 3183             memcg_slab_free_hook(s, &head, 1);
         : 3184             redo:
    0.00 :   ffff800010209850:       mov     x0, #0xffffffffffffffff         // #-1
         : 3186             compound_head():
   50.92 :   ffff800010209854:       csel    x20, x1, x20, ne  // ne = any
         : 188              kmem_cache_free():
    0.00 :   ffff800010209858:       adrp    x1, ffff800011f17000 <__boot_cpu_mode>
    0.00 :   ffff80001020985c:       ldr     x1, [x1, #16]
    0.00 :   ffff800010209860:       lsl     x0, x0, x1
    0.00 :   ffff800010209864:       tbz     x23, #55, ffff800010209970 <kmem_cache_free+0x180>
    0.00 :   ffff800010209868:       orr     x23, x23, x0
         : 3184             arch_static_branch():
    0.00 :   ffff80001020986c:       nop
         : 22               set_freepointer():
         : 312              void *p;
    0.00 :   ffff800010209870:       ldr     w0, [x19, #40]
         : 319              copy_from_kernel_nofault(&p, (void **)freepointer_addr, sizeof(p));
    0.00 :   ffff800010209874:       str     xzr, [x21, x0]
         : 321              slab_free():
         : 3167             * If fastpath is not possible then fall back to __slab_free where we deal
    0.00 :   ffff800010209878:       cbz     x21, ffff800010209948 <kmem_cache_free+0x158>
         : 3169             do_slab_free():
         :
    0.00 :   ffff80001020987c:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010209880:       add     x1, sp, #0x50
    0.00 :   ffff800010209884:       mov     x0, x19
    0.00 :   ffff800010209888:       str     x21, [sp, #80]
    0.00 :   ffff80001020988c:       bl      ffff800010203958 <memcg_slab_free_hook>
         : 3129             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010209890:       mrs     x2, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010209894:       ldr     w0, [x2, #8]
         : 47               pc += val;
    0.00 :   ffff800010209898:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff80001020989c:       str     w0, [x2, #8]
         : 50               do_slab_free():
         : 3132             * then add it.
    0.00 :   ffff8000102098a0:       ldr     x1, [x19]
    0.00 :   ffff8000102098a4:       add     x1, x1, #0x8
    0.00 :   ffff8000102098a8:       bl      ffff800010202198 <__kern_my_cpu_offset>
         : 3136             __percpu_read_64():
         : 125              __PERCPU_RET_OP_CASE( ,  , name, 64, op_llsc, op_lse)
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
    0.00 :   ffff8000102098ac:       ldr     x24, [x1, x0]
         : 132              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102098b0:       ldr     x0, [x2, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000102098b4:       sub     x0, x0, #0x1
    0.00 :   ffff8000102098b8:       str     w0, [x2, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102098bc:       cbnz    x0, ffff80001020997c <kmem_cache_free+0x18c>
         : 80               do_slab_free():
    0.00 :   ffff8000102098c0:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff8000102098c4:       nop
         : 3133             */
   49.08 :   ffff8000102098c8:       ldr     x2, [x19]
    0.00 :   ffff8000102098cc:       bl      ffff800010202198 <__kern_my_cpu_offset>
    0.00 :   ffff8000102098d0:       add     x1, x2, x0
         : 3135             remove_full(s, n, page);
    0.00 :   ffff8000102098d4:       ldr     x3, [x1, #8]
    0.00 :   ffff8000102098d8:       cmp     x3, x24
    0.00 :   ffff8000102098dc:       b.ne    ffff800010209890 <kmem_cache_free+0xa0>  // b.any
         : 3140             return;
    0.00 :   ffff8000102098e0:       ldr     x1, [x1, #16]
    0.00 :   ffff8000102098e4:       cmp     x1, x20
    0.00 :   ffff8000102098e8:       b.ne    ffff800010209a8c <kmem_cache_free+0x29c>  // b.any
         : 3144             set_freepointer():
         : 312              void *p;
    0.00 :   ffff8000102098ec:       ldr     w1, [x19, #40]
         : 314              do_slab_free():
         :
    0.00 :   ffff8000102098f0:       ldr     x5, [x2, x0]
         : 3143             get_current():
    0.00 :   ffff8000102098f4:       mrs     x7, sp_el0
         : 20               set_freepointer():
         : 319              copy_from_kernel_nofault(&p, (void **)freepointer_addr, sizeof(p));
    0.00 :   ffff8000102098f8:       str     x5, [x21, x1]
         : 321              __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000102098fc:       ldr     w0, [x7, #8]
         : 47               pc += val;
    0.00 :   ffff800010209900:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010209904:       str     w0, [x7, #8]
         : 50               do_slab_free():
         : 3145             * Slab on the partial list.
    0.00 :   ffff800010209908:       ldr     x4, [x19]
    0.00 :   ffff80001020990c:       bl      ffff800010202198 <__kern_my_cpu_offset>
    0.00 :   ffff800010209910:       ldr     x2, [sp, #80]
    0.00 :   ffff800010209914:       add     x3, x24, #0x100
    0.00 :   ffff800010209918:       mov     x1, x24
    0.00 :   ffff80001020991c:       add     x4, x4, x0
    0.00 :   ffff800010209920:       mov     x0, x5
    0.00 :   ffff800010209924:       bl      ffff800010203920 <__cmpxchg_double>
         : 3154             __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010209928:       ldr     x1, [x7, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001020992c:       sub     x1, x1, #0x1
    0.00 :   ffff800010209930:       str     w1, [x7, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010209934:       cbnz    x1, ffff800010209a44 <kmem_cache_free+0x254>
    0.00 :   ffff800010209938:       str     x0, [sp, #72]
         : 76               do_slab_free():
    0.00 :   ffff80001020993c:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010209940:       ldr     x0, [sp, #72]
    0.00 :   ffff800010209944:       cbnz    x0, ffff800010209890 <kmem_cache_free+0xa0>
         : 3148             kmem_cache_free():
         : 3185             /*
         : 3186             * Determine the currently cpus per cpu slab.
    0.00 :   ffff800010209948:       ldr     x1, [sp, #88]
    0.00 :   ffff80001020994c:       ldr     x0, [x22]
    0.00 :   ffff800010209950:       eor     x0, x1, x0
    0.00 :   ffff800010209954:       cbnz    x0, ffff800010209ae0 <kmem_cache_free+0x2f0>
    0.00 :   ffff800010209958:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001020995c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010209960:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010209964:       ldp     x29, x30, [sp], #96
    0.00 :   ffff800010209968:       autiasp
    0.00 :   ffff80001020996c:       ret
         : 3183             redo:
    0.00 :   ffff800010209970:       and     x0, x0, #0x7fffffffffffff
    0.00 :   ffff800010209974:       bic     x23, x23, x0
    0.00 :   ffff800010209978:       b       ffff80001020986c <kmem_cache_free+0x7c>
         : 3187             __preempt_count_dec_and_test():
    0.00 :   ffff80001020997c:       ldr     x0, [x2, #8]
    0.00 :   ffff800010209980:       cbnz    x0, ffff8000102098c8 <kmem_cache_free+0xd8>
         : 75               do_slab_free():
         : 3132             * then add it.
    0.00 :   ffff800010209984:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010209988:       b       ffff8000102098c8 <kmem_cache_free+0xd8>
         : 3135             slab_want_init_on_free():
         : 628              struct kmem_obj_info {
         : 629              void *kp_ptr;
         : 630              struct page *kp_page;
         : 631              void *kp_objp;
         : 632              unsigned long kp_data_offset;
         : 633              struct kmem_cache *kp_slab_cache;
    0.00 :   ffff80001020998c:       ldr     x0, [x19, #72]
    0.00 :   ffff800010209990:       cbnz    x0, ffff800010209870 <kmem_cache_free+0x80>
         : 629              void *kp_ret;
    0.00 :   ffff800010209994:       ldr     w0, [x19, #8]
    0.00 :   ffff800010209998:       and     w0, w0, #0xff800
    0.00 :   ffff80001020999c:       and     w0, w0, #0xfff80fff
         : 628              struct kmem_cache *kp_slab_cache;
    0.00 :   ffff8000102099a0:       cbnz    w0, ffff800010209870 <kmem_cache_free+0x80>
         : 630              slab_free_hook():
         : 1576             #endif /* CONFIG_SLUB_DEBUG */
    0.00 :   ffff8000102099a4:       ldr     w2, [x19, #28]
    0.00 :   ffff8000102099a8:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000102099ac:       mov     x0, x21
    0.00 :   ffff8000102099b0:       bl      ffff8000104a5e40 <__memset>
         :
    0.00 :   ffff8000102099b4:       ldr     w0, [x19, #8]
    0.00 :   ffff8000102099b8:       and     w3, w0, #0x400
    0.00 :   ffff8000102099bc:       tbz     w0, #10, ffff8000102099c4 <kmem_cache_free+0x1d4>
    0.00 :   ffff8000102099c0:       ldr     w3, [x19, #88]
         : 1578             /*
    0.00 :   ffff8000102099c4:       ldr     w0, [x19, #80]
    0.00 :   ffff8000102099c8:       mov     w1, #0x0                        // #0
         : 1579             * Hooks for other subsystems that check memory allocations. In a typical
    0.00 :   ffff8000102099cc:       ldr     w2, [x19, #24]
    0.00 :   ffff8000102099d0:       sub     w2, w2, w0
         : 1578             /*
    0.00 :   ffff8000102099d4:       add     x0, x21, w0, uxtw
    0.00 :   ffff8000102099d8:       sub     w2, w2, w3
    0.00 :   ffff8000102099dc:       bl      ffff8000104a5e40 <__memset>
    0.00 :   ffff8000102099e0:       b       ffff800010209870 <kmem_cache_free+0x80>
         : 1583             kmem_cache_debug_flags():
         : 234              if (static_branch_unlikely(&slub_debug_enabled))
    0.00 :   ffff8000102099e4:       ldr     w0, [x19, #8]
         : 236              cache_from_obj():
         : 449              static inline size_t slab_ksize(const struct kmem_cache *s)
    0.00 :   ffff8000102099e8:       tbz     w0, #8, ffff80001020982c <kmem_cache_free+0x3c>
         : 451              virt_to_head_page():
         : 897              #endif
         :
         : 899              static inline struct page *virt_to_head_page(const void *x)
         : 900              {
         : 901              struct page *page = virt_to_page(x);
         :
    0.00 :   ffff8000102099ec:       mov     x20, #0x1000000000000           // #281474976710656
    0.00 :   ffff8000102099f0:       add     x20, x1, x20
    0.00 :   ffff8000102099f4:       mov     x0, #0xfffffc0000000000         // #-4398046511104
    0.00 :   ffff8000102099f8:       lsr     x20, x20, #12
    0.00 :   ffff8000102099fc:       add     x20, x0, x20, lsl #6
         : 908              compound_head():
         : 184              {
    0.00 :   ffff800010209a00:       ldr     x1, [x20, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010209a04:       sub     x0, x1, #0x1
    0.00 :   ffff800010209a08:       tst     x1, #0x1
    0.00 :   ffff800010209a0c:       csel    x0, x0, x20, ne  // ne = any
         : 184              {
    0.00 :   ffff800010209a10:       ldr     x2, [x0, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010209a14:       sub     x1, x2, #0x1
    0.00 :   ffff800010209a18:       tst     x2, #0x1
    0.00 :   ffff800010209a1c:       csel    x1, x1, x0, ne  // ne = any
         : 191              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010209a20:       ldr     x1, [x1]
         : 113              virt_to_cache():
         :
    0.00 :   ffff800010209a24:       tst     w1, #0x200
    0.00 :   ffff800010209a28:       b.eq    ffff800010209aac <kmem_cache_free+0x2bc>  // b.none
         : 421              }
    0.00 :   ffff800010209a2c:       ldr     x24, [x0, #24]
         : 423              cache_from_obj():
         : 454              #else /* CONFIG_SLUB */
    0.00 :   ffff800010209a30:       cmp     x24, #0x0
    0.00 :   ffff800010209a34:       ccmp    x19, x24, #0x4, ne  // ne = any
    0.00 :   ffff800010209a38:       b.ne    ffff800010209a54 <kmem_cache_free+0x264>  // b.any
         : 458              virt_to_cache():
         : 421              }
    0.00 :   ffff800010209a3c:       mov     x19, x24
    0.00 :   ffff800010209a40:       b       ffff80001020982c <kmem_cache_free+0x3c>
         : 424              __preempt_count_dec_and_test():
    0.00 :   ffff800010209a44:       ldr     x1, [x7, #8]
    0.00 :   ffff800010209a48:       cbz     x1, ffff800010209938 <kmem_cache_free+0x148>
         : 75               do_slab_free():
         : 3145             * Slab on the partial list.
    0.00 :   ffff800010209a4c:       cbz     x0, ffff800010209948 <kmem_cache_free+0x158>
    0.00 :   ffff800010209a50:       b       ffff800010209890 <kmem_cache_free+0xa0>
         : 3148             cache_from_obj():
         : 454              #else /* CONFIG_SLUB */
    0.00 :   ffff800010209a54:       ldr     x2, [x19, #96]
    0.00 :   ffff800010209a58:       adrp    x1, ffff800010e7e000 <pageflag_names+0x98>
    0.00 :   ffff800010209a5c:       ldr     x3, [x24, #96]
    0.00 :   ffff800010209a60:       add     x1, x1, #0xc68
    0.00 :   ffff800010209a64:       add     x1, x1, #0x50
    0.00 :   ffff800010209a68:       adrp    x0, ffff80001142a000 <kallsyms_token_index+0x1f7a0>
    0.00 :   ffff800010209a6c:       add     x0, x0, #0x7b0
    0.00 :   ffff800010209a70:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff800010209a74:       brk     #0x800
         : 457              * Debugging requires use of the padding between object
    0.00 :   ffff800010209a78:       mov     x1, x21
    0.00 :   ffff800010209a7c:       mov     x0, x24
    0.00 :   ffff800010209a80:       mov     x19, x24
    0.00 :   ffff800010209a84:       bl      ffff800010204da8 <print_tracking>
         : 462              kmem_cache_free():
         :
    0.00 :   ffff800010209a88:       b       ffff800010209844 <kmem_cache_free+0x54>
         : 3183             do_slab_free():
         : 3155             stat(s, FREE_SLAB);
    0.00 :   ffff800010209a8c:       ldr     x2, [sp, #80]
    0.00 :   ffff800010209a90:       mov     x5, x23
    0.00 :   ffff800010209a94:       mov     x3, x21
    0.00 :   ffff800010209a98:       mov     x1, x20
    0.00 :   ffff800010209a9c:       mov     x0, x19
    0.00 :   ffff800010209aa0:       mov     w4, #0x1                        // #1
    0.00 :   ffff800010209aa4:       bl      ffff800010205dd8 <__slab_free>
         : 3163             kmem_cache_free():
         : 3184             /*
    0.00 :   ffff800010209aa8:       b       ffff800010209948 <kmem_cache_free+0x158>
         : 3186             virt_to_cache():
         :
    0.00 :   ffff800010209aac:       adrp    x2, ffff800011efe000 <errmap+0xc38>
    0.00 :   ffff800010209ab0:       ldrb    w0, [x2, #2838]
    0.00 :   ffff800010209ab4:       cbnz    w0, ffff800010209948 <kmem_cache_free+0x158>
    0.00 :   ffff800010209ab8:       mov     w3, #0x1                        // #1
    0.00 :   ffff800010209abc:       adrp    x1, ffff800010e7e000 <pageflag_names+0x98>
    0.00 :   ffff800010209ac0:       add     x1, x1, #0xc68
    0.00 :   ffff800010209ac4:       strb    w3, [x2, #2838]
    0.00 :   ffff800010209ac8:       add     x1, x1, #0x40
    0.00 :   ffff800010209acc:       adrp    x0, ffff80001142a000 <kallsyms_token_index+0x1f7a0>
    0.00 :   ffff800010209ad0:       add     x0, x0, #0x790
    0.00 :   ffff800010209ad4:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff800010209ad8:       brk     #0x800
         : 431              kmem_cache_free():
         :
    0.00 :   ffff800010209adc:       b       ffff800010209948 <kmem_cache_free+0x158>
         : 3185             * Determine the currently cpus per cpu slab.
    0.00 :   ffff800010209ae0:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102f20c8 <__ext4_journal_stop>:
         : 6                __ext4_journal_stop():
         : 110              return jbd2__journal_start(journal, blocks, rsv_blocks, revoke_creds,
         : 111              GFP_NOFS, type, line);
         : 112              }
         :
         : 114              int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)
         : 115              {
    0.00 :   ffff8000102f20c8:       paciasp
    0.00 :   ffff8000102f20cc:       stp     x29, x30, [sp, #-48]!
         : 118              ext4_handle_valid():
         :
         : 270              /* Note:  Do not use this for NULL handles.  This is only to determine if
         : 271              * a properly allocated handle is using a journal or not. */
         : 272              static inline int ext4_handle_valid(handle_t *handle)
         : 273              {
         : 274              if ((unsigned long)handle < EXT4_NOJOURNAL_MAX_REF_COUNT)
    0.00 :   ffff8000102f20d0:       cmp     x2, #0xfff
         : 276              __ext4_journal_stop():
    0.00 :   ffff8000102f20d4:       mov     x29, sp
         : 111              ext4_handle_valid():
    0.00 :   ffff8000102f20d8:       b.ls    ffff8000102f2124 <__ext4_journal_stop+0x5c>  // b.plast
         : 270              __ext4_journal_stop():
         : 120              if (!ext4_handle_valid(handle)) {
         : 121              ext4_put_nojournal(handle);
         : 122              return 0;
         : 123              }
         :
         : 125              err = handle->h_err;
    0.00 :   ffff8000102f20dc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000102f20e0:       mov     w20, w1
    0.00 :   ffff8000102f20e4:       mov     x19, x0
    0.00 :   ffff8000102f20e8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000102f20ec:       mov     x0, x2
         : 121              if (!handle->h_transaction) {
    0.00 :   ffff8000102f20f0:       ldr     x1, [x2]
         : 120              err = handle->h_err;
    0.00 :   ffff8000102f20f4:       ldr     w21, [x2, #32]
         : 121              if (!handle->h_transaction) {
    0.00 :   ffff8000102f20f8:       cbz     x1, ffff8000102f2174 <__ext4_journal_stop+0xac>
         : 126              rc = jbd2_journal_stop(handle);
         : 127              return err ? err : rc;
         : 128              }
         :
         : 130              sb = handle->h_transaction->t_journal->j_private;
   50.97 :   ffff8000102f20fc:       ldr     x1, [x1]
    0.00 :   ffff8000102f2100:       ldr     x22, [x1, #1304]
         : 127              rc = jbd2_journal_stop(handle);
    0.00 :   ffff8000102f2104:       bl      ffff800010354718 <jbd2_journal_stop>
         :
         : 130              if (!err)
    0.00 :   ffff8000102f2108:       cbnz    w21, ffff8000102f2148 <__ext4_journal_stop+0x80>
         : 131              err = rc;
         : 132              if (err)
    0.00 :   ffff8000102f210c:       cbnz    w0, ffff8000102f2144 <__ext4_journal_stop+0x7c>
    0.00 :   ffff8000102f2110:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102f2114:       ldp     x21, x22, [sp, #32]
         : 134              __ext4_std_error(sb, where, line, err);
         : 135              return err;
         : 136              }
    0.00 :   ffff8000102f2118:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102f211c:       autiasp
   49.03 :   ffff8000102f2120:       ret
         : 140              ext4_put_nojournal():
         : 53               BUG_ON(ref_cnt == 0);
    0.00 :   ffff8000102f2124:       cbz     x2, ffff8000102f2194 <__ext4_journal_stop+0xcc>
         : 55               ref_cnt--;
    0.00 :   ffff8000102f2128:       sub     x2, x2, #0x1
         : 57               __ext4_journal_stop():
         : 117              return 0;
    0.00 :   ffff8000102f212c:       mov     w0, #0x0                        // #0
         : 119              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000102f2130:       mrs     x1, sp_el0
         : 26               ext4_put_nojournal():
         : 58               current->journal_info = handle;
    0.00 :   ffff8000102f2134:       str     x2, [x1, #1824]
         : 60               __ext4_journal_stop():
         : 134              }
    0.00 :   ffff8000102f2138:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102f213c:       autiasp
    0.00 :   ffff8000102f2140:       ret
    0.00 :   ffff8000102f2144:       mov     w21, w0
         : 132              __ext4_std_error(sb, where, line, err);
    0.00 :   ffff8000102f2148:       mov     w2, w20
    0.00 :   ffff8000102f214c:       mov     x1, x19
    0.00 :   ffff8000102f2150:       mov     x0, x22
    0.00 :   ffff8000102f2154:       mov     w3, w21
    0.00 :   ffff8000102f2158:       bl      ffff800010337a98 <__ext4_std_error>
    0.00 :   ffff8000102f215c:       mov     w0, w21
    0.00 :   ffff8000102f2160:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102f2164:       ldp     x21, x22, [sp, #32]
         : 134              }
    0.00 :   ffff8000102f2168:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102f216c:       autiasp
    0.00 :   ffff8000102f2170:       ret
         : 122              rc = jbd2_journal_stop(handle);
    0.00 :   ffff8000102f2174:       bl      ffff800010354718 <jbd2_journal_stop>
         : 123              return err ? err : rc;
    0.00 :   ffff8000102f2178:       cmp     w21, #0x0
    0.00 :   ffff8000102f217c:       csel    w0, w0, w21, eq  // eq = none
    0.00 :   ffff8000102f2180:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102f2184:       ldp     x21, x22, [sp, #32]
         : 134              }
    0.00 :   ffff8000102f2188:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102f218c:       autiasp
    0.00 :   ffff8000102f2190:       ret
         : 138              ext4_put_nojournal():
         : 53               BUG_ON(ref_cnt == 0);
    0.00 :   ffff8000102f2194:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000102f2198:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000102f219c:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101d0ab0 <is_vmalloc_addr>:
         : 6                is_vmalloc_addr():
         : 62               static const bool vmap_allow_huge = false;
         : 63               #endif  /* CONFIG_HAVE_ARCH_HUGE_VMALLOC */
         :
         : 65               bool is_vmalloc_addr(const void *x)
         : 66               {
         : 67               unsigned long addr = (unsigned long)x;
   50.10 :   ffff8000101d0ab0:       mov     x1, #0x7ffff0000000             // #140737219919872
    0.00 :   ffff8000101d0ab4:       add     x0, x0, x1
    0.00 :   ffff8000101d0ab8:       mov     w1, #0xdfffffff                 // #-536870913
         :
    0.00 :   ffff8000101d0abc:       paciasp
         : 62               unsigned long addr = (unsigned long)x;
   49.90 :   ffff8000101d0ac0:       movk    x1, #0x7bff, lsl #32
    0.00 :   ffff8000101d0ac4:       cmp     x0, x1
         :
    0.00 :   ffff8000101d0ac8:       cset    w0, ls  // ls = plast
    0.00 :   ffff8000101d0acc:       autiasp
    0.00 :   ffff8000101d0ad0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101125d8 <timekeeping_advance>:
         : 6                timekeeping_advance():
         : 2129             /*
         : 2130             * timekeeping_advance - Updates the timekeeper to the current time and
         : 2131             * current NTP tick length
         : 2132             */
         : 2133             static void timekeeping_advance(enum timekeeping_adv_mode mode)
         : 2134             {
    0.00 :   ffff8000101125d8:       paciasp
    0.00 :   ffff8000101125dc:       stp     x29, x30, [sp, #-144]!
    0.00 :   ffff8000101125e0:       mov     x29, sp
    0.00 :   ffff8000101125e4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101125e8:       mov     w19, w0
    0.00 :   ffff8000101125ec:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101125f0:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000101125f4:       adrp    x25, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101125f8:       add     x1, x25, #0x948
         : 2137             u64 offset;
         : 2138             int shift = 0, maxshift;
         : 2139             unsigned int clock_set = 0;
         : 2140             unsigned long flags;
         :
         : 2142             raw_spin_lock_irqsave(&timekeeper_lock, flags);
    0.00 :   ffff8000101125fc:       adrp    x26, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010112600:       add     x20, x26, #0xf00
         : 2129             {
    0.00 :   ffff800010112604:       ldr     x0, [x1]
    0.00 :   ffff800010112608:       str     x0, [sp, #136]
    0.00 :   ffff80001011260c:       mov     x0, #0x0                        // #0
         : 2137             raw_spin_lock_irqsave(&timekeeper_lock, flags);
    0.00 :   ffff800010112610:       add     x21, x20, #0x128
    0.00 :   ffff800010112614:       mov     x0, x21
         : 2129             {
    0.00 :   ffff800010112618:       str     x1, [sp, #96]
         : 2137             raw_spin_lock_irqsave(&timekeeper_lock, flags);
    0.00 :   ffff80001011261c:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff800010112620:       str     x0, [sp, #104]
         :
         : 2141             /* Make sure we're fully resumed: */
         : 2142             if (unlikely(timekeeping_suspended))
    0.00 :   ffff800010112624:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010112628:       ldr     w0, [x0, #3068]
    0.00 :   ffff80001011262c:       cbnz    w0, ffff800010112a70 <timekeeping_advance+0x498>
         : 2146             tk_clock_read():
         : 191              struct clocksource *clock = READ_ONCE(tkr->clock);
    0.00 :   ffff800010112630:       ldr     x1, [x20, #312]
         : 193              return clock->read(clock);
    0.00 :   ffff800010112634:       stp     x27, x28, [sp, #80]
         : 191              struct clocksource *clock = READ_ONCE(tkr->clock);
    0.00 :   ffff800010112638:       add     x22, x20, #0x138
         : 193              return clock->read(clock);
    0.00 :   ffff80001011263c:       mov     x0, x1
         : 195              timekeeping_advance():
         :
         : 2148             offset = clocksource_delta(tk_clock_read(&tk->tkr_mono),
         : 2149             tk->tkr_mono.cycle_last, tk->tkr_mono.mask);
         :
         : 2151             /* Check if there's really nothing to do */
         : 2152             if (offset < real_tk->cycle_interval && mode == TK_ADV_TICK)
    0.00 :   ffff800010112640:       eor     w19, w19, #0x1
         : 2154             tk_clock_read():
         : 193              return clock->read(clock);
    0.00 :   ffff800010112644:       ldr     x1, [x1]
    0.00 :   ffff800010112648:       blr     x1
         : 196              clocksource_delta():
         : 32               return ret & ~(mask >> 1) ? 0 : ret;
         : 33               }
         : 34               #else
         : 35               static inline u64 clocksource_delta(u64 now, u64 last, u64 mask)
         : 36               {
         : 37               return (now - last) & mask;
    0.00 :   ffff80001011264c:       ldp     x4, x1, [x22, #8]
    0.00 :   ffff800010112650:       sub     x0, x0, x1
         : 40               timekeeping_advance():
         : 2147             if (offset < real_tk->cycle_interval && mode == TK_ADV_TICK)
    0.00 :   ffff800010112654:       ldr     x1, [x20, #224]
         : 2149             clocksource_delta():
    0.00 :   ffff800010112658:       and     x28, x0, x4
         : 33               timekeeping_advance():
    0.00 :   ffff80001011265c:       cmp     x1, x28
    0.00 :   ffff800010112660:       cset    w0, hi  // hi = pmore
    0.00 :   ffff800010112664:       tst     w19, w0
    0.00 :   ffff800010112668:       b.ne    ffff800010112a5c <timekeeping_advance+0x484>  // b.any
         : 2151             fls64():
         : 29               return fls(x);
         : 30               }
         : 31               #elif BITS_PER_LONG == 64
         : 32               static __always_inline int fls64(__u64 x)
         : 33               {
         : 34               if (x == 0)
    0.00 :   ffff80001011266c:       stp     x23, x24, [sp, #48]
         : 31               return 0;
         : 32               return __fls(x) + 1;
    0.00 :   ffff800010112670:       clz     x0, x28
    0.00 :   ffff800010112674:       mov     x21, #0x3f                      // #63
         : 35               timekeeping_advance():
         : 2161             * we calculate the largest doubling multiple of cycle_intervals
         : 2162             * that is smaller than the offset.  We then accumulate that
         : 2163             * chunk in one go, and then try to consume the next smaller
         : 2164             * doubled multiple.
         : 2165             */
         : 2166             shift = ilog2(offset) - ilog2(tk->cycle_interval);
    0.00 :   ffff800010112678:       ldr     x2, [x22, #216]
         : 2168             fls64():
    0.00 :   ffff80001011267c:       cmp     x28, #0x0
    0.00 :   ffff800010112680:       sub     x0, x21, x0
         : 33               accumulate_nsecs_to_secs():
         : 2043             u64 nsecps = (u64)NSEC_PER_SEC << tk->tkr_mono.shift;
    0.00 :   ffff800010112684:       mov     x24, #0xca00                    // #51712
    0.00 :   ffff800010112688:       clz     x1, x2
         : 2046             fls64():
    0.00 :   ffff80001011268c:       csinc   w0, wzr, w0, eq  // eq = none
    0.00 :   ffff800010112690:       sub     x1, x21, x1
    0.00 :   ffff800010112694:       cmp     x2, #0x0
    0.00 :   ffff800010112698:       add     w1, w1, #0x1
         : 35               accumulate_nsecs_to_secs():
    0.00 :   ffff80001011269c:       movk    x24, #0x3b9a, lsl #16
    0.00 :   ffff8000101126a0:       sub     w1, w0, w1
         : 2045             timekeeping_advance():
         : 2134             unsigned int clock_set = 0;
    0.00 :   ffff8000101126a4:       mov     w23, #0x0                       // #0
    0.00 :   ffff8000101126a8:       csel    w0, w1, w0, ne  // ne = any
         : 2162             shift = max(0, shift);
    0.00 :   ffff8000101126ac:       cmp     w0, #0x0
    0.00 :   ffff8000101126b0:       csel    w27, w0, wzr, ge  // ge = tcont
         : 2164             /* Bound shift to one less than what overflows tick_length */
         : 2165             maxshift = (64 - (ilog2(ntp_tick_length())+1)) - 1;
    0.00 :   ffff8000101126b4:       bl      ffff8000101139a0 <ntp_tick_length>
         : 2167             fls64():
         : 29               if (x == 0)
    0.00 :   ffff8000101126b8:       clz     x1, x0
    0.00 :   ffff8000101126bc:       sub     x3, x21, x1
    0.00 :   ffff8000101126c0:       cmp     x0, #0x0
    0.00 :   ffff8000101126c4:       add     w3, w3, #0x1
    0.00 :   ffff8000101126c8:       sub     w3, w21, w3
    0.00 :   ffff8000101126cc:       ldr     x5, [x22, #216]
    0.00 :   ffff8000101126d0:       csel    w3, w21, w3, eq  // eq = none
         : 37               timekeeping_advance():
         : 2165             shift = min(shift, maxshift);
    0.00 :   ffff8000101126d4:       cmp     w27, w3
    0.00 :   ffff8000101126d8:       csel    w27, w27, w3, le
         : 2166             while (offset >= tk->cycle_interval) {
    0.00 :   ffff8000101126dc:       cmp     x28, x5
    0.00 :   ffff8000101126e0:       b.cc    ffff800010112804 <timekeeping_advance+0x22c>  // b.lo, b.ul, b.last
    0.00 :   ffff8000101126e4:       nop
         : 2170             logarithmic_accumulation():
         : 2093             u64 interval = tk->cycle_interval << shift;
    0.00 :   ffff8000101126e8:       lsl     x0, x5, x27
         : 2097             if (offset < interval)
    0.00 :   ffff8000101126ec:       cmp     x28, x0
    0.00 :   ffff8000101126f0:       b.cc    ffff8000101127f0 <timekeeping_advance+0x218>  // b.lo, b.ul, b.last
         : 2105             tk->tkr_mono.xtime_nsec += tk->xtime_interval << shift;
    0.00 :   ffff8000101126f4:       ldr     x1, [x20, #536]
         : 2102             tk->tkr_mono.cycle_last += interval;
    0.00 :   ffff8000101126f8:       add     x2, x20, #0x138
         : 2104             accumulate_nsecs_to_secs():
         : 2043             u64 nsecps = (u64)NSEC_PER_SEC << tk->tkr_mono.shift;
    0.00 :   ffff8000101126fc:       ldr     w21, [x20, #340]
         : 2049             tk->tkr_mono.xtime_nsec -= nsecps;
    0.00 :   ffff800010112700:       mov     x19, x2
         : 2051             logarithmic_accumulation():
         : 2102             tk->tkr_mono.cycle_last += interval;
    0.00 :   ffff800010112704:       ldr     x6, [x20, #328]
         : 2101             offset -= interval;
    0.00 :   ffff800010112708:       sub     x28, x28, x0
         : 2105             tk->tkr_mono.xtime_nsec += tk->xtime_interval << shift;
    0.00 :   ffff80001011270c:       ldr     x7, [x20, #344]
         : 2102             tk->tkr_mono.cycle_last += interval;
    0.00 :   ffff800010112710:       add     x6, x6, x0
         : 2103             tk->tkr_raw.cycle_last  += interval;
    0.00 :   ffff800010112714:       ldr     x5, [x20, #384]
         : 2105             tk->tkr_mono.xtime_nsec += tk->xtime_interval << shift;
    0.00 :   ffff800010112718:       lsl     x1, x1, x27
         : 2107             accumulate_nsecs_to_secs():
         : 2044             unsigned int clock_set = 0;
    0.00 :   ffff80001011271c:       mov     w22, #0x0                       // #0
         : 2046             logarithmic_accumulation():
         : 2105             tk->tkr_mono.xtime_nsec += tk->xtime_interval << shift;
    0.00 :   ffff800010112720:       add     x1, x1, x7
         : 2103             tk->tkr_raw.cycle_last  += interval;
    0.00 :   ffff800010112724:       add     x0, x5, x0
         : 2105             accumulate_nsecs_to_secs():
         : 2043             u64 nsecps = (u64)NSEC_PER_SEC << tk->tkr_mono.shift;
    0.00 :   ffff800010112728:       lsl     x21, x24, x21
         : 2045             logarithmic_accumulation():
         : 2102             tk->tkr_mono.cycle_last += interval;
    0.00 :   ffff80001011272c:       str     x6, [x20, #328]
         : 2105             tk->tkr_mono.xtime_nsec += tk->xtime_interval << shift;
    0.00 :   ffff800010112730:       str     x1, [x20, #344]
         : 2103             tk->tkr_raw.cycle_last  += interval;
    0.00 :   ffff800010112734:       str     x0, [x20, #384]
         : 2105             accumulate_nsecs_to_secs():
         : 2046             while (tk->tkr_mono.xtime_nsec >= nsecps) {
    0.00 :   ffff800010112738:       cmp     x21, x1
    0.00 :   ffff80001011273c:       b.hi    ffff800010112774 <timekeeping_advance+0x19c>  // b.pmore
         : 2050             tk->xtime_sec++;
    0.00 :   ffff800010112740:       ldr     x0, [x19, #112]
         : 2049             tk->tkr_mono.xtime_nsec -= nsecps;
    0.00 :   ffff800010112744:       sub     x1, x1, x21
         : 2056             if (unlikely(tk->skip_second_overflow)) {
    0.00 :   ffff800010112748:       ldr     w2, [x19, #272]
         : 2050             tk->xtime_sec++;
    0.00 :   ffff80001011274c:       add     x0, x0, #0x1
         : 2049             tk->tkr_mono.xtime_nsec -= nsecps;
    0.00 :   ffff800010112750:       str     x1, [x19, #32]
         : 2050             tk->xtime_sec++;
    0.00 :   ffff800010112754:       str     x0, [x19, #112]
         : 2056             if (unlikely(tk->skip_second_overflow)) {
    0.00 :   ffff800010112758:       cbnz    w2, ffff800010112988 <timekeeping_advance+0x3b0>
         : 2062             leap = second_overflow(tk->xtime_sec);
    0.00 :   ffff80001011275c:       bl      ffff800010113a18 <second_overflow>
    0.00 :   ffff800010112760:       mov     w25, w0
         : 2063             if (unlikely(leap)) {
    0.00 :   ffff800010112764:       cbnz    w0, ffff800010112990 <timekeeping_advance+0x3b8>
    0.00 :   ffff800010112768:       ldr     x1, [x19, #32]
         : 2046             while (tk->tkr_mono.xtime_nsec >= nsecps) {
    0.00 :   ffff80001011276c:       cmp     x21, x1
    0.00 :   ffff800010112770:       b.ls    ffff800010112740 <timekeeping_advance+0x168>  // b.plast
         : 2049             logarithmic_accumulation():
         : 2109             tk->tkr_raw.xtime_nsec += tk->raw_interval << shift;
    0.00 :   ffff800010112774:       ldr     x0, [x20, #552]
         : 2106             *clock_set |= accumulate_nsecs_to_secs(tk);
    0.00 :   ffff800010112778:       orr     w23, w23, w22
         : 2109             tk->tkr_raw.xtime_nsec += tk->raw_interval << shift;
    0.00 :   ffff80001011277c:       ldr     x5, [x20, #400]
         : 2110             snsec_per_sec = (u64)NSEC_PER_SEC << tk->tkr_raw.shift;
    0.00 :   ffff800010112780:       ldr     w1, [x20, #396]
         : 2109             tk->tkr_raw.xtime_nsec += tk->raw_interval << shift;
    0.00 :   ffff800010112784:       lsl     x0, x0, x27
    0.00 :   ffff800010112788:       add     x0, x0, x5
    0.00 :   ffff80001011278c:       str     x0, [x20, #400]
         : 2110             snsec_per_sec = (u64)NSEC_PER_SEC << tk->tkr_raw.shift;
    0.00 :   ffff800010112790:       lsl     x1, x24, x1
         : 2111             while (tk->tkr_raw.xtime_nsec >= snsec_per_sec) {
    0.00 :   ffff800010112794:       cmp     x0, x1
    0.00 :   ffff800010112798:       b.cc    ffff8000101127b8 <timekeeping_advance+0x1e0>  // b.lo, b.ul, b.last
    0.00 :   ffff80001011279c:       ldr     x2, [x20, #504]
         : 2112             tk->tkr_raw.xtime_nsec -= snsec_per_sec;
    0.00 :   ffff8000101127a0:       sub     x0, x0, x1
         : 2111             while (tk->tkr_raw.xtime_nsec >= snsec_per_sec) {
    0.00 :   ffff8000101127a4:       cmp     x1, x0
         : 2113             tk->raw_sec++;
    0.00 :   ffff8000101127a8:       add     x2, x2, #0x1
         : 2111             while (tk->tkr_raw.xtime_nsec >= snsec_per_sec) {
    0.00 :   ffff8000101127ac:       b.ls    ffff8000101127a0 <timekeeping_advance+0x1c8>  // b.plast
    0.00 :   ffff8000101127b0:       str     x0, [x20, #400]
    0.00 :   ffff8000101127b4:       str     x2, [x20, #504]
         : 2118             tk->ntp_error -= (tk->xtime_interval + tk->xtime_remainder) <<
    0.00 :   ffff8000101127b8:       ldr     x6, [x20, #536]
    0.00 :   ffff8000101127bc:       ldr     x0, [x20, #544]
         : 2117             tk->ntp_error += tk->ntp_tick << shift;
    0.00 :   ffff8000101127c0:       ldr     x2, [x20, #560]
         : 2118             tk->ntp_error -= (tk->xtime_interval + tk->xtime_remainder) <<
    0.00 :   ffff8000101127c4:       add     x6, x6, x0
         : 2119             (tk->ntp_error_shift + shift);
    0.00 :   ffff8000101127c8:       ldr     w7, [x20, #576]
    0.00 :   ffff8000101127cc:       ldr     x5, [x20, #528]
    0.00 :   ffff8000101127d0:       add     w7, w27, w7
         : 2117             tk->ntp_error += tk->ntp_tick << shift;
    0.00 :   ffff8000101127d4:       ldr     x8, [x20, #568]
    0.00 :   ffff8000101127d8:       lsl     x2, x2, x27
         : 2118             tk->ntp_error -= (tk->xtime_interval + tk->xtime_remainder) <<
    0.00 :   ffff8000101127dc:       lsl     x6, x6, x7
         : 2117             tk->ntp_error += tk->ntp_tick << shift;
    0.00 :   ffff8000101127e0:       add     x2, x2, x8
    0.00 :   ffff8000101127e4:       lsl     x0, x5, x27
         : 2118             tk->ntp_error -= (tk->xtime_interval + tk->xtime_remainder) <<
    0.00 :   ffff8000101127e8:       sub     x2, x2, x6
    0.00 :   ffff8000101127ec:       str     x2, [x20, #568]
         : 2121             timekeeping_advance():
         : 2170             offset = logarithmic_accumulation(tk, offset, shift,
         : 2171             &clock_set);
         : 2172             if (offset < tk->cycle_interval<<shift)
         : 2173             shift--;
    0.00 :   ffff8000101127f0:       cmp     x0, x28
    0.00 :   ffff8000101127f4:       cset    w0, hi  // hi = pmore
         : 2166             while (offset >= tk->cycle_interval) {
    0.00 :   ffff8000101127f8:       cmp     x28, x5
         : 2170             shift--;
    0.00 :   ffff8000101127fc:       sub     w27, w27, w0
         : 2166             while (offset >= tk->cycle_interval) {
    0.00 :   ffff800010112800:       b.cs    ffff8000101126e8 <timekeeping_advance+0x110>  // b.hs, b.nlast
         : 2168             timekeeping_adjust():
         : 1988             if (likely(tk->ntp_tick == ntp_tick_length())) {
    0.00 :   ffff800010112804:       add     x19, x20, #0x138
    0.00 :   ffff800010112808:       ldr     x21, [x19, #248]
    0.00 :   ffff80001011280c:       bl      ffff8000101139a0 <ntp_tick_length>
    0.00 :   ffff800010112810:       cmp     x21, x0
    0.00 :   ffff800010112814:       b.ne    ffff800010112af4 <timekeeping_advance+0x51c>  // b.any
         : 1989             mult = tk->tkr_mono.mult - tk->ntp_err_mult;
    0.00 :   ffff800010112818:       ldr     w0, [x19, #24]
    0.00 :   ffff80001011281c:       ldr     w1, [x19, #268]
    0.00 :   ffff800010112820:       ldr     x3, [x19, #216]
    0.00 :   ffff800010112824:       sub     w2, w0, w1
         : 2002             tk->ntp_err_mult = tk->ntp_error > 0 ? 1 : 0;
    0.00 :   ffff800010112828:       ldr     x1, [x20, #568]
    0.00 :   ffff80001011282c:       cmp     x1, #0x0
    0.00 :   ffff800010112830:       cset    w1, gt
    0.00 :   ffff800010112834:       str     w1, [x20, #580]
         : 2003             mult += tk->ntp_err_mult;
    0.00 :   ffff800010112838:       add     w1, w1, w2
         : 2005             timekeeping_apply_adjustment():
         : 1908             if (mult_adj == 0) {
    0.00 :   ffff80001011283c:       subs    w0, w1, w0
    0.00 :   ffff800010112840:       b.eq    ffff800010112890 <timekeeping_advance+0x2b8>  // b.none
         : 1911             timekeeping_advance():
         : 2174             }
         :
         : 2176             /* Adjust the multiplier to correct NTP error */
         : 2177             timekeeping_adjust(tk, offset);
    0.00 :   ffff800010112844:       mov     x4, x28
         : 2179             timekeeping_apply_adjustment():
         : 1906             s64 interval = tk->cycle_interval;
    0.00 :   ffff800010112848:       mov     x2, x3
         : 1910             } else if (mult_adj == -1) {
    0.00 :   ffff80001011284c:       cmn     w0, #0x1
    0.00 :   ffff800010112850:       b.eq    ffff800010112a50 <timekeeping_advance+0x478>  // b.none
         : 1913             } else if (mult_adj != 1) {
    0.00 :   ffff800010112854:       cmp     w0, #0x1
    0.00 :   ffff800010112858:       b.eq    ffff800010112868 <timekeeping_advance+0x290>  // b.none
         : 1914             interval *= mult_adj;
    0.00 :   ffff80001011285c:       sxtw    x3, w0
    0.00 :   ffff800010112860:       mul     x2, x2, x3
         : 1915             offset *= mult_adj;
    0.00 :   ffff800010112864:       mul     x4, x28, x3
         : 1965             if ((mult_adj > 0) && (tk->tkr_mono.mult + mult_adj < mult_adj)) {
    0.00 :   ffff800010112868:       cmp     w0, #0x0
    0.00 :   ffff80001011286c:       ccmp    w1, w0, #0x2, gt
    0.00 :   ffff800010112870:       b.cc    ffff800010112a80 <timekeeping_advance+0x4a8>  // b.lo, b.ul, b.last
         : 1971             tk->tkr_mono.mult += mult_adj;
    0.00 :   ffff800010112874:       str     w1, [x20, #336]
         : 1973             tk->tkr_mono.xtime_nsec -= offset;
    0.00 :   ffff800010112878:       ldr     x3, [x20, #344]
         : 1972             tk->xtime_interval += interval;
    0.00 :   ffff80001011287c:       ldr     x1, [x20, #536]
         : 1973             tk->tkr_mono.xtime_nsec -= offset;
    0.00 :   ffff800010112880:       sub     x4, x3, x4
    0.00 :   ffff800010112884:       str     x4, [x20, #344]
         : 1972             tk->xtime_interval += interval;
    0.00 :   ffff800010112888:       add     x2, x1, x2
    0.00 :   ffff80001011288c:       str     x2, [x20, #536]
         : 1975             timekeeping_adjust():
         : 2007             if (unlikely(tk->tkr_mono.clock->maxadj &&
    0.00 :   ffff800010112890:       ldr     x1, [x20, #312]
    0.00 :   ffff800010112894:       ldr     w0, [x1, #32]
    0.00 :   ffff800010112898:       cbnz    w0, ffff800010112a88 <timekeeping_advance+0x4b0>
         : 2026             if (unlikely((s64)tk->tkr_mono.xtime_nsec < 0)) {
    0.00 :   ffff80001011289c:       ldr     x2, [x20, #344]
    0.00 :   ffff8000101128a0:       mov     x24, #0xca00                    // #51712
    0.00 :   ffff8000101128a4:       ldr     w1, [x20, #340]
    0.00 :   ffff8000101128a8:       movk    x24, #0x3b9a, lsl #16
    0.00 :   ffff8000101128ac:       lsl     x24, x24, x1
    0.00 :   ffff8000101128b0:       tbnz    x2, #63, ffff800010112ad4 <timekeeping_advance+0x4fc>
         : 2033             __timekeeping_set_tai_offset():
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff8000101128b4:       mov     w22, #0xca00                    // #51712
         : 1422             accumulate_nsecs_to_secs():
         : 2049             tk->tkr_mono.xtime_nsec -= nsecps;
    0.00 :   ffff8000101128b8:       add     x19, x20, #0x138
         : 2044             unsigned int clock_set = 0;
    0.00 :   ffff8000101128bc:       mov     w21, #0x0                       // #0
         : 2046             __timekeeping_set_tai_offset():
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff8000101128c0:       movk    w22, #0x3b9a, lsl #16
         : 1422             accumulate_nsecs_to_secs():
         : 2046             while (tk->tkr_mono.xtime_nsec >= nsecps) {
    0.00 :   ffff8000101128c4:       cmp     x24, x2
    0.00 :   ffff8000101128c8:       b.hi    ffff800010112900 <timekeeping_advance+0x328>  // b.pmore
         : 2050             tk->xtime_sec++;
    0.00 :   ffff8000101128cc:       ldr     x0, [x19, #112]
         : 2049             tk->tkr_mono.xtime_nsec -= nsecps;
    0.00 :   ffff8000101128d0:       sub     x2, x2, x24
         : 2056             if (unlikely(tk->skip_second_overflow)) {
    0.00 :   ffff8000101128d4:       ldr     w1, [x19, #272]
         : 2050             tk->xtime_sec++;
    0.00 :   ffff8000101128d8:       add     x0, x0, #0x1
         : 2049             tk->tkr_mono.xtime_nsec -= nsecps;
    0.00 :   ffff8000101128dc:       str     x2, [x19, #32]
         : 2050             tk->xtime_sec++;
    0.00 :   ffff8000101128e0:       str     x0, [x19, #112]
         : 2056             if (unlikely(tk->skip_second_overflow)) {
    0.00 :   ffff8000101128e4:       cbnz    w1, ffff8000101129e8 <timekeeping_advance+0x410>
         : 2062             leap = second_overflow(tk->xtime_sec);
    0.00 :   ffff8000101128e8:       bl      ffff800010113a18 <second_overflow>
    0.00 :   ffff8000101128ec:       mov     w27, w0
         : 2063             if (unlikely(leap)) {
    0.00 :   ffff8000101128f0:       cbnz    w0, ffff8000101129f0 <timekeeping_advance+0x418>
    0.00 :   ffff8000101128f4:       ldr     x2, [x19, #32]
         : 2046             while (tk->tkr_mono.xtime_nsec >= nsecps) {
    0.00 :   ffff8000101128f8:       cmp     x24, x2
    0.00 :   ffff8000101128fc:       b.ls    ffff8000101128cc <timekeeping_advance+0x2f4>  // b.plast
         : 2049             do_raw_write_seqcount_begin():
         : 473              } while (0)
         :
         : 475              static inline void do_raw_write_seqcount_begin(seqcount_t *s)
         : 476              {
         : 477              kcsan_nestable_atomic_begin();
         : 478              s->sequence++;
    0.00 :   ffff800010112900:       ldr     w0, [x26, #3840]
         : 480              timekeeping_advance():
         :
         : 2181             /*
         : 2182             * Finally, make sure that after the rounding
         : 2183             * xtime_nsec isn't larger than NSEC_PER_SEC
         : 2184             */
         : 2185             clock_set |= accumulate_nsecs_to_secs(tk);
    0.00 :   ffff800010112904:       orr     w23, w21, w23
         : 2187             do_raw_write_seqcount_begin():
    0.00 :   ffff800010112908:       add     w0, w0, #0x1
    0.00 :   ffff80001011290c:       str     w0, [x26, #3840]
         : 474              smp_wmb();
    0.00 :   ffff800010112910:       dmb     ishst
         : 476              timekeeping_advance():
         : 2193             * well, i.e. move the timekeeper pointer getter into the
         : 2194             * spinlocked/seqcount protected sections. And we trade this
         : 2195             * memcpy under the tk_core.seq against one before we start
         : 2196             * updating.
         : 2197             */
         : 2198             timekeeping_update(tk, clock_set);
    0.00 :   ffff800010112914:       add     x19, x20, #0x138
    0.00 :   ffff800010112918:       mov     w1, w23
    0.00 :   ffff80001011291c:       mov     x0, x19
    0.00 :   ffff800010112920:       bl      ffff800010111850 <timekeeping_update>
         : 2194             memcpy(real_tk, tk, sizeof(*tk));
    0.00 :   ffff800010112924:       mov     x1, x19
    0.00 :   ffff800010112928:       add     x0, x20, #0x8
    0.00 :   ffff80001011292c:       mov     x2, #0x118                      // #280
    0.00 :   ffff800010112930:       bl      ffff8000104a5b40 <__memcpy>
         : 2199             do_raw_write_seqcount_end():
         : 493              preempt_enable();                                       \
         : 494              } while (0)
         :
         : 496              static inline void do_raw_write_seqcount_end(seqcount_t *s)
         : 497              {
         : 498              smp_wmb();
    0.00 :   ffff800010112934:       dmb     ishst
         : 494              s->sequence++;
  100.00 :   ffff800010112938:       ldr     w2, [x26, #3840]
         : 496              timekeeping_advance():
         : 2198             /* The memcpy must come last. Do not put anything here! */
         : 2199             write_seqcount_end(&tk_core.seq);
         : 2200             out:
         : 2201             raw_spin_unlock_irqrestore(&timekeeper_lock, flags);
    0.00 :   ffff80001011293c:       add     x0, x20, #0x128
    0.00 :   ffff800010112940:       ldr     x1, [sp, #104]
         : 2204             do_raw_write_seqcount_end():
    0.00 :   ffff800010112944:       add     w2, w2, #0x1
    0.00 :   ffff800010112948:       str     w2, [x26, #3840]
         : 496              timekeeping_advance():
    0.00 :   ffff80001011294c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 2199             if (clock_set)
    0.00 :   ffff800010112950:       cbnz    w23, ffff800010112a40 <timekeeping_advance+0x468>
    0.00 :   ffff800010112954:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010112958:       ldp     x27, x28, [sp, #80]
         : 2202             /* Have to call _delayed version, since in irq context*/
         : 2203             clock_was_set_delayed();
         : 2204             }
    0.00 :   ffff80001011295c:       ldr     x0, [sp, #96]
    0.00 :   ffff800010112960:       ldr     x1, [sp, #136]
    0.00 :   ffff800010112964:       ldr     x0, [x0]
    0.00 :   ffff800010112968:       eor     x0, x1, x0
    0.00 :   ffff80001011296c:       cbnz    x0, ffff800010112b1c <timekeeping_advance+0x544>
    0.00 :   ffff800010112970:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010112974:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010112978:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001011297c:       ldp     x29, x30, [sp], #144
    0.00 :   ffff800010112980:       autiasp
    0.00 :   ffff800010112984:       ret
         : 2216             accumulate_nsecs_to_secs():
         : 2057             tk->skip_second_overflow = 0;
    0.00 :   ffff800010112988:       str     wzr, [x19, #272]
         : 2058             continue;
    0.00 :   ffff80001011298c:       b       ffff800010112738 <timekeeping_advance+0x160>
         : 2060             timespec64_sub():
         : 79               */
         : 80               static inline struct timespec64 timespec64_sub(struct timespec64 lhs,
         : 81               struct timespec64 rhs)
         : 82               {
         : 83               struct timespec64 ts_delta;
         : 84               set_normalized_timespec64(&ts_delta, lhs.tv_sec - rhs.tv_sec,
    0.00 :   ffff800010112990:       ldp     x7, x2, [x19, #128]
         : 86               accumulate_nsecs_to_secs():
         : 2066             tk->xtime_sec += leap;
    0.00 :   ffff800010112994:       sxtw    x1, w0
    0.00 :   ffff800010112998:       ldr     x6, [x19, #112]
         : 2069             timespec64_sub():
    0.00 :   ffff80001011299c:       add     x0, sp, #0x78
         : 80               accumulate_nsecs_to_secs():
         : 2075             clock_set = TK_CLOCK_WAS_SET;
    0.00 :   ffff8000101129a0:       mov     w22, #0x4                       // #4
         : 2066             tk->xtime_sec += leap;
    0.00 :   ffff8000101129a4:       add     x6, x6, x1
    0.00 :   ffff8000101129a8:       str     x6, [x19, #112]
         : 2069             timespec64_sub():
    0.00 :   ffff8000101129ac:       sub     x1, x7, x1
    0.00 :   ffff8000101129b0:       bl      ffff80001010b620 <set_normalized_timespec64>
         : 81               accumulate_nsecs_to_secs():
         : 2070             tk_set_wall_to_mono(tk,
    0.00 :   ffff8000101129b4:       ldp     x1, x2, [sp, #120]
    0.00 :   ffff8000101129b8:       mov     x0, x19
    0.00 :   ffff8000101129bc:       bl      ffff800010111650 <tk_set_wall_to_mono>
         : 2073             __timekeeping_set_tai_offset(tk, tk->tai_offset - leap);
    0.00 :   ffff8000101129c0:       ldr     w0, [x19, #168]
         : 2075             __timekeeping_set_tai_offset():
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff8000101129c4:       ldr     x2, [x19, #144]
         : 1422             accumulate_nsecs_to_secs():
         : 2073             __timekeeping_set_tai_offset(tk, tk->tai_offset - leap);
    0.00 :   ffff8000101129c8:       sub     w5, w0, w25
         : 2075             __timekeeping_set_tai_offset():
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff8000101129cc:       mov     w0, #0xca00                     // #51712
         : 1419             tk->tai_offset = tai_offset;
    0.00 :   ffff8000101129d0:       str     w5, [x19, #168]
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff8000101129d4:       movk    w0, #0x3b9a, lsl #16
    0.00 :   ffff8000101129d8:       ldr     x1, [x19, #32]
    0.00 :   ffff8000101129dc:       smaddl  x5, w5, w0, x2
    0.00 :   ffff8000101129e0:       str     x5, [x19, #160]
         : 1425             accumulate_nsecs_to_secs():
         : 2075             clock_set = TK_CLOCK_WAS_SET;
    0.00 :   ffff8000101129e4:       b       ffff800010112738 <timekeeping_advance+0x160>
         : 2057             tk->skip_second_overflow = 0;
    0.00 :   ffff8000101129e8:       str     wzr, [x19, #272]
         : 2058             continue;
    0.00 :   ffff8000101129ec:       b       ffff8000101128c4 <timekeeping_advance+0x2ec>
         : 2060             timespec64_sub():
    0.00 :   ffff8000101129f0:       ldp     x4, x2, [x19, #128]
         : 80               accumulate_nsecs_to_secs():
         : 2066             tk->xtime_sec += leap;
    0.00 :   ffff8000101129f4:       sxtw    x1, w0
    0.00 :   ffff8000101129f8:       ldr     x3, [x19, #112]
         : 2069             timespec64_sub():
    0.00 :   ffff8000101129fc:       add     x0, sp, #0x78
         : 80               accumulate_nsecs_to_secs():
         : 2075             clock_set = TK_CLOCK_WAS_SET;
    0.00 :   ffff800010112a00:       mov     w21, #0x4                       // #4
         : 2066             tk->xtime_sec += leap;
    0.00 :   ffff800010112a04:       add     x3, x3, x1
    0.00 :   ffff800010112a08:       str     x3, [x19, #112]
         : 2069             timespec64_sub():
    0.00 :   ffff800010112a0c:       sub     x1, x4, x1
    0.00 :   ffff800010112a10:       bl      ffff80001010b620 <set_normalized_timespec64>
         : 81               accumulate_nsecs_to_secs():
         : 2070             tk_set_wall_to_mono(tk,
    0.00 :   ffff800010112a14:       ldp     x1, x2, [sp, #120]
    0.00 :   ffff800010112a18:       mov     x0, x19
    0.00 :   ffff800010112a1c:       bl      ffff800010111650 <tk_set_wall_to_mono>
         : 2073             __timekeeping_set_tai_offset(tk, tk->tai_offset - leap);
    0.00 :   ffff800010112a20:       ldr     w0, [x19, #168]
         : 2075             __timekeeping_set_tai_offset():
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff800010112a24:       ldr     x1, [x19, #144]
         : 1422             accumulate_nsecs_to_secs():
         : 2073             __timekeeping_set_tai_offset(tk, tk->tai_offset - leap);
    0.00 :   ffff800010112a28:       sub     w27, w0, w27
         : 2075             __timekeeping_set_tai_offset():
         : 1419             tk->tai_offset = tai_offset;
    0.00 :   ffff800010112a2c:       str     w27, [x19, #168]
         : 1421             timekeeping_advance():
         : 43               static inline ktime_t ktime_set(const s64 secs, const unsigned long nsecs)
         : 44               {
         : 45               if (unlikely(secs >= KTIME_SEC_MAX))
         : 46               return KTIME_MAX;
         :
         : 48               return secs * NSEC_PER_SEC + (s64)nsecs;
    0.00 :   ffff800010112a30:       ldr     x2, [x19, #32]
         : 50               __timekeeping_set_tai_offset():
         : 1420             tk->offs_tai = ktime_add(tk->offs_real, ktime_set(tai_offset, 0));
    0.00 :   ffff800010112a34:       smaddl  x27, w27, w22, x1
    0.00 :   ffff800010112a38:       str     x27, [x19, #160]
         : 1423             accumulate_nsecs_to_secs():
         : 2075             clock_set = TK_CLOCK_WAS_SET;
    0.00 :   ffff800010112a3c:       b       ffff8000101128c4 <timekeeping_advance+0x2ec>
         : 2077             timekeeping_advance():
         : 2201             clock_was_set_delayed();
    0.00 :   ffff800010112a40:       bl      ffff800010110150 <clock_was_set_delayed>
    0.00 :   ffff800010112a44:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010112a48:       ldp     x27, x28, [sp, #80]
         : 2202             }
    0.00 :   ffff800010112a4c:       b       ffff80001011295c <timekeeping_advance+0x384>
         : 2204             timekeeping_apply_adjustment():
         : 1911             interval = -interval;
    0.00 :   ffff800010112a50:       neg     x2, x3
         : 1912             offset = -offset;
    0.00 :   ffff800010112a54:       neg     x4, x28
         : 1965             if ((mult_adj > 0) && (tk->tkr_mono.mult + mult_adj < mult_adj)) {
    0.00 :   ffff800010112a58:       b       ffff800010112874 <timekeeping_advance+0x29c>
         : 1967             timekeeping_advance():
         : 2198             raw_spin_unlock_irqrestore(&timekeeper_lock, flags);
    0.00 :   ffff800010112a5c:       ldr     x1, [sp, #104]
    0.00 :   ffff800010112a60:       mov     x0, x21
    0.00 :   ffff800010112a64:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 2199             if (clock_set)
    0.00 :   ffff800010112a68:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010112a6c:       b       ffff80001011295c <timekeeping_advance+0x384>
         : 2198             raw_spin_unlock_irqrestore(&timekeeper_lock, flags);
    0.00 :   ffff800010112a70:       ldr     x1, [sp, #104]
    0.00 :   ffff800010112a74:       mov     x0, x21
    0.00 :   ffff800010112a78:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 2199             if (clock_set)
    0.00 :   ffff800010112a7c:       b       ffff80001011295c <timekeeping_advance+0x384>
         : 2201             timekeeping_apply_adjustment():
         : 1967             WARN_ON_ONCE(1);
    0.00 :   ffff800010112a80:       brk     #0x800
         : 1968             return;
    0.00 :   ffff800010112a84:       b       ffff800010112890 <timekeeping_advance+0x2b8>
         : 1970             timekeeping_adjust():
         : 2007             if (unlikely(tk->tkr_mono.clock->maxadj &&
    0.00 :   ffff800010112a88:       ldr     w3, [x1, #16]
    0.00 :   ffff800010112a8c:       ldr     w2, [x20, #336]
    0.00 :   ffff800010112a90:       subs    w4, w2, w3
    0.00 :   ffff800010112a94:       cneg    w4, w4, mi  // mi = first
    0.00 :   ffff800010112a98:       cmp     w0, w4
    0.00 :   ffff800010112a9c:       b.cs    ffff80001011289c <timekeeping_advance+0x2c4>  // b.hs, b.nlast
         : 2010             printk_once(KERN_WARNING
    0.00 :   ffff800010112aa0:       adrp    x4, ffff800011efe000 <errmap+0xc38>
    0.00 :   ffff800010112aa4:       ldrb    w5, [x4, #2811]
    0.00 :   ffff800010112aa8:       cbnz    w5, ffff80001011289c <timekeeping_advance+0x2c4>
    0.00 :   ffff800010112aac:       ldr     x1, [x1, #48]
    0.00 :   ffff800010112ab0:       mov     w5, #0x1                        // #1
    0.00 :   ffff800010112ab4:       mov     w0, w0
    0.00 :   ffff800010112ab8:       mov     w2, w2
    0.00 :   ffff800010112abc:       add     x3, x0, w3, uxtw
    0.00 :   ffff800010112ac0:       strb    w5, [x4, #2811]
    0.00 :   ffff800010112ac4:       adrp    x0, ffff80001141f000 <kallsyms_token_index+0x147a0>
    0.00 :   ffff800010112ac8:       add     x0, x0, #0x960
    0.00 :   ffff800010112acc:       bl      ffff800010e19544 <printk>
    0.00 :   ffff800010112ad0:       b       ffff80001011289c <timekeeping_advance+0x2c4>
         : 2029             tk->xtime_sec--;
    0.00 :   ffff800010112ad4:       ldr     x1, [x20, #424]
         : 2027             tk->tkr_mono.xtime_nsec += (u64)NSEC_PER_SEC <<
    0.00 :   ffff800010112ad8:       add     x2, x2, x24
         : 2030             tk->skip_second_overflow = 1;
    0.00 :   ffff800010112adc:       mov     w3, #0x1                        // #1
         : 2027             tk->tkr_mono.xtime_nsec += (u64)NSEC_PER_SEC <<
    0.00 :   ffff800010112ae0:       str     x2, [x20, #344]
         : 2029             tk->xtime_sec--;
    0.00 :   ffff800010112ae4:       sub     x1, x1, #0x1
    0.00 :   ffff800010112ae8:       str     x1, [x20, #424]
         : 2030             tk->skip_second_overflow = 1;
    0.00 :   ffff800010112aec:       str     w3, [x20, #584]
    0.00 :   ffff800010112af0:       b       ffff8000101128b4 <timekeeping_advance+0x2dc>
         : 1991             tk->ntp_tick = ntp_tick_length();
    0.00 :   ffff800010112af4:       bl      ffff8000101139a0 <ntp_tick_length>
    0.00 :   ffff800010112af8:       str     x0, [x19, #248]
         : 1992             mult = div64_u64((tk->ntp_tick >> tk->ntp_error_shift) -
    0.00 :   ffff800010112afc:       ldr     w2, [x19, #264]
    0.00 :   ffff800010112b00:       ldr     x1, [x19, #232]
    0.00 :   ffff800010112b04:       ldr     x3, [x19, #216]
    0.00 :   ffff800010112b08:       lsr     x0, x0, x2
    0.00 :   ffff800010112b0c:       sub     x1, x0, x1
    0.00 :   ffff800010112b10:       ldr     w0, [x19, #24]
    0.00 :   ffff800010112b14:       udiv    x2, x1, x3
    0.00 :   ffff800010112b18:       b       ffff800010112828 <timekeeping_advance+0x250>
    0.00 :   ffff800010112b1c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010112b20:       stp     x27, x28, [sp, #80]
         : 2003             timekeeping_advance():
         : 2202             }
    0.00 :   ffff800010112b24:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104bcfa8 <xas_start>:
         : 6                xas_valid():
         : 1427             *
         : 1428             * Return: %true if the xas can be used for operations.
         : 1429             */
         : 1430             static inline bool xas_valid(const struct xa_state *xas)
         : 1431             {
         : 1432             return !xas_invalid(xas);
    0.00 :   ffff8000104bcfa8:       ldr     x1, [x0, #24]
         : 1434             xas_start():
         : 180              * error state, return NULL.  If the index is outside the current scope
         : 181              * of the xarray, return NULL without changing @xas->xa_node.  Otherwise
         : 182              * set @xas->xa_node to NULL and return the current head of the array.
         : 183              */
         : 184              static void *xas_start(struct xa_state *xas)
         : 185              {
    0.00 :   ffff8000104bcfac:       paciasp
   47.52 :   ffff8000104bcfb0:       mov     x2, x0
         : 183              void *entry;
         :
         : 185              if (xas_valid(xas))
    0.00 :   ffff8000104bcfb4:       ands    x0, x1, #0x3
    0.00 :   ffff8000104bcfb8:       b.eq    ffff8000104bd028 <xas_start+0x80>  // b.none
         : 188              xa_is_err():
         : 201              return unlikely(xa_is_internal(entry) &&
    0.00 :   ffff8000104bcfbc:       cmp     x0, #0x2
    0.00 :   ffff8000104bcfc0:       mov     x0, #0xffffffffffffc005         // #-16379
    0.00 :   ffff8000104bcfc4:       ccmp    x1, x0, #0x0, eq  // eq = none
    0.00 :   ffff8000104bcfc8:       b.hi    ffff8000104bd018 <xas_start+0x70>  // b.pmore
         : 206              xas_start():
         : 188              return xas_reload(xas);
         : 189              if (xas_error(xas))
         : 190              return NULL;
         :
         : 192              entry = xa_head(xas->xa);
    0.00 :   ffff8000104bcfcc:       ldp     x0, x1, [x2]
         : 194              xa_head():
         : 1166             return rcu_dereference_check(xa->xa_head,
    0.00 :   ffff8000104bcfd0:       ldr     x0, [x0, #8]
         : 1168             xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bcfd4:       cmp     x0, #0x1, lsl #12
         : 1228             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bcfd8:       and     x3, x0, #0x3
         : 171              xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bcfdc:       ccmp    x3, #0x2, #0x0, hi  // hi = pmore
    0.00 :   ffff8000104bcfe0:       b.eq    ffff8000104bcff4 <xas_start+0x4c>  // b.none
         : 1229             xas_start():
         : 190              if (!xa_is_node(entry)) {
         : 191              if (xas->xa_index)
    0.00 :   ffff8000104bcfe4:       cbnz    x1, ffff8000104bd004 <xas_start+0x5c>
         : 197              } else {
         : 198              if ((xas->xa_index >> xa_to_node(entry)->shift) > XA_CHUNK_MASK)
         : 199              return set_bounds(xas);
         : 200              }
         :
         : 202              xas->xa_node = NULL;
   52.48 :   ffff8000104bcfe8:       str     xzr, [x2, #24]
         : 199              return entry;
         : 200              }
    0.00 :   ffff8000104bcfec:       autiasp
    0.00 :   ffff8000104bcff0:       ret
         : 193              if ((xas->xa_index >> xa_to_node(entry)->shift) > XA_CHUNK_MASK)
    0.00 :   ffff8000104bcff4:       ldurb   w3, [x0, #-2]
    0.00 :   ffff8000104bcff8:       lsr     x1, x1, x3
    0.00 :   ffff8000104bcffc:       cmp     x1, #0x3f
    0.00 :   ffff8000104bd000:       b.ls    ffff8000104bcfe8 <xas_start+0x40>  // b.plast
         : 198              set_bounds():
         : 168              xas->xa_node = XAS_BOUNDS;
    0.00 :   ffff8000104bd004:       mov     x1, #0x1                        // #1
         : 170              xas_start():
         : 191              return set_bounds(xas);
    0.00 :   ffff8000104bd008:       mov     x0, #0x0                        // #0
         : 199              }
    0.00 :   ffff8000104bd00c:       autiasp
         : 201              set_bounds():
         : 168              xas->xa_node = XAS_BOUNDS;
    0.00 :   ffff8000104bd010:       str     x1, [x2, #24]
         : 170              xas_start():
         : 199              }
    0.00 :   ffff8000104bd014:       ret
         : 201              xa_err():
         : 221              return (long)entry >> 2;
    0.00 :   ffff8000104bd018:       asr     x1, x1, #2
         : 223              xas_start():
         : 185              if (xas_error(xas))
    0.00 :   ffff8000104bd01c:       cbz     w1, ffff8000104bcfcc <xas_start+0x24>
         : 186              return NULL;
    0.00 :   ffff8000104bd020:       mov     x0, #0x0                        // #0
    0.00 :   ffff8000104bd024:       b       ffff8000104bcfec <xas_start+0x44>
         : 189              xas_reload():
         : 1554             {
         : 1555             struct xa_node *node = xas->xa_node;
         : 1556             void *entry;
         : 1557             char offset;
         :
         : 1559             if (!node)
    0.00 :   ffff8000104bd028:       cbz     x1, ffff8000104bd070 <xas_start+0xc8>
         : 1557             return xa_head(xas->xa);
         : 1558             if (IS_ENABLED(CONFIG_XARRAY_MULTI)) {
         : 1559             offset = (xas->xa_index >> node->shift) & XA_CHUNK_MASK;
    0.00 :   ffff8000104bd02c:       ldr     x0, [x2, #8]
    0.00 :   ffff8000104bd030:       ldrb    w2, [x1]
    0.00 :   ffff8000104bd034:       lsr     x0, x0, x2
         : 1563             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000104bd038:       ubfiz   x0, x0, #3, #6
    0.00 :   ffff8000104bd03c:       add     x0, x0, #0x20
    0.00 :   ffff8000104bd040:       add     x0, x1, x0
    0.00 :   ffff8000104bd044:       ldr     x0, [x0, #8]
         : 1187             xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000104bd048:       cmp     x0, #0xfd
         : 1251             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd04c:       and     x2, x0, #0x3
         : 171              xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000104bd050:       ccmp    x2, #0x2, #0x0, ls  // ls = plast
    0.00 :   ffff8000104bd054:       b.ne    ffff8000104bcfec <xas_start+0x44>  // b.any
         : 1252             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000104bd058:       ubfx    x0, x0, #2, #8
         : 1184             xas_start():
         : 199              }
    0.00 :   ffff8000104bd05c:       autiasp
         : 201              xa_entry():
    0.00 :   ffff8000104bd060:       add     x0, x0, #0x4
    0.00 :   ffff8000104bd064:       add     x1, x1, x0, lsl #3
    0.00 :   ffff8000104bd068:       ldr     x0, [x1, #8]
         : 1185             xas_start():
    0.00 :   ffff8000104bd06c:       ret
         : 200              xas_reload():
         : 1555             return xa_head(xas->xa);
    0.00 :   ffff8000104bd070:       ldr     x0, [x2]
         : 1557             xa_head():
         : 1166             return rcu_dereference_check(xa->xa_head,
    0.00 :   ffff8000104bd074:       ldr     x0, [x0, #8]
    0.00 :   ffff8000104bd078:       b       ffff8000104bcfec <xas_start+0x44>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b6f78 <scheduler_tick>:
         : 6                scheduler_tick():
         : 4594             *   provided by mmdrop_lazy_tlb(),
         : 4595             * - a sync_core for SYNC_CORE.
         : 4596             */
         : 4597             if (mm) {
         : 4598             membarrier_mm_sync_core_before_usermode(mm);
         : 4599             mmdrop_lazy_tlb(mm);
    0.00 :   ffff8000100b6f78:       paciasp
    0.00 :   ffff8000100b6f7c:       stp     x29, x30, [sp, #-64]!
         : 4595             }
    0.00 :   ffff8000100b6f80:       adrp    x0, ffff80001176d000 <cpu_number>
         : 4594             mmdrop_lazy_tlb(mm);
    0.00 :   ffff8000100b6f84:       mov     x29, sp
    0.00 :   ffff8000100b6f88:       stp     x19, x20, [sp, #16]
         : 4595             }
    0.00 :   ffff8000100b6f8c:       add     x0, x0, #0x0
         : 4597             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100b6f90:       mrs     x1, tpidr_el1
         : 46               scheduler_tick():
         : 4594             mmdrop_lazy_tlb(mm);
    0.00 :   ffff8000100b6f94:       stp     x21, x22, [sp, #32]
         :
    0.00 :   ffff8000100b6f98:       adrp    x21, ffff800011c2d000 <xen_lateeoi_chip+0x68>
         : 4594             mmdrop_lazy_tlb(mm);
    0.00 :   ffff8000100b6f9c:       str     x23, [sp, #48]
         :
    0.00 :   ffff8000100b6fa0:       add     x21, x21, #0x760
    0.00 :   ffff8000100b6fa4:       ldrsw   x22, [x0, x1]
    0.00 :   ffff8000100b6fa8:       adrp    x0, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100b6fac:       add     x20, x0, #0xc40
    0.00 :   ffff8000100b6fb0:       mov     x19, x20
    0.00 :   ffff8000100b6fb4:       ldr     x0, [x21, x22, lsl #3]
    0.00 :   ffff8000100b6fb8:       add     x19, x19, x0
         : 4597             if (unlikely(prev_state == TASK_DEAD)) {
    0.00 :   ffff8000100b6fbc:       ldr     x23, [x19, #2352]
         : 4602             if (prev->sched_class->task_dead)
         : 4603             prev->sched_class->task_dead(prev);
         :
         : 4605             /*
         : 4606             * Remove function-return probe instances associated with this
    0.00 :   ffff8000100b6fc0:       bl      ffff8000107c99a0 <topology_scale_freq_tick>
         : 4608             rq_lock():
         : 1334             {
         : 1335             raw_spin_rq_unlock(rq);
         : 1336             local_irq_restore(flags);
         : 1337             }
         :
         : 1339             #define raw_spin_rq_lock_irqsave(rq, flags)     \
    0.00 :   ffff8000100b6fc4:       mov     x0, x19
    0.00 :   ffff8000100b6fc8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 1342             update_rq_clock():
         :
    0.00 :   ffff8000100b6fcc:       ldr     w0, [x19, #2392]
    0.00 :   ffff8000100b6fd0:       tbnz    w0, #1, ffff8000100b6fdc <scheduler_tick+0x64>
    0.00 :   ffff8000100b6fd4:       mov     x0, x19
    0.00 :   ffff8000100b6fd8:       bl      ffff8000100b16c0 <update_rq_clock.part.106>
         : 322              topology_get_thermal_pressure():
         :
         : 57               DECLARE_PER_CPU(unsigned long, thermal_pressure);
         :
         : 59               static inline unsigned long topology_get_thermal_pressure(int cpu)
         : 60               {
         : 61               return per_cpu(thermal_pressure, cpu);
    0.00 :   ffff8000100b6fdc:       ldrsw   x3, [x19, #2576]
         : 63               rq_clock_thermal():
         : 1211             */
    0.00 :   ffff8000100b6fe0:       adrp    x0, ffff800011f28000 <ucounts_hashtable+0x1a88>
         : 1213             topology_get_thermal_pressure():
    0.00 :   ffff8000100b6fe4:       adrp    x2, ffff800011778000 <ipi_to_irq>
    0.00 :   ffff8000100b6fe8:       add     x2, x2, #0x718
         : 58               rq_clock_thermal():
    0.00 :   ffff8000100b6fec:       ldr     w0, [x0, #1984]
         : 1212             scheduler_tick():
         : 4609             */
         : 4610             kprobe_flush_task(prev);
         :
         : 4612             /* Task is done with its stack. */
         : 4613             put_task_stack(prev);
         :
    0.00 :   ffff8000100b6ff0:       mov     x1, x19
         : 4616             topology_get_thermal_pressure():
    0.00 :   ffff8000100b6ff4:       ldr     x4, [x21, x3, lsl #3]
         : 57               rq_clock_thermal():
    0.00 :   ffff8000100b6ff8:       ldr     x3, [x19, #2432]
         : 1212             scheduler_tick():
    0.00 :   ffff8000100b6ffc:       ldr     x2, [x4, x2]
    0.00 :   ffff8000100b7000:       lsr     x0, x3, x0
    0.00 :   ffff8000100b7004:       bl      ffff8000100d5700 <update_thermal_load_avg>
         : 4610             put_task_struct_rcu_user(prev);
    0.00 :   ffff8000100b7008:       ldr     x3, [x23, #120]
    0.00 :   ffff8000100b700c:       mov     x1, x23
    0.00 :   ffff8000100b7010:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100b7014:       mov     x0, x19
    0.00 :   ffff8000100b7018:       ldr     x3, [x3, #128]
    0.00 :   ffff8000100b701c:       blr     x3
         : 4613             }
         :
         : 4615             return rq;
    0.00 :   ffff8000100b7020:       mov     x0, x19
    0.00 :   ffff8000100b7024:       bl      ffff8000100ba218 <calc_global_load_tick>
         : 4618             rq_unlock():
         : 1367             {
         : 1368             SCHED_WARN_ON(!entity_is_task(se));
         : 1369             return container_of(se, struct task_struct, se);
         : 1370             }
         :
         : 1372             static inline struct cfs_rq *task_cfs_rq(struct task_struct *p)
    0.00 :   ffff8000100b7028:       mov     x0, x19
    0.00 :   ffff8000100b702c:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 1375             scheduler_tick():
         :
         : 4621             /**
         : 4622             * schedule_tail - first thing a freshly forked thread must call.
         : 4623             * @prev: the thread we just switched away from.
         : 4624             */
         : 4625             asmlinkage __visible void schedule_tail(struct task_struct *prev)
    0.00 :   ffff8000100b7030:       bl      ffff80001016f3f0 <perf_event_task_tick>
         : 4627             idle_cpu():
         : 5834             *         - in IRQ context, return from interrupt-handler to
         : 5835             *           preemptible context
         : 5836             *
         : 5837             *       - If the kernel is not preemptible (CONFIG_PREEMPTION is not set)
         : 5838             *         then at the next:
         : 5839             *
    0.00 :   ffff8000100b7034:       ldr     x2, [x21, x22, lsl #3]
    0.00 :   ffff8000100b7038:       mov     x0, x20
    0.00 :   ffff8000100b703c:       add     x0, x0, x2
         : 5836             *          - cond_resched() call
         : 5837             *          - explicit schedule() call
    0.00 :   ffff8000100b7040:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000100b7044:       ldr     x2, [x0, #2352]
   49.90 :   ffff8000100b7048:       ldr     x3, [x0, #2360]
    0.00 :   ffff8000100b704c:       cmp     x3, x2
    0.00 :   ffff8000100b7050:       b.eq    ffff8000100b7078 <scheduler_tick+0x100>  // b.none
         : 5843             scheduler_tick():
         : 4623             /*
   50.10 :   ffff8000100b7054:       strb    w1, [x19, #2505]
         : 4624             * New tasks start with FORK_PREEMPT_COUNT, see there and
    0.00 :   ffff8000100b7058:       mov     x0, x19
    0.00 :   ffff8000100b705c:       bl      ffff8000100c72f0 <trigger_load_balance>
         : 4626             *
    0.00 :   ffff8000100b7060:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b7064:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b7068:       ldr     x23, [sp, #48]
    0.00 :   ffff8000100b706c:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000100b7070:       autiasp
    0.00 :   ffff8000100b7074:       ret
         : 4633             idle_cpu():
         : 5839             *          - return from syscall or exception to user-space
         : 5840             *          - return from interrupt-handler to user-space
         : 5841             *
    0.00 :   ffff8000100b7078:       ldr     w2, [x0, #4]
    0.00 :   ffff8000100b707c:       cbnz    w2, ffff8000100b7054 <scheduler_tick+0xdc>
         : 5843             * WARNING: must be called with preemption disabled!
         : 5844             */
         : 5845             static void __sched notrace __schedule(bool preempt)
         : 5846             {
    0.00 :   ffff8000100b7080:       ldr     w0, [x0, #104]
    0.00 :   ffff8000100b7084:       cmp     w0, #0x0
    0.00 :   ffff8000100b7088:       cset    w1, eq  // eq = none
    0.00 :   ffff8000100b708c:       b       ffff8000100b7054 <scheduler_tick+0xdc>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010102e18 <rcu_sched_clock_irq>:
         : 6                rcu_sched_clock_irq():
         : 2635             cond_resched_tasks_rcu_qs();
         : 2636             mask = 0;
         : 2637             raw_spin_lock_irqsave_rcu_node(rnp, flags);
         : 2638             rcu_state.cbovldnext |= !!rnp->cbovldmask;
         : 2639             if (rnp->qsmask == 0) {
         : 2640             if (rcu_preempt_blocked_readers_cgp(rnp)) {
    0.00 :   ffff800010102e18:       paciasp
    0.00 :   ffff800010102e1c:       stp     x29, x30, [sp, #-272]!
    0.00 :   ffff800010102e20:       mov     x29, sp
    0.00 :   ffff800010102e24:       stp     x19, x20, [sp, #16]
         : 2638             /*
         : 2639             * No point in scanning bits because they
         : 2640             * are all zero.  But we might need to
    0.00 :   ffff800010102e28:       adrp    x19, ffff80001177a000 <runqueues+0x3c0>
    0.00 :   ffff800010102e2c:       add     x19, x19, #0x900
         : 2635             if (rcu_preempt_blocked_readers_cgp(rnp)) {
    0.00 :   ffff800010102e30:       stp     x21, x22, [sp, #32]
         : 2637             __kern_my_cpu_offset():
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
         : 45               "mrs %0, tpidr_el2",
         : 46               ARM64_HAS_VIRT_HOST_EXTN)
         : 47               : "=r" (off) :
         : 48               "Q" (*(const unsigned long *)current_stack_pointer));
    0.00 :   ffff800010102e34:       mov     x4, sp
         : 50               rcu_sched_clock_irq():
         : 2638             * are all zero.  But we might need to
    0.00 :   ffff800010102e38:       add     x1, x19, #0x28
         : 2635             if (rcu_preempt_blocked_readers_cgp(rnp)) {
    0.00 :   ffff800010102e3c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010102e40:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010102e44:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010102e48:       add     x20, x20, #0x948
         : 2640             * priority-boost blocked readers.
         : 2641             */
    0.00 :   ffff800010102e4c:       add     x2, x19, #0x125
         : 2635             if (rcu_preempt_blocked_readers_cgp(rnp)) {
    0.00 :   ffff800010102e50:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010102e54:       mov     w21, w0
         : 2638             __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010102e58:       mrs     x5, tpidr_el1
         : 41               rcu_sched_clock_irq():
         : 2638             * are all zero.  But we might need to
    0.00 :   ffff800010102e5c:       ldr     x3, [x1, x5]
         : 2635             if (rcu_preempt_blocked_readers_cgp(rnp)) {
   49.89 :   ffff800010102e60:       ldr     x0, [x20]
    0.00 :   ffff800010102e64:       str     x0, [sp, #264]
    0.00 :   ffff800010102e68:       mov     x0, #0x0                        // #0
         : 2640             */
    0.00 :   ffff800010102e6c:       mov     x0, x2
         : 2638             * are all zero.  But we might need to
    0.00 :   ffff800010102e70:       add     x3, x3, #0x1
    0.00 :   ffff800010102e74:       str     x3, [x1, x5]
         : 2641             __kern_my_cpu_offset():
    0.00 :   ffff800010102e78:       mrs     x1, tpidr_el1
         : 40               rcu_sched_clock_irq():
         : 2640             */
    0.00 :   ffff800010102e7c:       add     x0, x0, x1
    0.00 :   ffff800010102e80:       ldarb   w0, [x0]
    0.00 :   ffff800010102e84:       tst     w0, #0xff
    0.00 :   ffff800010102e88:       b.ne    ffff80001010322c <rcu_sched_clock_irq+0x414>  // b.any
         : 2645             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010102e8c:       mrs     x5, sp_el0
         : 26               rcu_flavor_sched_clock_irq():
         : 752              void exit_rcu(void)
         : 753              {
         : 754              struct task_struct *t = current;
         :
         : 756              if (unlikely(!list_empty(&current->rcu_node_entry))) {
         : 757              rcu_preempt_depth_set(1);
    0.00 :   ffff800010102e90:       cbz     w21, ffff800010103220 <rcu_sched_clock_irq+0x408>
         : 759              get_current():
    0.00 :   ffff800010102e94:       mrs     x0, sp_el0
         : 20               rcu_flavor_sched_clock_irq():
         : 753              barrier();
    0.00 :   ffff800010102e98:       ldrb    w1, [x0, #776]
    0.00 :   ffff800010102e9c:       tst     w1, #0xff
    0.00 :   ffff800010102ea0:       b.ne    ffff800010103060 <rcu_sched_clock_irq+0x248>  // b.any
         : 757              get_current():
    0.00 :   ffff800010102ea4:       mrs     x3, sp_el0
         : 20               rcu_flavor_sched_clock_irq():
         : 755              WRITE_ONCE(t->rcu_read_unlock_special.b.blocked, true);
         : 756              } else if (unlikely(rcu_preempt_depth())) {
    0.00 :   ffff800010102ea8:       ldr     w0, [x3, #732]
    0.00 :   ffff800010102eac:       cmp     w0, #0x0
    0.00 :   ffff800010102eb0:       b.gt    ffff800010102ec0 <rcu_sched_clock_irq+0xa8>
         : 760              preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010102eb4:       ldr     w0, [x3, #8]
         : 19               rcu_flavor_sched_clock_irq():
    0.00 :   ffff800010102eb8:       and     w0, w0, #0xffff
    0.00 :   ffff800010102ebc:       cbz     w0, ffff80001010325c <rcu_sched_clock_irq+0x444>
         : 758              rcu_preempt_depth_set(1);
         : 759              } else {
         : 760              return;
    0.00 :   ffff800010102ec0:       mov     x0, x5
    0.00 :   ffff800010102ec4:       bl      ffff8000100ff0f0 <rcu_preempt_need_deferred_qs>
    0.00 :   ffff800010102ec8:       tst     w0, #0xff
    0.00 :   ffff800010102ecc:       b.ne    ffff800010103248 <rcu_sched_clock_irq+0x430>  // b.any
         : 765              get_current():
    0.00 :   ffff800010102ed0:       mrs     x0, sp_el0
         : 20               rcu_flavor_sched_clock_irq():
         : 771              * specified number of elements.
         : 772              */
         : 773              static void
         : 774              dump_blkd_tasks(struct rcu_node *rnp, int ncheck)
         : 775              {
         : 776              int cpu;
    0.00 :   ffff800010102ed4:       ldr     w0, [x0, #732]
    0.00 :   ffff800010102ed8:       mov     x1, sp
    0.00 :   ffff800010102edc:       cmp     w0, #0x0
    0.00 :   ffff800010102ee0:       b.le    ffff800010102f00 <rcu_sched_clock_irq+0xe8>
         : 772              int i;
    0.00 :   ffff800010102ee4:       add     x0, x19, #0x12
         : 774              __kern_my_cpu_offset():
    0.00 :   ffff800010102ee8:       mrs     x2, tpidr_el1
         : 40               rcu_flavor_sched_clock_irq():
         : 771              int cpu;
    0.00 :   ffff800010102eec:       ldrb    w0, [x0, x2]
    0.00 :   ffff800010102ef0:       cbz     w0, ffff800010102f00 <rcu_sched_clock_irq+0xe8>
         : 773              struct list_head *lhp;
    0.00 :   ffff800010102ef4:       add     x0, x19, #0x10
         : 772              int i;
    0.00 :   ffff800010102ef8:       ldrb    w0, [x0, x2]
    0.00 :   ffff800010102efc:       cbnz    w0, ffff800010103290 <rcu_sched_clock_irq+0x478>
    0.00 :   ffff800010102f00:       adrp    x7, ffff800011cb3000 <_rs.29273+0x20>
    0.00 :   ffff800010102f04:       add     x28, x7, #0xa80
         : 777              rcu_stall_is_suppressed_at_boot():
         :
         : 206              extern int rcu_cpu_stall_suppress_at_boot;
         :
         : 208              static inline bool rcu_stall_is_suppressed_at_boot(void)
         : 209              {
         : 210              return rcu_cpu_stall_suppress_at_boot && !rcu_inkernel_boot_has_ended();
    0.00 :   ffff800010102f08:       adrp    x25, ffff800011c29000 <page_wait_table+0x14c0>
         : 212              rcu_pending():
         :
         : 3906             /* Does this CPU have callbacks ready to invoke? */
         : 3907             if (!rcu_rdp_is_offloaded(rdp) &&
         : 3908             rcu_segcblist_ready_cbs(&rdp->cblist))
         : 3909             return 1;
         :
    0.00 :   ffff800010102f0c:       mov     x26, x19
         : 3912             __kern_my_cpu_offset():
    0.00 :   ffff800010102f10:       mrs     x22, tpidr_el1
         : 40               rcu_stall_is_suppressed_at_boot():
    0.00 :   ffff800010102f14:       ldr     w0, [x25, #2884]
         : 206              rcu_pending():
    0.00 :   ffff800010102f18:       add     x27, x26, x22
         : 3906             /* Has RCU gone idle with this CPU needing another grace period? */
   50.11 :   ffff800010102f1c:       ldr     x23, [x27, #24]
         : 3908             rcu_stall_is_suppressed_at_boot():
    0.00 :   ffff800010102f20:       cbnz    w0, ffff800010103034 <rcu_sched_clock_irq+0x21c>
         : 206              rcu_stall_is_suppressed():
         : 217              extern int rcu_cpu_stall_timeout;
         : 218              int rcu_jiffies_till_stall_check(void);
         :
         : 220              static inline bool rcu_stall_is_suppressed(void)
         : 221              {
         : 222              return rcu_stall_is_suppressed_at_boot() || rcu_cpu_stall_suppress;
    0.00 :   ffff800010102f24:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010102f28:       ldr     w0, [x0, #2872]
    0.00 :   ffff800010102f2c:       cbnz    w0, ffff800010103040 <rcu_sched_clock_irq+0x228>
         : 226              rcu_seq_current():
         : 99               return READ_ONCE(*sp);
    0.00 :   ffff800010102f30:       ldr     x0, [x28, #8776]
         : 101              check_cpu_stall():
         : 657              unsigned long gs1;
         : 658              unsigned long gs2;
         : 659              unsigned long gps;
         : 660              unsigned long j;
         : 661              unsigned long jn;
         : 662              unsigned long js;
    0.00 :   ffff800010102f34:       tst     x0, #0x3
    0.00 :   ffff800010102f38:       b.eq    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.none
         : 665              rcu_stall_kick_kthreads():
         : 167              return;
    0.00 :   ffff800010102f3c:       adrp    x10, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010102f40:       add     x24, x10, #0xd48
    0.00 :   ffff800010102f44:       ldrb    w0, [x24, #60]
    0.00 :   ffff800010102f48:       tst     w0, #0xff
    0.00 :   ffff800010102f4c:       b.eq    ffff800010102f54 <rcu_sched_clock_irq+0x13c>  // b.none
    0.00 :   ffff800010102f50:       bl      ffff8000100ffee8 <rcu_stall_kick_kthreads.part.88>
         : 174              check_cpu_stall():
         : 661              struct rcu_node *rnp;
         :
         : 663              lockdep_assert_irqs_disabled();
         : 664              if ((rcu_stall_is_suppressed() && !READ_ONCE(rcu_kick_kthreads)) ||
    0.00 :   ffff800010102f54:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010102f58:       ldr     x1, [x11, #2432]
         : 681              * value of rcu_state.jiffies_stall.  But given the memory barriers,
         : 682              * the only way that this can happen is if one grace period ends
         : 683              * and another starts between these two fetches.  This is detected
         : 684              * by comparing the second fetch of rcu_state.gp_seq with the
         : 685              * previous fetch from rcu_state.gp_seq.
         : 686              *
    0.00 :   ffff800010102f5c:       ldr     x0, [x28, #8776]
         : 682              * Given this check, comparisons of jiffies, rcu_state.jiffies_stall,
    0.00 :   ffff800010102f60:       dmb     ishld
         : 683              * and rcu_state.gp_start suffice to forestall false positives.
    0.00 :   ffff800010102f64:       ldr     x4, [x28, #9096]
         : 684              */
    0.00 :   ffff800010102f68:       dmb     ishld
         : 685              gs1 = READ_ONCE(rcu_state.gp_seq);
    0.00 :   ffff800010102f6c:       ldr     x7, [x28, #9064]
         : 686              smp_rmb(); /* Pick up ->gp_seq first... */
    0.00 :   ffff800010102f70:       dmb     ishld
         : 687              js = READ_ONCE(rcu_state.jiffies_stall);
    0.00 :   ffff800010102f74:       ldr     x12, [x28, #8776]
         : 688              smp_rmb(); /* ...then ->jiffies_stall before the rest... */
    0.00 :   ffff800010102f78:       cmp     x0, x12
    0.00 :   ffff800010102f7c:       b.eq    ffff800010103068 <rcu_sched_clock_irq+0x250>  // b.none
         : 691              rcu_pending():
         : 3918             if (rcu_seq_current(&rnp->gp_seq) != rdp->gp_seq ||
         : 3919             unlikely(READ_ONCE(rdp->gpwrap))) /* outside lock */
         : 3920             return 1;
         :
         : 3922             /* nothing to do */
         : 3923             return 0;
    0.00 :   ffff800010102f80:       cbz     w21, ffff800010103058 <rcu_sched_clock_irq+0x240>
         : 3923             }
         :
         : 3925             /*
         : 3926             * Helper function for rcu_barrier() tracing.  If tracing is disabled,
         : 3927             * the compiler is expected to optimize this away.
    0.00 :   ffff800010102f84:       ldrb    w1, [x27, #18]
         : 3929             rcu_seq_current():
    0.00 :   ffff800010102f88:       ldr     x0, [x28, #8776]
         : 100              rcu_seq_state():
         : 41               return s & RCU_SEQ_STATE_MASK;
    0.00 :   ffff800010102f8c:       and     w19, w0, #0x3
         : 43               rcu_pending():
    0.00 :   ffff800010102f90:       cbz     w1, ffff800010102ffc <rcu_sched_clock_irq+0x1e4>
    0.00 :   ffff800010102f94:       ldrb    w0, [x27, #16]
    0.00 :   ffff800010102f98:       cbnz    w0, ffff800010102ffc <rcu_sched_clock_irq+0x1e4>
    0.00 :   ffff800010102f9c:       cbnz    w19, ffff800010102fc8 <rcu_sched_clock_irq+0x1b0>
         : 3928             */
         : 3929             static void rcu_barrier_trace(const char *s, int cpu, unsigned long done)
         : 3930             {
         : 3931             trace_rcu_barrier(rcu_state.name, s, cpu,
         : 3932             atomic_read(&rcu_state.barrier_cpu_count), done);
    0.00 :   ffff800010102fa0:       add     x21, x27, #0x70
    0.00 :   ffff800010102fa4:       mov     x0, x21
    0.00 :   ffff800010102fa8:       bl      ffff800010104928 <rcu_segcblist_ready_cbs>
         : 3927             trace_rcu_barrier(rcu_state.name, s, cpu,
    0.00 :   ffff800010102fac:       tst     w0, #0xff
    0.00 :   ffff800010102fb0:       b.ne    ffff800010102fc8 <rcu_sched_clock_irq+0x1b0>  // b.any
         : 3930             rcu_segcblist_test_flags():
         : 71               }
         :
         : 73               static inline bool rcu_segcblist_test_flags(struct rcu_segcblist *rsclp,
         : 74               int flags)
         : 75               {
         : 76               return READ_ONCE(rsclp->flags) & flags;
    0.00 :   ffff800010102fb4:       ldrb    w0, [x21, #112]
         : 78               rcu_pending():
         : 3932             }
         :
         : 3934             /*
         : 3935             * RCU callback function for rcu_barrier().  If we are last, wake
    0.00 :   ffff800010102fb8:       tbz     w0, #0, ffff800010103014 <rcu_sched_clock_irq+0x1fc>
         : 3937             rcu_segcblist_restempty():
         : 110              * rcu_segcblist structure empty of callbacks?  (The specified
         : 111              * segment might well contain callbacks.)
         : 112              */
         : 113              static inline bool rcu_segcblist_restempty(struct rcu_segcblist *rsclp, int seg)
         : 114              {
         : 115              return !READ_ONCE(*READ_ONCE(rsclp->tails[seg]));
    0.00 :   ffff800010102fbc:       ldr     x0, [x21, #24]
    0.00 :   ffff800010102fc0:       ldr     x0, [x0]
         : 118              rcu_pending():
         : 3933             * up the task executing rcu_barrier().
    0.00 :   ffff800010102fc4:       cbz     x0, ffff800010103014 <rcu_sched_clock_irq+0x1fc>
         : 3935             rcu_sched_clock_irq():
         : 2650             if (f(rdp)) {
    0.00 :   ffff800010102fc8:       bl      ffff8000101008a0 <invoke_rcu_core>
         : 2654             }
    0.00 :   ffff800010102fcc:       ldr     x1, [sp, #264]
    0.00 :   ffff800010102fd0:       ldr     x0, [x20]
    0.00 :   ffff800010102fd4:       eor     x0, x1, x0
    0.00 :   ffff800010102fd8:       cbnz    x0, ffff800010103518 <rcu_sched_clock_irq+0x700>
    0.00 :   ffff800010102fdc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010102fe0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010102fe4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010102fe8:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010102fec:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010102ff0:       ldp     x29, x30, [sp], #272
    0.00 :   ffff800010102ff4:       autiasp
    0.00 :   ffff800010102ff8:       ret
         : 2667             rcu_pending():
         : 3928             atomic_read(&rcu_state.barrier_cpu_count), done);
    0.00 :   ffff800010102ffc:       add     x21, x27, #0x70
    0.00 :   ffff800010103000:       mov     x0, x21
    0.00 :   ffff800010103004:       bl      ffff800010104928 <rcu_segcblist_ready_cbs>
         : 3927             trace_rcu_barrier(rcu_state.name, s, cpu,
    0.00 :   ffff800010103008:       tst     w0, #0xff
    0.00 :   ffff80001010300c:       b.ne    ffff800010102fc8 <rcu_sched_clock_irq+0x1b0>  // b.any
         : 3932             * RCU callback function for rcu_barrier().  If we are last, wake
    0.00 :   ffff800010103010:       cbz     w19, ffff800010102fb4 <rcu_sched_clock_irq+0x19c>
         : 3934             rcu_seq_current():
         : 99               return READ_ONCE(*sp);
    0.00 :   ffff800010103014:       ldr     x1, [x23, #8]
         : 101              rcu_pending():
         : 3938             *
         : 3939             * Note that the value of rcu_state.barrier_sequence must be captured
         : 3940             * before the atomic_dec_and_test().  Otherwise, if this CPU is not last,
         : 3941             * other CPUs might count the value down to zero before this CPU gets
         : 3942             * around to invoking rcu_barrier_trace(), which might result in bogus
    0.00 :   ffff800010103018:       ldr     x0, [x26, x22]
    0.00 :   ffff80001010301c:       cmp     x1, x0
    0.00 :   ffff800010103020:       b.ne    ffff800010102fc8 <rcu_sched_clock_irq+0x1b0>  // b.any
         : 3939             * data from the next instance of rcu_barrier().
    0.00 :   ffff800010103024:       ldrb    w0, [x27, #20]
         : 3938             * around to invoking rcu_barrier_trace(), which might result in bogus
    0.00 :   ffff800010103028:       tst     w0, #0xff
    0.00 :   ffff80001010302c:       b.eq    ffff800010102fcc <rcu_sched_clock_irq+0x1b4>  // b.none
    0.00 :   ffff800010103030:       b       ffff800010102fc8 <rcu_sched_clock_irq+0x1b0>
         : 3942             rcu_stall_is_suppressed_at_boot():
         : 205              return rcu_cpu_stall_suppress_at_boot && !rcu_inkernel_boot_has_ended();
    0.00 :   ffff800010103034:       bl      ffff8000100fa780 <rcu_inkernel_boot_has_ended>
    0.00 :   ffff800010103038:       tst     w0, #0xff
    0.00 :   ffff80001010303c:       b.ne    ffff800010102f24 <rcu_sched_clock_irq+0x10c>  // b.any
         : 209              check_cpu_stall():
         : 657              unsigned long js;
    0.00 :   ffff800010103040:       adrp    x0, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010103044:       add     x0, x0, #0xd48
    0.00 :   ffff800010103048:       ldrb    w0, [x0, #60]
    0.00 :   ffff80001010304c:       tst     w0, #0xff
    0.00 :   ffff800010103050:       b.ne    ffff800010102f30 <rcu_sched_clock_irq+0x118>  // b.any
         : 663              rcu_pending():
         : 3918             return 0;
    0.00 :   ffff800010103054:       cbnz    w21, ffff800010102f84 <rcu_sched_clock_irq+0x16c>
    0.00 :   ffff800010103058:       bl      ffff8000100ffe88 <rcu_is_cpu_rrupt_from_idle>
    0.00 :   ffff80001010305c:       b       ffff800010102f84 <rcu_sched_clock_irq+0x16c>
         : 3922             rcu_flavor_sched_clock_irq():
         : 753              barrier();
    0.00 :   ffff800010103060:       strb    wzr, [x0, #776]
    0.00 :   ffff800010103064:       b       ffff800010102ea4 <rcu_sched_clock_irq+0x8c>
         : 756              check_cpu_stall():
         : 688              smp_rmb(); /* ...then ->jiffies_stall before the rest... */
    0.00 :   ffff800010103068:       subs    x3, x1, x4
    0.00 :   ffff80001010306c:       b.mi    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.first
         : 689              gps = READ_ONCE(rcu_state.gp_start);
    0.00 :   ffff800010103070:       cmp     x7, x4
    0.00 :   ffff800010103074:       b.pl    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.nfrst
         : 692              rcu_jiffies_till_stall_check():
         : 29               int rcu_jiffies_till_stall_check(void)
    0.00 :   ffff800010103078:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
         : 31               check_cpu_stall():
         : 692              smp_rmb(); /* ...and finally ->gp_start before ->gp_seq again. */
         : 693              gs2 = READ_ONCE(rcu_state.gp_seq);
         : 694              if (gs1 != gs2 ||
    0.00 :   ffff80001010307c:       ldr     x6, [x27, #24]
         : 696              rcu_jiffies_till_stall_check():
         : 29               int rcu_jiffies_till_stall_check(void)
    0.00 :   ffff800010103080:       ldr     w0, [x14, #2876]
         : 35               * for CONFIG_RCU_CPU_STALL_TIMEOUT.
    0.00 :   ffff800010103084:       cmp     w0, #0x2
    0.00 :   ffff800010103088:       b.gt    ffff8000101032c4 <rcu_sched_clock_irq+0x4ac>
         : 36               */
    0.00 :   ffff80001010308c:       mov     w1, #0x3                        // #3
    0.00 :   ffff800010103090:       mov     x0, #0x8ca                      // #2250
    0.00 :   ffff800010103094:       str     w1, [x14, #2876]
         : 40               check_cpu_stall():
         : 693              ULONG_CMP_LT(j, js) ||
    0.00 :   ffff800010103098:       ldr     x1, [x11, #2432]
         : 695              rcu_seq_current():
         : 99               return READ_ONCE(*sp);
    0.00 :   ffff80001010309c:       ldr     x2, [x28, #8776]
         : 101              check_cpu_stall():
    0.00 :   ffff8000101030a0:       add     x1, x1, #0x3
    0.00 :   ffff8000101030a4:       add     x5, x1, x0
         : 694              ULONG_CMP_GE(gps, js))
    0.00 :   ffff8000101030a8:       tst     x2, #0x3
    0.00 :   ffff8000101030ac:       b.eq    ffff8000101030c0 <rcu_sched_clock_irq+0x2a8>  // b.none
         : 695              return; /* No stall or GP completed since entering function. */
    0.00 :   ffff8000101030b0:       ldr     x1, [x6, #32]
    0.00 :   ffff8000101030b4:       ldr     x0, [x27, #32]
         : 694              ULONG_CMP_GE(gps, js))
    0.00 :   ffff8000101030b8:       tst     x1, x0
    0.00 :   ffff8000101030bc:       b.ne    ffff800010103318 <rcu_sched_clock_irq+0x500>  // b.any
         : 697              rcu_seq_current():
    0.00 :   ffff8000101030c0:       ldr     x0, [x28, #8776]
         : 100              check_cpu_stall():
         : 703              if (rcu_gp_in_progress() &&
         : 704              (READ_ONCE(rnp->qsmask) & rdp->grpmask) &&
         : 705              cmpxchg(&rcu_state.jiffies_stall, js, jn) == js) {
         :
         : 707              /*
         : 708              * If a virtual machine is stopped by the host it can look to
    0.00 :   ffff8000101030c4:       tst     x0, #0x3
    0.00 :   ffff8000101030c8:       b.eq    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.none
    0.00 :   ffff8000101030cc:       cmp     x3, #0x2
    0.00 :   ffff8000101030d0:       b.mi    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.first
         : 713              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101030d4:       b       ffff800010103468 <rcu_sched_clock_irq+0x650>
    0.00 :   ffff8000101030d8:       b       ffff800010103468 <rcu_sched_clock_irq+0x650>
         : 46               __lse__cmpxchg_case_mb_64():
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
         : 381              __CMPXCHG_CASE(w, b,  mb_,  8, al, "memory")
         : 382              __CMPXCHG_CASE(w, h,  mb_, 16, al, "memory")
         : 383              __CMPXCHG_CASE(w,  ,  mb_, 32, al, "memory")
         : 384              __CMPXCHG_CASE(x,  ,  mb_, 64, al, "memory")
    0.00 :   ffff8000101030dc:       adrp    x0, ffff800011cb5000 <rcu_state+0x1580>
    0.00 :   ffff8000101030e0:       mov     x2, x5
    0.00 :   ffff8000101030e4:       mov     x1, x4
    0.00 :   ffff8000101030e8:       add     x0, x0, #0xe08
    0.00 :   ffff8000101030ec:       mov     x3, #0x2388                     // #9096
    0.00 :   ffff8000101030f0:       add     x3, x28, x3
    0.00 :   ffff8000101030f4:       mov     x5, x1
    0.00 :   ffff8000101030f8:       casal   x5, x2, [x3]
    0.00 :   ffff8000101030fc:       mov     x0, x5
         : 394              check_cpu_stall():
         : 704              * the watchdog like an RCU stall. Check to see if the host
    0.00 :   ffff800010103100:       cmp     x4, x0
    0.00 :   ffff800010103104:       b.ne    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.any
         : 707              rcu_stall_kick_kthreads():
         : 167              return;
    0.00 :   ffff800010103108:       ldrb    w0, [x24, #60]
    0.00 :   ffff80001010310c:       tst     w0, #0xff
    0.00 :   ffff800010103110:       b.eq    ffff800010103120 <rcu_sched_clock_irq+0x308>  // b.none
    0.00 :   ffff800010103114:       stp     x7, x12, [sp, #104]
    0.00 :   ffff800010103118:       bl      ffff8000100ffee8 <rcu_stall_kick_kthreads.part.88>
    0.00 :   ffff80001010311c:       ldp     x7, x12, [sp, #104]
         : 174              rcu_stall_is_suppressed_at_boot():
         : 205              return rcu_cpu_stall_suppress_at_boot && !rcu_inkernel_boot_has_ended();
    0.00 :   ffff800010103120:       ldr     w0, [x25, #2884]
    0.00 :   ffff800010103124:       cbnz    w0, ffff800010103488 <rcu_sched_clock_irq+0x670>
         : 208              rcu_stall_is_suppressed():
         : 217              return rcu_stall_is_suppressed_at_boot() || rcu_cpu_stall_suppress;
    0.00 :   ffff800010103128:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010312c:       ldr     w0, [x0, #2872]
    0.00 :   ffff800010103130:       cbnz    w0, ffff80001010349c <rcu_sched_clock_irq+0x684>
         : 221              print_other_cpu_stall():
         : 540              * RCU CPU stall warnings.
    0.00 :   ffff800010103134:       ldr     x1, [x28, #9120]
    0.00 :   ffff800010103138:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff80001010313c:       add     x0, x0, #0x858
         : 523              unsigned long flags;
    0.00 :   ffff800010103140:       str     wzr, [sp, #104]
    0.00 :   ffff800010103144:       stp     x7, x12, [sp, #136]
         : 540              * RCU CPU stall warnings.
    0.00 :   ffff800010103148:       bl      ffff800010e19544 <printk>
         : 541              */
    0.00 :   ffff80001010314c:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010103150:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010103154:       add     x1, x1, #0xa08
    0.00 :   ffff800010103158:       stp     x1, x27, [sp, #112]
    0.00 :   ffff80001010315c:       ldr     w0, [x0, #2896]
    0.00 :   ffff800010103160:       str     x23, [sp, #128]
    0.00 :   ffff800010103164:       sub     w0, w0, #0x1
    0.00 :   ffff800010103168:       str     w21, [sp, #152]
    0.00 :   ffff80001010316c:       stp     x26, x22, [sp, #160]
    0.00 :   ffff800010103170:       add     x0, x28, w0, sxtw #3
    0.00 :   ffff800010103174:       ldr     x25, [x0, #8704]
    0.00 :   ffff800010103178:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010317c:       add     x0, x0, #0xb50
    0.00 :   ffff800010103180:       ldrsw   x0, [x0, #4]
    0.00 :   ffff800010103184:       add     x0, x28, x0, lsl #9
    0.00 :   ffff800010103188:       cmp     x25, x0
    0.00 :   ffff80001010318c:       b.cs    ffff80001010351c <rcu_sched_clock_irq+0x704>  // b.hs, b.nlast
         : 542              trace_rcu_stall_warning(rcu_state.name, TPS("StallDetected"));
    0.00 :   ffff800010103190:       mov     x0, x25
    0.00 :   ffff800010103194:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff800010103198:       mov     x23, x0
         : 543              pr_err("INFO: %s detected stalls on CPUs/tasks:\n", rcu_state.name);
    0.00 :   ffff80001010319c:       ldr     x0, [x25, #32]
    0.00 :   ffff8000101031a0:       cbz     x0, ffff800010103598 <rcu_sched_clock_irq+0x780>
         : 544              rcu_for_each_leaf_node(rnp) {
    0.00 :   ffff8000101031a4:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101031a8:       add     x0, x0, #0xb50
    0.00 :   ffff8000101031ac:       ldrb    w1, [x25, #129]
    0.00 :   ffff8000101031b0:       ldr     w0, [x0]
    0.00 :   ffff8000101031b4:       sub     w0, w0, #0x1
    0.00 :   ffff8000101031b8:       cmp     w1, w0
    0.00 :   ffff8000101031bc:       b.eq    ffff8000101031c4 <rcu_sched_clock_irq+0x3ac>  // b.none
    0.00 :   ffff8000101031c0:       brk     #0x800
    0.00 :   ffff8000101031c4:       ldr     x1, [sp, #112]
    0.00 :   ffff8000101031c8:       ldr     w0, [x25, #120]
    0.00 :   ffff8000101031cc:       sub     w0, w0, #0x1
    0.00 :   ffff8000101031d0:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff8000101031d4:       ldr     w26, [x25, #124]
    0.00 :   ffff8000101031d8:       mov     w21, w0
    0.00 :   ffff8000101031dc:       ldr     w22, [sp, #104]
    0.00 :   ffff8000101031e0:       cmp     w21, w26
    0.00 :   ffff8000101031e4:       b.gt    ffff800010103594 <rcu_sched_clock_irq+0x77c>
         : 545              raw_spin_lock_irqsave_rcu_node(rnp, flags);
    0.00 :   ffff8000101031e8:       ldr     w1, [x25, #120]
    0.00 :   ffff8000101031ec:       ldr     x0, [x25, #32]
    0.00 :   ffff8000101031f0:       sub     w1, w21, w1
    0.00 :   ffff8000101031f4:       lsr     x0, x0, x1
    0.00 :   ffff8000101031f8:       tbz     w0, #0, ffff80001010320c <rcu_sched_clock_irq+0x3f4>
         : 546              if (rnp->qsmask != 0) {
    0.00 :   ffff8000101031fc:       mov     w0, w21
    0.00 :   ffff800010103200:       bl      ffff800010e1a45c <print_cpu_stall_info>
         : 547              for_each_leaf_node_possible_cpu(rnp, cpu)
    0.00 :   ffff800010103204:       ldr     w26, [x25, #124]
    0.00 :   ffff800010103208:       add     w22, w22, #0x1
         : 544              rcu_for_each_leaf_node(rnp) {
    0.00 :   ffff80001010320c:       ldr     x1, [sp, #112]
    0.00 :   ffff800010103210:       mov     w0, w21
    0.00 :   ffff800010103214:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff800010103218:       mov     w21, w0
    0.00 :   ffff80001010321c:       b       ffff8000101031e0 <rcu_sched_clock_irq+0x3c8>
         : 550              rcu_flavor_sched_clock_irq():
         : 752              rcu_preempt_depth_set(1);
    0.00 :   ffff800010103220:       bl      ffff8000100ffe88 <rcu_is_cpu_rrupt_from_idle>
    0.00 :   ffff800010103224:       cbnz    w0, ffff800010102e94 <rcu_sched_clock_irq+0x7c>
    0.00 :   ffff800010103228:       b       ffff800010102ea4 <rcu_sched_clock_irq+0x8c>
         : 756              rcu_sched_clock_irq():
         : 2642             /* rcu_initiate_boost() releases rnp->lock */
    0.00 :   ffff80001010322c:       bl      ffff8000100ffe88 <rcu_is_cpu_rrupt_from_idle>
    0.00 :   ffff800010103230:       orr     w0, w0, w21
    0.00 :   ffff800010103234:       cbz     w0, ffff8000101032e0 <rcu_sched_clock_irq+0x4c8>
         : 2646             continue;
    0.00 :   ffff800010103238:       add     x0, x19, #0x125
         : 2648             __kern_my_cpu_offset():
    0.00 :   ffff80001010323c:       mrs     x1, tpidr_el1
         : 40               rcu_sched_clock_irq():
    0.00 :   ffff800010103240:       strb    wzr, [x0, x1]
    0.00 :   ffff800010103244:       b       ffff800010102e8c <rcu_sched_clock_irq+0x74>
         : 2648             arch_static_branch_jump():
    0.00 :   ffff800010103248:       b       ffff800010103280 <rcu_sched_clock_irq+0x468>
    0.00 :   ffff80001010324c:       b       ffff800010103280 <rcu_sched_clock_irq+0x468>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010103250:       mov     x0, #0x2                        // #2
    0.00 :   ffff800010103254:       stset   x0, [x5]
    0.00 :   ffff800010103258:       b       ffff800010103284 <rcu_sched_clock_irq+0x46c>
         : 181              rcu_flavor_sched_clock_irq():
         : 762              }
    0.00 :   ffff80001010325c:       mov     x0, x5
    0.00 :   ffff800010103260:       bl      ffff8000100ff0f0 <rcu_preempt_need_deferred_qs>
    0.00 :   ffff800010103264:       tst     w0, #0xff
    0.00 :   ffff800010103268:       b.ne    ffff800010103448 <rcu_sched_clock_irq+0x630>  // b.any
         : 765              * Dump the blocked-tasks state, but limit the list dump to the
    0.00 :   ffff80001010326c:       ldr     w0, [x3, #732]
    0.00 :   ffff800010103270:       cbnz    w0, ffff800010103460 <rcu_sched_clock_irq+0x648>
         : 766              * specified number of elements.
    0.00 :   ffff800010103274:       bl      ffff8000100ff130 <rcu_qs>
         : 767              */
    0.00 :   ffff800010103278:       mov     x1, sp
    0.00 :   ffff80001010327c:       b       ffff800010102f00 <rcu_sched_clock_irq+0xe8>
         : 770              __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010103280:       b       ffff800010104660 <rcu_needs_cpu+0x2e8>
         : 229              get_current():
    0.00 :   ffff800010103284:       mrs     x0, sp_el0
         : 20               set_preempt_need_resched():
         : 31               task_thread_info(p)->preempt_count = PREEMPT_DISABLED; \
         : 32               } while (0)
         :
         : 34               static inline void set_preempt_need_resched(void)
         : 35               {
         : 36               current_thread_info()->preempt.need_resched = 0;
    0.00 :   ffff800010103288:       str     wzr, [x0, #12]
    0.00 :   ffff80001010328c:       b       ffff800010102ed0 <rcu_sched_clock_irq+0xb8>
         : 39               rcu_flavor_sched_clock_irq():
         : 773              struct list_head *lhp;
    0.00 :   ffff800010103290:       ldrb    w0, [x5, #737]
         : 775              bool onl;
         : 776              struct rcu_data *rdp;
    0.00 :   ffff800010103294:       adrp    x7, ffff800011cb3000 <_rs.29273+0x20>
    0.00 :   ffff800010103298:       add     x28, x7, #0xa80
         : 773              struct list_head *lhp;
    0.00 :   ffff80001010329c:       cbnz    w0, ffff800010102f08 <rcu_sched_clock_irq+0xf0>
         : 775              struct rcu_data *rdp;
    0.00 :   ffff8000101032a0:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000101032a4:       ldr     x2, [x0, #2432]
    0.00 :   ffff8000101032a8:       ldr     x0, [x28, #9064]
    0.00 :   ffff8000101032ac:       add     x0, x0, #0xfa
    0.00 :   ffff8000101032b0:       cmp     x0, x2
    0.00 :   ffff8000101032b4:       b.pl    ffff800010102f08 <rcu_sched_clock_irq+0xf0>  // b.nfrst
         : 776              struct rcu_node *rnp1;
    0.00 :   ffff8000101032b8:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000101032bc:       strb    w0, [x5, #737]
    0.00 :   ffff8000101032c0:       b       ffff800010102f08 <rcu_sched_clock_irq+0xf0>
         : 780              rcu_jiffies_till_stall_check():
         : 38               WRITE_ONCE(rcu_cpu_stall_timeout, 3);
    0.00 :   ffff8000101032c4:       cmp     w0, #0x12c
    0.00 :   ffff8000101032c8:       b.le    ffff800010103300 <rcu_sched_clock_irq+0x4e8>
         : 39               till_stall_check = 3;
    0.00 :   ffff8000101032cc:       mov     x0, #0x6ee8                     // #28392
    0.00 :   ffff8000101032d0:       mov     w1, #0x12c                      // #300
    0.00 :   ffff8000101032d4:       movk    x0, #0x3, lsl #16
    0.00 :   ffff8000101032d8:       str     w1, [x14, #2876]
         : 40               } else if (till_stall_check > 300) {
    0.00 :   ffff8000101032dc:       b       ffff800010103098 <rcu_sched_clock_irq+0x280>
         : 42               get_current():
    0.00 :   ffff8000101032e0:       mrs     x0, sp_el0
         : 20               arch_static_branch_jump():
    0.00 :   ffff8000101032e4:       b       ffff800010103310 <rcu_sched_clock_irq+0x4f8>
    0.00 :   ffff8000101032e8:       b       ffff800010103310 <rcu_sched_clock_irq+0x4f8>
         : 40               __lse_atomic64_or():
    0.00 :   ffff8000101032ec:       mov     x1, #0x2                        // #2
    0.00 :   ffff8000101032f0:       stset   x1, [x0]
         : 179              get_current():
    0.00 :   ffff8000101032f4:       mrs     x0, sp_el0
         : 20               set_preempt_need_resched():
    0.00 :   ffff8000101032f8:       str     wzr, [x0, #12]
    0.00 :   ffff8000101032fc:       b       ffff800010103238 <rcu_sched_clock_irq+0x420>
    0.00 :   ffff800010103300:       mov     w1, #0x2ee                      // #750
    0.00 :   ffff800010103304:       mul     w0, w0, w1
    0.00 :   ffff800010103308:       sxtw    x0, w0
    0.00 :   ffff80001010330c:       b       ffff800010103098 <rcu_sched_clock_irq+0x280>
         : 37               __ll_sc_atomic64_or():
    0.00 :   ffff800010103310:       b       ffff800010104678 <rcu_needs_cpu+0x300>
    0.00 :   ffff800010103314:       b       ffff8000101032f4 <rcu_sched_clock_irq+0x4dc>
         : 224              arch_static_branch_jump():
    0.00 :   ffff800010103318:       b       ffff800010103478 <rcu_sched_clock_irq+0x660>
    0.00 :   ffff80001010331c:       b       ffff800010103478 <rcu_sched_clock_irq+0x660>
         : 40               __lse__cmpxchg_case_mb_64():
         : 379              __CMPXCHG_CASE(x,  ,  mb_, 64, al, "memory")
    0.00 :   ffff800010103320:       adrp    x0, ffff800011cb5000 <rcu_state+0x1580>
    0.00 :   ffff800010103324:       mov     x1, x4
    0.00 :   ffff800010103328:       mov     x2, x5
    0.00 :   ffff80001010332c:       add     x0, x0, #0xe08
    0.00 :   ffff800010103330:       mov     x6, #0x2388                     // #9096
    0.00 :   ffff800010103334:       add     x6, x28, x6
    0.00 :   ffff800010103338:       mov     x8, x1
    0.00 :   ffff80001010333c:       casal   x8, x2, [x6]
    0.00 :   ffff800010103340:       mov     x0, x8
         : 389              check_cpu_stall():
         : 695              return; /* No stall or GP completed since entering function. */
    0.00 :   ffff800010103344:       cmp     x4, x0
    0.00 :   ffff800010103348:       b.ne    ffff8000101030c0 <rcu_sched_clock_irq+0x2a8>  // b.any
         : 698              rcu_stall_kick_kthreads():
         : 167              return;
    0.00 :   ffff80001010334c:       ldrb    w0, [x24, #60]
         : 169              print_cpu_stall():
         : 594              {
    0.00 :   ffff800010103350:       mov     x2, x19
         : 596              __kern_my_cpu_offset():
    0.00 :   ffff800010103354:       mrs     x1, tpidr_el1
    0.00 :   ffff800010103358:       str     x1, [sp, #104]
         : 41               rcu_stall_kick_kthreads():
         : 167              return;
    0.00 :   ffff80001010335c:       tst     w0, #0xff
    0.00 :   ffff800010103360:       b.eq    ffff800010103370 <rcu_sched_clock_irq+0x558>  // b.none
    0.00 :   ffff800010103364:       stp     x7, x2, [sp, #112]
    0.00 :   ffff800010103368:       bl      ffff8000100ffee8 <rcu_stall_kick_kthreads.part.88>
    0.00 :   ffff80001010336c:       ldp     x7, x2, [sp, #112]
         : 173              rcu_stall_is_suppressed_at_boot():
         : 205              return rcu_cpu_stall_suppress_at_boot && !rcu_inkernel_boot_has_ended();
    0.00 :   ffff800010103370:       ldr     w0, [x25, #2884]
    0.00 :   ffff800010103374:       cbnz    w0, ffff8000101034e0 <rcu_sched_clock_irq+0x6c8>
         : 208              rcu_stall_is_suppressed():
         : 217              return rcu_stall_is_suppressed_at_boot() || rcu_cpu_stall_suppress;
    0.00 :   ffff800010103378:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010337c:       ldr     w0, [x0, #2872]
    0.00 :   ffff800010103380:       cbnz    w0, ffff8000101034f4 <rcu_sched_clock_irq+0x6dc>
         : 221              print_cpu_stall():
         : 594              {
    0.00 :   ffff800010103384:       ldr     x0, [sp, #104]
    0.00 :   ffff800010103388:       str     x7, [sp, #120]
         : 611              * RCU CPU stall warnings.
    0.00 :   ffff80001010338c:       ldr     x1, [x28, #9120]
         : 594              {
    0.00 :   ffff800010103390:       add     x0, x2, x0
    0.00 :   ffff800010103394:       str     x0, [sp, #104]
         : 611              * RCU CPU stall warnings.
    0.00 :   ffff800010103398:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff80001010339c:       add     x0, x0, #0x828
         : 596              unsigned long flags;
    0.00 :   ffff8000101033a0:       mov     x25, #0x0                       // #0
         : 611              * RCU CPU stall warnings.
    0.00 :   ffff8000101033a4:       bl      ffff800010e19544 <printk>
         : 612              */
    0.00 :   ffff8000101033a8:       ldr     x0, [sp, #104]
    0.00 :   ffff8000101033ac:       ldr     x0, [x0, #24]
    0.00 :   ffff8000101033b0:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff8000101033b4:       str     x0, [sp, #112]
         : 613              trace_rcu_stall_warning(rcu_state.name, TPS("SelfDetected"));
    0.00 :   ffff8000101033b8:       adrp    x2, ffff80001176d000 <cpu_number>
    0.00 :   ffff8000101033bc:       add     x2, x2, #0x0
    0.00 :   ffff8000101033c0:       bl      ffff8000100fd320 <__kern_my_cpu_offset>
    0.00 :   ffff8000101033c4:       ldr     w0, [x2, x0]
    0.00 :   ffff8000101033c8:       bl      ffff800010e1a45c <print_cpu_stall_info>
         : 614              pr_err("INFO: %s self-detected stall on CPU\n", rcu_state.name);
    0.00 :   ffff8000101033cc:       ldp     x0, x1, [sp, #104]
    0.00 :   ffff8000101033d0:       ldr     x0, [x0, #24]
    0.00 :   ffff8000101033d4:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 615              raw_spin_lock_irqsave_rcu_node(rdp->mynode, flags);
    0.00 :   ffff8000101033d8:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101033dc:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101033e0:       ldr     x7, [sp, #120]
    0.00 :   ffff8000101033e4:       str     x28, [sp, #120]
    0.00 :   ffff8000101033e8:       ldr     w4, [x0, #3120]
    0.00 :   ffff8000101033ec:       mov     x28, x26
    0.00 :   ffff8000101033f0:       add     x0, x1, #0xa08
    0.00 :   ffff8000101033f4:       mov     w26, w21
    0.00 :   ffff8000101033f8:       mov     w21, w4
    0.00 :   ffff8000101033fc:       stp     x22, x0, [sp, #104]
    0.00 :   ffff800010103400:       mov     x22, x7
    0.00 :   ffff800010103404:       mov     w0, #0xffffffff                 // #-1
    0.00 :   ffff800010103408:       ldr     x1, [sp, #112]
    0.00 :   ffff80001010340c:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff800010103410:       cmp     w0, w21
    0.00 :   ffff800010103414:       adrp    x1, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff800010103418:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff80001010341c:       add     x3, x1, #0x760
    0.00 :   ffff800010103420:       b.cs    ffff800010103714 <rcu_sched_clock_irq+0x8fc>  // b.hs, b.nlast
         : 635              rcu_get_n_cbs_cpu():
         : 234              /*
    0.00 :   ffff800010103424:       ldr     x2, [x3, w0, sxtw #3]
    0.00 :   ffff800010103428:       mov     x1, x19
    0.00 :   ffff80001010342c:       add     x1, x1, x2
         : 238              rcu_segcblist_test_flags():
         : 71               return READ_ONCE(rsclp->flags) & flags;
    0.00 :   ffff800010103430:       add     x1, x1, #0x70
    0.00 :   ffff800010103434:       ldrb    w2, [x1, #112]
         : 74               rcu_get_n_cbs_cpu():
         : 236              * Handles both the nocbs and normal cases.
    0.00 :   ffff800010103438:       tbz     w2, #0, ffff8000101037e4 <rcu_sched_clock_irq+0x9cc>
         : 238              rcu_segcblist_n_cbs():
         : 52               return READ_ONCE(rsclp->len);
    0.00 :   ffff80001010343c:       ldr     x1, [x1, #72]
         : 54               print_cpu_stall():
         : 616              print_cpu_stall_info(smp_processor_id());
    0.00 :   ffff800010103440:       add     x25, x25, x1
    0.00 :   ffff800010103444:       b       ffff800010103408 <rcu_sched_clock_irq+0x5f0>
         : 619              rcu_flavor_sched_clock_irq():
         :
    0.00 :   ffff800010103448:       mov     x0, x5
    0.00 :   ffff80001010344c:       bl      ffff800010101e28 <rcu_preempt_deferred_qs>
         : 764              /*
    0.00 :   ffff800010103450:       adrp    x7, ffff800011cb3000 <_rs.29273+0x20>
    0.00 :   ffff800010103454:       mov     x1, sp
    0.00 :   ffff800010103458:       add     x28, x7, #0xa80
    0.00 :   ffff80001010345c:       b       ffff800010102f08 <rcu_sched_clock_irq+0xf0>
         : 765              * Dump the blocked-tasks state, but limit the list dump to the
    0.00 :   ffff800010103460:       brk     #0x800
    0.00 :   ffff800010103464:       b       ffff800010102ed0 <rcu_sched_clock_irq+0xb8>
         : 768              __ll_sc__cmpxchg_case_mb_64():
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
         : 316              __CMPXCHG_CASE(w, b,  mb_,  8, dmb ish,  , l, "memory", K)
         : 317              __CMPXCHG_CASE(w, h,  mb_, 16, dmb ish,  , l, "memory", K)
         : 318              __CMPXCHG_CASE(w,  ,  mb_, 32, dmb ish,  , l, "memory", K)
         : 319              __CMPXCHG_CASE( ,  ,  mb_, 64, dmb ish,  , l, "memory", L)
    0.00 :   ffff800010103468:       mov     x1, #0x2388                     // #9096
    0.00 :   ffff80001010346c:       add     x2, x28, x1
    0.00 :   ffff800010103470:       b       ffff800010104694 <rcu_needs_cpu+0x31c>
    0.00 :   ffff800010103474:       b       ffff800010103100 <rcu_sched_clock_irq+0x2e8>
    0.00 :   ffff800010103478:       mov     x0, #0x2388                     // #9096
    0.00 :   ffff80001010347c:       add     x2, x28, x0
    0.00 :   ffff800010103480:       b       ffff8000101046b4 <rcu_needs_cpu+0x33c>
    0.00 :   ffff800010103484:       b       ffff800010103344 <rcu_sched_clock_irq+0x52c>
    0.00 :   ffff800010103488:       stp     x7, x12, [sp, #104]
         : 329              rcu_stall_is_suppressed_at_boot():
         : 205              return rcu_cpu_stall_suppress_at_boot && !rcu_inkernel_boot_has_ended();
    0.00 :   ffff80001010348c:       bl      ffff8000100fa780 <rcu_inkernel_boot_has_ended>
    0.00 :   ffff800010103490:       tst     w0, #0xff
    0.00 :   ffff800010103494:       ldp     x7, x12, [sp, #104]
    0.00 :   ffff800010103498:       b.ne    ffff800010103128 <rcu_sched_clock_irq+0x310>  // b.any
         : 210              check_cpu_stall():
         : 709              * stopped the vm.
         : 710              */
         : 711              if (kvm_check_and_clear_guest_paused())
         : 712              return;
         :
    0.00 :   ffff80001010349c:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101034a0:       ldr     w0, [x0, #2888]
    0.00 :   ffff8000101034a4:       cbz     w0, ffff800010102f80 <rcu_sched_clock_irq+0x168>
         : 717              atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff8000101034a8:       ldr     w0, [x24, #72]
         : 35               check_cpu_stall():
         : 710              /* We haven't checked in, so go dump stack. */
    0.00 :   ffff8000101034ac:       cbnz    w0, ffff800010102f80 <rcu_sched_clock_irq+0x168>
         : 712              __xchg_mb():
         : 88               }
         :
         : 90               __XCHG_GEN()
         : 91               __XCHG_GEN(_acq)
         : 92               __XCHG_GEN(_rel)
         : 93               __XCHG_GEN(_mb)
    0.00 :   ffff8000101034b0:       add     x0, x24, #0x48
    0.00 :   ffff8000101034b4:       bl      ffff8000100fe340 <__xchg_case_mb_32.constprop.105>
         : 96               check_cpu_stall():
    0.00 :   ffff8000101034b8:       cbnz    w0, ffff800010102f80 <rcu_sched_clock_irq+0x168>
    0.00 :   ffff8000101034bc:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101034c0:       ldr     w1, [x0, #2872]
    0.00 :   ffff8000101034c4:       cbnz    w1, ffff8000101034d0 <rcu_sched_clock_irq+0x6b8>
         :
    0.00 :   ffff8000101034c8:       str     wzr, [x0, #2872]
    0.00 :   ffff8000101034cc:       b       ffff800010102f80 <rcu_sched_clock_irq+0x168>
    0.00 :   ffff8000101034d0:       cmp     w1, #0x3
    0.00 :   ffff8000101034d4:       b.ne    ffff800010102f80 <rcu_sched_clock_irq+0x168>  // b.any
    0.00 :   ffff8000101034d8:       str     wzr, [x0, #2872]
    0.00 :   ffff8000101034dc:       b       ffff800010102f80 <rcu_sched_clock_irq+0x168>
    0.00 :   ffff8000101034e0:       stp     x7, x2, [sp, #112]
         : 709              rcu_stall_is_suppressed_at_boot():
    0.00 :   ffff8000101034e4:       bl      ffff8000100fa780 <rcu_inkernel_boot_has_ended>
    0.00 :   ffff8000101034e8:       tst     w0, #0xff
    0.00 :   ffff8000101034ec:       ldp     x7, x2, [sp, #112]
    0.00 :   ffff8000101034f0:       b.ne    ffff800010103378 <rcu_sched_clock_irq+0x560>  // b.any
         : 209              check_cpu_stall():
         : 700              cmpxchg(&rcu_state.jiffies_stall, js, jn) == js) {
    0.00 :   ffff8000101034f4:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101034f8:       ldr     w0, [x0, #2888]
    0.00 :   ffff8000101034fc:       cbz     w0, ffff800010102f80 <rcu_sched_clock_irq+0x168>
         : 704              atomic_read():
    0.00 :   ffff800010103500:       ldr     w0, [x24, #64]
         : 29               check_cpu_stall():
         :
    0.00 :   ffff800010103504:       cbnz    w0, ffff800010102f80 <rcu_sched_clock_irq+0x168>
         : 703              __xchg_mb():
    0.00 :   ffff800010103508:       add     x0, x24, #0x40
    0.00 :   ffff80001010350c:       bl      ffff8000100fe340 <__xchg_case_mb_32.constprop.105>
         : 90               check_cpu_stall():
    0.00 :   ffff800010103510:       cbnz    w0, ffff800010102f80 <rcu_sched_clock_irq+0x168>
    0.00 :   ffff800010103514:       b       ffff8000101034bc <rcu_sched_clock_irq+0x6a4>
         : 703              rcu_sched_clock_irq():
         : 2654             }
    0.00 :   ffff800010103518:       bl      ffff800010e2b8c8 <__stack_chk_fail>
    0.00 :   ffff80001010351c:       ldp     x7, x12, [sp, #136]
         : 2657             print_other_cpu_stall():
         : 554              lockdep_assert_irqs_disabled();
    0.00 :   ffff800010103520:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010103524:       ldp     x26, x22, [sp, #160]
         : 557              rcu_get_n_cbs_cpu():
         : 234              /*
    0.00 :   ffff800010103528:       adrp    x25, ffff800011c2d000 <xen_lateeoi_chip+0x68>
         : 236              print_other_cpu_stall():
    0.00 :   ffff80001010352c:       ldr     w3, [x0, #3120]
         : 525              unsigned long j;
    0.00 :   ffff800010103530:       mov     x4, #0x0                        // #0
    0.00 :   ffff800010103534:       ldr     w21, [sp, #152]
         : 528              rcu_get_n_cbs_cpu():
    0.00 :   ffff800010103538:       add     x25, x25, #0x760
    0.00 :   ffff80001010353c:       str     x28, [sp, #144]
    0.00 :   ffff800010103540:       mov     x28, x12
    0.00 :   ffff800010103544:       ldp     x27, x23, [sp, #120]
    0.00 :   ffff800010103548:       str     w21, [sp, #120]
    0.00 :   ffff80001010354c:       mov     x21, x4
    0.00 :   ffff800010103550:       stp     x26, x22, [sp, #128]
    0.00 :   ffff800010103554:       mov     x26, x7
    0.00 :   ffff800010103558:       mov     w22, w3
         : 243              print_other_cpu_stall():
         : 554              lockdep_assert_irqs_disabled();
    0.00 :   ffff80001010355c:       mov     w0, #0xffffffff                 // #-1
    0.00 :   ffff800010103560:       ldr     x1, [sp, #112]
    0.00 :   ffff800010103564:       bl      ffff8000104a7778 <cpumask_next>
    0.00 :   ffff800010103568:       cmp     w0, w22
    0.00 :   ffff80001010356c:       b.cs    ffff80001010385c <rcu_sched_clock_irq+0xa44>  // b.hs, b.nlast
         : 560              rcu_get_n_cbs_cpu():
    0.00 :   ffff800010103570:       ldr     x2, [x25, w0, sxtw #3]
    0.00 :   ffff800010103574:       mov     x1, x19
    0.00 :   ffff800010103578:       add     x1, x1, x2
         : 237              rcu_segcblist_test_flags():
         : 71               return READ_ONCE(rsclp->flags) & flags;
    0.00 :   ffff80001010357c:       add     x1, x1, #0x70
    0.00 :   ffff800010103580:       ldrb    w2, [x1, #112]
         : 74               rcu_get_n_cbs_cpu():
         : 236              * Handles both the nocbs and normal cases.
    0.00 :   ffff800010103584:       tbz     w2, #0, ffff800010103a74 <rcu_sched_clock_irq+0xc5c>
         : 238              rcu_segcblist_n_cbs():
         : 52               return READ_ONCE(rsclp->len);
    0.00 :   ffff800010103588:       ldr     x1, [x1, #72]
         : 54               print_other_cpu_stall():
         : 555              }
    0.00 :   ffff80001010358c:       add     x21, x21, x1
    0.00 :   ffff800010103590:       b       ffff800010103560 <rcu_sched_clock_irq+0x748>
    0.00 :   ffff800010103594:       str     w22, [sp, #104]
         : 559              rcu_preempt_blocked_readers_cgp():
         : 410              * rcu_read_unlock()) and ->rcu_read_unlock_special is non-zero, then
    0.00 :   ffff800010103598:       ldr     x0, [x25, #160]
         : 412              rcu_print_task_stall():
         : 270              raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
    0.00 :   ffff80001010359c:       cbnz    x0, ffff8000101035b8 <rcu_sched_clock_irq+0x7a0>
         : 271              return 0;
    0.00 :   ffff8000101035a0:       mov     w21, #0x0                       // #0
         : 273              print_other_cpu_stall():
         : 550              ndetected++;
    0.00 :   ffff8000101035a4:       ldr     w0, [sp, #104]
         : 541              */
    0.00 :   ffff8000101035a8:       add     x25, x25, #0x200
         : 550              ndetected++;
    0.00 :   ffff8000101035ac:       add     w0, w0, w21
    0.00 :   ffff8000101035b0:       str     w0, [sp, #104]
         : 551              }
    0.00 :   ffff8000101035b4:       b       ffff800010103178 <rcu_sched_clock_irq+0x360>
         : 553              rcu_print_task_stall():
         : 272              }
    0.00 :   ffff8000101035b8:       ldp     w2, w3, [x25, #120]
    0.00 :   ffff8000101035bc:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff8000101035c0:       ldrb    w1, [x25, #129]
    0.00 :   ffff8000101035c4:       add     x0, x0, #0x6f0
    0.00 :   ffff8000101035c8:       add     x27, x25, #0x90
         : 276              struct task_struct, rcu_node_entry);
    0.00 :   ffff8000101035cc:       mov     x21, #0x0                       // #0
         : 278              __lse_atomic_fetch_add_relaxed():
         : 52               ATOMIC_FETCH_OPS(add, ldadd)
    0.00 :   ffff8000101035d0:       mov     w26, #0x1                       // #1
         : 54               rcu_print_task_stall():
         : 272              }
    0.00 :   ffff8000101035d4:       bl      ffff800010e19544 <printk>
         : 274              rnp->level, rnp->grplo, rnp->grphi);
    0.00 :   ffff8000101035d8:       ldr     x0, [x25, #160]
         : 276              struct task_struct, rcu_node_entry);
    0.00 :   ffff8000101035dc:       ldr     x0, [x0, #8]
    0.00 :   ffff8000101035e0:       ldr     x2, [x0]
    0.00 :   ffff8000101035e4:       sub     x22, x2, #0x2e8
    0.00 :   ffff8000101035e8:       add     x0, x22, #0x2e8
    0.00 :   ffff8000101035ec:       mov     w1, w21
    0.00 :   ffff8000101035f0:       cmp     x0, x27
    0.00 :   ffff8000101035f4:       b.eq    ffff800010103638 <rcu_sched_clock_irq+0x820>  // b.none
         : 284              arch_atomic_fetch_add_relaxed():
         : 49               ATOMIC_FETCH_OP(        , op)
         :
         : 51               ATOMIC_FETCH_OPS(atomic_fetch_andnot)
         : 52               ATOMIC_FETCH_OPS(atomic_fetch_or)
         : 53               ATOMIC_FETCH_OPS(atomic_fetch_xor)
         : 54               ATOMIC_FETCH_OPS(atomic_fetch_add)
    0.00 :   ffff8000101035f8:       bl      ffff8000100fd2f8 <system_uses_lse_atomics>
    0.00 :   ffff8000101035fc:       tst     w0, #0xff
         : 57               __refcount_add():
         : 193              return __refcount_add_not_zero(i, r, NULL);
         : 194              }
         :
         : 196              static inline void __refcount_add(int i, refcount_t *r, int *oldp)
         : 197              {
         : 198              int old = atomic_fetch_add_relaxed(i, &r->refs);
    0.00 :   ffff800010103600:       add     x0, x22, #0x20
         : 200              arch_atomic_fetch_add_relaxed():
    0.00 :   ffff800010103604:       b.eq    ffff800010103708 <rcu_sched_clock_irq+0x8f0>  // b.none
         : 50               __lse_atomic_fetch_add_relaxed():
    0.00 :   ffff800010103608:       mov     w1, w26
    0.00 :   ffff80001010360c:       ldadd   w1, w1, [x0]
         : 54               __refcount_add():
         :
         : 199              if (oldp)
         : 200              *oldp = old;
         :
         : 202              if (unlikely(!old))
    0.00 :   ffff800010103610:       cmp     w1, #0x0
    0.00 :   ffff800010103614:       b.ne    ffff8000101039ec <rcu_sched_clock_irq+0xbd4>  // b.any
         : 199              refcount_warn_saturate(r, REFCOUNT_ADD_UAF);
    0.00 :   ffff800010103618:       mov     w1, #0x2                        // #2
    0.00 :   ffff80001010361c:       bl      ffff800010470e68 <refcount_warn_saturate>
         : 202              rcu_print_task_stall():
         : 278              get_task_struct(t);
    0.00 :   ffff800010103620:       add     x0, sp, #0xc8
    0.00 :   ffff800010103624:       str     x22, [x0, x21, lsl #3]
         : 279              ts[i++] = t;
    0.00 :   ffff800010103628:       add     x21, x21, #0x1
    0.00 :   ffff80001010362c:       cmp     x21, #0x8
    0.00 :   ffff800010103630:       b.ne    ffff800010103a80 <rcu_sched_clock_irq+0xc68>  // b.any
    0.00 :   ffff800010103634:       mov     w1, w21
         : 283              raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
    0.00 :   ffff800010103638:       sub     w21, w1, #0x1
         : 282              }
    0.00 :   ffff80001010363c:       mov     x0, x25
    0.00 :   ffff800010103640:       mov     x1, x23
         : 285              t = ts[--i];
    0.00 :   ffff800010103644:       adrp    x27, ffff8000100fd000 <srcu_gp_start_if_needed+0x350>
         : 288              else
    0.00 :   ffff800010103648:       adrp    x26, ffff80001141e000 <kallsyms_token_index+0x137a0>
         : 282              }
    0.00 :   ffff80001010364c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 283              raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
    0.00 :   ffff800010103650:       sxtw    x23, w21
         : 285              t = ts[--i];
    0.00 :   ffff800010103654:       add     x27, x27, #0xf98
         : 283              raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
    0.00 :   ffff800010103658:       cbz     w23, ffff800010103810 <rcu_sched_clock_irq+0x9f8>
         : 284              while (i) {
    0.00 :   ffff80001010365c:       add     x0, sp, #0xc8
         : 285              t = ts[--i];
    0.00 :   ffff800010103660:       add     x2, sp, #0xbc
    0.00 :   ffff800010103664:       mov     x1, x27
         : 284              while (i) {
    0.00 :   ffff800010103668:       ldr     x22, [x0, x23, lsl #3]
         : 285              t = ts[--i];
    0.00 :   ffff80001010366c:       mov     x0, x22
    0.00 :   ffff800010103670:       bl      ffff8000100b62d8 <try_invoke_on_locked_down_task>
    0.00 :   ffff800010103674:       tst     w0, #0xff
    0.00 :   ffff800010103678:       b.eq    ffff800010103820 <rcu_sched_clock_irq+0xa08>  // b.none
         : 288              else
    0.00 :   ffff80001010367c:       ldrb    w5, [sp, #194]
    0.00 :   ffff800010103680:       adrp    x2, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff800010103684:       ldrb    w4, [sp, #193]
    0.00 :   ffff800010103688:       add     x2, x2, #0x890
    0.00 :   ffff80001010368c:       ldrb    w3, [sp, #192]
    0.00 :   ffff800010103690:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff800010103694:       ldrb    w6, [sp, #196]
    0.00 :   ffff800010103698:       add     x0, x0, #0x898
    0.00 :   ffff80001010369c:       adrp    x1, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff8000101036a0:       add     x7, x26, #0x888
    0.00 :   ffff8000101036a4:       add     x1, x1, #0x8a0
    0.00 :   ffff8000101036a8:       ldrb    w5, [x2, x5]
    0.00 :   ffff8000101036ac:       ldrb    w4, [x0, x4]
    0.00 :   ffff8000101036b0:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff8000101036b4:       ldrb    w6, [x7, x6]
    0.00 :   ffff8000101036b8:       add     x0, x0, #0x730
    0.00 :   ffff8000101036bc:       ldrb    w3, [x1, x3]
    0.00 :   ffff8000101036c0:       ldr     w2, [sp, #188]
    0.00 :   ffff8000101036c4:       ldr     w1, [x22, #1096]
    0.00 :   ffff8000101036c8:       bl      ffff800010e19544 <printk>
         : 309              arch_atomic_fetch_sub_release():
         : 51               ATOMIC_FETCH_OPS(atomic_fetch_and)
         : 52               ATOMIC_FETCH_OPS(atomic_fetch_sub)
    0.00 :   ffff8000101036cc:       bl      ffff8000100fd2f8 <system_uses_lse_atomics>
    0.00 :   ffff8000101036d0:       tst     w0, #0xff
         : 55               put_task_struct():
         :
         : 113              extern void __put_task_struct(struct task_struct *t);
         :
         : 115              static inline void put_task_struct(struct task_struct *t)
         : 116              {
         : 117              if (refcount_dec_and_test(&t->usage))
    0.00 :   ffff8000101036d4:       add     x0, x22, #0x20
         : 119              arch_atomic_fetch_sub_release():
    0.00 :   ffff8000101036d8:       b.eq    ffff800010103834 <rcu_sched_clock_irq+0xa1c>  // b.none
         : 52               __lse_atomic_fetch_sub_release():
         : 161              ATOMIC_FETCH_OP_SUB(_release,  l, "memory")
    0.00 :   ffff8000101036dc:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000101036e0:       neg     w1, w1
    0.00 :   ffff8000101036e4:       ldaddl  w1, w1, [x0]
         : 165              __refcount_sub_and_test():
         : 277              int old = atomic_fetch_sub_release(i, &r->refs);
         :
         : 279              if (oldp)
         : 280              *oldp = old;
         :
         : 282              if (old == i) {
    0.00 :   ffff8000101036e8:       cmp     w1, #0x1
    0.00 :   ffff8000101036ec:       b.ne    ffff800010103844 <rcu_sched_clock_irq+0xa2c>  // b.any
         : 278              smp_acquire__after_ctrl_dep();
    0.00 :   ffff8000101036f0:       dmb     ishld
         : 280              put_task_struct():
         : 113              __put_task_struct(t);
    0.00 :   ffff8000101036f4:       mov     x0, x22
    0.00 :   ffff8000101036f8:       bl      ffff80001007df38 <__put_task_struct>
         : 116              rcu_print_task_stall():
         : 296              put_task_struct(t);
    0.00 :   ffff8000101036fc:       sub     x23, x23, #0x1
         : 283              raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
    0.00 :   ffff800010103700:       cbz     w23, ffff800010103810 <rcu_sched_clock_irq+0x9f8>
    0.00 :   ffff800010103704:       b       ffff80001010365c <rcu_sched_clock_irq+0x844>
         : 286              __ll_sc_atomic_fetch_add_relaxed():
         : 111              ATOMIC_OPS(add, add, I)
    0.00 :   ffff800010103708:       add     x4, x22, #0x20
    0.00 :   ffff80001010370c:       b       ffff8000101046d4 <rcu_needs_cpu+0x35c>
    0.00 :   ffff800010103710:       b       ffff800010103610 <rcu_sched_clock_irq+0x7f8>
         : 115              rcu_seq_current():
         : 99               return READ_ONCE(*sp);
    0.00 :   ffff800010103714:       mov     w21, w26
    0.00 :   ffff800010103718:       mov     x26, x28
    0.00 :   ffff80001010371c:       ldr     x28, [sp, #120]
         : 103              print_cpu_stall():
         : 617              raw_spin_unlock_irqrestore_rcu_node(rdp->mynode, flags);
    0.00 :   ffff800010103720:       mov     x3, x25
    0.00 :   ffff800010103724:       ldr     x1, [x11, #2432]
    0.00 :   ffff800010103728:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
         : 621              rcu_seq_current():
    0.00 :   ffff80001010372c:       ldr     x2, [x28, #8776]
         : 100              print_cpu_stall():
    0.00 :   ffff800010103730:       sub     x1, x1, x22
    0.00 :   ffff800010103734:       add     x0, x0, #0x6d0
    0.00 :   ffff800010103738:       ldr     x22, [sp, #104]
    0.00 :   ffff80001010373c:       bl      ffff800010e19544 <printk>
         : 621              jiffies - gps,
    0.00 :   ffff800010103740:       bl      ffff800010e19b64 <rcu_check_gp_kthread_expired_fqs_timer>
         : 622              (long)rcu_seq_current(&rcu_state.gp_seq), totqlen);
    0.00 :   ffff800010103744:       bl      ffff800010e19c50 <rcu_check_gp_kthread_starvation>
         : 624              rcu_check_gp_kthread_expired_fqs_timer();
    0.00 :   ffff800010103748:       bl      ffff800010e19d84 <rcu_dump_cpu_stacks>
         :
    0.00 :   ffff80001010374c:       mov     x0, x28
    0.00 :   ffff800010103750:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         :
    0.00 :   ffff800010103754:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010103758:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010375c:       ldr     x2, [x11, #2432]
    0.00 :   ffff800010103760:       ldr     x1, [x28, #9096]
    0.00 :   ffff800010103764:       cmp     x2, x1
    0.00 :   ffff800010103768:       b.mi    ffff800010103798 <rcu_sched_clock_irq+0x980>  // b.first
         : 635              rcu_jiffies_till_stall_check():
         : 29               int rcu_jiffies_till_stall_check(void)
    0.00 :   ffff80001010376c:       ldr     w2, [x14, #2876]
         : 35               * for CONFIG_RCU_CPU_STALL_TIMEOUT.
    0.00 :   ffff800010103770:       cmp     w2, #0x2
    0.00 :   ffff800010103774:       b.gt    ffff8000101037f0 <rcu_sched_clock_irq+0x9d8>
         : 36               */
    0.00 :   ffff800010103778:       mov     w2, #0x3                        // #3
    0.00 :   ffff80001010377c:       str     w2, [x14, #2876]
         : 39               print_cpu_stall():
         : 629              raw_spin_lock_irqsave_rcu_node(rnp, flags);
    0.00 :   ffff800010103780:       mov     w1, #0x2ee                      // #750
    0.00 :   ffff800010103784:       ldr     x3, [x11, #2432]
    0.00 :   ffff800010103788:       mul     w2, w2, w1
    0.00 :   ffff80001010378c:       add     x3, x3, #0x3
    0.00 :   ffff800010103790:       add     x2, x3, w2, sxtw
    0.00 :   ffff800010103794:       str     x2, [x28, #9096]
         : 631              if (ULONG_CMP_GE(jiffies, READ_ONCE(rcu_state.jiffies_stall)))
    0.00 :   ffff800010103798:       mov     x1, x0
    0.00 :   ffff80001010379c:       mov     x0, x28
    0.00 :   ffff8000101037a0:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 635              panic_on_rcu_stall():
         : 112              static int cpu_stall;
    0.00 :   ffff8000101037a4:       ldr     w0, [x24, #16]
    0.00 :   ffff8000101037a8:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101037ac:       add     w0, w0, #0x1
    0.00 :   ffff8000101037b0:       ldr     w1, [x1, #2912]
    0.00 :   ffff8000101037b4:       str     w0, [x24, #16]
    0.00 :   ffff8000101037b8:       cmp     w0, w1
    0.00 :   ffff8000101037bc:       b.lt    ffff8000101037c4 <rcu_sched_clock_irq+0x9ac>  // b.tstop
    0.00 :   ffff8000101037c0:       bl      ffff8000100fe008 <panic_on_rcu_stall.part.89>
         : 121              get_current():
    0.00 :   ffff8000101037c4:       mrs     x0, sp_el0
         : 20               arch_static_branch_jump():
    0.00 :   ffff8000101037c8:       b       ffff800010103808 <rcu_sched_clock_irq+0x9f0>
    0.00 :   ffff8000101037cc:       b       ffff800010103808 <rcu_sched_clock_irq+0x9f0>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff8000101037d0:       mov     x1, #0x2                        // #2
    0.00 :   ffff8000101037d4:       stset   x1, [x0]
         : 180              get_current():
    0.00 :   ffff8000101037d8:       mrs     x0, sp_el0
         : 20               set_preempt_need_resched():
    0.00 :   ffff8000101037dc:       str     wzr, [x0, #12]
    0.00 :   ffff8000101037e0:       b       ffff8000101034f4 <rcu_sched_clock_irq+0x6dc>
         : 33               rcu_get_n_cbs_cpu():
         : 238              static long rcu_get_n_cbs_cpu(int cpu)
    0.00 :   ffff8000101037e4:       mov     x1, #0x0                        // #0
         : 240              print_cpu_stall():
         : 616              print_cpu_stall_info(smp_processor_id());
    0.00 :   ffff8000101037e8:       add     x25, x25, x1
    0.00 :   ffff8000101037ec:       b       ffff800010103408 <rcu_sched_clock_irq+0x5f0>
         : 619              rcu_jiffies_till_stall_check():
         : 38               WRITE_ONCE(rcu_cpu_stall_timeout, 3);
    0.00 :   ffff8000101037f0:       cmp     w2, #0x12c
    0.00 :   ffff8000101037f4:       b.le    ffff800010103780 <rcu_sched_clock_irq+0x968>
         : 39               till_stall_check = 3;
    0.00 :   ffff8000101037f8:       mov     w3, #0x12c                      // #300
         : 40               } else if (till_stall_check > 300) {
    0.00 :   ffff8000101037fc:       mov     w2, w3
         : 39               till_stall_check = 3;
    0.00 :   ffff800010103800:       str     w3, [x14, #2876]
         : 40               } else if (till_stall_check > 300) {
    0.00 :   ffff800010103804:       b       ffff800010103780 <rcu_sched_clock_irq+0x968>
         : 42               __ll_sc_atomic64_or():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010103808:       b       ffff8000101046ec <rcu_needs_cpu+0x374>
    0.00 :   ffff80001010380c:       b       ffff8000101037d8 <rcu_sched_clock_irq+0x9c0>
         : 225              rcu_print_task_stall():
         : 298              }
    0.00 :   ffff800010103810:       adrp    x0, ffff80001140b000 <kallsyms_token_index+0x7a0>
    0.00 :   ffff800010103814:       add     x0, x0, #0xcd0
    0.00 :   ffff800010103818:       bl      ffff800010e19544 <printk>
         : 299              pr_cont("\n");
    0.00 :   ffff80001010381c:       b       ffff8000101035a4 <rcu_sched_clock_irq+0x78c>
         : 286              if (!try_invoke_on_locked_down_task(t, check_slow_task, &rscr))
    0.00 :   ffff800010103820:       ldr     w1, [x22, #1096]
    0.00 :   ffff800010103824:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff800010103828:       add     x0, x0, #0x4c8
    0.00 :   ffff80001010382c:       bl      ffff800010e19544 <printk>
    0.00 :   ffff800010103830:       b       ffff8000101036cc <rcu_sched_clock_irq+0x8b4>
         : 292              __ll_sc_atomic_fetch_sub_release():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010103834:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010103838:       add     x5, x22, #0x20
    0.00 :   ffff80001010383c:       b       ffff800010104704 <rcu_needs_cpu+0x38c>
    0.00 :   ffff800010103840:       b       ffff8000101036e8 <rcu_sched_clock_irq+0x8d0>
         : 117              __refcount_sub_and_test():
         : 282              return true;
         : 283              }
         :
         : 285              if (unlikely(old < 0 || old - i < 0))
    0.00 :   ffff800010103844:       cmp     w1, #0x0
    0.00 :   ffff800010103848:       b.gt    ffff8000101036fc <rcu_sched_clock_irq+0x8e4>
         : 283              refcount_warn_saturate(r, REFCOUNT_SUB_UAF);
    0.00 :   ffff80001010384c:       mov     w1, #0x3                        // #3
    0.00 :   ffff800010103850:       sub     x23, x23, #0x1
    0.00 :   ffff800010103854:       bl      ffff800010470e68 <refcount_warn_saturate>
         : 287              rcu_print_task_stall():
         : 296              put_task_struct(t);
    0.00 :   ffff800010103858:       b       ffff800010103700 <rcu_sched_clock_irq+0x8e8>
         : 298              print_other_cpu_stall():
         :
    0.00 :   ffff80001010385c:       mov     x12, x28
    0.00 :   ffff800010103860:       mov     x7, x26
    0.00 :   ffff800010103864:       mov     x4, x21
    0.00 :   ffff800010103868:       adrp    x1, ffff80001176d000 <cpu_number>
    0.00 :   ffff80001010386c:       add     x1, x1, #0x0
    0.00 :   ffff800010103870:       ldr     w21, [sp, #120]
    0.00 :   ffff800010103874:       ldr     x28, [sp, #144]
    0.00 :   ffff800010103878:       str     x12, [sp, #112]
    0.00 :   ffff80001010387c:       str     x7, [sp, #152]
    0.00 :   ffff800010103880:       ldp     x26, x22, [sp, #128]
    0.00 :   ffff800010103884:       bl      ffff8000100fd320 <__kern_my_cpu_offset>
    0.00 :   ffff800010103888:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff80001010388c:       ldr     x2, [x11, #2432]
    0.00 :   ffff800010103890:       ldr     w1, [x1, x0]
    0.00 :   ffff800010103894:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff800010103898:       ldr     x7, [sp, #152]
    0.00 :   ffff80001010389c:       add     x0, x0, #0x748
         : 574              rcu_seq_current():
    0.00 :   ffff8000101038a0:       ldr     x3, [x28, #8776]
         : 100              print_other_cpu_stall():
    0.00 :   ffff8000101038a4:       sub     x2, x2, x7
    0.00 :   ffff8000101038a8:       bl      ffff800010e19544 <printk>
         : 559              pr_cont("\t(detected by %d, t=%ld jiffies, g=%ld, q=%lu)\n",
    0.00 :   ffff8000101038ac:       ldr     w0, [sp, #104]
    0.00 :   ffff8000101038b0:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000101038b4:       ldr     x12, [sp, #112]
    0.00 :   ffff8000101038b8:       cbz     w0, ffff800010103920 <rcu_sched_clock_irq+0xb08>
         : 560              smp_processor_id(), (long)(jiffies - gps),
    0.00 :   ffff8000101038bc:       bl      ffff800010e19d84 <rcu_dump_cpu_stacks>
         : 563              rcu_dump_cpu_stacks();
    0.00 :   ffff8000101038c0:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101038c4:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101038c8:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000101038cc:       ldr     w0, [x0, #2896]
    0.00 :   ffff8000101038d0:       sub     w0, w0, #0x1
    0.00 :   ffff8000101038d4:       add     x0, x28, w0, sxtw #3
    0.00 :   ffff8000101038d8:       ldr     x19, [x0, #8704]
    0.00 :   ffff8000101038dc:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101038e0:       add     x0, x0, #0xb50
    0.00 :   ffff8000101038e4:       ldrsw   x0, [x0, #4]
    0.00 :   ffff8000101038e8:       add     x0, x28, x0, lsl #9
    0.00 :   ffff8000101038ec:       cmp     x19, x0
    0.00 :   ffff8000101038f0:       b.cs    ffff800010103940 <rcu_sched_clock_irq+0xb28>  // b.hs, b.nlast
         : 577              rcu_print_detail_task_stall_rnp():
         : 215              if (!rcu_preempt_blocked_readers_cgp(rnp)) {
    0.00 :   ffff8000101038f4:       mov     x0, x19
    0.00 :   ffff8000101038f8:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff8000101038fc:       mov     x1, x0
         : 219              rcu_preempt_blocked_readers_cgp():
    0.00 :   ffff800010103900:       ldr     x0, [x19, #160]
         : 411              rcu_print_detail_task_stall_rnp():
         : 216              raw_spin_unlock_irqrestore_rcu_node(rnp, flags);
    0.00 :   ffff800010103904:       cbnz    x0, ffff800010103a08 <rcu_sched_clock_irq+0xbf0>
         : 217              return;
    0.00 :   ffff800010103908:       mov     x0, x19
    0.00 :   ffff80001010390c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 218              }
    0.00 :   ffff800010103910:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010103914:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
         : 221              print_other_cpu_stall():
         : 563              rcu_dump_cpu_stacks();
    0.00 :   ffff800010103918:       add     x19, x19, #0x200
    0.00 :   ffff80001010391c:       b       ffff8000101038dc <rcu_sched_clock_irq+0xac4>
         : 566              rcu_seq_current():
    0.00 :   ffff800010103920:       ldr     x0, [x28, #8776]
         : 100              print_other_cpu_stall():
         : 566              rcu_for_each_leaf_node(rnp)
    0.00 :   ffff800010103924:       cmp     x12, x0
    0.00 :   ffff800010103928:       b.eq    ffff8000101039ac <rcu_sched_clock_irq+0xb94>  // b.none
         : 567              rcu_print_detail_task_stall_rnp(rnp);
    0.00 :   ffff80001010392c:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
    0.00 :   ffff800010103930:       add     x0, x0, #0x780
    0.00 :   ffff800010103934:       bl      ffff800010e19544 <printk>
    0.00 :   ffff800010103938:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010393c:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
         : 578              }
    0.00 :   ffff800010103940:       ldr     x1, [x11, #2432]
    0.00 :   ffff800010103944:       ldr     x0, [x28, #9096]
    0.00 :   ffff800010103948:       cmp     x1, x0
    0.00 :   ffff80001010394c:       b.mi    ffff80001010397c <rcu_sched_clock_irq+0xb64>  // b.first
         : 583              rcu_jiffies_till_stall_check():
         : 29               int rcu_jiffies_till_stall_check(void)
    0.00 :   ffff800010103950:       ldr     w0, [x14, #2876]
         : 35               * for CONFIG_RCU_CPU_STALL_TIMEOUT.
    0.00 :   ffff800010103954:       cmp     w0, #0x2
    0.00 :   ffff800010103958:       b.gt    ffff800010103a5c <rcu_sched_clock_irq+0xc44>
         : 36               */
    0.00 :   ffff80001010395c:       mov     w0, #0x3                        // #3
    0.00 :   ffff800010103960:       str     w0, [x14, #2876]
         : 39               print_other_cpu_stall():
         : 579              }
    0.00 :   ffff800010103964:       mov     w2, #0x2ee                      // #750
    0.00 :   ffff800010103968:       ldr     x1, [x11, #2432]
    0.00 :   ffff80001010396c:       mul     w0, w0, w2
    0.00 :   ffff800010103970:       add     x1, x1, #0x3
    0.00 :   ffff800010103974:       add     x0, x1, w0, sxtw
    0.00 :   ffff800010103978:       str     x0, [x28, #9096]
         : 582              WRITE_ONCE(rcu_state.jiffies_stall,
    0.00 :   ffff80001010397c:       bl      ffff800010e19b64 <rcu_check_gp_kthread_expired_fqs_timer>
         : 583              jiffies + 3 * rcu_jiffies_till_stall_check() + 3);
    0.00 :   ffff800010103980:       bl      ffff800010e19c50 <rcu_check_gp_kthread_starvation>
         : 585              panic_on_rcu_stall():
         : 112              static int cpu_stall;
    0.00 :   ffff800010103984:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010103988:       add     x1, x1, #0xb50
    0.00 :   ffff80001010398c:       ldr     w0, [x24, #16]
    0.00 :   ffff800010103990:       ldr     w1, [x1, #16]
    0.00 :   ffff800010103994:       add     w0, w0, #0x1
    0.00 :   ffff800010103998:       str     w0, [x24, #16]
    0.00 :   ffff80001010399c:       cmp     w0, w1
    0.00 :   ffff8000101039a0:       b.ge    ffff8000101039e0 <rcu_sched_clock_irq+0xbc8>  // b.tcont
         : 121              print_other_cpu_stall():
         :
    0.00 :   ffff8000101039a4:       bl      ffff8000100ffd78 <rcu_force_quiescent_state>
    0.00 :   ffff8000101039a8:       b       ffff80001010349c <rcu_sched_clock_irq+0x684>
         : 571              } else {
    0.00 :   ffff8000101039ac:       adrp    x1, ffff800011cb3000 <_rs.29273+0x20>
    0.00 :   ffff8000101039b0:       adrp    x0, ffff80001141e000 <kallsyms_token_index+0x137a0>
         : 569              if (rcu_seq_current(&rcu_state.gp_seq) != gp_seq) {
    0.00 :   ffff8000101039b4:       ldr     x3, [x11, #2432]
         : 571              } else {
    0.00 :   ffff8000101039b8:       add     x0, x0, #0x7b8
    0.00 :   ffff8000101039bc:       ldr     x5, [x1, #2504]
    0.00 :   ffff8000101039c0:       ldr     x6, [x28, #32]
         : 570              pr_err("INFO: Stall ended before state dump start\n");
    0.00 :   ffff8000101039c4:       ldr     x4, [x28, #9080]
         : 571              } else {
    0.00 :   ffff8000101039c8:       ldr     x1, [x28, #9120]
    0.00 :   ffff8000101039cc:       sub     x2, x3, x4
    0.00 :   ffff8000101039d0:       bl      ffff800010e19544 <printk>
    0.00 :   ffff8000101039d4:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000101039d8:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101039dc:       b       ffff800010103940 <rcu_sched_clock_irq+0xb28>
         : 578              panic_on_rcu_stall():
    0.00 :   ffff8000101039e0:       bl      ffff8000100fe008 <panic_on_rcu_stall.part.89>
         : 572              print_other_cpu_stall():
         :
    0.00 :   ffff8000101039e4:       bl      ffff8000100ffd78 <rcu_force_quiescent_state>
    0.00 :   ffff8000101039e8:       b       ffff80001010349c <rcu_sched_clock_irq+0x684>
         : 590              __refcount_add():
         : 200              else if (unlikely(old < 0 || old + i < 0))
    0.00 :   ffff8000101039ec:       b.ge    ffff8000101039fc <rcu_sched_clock_irq+0xbe4>  // b.tcont
         : 201              refcount_warn_saturate(r, REFCOUNT_ADD_OVF);
    0.00 :   ffff8000101039f0:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000101039f4:       bl      ffff800010470e68 <refcount_warn_saturate>
    0.00 :   ffff8000101039f8:       b       ffff800010103620 <rcu_sched_clock_irq+0x808>
         : 200              else if (unlikely(old < 0 || old + i < 0))
    0.00 :   ffff8000101039fc:       cmn     w1, #0x1
    0.00 :   ffff800010103a00:       b.mi    ffff8000101039f0 <rcu_sched_clock_irq+0xbd8>  // b.first
    0.00 :   ffff800010103a04:       b       ffff800010103620 <rcu_sched_clock_irq+0x808>
         : 204              rcu_print_detail_task_stall_rnp():
         : 220              struct task_struct, rcu_node_entry);
    0.00 :   ffff800010103a08:       ldr     x0, [x19, #160]
    0.00 :   ffff800010103a0c:       add     x2, x19, #0x90
         : 222              /*
    0.00 :   ffff800010103a10:       ldr     x0, [x0, #8]
    0.00 :   ffff800010103a14:       ldr     x25, [x0]
    0.00 :   ffff800010103a18:       sub     x25, x25, #0x2e8
    0.00 :   ffff800010103a1c:       add     x0, x25, #0x2e8
    0.00 :   ffff800010103a20:       cmp     x0, x2
    0.00 :   ffff800010103a24:       b.eq    ffff800010103a44 <rcu_sched_clock_irq+0xc2c>  // b.none
         : 228              }
    0.00 :   ffff800010103a28:       mov     x0, x25
    0.00 :   ffff800010103a2c:       stp     x1, x2, [sp, #104]
    0.00 :   ffff800010103a30:       bl      ffff8000100b1880 <sched_show_task>
         : 222              /*
    0.00 :   ffff800010103a34:       ldr     x25, [x25, #744]
    0.00 :   ffff800010103a38:       ldp     x1, x2, [sp, #104]
    0.00 :   ffff800010103a3c:       sub     x25, x25, #0x2e8
    0.00 :   ffff800010103a40:       b       ffff800010103a1c <rcu_sched_clock_irq+0xc04>
         : 230              }
    0.00 :   ffff800010103a44:       mov     x0, x19
    0.00 :   ffff800010103a48:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
    0.00 :   ffff800010103a4c:       adrp    x11, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010103a50:       adrp    x14, ffff800011c29000 <page_wait_table+0x14c0>
         : 235              print_other_cpu_stall():
         : 563              rcu_dump_cpu_stacks();
    0.00 :   ffff800010103a54:       add     x19, x19, #0x200
    0.00 :   ffff800010103a58:       b       ffff8000101038dc <rcu_sched_clock_irq+0xac4>
         : 566              rcu_jiffies_till_stall_check():
         : 38               WRITE_ONCE(rcu_cpu_stall_timeout, 3);
    0.00 :   ffff800010103a5c:       cmp     w0, #0x12c
    0.00 :   ffff800010103a60:       b.le    ffff800010103964 <rcu_sched_clock_irq+0xb4c>
         : 39               till_stall_check = 3;
    0.00 :   ffff800010103a64:       mov     w1, #0x12c                      // #300
         : 40               } else if (till_stall_check > 300) {
    0.00 :   ffff800010103a68:       mov     w0, w1
         : 39               till_stall_check = 3;
    0.00 :   ffff800010103a6c:       str     w1, [x14, #2876]
         : 40               } else if (till_stall_check > 300) {
    0.00 :   ffff800010103a70:       b       ffff800010103964 <rcu_sched_clock_irq+0xb4c>
         : 42               rcu_get_n_cbs_cpu():
    0.00 :   ffff800010103a74:       mov     x1, #0x0                        // #0
         : 239              print_other_cpu_stall():
         : 555              }
    0.00 :   ffff800010103a78:       add     x21, x21, x1
    0.00 :   ffff800010103a7c:       b       ffff800010103560 <rcu_sched_clock_irq+0x748>
         : 558              rcu_print_task_stall():
         : 276              struct task_struct, rcu_node_entry);
    0.00 :   ffff800010103a80:       ldr     x22, [x22, #744]
    0.00 :   ffff800010103a84:       sub     x22, x22, #0x2e8
    0.00 :   ffff800010103a88:       b       ffff8000101035e8 <rcu_sched_clock_irq+0x7d0>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100d5700 <update_thermal_load_avg>:
         : 6                ___update_load_sum():
         : 189              ___update_load_sum(u64 now, struct sched_avg *sa,
         : 190              unsigned long load, unsigned long runnable, int running)
         : 191              {
         : 192              u64 delta;
         :
         : 194              delta = now - sa->last_update_time;
    0.00 :   ffff8000100d5700:       ldr     x4, [x1, #2816]
         : 194              /*
         : 195              * This should only happen when time goes backwards, which it
         : 196              * unfortunately does during sched clock init when we swap over to TSC.
         : 197              */
         : 198              if ((s64)delta < 0) {
    0.00 :   ffff8000100d5704:       subs    x3, x0, x4
    0.00 :   ffff8000100d5708:       b.mi    ffff8000100d5760 <update_thermal_load_avg+0x60>  // b.first
         :
         : 204              /*
         : 205              * Use 1024ns as the unit of measurement since it's a reasonable
         : 206              * approximation of 1us and fast to compute.
         : 207              */
         : 208              delta >>= 10;
    0.00 :   ffff8000100d570c:       lsr     x5, x3, #10
         : 204              if (!delta)
    0.00 :   ffff8000100d5710:       cbz     x5, ffff8000100d5800 <update_thermal_load_avg+0x100>
         : 206              update_thermal_load_avg():
         : 408              * "delta capacity" =  actual capacity  -
         : 409              *                       capped capacity a cpu due to a thermal event.
         : 410              */
         :
         : 412              int update_thermal_load_avg(u64 now, struct rq *rq, u64 capacity)
         : 413              {
    0.00 :   ffff8000100d5714:       paciasp
    0.00 :   ffff8000100d5718:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff8000100d571c:       add     x6, x1, #0xb00
    0.00 :   ffff8000100d5720:       mov     x29, sp
         : 418              ___update_load_sum():
         : 207              sa->last_update_time += delta << 10;
    0.00 :   ffff8000100d5724:       and     x3, x3, #0xfffffffffffffc00
    0.00 :   ffff8000100d5728:       add     x3, x3, x4
    0.00 :   ffff8000100d572c:       str     x3, [x1, #2816]
         : 220              if (!load)
    0.00 :   ffff8000100d5730:       mov     x7, x1
    0.00 :   ffff8000100d5734:       mov     w0, w5
    0.00 :   ffff8000100d5738:       mov     x8, x2
    0.00 :   ffff8000100d573c:       ldr     w1, [x6, #28]
    0.00 :   ffff8000100d5740:       add     x5, x5, w1, uxtw
    0.00 :   ffff8000100d5744:       lsr     x10, x5, #10
    0.00 :   ffff8000100d5748:       cbnz    x2, ffff8000100d5770 <update_thermal_load_avg+0x70>
         : 228              accumulate_sum():
         : 118              if (periods) {
    0.00 :   ffff8000100d574c:       cmp     x5, #0x3ff
    0.00 :   ffff8000100d5750:       b.hi    ffff8000100d580c <update_thermal_load_avg+0x10c>  // b.pmore
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5754:       mov     w9, w5
    0.00 :   ffff8000100d5758:       str     w5, [x6, #28]
         : 147              if (runnable)
    0.00 :   ffff8000100d575c:       b       ffff8000100d57c0 <update_thermal_load_avg+0xc0>
         : 149              update_thermal_load_avg():
         : 418              ___update_load_avg(&rq->avg_thermal, 1);
         : 419              trace_pelt_thermal_tp(rq);
         : 420              return 1;
         : 421              }
         :
         : 423              return 0;
    0.00 :   ffff8000100d5760:       mov     w2, #0x0                        // #0
         : 425              ___update_load_sum():
         : 195              sa->last_update_time = now;
    0.00 :   ffff8000100d5764:       str     x0, [x1, #2816]
         : 197              update_thermal_load_avg():
         : 419              }
    0.00 :   ffff8000100d5768:       mov     w0, w2
    0.00 :   ffff8000100d576c:       ret
         : 422              accumulate_sum():
         : 118              if (periods) {
    0.00 :   ffff8000100d5770:       cmp     x5, #0x3ff
    0.00 :   ffff8000100d5774:       mov     w12, w2
    0.00 :   ffff8000100d5778:       b.hi    ffff8000100d5880 <update_thermal_load_avg+0x180>  // b.pmore
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d577c:       mov     w9, w5
    0.00 :   ffff8000100d5780:       mov     x11, x8
    0.00 :   ffff8000100d5784:       str     w5, [x6, #28]
         : 146              sa->load_sum += load * contrib;
    0.00 :   ffff8000100d5788:       ldr     x1, [x6, #8]
    0.00 :   ffff8000100d578c:       mov     w2, w0
    0.00 :   ffff8000100d5790:       madd    x8, x2, x8, x1
    0.00 :   ffff8000100d5794:       str     x8, [x6, #8]
         : 147              if (runnable)
    0.00 :   ffff8000100d5798:       cbz     x11, ffff8000100d57c0 <update_thermal_load_avg+0xc0>
         : 148              sa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100d579c:       mov     w1, w0
    0.00 :   ffff8000100d57a0:       ldr     x2, [x6, #16]
    0.00 :   ffff8000100d57a4:       mul     x1, x1, x11
    0.00 :   ffff8000100d57a8:       add     x1, x2, x1, lsl #10
    0.00 :   ffff8000100d57ac:       str     x1, [x6, #16]
         : 149              if (running)
    0.00 :   ffff8000100d57b0:       cbz     w12, ffff8000100d57c0 <update_thermal_load_avg+0xc0>
         : 150              sa->util_sum += contrib << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100d57b4:       ldr     w1, [x6, #24]
    0.00 :   ffff8000100d57b8:       add     w0, w1, w0, lsl #10
    0.00 :   ffff8000100d57bc:       str     w0, [x6, #24]
         : 154              update_thermal_load_avg():
         : 418              return 0;
    0.00 :   ffff8000100d57c0:       mov     w2, #0x0                        // #0
         : 420              ___update_load_sum():
         : 230              if (!accumulate_sum(delta, sa, load, runnable, running))
    0.00 :   ffff8000100d57c4:       cbz     w10, ffff8000100d57f0 <update_thermal_load_avg+0xf0>
         : 232              div_u64_rem():
         : 28               * divide.
         : 29               */
         : 30               static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
         : 31               {
         : 32               *remainder = dividend % divisor;
         : 33               return dividend / divisor;
    0.00 :   ffff8000100d57c8:       ldp     x4, x3, [x6, #8]
         : 35               get_pelt_divider():
         : 42               }
         : 43               #endif
         :
         : 45               static inline u32 get_pelt_divider(struct sched_avg *avg)
         : 46               {
         : 47               return LOAD_AVG_MAX - 1024 + avg->period_contrib;
    0.00 :   ffff8000100d57cc:       mov     w0, #0xb67e                     // #46718
         : 49               ___update_load_avg():
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
  100.00 :   ffff8000100d57d0:       ldr     w1, [x6, #24]
         : 272              get_pelt_divider():
    0.00 :   ffff8000100d57d4:       add     w5, w9, w0
         : 43               update_thermal_load_avg():
         : 415              return 1;
    0.00 :   ffff8000100d57d8:       mov     w2, #0x1                        // #1
         : 417              div_u64_rem():
    0.00 :   ffff8000100d57dc:       udiv    x4, x4, x5
    0.00 :   ffff8000100d57e0:       udiv    x3, x3, x5
         : 30               ___update_load_avg():
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d57e4:       udiv    w0, w1, w5
         : 269              sa->runnable_avg = div_u64(sa->runnable_sum, divider);
    0.00 :   ffff8000100d57e8:       stp     x4, x3, [x6, #32]
         : 270              WRITE_ONCE(sa->util_avg, sa->util_sum / divider);
    0.00 :   ffff8000100d57ec:       str     x0, [x7, #2864]
         : 272              update_thermal_load_avg():
         : 419              }
    0.00 :   ffff8000100d57f0:       mov     w0, w2
    0.00 :   ffff8000100d57f4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000100d57f8:       autiasp
    0.00 :   ffff8000100d57fc:       ret
         : 418              return 0;
    0.00 :   ffff8000100d5800:       mov     w2, #0x0                        // #0
         : 419              }
    0.00 :   ffff8000100d5804:       mov     w0, w2
    0.00 :   ffff8000100d5808:       ret
         : 422              ___update_load_sum():
         : 221              runnable = running = 0;
    0.00 :   ffff8000100d580c:       mov     x11, #0x0                       // #0
         : 223              accumulate_sum():
         : 118              if (periods) {
    0.00 :   ffff8000100d5810:       mov     w12, #0x0                       // #0
         : 120              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d5814:       mov     x2, #0x83ff                     // #33791
    0.00 :   ffff8000100d5818:       movk    x2, #0x1f, lsl #16
    0.00 :   ffff8000100d581c:       cmp     x5, x2
         : 43               accumulate_sum():
         : 119              sa->load_sum = decay_load(sa->load_sum, periods);
    0.00 :   ffff8000100d5820:       ldr     x2, [x6, #8]
         : 121              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d5824:       b.hi    ffff8000100d58a4 <update_thermal_load_avg+0x1a4>  // b.pmore
         : 52               if (unlikely(local_n >= LOAD_AVG_PERIOD)) {
    0.00 :   ffff8000100d5828:       cmp     w10, #0x1f
    0.00 :   ffff8000100d582c:       b.hi    ffff8000100d58b0 <update_thermal_load_avg+0x1b0>  // b.pmore
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d5830:       adrp    x3, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d5834:       add     x3, x3, #0xb98
         : 60               mul_u64_u32_shr():
         : 161              #if defined(CONFIG_ARCH_SUPPORTS_INT128) && defined(__SIZEOF_INT128__)
         :
         : 163              #ifndef mul_u64_u32_shr
         : 164              static inline u64 mul_u64_u32_shr(u64 a, u32 mul, unsigned int shift)
         : 165              {
         : 166              return (u64)(((unsigned __int128)a * mul) >> shift);
    0.00 :   ffff8000100d5838:       ldr     x4, [x6, #16]
    0.00 :   ffff8000100d583c:       ldr     w9, [x3, w10, uxtw #2]
         : 169              accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d5840:       ldr     w3, [x6, #24]
         : 124              mul_u64_u32_shr():
    0.00 :   ffff8000100d5844:       mul     x14, x9, x2
    0.00 :   ffff8000100d5848:       mul     x13, x9, x4
    0.00 :   ffff8000100d584c:       umulh   x2, x9, x2
    0.00 :   ffff8000100d5850:       umulh   x4, x9, x4
    0.00 :   ffff8000100d5854:       extr    x2, x2, x14, #32
    0.00 :   ffff8000100d5858:       extr    x4, x4, x13, #32
    0.00 :   ffff8000100d585c:       stp     x2, x4, [x6, #8]
    0.00 :   ffff8000100d5860:       mul     x2, x3, x9
    0.00 :   ffff8000100d5864:       lsr     x2, x2, #32
         : 170              accumulate_sum():
    0.00 :   ffff8000100d5868:       str     w2, [x6, #24]
         : 127              delta %= 1024;
    0.00 :   ffff8000100d586c:       and     x13, x5, #0x3ff
    0.00 :   ffff8000100d5870:       mov     w9, w13
         : 128              if (load) {
    0.00 :   ffff8000100d5874:       cbnz    x8, ffff8000100d5888 <update_thermal_load_avg+0x188>
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d5878:       str     w13, [x6, #28]
         : 145              if (load)
    0.00 :   ffff8000100d587c:       b       ffff8000100d5798 <update_thermal_load_avg+0x98>
         : 118              if (periods) {
    0.00 :   ffff8000100d5880:       mov     x11, x8
    0.00 :   ffff8000100d5884:       b       ffff8000100d5814 <update_thermal_load_avg+0x114>
         : 139              contrib = __accumulate_pelt_segments(periods,
    0.00 :   ffff8000100d5888:       mov     w0, #0x400                      // #1024
    0.00 :   ffff8000100d588c:       mov     w2, w13
    0.00 :   ffff8000100d5890:       sub     w1, w0, w1
    0.00 :   ffff8000100d5894:       mov     x0, x10
    0.00 :   ffff8000100d5898:       bl      ffff8000100d4ca8 <__accumulate_pelt_segments>
         : 143              sa->period_contrib = delta;
    0.00 :   ffff8000100d589c:       str     w13, [x6, #28]
         : 145              if (load)
    0.00 :   ffff8000100d58a0:       b       ffff8000100d5788 <update_thermal_load_avg+0x88>
         : 120              sa->runnable_sum =
    0.00 :   ffff8000100d58a4:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100d58a8:       stp     xzr, xzr, [x6, #8]
         : 123              decay_load():
         : 39               if (unlikely(n > LOAD_AVG_PERIOD * 63))
    0.00 :   ffff8000100d58ac:       b       ffff8000100d5868 <update_thermal_load_avg+0x168>
         : 57               val = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);
    0.00 :   ffff8000100d58b0:       and     x14, x10, #0x1f
    0.00 :   ffff8000100d58b4:       adrp    x9, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
    0.00 :   ffff8000100d58b8:       add     x9, x9, #0xb98
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d58bc:       lsr     w3, w10, #5
    0.00 :   ffff8000100d58c0:       ldr     x4, [x6, #16]
    0.00 :   ffff8000100d58c4:       mov     w13, w3
         : 57               mul_u64_u32_shr():
    0.00 :   ffff8000100d58c8:       ldr     w9, [x9, x14, lsl #2]
         : 162              decay_load():
    0.00 :   ffff8000100d58cc:       lsr     x2, x2, x3
         : 54               accumulate_sum():
         : 122              sa->util_sum = decay_load((u64)(sa->util_sum), periods);
    0.00 :   ffff8000100d58d0:       ldr     w3, [x6, #24]
         : 124              decay_load():
         : 53               val >>= local_n / LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d58d4:       lsr     x4, x4, x13
         : 55               mul_u64_u32_shr():
    0.00 :   ffff8000100d58d8:       mul     x14, x2, x9
         : 162              decay_load():
    0.00 :   ffff8000100d58dc:       lsr     x3, x3, x13
         : 54               mul_u64_u32_shr():
    0.00 :   ffff8000100d58e0:       umulh   x2, x2, x9
    0.00 :   ffff8000100d58e4:       mul     x13, x4, x9
    0.00 :   ffff8000100d58e8:       umulh   x4, x4, x9
    0.00 :   ffff8000100d58ec:       extr    x2, x2, x14, #32
    0.00 :   ffff8000100d58f0:       str     x2, [x6, #8]
    0.00 :   ffff8000100d58f4:       extr    x2, x4, x13, #32
    0.00 :   ffff8000100d58f8:       str     x2, [x6, #16]
         : 168              decay_load():
         : 54               local_n %= LOAD_AVG_PERIOD;
    0.00 :   ffff8000100d58fc:       b       ffff8000100d5860 <update_thermal_load_avg+0x160>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100f5080 <irq_find_mapping>:
         : 6                irq_find_mapping():
         : 871              if (WARN_ON(domain == NULL))
         : 872              return;
         :
         : 874              if (irq_domain_is_hierarchy(domain)) {
         : 875              irq_domain_free_irqs(virq, 1);
         : 876              } else {
    0.00 :   ffff8000100f5080:       paciasp
    0.00 :   ffff8000100f5084:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000100f5088:       mov     x29, sp
    0.00 :   ffff8000100f508c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100f5090:       mov     x20, x1
    0.00 :   ffff8000100f5094:       mov     x19, x0
    0.00 :   ffff8000100f5098:       str     x21, [sp, #32]
         : 875              irq_domain_disassociate(domain, virq);
         : 876              irq_free_desc(virq);
         : 877              }
         : 878              }
    0.00 :   ffff8000100f509c:       cbz     x0, ffff8000100f5110 <irq_find_mapping+0x90>
         : 880              EXPORT_SYMBOL_GPL(irq_dispose_mapping);
         :
         : 882              /**
         : 883              * __irq_resolve_mapping() - Find a linux irq from a hw irq number.
         : 884              * @domain: domain owning this hardware interrupt
    0.00 :   ffff8000100f50a0:       ldr     w0, [x19, #88]
    0.00 :   ffff8000100f50a4:       cmp     x0, x20
    0.00 :   ffff8000100f50a8:       b.hi    ffff8000100f5138 <irq_find_mapping+0xb8>  // b.pmore
         : 887              * @irq: optional pointer to return the Linux irq if required
         : 888              *
         : 889              * Returns the interrupt descriptor.
         : 890              */
         : 891              struct irq_desc *__irq_resolve_mapping(struct irq_domain *domain,
         : 892              irq_hw_number_t hwirq,
    0.00 :   ffff8000100f50ac:       ldr     w0, [x19, #92]
    0.00 :   ffff8000100f50b0:       cmp     x0, x20
    0.00 :   ffff8000100f50b4:       b.ls    ffff8000100f50d8 <irq_find_mapping+0x58>  // b.plast
         : 888              unsigned int *irq)
    0.00 :   ffff8000100f50b8:       add     x20, x20, #0x24
    0.00 :   ffff8000100f50bc:       ldr     w21, [x19, x20, lsl #2]
         : 894              {
         : 895              struct irq_desc *desc = NULL;
         : 896              struct irq_data *data;
         :
         : 898              /* Look for default domain if necessary */
         : 899              if (domain == NULL)
    0.00 :   ffff8000100f50c0:       mov     w0, w21
    0.00 :   ffff8000100f50c4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100f50c8:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100f50cc:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100f50d0:       autiasp
    0.00 :   ffff8000100f50d4:       ret
         : 906              rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100f50d8:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              irq_find_mapping():
         : 891              struct irq_data *data;
    0.00 :   ffff8000100f50dc:       mov     x1, x20
    0.00 :   ffff8000100f50e0:       add     x0, x19, #0x60
    0.00 :   ffff8000100f50e4:       bl      ffff8000104b2b80 <radix_tree_lookup>
    0.00 :   ffff8000100f50e8:       mov     x19, x0
         : 896              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100f50ec:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              irq_find_mapping():
         : 893              /* Look for default domain if necessary */
    0.00 :   ffff8000100f50f0:       cbz     x19, ffff8000100f511c <irq_find_mapping+0x9c>
    0.00 :   ffff8000100f50f4:       ldr     w21, [x19, #4]
         : 894              if (domain == NULL)
  100.00 :   ffff8000100f50f8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100f50fc:       mov     w0, w21
    0.00 :   ffff8000100f5100:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100f5104:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100f5108:       autiasp
    0.00 :   ffff8000100f510c:       ret
         : 876              EXPORT_SYMBOL_GPL(irq_dispose_mapping);
    0.00 :   ffff8000100f5110:       adrp    x0, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff8000100f5114:       ldr     x19, [x0, #3352]
         :
    0.00 :   ffff8000100f5118:       cbnz    x19, ffff8000100f50a0 <irq_find_mapping+0x20>
         : 878              /**
    0.00 :   ffff8000100f511c:       mov     w21, #0x0                       // #0
         : 894              if (domain == NULL)
    0.00 :   ffff8000100f5120:       mov     w0, w21
    0.00 :   ffff8000100f5124:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100f5128:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100f512c:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100f5130:       autiasp
    0.00 :   ffff8000100f5134:       ret
         : 901              irq_domain_get_irq_data():
         :
         : 1265             static int irq_domain_alloc_irq_data(struct irq_domain *domain,
         : 1266             unsigned int virq, unsigned int nr_irqs)
         : 1267             {
         : 1268             struct irq_data *irq_data;
         : 1269             struct irq_domain *parent;
    0.00 :   ffff8000100f5138:       mov     w0, w20
         : 1271             irq_find_mapping():
         : 881              * @hwirq: hardware irq number in that domain space
    0.00 :   ffff8000100f513c:       mov     w21, w20
         : 883              irq_domain_get_irq_data():
         : 1264             struct irq_domain *parent;
    0.00 :   ffff8000100f5140:       bl      ffff8000100f1168 <irq_get_irq_data>
    0.00 :   ffff8000100f5144:       cbnz    x0, ffff8000100f5154 <irq_find_mapping+0xd4>
    0.00 :   ffff8000100f5148:       b       ffff8000100f50ac <irq_find_mapping+0x2c>
         : 1265             int i;
    0.00 :   ffff8000100f514c:       ldr     x0, [x0, #40]
         : 1264             struct irq_domain *parent;
    0.00 :   ffff8000100f5150:       cbz     x0, ffff8000100f50ac <irq_find_mapping+0x2c>
         :
    0.00 :   ffff8000100f5154:       ldr     x1, [x0, #32]
    0.00 :   ffff8000100f5158:       cmp     x1, x19
    0.00 :   ffff8000100f515c:       b.ne    ffff8000100f514c <irq_find_mapping+0xcc>  // b.any
         : 1270             irq_find_mapping():
         : 882              * @irq: optional pointer to return the Linux irq if required
    0.00 :   ffff8000100f5160:       ldr     x0, [x0, #8]
    0.00 :   ffff8000100f5164:       cmp     x0, x20
    0.00 :   ffff8000100f5168:       b.ne    ffff8000100f50ac <irq_find_mapping+0x2c>  // b.any
    0.00 :   ffff8000100f516c:       b       ffff8000100f50c0 <irq_find_mapping+0x40>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010110340 <hrtimer_interrupt>:
         : 6                hrtimer_interrupt():
         : 1634             /*
         : 1635             * High resolution timer interrupt
         : 1636             * Called with interrupts disabled
         : 1637             */
         : 1638             void hrtimer_interrupt(struct clock_event_device *dev)
         : 1639             {
    0.00 :   ffff800010110340:       paciasp
    0.00 :   ffff800010110344:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff800010110348:       mov     x29, sp
         : 1643             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001011034c:       mrs     x1, tpidr_el1
         : 46               hrtimer_interrupt():
    0.00 :   ffff800010110350:       stp     x19, x20, [sp, #16]
         : 1635             struct hrtimer_cpu_base *cpu_base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff800010110354:       adrp    x19, ffff800011776000 <timer_bases+0x2380>
    0.00 :   ffff800010110358:       add     x19, x19, #0x180
    0.00 :   ffff80001011035c:       add     x19, x19, x1
         : 1640             ktime_t expires_next, now, entry_time, delta;
         : 1641             unsigned long flags;
         : 1642             int retries = 0;
         :
         : 1644             BUG_ON(!cpu_base->hres_active);
    0.00 :   ffff800010110360:       ldrb    w1, [x19, #16]
  100.00 :   ffff800010110364:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010110368:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001011036c:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010110370:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010110374:       tbz     w1, #0, ffff80001011057c <hrtimer_interrupt+0x23c>
    0.00 :   ffff800010110378:       mov     x1, x0
         : 1641             cpu_base->nr_events++;
    0.00 :   ffff80001011037c:       ldr     w2, [x19, #20]
         : 1642             dev->next_event = KTIME_MAX;
    0.00 :   ffff800010110380:       mov     x22, #0x7fffffffffffffff        // #9223372036854775807
         :
         : 1645             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff800010110384:       mov     x0, x19
         : 1641             cpu_base->nr_events++;
    0.00 :   ffff800010110388:       add     w2, w2, #0x1
    0.00 :   ffff80001011038c:       str     w2, [x19, #20]
         : 1642             dev->next_event = KTIME_MAX;
    0.00 :   ffff800010110390:       str     x22, [x1, #24]
         : 1644             hrtimer_update_base():
         : 627              ktime_t *offs_real = &base->clock_base[HRTIMER_BASE_REALTIME].offset;
    0.00 :   ffff800010110394:       add     x27, x19, #0xb8
         : 628              ktime_t *offs_boot = &base->clock_base[HRTIMER_BASE_BOOTTIME].offset;
    0.00 :   ffff800010110398:       add     x26, x19, #0xf8
         : 629              ktime_t *offs_tai = &base->clock_base[HRTIMER_BASE_TAI].offset;
    0.00 :   ffff80001011039c:       add     x25, x19, #0x138
         : 631              hrtimer_interrupt():
         : 1644             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff8000101103a0:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 1646             hrtimer_update_base():
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff8000101103a4:       add     x24, x19, #0xc
    0.00 :   ffff8000101103a8:       mov     x1, x27
         : 634              hrtimer_interrupt():
         : 1644             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff8000101103ac:       mov     x20, x0
         : 1646             hrtimer_update_base():
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff8000101103b0:       mov     x2, x26
    0.00 :   ffff8000101103b4:       mov     x3, x25
    0.00 :   ffff8000101103b8:       mov     x0, x24
    0.00 :   ffff8000101103bc:       bl      ffff800010113218 <ktime_get_update_offsets_now>
    0.00 :   ffff8000101103c0:       mov     x23, x0
         : 637              hrtimer_interrupt():
         : 1645             entry_time = now = hrtimer_update_base(cpu_base);
    0.00 :   ffff8000101103c4:       mov     x28, x0
         : 1647             hrtimer_update_base():
         : 634              base->clock_base[HRTIMER_BASE_REALTIME_SOFT].offset = *offs_real;
    0.00 :   ffff8000101103c8:       ldr     x0, [x19, #184]
    0.00 :   ffff8000101103cc:       str     x0, [x19, #440]
         : 635              base->clock_base[HRTIMER_BASE_BOOTTIME_SOFT].offset = *offs_boot;
    0.00 :   ffff8000101103d0:       ldr     x1, [x19, #248]
         : 636              base->clock_base[HRTIMER_BASE_TAI_SOFT].offset = *offs_tai;
    0.00 :   ffff8000101103d4:       mov     w21, #0x3                       // #3
    0.00 :   ffff8000101103d8:       ldr     x0, [x19, #312]
         : 635              base->clock_base[HRTIMER_BASE_BOOTTIME_SOFT].offset = *offs_boot;
    0.00 :   ffff8000101103dc:       str     x1, [x19, #504]
         : 636              base->clock_base[HRTIMER_BASE_TAI_SOFT].offset = *offs_tai;
    0.00 :   ffff8000101103e0:       str     x0, [x19, #568]
         : 638              hrtimer_interrupt():
         : 1647             retry:
         : 1648             cpu_base->in_hrtirq = 1;
    0.00 :   ffff8000101103e4:       ldrb    w0, [x19, #16]
         : 1650             ktime_compare():
         : 97               *   cmp1 == cmp2: return 0
         : 98               *   cmp1  > cmp2: return >0
         : 99               */
         : 100              static inline int ktime_compare(const ktime_t cmp1, const ktime_t cmp2)
         : 101              {
         : 102              if (cmp1 < cmp2)
    0.00 :   ffff8000101103e8:       ldr     x1, [x19, #48]
         : 104              hrtimer_interrupt():
    0.00 :   ffff8000101103ec:       orr     w0, w0, #0x2
    0.00 :   ffff8000101103f0:       strb    w0, [x19, #16]
         : 1655             * held to prevent that a timer is enqueued in our queue via
         : 1656             * the migration code. This does not affect enqueueing of
         : 1657             * timers which run their callback and need to be requeued on
         : 1658             * this CPU.
         : 1659             */
         : 1660             cpu_base->expires_next = KTIME_MAX;
    0.00 :   ffff8000101103f4:       str     x22, [x19, #32]
         : 1662             ktime_compare():
    0.00 :   ffff8000101103f8:       cmp     x1, x28
    0.00 :   ffff8000101103fc:       b.gt    ffff800010110414 <hrtimer_interrupt+0xd4>
         : 99               hrtimer_interrupt():
         :
         : 1660             if (!ktime_before(now, cpu_base->softirq_expires_next)) {
         : 1661             cpu_base->softirq_expires_next = KTIME_MAX;
         : 1662             cpu_base->softirq_activated = 1;
    0.00 :   ffff800010110400:       orr     w0, w0, #0x8
    0.00 :   ffff800010110404:       strb    w0, [x19, #16]
         : 1658             cpu_base->softirq_expires_next = KTIME_MAX;
    0.00 :   ffff800010110408:       str     x22, [x19, #48]
         : 1660             raise_softirq_irqoff(HRTIMER_SOFTIRQ);
    0.00 :   ffff80001011040c:       mov     w0, #0x8                        // #8
    0.00 :   ffff800010110410:       bl      ffff8000100893a8 <raise_softirq_irqoff>
         : 1663             }
         :
         : 1665             __hrtimer_run_queues(cpu_base, now, flags, HRTIMER_ACTIVE_HARD);
    0.00 :   ffff800010110414:       mov     x1, x28
    0.00 :   ffff800010110418:       mov     x2, x20
    0.00 :   ffff80001011041c:       mov     w3, #0xf                        // #15
    0.00 :   ffff800010110420:       mov     x0, x19
    0.00 :   ffff800010110424:       bl      ffff80001010f860 <__hrtimer_run_queues>
         :
         : 1667             /* Reevaluate the clock bases for the [soft] next expiry */
         : 1668             expires_next = hrtimer_update_next_event(cpu_base);
    0.00 :   ffff800010110428:       mov     x0, x19
    0.00 :   ffff80001011042c:       bl      ffff80001010f680 <hrtimer_update_next_event>
         : 1672             /*
         : 1673             * Store the new expiry value so the migration code can verify
         : 1674             * against it.
         : 1675             */
         : 1676             cpu_base->expires_next = expires_next;
         : 1677             cpu_base->in_hrtirq = 0;
    0.00 :   ffff800010110430:       ldrb    w2, [x19, #16]
         : 1666             expires_next = hrtimer_update_next_event(cpu_base);
    0.00 :   ffff800010110434:       mov     x28, x0
         : 1671             cpu_base->expires_next = expires_next;
    0.00 :   ffff800010110438:       str     x28, [x19, #32]
         : 1673             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff80001011043c:       mov     x1, x20
         : 1672             cpu_base->in_hrtirq = 0;
    0.00 :   ffff800010110440:       and     w2, w2, #0xfffffffd
    0.00 :   ffff800010110444:       strb    w2, [x19, #16]
         : 1673             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff800010110448:       mov     x0, x19
    0.00 :   ffff80001011044c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         :
         : 1677             /* Reprogramming necessary ? */
         : 1678             if (!tick_program_event(expires_next, 0)) {
    0.00 :   ffff800010110450:       mov     x0, x28
    0.00 :   ffff800010110454:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010110458:       bl      ffff80001011ff78 <tick_program_event>
    0.00 :   ffff80001011045c:       cbz     w0, ffff800010110550 <hrtimer_interrupt+0x210>
         : 1694             * overreacting on some spurious event.
         : 1695             *
         : 1696             * Acquire base lock for updating the offsets and retrieving
         : 1697             * the current time.
         : 1698             */
         : 1699             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff800010110460:       mov     x0, x19
    0.00 :   ffff800010110464:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 1702             hrtimer_update_base():
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff800010110468:       mov     x2, x26
    0.00 :   ffff80001011046c:       mov     x1, x27
         : 634              hrtimer_interrupt():
         : 1694             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff800010110470:       mov     x20, x0
         : 1696             hrtimer_update_base():
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff800010110474:       mov     x3, x25
    0.00 :   ffff800010110478:       mov     x0, x24
    0.00 :   ffff80001011047c:       bl      ffff800010113218 <ktime_get_update_offsets_now>
    0.00 :   ffff800010110480:       mov     x28, x0
         : 636              hrtimer_interrupt():
         : 1696             now = hrtimer_update_base(cpu_base);
         : 1697             cpu_base->nr_retries++;
    0.00 :   ffff800010110484:       ldrh    w0, [x19, #24]
         : 1699             hrtimer_update_base():
         : 634              base->clock_base[HRTIMER_BASE_REALTIME_SOFT].offset = *offs_real;
    0.00 :   ffff800010110488:       ldr     x2, [x19, #184]
         : 636              hrtimer_interrupt():
         : 1696             cpu_base->nr_retries++;
    0.00 :   ffff80001011048c:       add     w0, w0, #0x1
    0.00 :   ffff800010110490:       strh    w0, [x19, #24]
         : 1697             if (++retries < 3)
    0.00 :   ffff800010110494:       subs    w21, w21, #0x1
         : 1699             hrtimer_update_base():
         : 635              base->clock_base[HRTIMER_BASE_BOOTTIME_SOFT].offset = *offs_boot;
    0.00 :   ffff800010110498:       ldr     x1, [x19, #248]
         : 634              base->clock_base[HRTIMER_BASE_REALTIME_SOFT].offset = *offs_real;
    0.00 :   ffff80001011049c:       str     x2, [x19, #440]
         : 636              base->clock_base[HRTIMER_BASE_TAI_SOFT].offset = *offs_tai;
    0.00 :   ffff8000101104a0:       ldr     x0, [x19, #312]
         : 635              base->clock_base[HRTIMER_BASE_BOOTTIME_SOFT].offset = *offs_boot;
    0.00 :   ffff8000101104a4:       str     x1, [x19, #504]
         : 636              base->clock_base[HRTIMER_BASE_TAI_SOFT].offset = *offs_tai;
    0.00 :   ffff8000101104a8:       str     x0, [x19, #568]
         : 638              hrtimer_interrupt():
         : 1697             if (++retries < 3)
    0.00 :   ffff8000101104ac:       b.ne    ffff8000101103e4 <hrtimer_interrupt+0xa4>  // b.any
         : 1706             * here. We stored the entry time, so we know exactly how long
         : 1707             * we spent here. We schedule the next event this amount of
         : 1708             * time away.
         : 1709             */
         : 1710             cpu_base->nr_hangs++;
         : 1711             cpu_base->hang_detected = 1;
    0.00 :   ffff8000101104b0:       ldrb    w3, [x19, #16]
         : 1707             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff8000101104b4:       mov     x0, x19
         : 1705             cpu_base->nr_hangs++;
    0.00 :   ffff8000101104b8:       ldrh    w2, [x19, #26]
         : 1707             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff8000101104bc:       mov     x1, x20
         : 1706             cpu_base->hang_detected = 1;
    0.00 :   ffff8000101104c0:       orr     w3, w3, #0x4
    0.00 :   ffff8000101104c4:       strb    w3, [x19, #16]
         : 1705             cpu_base->nr_hangs++;
    0.00 :   ffff8000101104c8:       add     w2, w2, #0x1
    0.00 :   ffff8000101104cc:       strh    w2, [x19, #26]
         :
         : 1710             delta = ktime_sub(now, entry_time);
    0.00 :   ffff8000101104d0:       sub     x23, x28, x23
         : 1707             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff8000101104d4:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1710             if ((unsigned int)delta > cpu_base->max_hang_time)
    0.00 :   ffff8000101104d8:       ldr     w0, [x19, #28]
    0.00 :   ffff8000101104dc:       cmp     w23, w0
    0.00 :   ffff8000101104e0:       b.hi    ffff800010110548 <hrtimer_interrupt+0x208>  // b.pmore
         : 1716             cpu_base->max_hang_time = (unsigned int) delta;
         : 1717             /*
         : 1718             * Limit it to a sensible value as we enforce a longer
         : 1719             * delay. Give the CPU at least 100ms to catch up.
         : 1720             */
         : 1721             if (delta > 100 * NSEC_PER_MSEC)
    0.00 :   ffff8000101104e4:       mov     x0, #0xe100                     // #57600
         : 1720             expires_next = ktime_add_ns(now, 100 * NSEC_PER_MSEC);
         : 1721             else
         : 1722             expires_next = ktime_add(now, delta);
         : 1723             tick_program_event(expires_next, 1);
    0.00 :   ffff8000101104e8:       mov     w1, #0x1                        // #1
         : 1716             if (delta > 100 * NSEC_PER_MSEC)
    0.00 :   ffff8000101104ec:       movk    x0, #0x5f5, lsl #16
         : 1717             expires_next = ktime_add_ns(now, 100 * NSEC_PER_MSEC);
    0.00 :   ffff8000101104f0:       cmp     x23, x0
    0.00 :   ffff8000101104f4:       add     x0, x28, x0
    0.00 :   ffff8000101104f8:       add     x28, x23, x28
         : 1720             tick_program_event(expires_next, 1);
    0.00 :   ffff8000101104fc:       csel    x0, x28, x0, le
    0.00 :   ffff800010110500:       bl      ffff80001011ff78 <tick_program_event>
         : 1721             pr_warn_once("hrtimer: interrupt took %llu ns\n", ktime_to_ns(delta));
    0.00 :   ffff800010110504:       adrp    x2, ffff800011efe000 <errmap+0xc38>
    0.00 :   ffff800010110508:       ldrb    w0, [x2, #2810]
    0.00 :   ffff80001011050c:       cbnz    w0, ffff800010110528 <hrtimer_interrupt+0x1e8>
    0.00 :   ffff800010110510:       mov     w3, #0x1                        // #1
    0.00 :   ffff800010110514:       adrp    x0, ffff80001141f000 <kallsyms_token_index+0x147a0>
    0.00 :   ffff800010110518:       mov     x1, x23
    0.00 :   ffff80001011051c:       strb    w3, [x2, #2810]
    0.00 :   ffff800010110520:       add     x0, x0, #0x8a8
    0.00 :   ffff800010110524:       bl      ffff800010e19544 <printk>
         : 1722             }
    0.00 :   ffff800010110528:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001011052c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010110530:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010110534:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010110538:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001011053c:       ldp     x29, x30, [sp], #96
    0.00 :   ffff800010110540:       autiasp
    0.00 :   ffff800010110544:       ret
         : 1711             cpu_base->max_hang_time = (unsigned int) delta;
    0.00 :   ffff800010110548:       str     w23, [x19, #28]
    0.00 :   ffff80001011054c:       b       ffff8000101104e4 <hrtimer_interrupt+0x1a4>
         : 1677             cpu_base->hang_detected = 0;
    0.00 :   ffff800010110550:       ldrb    w0, [x19, #16]
    0.00 :   ffff800010110554:       and     w0, w0, #0xfffffffb
    0.00 :   ffff800010110558:       strb    w0, [x19, #16]
         : 1722             }
    0.00 :   ffff80001011055c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010110560:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010110564:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010110568:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001011056c:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010110570:       ldp     x29, x30, [sp], #96
    0.00 :   ffff800010110574:       autiasp
    0.00 :   ffff800010110578:       ret
         : 1640             BUG_ON(!cpu_base->hres_active);
    0.00 :   ffff80001011057c:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010f700 <__remove_hrtimer>:
         : 6                __remove_hrtimer():
         : 1005             * anyway (e.g. timer interrupt)
         : 1006             */
         : 1007             static void __remove_hrtimer(struct hrtimer *timer,
         : 1008             struct hrtimer_clock_base *base,
         : 1009             u8 newstate, int reprogram)
         : 1010             {
    0.00 :   ffff80001010f700:       paciasp
    0.00 :   ffff80001010f704:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff80001010f708:       and     w2, w2, #0xff
    0.00 :   ffff80001010f70c:       mov     x29, sp
    0.00 :   ffff80001010f710:       stp     x21, x22, [sp, #32]
         : 1007             struct hrtimer_cpu_base *cpu_base = base->cpu_base;
         : 1008             u8 state = timer->state;
    0.00 :   ffff80001010f714:       ldrb    w4, [x0, #56]
         : 1006             struct hrtimer_cpu_base *cpu_base = base->cpu_base;
    0.00 :   ffff80001010f718:       ldr     x22, [x1]
         :
         : 1011             /* Pairs with the lockless read in hrtimer_is_queued() */
         : 1012             WRITE_ONCE(timer->state, newstate);
    0.00 :   ffff80001010f71c:       strb    w2, [x0, #56]
         : 1011             if (!(state & HRTIMER_STATE_ENQUEUED))
    0.00 :   ffff80001010f720:       tbnz    w4, #0, ffff80001010f734 <__remove_hrtimer+0x34>
         : 1027             * an superfluous call to hrtimer_force_reprogram() on the
         : 1028             * remote cpu later on if the same timer gets enqueued again.
         : 1029             */
         : 1030             if (reprogram && timer == cpu_base->next_timer)
         : 1031             hrtimer_force_reprogram(cpu_base, 1);
         : 1032             }
    0.00 :   ffff80001010f724:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001010f728:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001010f72c:       autiasp
    0.00 :   ffff80001010f730:       ret
         : 1014             if (!timerqueue_del(&base->active, &timer->node))
    0.00 :   ffff80001010f734:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001010f738:       mov     x20, x1
    0.00 :   ffff80001010f73c:       mov     w21, w3
    0.00 :   ffff80001010f740:       mov     x1, x0
    0.00 :   ffff80001010f744:       mov     x19, x0
    0.00 :   ffff80001010f748:       add     x0, x20, #0x20
    0.00 :   ffff80001010f74c:       bl      ffff8000104b7970 <timerqueue_del>
    0.00 :   ffff80001010f750:       tst     w0, #0xff
    0.00 :   ffff80001010f754:       b.ne    ffff80001010f770 <__remove_hrtimer+0x70>  // b.any
         : 1015             cpu_base->active_bases &= ~(1 << base->index);
    0.00 :   ffff80001010f758:       ldr     w2, [x20, #8]
    0.00 :   ffff80001010f75c:       mov     w0, #0x1                        // #1
   50.21 :   ffff80001010f760:       ldr     w1, [x22, #8]
    0.00 :   ffff80001010f764:       lsl     w0, w0, w2
    0.00 :   ffff80001010f768:       bic     w0, w1, w0
    0.00 :   ffff80001010f76c:       str     w0, [x22, #8]
         : 1025             if (reprogram && timer == cpu_base->next_timer)
    0.00 :   ffff80001010f770:       cbz     w21, ffff80001010f780 <__remove_hrtimer+0x80>
    0.00 :   ffff80001010f774:       ldr     x0, [x22, #40]
    0.00 :   ffff80001010f778:       cmp     x0, x19
    0.00 :   ffff80001010f77c:       b.eq    ffff80001010f794 <__remove_hrtimer+0x94>  // b.none
   49.79 :   ffff80001010f780:       ldp     x19, x20, [sp, #16]
         : 1027             }
    0.00 :   ffff80001010f784:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001010f788:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001010f78c:       autiasp
    0.00 :   ffff80001010f790:       ret
         : 1032             hrtimer_force_reprogram():
         : 665              expires_next = hrtimer_update_next_event(cpu_base);
    0.00 :   ffff80001010f794:       mov     x0, x22
    0.00 :   ffff80001010f798:       bl      ffff80001010f680 <hrtimer_update_next_event>
         : 667              if (skip_equal && expires_next == cpu_base->expires_next)
    0.00 :   ffff80001010f79c:       ldr     x2, [x22, #32]
    0.00 :   ffff80001010f7a0:       cmp     x0, x2
    0.00 :   ffff80001010f7a4:       b.eq    ffff80001010f780 <__remove_hrtimer+0x80>  // b.none
         : 671              __hrtimer_hres_active():
         : 647              cpu_base->hres_active : 0;
    0.00 :   ffff80001010f7a8:       ldrb    w2, [x22, #16]
         : 649              hrtimer_force_reprogram():
         : 670              cpu_base->expires_next = expires_next;
    0.00 :   ffff80001010f7ac:       str     x0, [x22, #32]
         : 689              if (!__hrtimer_hres_active(cpu_base) || cpu_base->hang_detected)
    0.00 :   ffff80001010f7b0:       tbz     w2, #0, ffff80001010f780 <__remove_hrtimer+0x80>
    0.00 :   ffff80001010f7b4:       tbnz    w2, #2, ffff80001010f780 <__remove_hrtimer+0x80>
         : 692              tick_program_event(cpu_base->expires_next, 1);
    0.00 :   ffff80001010f7b8:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001010f7bc:       bl      ffff80001011ff78 <tick_program_event>
    0.00 :   ffff80001010f7c0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001010f7c4:       b       ffff80001010f724 <__remove_hrtimer+0x24>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101a4d50 <__mod_node_page_state>:
         : 6                __mod_node_page_state():
         : 339              void __mod_node_page_state(struct pglist_data *pgdat, enum node_stat_item item,
         : 340              long delta)
         : 341              {
         : 342              struct per_cpu_nodestat __percpu *pcp = pgdat->per_cpu_nodestats;
         : 343              s8 __percpu *p = pcp->vm_node_stat_diff + item;
         : 344              long x;
   52.53 :   ffff8000101a4d50:       ldr     x5, [x0, #8896]
         : 338              s8 __percpu *p = pcp->vm_node_stat_diff + item;
    0.00 :   ffff8000101a4d54:       paciasp
         : 340              vmstat_item_in_bytes():
         : 248              * Internally values are stored in pages.
         : 249              *
         : 250              * Per-memcg and per-lruvec counters track memory, consumed
         : 251              * by individual slab objects. These counters are actually
         : 252              * byte-precise.
         : 253              */
    0.00 :   ffff8000101a4d58:       sub     w3, w1, #0x5
         : 255              __mod_node_page_state():
         : 340              long t;
    0.00 :   ffff8000101a4d5c:       mov     w1, w1
         : 352              * internally to keep the per-cpu counters compact.
         : 353              */
         : 354              VM_WARN_ON_ONCE(delta & (PAGE_SIZE - 1));
         : 355              delta >>= PAGE_SHIFT;
         : 356              }
         :
    0.00 :   ffff8000101a4d60:       cmp     w3, #0x2
         : 340              long t;
    0.00 :   ffff8000101a4d64:       add     x4, x5, #0x1
         :
    0.00 :   ffff8000101a4d68:       asr     x3, x2, #12
         : 340              long t;
    0.00 :   ffff8000101a4d6c:       add     x4, x4, x1
         :
    0.00 :   ffff8000101a4d70:       csel    x2, x3, x2, cc  // cc = lo, ul, last
         : 354              __kern_my_cpu_offset():
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
         : 45               "mrs %0, tpidr_el2",
         : 46               ARM64_HAS_VIRT_HOST_EXTN)
         : 47               : "=r" (off) :
         : 48               "Q" (*(const unsigned long *)current_stack_pointer));
    0.00 :   ffff8000101a4d74:       mov     x6, sp
         : 50               __mod_node_page_state():
         : 355              x = delta + __this_cpu_read(*p);
         :
         : 357              t = __this_cpu_read(pcp->stat_threshold);
    0.00 :   ffff8000101a4d78:       mov     x3, x4
         : 359              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000101a4d7c:       mrs     x7, tpidr_el1
         : 41               __mod_node_page_state():
    0.00 :   ffff8000101a4d80:       ldrsb   x3, [x3, x7]
         :
         : 360              if (unlikely(abs(x) > t)) {
         : 361              node_page_state_add(x, pgdat, item);
         : 362              x = 0;
    0.00 :   ffff8000101a4d84:       adds    x2, x3, x2
         : 357              if (unlikely(abs(x) > t)) {
    0.00 :   ffff8000101a4d88:       ldrsb   x5, [x5, x7]
         : 359              x = 0;
    0.00 :   ffff8000101a4d8c:       cneg    x3, x2, mi  // mi = first
    0.00 :   ffff8000101a4d90:       cmp     x5, x3
    0.00 :   ffff8000101a4d94:       b.lt    ffff8000101a4db0 <__mod_node_page_state+0x60>  // b.tstop
    0.00 :   ffff8000101a4d98:       sxtb    w2, w2
         : 363              }
         : 364              __this_cpu_write(*p, x);
         : 365              }
         : 366              EXPORT_SYMBOL(__mod_node_page_state);
    0.00 :   ffff8000101a4d9c:       mov     x0, x4
         :
    0.00 :   ffff8000101a4da0:       autiasp
         : 366              __kern_my_cpu_offset():
   47.47 :   ffff8000101a4da4:       mrs     x1, tpidr_el1
         : 40               __mod_node_page_state():
         : 363              EXPORT_SYMBOL(__mod_node_page_state);
    0.00 :   ffff8000101a4da8:       strb    w2, [x0, x1]
         :
    0.00 :   ffff8000101a4dac:       ret
         : 366              node_page_state_add():
         : 182              }
         :
         : 184              static inline unsigned long global_zone_page_state(enum zone_stat_item item)
         : 185              {
         : 186              long x = atomic_long_read(&vm_zone_stat[item]);
         : 187              #ifdef CONFIG_SMP
    0.00 :   ffff8000101a4db0:       add     x1, x1, #0x459
    0.00 :   ffff8000101a4db4:       lsl     x1, x1, #3
    0.00 :   ffff8000101a4db8:       add     x0, x0, x1
         : 191              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101a4dbc:       b       ffff8000101a4e08 <__mod_node_page_state+0xb8>
    0.00 :   ffff8000101a4dc0:       b       ffff8000101a4e08 <__mod_node_page_state+0xb8>
         : 46               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000101a4dc4:       mov     x3, x2
    0.00 :   ffff8000101a4dc8:       stadd   x3, [x0]
         : 187              node_page_state_add():
         : 183              if (x < 0)
    0.00 :   ffff8000101a4dcc:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101a4dd0:       add     x0, x0, #0x340
    0.00 :   ffff8000101a4dd4:       add     x1, x0, x1
    0.00 :   ffff8000101a4dd8:       mov     x0, #0xffffffffffffddf8         // #-8712
    0.00 :   ffff8000101a4ddc:       add     x1, x1, x0
         : 189              arch_static_branch_jump():
    0.00 :   ffff8000101a4de0:       b       ffff8000101a4df8 <__mod_node_page_state+0xa8>
    0.00 :   ffff8000101a4de4:       b       ffff8000101a4df8 <__mod_node_page_state+0xa8>
         : 40               __lse_atomic64_add():
    0.00 :   ffff8000101a4de8:       stadd   x2, [x1]
    0.00 :   ffff8000101a4dec:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000101a4df0:       mov     x6, sp
    0.00 :   ffff8000101a4df4:       b       ffff8000101a4d9c <__mod_node_page_state+0x4c>
         : 183              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000101a4df8:       b       ffff8000101a6d68 <quiet_vmstat+0x240>
    0.00 :   ffff8000101a4dfc:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000101a4e00:       mov     x6, sp
    0.00 :   ffff8000101a4e04:       b       ffff8000101a4d9c <__mod_node_page_state+0x4c>
    0.00 :   ffff8000101a4e08:       b       ffff8000101a6d80 <quiet_vmstat+0x258>
    0.00 :   ffff8000101a4e0c:       b       ffff8000101a4dcc <__mod_node_page_state+0x7c>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000103534b0 <stop_this_handle>:
         : 6                stop_this_handle():
         : 708              read_unlock(&journal->j_state_lock);
         : 709              return result;
         : 710              }
         :
         : 712              static void stop_this_handle(handle_t *handle)
         : 713              {
    0.00 :   ffff8000103534b0:       paciasp
    0.00 :   ffff8000103534b4:       stp     x29, x30, [sp, #-48]!
         : 716              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000103534b8:       mrs     x1, sp_el0
         : 26               stop_this_handle():
    0.00 :   ffff8000103534bc:       mov     x29, sp
    0.00 :   ffff8000103534c0:       stp     x19, x20, [sp, #16]
         : 713              transaction_t *transaction = handle->h_transaction;
         : 714              journal_t *journal = transaction->t_journal;
         : 715              int revokes;
         :
         : 717              J_ASSERT(journal_current_handle() == handle);
    0.00 :   ffff8000103534c4:       ldr     x2, [x1, #1824]
         : 709              transaction_t *transaction = handle->h_transaction;
    0.00 :   ffff8000103534c8:       ldr     x19, [x0]
         : 713              J_ASSERT(journal_current_handle() == handle);
    0.00 :   ffff8000103534cc:       cmp     x0, x2
    0.00 :   ffff8000103534d0:       b.ne    ffff800010353618 <stop_this_handle+0x168>  // b.any
         : 716              atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff8000103534d4:       ldr     w2, [x19, #152]
    0.00 :   ffff8000103534d8:       str     x21, [sp, #32]
         : 36               stop_this_handle():
         : 714              J_ASSERT(atomic_read(&transaction->t_updates) > 0);
    0.00 :   ffff8000103534dc:       cmp     w2, #0x0
    0.00 :   ffff8000103534e0:       b.le    ffff800010353620 <stop_this_handle+0x170>
         : 710              journal_t *journal = transaction->t_journal;
    0.00 :   ffff8000103534e4:       ldr     x21, [x19]
         : 715              current->journal_info = NULL;
    0.00 :   ffff8000103534e8:       str     xzr, [x1, #1824]
         : 722              * Subtract necessary revoke descriptor blocks from handle credits. We
         : 723              * take care to account only for revoke descriptor blocks the
         : 724              * transaction will really need as large sequences of transactions with
         : 725              * small numbers of revokes are relatively common.
         : 726              */
         : 727              revokes = handle->h_revoke_credits_requested - handle->h_revoke_credits;
    0.00 :   ffff8000103534ec:       ldp     w2, w1, [x0, #20]
    0.00 :   ffff8000103534f0:       sub     w5, w2, #0x1
         : 723              if (revokes) {
    0.00 :   ffff8000103534f4:       subs    w2, w1, w2
    0.00 :   ffff8000103534f8:       b.ne    ffff800010353574 <stop_this_handle+0xc4>  // b.any
    0.00 :   ffff8000103534fc:       ldr     w1, [x0, #16]
         : 736              revoke_descriptors =
         : 737              DIV_ROUND_UP(t_revokes, rr_per_blk) -
         : 738              DIV_ROUND_UP(t_revokes - revokes, rr_per_blk);
         : 739              handle->h_total_credits -= revoke_descriptors;
         : 740              }
         : 741              atomic_sub(handle->h_total_credits,
    0.00 :   ffff800010353500:       add     x2, x19, #0x9c
         : 743              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010353504:       b       ffff80001035360c <stop_this_handle+0x15c>
    0.00 :   ffff800010353508:       b       ffff80001035360c <stop_this_handle+0x15c>
         : 46               __lse_atomic_sub():
         :
         : 114              #undef ATOMIC_FETCH_OP_AND
         :
         : 116              static inline void __lse_atomic_sub(int i, atomic_t *v)
         : 117              {
         : 118              asm volatile(
    0.00 :   ffff80001035350c:       neg     w1, w1
    0.00 :   ffff800010353510:       stadd   w1, [x2]
         : 121              stop_this_handle():
         : 738              &transaction->t_outstanding_credits);
         : 739              if (handle->h_rsv_handle)
   51.08 :   ffff800010353514:       mov     x20, x0
    0.00 :   ffff800010353518:       ldr     x0, [x0, #8]
    0.00 :   ffff80001035351c:       cbz     x0, ffff800010353528 <stop_this_handle+0x78>
         : 739              __jbd2_journal_unreserve_handle(handle->h_rsv_handle,
    0.00 :   ffff800010353520:       mov     x1, x19
    0.00 :   ffff800010353524:       bl      ffff8000103533d8 <__jbd2_journal_unreserve_handle>
         : 741              transaction);
         : 742              if (atomic_dec_and_test(&transaction->t_updates))
    0.00 :   ffff800010353528:       add     x1, x19, #0x98
         : 744              arch_static_branch_jump():
    0.00 :   ffff80001035352c:       b       ffff8000103535e4 <stop_this_handle+0x134>
    0.00 :   ffff800010353530:       b       ffff8000103535e4 <stop_this_handle+0x134>
         : 40               __lse_atomic_sub_return():
         : 141              }
         :
         : 143              ATOMIC_OP_SUB_RETURN(_relaxed,   )
         : 144              ATOMIC_OP_SUB_RETURN(_acquire,  a, "memory")
         : 145              ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
         : 146              ATOMIC_OP_SUB_RETURN(        , al, "memory")
   48.92 :   ffff800010353534:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010353538:       neg     w0, w0
    0.00 :   ffff80001035353c:       ldaddal w0, w2, [x1]
    0.00 :   ffff800010353540:       add     w0, w0, w2
         : 151              stop_this_handle():
    0.00 :   ffff800010353544:       cbz     w0, ffff8000103535f4 <stop_this_handle+0x144>
         : 742              get_current():
    0.00 :   ffff800010353548:       mrs     x1, sp_el0
         : 20               memalloc_nofs_restore():
         : 263              *
         : 264              * This functions marks the beginning of the GFP_NOFS allocation scope.
         : 265              * All further allocations will implicitly drop __GFP_FS flag and so
         : 266              * they are safe for the FS critical section from the allocation recursion
         : 267              * point of view. Use memalloc_nofs_restore to end the scope with flags
         : 268              * returned by this function.
    0.00 :   ffff80001035354c:       ldr     w0, [x1, #36]
    0.00 :   ffff800010353550:       ldr     w2, [x20, #52]
    0.00 :   ffff800010353554:       and     w0, w0, #0xfffbffff
    0.00 :   ffff800010353558:       orr     w0, w0, w2
    0.00 :   ffff80001035355c:       str     w0, [x1, #36]
         : 274              stop_this_handle():
         : 750              /*
         : 751              * Scope of the GFP_NOFS context is over here and so we can restore the
         : 752              * original alloc context.
         : 753              */
         : 754              memalloc_nofs_restore(handle->saved_alloc_context);
         : 755              }
    0.00 :   ffff800010353560:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010353564:       ldr     x21, [sp, #32]
    0.00 :   ffff800010353568:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001035356c:       autiasp
    0.00 :   ffff800010353570:       ret
         : 725              int rr_per_blk = journal->j_revoke_records_per_block;
    0.00 :   ffff800010353574:       ldr     w4, [x21, #1044]
         : 727              WARN_ON_ONCE(DIV_ROUND_UP(revokes, rr_per_blk)
    0.00 :   ffff800010353578:       sub     w3, w2, #0x1
    0.00 :   ffff80001035357c:       ldr     w6, [x0, #16]
    0.00 :   ffff800010353580:       add     w3, w3, w4
    0.00 :   ffff800010353584:       sdiv    w3, w3, w4
    0.00 :   ffff800010353588:       cmp     w3, w6
    0.00 :   ffff80001035358c:       b.gt    ffff800010353624 <stop_this_handle+0x174>
         : 729              t_revokes = atomic_add_return(revokes,
    0.00 :   ffff800010353590:       add     x3, x19, #0xa0
         : 731              arch_static_branch_jump():
    0.00 :   ffff800010353594:       b       ffff8000103535d4 <stop_this_handle+0x124>
    0.00 :   ffff800010353598:       b       ffff8000103535d4 <stop_this_handle+0x124>
         : 39               __lse_atomic_add_return():
         : 76               ATOMIC_OP_ADD_RETURN(        , al, "memory")
    0.00 :   ffff80001035359c:       ldaddal w2, w6, [x3]
    0.00 :   ffff8000103535a0:       add     w2, w2, w6
         : 79               stop_this_handle():
         : 733              DIV_ROUND_UP(t_revokes - revokes, rr_per_blk);
    0.00 :   ffff8000103535a4:       sub     w1, w4, w1
         : 732              DIV_ROUND_UP(t_revokes, rr_per_blk) -
    0.00 :   ffff8000103535a8:       sub     w3, w4, #0x1
         : 733              DIV_ROUND_UP(t_revokes - revokes, rr_per_blk);
    0.00 :   ffff8000103535ac:       add     w1, w1, w5
         : 732              DIV_ROUND_UP(t_revokes, rr_per_blk) -
    0.00 :   ffff8000103535b0:       add     w3, w3, w2
         : 733              DIV_ROUND_UP(t_revokes - revokes, rr_per_blk);
    0.00 :   ffff8000103535b4:       add     w1, w1, w2
         : 734              handle->h_total_credits -= revoke_descriptors;
    0.00 :   ffff8000103535b8:       ldr     w5, [x0, #16]
         : 732              DIV_ROUND_UP(t_revokes, rr_per_blk) -
    0.00 :   ffff8000103535bc:       sdiv    w2, w3, w4
         : 733              DIV_ROUND_UP(t_revokes - revokes, rr_per_blk);
    0.00 :   ffff8000103535c0:       sdiv    w1, w1, w4
         : 734              handle->h_total_credits -= revoke_descriptors;
    0.00 :   ffff8000103535c4:       add     w1, w1, w5
    0.00 :   ffff8000103535c8:       sub     w1, w1, w2
    0.00 :   ffff8000103535cc:       str     w1, [x0, #16]
    0.00 :   ffff8000103535d0:       b       ffff800010353500 <stop_this_handle+0x50>
         : 739              __ll_sc_atomic_add_return():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff8000103535d4:       add     x7, x19, #0xa0
    0.00 :   ffff8000103535d8:       b       ffff8000103564d4 <jbd2_journal_begin_ordered_truncate+0xf4>
    0.00 :   ffff8000103535dc:       mov     w2, w3
    0.00 :   ffff8000103535e0:       b       ffff8000103535a4 <stop_this_handle+0xf4>
         : 121              __ll_sc_atomic_sub_return():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000103535e4:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000103535e8:       add     x3, x19, #0x98
    0.00 :   ffff8000103535ec:       b       ffff8000103564f0 <jbd2_journal_begin_ordered_truncate+0x110>
         : 116              stop_this_handle():
         : 741              if (atomic_dec_and_test(&transaction->t_updates))
    0.00 :   ffff8000103535f0:       cbnz    w0, ffff800010353548 <stop_this_handle+0x98>
         : 742              wake_up(&journal->j_wait_updates);
    0.00 :   ffff8000103535f4:       add     x0, x21, #0xd0
    0.00 :   ffff8000103535f8:       mov     x3, #0x0                        // #0
    0.00 :   ffff8000103535fc:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010353600:       mov     w1, #0x3                        // #3
    0.00 :   ffff800010353604:       bl      ffff8000100cfab8 <__wake_up>
    0.00 :   ffff800010353608:       b       ffff800010353548 <stop_this_handle+0x98>
         : 749              __ll_sc_atomic_sub():
    0.00 :   ffff80001035360c:       add     x4, x19, #0x9c
    0.00 :   ffff800010353610:       b       ffff80001035650c <jbd2_journal_begin_ordered_truncate+0x12c>
    0.00 :   ffff800010353614:       b       ffff800010353514 <stop_this_handle+0x64>
    0.00 :   ffff800010353618:       str     x21, [sp, #32]
         : 116              stop_this_handle():
         : 713              J_ASSERT(journal_current_handle() == handle);
    0.00 :   ffff80001035361c:       brk     #0x800
         : 714              J_ASSERT(atomic_read(&transaction->t_updates) > 0);
    0.00 :   ffff800010353620:       brk     #0x800
         : 727              WARN_ON_ONCE(DIV_ROUND_UP(revokes, rr_per_blk)
    0.00 :   ffff800010353624:       brk     #0x800
    0.00 :   ffff800010353628:       b       ffff800010353590 <stop_this_handle+0xe0>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101a66b0 <__inc_numa_state>:
         : 6                __inc_numa_state():
         : 969              unsigned long count = 0;
         : 970              int i;
         :
         : 972              for (i = 0; i < MAX_NR_ZONES; i++)
         : 973              count += zone_numa_event_state(zones + i, item);
         :
   53.08 :   ffff8000101a66b0:       ldr     x3, [x0, #88]
         : 967              for (i = 0; i < MAX_NR_ZONES; i++)
    0.00 :   ffff8000101a66b4:       paciasp
         :
    0.00 :   ffff8000101a66b8:       mov     w1, w1
         : 971              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000101a66bc:       mrs     x5, tpidr_el1
         : 46               __inc_numa_state():
    0.00 :   ffff8000101a66c0:       add     x3, x3, #0x42
         : 974              return count;
         : 975              }
         :
         : 977              /*
         : 978              * Determine the per node value of a stat item.
    0.00 :   ffff8000101a66c4:       mov     w6, #0xfffd                     // #65533
         :
    0.00 :   ffff8000101a66c8:       add     x3, x3, x1, lsl #1
         :
    0.00 :   ffff8000101a66cc:       mov     x4, x3
   46.92 :   ffff8000101a66d0:       ldrh    w2, [x4, x5]
    0.00 :   ffff8000101a66d4:       add     w2, w2, #0x1
    0.00 :   ffff8000101a66d8:       and     w2, w2, #0xffff
    0.00 :   ffff8000101a66dc:       strh    w2, [x4, x5]
         : 974              * Determine the per node value of a stat item.
    0.00 :   ffff8000101a66e0:       cmp     w2, w6
    0.00 :   ffff8000101a66e4:       b.hi    ffff8000101a66f0 <__inc_numa_state+0x40>  // b.pmore
         : 978              */
         : 979              unsigned long node_page_state_pages(struct pglist_data *pgdat,
         : 980              enum node_stat_item item)
         : 981              {
    0.00 :   ffff8000101a66e8:       autiasp
    0.00 :   ffff8000101a66ec:       ret
         : 975              */
    0.00 :   ffff8000101a66f0:       add     x1, x1, #0xc2
    0.00 :   ffff8000101a66f4:       and     x2, x2, #0xffff
         : 978              zone_numa_state_add():
         :
         : 149              #ifdef CONFIG_NUMA
         : 150              static inline void zone_numa_event_add(long x, struct zone *zone,
         : 151              enum numa_stat_item item)
         : 152              {
         : 153              atomic_long_add(x, &zone->vm_numa_event[item]);
    0.00 :   ffff8000101a66f8:       lsl     x1, x1, #3
    0.00 :   ffff8000101a66fc:       add     x0, x0, x1
         : 156              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101a6700:       b       ffff8000101a6740 <__inc_numa_state+0x90>
    0.00 :   ffff8000101a6704:       b       ffff8000101a6740 <__inc_numa_state+0x90>
         : 46               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000101a6708:       mov     x4, x2
    0.00 :   ffff8000101a670c:       stadd   x4, [x0]
         : 187              zone_numa_state_add():
         : 149              atomic_long_add(x, &vm_numa_event[item]);
    0.00 :   ffff8000101a6710:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101a6714:       add     x0, x0, #0x340
    0.00 :   ffff8000101a6718:       add     x1, x0, x1
    0.00 :   ffff8000101a671c:       sub     x1, x1, #0x590
         : 154              arch_static_branch_jump():
    0.00 :   ffff8000101a6720:       b       ffff8000101a6738 <__inc_numa_state+0x88>
    0.00 :   ffff8000101a6724:       b       ffff8000101a6738 <__inc_numa_state+0x88>
         : 40               __lse_atomic64_add():
    0.00 :   ffff8000101a6728:       stadd   x2, [x1]
         : 180              __kern_my_cpu_offset():
    0.00 :   ffff8000101a672c:       mrs     x0, tpidr_el1
         : 40               __inc_numa_state():
         : 976              unsigned long node_page_state_pages(struct pglist_data *pgdat,
    0.00 :   ffff8000101a6730:       strh    wzr, [x3, x0]
         : 978              {
    0.00 :   ffff8000101a6734:       b       ffff8000101a66e8 <__inc_numa_state+0x38>
         : 980              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000101a6738:       b       ffff8000101a7134 <quiet_vmstat+0x60c>
    0.00 :   ffff8000101a673c:       b       ffff8000101a672c <__inc_numa_state+0x7c>
    0.00 :   ffff8000101a6740:       b       ffff8000101a714c <quiet_vmstat+0x624>
    0.00 :   ffff8000101a6744:       b       ffff8000101a6710 <__inc_numa_state+0x60>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010102998 <__rcu_read_unlock>:
         : 6                __rcu_read_unlock():
         : 455              */
         : 456              static bool rcu_preempt_has_tasks(struct rcu_node *rnp)
         : 457              {
         : 458              return !list_empty(&rnp->blkd_tasks);
         : 459              }
         :
    0.00 :   ffff800010102998:       paciasp
    0.65 :   ffff80001010299c:       stp     x29, x30, [sp, #-32]!
         : 463              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
   99.35 :   ffff8000101029a0:       mrs     x0, sp_el0
         : 26               __rcu_read_unlock():
    0.00 :   ffff8000101029a4:       mov     x29, sp
         : 456              rcu_preempt_read_exit():
         : 423              }
    0.00 :   ffff8000101029a8:       ldr     w1, [x0, #732]
    0.00 :   ffff8000101029ac:       sub     w1, w1, #0x1
    0.00 :   ffff8000101029b0:       str     w1, [x0, #732]
         : 427              __rcu_read_unlock():
         : 459              /*
         : 460              * Report deferred quiescent states.  The deferral time can
         : 461              * be quite short, for example, in the case of the call from
         : 462              * rcu_read_unlock_special().
    0.00 :   ffff8000101029b4:       cbnz    w1, ffff8000101029c0 <__rcu_read_unlock+0x28>
         : 461              */
         : 462              static void
    0.00 :   ffff8000101029b8:       ldr     w1, [x0, #736]
    0.00 :   ffff8000101029bc:       cbnz    w1, ffff8000101029cc <__rcu_read_unlock+0x34>
         : 469              bool empty_exp;
         : 470              bool empty_norm;
         : 471              bool empty_exp_now;
         : 472              struct list_head *np;
         : 473              bool drop_boost_mutex = false;
         : 474              struct rcu_data *rdp;
    0.00 :   ffff8000101029c0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000101029c4:       autiasp
    0.00 :   ffff8000101029c8:       ret
         : 478              preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000101029cc:       ldr     w1, [x0, #8]
    0.00 :   ffff8000101029d0:       ldr     w2, [x0, #8]
         : 20               rcu_read_unlock_special():
         : 669              }
         : 670              }
         : 671              local_irq_restore(flags);
         : 672              return;
         : 673              }
         : 674              rcu_preempt_deferred_qs_irqrestore(t, flags);
    0.00 :   ffff8000101029d4:       tst     w2, #0xf00000
    0.00 :   ffff8000101029d8:       b.ne    ffff8000101029c0 <__rcu_read_unlock+0x28>  // b.any
         : 677              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101029dc:       str     x19, [sp, #16]
    0.00 :   ffff8000101029e0:       mrs     x19, daif
         : 78               arch_irqs_disabled_flags():
         : 90               asm volatile(ALTERNATIVE(
         : 91               "and    %w0, %w1, #" __stringify(PSR_I_BIT),
         : 92               "eor    %w0, %w1, #" __stringify(GIC_PRIO_IRQON),
         : 93               ARM64_HAS_IRQ_PRIO_MASKING)
         : 94               : "=&r" (res)
         : 95               : "r" ((int) flags)
    0.00 :   ffff8000101029e4:       mov     w2, w19
         : 85               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101029e8:       and     w3, w19, #0x80
         : 87               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff8000101029ec:       cbz     w3, ffff800010102a74 <__rcu_read_unlock+0xdc>
         : 118              arch_irqs_disabled_flags():
         : 85               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101029f0:       and     w3, w2, #0x80
         : 87               rcu_read_unlock_special():
         : 674              }
         :
         : 676              /*
         : 677              * Check that the list of blocked tasks for the newly completed grace
         : 678              * period is in fact empty.  It is a serious bug to complete a grace
    0.00 :   ffff8000101029f4:       and     w1, w1, #0xffff
    0.00 :   ffff8000101029f8:       orr     w1, w1, w3
    0.00 :   ffff8000101029fc:       cbz     w1, ffff800010102a64 <__rcu_read_unlock+0xcc>
         : 679              * period that still has RCU readers blocked!  This function must be
         : 680              * invoked -before- updating this rnp's ->gp_seq.
         : 681              *
         : 682              * Also, if there are blocked tasks on the list, they automatically
         : 683              * block the newly created grace period, so set up ->gp_tasks accordingly.
    0.00 :   ffff800010102a00:       ldr     x1, [x0, #760]
         : 685              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010102a04:       mrs     x2, tpidr_el1
         : 46               rcu_read_unlock_special():
         : 676              * invoked -before- updating this rnp's ->gp_seq.
    0.00 :   ffff800010102a08:       adrp    x0, ffff80001177a000 <runqueues+0x3c0>
    0.00 :   ffff800010102a0c:       add     x0, x0, #0x900
    0.00 :   ffff800010102a10:       add     x2, x0, x2
         : 679              * block the newly created grace period, so set up ->gp_tasks accordingly.
    0.00 :   ffff800010102a14:       cbz     x1, ffff800010102b04 <__rcu_read_unlock+0x16c>
    0.00 :   ffff800010102a18:       ldr     x0, [x1, #168]
    0.00 :   ffff800010102a1c:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010102a20:       cbz     x0, ffff800010102b04 <__rcu_read_unlock+0x16c>
         : 685              */
         : 686              static void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)
         : 687              {
         : 688              struct task_struct *t;
         :
         : 690              RCU_LOCKDEP_WARN(preemptible(), "rcu_preempt_check_blocked_tasks() invoked with preemption enabled!!!\n");
    0.00 :   ffff800010102a24:       adrp    x0, ffff800011cb3000 <_rs.29273+0x20>
    0.00 :   ffff800010102a28:       ldrb    w0, [x0, #2368]
    0.00 :   ffff800010102a2c:       cbz     w0, ffff800010102a84 <__rcu_read_unlock+0xec>
         : 694              get_current():
    0.00 :   ffff800010102a30:       mrs     x0, sp_el0
         : 20               preempt_count():
    0.00 :   ffff800010102a34:       ldr     w0, [x0, #8]
         : 13               rcu_read_unlock_special():
    0.00 :   ffff800010102a38:       tst     w0, #0xf0000
    0.00 :   ffff800010102a3c:       b.ne    ffff800010102a4c <__rcu_read_unlock+0xb4>  // b.any
    0.00 :   ffff800010102a40:       cmp     w3, #0x0
    0.00 :   ffff800010102a44:       ccmp    w1, #0x0, #0x4, eq  // eq = none
    0.00 :   ffff800010102a48:       b.eq    ffff800010102a84 <__rcu_read_unlock+0xec>  // b.none
         : 689              raw_lockdep_assert_held_rcu_node(rnp);
         : 690              if (WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)))
         : 691              dump_blkd_tasks(rnp, 10);
         : 692              if (rcu_preempt_has_tasks(rnp) &&
    0.00 :   ffff800010102a4c:       mov     w0, #0x9                        // #9
    0.00 :   ffff800010102a50:       bl      ffff8000100893a8 <raise_softirq_irqoff>
         : 695              arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff800010102a54:       msr     daif, x19
         : 129              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010102a58:       nop
         : 28               arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff800010102a5c:       ldr     x19, [sp, #16]
    0.00 :   ffff800010102a60:       b       ffff8000101029c0 <__rcu_read_unlock+0x28>
         : 138              rcu_read_unlock_special():
         : 709              * elsewhere, hence this function need only check for quiescent states
         : 710              * related to the current CPU, not to those related to tasks.
         : 711              */
         : 712              static void rcu_flavor_sched_clock_irq(int user)
         : 713              {
         : 714              struct task_struct *t = current;
    0.00 :   ffff800010102a64:       mov     x1, x19
    0.00 :   ffff800010102a68:       bl      ffff800010101ba0 <rcu_preempt_deferred_qs_irqrestore>
         : 717              __rcu_read_unlock():
         : 469              struct rcu_data *rdp;
    0.00 :   ffff800010102a6c:       ldr     x19, [sp, #16]
    0.00 :   ffff800010102a70:       b       ffff8000101029c0 <__rcu_read_unlock+0x28>
         : 472              arch_static_branch():
    0.00 :   ffff800010102a74:       nop
    0.00 :   ffff800010102a78:       mov     x3, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010102a7c:       msr     daifset, #0x3
    0.00 :   ffff800010102a80:       b       ffff8000101029f0 <__rcu_read_unlock+0x58>
         : 57               get_current():
    0.00 :   ffff800010102a84:       mrs     x0, sp_el0
         : 20               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010102a88:       b       ffff800010102b2c <__rcu_read_unlock+0x194>
    0.00 :   ffff800010102a8c:       b       ffff800010102b2c <__rcu_read_unlock+0x194>
         : 46               __lse_atomic64_or():
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010102a90:       mov     x4, #0x2                        // #2
    0.00 :   ffff800010102a94:       stset   x4, [x0]
         : 185              get_current():
    0.00 :   ffff800010102a98:       mrs     x0, sp_el0
         : 20               set_preempt_need_resched():
         : 31               task_thread_info(p)->preempt_count = PREEMPT_DISABLED; \
         : 32               } while (0)
         :
         : 34               static inline void set_preempt_need_resched(void)
         : 35               {
         : 36               current_thread_info()->preempt.need_resched = 0;
    0.00 :   ffff800010102a9c:       str     wzr, [x0, #12]
         : 38               rcu_read_unlock_special():
         : 697              WARN_ON_ONCE(rnp->qsmask);
    0.00 :   ffff800010102aa0:       cmp     w3, #0x0
    0.00 :   ffff800010102aa4:       ccmp    w1, #0x0, #0x4, ne  // ne = any
    0.00 :   ffff800010102aa8:       b.eq    ffff800010102a54 <__rcu_read_unlock+0xbc>  // b.none
         : 698              }
    0.00 :   ffff800010102aac:       ldrb    w0, [x2, #72]
    0.00 :   ffff800010102ab0:       cbnz    w0, ffff800010102a54 <__rcu_read_unlock+0xbc>
    0.00 :   ffff800010102ab4:       ldr     w1, [x2, #424]
         : 702              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010102ab8:       adrp    x3, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010102abc:       add     x3, x3, #0x9e8
    0.00 :   ffff800010102ac0:       cmp     w1, #0x0
    0.00 :   ffff800010102ac4:       add     w0, w1, #0x3f
    0.00 :   ffff800010102ac8:       csel    w0, w0, w1, lt  // lt = tstop
    0.00 :   ffff800010102acc:       asr     w0, w0, #6
    0.00 :   ffff800010102ad0:       sxtw    x0, w0
    0.00 :   ffff800010102ad4:       ldr     x0, [x3, x0, lsl #3]
    0.00 :   ffff800010102ad8:       lsr     x0, x0, x1
         : 121              rcu_read_unlock_special():
    0.00 :   ffff800010102adc:       tbz     w0, #0, ffff800010102a54 <__rcu_read_unlock+0xbc>
         : 699              init_irq_work():
         : 36               struct irq_work name = IRQ_WORK_INIT(_f)
         :
         : 38               static inline
         : 39               void init_irq_work(struct irq_work *work, void (*func)(struct irq_work *))
         : 40               {
         : 41               *work = IRQ_WORK_INIT(func);
    0.00 :   ffff800010102ae0:       add     x0, x2, #0x30
    0.00 :   ffff800010102ae4:       stp     xzr, xzr, [x2, #48]
    0.00 :   ffff800010102ae8:       adrp    x3, ffff8000100fd000 <srcu_gp_start_if_needed+0x350>
    0.00 :   ffff800010102aec:       add     x3, x3, #0x718
         : 46               rcu_read_unlock_special():
         : 702              * context switches for Tasks RCU.  When a task blocks, the task is
    0.00 :   ffff800010102af0:       mov     w4, #0x1                        // #1
         : 704              init_irq_work():
    0.00 :   ffff800010102af4:       str     x3, [x0, #16]
         : 37               rcu_read_unlock_special():
    0.00 :   ffff800010102af8:       strb    w4, [x2, #72]
         : 703              * recorded in the corresponding CPU's rcu_node structure, which is checked
    0.00 :   ffff800010102afc:       bl      ffff80001015d980 <irq_work_queue_on>
    0.00 :   ffff800010102b00:       b       ffff800010102a54 <__rcu_read_unlock+0xbc>
         : 680              */
    0.00 :   ffff800010102b04:       ldp     x1, x0, [x2, #24]
    0.00 :   ffff800010102b08:       ldr     x1, [x1, #72]
         : 679              * block the newly created grace period, so set up ->gp_tasks accordingly.
    0.00 :   ffff800010102b0c:       tst     x1, x0
    0.00 :   ffff800010102b10:       cset    w1, ne  // ne = any
    0.00 :   ffff800010102b14:       b       ffff800010102a24 <__rcu_read_unlock+0x8c>
         : 683              arch_local_irq_restore():
         : 130              pmr_sync();
    0.00 :   ffff800010102b18:       dsb     sy
    0.00 :   ffff800010102b1c:       ldr     x19, [sp, #16]
    0.00 :   ffff800010102b20:       b       ffff8000101029c0 <__rcu_read_unlock+0x28>
         : 134              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010102b24:       mov     x3, #0xa0                       // #160
    0.00 :   ffff800010102b28:       b       ffff800010102a7c <__rcu_read_unlock+0xe4>
         : 24               __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010102b2c:       b       ffff8000101045f0 <rcu_needs_cpu+0x278>
    0.00 :   ffff800010102b30:       b       ffff800010102a98 <__rcu_read_unlock+0x100>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e352c0 <_raw_read_lock>:
         : 6                _raw_read_lock():
         : 222              EXPORT_SYMBOL(_raw_read_trylock);
         : 223              #endif
         :
         : 225              #ifndef CONFIG_INLINE_READ_LOCK
         : 226              void __lockfunc _raw_read_lock(rwlock_t *lock)
         : 227              {
    0.00 :   ffff800010e352c0:       paciasp
    0.00 :   ffff800010e352c4:       stp     x29, x30, [sp, #-16]!
         : 230              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e352c8:       mrs     x2, sp_el0
         : 26               _raw_read_lock():
    0.00 :   ffff800010e352cc:       mov     x29, sp
         : 223              __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010e352d0:       ldr     w1, [x2, #8]
         : 47               pc += val;
    0.00 :   ffff800010e352d4:       add     w1, w1, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010e352d8:       str     w1, [x2, #8]
         : 50               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e352dc:       b       ffff800010e35300 <_raw_read_lock+0x40>
    0.00 :   ffff800010e352e0:       b       ffff800010e35300 <_raw_read_lock+0x40>
         : 46               __lse_atomic_add_return_acquire():
         : 74               \
         : 75               return i;                                                       \
         : 76               }
         :
         : 78               ATOMIC_OP_ADD_RETURN(_relaxed,   )
         : 79               ATOMIC_OP_ADD_RETURN(_acquire,  a, "memory")
    0.00 :   ffff800010e352e4:       mov     w1, #0x200                      // #512
    0.00 :   ffff800010e352e8:       ldadda  w1, w2, [x0]
  100.00 :   ffff800010e352ec:       add     w1, w1, w2
         : 83               queued_read_lock():
         : 79               static inline void queued_read_lock(struct qrwlock *lock)
         : 80               {
         : 81               int cnts;
         :
         : 83               cnts = atomic_add_return_acquire(_QR_BIAS, &lock->cnts);
         : 84               if (likely(!(cnts & _QW_WMASK)))
    0.00 :   ffff800010e352f0:       tst     x1, #0x1ff
    0.00 :   ffff800010e352f4:       b.eq    ffff800010e3530c <_raw_read_lock+0x4c>  // b.none
         : 83               return;
         :
         : 85               /* The slowpath will decrement the reader count, if necessary. */
         : 86               queued_read_lock_slowpath(lock);
    0.00 :   ffff800010e352f8:       bl      ffff8000100db1a0 <queued_read_lock_slowpath>
         : 88               _raw_read_lock():
         : 224              __raw_read_lock(lock);
         : 225              }
    0.00 :   ffff800010e352fc:       b       ffff800010e3530c <_raw_read_lock+0x4c>
         : 227              __ll_sc_atomic_add_return_acquire():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff800010e35300:       b       ffff800010e35904 <_raw_read_lock_irqsave+0x20c>
         : 118              queued_read_lock():
         : 79               if (likely(!(cnts & _QW_WMASK)))
    0.00 :   ffff800010e35304:       tst     x1, #0x1ff
    0.00 :   ffff800010e35308:       b.ne    ffff800010e352f8 <_raw_read_lock+0x38>  // b.any
         : 82               _raw_read_lock():
    0.00 :   ffff800010e3530c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e35310:       autiasp
    0.00 :   ffff800010e35314:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001017d860 <unlock_page>:
         : 6                unlock_page():
         : 1453             * clear the PG_locked bit and test PG_waiters at the same time fairly
         : 1454             * portably (architectures that do LL/SC can test any bit, while x86 can
         : 1455             * test the sign bit).
         : 1456             */
         : 1457             void unlock_page(struct page *page)
         : 1458             {
    0.00 :   ffff80001017d860:       paciasp
    0.00 :   ffff80001017d864:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001017d868:       mov     x29, sp
         : 1462             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff80001017d86c:       ldr     x1, [x0, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff80001017d870:       sub     x2, x1, #0x1
    0.00 :   ffff80001017d874:       tst     x1, #0x1
    0.00 :   ffff80001017d878:       csel    x0, x2, x0, ne  // ne = any
         : 193              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
   53.72 :   ffff80001017d87c:       b       ffff80001017d89c <unlock_page+0x3c>
    0.00 :   ffff80001017d880:       b       ffff80001017d89c <unlock_page+0x3c>
         : 46               __lse_atomic64_fetch_andnot_release():
         : 202              ATOMIC64_FETCH_OP(_relaxed,   , op, asm_op)                     \
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff80001017d884:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001017d888:       ldclrl  x1, x1, [x0]
         : 210              unlock_page():
         : 1457             BUILD_BUG_ON(PG_waiters != 7);
         : 1458             page = compound_head(page);
         : 1459             VM_BUG_ON_PAGE(!PageLocked(page), page);
         : 1460             if (clear_bit_unlock_is_negative_byte(PG_locked, &page->flags))
   46.28 :   ffff80001017d88c:       tbnz    w1, #7, ffff80001017d8a8 <unlock_page+0x48>
         : 1459             wake_up_page_bit(page, PG_locked);
         : 1460             }
    0.00 :   ffff80001017d890:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001017d894:       autiasp
    0.00 :   ffff80001017d898:       ret
         : 1464             __ll_sc_atomic64_fetch_andnot_release():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff80001017d89c:       mov     x2, #0x1                        // #1
    0.00 :   ffff80001017d8a0:       b       ffff800010184320 <generic_file_write_iter+0x1c8>
         : 237              unlock_page():
         : 1457             if (clear_bit_unlock_is_negative_byte(PG_locked, &page->flags))
    0.00 :   ffff80001017d8a4:       tbz     w1, #7, ffff80001017d890 <unlock_page+0x30>
         : 1458             wake_up_page_bit(page, PG_locked);
    0.00 :   ffff80001017d8a8:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001017d8ac:       bl      ffff80001017d710 <wake_up_page_bit>
         : 1459             }
    0.00 :   ffff80001017d8b0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001017d8b4:       autiasp
    0.00 :   ffff80001017d8b8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010313e40 <ext4_da_write_end>:
         : 6                ext4_da_write_end():
         :
         : 3071             static int ext4_da_write_end(struct file *file,
         : 3072             struct address_space *mapping,
         : 3073             loff_t pos, unsigned len, unsigned copied,
         : 3074             struct page *page, void *fsdata)
         : 3075             {
    0.00 :   ffff800010313e40:       paciasp
    0.00 :   ffff800010313e44:       stp     x29, x30, [sp, #-112]!
         : 3078             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
   51.94 :   ffff800010313e48:       mrs     x7, sp_el0
         : 26               ext4_da_write_end():
    0.00 :   ffff800010313e4c:       mov     x29, sp
    0.00 :   ffff800010313e50:       stp     x19, x20, [sp, #16]
         : 3078             handle_t *handle = ext4_journal_current_handle();
         : 3079             loff_t new_i_size;
         : 3080             unsigned long start, end;
         : 3081             int write_mode = (int)(unsigned long)fsdata;
         :
         : 3083             if (write_mode == FALL_BACK_TO_NONDELALLOC)
    0.00 :   ffff800010313e54:       cmp     w6, #0x1
         : 3070             {
    0.00 :   ffff800010313e58:       stp     x25, x26, [sp, #64]
         : 3071             struct inode *inode = mapping->host;
    0.00 :   ffff800010313e5c:       ldr     x19, [x1]
         : 3073             journal_current_handle():
         : 1471             * ever tries to take a handle on the running transaction while we are in the
         : 1472             * middle of moving it to the commit phase.  j_state_lock does this.
         : 1473             *
         : 1474             * Note that the locking is completely interrupt unsafe.  We never touch
         : 1475             * journal structures from interrupts.
         : 1476             */
    0.00 :   ffff800010313e60:       ldr     x25, [x7, #1824]
         : 1478             ext4_da_write_end():
         : 3078             if (write_mode == FALL_BACK_TO_NONDELALLOC)
    0.00 :   ffff800010313e64:       b.eq    ffff80001031409c <ext4_da_write_end+0x25c>  // b.none
         : 3092             * generic_write_end() will run mark_inode_dirty() if i_size
         : 3093             * changes.  So let's piggyback the i_disksize mark_inode_dirty
         : 3094             * into that.
         : 3095             */
         : 3096             new_i_size = pos + copied;
         : 3097             if (copied && new_i_size > EXT4_I(inode)->i_disksize) {
    0.00 :   ffff800010313e68:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010313e6c:       mov     x8, x0
    0.00 :   ffff800010313e70:       mov     x21, x6
    0.00 :   ffff800010313e74:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010313e78:       mov     x26, x2
    0.00 :   ffff800010313e7c:       mov     x24, x1
    0.00 :   ffff800010313e80:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010313e84:       mov     w22, w4
    0.00 :   ffff800010313e88:       mov     w28, w3
    0.00 :   ffff800010313e8c:       mov     x27, x5
   48.06 :   ffff800010313e90:       cbnz    w4, ffff800010313f20 <ext4_da_write_end+0xe0>
    0.00 :   ffff800010313e94:       adrp    x20, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff800010313e98:       add     x20, x20, #0x30
         : 3072             int ret = 0, ret2;
    0.00 :   ffff800010313e9c:       mov     w23, #0x0                       // #0
         : 3104             */
         : 3105             ret = ext4_mark_inode_dirty(handle, inode);
         : 3106             }
         : 3107             }
         :
         : 3109             if (write_mode != CONVERT_INLINE_DATA &&
    0.00 :   ffff800010313ea0:       cmp     w21, #0x2
    0.00 :   ffff800010313ea4:       b.eq    ffff800010313eb0 <ext4_da_write_end+0x70>  // b.none
         : 3112             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010313ea8:       ldur    x0, [x19, #-240]
         : 113              ext4_da_write_end():
    0.00 :   ffff800010313eac:       tbnz    x0, #39, ffff800010313fb4 <ext4_da_write_end+0x174>
         : 3110             ext4_test_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA) &&
         : 3111             ext4_has_inline_data(inode))
         : 3112             ret2 = ext4_da_write_inline_data_end(inode, pos, len, copied,
         : 3113             page);
         : 3114             else
         : 3115             ret2 = generic_write_end(file, mapping, pos, len, copied,
    0.00 :   ffff800010313eb0:       mov     x6, x21
    0.00 :   ffff800010313eb4:       mov     x5, x27
    0.00 :   ffff800010313eb8:       mov     w4, w22
    0.00 :   ffff800010313ebc:       mov     w3, w28
    0.00 :   ffff800010313ec0:       mov     x2, x26
    0.00 :   ffff800010313ec4:       mov     x1, x24
    0.00 :   ffff800010313ec8:       mov     x0, x8
    0.00 :   ffff800010313ecc:       bl      ffff80001027bbf0 <generic_write_end>
    0.00 :   ffff800010313ed0:       mov     w19, w0
         : 3116             page, fsdata);
         :
         : 3118             copied = ret2;
         : 3119             if (ret2 < 0)
         : 3120             ret = ret2;
         : 3121             ret2 = ext4_journal_stop(handle);
    0.00 :   ffff800010313ed4:       mov     x2, x25
    0.00 :   ffff800010313ed8:       add     x0, x20, #0x4c8
    0.00 :   ffff800010313edc:       mov     w1, #0xc2c                      // #3116
         : 3114             if (ret2 < 0)
    0.00 :   ffff800010313ee0:       tbnz    w19, #31, ffff800010313fe8 <ext4_da_write_end+0x1a8>
         : 3116             ret2 = ext4_journal_stop(handle);
    0.00 :   ffff800010313ee4:       bl      ffff8000102f20c8 <__ext4_journal_stop>
         : 3117             if (unlikely(ret2 && !ret))
    0.00 :   ffff800010313ee8:       cmp     w0, #0x0
    0.00 :   ffff800010313eec:       ccmp    w23, #0x0, #0x0, ne  // ne = any
    0.00 :   ffff800010313ef0:       b.eq    ffff800010314088 <ext4_da_write_end+0x248>  // b.none
         : 3120             ret = ret2;
         :
         : 3122             return ret ? ret : copied;
    0.00 :   ffff800010313ef4:       cmp     w23, #0x0
    0.00 :   ffff800010313ef8:       csel    w19, w19, w23, eq  // eq = none
    0.00 :   ffff800010313efc:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010313f00:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010313f04:       ldp     x27, x28, [sp, #80]
         : 3121             }
    0.00 :   ffff800010313f08:       mov     w0, w19
    0.00 :   ffff800010313f0c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010313f10:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010313f14:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010313f18:       autiasp
    0.00 :   ffff800010313f1c:       ret
         : 3092             if (copied && new_i_size > EXT4_I(inode)->i_disksize) {
    0.00 :   ffff800010313f20:       ldur    x1, [x19, #-88]
         : 3091             new_i_size = pos + copied;
    0.00 :   ffff800010313f24:       mov     w3, w4
    0.00 :   ffff800010313f28:       add     x20, x3, x2
         : 3092             if (copied && new_i_size > EXT4_I(inode)->i_disksize) {
    0.00 :   ffff800010313f2c:       sub     x0, x19, #0x140
    0.00 :   ffff800010313f30:       cmp     x1, x20
    0.00 :   ffff800010313f34:       b.ge    ffff800010313e94 <ext4_da_write_end+0x54>  // b.tcont
         : 3096             test_bit():
    0.00 :   ffff800010313f38:       ldur    x1, [x19, #-240]
         : 107              ext4_has_inline_data():
         : 3566             int *retval);
         : 3567             extern int ext4_inline_data_fiemap(struct inode *inode,
         : 3568             struct fiemap_extent_info *fieinfo,
         : 3569             int *has_inline, __u64 start, __u64 len);
         :
         : 3571             struct iomap;
    0.00 :   ffff800010313f3c:       tst     w1, #0x10000000
    0.00 :   ffff800010313f40:       b.eq    ffff800010314010 <ext4_da_write_end+0x1d0>  // b.none
    0.00 :   ffff800010313f44:       ldrh    w1, [x0, #1034]
    0.00 :   ffff800010313f48:       cbz     w1, ffff800010314010 <ext4_da_write_end+0x1d0>
         : 3576             ext4_update_i_disksize():
         : 3335             */
    0.00 :   ffff800010313f4c:       ldrh    w1, [x19]
    0.00 :   ffff800010313f50:       and     w1, w1, #0xf000
    0.00 :   ffff800010313f54:       cmp     w1, #0x8, lsl #12
    0.00 :   ffff800010313f58:       b.eq    ffff8000103140bc <ext4_da_write_end+0x27c>  // b.none
         : 3337             #else
    0.00 :   ffff800010313f5c:       add     x23, x0, #0xf0
    0.00 :   ffff800010313f60:       str     x8, [sp, #104]
    0.00 :   ffff800010313f64:       mov     x0, x23
    0.00 :   ffff800010313f68:       bl      ffff800010e315d0 <down_write>
         : 3338             #define EXT4_FREECLUSTERS_WATERMARK 0
    0.00 :   ffff800010313f6c:       ldur    x0, [x19, #-88]
    0.00 :   ffff800010313f70:       ldr     x8, [sp, #104]
    0.00 :   ffff800010313f74:       cmp     x20, x0
    0.00 :   ffff800010313f78:       b.le    ffff800010313f80 <ext4_da_write_end+0x140>
         : 3339             #endif
    0.00 :   ffff800010313f7c:       stur    x20, [x19, #-88]
         :
    0.00 :   ffff800010313f80:       mov     x0, x23
         : 3342             ext4_da_write_end():
         : 3100             ret = ext4_mark_inode_dirty(handle, inode);
    0.00 :   ffff800010313f84:       adrp    x20, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff800010313f88:       add     x20, x20, #0x30
    0.00 :   ffff800010313f8c:       str     x8, [sp, #104]
         : 3104             ext4_update_i_disksize():
    0.00 :   ffff800010313f90:       bl      ffff8000100d97f8 <up_write>
         : 3341             ext4_da_write_end():
    0.00 :   ffff800010313f94:       add     x2, x20, #0x4c8
    0.00 :   ffff800010313f98:       mov     w3, #0xc1c                      // #3100
    0.00 :   ffff800010313f9c:       mov     x1, x19
    0.00 :   ffff800010313fa0:       mov     x0, x25
    0.00 :   ffff800010313fa4:       bl      ffff800010311200 <__ext4_mark_inode_dirty>
    0.00 :   ffff800010313fa8:       mov     w23, w0
    0.00 :   ffff800010313fac:       ldr     x8, [sp, #104]
    0.00 :   ffff800010313fb0:       b       ffff800010313ea0 <ext4_da_write_end+0x60>
         : 3108             test_bit():
    0.00 :   ffff800010313fb4:       ldur    x0, [x19, #-240]
         : 107              ext4_has_inline_data():
         : 3566             struct iomap;
    0.00 :   ffff800010313fb8:       tst     w0, #0x10000000
    0.00 :   ffff800010313fbc:       b.eq    ffff800010313eb0 <ext4_da_write_end+0x70>  // b.none
    0.00 :   ffff800010313fc0:       ldrh    w0, [x19, #714]
    0.00 :   ffff800010313fc4:       cbz     w0, ffff800010313eb0 <ext4_da_write_end+0x70>
         : 3571             ext4_da_write_end():
         : 3107             ret2 = ext4_da_write_inline_data_end(inode, pos, len, copied,
    0.00 :   ffff800010313fc8:       mov     x0, x19
    0.00 :   ffff800010313fcc:       mov     x4, x27
    0.00 :   ffff800010313fd0:       mov     w3, w22
    0.00 :   ffff800010313fd4:       mov     w2, w28
    0.00 :   ffff800010313fd8:       mov     x1, x26
    0.00 :   ffff800010313fdc:       bl      ffff8000103090f8 <ext4_da_write_inline_data_end>
    0.00 :   ffff800010313fe0:       mov     w19, w0
    0.00 :   ffff800010313fe4:       b       ffff800010313ed4 <ext4_da_write_end+0x94>
         : 3116             ret2 = ext4_journal_stop(handle);
    0.00 :   ffff800010313fe8:       bl      ffff8000102f20c8 <__ext4_journal_stop>
         : 3121             }
    0.00 :   ffff800010313fec:       mov     w0, w19
    0.00 :   ffff800010313ff0:       ldp     x19, x20, [sp, #16]
         : 3116             ret2 = ext4_journal_stop(handle);
    0.00 :   ffff800010313ff4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010313ff8:       ldp     x23, x24, [sp, #48]
         : 3121             }
    0.00 :   ffff800010313ffc:       ldp     x25, x26, [sp, #64]
         : 3116             ret2 = ext4_journal_stop(handle);
    0.00 :   ffff800010314000:       ldp     x27, x28, [sp, #80]
         : 3121             }
    0.00 :   ffff800010314004:       ldp     x29, x30, [sp], #112
    0.00 :   ffff800010314008:       autiasp
    0.00 :   ffff80001031400c:       ret
         : 3125             test_bit():
    0.00 :   ffff800010314010:       ldr     x2, [x27]
         : 107              ext4_da_should_update_i_disksize():
         : 3051             struct inode *inode = page->mapping->host;
    0.00 :   ffff800010314014:       ldr     x1, [x27, #24]
         : 3055             bh = page_buffers(page);
    0.00 :   ffff800010314018:       tst     w2, #0x2000
         : 3051             struct inode *inode = page->mapping->host;
    0.00 :   ffff80001031401c:       ldr     x2, [x1]
         : 3055             bh = page_buffers(page);
    0.00 :   ffff800010314020:       b.eq    ffff8000103140dc <ext4_da_write_end+0x29c>  // b.none
         : 3057             ext4_da_write_end():
         : 3084             end = start + copied - 1;
    0.00 :   ffff800010314024:       sub     x1, x3, #0x1
         : 3086             ext4_da_should_update_i_disksize():
         : 3056             idx = offset >> inode->i_blkbits;
    0.00 :   ffff800010314028:       ldrb    w4, [x2, #142]
         : 3058             ext4_da_write_end():
         : 3083             start = pos & (PAGE_SIZE - 1);
    0.00 :   ffff80001031402c:       and     x3, x26, #0xfff
         : 3084             end = start + copied - 1;
    0.00 :   ffff800010314030:       add     x3, x3, x1
         : 3086             ext4_da_should_update_i_disksize():
         : 3055             bh = page_buffers(page);
    0.00 :   ffff800010314034:       ldr     x2, [x27, #40]
         : 3056             idx = offset >> inode->i_blkbits;
    0.00 :   ffff800010314038:       lsr     x3, x3, x4
         : 3058             for (i = 0; i < idx; i++)
    0.00 :   ffff80001031403c:       cbz     w3, ffff800010314058 <ext4_da_write_end+0x218>
    0.00 :   ffff800010314040:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010314044:       nop
    0.00 :   ffff800010314048:       add     w1, w1, #0x1
    0.00 :   ffff80001031404c:       cmp     w3, w1
         : 3059             bh = bh->b_this_page;
    0.00 :   ffff800010314050:       ldr     x2, [x2, #8]
         : 3058             for (i = 0; i < idx; i++)
    0.00 :   ffff800010314054:       b.ne    ffff800010314048 <ext4_da_write_end+0x208>  // b.any
         : 3060             test_bit():
    0.00 :   ffff800010314058:       ldr     x23, [x2]
    0.00 :   ffff80001031405c:       ubfx    w23, w23, #4, #1
         : 108              ext4_da_should_update_i_disksize():
         : 3061             if (!buffer_mapped(bh) || (buffer_delay(bh)) || buffer_unwritten(bh))
    0.00 :   ffff800010314060:       cbz     w23, ffff80001031407c <ext4_da_write_end+0x23c>
         : 3063             test_bit():
    0.00 :   ffff800010314064:       ldr     x23, [x2]
    0.00 :   ffff800010314068:       ubfx    w23, w23, #8, #1
         : 108              ext4_da_should_update_i_disksize():
    0.00 :   ffff80001031406c:       cbnz    w23, ffff8000103140cc <ext4_da_write_end+0x28c>
         : 3062             test_bit():
    0.00 :   ffff800010314070:       ldr     x1, [x2]
         : 107              ext4_da_should_update_i_disksize():
    0.00 :   ffff800010314074:       tst     w1, #0x800
    0.00 :   ffff800010314078:       b.eq    ffff800010313f4c <ext4_da_write_end+0x10c>  // b.none
    0.00 :   ffff80001031407c:       adrp    x20, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff800010314080:       add     x20, x20, #0x30
    0.00 :   ffff800010314084:       b       ffff800010313ea0 <ext4_da_write_end+0x60>
         : 3066             ext4_da_write_end():
    0.00 :   ffff800010314088:       mov     w19, w0
    0.00 :   ffff80001031408c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010314090:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010314094:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010314098:       b       ffff800010313f08 <ext4_da_write_end+0xc8>
         : 3079             return ext4_write_end(file, mapping, pos,
    0.00 :   ffff80001031409c:       bl      ffff800010313b20 <ext4_write_end>
    0.00 :   ffff8000103140a0:       mov     w19, w0
         : 3121             }
    0.00 :   ffff8000103140a4:       mov     w0, w19
    0.00 :   ffff8000103140a8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000103140ac:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000103140b0:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000103140b4:       autiasp
    0.00 :   ffff8000103140b8:       ret
         : 3128             atomic64_read():
         : 838              static __always_inline s64
         : 839              atomic64_dec_return_acquire(atomic64_t *v)
         : 840              {
         : 841              instrument_atomic_read_write(v, sizeof(*v));
         : 842              return arch_atomic64_dec_return_acquire(v);
         : 843              }
    0.00 :   ffff8000103140bc:       ldr     x1, [x19, #160]
         : 845              ext4_update_i_disksize():
         : 3335             */
    0.00 :   ffff8000103140c0:       cbnz    x1, ffff800010313f5c <ext4_da_write_end+0x11c>
    0.00 :   ffff8000103140c4:       brk     #0x800
    0.00 :   ffff8000103140c8:       b       ffff800010313f5c <ext4_da_write_end+0x11c>
    0.00 :   ffff8000103140cc:       adrp    x20, ffff800010e8a000 <__func__.49343+0x10>
         : 3340             ext4_da_write_end():
         : 3072             int ret = 0, ret2;
    0.00 :   ffff8000103140d0:       mov     w23, #0x0                       // #0
    0.00 :   ffff8000103140d4:       add     x20, x20, #0x30
    0.00 :   ffff8000103140d8:       b       ffff800010313ea0 <ext4_da_write_end+0x60>
         : 3076             ext4_da_should_update_i_disksize():
         : 3055             bh = page_buffers(page);
    0.00 :   ffff8000103140dc:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104bd080 <xas_load>:
         : 6                xas_load():
         : 232              *
         : 233              * Context: Any context.  The caller should hold the xa_lock or the RCU lock.
         : 234              * Return: Usually an entry in the XArray, but see description for exceptions.
         : 235              */
         : 236              void *xas_load(struct xa_state *xas)
         : 237              {
    0.00 :   ffff8000104bd080:       mov     x4, x0
    0.00 :   ffff8000104bd084:       paciasp
    0.00 :   ffff8000104bd088:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff8000104bd08c:       mov     x29, sp
         : 233              void *entry = xas_start(xas);
    0.00 :   ffff8000104bd090:       bl      ffff8000104bcfa8 <xas_start>
    0.00 :   ffff8000104bd094:       nop
         : 236              xa_is_node():
         : 1226             }
         :
         : 1228             /* Private */
         : 1229             static inline bool xa_is_node(const void *entry)
         : 1230             {
         : 1231             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd098:       cmp     x0, #0x1, lsl #12
         : 1233             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd09c:       and     x1, x0, #0x3
         : 171              xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd0a0:       ccmp    x1, #0x2, #0x0, hi  // hi = pmore
    0.00 :   ffff8000104bd0a4:       b.eq    ffff8000104bd0b4 <xas_load+0x34>  // b.none
         : 1229             xas_load():
         : 245              entry = xas_descend(xas, node);
         : 246              if (node->shift == 0)
         : 247              break;
         : 248              }
         : 249              return entry;
         : 250              }
    0.00 :   ffff8000104bd0a8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000104bd0ac:       autiasp
    0.00 :   ffff8000104bd0b0:       ret
         : 238              if (xas->xa_shift > node->shift)
    0.00 :   ffff8000104bd0b4:       ldurb   w3, [x0, #-2]
         : 240              xa_to_node():
         : 1220             return (struct xa_node *)((unsigned long)entry - 2);
    0.00 :   ffff8000104bd0b8:       sub     x2, x0, #0x2
         : 1222             xas_load():
   47.48 :   ffff8000104bd0bc:       ldrb    w1, [x4, #16]
    0.00 :   ffff8000104bd0c0:       cmp     w1, w3
    0.00 :   ffff8000104bd0c4:       b.hi    ffff8000104bd0a8 <xas_load+0x28>  // b.pmore
         : 241              get_offset():
         : 144              return (index >> node->shift) & XA_CHUNK_MASK;
    0.00 :   ffff8000104bd0c8:       ldr     x1, [x4, #8]
    0.00 :   ffff8000104bd0cc:       lsr     x1, x1, x3
    0.00 :   ffff8000104bd0d0:       and     w1, w1, #0x3f
         : 148              xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000104bd0d4:       ubfiz   x0, x1, #3, #6
    0.00 :   ffff8000104bd0d8:       add     x0, x0, #0x20
    0.00 :   ffff8000104bd0dc:       add     x0, x2, x0
    0.00 :   ffff8000104bd0e0:       ldr     x0, [x0, #8]
         : 1187             xas_descend():
         : 206              xas->xa_node = node;
    0.00 :   ffff8000104bd0e4:       str     x2, [x4, #24]
         : 208              xa_is_sibling():
         : 1249             *
         : 1250             * Return: %true if the entry is a sibling entry.
         : 1251             */
         : 1252             static inline bool xa_is_sibling(const void *entry)
         : 1253             {
         : 1254             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000104bd0e8:       cmp     x0, #0xfd
         : 1256             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd0ec:       and     x3, x0, #0x3
         : 171              xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000104bd0f0:       ccmp    x3, #0x2, #0x0, ls  // ls = plast
    0.00 :   ffff8000104bd0f4:       b.ne    ffff8000104bd110 <xas_load+0x90>  // b.any
         : 1252             xa_to_internal():
         : 157              return (unsigned long)entry >> 2;
    0.00 :   ffff8000104bd0f8:       lsr     x0, x0, #2
         : 159              xas_descend():
         : 208              offset = xa_to_sibling(entry);
    0.00 :   ffff8000104bd0fc:       mov     w1, w0
         : 210              xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000104bd100:       ubfiz   x0, x0, #3, #32
    0.00 :   ffff8000104bd104:       add     x0, x0, #0x20
    0.00 :   ffff8000104bd108:       add     x0, x2, x0
    0.00 :   ffff8000104bd10c:       ldr     x0, [x0, #8]
         : 1187             xas_descend():
         : 212              xas->xa_offset = offset;
    0.00 :   ffff8000104bd110:       strb    w1, [x4, #18]
         : 214              xas_load():
         : 241              if (node->shift == 0)
   52.52 :   ffff8000104bd114:       ldrb    w1, [x2]
    0.00 :   ffff8000104bd118:       cbnz    w1, ffff8000104bd098 <xas_load+0x18>
         : 245              }
    0.00 :   ffff8000104bd11c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000104bd120:       autiasp
    0.00 :   ffff8000104bd124:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101ce788 <page_remove_rmap>:
         : 6                page_remove_rmap():
         : 1347             * @compound:    uncharge the page as compound or small page
         : 1348             *
         : 1349             * The caller needs to hold the pte lock.
         : 1350             */
         : 1351             void page_remove_rmap(struct page *page, bool compound)
         : 1352             {
    0.00 :   ffff8000101ce788:       paciasp
    0.00 :   ffff8000101ce78c:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000101ce790:       mov     x29, sp
    0.00 :   ffff8000101ce794:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101ce798:       mov     x19, x0
    0.00 :   ffff8000101ce79c:       and     w20, w1, #0xff
         : 1348             lock_page_memcg(page);
    0.00 :   ffff8000101ce7a0:       bl      ffff80001021ca48 <lock_page_memcg>
         : 1350             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff8000101ce7a4:       ldr     x1, [x19, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff8000101ce7a8:       sub     x0, x1, #0x1
    0.00 :   ffff8000101ce7ac:       tst     x1, #0x1
    0.00 :   ffff8000101ce7b0:       csel    x0, x0, x19, ne  // ne = any
         : 193              PageAnon():
         : 484              */
         : 485              #define PAGE_MAPPING_ANON       0x1
         : 486              #define PAGE_MAPPING_MOVABLE    0x2
         : 487              #define PAGE_MAPPING_KSM        (PAGE_MAPPING_ANON | PAGE_MAPPING_MOVABLE)
         : 488              #define PAGE_MAPPING_FLAGS      (PAGE_MAPPING_ANON | PAGE_MAPPING_MOVABLE)
         :
    0.00 :   ffff8000101ce7b4:       ldr     x0, [x0, #24]
         : 491              page_remove_rmap():
         :
         : 1351             if (!PageAnon(page)) {
    0.00 :   ffff8000101ce7b8:       tbz     w0, #0, ffff8000101ce8fc <page_remove_rmap+0x174>
         : 1355             page_remove_file_rmap(page, compound);
         : 1356             goto out;
         : 1357             }
         :
         : 1359             if (compound) {
    0.00 :   ffff8000101ce7bc:       cbnz    w20, ffff8000101ce868 <page_remove_rmap+0xe0>
         : 1361             page_remove_anon_compound_rmap(page);
         : 1362             goto out;
         : 1363             }
         :
         : 1365             /* page still mapped by someone else? */
         : 1366             if (!atomic_add_negative(-1, &page->_mapcount))
    0.00 :   ffff8000101ce7c0:       add     x1, x19, #0x30
         : 1368             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101ce7c4:       b       ffff8000101ce7f4 <page_remove_rmap+0x6c>
    0.00 :   ffff8000101ce7c8:       b       ffff8000101ce7f4 <page_remove_rmap+0x6c>
         : 46               __lse_atomic_add_return():
         : 76               }
         :
         : 78               ATOMIC_OP_ADD_RETURN(_relaxed,   )
         : 79               ATOMIC_OP_ADD_RETURN(_acquire,  a, "memory")
         : 80               ATOMIC_OP_ADD_RETURN(_release,  l, "memory")
         : 81               ATOMIC_OP_ADD_RETURN(        , al, "memory")
    0.00 :   ffff8000101ce7cc:       mov     w0, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce7d0:       ldaddal w0, w2, [x1]
  100.00 :   ffff8000101ce7d4:       add     w0, w0, w2
         : 85               page_remove_rmap():
    0.00 :   ffff8000101ce7d8:       tbnz    w0, #31, ffff8000101ce804 <page_remove_rmap+0x7c>
         : 1387             * and remember that it's only reliable while mapped.
         : 1388             * Leaving it set also helps swapoff to reinstate ptes
         : 1389             * faster for those pages still in swapcache.
         : 1390             */
         : 1391             out:
         : 1392             unlock_page_memcg(page);
    0.00 :   ffff8000101ce7dc:       mov     x0, x19
    0.00 :   ffff8000101ce7e0:       bl      ffff80001021cb50 <unlock_page_memcg>
         : 1388             }
    0.00 :   ffff8000101ce7e4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101ce7e8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000101ce7ec:       autiasp
    0.00 :   ffff8000101ce7f0:       ret
         : 1393             __ll_sc_atomic_add_return():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff8000101ce7f4:       mov     w1, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce7f8:       add     x3, x19, #0x30
    0.00 :   ffff8000101ce7fc:       b       ffff8000101d0778 <hugepage_add_new_anon_rmap+0x160>
         : 120              page_remove_rmap():
         : 1361             if (!atomic_add_negative(-1, &page->_mapcount))
    0.00 :   ffff8000101ce800:       tbz     w0, #31, ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1363             __dec_lruvec_page_state():
         :
         : 531              #endif /* CONFIG_MEMCG */
         :
         : 533              static inline void inc_lruvec_state(struct lruvec *lruvec,
         : 534              enum node_stat_item idx)
         : 535              {
    0.00 :   ffff8000101ce804:       mov     w1, #0x11                       // #17
    0.00 :   ffff8000101ce808:       mov     x0, x19
    0.00 :   ffff8000101ce80c:       mov     w2, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce810:       bl      ffff800010222048 <__mod_lruvec_page_state>
         : 540              compound_head():
         : 184              {
    0.00 :   ffff8000101ce814:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101ce818:       sub     x0, x1, #0x1
    0.00 :   ffff8000101ce81c:       tst     x1, #0x1
    0.00 :   ffff8000101ce820:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101ce824:       ldr     x0, [x0]
         : 113              page_remove_rmap():
         : 1371             if (unlikely(PageMlocked(page)))
    0.00 :   ffff8000101ce828:       tst     w0, #0x200000
    0.00 :   ffff8000101ce82c:       b.ne    ffff8000101ceadc <page_remove_rmap+0x354>  // b.any
         : 1374             test_bit():
    0.00 :   ffff8000101ce830:       ldr     x0, [x19]
         : 107              PageCompound():
         :
    0.00 :   ffff8000101ce834:       tst     w0, #0x10000
    0.00 :   ffff8000101ce838:       b.eq    ffff8000101ce9c4 <page_remove_rmap+0x23c>  // b.none
         : 201              compound_head():
         : 184              {
    0.00 :   ffff8000101ce83c:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101ce840:       sub     x0, x1, #0x1
    0.00 :   ffff8000101ce844:       tst     x1, #0x1
         : 190              page_remove_rmap():
         : 1375             deferred_split_huge_page(compound_head(page));
    0.00 :   ffff8000101ce848:       csel    x0, x0, x19, ne  // ne = any
    0.00 :   ffff8000101ce84c:       bl      ffff800010216ca8 <deferred_split_huge_page>
         : 1387             unlock_page_memcg(page);
    0.00 :   ffff8000101ce850:       mov     x0, x19
    0.00 :   ffff8000101ce854:       bl      ffff80001021cb50 <unlock_page_memcg>
         : 1388             }
    0.00 :   ffff8000101ce858:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101ce85c:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000101ce860:       autiasp
    0.00 :   ffff8000101ce864:       ret
         : 1393             compound_mapcount_ptr():
         : 229              * WANT_PAGE_VIRTUAL in asm/page.h
         : 230              */
         : 231              #if defined(WANT_PAGE_VIRTUAL)
         : 232              void *virtual;                  /* Kernel virtual address (NULL if
         : 233              not kmapped, ie. highmem) */
         : 234              #endif /* WANT_PAGE_VIRTUAL */
    0.00 :   ffff8000101ce868:       add     x1, x19, #0x54
         : 236              arch_static_branch_jump():
    0.00 :   ffff8000101ce86c:       b       ffff8000101ce9b4 <page_remove_rmap+0x22c>
    0.00 :   ffff8000101ce870:       b       ffff8000101ce9b4 <page_remove_rmap+0x22c>
         : 40               __lse_atomic_add_return():
    0.00 :   ffff8000101ce874:       mov     w0, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce878:       ldaddal w0, w2, [x1]
    0.00 :   ffff8000101ce87c:       add     w0, w0, w2
         : 79               page_remove_anon_compound_rmap():
         : 1299             if (!atomic_add_negative(-1, compound_mapcount_ptr(page)))
    0.00 :   ffff8000101ce880:       tbz     w0, #31, ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1303             if (unlikely(PageHuge(page)))
    0.00 :   ffff8000101ce884:       mov     x0, x19
    0.00 :   ffff8000101ce888:       bl      ffff8000101ee070 <PageHuge>
    0.00 :   ffff8000101ce88c:       mov     w20, w0
    0.00 :   ffff8000101ce890:       cbnz    w0, ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1308             test_bit():
    0.00 :   ffff8000101ce894:       ldr     x3, [x19]
         : 107              page_remove_anon_compound_rmap():
         : 1309             __mod_lruvec_page_state(page, NR_ANON_THPS, -thp_nr_pages(page));
    0.00 :   ffff8000101ce898:       mov     x0, x19
         : 1311             thp_nr_pages():
         : 276              return 0;
         : 277              }
         :
         : 279              /**
         : 280              * thp_nr_pages - The number of regular pages in this huge page.
         : 281              * @page: The head page of a huge page.
    0.00 :   ffff8000101ce89c:       mov     w2, #0xfffffe00                 // #-512
         : 283              page_remove_anon_compound_rmap():
    0.00 :   ffff8000101ce8a0:       mov     w1, #0x1c                       // #28
         : 1310             thp_nr_pages():
    0.00 :   ffff8000101ce8a4:       tst     w3, #0x10000
         : 277              page_remove_anon_compound_rmap():
    0.00 :   ffff8000101ce8a8:       csinv   w2, w2, wzr, ne  // ne = any
    0.00 :   ffff8000101ce8ac:       bl      ffff800010222048 <__mod_lruvec_page_state>
         : 1311             test_and_clear_bit():
         : 51               {
         : 52               long old;
         : 53               unsigned long mask = BIT_MASK(nr);
         :
         : 55               p += BIT_WORD(nr);
         : 56               if (!(READ_ONCE(*p) & mask))
    0.00 :   ffff8000101ce8b0:       ldr     x0, [x19, #64]
    0.00 :   ffff8000101ce8b4:       tbnz    w0, #6, ffff8000101cea40 <page_remove_rmap+0x2b8>
         : 59               test_bit():
    0.00 :   ffff8000101ce8b8:       ldr     x0, [x19]
         : 107              thp_nr_pages():
         : 277              */
    0.00 :   ffff8000101ce8bc:       mov     w20, #0x200                     // #512
    0.00 :   ffff8000101ce8c0:       tst     w0, #0x10000
    0.00 :   ffff8000101ce8c4:       csinc   w20, w20, wzr, ne  // ne = any
         : 281              compound_head():
         : 184              {
    0.00 :   ffff8000101ce8c8:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101ce8cc:       sub     x0, x1, #0x1
    0.00 :   ffff8000101ce8d0:       tst     x1, #0x1
    0.00 :   ffff8000101ce8d4:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff8000101ce8d8:       ldr     x0, [x0]
         : 107              page_remove_anon_compound_rmap():
         : 1332             if (unlikely(PageMlocked(page)))
    0.00 :   ffff8000101ce8dc:       tst     w0, #0x200000
    0.00 :   ffff8000101ce8e0:       b.ne    ffff8000101ceb04 <page_remove_rmap+0x37c>  // b.any
         : 1335             if (nr)
    0.00 :   ffff8000101ce8e4:       cbz     w20, ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1336             __mod_lruvec_page_state(page, NR_ANON_MAPPED, -nr);
    0.00 :   ffff8000101ce8e8:       neg     w2, w20
    0.00 :   ffff8000101ce8ec:       mov     w1, #0x11                       // #17
    0.00 :   ffff8000101ce8f0:       mov     x0, x19
    0.00 :   ffff8000101ce8f4:       bl      ffff800010222048 <__mod_lruvec_page_state>
    0.00 :   ffff8000101ce8f8:       b       ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1342             page_remove_file_rmap():
         : 1257             if (unlikely(PageHuge(page))) {
    0.00 :   ffff8000101ce8fc:       mov     x0, x19
    0.00 :   ffff8000101ce900:       bl      ffff8000101ee070 <PageHuge>
    0.00 :   ffff8000101ce904:       cbnz    w0, ffff8000101ceae8 <page_remove_rmap+0x360>
         : 1264             if (compound && PageTransHuge(page)) {
    0.00 :   ffff8000101ce908:       cbz     w20, ffff8000101ce9d8 <page_remove_rmap+0x250>
         : 1266             test_bit():
    0.00 :   ffff8000101ce90c:       ldr     x4, [x19]
    0.00 :   ffff8000101ce910:       ubfx    w4, w4, #16, #1
         : 108              page_remove_file_rmap():
    0.00 :   ffff8000101ce914:       cbz     w4, ffff8000101ce9d8 <page_remove_rmap+0x250>
         : 1265             test_bit():
    0.00 :   ffff8000101ce918:       mov     x1, x19
         : 107              thp_nr_pages():
    0.00 :   ffff8000101ce91c:       mov     w5, #0x200                      // #512
    0.00 :   ffff8000101ce920:       add     x3, x19, #0x70
         : 279              __ll_sc_atomic_add_return():
    0.00 :   ffff8000101ce924:       mov     w2, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce928:       mov     w6, #0x40                       // #64
         : 113              test_bit():
    0.00 :   ffff8000101ce92c:       ldr     x7, [x1], #48
         : 107              thp_nr_pages():
    0.00 :   ffff8000101ce930:       tst     w7, #0x10000
    0.00 :   ffff8000101ce934:       csel    w4, w4, w5, eq  // eq = none
         : 279              page_remove_file_rmap():
         : 1267             for (i = 0, nr = 0; i < nr_pages; i++) {
    0.00 :   ffff8000101ce938:       add     w5, w4, w2
    0.00 :   ffff8000101ce93c:       umaddl  x5, w5, w6, x3
         : 1270             arch_static_branch_jump():
    0.00 :   ffff8000101ce940:       b       ffff8000101ce9d0 <page_remove_rmap+0x248>
    0.00 :   ffff8000101ce944:       b       ffff8000101ce9d0 <page_remove_rmap+0x248>
         : 40               __lse_atomic_add_return():
    0.00 :   ffff8000101ce948:       mov     w3, w2
    0.00 :   ffff8000101ce94c:       ldaddal w3, w6, [x1]
    0.00 :   ffff8000101ce950:       add     w3, w3, w6
    0.00 :   ffff8000101ce954:       add     x1, x1, #0x40
         : 80               page_remove_file_rmap():
         : 1269             nr++;
    0.00 :   ffff8000101ce958:       add     w0, w0, w3, lsr #31
         : 1267             for (i = 0, nr = 0; i < nr_pages; i++) {
    0.00 :   ffff8000101ce95c:       cmp     x5, x1
    0.00 :   ffff8000101ce960:       b.ne    ffff8000101ce940 <page_remove_rmap+0x1b8>  // b.any
         : 1270             compound_mapcount_ptr():
    0.00 :   ffff8000101ce964:       add     x2, x19, #0x54
         : 230              arch_static_branch_jump():
    0.00 :   ffff8000101ce968:       b       ffff8000101ceacc <page_remove_rmap+0x344>
    0.00 :   ffff8000101ce96c:       b       ffff8000101ceacc <page_remove_rmap+0x344>
         : 40               __lse_atomic_add_return():
    0.00 :   ffff8000101ce970:       mov     w1, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce974:       ldaddal w1, w3, [x2]
    0.00 :   ffff8000101ce978:       add     w1, w1, w3
         : 79               page_remove_file_rmap():
         : 1271             if (!atomic_add_negative(-1, compound_mapcount_ptr(page)))
    0.00 :   ffff8000101ce97c:       tbz     w1, #31, ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1273             compound_head():
         : 184              {
    0.00 :   ffff8000101ce980:       ldr     x1, [x19, #8]
         :
    0.00 :   ffff8000101ce984:       neg     w20, w0
    0.00 :   ffff8000101ce988:       neg     w2, w4
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101ce98c:       sub     x0, x1, #0x1
    0.00 :   ffff8000101ce990:       tst     x1, #0x1
    0.00 :   ffff8000101ce994:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff8000101ce998:       ldr     x0, [x0]
         : 107              page_remove_file_rmap():
         : 1273             if (PageSwapBacked(page))
    0.00 :   ffff8000101ce99c:       tst     w0, #0x80000
    0.00 :   ffff8000101ce9a0:       b.eq    ffff8000101ceb2c <page_remove_rmap+0x3a4>  // b.none
         : 1274             __mod_lruvec_page_state(page, NR_SHMEM_PMDMAPPED,
    0.00 :   ffff8000101ce9a4:       mov     w1, #0x19                       // #25
    0.00 :   ffff8000101ce9a8:       mov     x0, x19
    0.00 :   ffff8000101ce9ac:       bl      ffff800010222048 <__mod_lruvec_page_state>
    0.00 :   ffff8000101ce9b0:       b       ffff8000101ce9f8 <page_remove_rmap+0x270>
         : 1279             __ll_sc_atomic_add_return():
    0.00 :   ffff8000101ce9b4:       mov     w1, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce9b8:       add     x3, x19, #0x54
    0.00 :   ffff8000101ce9bc:       b       ffff8000101d0794 <hugepage_add_new_anon_rmap+0x17c>
    0.00 :   ffff8000101ce9c0:       b       ffff8000101ce880 <page_remove_rmap+0xf8>
         : 115              PageTail():
         :
    0.00 :   ffff8000101ce9c4:       ldr     x0, [x19, #8]
         : 195              PageCompound():
         :
    0.00 :   ffff8000101ce9c8:       tbz     w0, #0, ffff8000101ce7dc <page_remove_rmap+0x54>
    0.00 :   ffff8000101ce9cc:       b       ffff8000101ce83c <page_remove_rmap+0xb4>
         : 201              __ll_sc_atomic_add_return():
    0.00 :   ffff8000101ce9d0:       b       ffff8000101d07b0 <hugepage_add_new_anon_rmap+0x198>
    0.00 :   ffff8000101ce9d4:       b       ffff8000101ce954 <page_remove_rmap+0x1cc>
         : 113              page_remove_file_rmap():
         : 1280             if (!atomic_add_negative(-1, &page->_mapcount))
    0.00 :   ffff8000101ce9d8:       add     x1, x19, #0x30
         : 1282             arch_static_branch_jump():
    0.00 :   ffff8000101ce9dc:       b       ffff8000101cea30 <page_remove_rmap+0x2a8>
    0.00 :   ffff8000101ce9e0:       b       ffff8000101cea30 <page_remove_rmap+0x2a8>
         : 40               __lse_atomic_add_return():
    0.00 :   ffff8000101ce9e4:       mov     w0, #0xffffffff                 // #-1
    0.00 :   ffff8000101ce9e8:       ldaddal w0, w2, [x1]
    0.00 :   ffff8000101ce9ec:       add     w0, w0, w2
         : 79               page_remove_file_rmap():
    0.00 :   ffff8000101ce9f0:       tbz     w0, #31, ffff8000101ce7dc <page_remove_rmap+0x54>
    0.00 :   ffff8000101ce9f4:       mov     w20, #0xffffffff                // #-1
         : 1289             __mod_lruvec_page_state(page, NR_FILE_MAPPED, -nr);
    0.00 :   ffff8000101ce9f8:       mov     w1, #0x12                       // #18
    0.00 :   ffff8000101ce9fc:       mov     x0, x19
    0.00 :   ffff8000101cea00:       mov     w2, w20
    0.00 :   ffff8000101cea04:       bl      ffff800010222048 <__mod_lruvec_page_state>
         : 1294             compound_head():
         : 184              {
    0.00 :   ffff8000101cea08:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101cea0c:       sub     x0, x1, #0x1
    0.00 :   ffff8000101cea10:       tst     x1, #0x1
    0.00 :   ffff8000101cea14:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff8000101cea18:       ldr     x0, [x0]
         : 107              page_remove_file_rmap():
         : 1291             if (unlikely(PageMlocked(page)))
    0.00 :   ffff8000101cea1c:       tst     w0, #0x200000
    0.00 :   ffff8000101cea20:       b.eq    ffff8000101ce7dc <page_remove_rmap+0x54>  // b.none
         : 1292             clear_page_mlock(page);
    0.00 :   ffff8000101cea24:       mov     x0, x19
    0.00 :   ffff8000101cea28:       bl      ffff8000101c19f0 <clear_page_mlock>
    0.00 :   ffff8000101cea2c:       b       ffff8000101ce7dc <page_remove_rmap+0x54>
         : 1296             __ll_sc_atomic_add_return():
    0.00 :   ffff8000101cea30:       mov     w1, #0xffffffff                 // #-1
    0.00 :   ffff8000101cea34:       add     x3, x19, #0x30
    0.00 :   ffff8000101cea38:       b       ffff8000101d07cc <hugepage_add_new_anon_rmap+0x1b4>
    0.00 :   ffff8000101cea3c:       b       ffff8000101ce9f0 <page_remove_rmap+0x268>
         : 115              TestClearPageDoubleMap():
         : 687              /*
         : 688              * PageDoubleMap indicates that the compound page is mapped with PTEs as well
         : 689              * as PMDs.
         : 690              *
         : 691              * This is required for optimization of rmap operations for THP: we can postpone
         : 692              * per small page mapcount accounting (and its overhead from atomic operations)
    0.00 :   ffff8000101cea40:       add     x1, x19, #0x40
         : 694              arch_static_branch_jump():
    0.00 :   ffff8000101cea44:       b       ffff8000101ceb1c <page_remove_rmap+0x394>
    0.00 :   ffff8000101cea48:       b       ffff8000101ceb1c <page_remove_rmap+0x394>
         : 40               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OP(_relaxed,   , op, asm_op)                     \
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff8000101cea4c:       mov     x0, #0x40                       // #64
    0.00 :   ffff8000101cea50:       ldclral x0, x0, [x1]
         : 210              page_remove_anon_compound_rmap():
         : 1311             if (TestClearPageDoubleMap(page)) {
    0.00 :   ffff8000101cea54:       tbz     w0, #6, ffff8000101ce8b8 <page_remove_rmap+0x130>
    0.00 :   ffff8000101cea58:       add     x0, x19, #0x30
         : 1316             for (i = 0, nr = 0; i < thp_nr_pages(page); i++) {
    0.00 :   ffff8000101cea5c:       mov     w2, #0x0                        // #0
         : 1318             thp_nr_pages():
    0.00 :   ffff8000101cea60:       mov     w5, #0x1                        // #1
    0.00 :   ffff8000101cea64:       mov     w4, #0x200                      // #512
         : 279              __ll_sc_atomic_add_return():
    0.00 :   ffff8000101cea68:       mov     w3, #0xffffffff                 // #-1
    0.00 :   ffff8000101cea6c:       b       ffff8000101cea90 <page_remove_rmap+0x308>
         : 113              arch_static_branch_jump():
    0.00 :   ffff8000101cea70:       b       ffff8000101ceb14 <page_remove_rmap+0x38c>
    0.00 :   ffff8000101cea74:       b       ffff8000101ceb14 <page_remove_rmap+0x38c>
         : 40               __lse_atomic_add_return():
         : 76               ATOMIC_OP_ADD_RETURN(        , al, "memory")
    0.00 :   ffff8000101cea78:       mov     w1, w3
    0.00 :   ffff8000101cea7c:       ldaddal w1, w6, [x0]
    0.00 :   ffff8000101cea80:       add     w1, w1, w6
         : 80               page_remove_anon_compound_rmap():
    0.00 :   ffff8000101cea84:       add     w2, w2, #0x1
    0.00 :   ffff8000101cea88:       add     x0, x0, #0x40
         : 1318             nr++;
    0.00 :   ffff8000101cea8c:       add     w20, w20, w1, lsr #31
         : 1320             test_bit():
    0.00 :   ffff8000101cea90:       ldr     x1, [x19]
         : 107              thp_nr_pages():
    0.00 :   ffff8000101cea94:       tst     x1, #0x10000
    0.00 :   ffff8000101cea98:       csel    w1, w5, w4, eq  // eq = none
         : 279              page_remove_anon_compound_rmap():
         : 1316             for (i = 0, nr = 0; i < thp_nr_pages(page); i++) {
    0.00 :   ffff8000101cea9c:       cmp     w2, w1
    0.00 :   ffff8000101ceaa0:       b.lt    ffff8000101cea70 <page_remove_rmap+0x2e8>  // b.tstop
         : 1326             if (nr && nr < thp_nr_pages(page))
    0.00 :   ffff8000101ceaa4:       cbz     w20, ffff8000101ce8c8 <page_remove_rmap+0x140>
         : 1328             test_bit():
    0.00 :   ffff8000101ceaa8:       ldr     x1, [x19]
         : 107              thp_nr_pages():
    0.00 :   ffff8000101ceaac:       mov     w0, #0x200                      // #512
    0.00 :   ffff8000101ceab0:       tst     w1, #0x10000
    0.00 :   ffff8000101ceab4:       csinc   w0, w0, wzr, ne  // ne = any
         : 280              page_remove_anon_compound_rmap():
    0.00 :   ffff8000101ceab8:       cmp     w20, w0
    0.00 :   ffff8000101ceabc:       b.ge    ffff8000101ce8c8 <page_remove_rmap+0x140>  // b.tcont
         : 1327             deferred_split_huge_page(page);
    0.00 :   ffff8000101ceac0:       mov     x0, x19
    0.00 :   ffff8000101ceac4:       bl      ffff800010216ca8 <deferred_split_huge_page>
    0.00 :   ffff8000101ceac8:       b       ffff8000101ce8c8 <page_remove_rmap+0x140>
         : 1331             __ll_sc_atomic_add_return():
    0.00 :   ffff8000101ceacc:       mov     w2, #0xffffffff                 // #-1
    0.00 :   ffff8000101cead0:       add     x5, x19, #0x54
    0.00 :   ffff8000101cead4:       b       ffff8000101d07e8 <hugepage_add_new_anon_rmap+0x1d0>
    0.00 :   ffff8000101cead8:       b       ffff8000101ce97c <page_remove_rmap+0x1f4>
         : 115              page_remove_rmap():
         : 1372             clear_page_mlock(page);
    0.00 :   ffff8000101ceadc:       mov     x0, x19
    0.00 :   ffff8000101ceae0:       bl      ffff8000101c19f0 <clear_page_mlock>
    0.00 :   ffff8000101ceae4:       b       ffff8000101ce830 <page_remove_rmap+0xa8>
         : 1376             compound_mapcount_ptr():
    0.00 :   ffff8000101ceae8:       add     x1, x19, #0x54
         : 230              arch_static_branch_jump():
    0.00 :   ffff8000101ceaec:       b       ffff8000101ceb3c <page_remove_rmap+0x3b4>
    0.00 :   ffff8000101ceaf0:       b       ffff8000101ceb3c <page_remove_rmap+0x3b4>
         : 40               __lse_atomic_sub():
         : 113              asm volatile(
    0.00 :   ffff8000101ceaf4:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000101ceaf8:       neg     w0, w0
    0.00 :   ffff8000101ceafc:       stadd   w0, [x1]
    0.00 :   ffff8000101ceb00:       b       ffff8000101ce7dc <page_remove_rmap+0x54>
         : 118              page_remove_anon_compound_rmap():
         : 1333             clear_page_mlock(page);
    0.00 :   ffff8000101ceb04:       mov     x0, x19
    0.00 :   ffff8000101ceb08:       bl      ffff8000101c19f0 <clear_page_mlock>
         : 1335             if (nr)
    0.00 :   ffff8000101ceb0c:       cbz     w20, ffff8000101ce7dc <page_remove_rmap+0x54>
    0.00 :   ffff8000101ceb10:       b       ffff8000101ce8e8 <page_remove_rmap+0x160>
         : 1338             __ll_sc_atomic_add_return():
    0.00 :   ffff8000101ceb14:       b       ffff8000101d0804 <hugepage_add_new_anon_rmap+0x1ec>
    0.00 :   ffff8000101ceb18:       b       ffff8000101cea84 <page_remove_rmap+0x2fc>
         : 113              __ll_sc_atomic64_fetch_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff8000101ceb1c:       mov     x1, #0x40                       // #64
    0.00 :   ffff8000101ceb20:       add     x4, x19, x1
    0.00 :   ffff8000101ceb24:       b       ffff8000101d0820 <hugepage_add_new_anon_rmap+0x208>
    0.00 :   ffff8000101ceb28:       b       ffff8000101cea54 <page_remove_rmap+0x2cc>
         : 239              page_remove_file_rmap():
         : 1277             __mod_lruvec_page_state(page, NR_FILE_PMDMAPPED,
    0.00 :   ffff8000101ceb2c:       mov     w1, #0x1b                       // #27
    0.00 :   ffff8000101ceb30:       mov     x0, x19
    0.00 :   ffff8000101ceb34:       bl      ffff800010222048 <__mod_lruvec_page_state>
    0.00 :   ffff8000101ceb38:       b       ffff8000101ce9f8 <page_remove_rmap+0x270>
         : 1282             __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000101ceb3c:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000101ceb40:       add     x3, x19, #0x54
    0.00 :   ffff8000101ceb44:       b       ffff8000101d083c <hugepage_add_new_anon_rmap+0x224>
    0.00 :   ffff8000101ceb48:       b       ffff8000101ce7dc <page_remove_rmap+0x54>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010180a00 <add_to_page_cache_lru>:
         : 6                add_to_page_cache_lru():
         : 962              }
         : 963              EXPORT_SYMBOL(add_to_page_cache_locked);
         :
         : 965              int add_to_page_cache_lru(struct page *page, struct address_space *mapping,
         : 966              pgoff_t offset, gfp_t gfp_mask)
         : 967              {
    0.00 :   ffff800010180a00:       paciasp
    0.00 :   ffff800010180a04:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010180a08:       mov     x29, sp
    0.00 :   ffff800010180a0c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010180a10:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010180a14:       add     x20, x20, #0x948
    0.00 :   ffff800010180a18:       ldr     x4, [x20]
    0.00 :   ffff800010180a1c:       str     x4, [sp, #56]
    0.00 :   ffff800010180a20:       mov     x4, #0x0                        // #0
    0.00 :   ffff800010180a24:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010180a28:       mov     x19, x0
         : 963              void *shadow = NULL;
    0.00 :   ffff800010180a2c:       str     xzr, [sp, #48]
         : 962              {
    0.00 :   ffff800010180a30:       mov     w22, w3
         : 964              compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010180a34:       ldr     x6, [x0, #8]
         : 191              add_to_page_cache_lru():
         : 967              int ret;
         :
         : 969              __SetPageLocked(page);
         : 970              ret = __add_to_page_cache_locked(page, mapping, offset,
    0.00 :   ffff800010180a38:       add     x4, sp, #0x30
         : 972              compound_head():
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010180a3c:       sub     x5, x6, #0x1
    0.00 :   ffff800010180a40:       tst     x6, #0x1
    0.00 :   ffff800010180a44:       csel    x5, x5, x0, ne  // ne = any
         : 193              __set_bit():
         : 21               static inline void __set_bit(int nr, volatile unsigned long *addr)
         : 22               {
         : 23               unsigned long mask = BIT_MASK(nr);
         : 24               unsigned long *p = ((unsigned long *)addr) + BIT_WORD(nr);
         :
         : 26               *p  |= mask;
    0.00 :   ffff800010180a48:       ldr     x6, [x5]
    0.00 :   ffff800010180a4c:       orr     x6, x6, #0x1
   56.61 :   ffff800010180a50:       str     x6, [x5]
         : 30               add_to_page_cache_lru():
    0.00 :   ffff800010180a54:       bl      ffff8000101806f0 <__add_to_page_cache_locked>
    0.00 :   ffff800010180a58:       mov     w21, w0
         : 969              gfp_mask, &shadow);
         : 970              if (unlikely(ret))
    0.00 :   ffff800010180a5c:       cbnz    w0, ffff800010180ad0 <add_to_page_cache_lru+0xd0>
         : 972              compound_head():
         : 184              {
    0.00 :   ffff800010180a60:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010180a64:       sub     x0, x1, #0x1
    0.00 :   ffff800010180a68:       tst     x1, #0x1
    0.00 :   ffff800010180a6c:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010180a70:       ldr     x0, [x0]
         : 113              add_to_page_cache_lru():
         : 980              * any other repeatedly accessed page.
         : 981              * The exception is pages getting rewritten; evicting other
         : 982              * data from the working set, only to cache data that will
         : 983              * get overwritten with something else, is a waste of memory.
         : 984              */
         : 985              WARN_ON_ONCE(PageActive(page));
    0.00 :   ffff800010180a74:       tst     w0, #0x20
    0.00 :   ffff800010180a78:       b.ne    ffff800010180ac4 <add_to_page_cache_lru+0xc4>  // b.any
         : 981              if (!(gfp_mask & __GFP_WRITE) && shadow)
   43.39 :   ffff800010180a7c:       tbz     w22, #12, ffff800010180ab0 <add_to_page_cache_lru+0xb0>
         : 983              workingset_refault(page, shadow);
         : 984              lru_cache_add(page);
    0.00 :   ffff800010180a80:       mov     x0, x19
    0.00 :   ffff800010180a84:       bl      ffff800010190568 <lru_cache_add>
         : 986              }
         : 987              return ret;
         : 988              }
    0.00 :   ffff800010180a88:       mov     w0, w21
    0.00 :   ffff800010180a8c:       ldr     x2, [sp, #56]
    0.00 :   ffff800010180a90:       ldr     x1, [x20]
    0.00 :   ffff800010180a94:       eor     x1, x2, x1
    0.00 :   ffff800010180a98:       cbnz    x1, ffff800010180af0 <add_to_page_cache_lru+0xf0>
    0.00 :   ffff800010180a9c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010180aa0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010180aa4:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010180aa8:       autiasp
    0.00 :   ffff800010180aac:       ret
         : 981              if (!(gfp_mask & __GFP_WRITE) && shadow)
    0.00 :   ffff800010180ab0:       ldr     x1, [sp, #48]
    0.00 :   ffff800010180ab4:       cbz     x1, ffff800010180a80 <add_to_page_cache_lru+0x80>
         : 982              workingset_refault(page, shadow);
    0.00 :   ffff800010180ab8:       mov     x0, x19
    0.00 :   ffff800010180abc:       bl      ffff8000101b3a18 <workingset_refault>
    0.00 :   ffff800010180ac0:       b       ffff800010180a80 <add_to_page_cache_lru+0x80>
         : 980              WARN_ON_ONCE(PageActive(page));
    0.00 :   ffff800010180ac4:       brk     #0x800
         : 981              if (!(gfp_mask & __GFP_WRITE) && shadow)
    0.00 :   ffff800010180ac8:       tbnz    w22, #12, ffff800010180a80 <add_to_page_cache_lru+0x80>
    0.00 :   ffff800010180acc:       b       ffff800010180ab0 <add_to_page_cache_lru+0xb0>
         : 984              compound_head():
         : 184              {
    0.00 :   ffff800010180ad0:       ldr     x0, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010180ad4:       sub     x1, x0, #0x1
    0.00 :   ffff800010180ad8:       tst     x0, #0x1
    0.00 :   ffff800010180adc:       csel    x19, x1, x19, ne  // ne = any
         : 191              __clear_bit():
         : 29               *p &= ~mask;
    0.00 :   ffff800010180ae0:       ldr     x0, [x19]
    0.00 :   ffff800010180ae4:       and     x0, x0, #0xfffffffffffffffe
    0.00 :   ffff800010180ae8:       str     x0, [x19]
    0.00 :   ffff800010180aec:       b       ffff800010180a88 <add_to_page_cache_lru+0x88>
         : 34               add_to_page_cache_lru():
         : 986              }
    0.00 :   ffff800010180af0:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (5 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e2b620 <__cpu_do_idle_irqprio>:
         : 6                __cpu_do_idle_irqprio():
         : 84               cpu_die();
         : 85               }
         : 86               #endif
         :
         : 88               /*
         : 89               * Called by kexec, immediately prior to machine_kexec().
    0.00 :   ffff800010e2b620:       paciasp
    0.00 :   ffff800010e2b624:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e2b628:       mov     x29, sp
         : 88               *
         : 89               * This must completely disable all secondary CPUs; simply causing those CPUs
         : 90               * to execute e.g. a RAM-based pin loop is not sufficient. This allows the
         : 91               * kexec'd kernel to use any and all RAM as it sees fit, without having to
    0.00 :   ffff800010e2b62c:       mrs     x1, daif
         : 89               * avoid any code or data used by any SW CPU pin loop. The CPU hotplug
    0.00 :   ffff800010e2b630:       orr     x0, x1, #0xc0
    0.00 :   ffff800010e2b634:       msr     daif, x0
         : 92               gic_read_pmr():
         : 109              write_sysreg_s(val, SYS_ICC_BPR1_EL1);
         : 110              }
         :
         : 112              static inline u32 gic_read_pmr(void)
         : 113              {
         : 114              return read_sysreg_s(SYS_ICC_PMR_EL1);
    0.00 :   ffff800010e2b638:       mrs     x0, s3_0_c4_c6_0
         : 116              gic_write_pmr():
         : 114              }
         :
         : 116              static __always_inline void gic_write_pmr(u32 val)
         : 117              {
         : 118              write_sysreg_s(val, SYS_ICC_PMR_EL1);
    0.00 :   ffff800010e2b63c:       mov     x2, #0xf0                       // #240
    0.00 :   ffff800010e2b640:       msr     s3_0_c4_c6_0, x2
         : 121              __cpu_do_idle_irqprio():
         : 98               {
         : 99               smp_shutdown_nonboot_cpus(reboot_cpu);
         : 100              }
         :
         : 102              /*
         : 103              * Halting simply requires that the secondary CPUs stop performing any
    0.00 :   ffff800010e2b644:       bl      ffff800010e2b608 <__cpu_do_idle>
         : 105              gic_write_pmr():
    0.00 :   ffff800010e2b648:       and     x0, x0, #0xffffffff
    0.00 :   ffff800010e2b64c:       msr     s3_0_c4_c6_0, x0
         : 116              __cpu_do_idle_irqprio():
         : 101              * activity (executing tasks, handling interrupts). smp_send_stop()
         : 102              * achieves this.
         : 103              */
    0.00 :   ffff800010e2b650:       msr     daif, x1
         : 102              void machine_halt(void)
  100.00 :   ffff800010e2b654:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e2b658:       autiasp
    0.00 :   ffff800010e2b65c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010220470 <__count_memcg_events.part.88>:
         : 6                __count_memcg_events():
         : 791              */
         : 792              static inline void mod_objcg_mlstate(struct obj_cgroup *objcg,
         : 793              struct pglist_data *pgdat,
         : 794              enum node_stat_item idx, int nr)
         : 795              {
         : 796              struct mem_cgroup *memcg;
    0.00 :   ffff800010220470:       paciasp
    0.00 :   ffff800010220474:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010220478:       mov     x29, sp
         : 797              struct lruvec *lruvec;
         :
         : 799              rcu_read_lock();
         : 800              memcg = obj_cgroup_memcg(objcg);
         : 801              lruvec = mem_cgroup_lruvec(memcg, pgdat);
         : 802              mod_memcg_lruvec_state(lruvec, idx, nr);
    0.00 :   ffff80001022047c:       ldr     x3, [x0, #3600]
    0.00 :   ffff800010220480:       ubfiz   x1, x1, #3, #32
         : 798              rcu_read_unlock();
    0.00 :   ffff800010220484:       adrp    x4, ffff80001176d000 <cpu_number>
         : 797              mod_memcg_lruvec_state(lruvec, idx, nr);
    0.00 :   ffff800010220488:       add     x1, x1, #0x150
         : 799              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001022048c:       mrs     x5, tpidr_el1
         : 46               __count_memcg_events():
    0.00 :   ffff800010220490:       add     x1, x3, x1
         : 798              rcu_read_unlock();
    0.00 :   ffff800010220494:       add     x3, x4, #0x0
         : 797              mod_memcg_lruvec_state(lruvec, idx, nr);
    0.00 :   ffff800010220498:       ldr     x4, [x1, x5]
    0.00 :   ffff80001022049c:       add     x4, x4, x2
  100.00 :   ffff8000102204a0:       str     x4, [x1, x5]
         : 801              __kern_my_cpu_offset():
    0.00 :   ffff8000102204a4:       mrs     x1, tpidr_el1
         : 40               __count_memcg_events():
         : 798              rcu_read_unlock();
    0.00 :   ffff8000102204a8:       ldr     w1, [x3, x1]
    0.00 :   ffff8000102204ac:       ldr     x0, [x0]
    0.00 :   ffff8000102204b0:       bl      ffff80001013ecd8 <cgroup_rstat_updated>
         : 799              }
    0.00 :   ffff8000102204b4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000102204b8:       autiasp
    0.00 :   ffff8000102204bc:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001024cfd0 <__pollwait>:
         : 6                __pollwait():
         : 223              }
         :
         : 225              /* Add a new entry */
         : 226              static void __pollwait(struct file *filp, wait_queue_head_t *wait_address,
         : 227              poll_table *p)
         : 228              {
  100.00 :   ffff80001024cfd0:       paciasp
    0.00 :   ffff80001024cfd4:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff80001024cfd8:       mov     x29, sp
    0.00 :   ffff80001024cfdc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001024cfe0:       mov     x20, x0
    0.00 :   ffff80001024cfe4:       mov     x19, x2
    0.00 :   ffff80001024cfe8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001024cfec:       mov     x22, x1
         : 237              poll_get_entry():
         : 164              if (p->inline_index < N_INLINE_POLL_ENTRIES)
    0.00 :   ffff80001024cff0:       ldr     w0, [x2, #40]
    0.00 :   ffff80001024cff4:       cmp     w0, #0x8
    0.00 :   ffff80001024cff8:       b.ls    ffff80001024d0ac <__pollwait+0xdc>  // b.plast
         : 162              struct poll_table_page *table = p->table;
    0.00 :   ffff80001024cffc:       ldr     x21, [x2, #16]
         : 167              if (!table || POLL_TABLE_FULL(table)) {
    0.00 :   ffff80001024d000:       cbz     x21, ffff80001024d018 <__pollwait+0x48>
    0.00 :   ffff80001024d004:       ldr     x3, [x21, #8]
    0.00 :   ffff80001024d008:       add     x0, x21, #0x1, lsl #12
    0.00 :   ffff80001024d00c:       add     x1, x3, #0x40
    0.00 :   ffff80001024d010:       cmp     x1, x0
    0.00 :   ffff80001024d014:       b.ls    ffff80001024d040 <__pollwait+0x70>  // b.plast
         : 170              new_table = (struct poll_table_page *) __get_free_page(GFP_KERNEL);
    0.00 :   ffff80001024d018:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001024d01c:       mov     w0, #0xcc0                      // #3264
    0.00 :   ffff80001024d020:       bl      ffff8000101d71f8 <__get_free_pages>
         : 171              if (!new_table) {
    0.00 :   ffff80001024d024:       cbz     x0, ffff80001024d0c4 <__pollwait+0xf4>
         : 175              new_table->entry = new_table->entries;
    0.00 :   ffff80001024d028:       add     x1, x0, #0x10
    0.00 :   ffff80001024d02c:       stp     x21, x1, [x0]
         : 177              p->table = new_table;
    0.00 :   ffff80001024d030:       mov     x21, x0
    0.00 :   ffff80001024d034:       str     x0, [x19, #16]
         : 178              table = new_table;
    0.00 :   ffff80001024d038:       ldr     x3, [x0, #8]
    0.00 :   ffff80001024d03c:       add     x1, x3, #0x40
         : 181              return table->entry++;
    0.00 :   ffff80001024d040:       str     x1, [x21, #8]
         : 183              __pollwait():
         : 226              struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt);
         : 227              struct poll_table_entry *entry = poll_get_entry(pwq);
         : 228              if (!entry)
    0.00 :   ffff80001024d044:       cbz     x3, ffff80001024d098 <__pollwait+0xc8>
         : 230              get_file():
         : 970              unsigned char f_handle[];
         : 971              };
         :
         : 973              static inline struct file *get_file(struct file *f)
         : 974              {
         : 975              atomic_long_inc(&f->f_count);
    0.00 :   ffff80001024d048:       add     x1, x20, #0x38
         : 977              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001024d04c:       b       ffff80001024d060 <__pollwait+0x90>
    0.00 :   ffff80001024d050:       b       ffff80001024d060 <__pollwait+0x90>
         : 46               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff80001024d054:       mov     x0, #0x1                        // #1
    0.00 :   ffff80001024d058:       stadd   x0, [x1]
    0.00 :   ffff80001024d05c:       b       ffff80001024d068 <__pollwait+0x98>
         : 188              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff80001024d060:       add     x2, x20, #0x38
    0.00 :   ffff80001024d064:       b       ffff80001024f610 <__arm64_compat_sys_ppoll_time64+0xe8>
         : 218              __pollwait():
         : 228              return;
         : 229              entry->filp = get_file(filp);
    0.00 :   ffff80001024d068:       str     x20, [x3]
         : 231              init_waitqueue_func_entry():
         : 92               }
         :
         : 94               static inline void
         : 95               init_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func)
         : 96               {
         : 97               wq_entry->flags         = 0;
    0.00 :   ffff80001024d06c:       add     x4, x3, #0x10
         : 99               __pollwait():
         : 229              entry->wait_address = wait_address;
    0.00 :   ffff80001024d070:       str     x22, [x3, #56]
         : 231              init_waitqueue_func_entry():
         : 94               wq_entry->private       = NULL;
         : 95               wq_entry->func          = func;
    0.00 :   ffff80001024d074:       adrp    x2, ffff80001024c000 <compat_filldir+0x2a0>
    0.00 :   ffff80001024d078:       add     x2, x2, #0xee0
         : 98               __pollwait():
         : 233              entry->key = p->_key;
         : 234              init_waitqueue_func_entry(&entry->wait, pollwake);
         : 235              entry->wait.private = pwq;
         : 236              add_wait_queue(wait_address, &entry->wait);
    0.00 :   ffff80001024d07c:       mov     x0, x22
         : 230              entry->key = p->_key;
    0.00 :   ffff80001024d080:       ldr     w5, [x19, #8]
         : 233              add_wait_queue(wait_address, &entry->wait);
    0.00 :   ffff80001024d084:       mov     x1, x4
         : 230              entry->key = p->_key;
    0.00 :   ffff80001024d088:       str     w5, [x3, #8]
         : 232              init_waitqueue_func_entry():
         : 92               wq_entry->flags         = 0;
    0.00 :   ffff80001024d08c:       str     wzr, [x3, #16]
         : 94               wq_entry->func          = func;
    0.00 :   ffff80001024d090:       stp     x19, x2, [x3, #24]
         : 96               __pollwait():
         : 233              add_wait_queue(wait_address, &entry->wait);
    0.00 :   ffff80001024d094:       bl      ffff8000100cf658 <add_wait_queue>
         : 234              }
    0.00 :   ffff80001024d098:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001024d09c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001024d0a0:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001024d0a4:       autiasp
    0.00 :   ffff80001024d0a8:       ret
         : 240              poll_get_entry():
         : 165              return p->inline_entries + p->inline_index++;
    0.00 :   ffff80001024d0ac:       sbfiz   x1, x0, #6, #32
    0.00 :   ffff80001024d0b0:       add     x3, x2, #0x30
    0.00 :   ffff80001024d0b4:       add     w0, w0, #0x1
    0.00 :   ffff80001024d0b8:       add     x3, x3, x1
    0.00 :   ffff80001024d0bc:       str     w0, [x2, #40]
    0.00 :   ffff80001024d0c0:       b       ffff80001024d044 <__pollwait+0x74>
         : 172              p->error = -ENOMEM;
    0.00 :   ffff80001024d0c4:       mov     w0, #0xfffffff4                 // #-12
    0.00 :   ffff80001024d0c8:       str     w0, [x19, #36]
         : 175              __pollwait():
         : 226              if (!entry)
    0.00 :   ffff80001024d0cc:       b       ffff80001024d098 <__pollwait+0xc8>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102557e0 <timestamp_truncate>:
         : 6                timestamp_truncate():
         : 2278             * Truncate a timespec to the granularity supported by the fs
         : 2279             * containing the inode. Always rounds down. gran must
         : 2280             * not be 0 nor greater than a second (NSEC_PER_SEC, or 10^9 ns).
         : 2281             */
         : 2282             struct timespec64 timestamp_truncate(struct timespec64 t, struct inode *inode)
         : 2283             {
  100.00 :   ffff8000102557e0:       paciasp
    0.00 :   ffff8000102557e4:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000102557e8:       mov     x29, sp
    0.00 :   ffff8000102557ec:       stp     x19, x20, [sp, #16]
         : 2279             struct super_block *sb = inode->i_sb;
    0.00 :   ffff8000102557f0:       ldr     x2, [x2, #40]
         : 2282             unsigned int gran = sb->s_time_gran;
         :
         : 2284             t.tv_sec = clamp(t.tv_sec, sb->s_time_min, sb->s_time_max);
    0.00 :   ffff8000102557f4:       ldr     x4, [x2, #896]
    0.00 :   ffff8000102557f8:       ldr     x3, [x2, #904]
    0.00 :   ffff8000102557fc:       cmp     x4, x0
    0.00 :   ffff800010255800:       csel    x0, x4, x0, gt
         : 2280             unsigned int gran = sb->s_time_gran;
    0.00 :   ffff800010255804:       ldr     w2, [x2, #888]
         : 2282             t.tv_sec = clamp(t.tv_sec, sb->s_time_min, sb->s_time_max);
    0.00 :   ffff800010255808:       cmp     x0, x3
    0.00 :   ffff80001025580c:       csel    x20, x0, x3, le
         : 2283             if (unlikely(t.tv_sec == sb->s_time_max || t.tv_sec == sb->s_time_min))
    0.00 :   ffff800010255810:       cmp     x4, x20
         : 2284             t.tv_nsec = 0;
    0.00 :   ffff800010255814:       ccmp    x0, x3, #0x0, ne  // ne = any
    0.00 :   ffff800010255818:       csel    x19, x1, xzr, lt  // lt = tstop
         :
         : 2288             /* Avoid division in the common cases 1 ns and 1 s. */
         : 2289             if (gran == 1)
    0.00 :   ffff80001025581c:       cmp     w2, #0x1
    0.00 :   ffff800010255820:       b.eq    ffff800010255858 <timestamp_truncate+0x78>  // b.none
         : 2289             ; /* nothing */
         : 2290             else if (gran == NSEC_PER_SEC)
    0.00 :   ffff800010255824:       mov     w0, #0xca00                     // #51712
    0.00 :   ffff800010255828:       movk    w0, #0x3b9a, lsl #16
    0.00 :   ffff80001025582c:       cmp     w2, w0
    0.00 :   ffff800010255830:       b.eq    ffff800010255870 <timestamp_truncate+0x90>  // b.none
         : 2291             t.tv_nsec = 0;
         : 2292             else if (gran > 1 && gran < NSEC_PER_SEC)
    0.00 :   ffff800010255834:       sub     w1, w2, #0x2
    0.00 :   ffff800010255838:       mov     w0, #0xc9fd                     // #51709
    0.00 :   ffff80001025583c:       movk    w0, #0x3b9a, lsl #16
    0.00 :   ffff800010255840:       cmp     w1, w0
    0.00 :   ffff800010255844:       b.hi    ffff80001025588c <timestamp_truncate+0xac>  // b.pmore
         : 2292             t.tv_nsec -= t.tv_nsec % gran;
    0.00 :   ffff800010255848:       mov     w2, w2
    0.00 :   ffff80001025584c:       sdiv    x0, x19, x2
    0.00 :   ffff800010255850:       msub    x2, x0, x2, x19
    0.00 :   ffff800010255854:       sub     x19, x19, x2
         : 2296             else
         : 2297             WARN(1, "invalid file time granularity: %u", gran);
         : 2298             return t;
         : 2299             }
    0.00 :   ffff800010255858:       mov     x0, x20
    0.00 :   ffff80001025585c:       mov     x1, x19
    0.00 :   ffff800010255860:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010255864:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010255868:       autiasp
    0.00 :   ffff80001025586c:       ret
         : 2290             t.tv_nsec = 0;
    0.00 :   ffff800010255870:       mov     x19, #0x0                       // #0
         : 2296             }
    0.00 :   ffff800010255874:       mov     x0, x20
    0.00 :   ffff800010255878:       mov     x1, x19
    0.00 :   ffff80001025587c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010255880:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010255884:       autiasp
    0.00 :   ffff800010255888:       ret
         : 2294             WARN(1, "invalid file time granularity: %u", gran);
    0.00 :   ffff80001025588c:       mov     w1, w2
    0.00 :   ffff800010255890:       adrp    x0, ffff80001142c000 <kallsyms_token_index+0x217a0>
    0.00 :   ffff800010255894:       add     x0, x0, #0xd78
    0.00 :   ffff800010255898:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff80001025589c:       brk     #0x800
         : 2296             }
    0.00 :   ffff8000102558a0:       mov     x0, x20
    0.00 :   ffff8000102558a4:       mov     x1, x19
    0.00 :   ffff8000102558a8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102558ac:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000102558b0:       autiasp
    0.00 :   ffff8000102558b4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010100360 <rcu_idle_exit>:
         : 6                rcu_idle_exit():
         : 941              * in a timely manner, the RCU grace-period kthread sets that CPU's
         : 942              * ->rcu_urgent_qs flag with the expectation that the next interrupt or
         : 943              * exception will invoke this function, which will turn on the scheduler
         : 944              * tick, which will enable RCU to detect that CPU's quiescent states,
         : 945              * for example, due to cond_resched() calls in CONFIG_PREEMPT=n kernels.
         : 946              * The tick will be disabled once a quiescent state is reported for
    0.00 :   ffff800010100360:       paciasp
    0.00 :   ffff800010100364:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010100368:       mov     x29, sp
         : 950              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff80001010036c:       mrs     x6, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010100370:       and     w0, w6, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff800010100374:       cbz     w0, ffff8000101003a0 <rcu_idle_exit+0x40>
         : 118              rcu_idle_exit():
         : 945              * this CPU.
         : 946              *
         : 947              * Of course, in carefully tuned systems, there might never be an
         : 948              * interrupt or exception.  In that case, the RCU grace-period kthread
    0.00 :   ffff800010100378:       bl      ffff800010e2bad0 <rcu_eqs_exit.isra.77>
         : 950              arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff80001010037c:       msr     daif, x6
         : 129              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010100380:       nop
         : 28               rcu_idle_exit():
         : 947              * will eventually cause one to happen.  However, in less carefully
         : 948              * controlled environments, this function allows RCU to get what it
    0.00 :   ffff800010100384:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010100388:       autiasp
    0.00 :   ffff80001010038c:       ret
         : 952              arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff800010100390:       dsb     sy
         : 137              rcu_idle_exit():
  100.00 :   ffff800010100394:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010100398:       autiasp
    0.00 :   ffff80001010039c:       ret
         : 950              arch_static_branch():
    0.00 :   ffff8000101003a0:       nop
    0.00 :   ffff8000101003a4:       mov     x0, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101003a8:       msr     daifset, #0x3
    0.00 :   ffff8000101003ac:       b       ffff800010100378 <rcu_idle_exit+0x18>
         : 57               arch_static_branch():
    0.00 :   ffff8000101003b0:       mov     x0, #0xa0                       // #160
    0.00 :   ffff8000101003b4:       b       ffff8000101003a8 <rcu_idle_exit+0x48>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101816f8 <grab_cache_page_write_begin>:
         : 6                grab_cache_page_write_begin():
         : 3603             * Find or create a page at the given pagecache position. Return the locked
         : 3604             * page. This function is specifically for buffered writes.
         : 3605             */
         : 3606             struct page *grab_cache_page_write_begin(struct address_space *mapping,
         : 3607             pgoff_t index, unsigned flags)
         : 3608             {
  100.00 :   ffff8000101816f8:       paciasp
    0.00 :   ffff8000101816fc:       stp     x29, x30, [sp, #-32]!
         : 3608             struct page *page;
         : 3609             int fgp_flags = FGP_LOCK|FGP_WRITE|FGP_CREAT;
         :
         : 3611             if (flags & AOP_FLAG_NOFS)
         : 3612             fgp_flags |= FGP_NOFS;
    0.00 :   ffff800010181700:       tst     w2, #0x2
         : 3603             {
    0.00 :   ffff800010181704:       mov     x29, sp
    0.00 :   ffff800010181708:       str     x19, [sp, #16]
         : 3608             fgp_flags |= FGP_NOFS;
    0.00 :   ffff80001018170c:       mov     w4, #0xe                        // #14
    0.00 :   ffff800010181710:       mov     w2, #0x1e                       // #30
         :
         : 3611             page = pagecache_get_page(mapping, index, fgp_flags,
    0.00 :   ffff800010181714:       csel    w2, w4, w2, eq  // eq = none
    0.00 :   ffff800010181718:       ldr     w3, [x0, #24]
    0.00 :   ffff80001018171c:       bl      ffff800010180af8 <pagecache_get_page>
    0.00 :   ffff800010181720:       mov     x19, x0
         : 3612             mapping_gfp_mask(mapping));
         : 3613             if (page)
    0.00 :   ffff800010181724:       cbz     x0, ffff80001018172c <grab_cache_page_write_begin+0x34>
         : 3613             wait_for_stable_page(page);
    0.00 :   ffff800010181728:       bl      ffff8000101886d8 <wait_for_stable_page>
         :
         : 3617             return page;
         : 3618             }
    0.00 :   ffff80001018172c:       mov     x0, x19
    0.00 :   ffff800010181730:       ldr     x19, [sp, #16]
    0.00 :   ffff800010181734:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010181738:       autiasp
    0.00 :   ffff80001018173c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104bd5c8 <xas_find_conflict>:
         : 6                xas_find_conflict():
         : 1393             */
         : 1394             void *xas_find_conflict(struct xa_state *xas)
         : 1395             {
         : 1396             void *curr;
         :
         : 1398             if (xas_error(xas))
    0.00 :   ffff8000104bd5c8:       ldr     x3, [x0, #24]
         : 1400             xa_is_err():
         : 201              * Context: Any context.
         : 202              * Return: %true if the entry indicates an error.
         : 203              */
         : 204              static inline bool xa_is_err(const void *entry)
         : 205              {
         : 206              return unlikely(xa_is_internal(entry) &&
    0.00 :   ffff8000104bd5cc:       mov     x1, #0xffffffffffffc005         // #-16379
         : 208              xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd5d0:       and     x2, x3, #0x3
         : 171              xa_is_err():
         : 201              return unlikely(xa_is_internal(entry) &&
    0.00 :   ffff8000104bd5d4:       cmp     x2, #0x2
    0.00 :   ffff8000104bd5d8:       ccmp    x3, x1, #0x0, eq  // eq = none
    0.00 :   ffff8000104bd5dc:       b.hi    ffff8000104bd6e4 <xas_find_conflict+0x11c>  // b.pmore
         : 205              xas_find_conflict():
         : 1396             return NULL;
         :
         : 1398             if (!xas->xa_node)
    0.00 :   ffff8000104bd5e0:       cbz     x3, ffff8000104bd6ec <xas_find_conflict+0x124>
         : 1390             {
    0.00 :   ffff8000104bd5e4:       paciasp
    0.00 :   ffff8000104bd5e8:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff8000104bd5ec:       mov     x4, x0
    0.00 :   ffff8000104bd5f0:       mov     x29, sp
         : 1399             return NULL;
         :
         : 1401             if (xas_top(xas->xa_node)) {
    0.00 :   ffff8000104bd5f4:       cmp     x3, #0x3
    0.00 :   ffff8000104bd5f8:       b.ls    ffff8000104bd6f4 <xas_find_conflict+0x12c>  // b.plast
         : 1411             }
         : 1412             if (curr)
         : 1413             return curr;
         : 1414             }
         :
         : 1416             if (xas->xa_node->shift > xas->xa_shift)
    0.00 :   ffff8000104bd5fc:       ldrb    w0, [x3]
    0.00 :   ffff8000104bd600:       ldrb    w6, [x4, #16]
    0.00 :   ffff8000104bd604:       cmp     w0, w6
    0.00 :   ffff8000104bd608:       b.hi    ffff8000104bd794 <xas_find_conflict+0x1cc>  // b.pmore
    0.00 :   ffff8000104bd60c:       ldrb    w2, [x4, #18]
         : 1415             return NULL;
         :
         : 1417             for (;;) {
         : 1418             if (xas->xa_node->shift == xas->xa_shift) {
    0.00 :   ffff8000104bd610:       cmp     w6, w0
    0.00 :   ffff8000104bd614:       b.eq    ffff8000104bd678 <xas_find_conflict+0xb0>  // b.none
         : 1418             if ((xas->xa_offset & xas->xa_sibs) == xas->xa_sibs)
         : 1419             break;
         : 1420             } else if (xas->xa_offset == XA_CHUNK_MASK) {
    0.00 :   ffff8000104bd618:       cmp     w2, #0x3f
    0.00 :   ffff8000104bd61c:       b.eq    ffff8000104bd6b4 <xas_find_conflict+0xec>  // b.none
         : 1425             xas->xa_node = xa_parent_locked(xas->xa, xas->xa_node);
         : 1426             if (!xas->xa_node)
         : 1427             break;
         : 1428             continue;
         : 1429             }
         : 1430             curr = xa_entry_locked(xas->xa, xas->xa_node, ++xas->xa_offset);
    0.00 :   ffff8000104bd620:       add     w2, w2, #0x1
    0.00 :   ffff8000104bd624:       and     w2, w2, #0xff
    0.00 :   ffff8000104bd628:       strb    w2, [x4, #18]
         : 1434             xa_entry_locked():
         : 1191             /* Private */
         : 1192             static inline void *xa_entry_locked(const struct xarray *xa,
         : 1193             const struct xa_node *node, unsigned int offset)
         : 1194             {
         : 1195             XA_NODE_BUG_ON(node, offset >= XA_CHUNK_SIZE);
         : 1196             return rcu_dereference_protected(node->slots[offset],
    0.00 :   ffff8000104bd62c:       add     x0, x3, w2, uxtb #3
    0.00 :   ffff8000104bd630:       ldr     x0, [x0, #40]
         : 1199             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd634:       and     x5, x0, #0x3
    0.00 :   ffff8000104bd638:       mov     x1, x0
         : 172              xa_is_sibling():
         : 1249             *
         : 1250             * Return: %true if the entry is a sibling entry.
         : 1251             */
         : 1252             static inline bool xa_is_sibling(const void *entry)
         : 1253             {
         : 1254             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000104bd63c:       cmp     x5, #0x2
    0.00 :   ffff8000104bd640:       cset    w5, eq  // eq = none
    0.00 :   ffff8000104bd644:       cmp     x0, #0xfd
    0.00 :   ffff8000104bd648:       ccmp    w5, #0x0, #0x4, ls  // ls = plast
    0.00 :   ffff8000104bd64c:       b.ne    ffff8000104bd66c <xas_find_conflict+0xa4>  // b.any
         : 1260             xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd650:       cmp     x0, #0x1, lsl #12
    0.00 :   ffff8000104bd654:       ccmp    w5, #0x0, #0x4, hi  // hi = pmore
    0.00 :   ffff8000104bd658:       b.ne    ffff8000104bd68c <xas_find_conflict+0xc4>  // b.any
    0.00 :   ffff8000104bd65c:       nop
         : 1231             xas_find_conflict():
         : 1433             while (xa_is_node(curr)) {
         : 1434             xas->xa_node = xa_to_node(curr);
         : 1435             xas->xa_offset = 0;
         : 1436             curr = xa_entry_locked(xas->xa, xas->xa_node, 0);
         : 1437             }
         : 1438             if (curr)
    0.00 :   ffff8000104bd660:       cbnz    x0, ffff8000104bd6d8 <xas_find_conflict+0x110>
    0.00 :   ffff8000104bd664:       ldrb    w2, [x4, #18]
    0.00 :   ffff8000104bd668:       ldr     x3, [x4, #24]
    0.00 :   ffff8000104bd66c:       ldrb    w0, [x3]
         : 1415             if (xas->xa_node->shift == xas->xa_shift) {
    0.00 :   ffff8000104bd670:       cmp     w6, w0
    0.00 :   ffff8000104bd674:       b.ne    ffff8000104bd618 <xas_find_conflict+0x50>  // b.any
         : 1416             if ((xas->xa_offset & xas->xa_sibs) == xas->xa_sibs)
    0.00 :   ffff8000104bd678:       ldrb    w0, [x4, #17]
    0.00 :   ffff8000104bd67c:       and     w1, w0, w2
    0.00 :   ffff8000104bd680:       cmp     w0, w1
    0.00 :   ffff8000104bd684:       b.ne    ffff8000104bd620 <xas_find_conflict+0x58>  // b.any
    0.00 :   ffff8000104bd688:       b       ffff8000104bd6cc <xas_find_conflict+0x104>
         : 1422             xa_to_node():
         : 1220             return (struct xa_node *)((unsigned long)entry - 2);
    0.00 :   ffff8000104bd68c:       sub     x1, x1, #0x2
         : 1222             xas_find_conflict():
         : 1430             xas->xa_offset = 0;
    0.00 :   ffff8000104bd690:       strb    wzr, [x4, #18]
         : 1429             xas->xa_node = xa_to_node(curr);
    0.00 :   ffff8000104bd694:       str     x1, [x4, #24]
         : 1431             xa_entry_locked():
         : 1191             return rcu_dereference_protected(node->slots[offset],
    0.00 :   ffff8000104bd698:       ldr     x1, [x1, #40]
         : 1193             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd69c:       and     x0, x1, #0x3
         : 171              xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd6a0:       cmp     x1, #0x1, lsl #12
    0.00 :   ffff8000104bd6a4:       ccmp    x0, #0x2, #0x0, hi  // hi = pmore
         : 1229             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd6a8:       mov     x0, x1
         : 171              xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd6ac:       b.ne    ffff8000104bd660 <xas_find_conflict+0x98>  // b.any
    0.00 :   ffff8000104bd6b0:       b       ffff8000104bd68c <xas_find_conflict+0xc4>
         : 1229             xas_find_conflict():
         : 1419             xas->xa_offset = xas->xa_node->offset;
    0.00 :   ffff8000104bd6b4:       ldrb    w2, [x3, #1]
    0.00 :   ffff8000104bd6b8:       strb    w2, [x4, #18]
         : 1420             xas->xa_node = xa_parent_locked(xas->xa, xas->xa_node);
    0.00 :   ffff8000104bd6bc:       ldr     x3, [x3, #8]
    0.00 :   ffff8000104bd6c0:       str     x3, [x4, #24]
         : 1421             if (!xas->xa_node)
    0.00 :   ffff8000104bd6c4:       cbnz    x3, ffff8000104bd66c <xas_find_conflict+0xa4>
    0.00 :   ffff8000104bd6c8:       ldrb    w1, [x4, #17]
         : 1436             return curr;
         : 1437             }
         : 1438             xas->xa_offset -= xas->xa_sibs;
    0.00 :   ffff8000104bd6cc:       sub     w2, w2, w1
         : 1437             return NULL;
    0.00 :   ffff8000104bd6d0:       mov     x0, #0x0                        // #0
         : 1436             xas->xa_offset -= xas->xa_sibs;
    0.00 :   ffff8000104bd6d4:       strb    w2, [x4, #18]
         : 1438             }
    0.00 :   ffff8000104bd6d8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000104bd6dc:       autiasp
    0.00 :   ffff8000104bd6e0:       ret
         : 1442             xa_err():
         : 221              return (long)entry >> 2;
    0.00 :   ffff8000104bd6e4:       asr     x1, x3, #2
         : 223              xas_find_conflict():
         : 1393             if (xas_error(xas))
    0.00 :   ffff8000104bd6e8:       cbz     w1, ffff8000104bd5e0 <xas_find_conflict+0x18>
         : 1397             return NULL;
    0.00 :   ffff8000104bd6ec:       mov     x0, #0x0                        // #0
         : 1438             }
    0.00 :   ffff8000104bd6f0:       ret
         : 1400             curr = xas_start(xas);
    0.00 :   ffff8000104bd6f4:       bl      ffff8000104bcfa8 <xas_start>
         : 1401             if (!curr)
    0.00 :   ffff8000104bd6f8:       cbz     x0, ffff8000104bd794 <xas_find_conflict+0x1cc>
         : 1403             xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd6fc:       cmp     x0, #0x1, lsl #12
         : 1228             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd700:       and     x1, x0, #0x3
         : 171              xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd704:       ccmp    x1, #0x2, #0x0, hi  // hi = pmore
    0.00 :   ffff8000104bd708:       b.ne    ffff8000104bd6d8 <xas_find_conflict+0x110>  // b.any
         : 1229             xas_descend():
         : 203              unsigned int offset = get_offset(xas->xa_index, node);
    0.00 :   ffff8000104bd70c:       ldr     x5, [x4, #8]
         : 205              xa_to_node():
         : 1220             return (struct xa_node *)((unsigned long)entry - 2);
  100.00 :   ffff8000104bd710:       sub     x3, x0, #0x2
         : 1222             get_offset():
         : 144              return (index >> node->shift) & XA_CHUNK_MASK;
    0.00 :   ffff8000104bd714:       ldurb   w2, [x0, #-2]
    0.00 :   ffff8000104bd718:       lsr     x2, x5, x2
    0.00 :   ffff8000104bd71c:       and     w2, w2, #0x3f
         : 148              xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000104bd720:       ubfiz   x0, x2, #3, #6
    0.00 :   ffff8000104bd724:       add     x0, x0, #0x20
    0.00 :   ffff8000104bd728:       add     x0, x3, x0
    0.00 :   ffff8000104bd72c:       ldr     x0, [x0, #8]
         : 1187             xas_descend():
         : 206              xas->xa_node = node;
    0.00 :   ffff8000104bd730:       str     x3, [x4, #24]
         : 208              xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000104bd734:       and     x1, x0, #0x3
         : 171              xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000104bd738:       cmp     x1, #0x2
    0.00 :   ffff8000104bd73c:       cset    w1, eq  // eq = none
    0.00 :   ffff8000104bd740:       cmp     x0, #0xfd
    0.00 :   ffff8000104bd744:       ccmp    w1, #0x0, #0x4, ls  // ls = plast
    0.00 :   ffff8000104bd748:       b.eq    ffff8000104bd770 <xas_find_conflict+0x1a8>  // b.none
         : 1255             xa_to_internal():
         : 157              return (unsigned long)entry >> 2;
    0.00 :   ffff8000104bd74c:       lsr     x0, x0, #2
         : 159              xas_descend():
         : 208              offset = xa_to_sibling(entry);
    0.00 :   ffff8000104bd750:       mov     w2, w0
         : 210              xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000104bd754:       ubfiz   x1, x0, #3, #32
    0.00 :   ffff8000104bd758:       add     x1, x1, #0x20
    0.00 :   ffff8000104bd75c:       add     x1, x3, x1
    0.00 :   ffff8000104bd760:       ldr     x0, [x1, #8]
    0.00 :   ffff8000104bd764:       and     x1, x0, #0x3
    0.00 :   ffff8000104bd768:       cmp     x1, #0x2
    0.00 :   ffff8000104bd76c:       cset    w1, eq  // eq = none
         : 1190             xas_descend():
         : 212              xas->xa_offset = offset;
    0.00 :   ffff8000104bd770:       strb    w2, [x4, #18]
         : 214              xa_is_node():
         : 1226             return xa_is_internal(entry) && (unsigned long)entry > 4096;
    0.00 :   ffff8000104bd774:       cmp     x0, #0x1, lsl #12
    0.00 :   ffff8000104bd778:       ccmp    w1, #0x0, #0x4, hi  // hi = pmore
    0.00 :   ffff8000104bd77c:       b.ne    ffff8000104bd710 <xas_find_conflict+0x148>  // b.any
         : 1230             xas_find_conflict():
         : 1407             if (curr)
    0.00 :   ffff8000104bd780:       cbnz    x0, ffff8000104bd6d8 <xas_find_conflict+0x110>
         : 1411             if (xas->xa_node->shift > xas->xa_shift)
    0.00 :   ffff8000104bd784:       ldrb    w0, [x3]
    0.00 :   ffff8000104bd788:       ldrb    w6, [x4, #16]
    0.00 :   ffff8000104bd78c:       cmp     w0, w6
    0.00 :   ffff8000104bd790:       b.ls    ffff8000104bd60c <xas_find_conflict+0x44>  // b.plast
         : 1397             return NULL;
    0.00 :   ffff8000104bd794:       mov     x0, #0x0                        // #0
         : 1438             }
    0.00 :   ffff8000104bd798:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000104bd79c:       autiasp
    0.00 :   ffff8000104bd7a0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101dd7a8 <__alloc_pages>:
         : 6                __alloc_pages():
         : 5164             static inline bool prepare_alloc_pages(gfp_t gfp_mask, unsigned int order,
         : 5165             int preferred_nid, nodemask_t *nodemask,
         : 5166             struct alloc_context *ac, gfp_t *alloc_gfp,
         : 5167             unsigned int *alloc_flags)
         : 5168             {
         : 5169             ac->highest_zoneidx = gfp_zone(gfp_mask);
    0.00 :   ffff8000101dd7a8:       paciasp
    0.00 :   ffff8000101dd7ac:       stp     x29, x30, [sp, #-128]!
         : 5174             if (cpusets_enabled()) {
         : 5175             *alloc_gfp |= __GFP_HARDWALL;
         : 5176             /*
         : 5177             * When we are in the interrupt context, it is irrelevant
         : 5178             * to the current task context. It means that any node ok.
         : 5179             */
    0.00 :   ffff8000101dd7b0:       cmp     w1, #0xa
         : 5164             ac->highest_zoneidx = gfp_zone(gfp_mask);
    0.00 :   ffff8000101dd7b4:       mov     x29, sp
    0.00 :   ffff8000101dd7b8:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101dd7bc:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101dd7c0:       add     x20, x20, #0x948
    0.00 :   ffff8000101dd7c4:       ldr     x4, [x20]
    0.00 :   ffff8000101dd7c8:       str     x4, [sp, #120]
    0.00 :   ffff8000101dd7cc:       mov     x4, #0x0                        // #0
    0.00 :   ffff8000101dd7d0:       stp     x23, x24, [sp, #48]
         :
    0.00 :   ffff8000101dd7d4:       stp     xzr, xzr, [sp, #80]
    0.00 :   ffff8000101dd7d8:       stp     xzr, xzr, [sp, #96]
    0.00 :   ffff8000101dd7dc:       str     xzr, [sp, #112]
         : 5174             */
    0.00 :   ffff8000101dd7e0:       b.hi    ffff8000101dda0c <__alloc_pages+0x264>  // b.pmore
         : 5179             if (!in_interrupt() && !ac->nodemask)
         : 5180             ac->nodemask = &cpuset_current_mems_allowed;
         : 5181             else
         : 5182             *alloc_flags |= ALLOC_CPUSET;
         : 5183             }
    0.00 :   ffff8000101dd7e4:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101dd7e8:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101dd7ec:       add     x24, x24, #0xd68
    0.00 :   ffff8000101dd7f0:       str     x25, [sp, #64]
    0.00 :   ffff8000101dd7f4:       mov     w21, w1
         : 5189             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000101dd7f8:       mrs     x1, sp_el0
         : 26               current_gfp_context():
         : 158              * imply CLONE_VM
         : 159              *
         : 160              * CLONE_VFORK can be used with CLONE_PARENT/CLONE_THREAD and thus
         : 161              * ->real_parent is not necessarily the task doing vfork(), so in
         : 162              * theory we can't rely on task_lock() if we want to dereference it.
         : 163              *
    0.00 :   ffff8000101dd7fc:       ldr     w1, [x1, #36]
    0.00 :   ffff8000101dd800:       mov     x22, x3
         : 166              __alloc_pages():
    0.00 :   ffff8000101dd804:       ldr     w19, [x24, #80]
         : 5180             current_gfp_context():
         : 160              * And in this case we can't trust the real_parent->mm == tsk->mm
         : 161              * check, it can be false negative. But we do not care, if init or
    0.00 :   ffff8000101dd808:       mov     w3, #0x100c0000                 // #269221888
    0.00 :   ffff8000101dd80c:       tst     w1, w3
         : 164              __alloc_pages():
    0.00 :   ffff8000101dd810:       and     w19, w0, w19
         : 5180             current_gfp_context():
    0.00 :   ffff8000101dd814:       b.ne    ffff8000101dda1c <__alloc_pages+0x274>  // b.any
         : 161              node_zonelist():
         : 502              if (unlikely(flags & __GFP_THISNODE))
         : 503              return ZONELIST_NOFALLBACK;
         : 504              #endif
         : 505              return ZONELIST_FALLBACK;
         : 506              }
         :
    0.00 :   ffff8000101dd818:       adrp    x1, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000101dd81c:       add     x1, x1, #0xf60
         : 510              gfp_zonelist():
         : 485              }
    0.00 :   ffff8000101dd820:       ubfx    x5, x19, #21, #1
         : 487              gfp_migratetype():
         : 337              #define GFP_TRANSHUGE   (GFP_TRANSHUGE_LIGHT | __GFP_DIRECT_RECLAIM)
    0.00 :   ffff8000101dd824:       ldr     w6, [x24, #84]
         : 339              gfp_zone():
         : 469              | 1 << (___GFP_DMA | ___GFP_DMA32 | ___GFP_HIGHMEM)                   \
    0.00 :   ffff8000101dd828:       ubfiz   w7, w19, #1, #4
    0.00 :   ffff8000101dd82c:       mov     w4, #0x122                      // #290
         : 472              node_zonelist():
         :
    0.00 :   ffff8000101dd830:       ldr     x1, [x1, w2, sxtw #3]
    0.00 :   ffff8000101dd834:       lsl     x3, x5, #6
    0.00 :   ffff8000101dd838:       add     x3, x3, x5
         : 506              gfp_migratetype():
         : 341              #define GFP_MOVABLE_SHIFT 3
    0.00 :   ffff8000101dd83c:       ubfx    x0, x19, #3, #2
         : 343              node_zonelist():
         :
    0.00 :   ffff8000101dd840:       mov     x2, #0x1900                     // #6400
         : 504              gfp_zone():
         : 469              | 1 << (___GFP_DMA | ___GFP_DMA32 | ___GFP_HIGHMEM)                   \
    0.00 :   ffff8000101dd844:       movk    w4, #0x132, lsl #16
         : 471              node_zonelist():
         :
    0.00 :   ffff8000101dd848:       add     x1, x1, x2
         : 504              gfp_migratetype():
         : 341              #define GFP_MOVABLE_SHIFT 3
    0.00 :   ffff8000101dd84c:       cmp     w6, #0x0
         : 343              node_zonelist():
         :
    0.00 :   ffff8000101dd850:       add     x3, x1, x3, lsl #4
         : 504              gfp_zone():
         : 469              | 1 << (___GFP_DMA | ___GFP_DMA32 | ___GFP_HIGHMEM)                   \
    0.00 :   ffff8000101dd854:       asr     w4, w4, w7
         : 471              gfp_migratetype():
         : 341              #define GFP_MOVABLE_SHIFT 3
    0.00 :   ffff8000101dd858:       csel    w0, w0, wzr, eq  // eq = none
         : 343              gfp_zone():
         : 469              | 1 << (___GFP_DMA | ___GFP_DMA32 | ___GFP_HIGHMEM)                   \
    0.00 :   ffff8000101dd85c:       and     w4, w4, #0x3
         : 471              prepare_alloc_pages():
         : 4974             &compact_result);
    0.00 :   ffff8000101dd860:       stp     x3, x22, [sp, #80]
         : 4972             alloc_flags, ac,
    0.00 :   ffff8000101dd864:       stp     w0, w4, [sp, #104]
         : 4974             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000101dd868:       nop
    0.00 :   ffff8000101dd86c:       mov     w23, w19
         : 29               __alloc_pages():
         : 5166             ac->nodemask = nodemask;
    0.00 :   ffff8000101dd870:       mov     w25, #0x1                       // #1
         : 5168             prepare_alloc_pages():
         : 4994             *  - not guaranteed to help because isolate_freepages()
    0.00 :   ffff8000101dd874:       mov     w1, w21
    0.00 :   ffff8000101dd878:       mov     w0, w19
    0.00 :   ffff8000101dd87c:       bl      ffff8000101db5b0 <should_fail_alloc_page>
    0.00 :   ffff8000101dd880:       tst     w0, #0xff
    0.00 :   ffff8000101dd884:       b.ne    ffff8000101dd998 <__alloc_pages+0x1f0>  // b.any
         : 5000             gfp_migratetype():
         : 337              #define GFP_TRANSHUGE   (GFP_TRANSHUGE_LIGHT | __GFP_DIRECT_RECLAIM)
    0.00 :   ffff8000101dd888:       cbnz    w6, ffff8000101dd89c <__alloc_pages+0xf4>
         : 341              #define GFP_MOVABLE_SHIFT 3
    0.00 :   ffff8000101dd88c:       ubfx    x1, x19, #3, #2
         : 343              gfp_to_alloc_flags_cma():
         :
    0.00 :   ffff8000101dd890:       orr     w0, w25, #0x80
    0.00 :   ffff8000101dd894:       cmp     w1, #0x1
    0.00 :   ffff8000101dd898:       csel    w25, w0, w25, eq  // eq = none
         : 3872             prepare_alloc_pages():
         : 5007             * using async compaction.
    0.00 :   ffff8000101dd89c:       ldr     x2, [sp, #88]
         : 5000             if (compact_result == COMPACT_SKIPPED ||
    0.00 :   ffff8000101dd8a0:       ubfx    x0, x19, #12, #1
    0.00 :   ffff8000101dd8a4:       strb    w0, [sp, #112]
         : 5003             first_zones_zonelist():
         : 1152             if (likely(!nodes && zonelist_zone_idx(z) <= highest_zoneidx))
         : 1153             return z;
         : 1154             return __next_zones_zonelist(z, highest_zoneidx, nodes);
         : 1155             }
         :
         : 1157             /**
    0.00 :   ffff8000101dd8a8:       mov     x0, x3
         : 1159             next_zones_zonelist():
         : 1126             nodemask_t *nodes);
    0.00 :   ffff8000101dd8ac:       cbnz    x2, ffff8000101dd9fc <__alloc_pages+0x254>
    0.00 :   ffff8000101dd8b0:       ldr     w1, [x3, #8]
    0.00 :   ffff8000101dd8b4:       cmp     w4, w1
    0.00 :   ffff8000101dd8b8:       b.cc    ffff8000101dd9fc <__alloc_pages+0x254>  // b.lo, b.ul, b.last
         : 1131             prepare_alloc_pages():
         : 5007             * using async compaction.
  100.00 :   ffff8000101dd8bc:       str     x0, [sp, #96]
         : 5009             alloc_flags_nofragment():
         :
    0.00 :   ffff8000101dd8c0:       and     w2, w19, #0x800
         : 3841             __alloc_pages():
         : 5197             ac->spread_dirty_pages = (gfp_mask & __GFP_WRITE);
         :
         : 5199             /*
         : 5200             * The preferred zone is used for statistics but crucially it is
         : 5201             * also used as the starting point for the zonelist iterator. It
         : 5202             * may get reset for allocations that ignore memory policies.
    0.00 :   ffff8000101dd8c4:       ldr     x0, [x0]
         : 5204             alloc_flags_nofragment():
         : 3842             return __should_fail_alloc_page(gfp_mask, order);
    0.00 :   ffff8000101dd8c8:       cbz     x0, ffff8000101dd8f8 <__alloc_pages+0x150>
         :
    0.00 :   ffff8000101dd8cc:       ldr     x1, [x0, #80]
    0.00 :   ffff8000101dd8d0:       sub     x1, x0, x1
    0.00 :   ffff8000101dd8d4:       cmp     x1, #0xc80
    0.00 :   ffff8000101dd8d8:       b.ne    ffff8000101dd8f8 <__alloc_pages+0x150>  // b.any
         : 3854             * the high-atomic reserves. This will over-estimate the size of the
    0.00 :   ffff8000101dd8dc:       ldr     w1, [x24, #72]
    0.00 :   ffff8000101dd8e0:       cmp     w1, #0x1
    0.00 :   ffff8000101dd8e4:       b.ls    ffff8000101dd8f4 <__alloc_pages+0x14c>  // b.plast
    0.00 :   ffff8000101dd8e8:       sub     x0, x0, #0x8, lsl #12
    0.00 :   ffff8000101dd8ec:       ldr     x0, [x0, #31296]
    0.00 :   ffff8000101dd8f0:       cbz     x0, ffff8000101dd8f8 <__alloc_pages+0x150>
         : 3857             if (likely(!alloc_harder))
    0.00 :   ffff8000101dd8f4:       orr     w2, w2, #0x100
         : 3859             __alloc_pages():
         : 5200             */
         : 5201             ac->preferred_zoneref = first_zones_zonelist(ac->zonelist,
         : 5202             ac->highest_zoneidx, ac->nodemask);
    0.00 :   ffff8000101dd8f8:       mov     w0, w23
    0.00 :   ffff8000101dd8fc:       orr     w2, w2, w25
    0.00 :   ffff8000101dd900:       add     x3, sp, #0x50
    0.00 :   ffff8000101dd904:       mov     w1, w21
    0.00 :   ffff8000101dd908:       bl      ffff8000101db958 <get_page_from_freelist>
    0.00 :   ffff8000101dd90c:       mov     x23, x0
         :
    0.00 :   ffff8000101dd910:       cbz     x0, ffff8000101dd9dc <__alloc_pages+0x234>
         : 5203             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101dd914:       b       ffff8000101dd91c <__alloc_pages+0x174>
         : 45               __alloc_pages():
         : 5216             * @page_list: Optional list to store the allocated pages
         : 5217             * @page_array: Optional array to store the pages
         : 5218             *
         : 5219             * This is a batched version of the page allocator that attempts to
         : 5220             * allocate nr_pages quickly. Pages are added to page_list if page_list
         : 5221             * is not NULL, otherwise it is assumed that the page_array is valid.
    0.00 :   ffff8000101dd918:       tbnz    w19, #22, ffff8000101dd9a8 <__alloc_pages+0x200>
    0.00 :   ffff8000101dd91c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101dd920:       ldr     x25, [sp, #64]
         : 5225             * For arrays, only NULL elements are populated with pages and nr_pages
         : 5226             * is the maximum number of pages that will be stored in the array.
         : 5227             *
         : 5228             * Returns the number of pages on the list or array.
         : 5229             */
         : 5230             unsigned long __alloc_pages_bulk(gfp_t gfp, int preferred_nid,
    0.00 :   ffff8000101dd924:       mov     x0, x23
    0.00 :   ffff8000101dd928:       ldr     x2, [sp, #120]
    0.00 :   ffff8000101dd92c:       ldr     x1, [x20]
    0.00 :   ffff8000101dd930:       eor     x1, x2, x1
    0.00 :   ffff8000101dd934:       cbnz    x1, ffff8000101dda54 <__alloc_pages+0x2ac>
    0.00 :   ffff8000101dd938:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101dd93c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000101dd940:       ldp     x29, x30, [sp], #128
    0.00 :   ffff8000101dd944:       autiasp
    0.00 :   ffff8000101dd948:       ret
         : 5241             get_current():
    0.00 :   ffff8000101dd94c:       mrs     x1, sp_el0
         : 20               preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000101dd950:       ldr     w0, [x1, #8]
         : 19               prepare_alloc_pages():
         : 4978             /*
    0.00 :   ffff8000101dd954:       orr     w23, w19, #0x100000
         : 4980             preempt_count():
    0.00 :   ffff8000101dd958:       ldr     w5, [x1, #8]
    0.00 :   ffff8000101dd95c:       ldr     w2, [x1, #8]
         : 14               prepare_alloc_pages():
         : 4983             /*
    0.00 :   ffff8000101dd960:       and     w0, w0, #0xf00000
    0.00 :   ffff8000101dd964:       and     w5, w5, #0xf0000
    0.00 :   ffff8000101dd968:       orr     w0, w0, w5
    0.00 :   ffff8000101dd96c:       and     w2, w2, #0xff00
    0.00 :   ffff8000101dd970:       orr     w0, w0, w2
    0.00 :   ffff8000101dd974:       cmp     w0, #0x0
    0.00 :   ffff8000101dd978:       ccmp    x22, #0x0, #0x0, eq  // eq = none
    0.00 :   ffff8000101dd97c:       b.eq    ffff8000101dda3c <__alloc_pages+0x294>  // b.none
         : 4994             *  - not guaranteed to help because isolate_freepages()
    0.00 :   ffff8000101dd980:       mov     w1, w21
    0.00 :   ffff8000101dd984:       mov     w0, w19
         : 4986             * or is prohibited because it recently failed at this
    0.00 :   ffff8000101dd988:       mov     w25, #0x41                      // #65
         : 4994             *  - not guaranteed to help because isolate_freepages()
    0.00 :   ffff8000101dd98c:       bl      ffff8000101db5b0 <should_fail_alloc_page>
    0.00 :   ffff8000101dd990:       tst     w0, #0xff
    0.00 :   ffff8000101dd994:       b.eq    ffff8000101dd888 <__alloc_pages+0xe0>  // b.none
    0.00 :   ffff8000101dd998:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101dd99c:       ldr     x25, [sp, #64]
         : 5000             __alloc_pages():
         : 5176             ac->nodemask = &cpuset_current_mems_allowed;
    0.00 :   ffff8000101dd9a0:       mov     x23, #0x0                       // #0
    0.00 :   ffff8000101dd9a4:       b       ffff8000101dd924 <__alloc_pages+0x17c>
         : 5216             * is not NULL, otherwise it is assumed that the page_array is valid.
    0.00 :   ffff8000101dd9a8:       cbz     x23, ffff8000101dd998 <__alloc_pages+0x1f0>
         : 5217             *
    0.00 :   ffff8000101dd9ac:       mov     w1, w19
    0.00 :   ffff8000101dd9b0:       mov     w2, w21
    0.00 :   ffff8000101dd9b4:       mov     x0, x23
    0.00 :   ffff8000101dd9b8:       bl      ffff800010224988 <__memcg_kmem_charge_page>
         : 5216             * is not NULL, otherwise it is assumed that the page_array is valid.
    0.00 :   ffff8000101dd9bc:       cbz     w0, ffff8000101dd91c <__alloc_pages+0x174>
         : 5218             * For lists, nr_pages is the number of pages that should be allocated.
    0.00 :   ffff8000101dd9c0:       mov     x0, x23
    0.00 :   ffff8000101dd9c4:       mov     w1, w21
         : 5219             *
    0.00 :   ffff8000101dd9c8:       mov     x23, #0x0                       // #0
         : 5218             * For lists, nr_pages is the number of pages that should be allocated.
    0.00 :   ffff8000101dd9cc:       bl      ffff8000101da838 <__free_pages>
    0.00 :   ffff8000101dd9d0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101dd9d4:       ldr     x25, [sp, #64]
    0.00 :   ffff8000101dd9d8:       b       ffff8000101dd924 <__alloc_pages+0x17c>
         : 5213             *
    0.00 :   ffff8000101dd9dc:       add     x2, sp, #0x50
    0.00 :   ffff8000101dd9e0:       mov     w1, w21
    0.00 :   ffff8000101dd9e4:       mov     w0, w19
         : 5211             * @page_list: Optional list to store the allocated pages
    0.00 :   ffff8000101dd9e8:       str     x22, [sp, #88]
         : 5205             /*
    0.00 :   ffff8000101dd9ec:       strb    wzr, [sp, #112]
         : 5213             *
    0.00 :   ffff8000101dd9f0:       bl      ffff8000101dcd70 <__alloc_pages_slowpath.constprop.122>
    0.00 :   ffff8000101dd9f4:       mov     x23, x0
    0.00 :   ffff8000101dd9f8:       b       ffff8000101dd914 <__alloc_pages+0x16c>
         : 5217             next_zones_zonelist():
         : 1128             /**
    0.00 :   ffff8000101dd9fc:       mov     w1, w4
    0.00 :   ffff8000101dda00:       mov     x0, x3
    0.00 :   ffff8000101dda04:       bl      ffff8000101a2e20 <__next_zones_zonelist>
    0.00 :   ffff8000101dda08:       b       ffff8000101dd8bc <__alloc_pages+0x114>
         : 1133             __alloc_pages():
         : 5175             if (!in_interrupt() && !ac->nodemask)
    0.00 :   ffff8000101dda0c:       tbnz    w0, #13, ffff8000101dd9a0 <__alloc_pages+0x1f8>
    0.00 :   ffff8000101dda10:       brk     #0x800
         : 5176             ac->nodemask = &cpuset_current_mems_allowed;
    0.00 :   ffff8000101dda14:       mov     x23, #0x0                       // #0
    0.00 :   ffff8000101dda18:       b       ffff8000101dd924 <__alloc_pages+0x17c>
         : 5179             current_gfp_context():
         : 165              * another oom-unkillable task does this it should blame itself.
         : 166              */
         : 167              rcu_read_lock();
         : 168              ret = tsk->vfork_done &&
         : 169              rcu_dereference(tsk->real_parent)->mm == tsk->mm;
    0.00 :   ffff8000101dda1c:       tbnz    w1, #19, ffff8000101dda4c <__alloc_pages+0x2a4>
         : 168              rcu_read_unlock();
         :
         : 170              return ret;
    0.00 :   ffff8000101dda20:       tst     x1, #0x40000
    0.00 :   ffff8000101dda24:       and     w0, w19, #0xffffff7f
    0.00 :   ffff8000101dda28:       csel    w19, w0, w19, ne  // ne = any
         : 171              }
         :
         : 173              /*
    0.00 :   ffff8000101dda2c:       tst     x1, #0x10000000
    0.00 :   ffff8000101dda30:       and     w0, w19, #0xfffffff7
    0.00 :   ffff8000101dda34:       csel    w19, w0, w19, ne  // ne = any
    0.00 :   ffff8000101dda38:       b       ffff8000101dd818 <__alloc_pages+0x70>
         : 178              prepare_alloc_pages():
         : 4984             * If allocating entire pageblock(s) and compaction
    0.00 :   ffff8000101dda3c:       add     x1, x1, #0x7b8
         : 4986             __alloc_pages():
         : 5166             ac->nodemask = nodemask;
    0.00 :   ffff8000101dda40:       mov     w25, #0x1                       // #1
         : 5168             prepare_alloc_pages():
         : 4984             * If allocating entire pageblock(s) and compaction
    0.00 :   ffff8000101dda44:       str     x1, [sp, #88]
    0.00 :   ffff8000101dda48:       b       ffff8000101dd874 <__alloc_pages+0xcc>
         : 4987             current_gfp_context():
         : 166              rcu_read_unlock();
    0.00 :   ffff8000101dda4c:       and     w19, w19, #0xffffff3f
    0.00 :   ffff8000101dda50:       b       ffff8000101dda2c <__alloc_pages+0x284>
    0.00 :   ffff8000101dda54:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101dda58:       str     x25, [sp, #64]
         : 171              __alloc_pages():
         : 5225             unsigned long __alloc_pages_bulk(gfp_t gfp, int preferred_nid,
    0.00 :   ffff8000101dda5c:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010165c88 <perf_mmap_fault>:
         : 6                perf_mmap_fault():
         : 5850             ++userpg->lock;
         : 5851             preempt_enable();
         : 5852             unlock:
         : 5853             rcu_read_unlock();
         : 5854             }
         : 5855             EXPORT_SYMBOL_GPL(perf_event_update_userpage);
    0.00 :   ffff800010165c88:       paciasp
    0.00 :   ffff800010165c8c:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010165c90:       mov     x29, sp
    0.00 :   ffff800010165c94:       stp     x19, x20, [sp, #16]
         :
         : 5856             static vm_fault_t perf_mmap_fault(struct vm_fault *vmf)
         : 5857             {
         : 5858             struct perf_event *event = vmf->vma->vm_file->private_data;
         : 5859             struct perf_buffer *rb;
    0.00 :   ffff800010165c98:       ldr     w1, [x0, #32]
    0.00 :   ffff800010165c9c:       tbz     w1, #1, ffff800010165cc4 <perf_mmap_fault+0x3c>
         : 5856             vm_fault_t ret = VM_FAULT_SIGBUS;
    0.00 :   ffff800010165ca0:       ldr     x0, [x0, #16]
         :
    0.00 :   ffff800010165ca4:       cmp     x0, #0x0
    0.00 :   ffff800010165ca8:       cset    w20, ne  // ne = any
    0.00 :   ffff800010165cac:       lsl     w20, w20, #1
         : 5882             vmf->page->mapping = vmf->vma->vm_file->f_mapping;
         : 5883             vmf->page->index   = vmf->pgoff;
         :
         : 5885             ret = 0;
         : 5886             unlock:
         : 5887             rcu_read_unlock();
    0.00 :   ffff800010165cb0:       mov     w0, w20
    0.00 :   ffff800010165cb4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010165cb8:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010165cbc:       autiasp
    0.00 :   ffff800010165cc0:       ret
    0.00 :   ffff800010165cc4:       str     x21, [sp, #32]
    0.00 :   ffff800010165cc8:       mov     x19, x0
    0.00 :   ffff800010165ccc:       and     w20, w1, #0x2
         :
    0.00 :   ffff800010165cd0:       ldr     x0, [x0]
    0.00 :   ffff800010165cd4:       ldr     x0, [x0, #160]
    0.00 :   ffff800010165cd8:       ldr     x21, [x0, #200]
         : 5855             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010165cdc:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              perf_mmap_fault():
         : 5862             }
    0.00 :   ffff800010165ce0:       ldr     x0, [x21, #712]
         :
    0.00 :   ffff800010165ce4:       cbz     x0, ffff800010165d54 <perf_mmap_fault+0xcc>
         : 5866             if (!rb)
    0.00 :   ffff800010165ce8:       ldr     x1, [x19, #16]
    0.00 :   ffff800010165cec:       cbz     x1, ffff800010165cf8 <perf_mmap_fault+0x70>
    0.00 :   ffff800010165cf0:       ldr     w2, [x19, #32]
    0.00 :   ffff800010165cf4:       tbnz    w2, #0, ffff800010165d54 <perf_mmap_fault+0xcc>
         : 5869             if (vmf->pgoff && (vmf->flags & FAULT_FLAG_WRITE))
    0.00 :   ffff800010165cf8:       bl      ffff800010178b98 <perf_mmap_to_page>
    0.00 :   ffff800010165cfc:       str     x0, [x19, #72]
    0.00 :   ffff800010165d00:       mov     x1, x0
         : 5870             goto unlock;
    0.00 :   ffff800010165d04:       cbz     x0, ffff800010165d54 <perf_mmap_fault+0xcc>
         : 5872             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010165d08:       ldr     x0, [x0, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010165d0c:       sub     x2, x0, #0x1
    0.00 :   ffff800010165d10:       tst     x0, #0x1
    0.00 :   ffff800010165d14:       csel    x1, x2, x1, ne  // ne = any
         : 193              page_ref_inc():
         : 116              return ret;
         : 117              }
         :
         : 119              static inline void page_ref_inc(struct page *page)
         : 120              {
         : 121              atomic_inc(&page->_refcount);
  100.00 :   ffff800010165d18:       add     x2, x1, #0x34
         : 123              arch_atomic_add():
         : 28               }
         :
         : 30               ATOMIC_OP(atomic_andnot)
         : 31               ATOMIC_OP(atomic_or)
         : 32               ATOMIC_OP(atomic_xor)
         : 33               ATOMIC_OP(atomic_add)
    0.00 :   ffff800010165d1c:       bl      ffff8000101648a8 <system_uses_lse_atomics>
    0.00 :   ffff800010165d20:       tst     w0, #0xff
    0.00 :   ffff800010165d24:       b.ne    ffff800010165d74 <perf_mmap_fault+0xec>  // b.any
         : 37               __ll_sc_atomic_add():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff800010165d28:       add     x1, x1, #0x34
    0.00 :   ffff800010165d2c:       b       ffff800010176a68 <perf_event_exit_cpu+0x28>
         : 119              perf_mmap_fault():
         : 5874             goto unlock;
    0.00 :   ffff800010165d30:       ldr     x1, [x19]
    0.00 :   ffff800010165d34:       ldr     x0, [x19, #72]
    0.00 :   ffff800010165d38:       ldr     x1, [x1, #160]
    0.00 :   ffff800010165d3c:       ldr     x1, [x1, #216]
    0.00 :   ffff800010165d40:       str     x1, [x0, #24]
         :
    0.00 :   ffff800010165d44:       ldr     x0, [x19, #72]
    0.00 :   ffff800010165d48:       ldr     x1, [x19, #16]
    0.00 :   ffff800010165d4c:       str     x1, [x0, #32]
         : 5877             vmf->page->mapping = vmf->vma->vm_file->f_mapping;
    0.00 :   ffff800010165d50:       b       ffff800010165d58 <perf_mmap_fault+0xd0>
         : 5853             {
    0.00 :   ffff800010165d54:       mov     w20, #0x2                       // #2
         : 5855             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010165d58:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              perf_mmap_fault():
         : 5882             rcu_read_unlock();
    0.00 :   ffff800010165d5c:       mov     w0, w20
    0.00 :   ffff800010165d60:       ldp     x19, x20, [sp, #16]
         : 5885             rcu_read_unlock():
    0.00 :   ffff800010165d64:       ldr     x21, [sp, #32]
         : 711              perf_mmap_fault():
    0.00 :   ffff800010165d68:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010165d6c:       autiasp
    0.00 :   ffff800010165d70:       ret
         : 5885             __lse_atomic_add():
         : 26               }
         :
         : 28               ATOMIC_OP(andnot, stclr)
         : 29               ATOMIC_OP(or, stset)
         : 30               ATOMIC_OP(xor, steor)
         : 31               ATOMIC_OP(add, stadd)
    0.00 :   ffff800010165d74:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010165d78:       add     x1, x1, #0x34
    0.00 :   ffff800010165d7c:       stadd   w0, [x1]
    0.00 :   ffff800010165d80:       b       ffff800010165d30 <perf_mmap_fault+0xa8>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001030c610 <ext4_da_get_block_prep>:
         : 6                ext4_da_get_block_prep():
         : 1819             * We also have b_blocknr = physicalblock mapping unwritten extent and b_bdev
         : 1820             * initialized properly.
         : 1821             */
         : 1822             int ext4_da_get_block_prep(struct inode *inode, sector_t iblock,
         : 1823             struct buffer_head *bh, int create)
         : 1824             {
    0.00 :   ffff80001030c610:       paciasp
    0.00 :   ffff80001030c614:       stp     x29, x30, [sp, #-160]!
    0.00 :   ffff80001030c618:       mov     x29, sp
    0.00 :   ffff80001030c61c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001030c620:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001030c624:       add     x22, x22, #0x948
    0.00 :   ffff80001030c628:       ldr     x4, [x22]
  100.00 :   ffff80001030c62c:       str     x4, [sp, #152]
    0.00 :   ffff80001030c630:       mov     x4, #0x0                        // #0
         : 1823             struct ext4_map_blocks map;
         : 1824             int ret = 0;
         :
         : 1826             BUG_ON(create == 0);
    0.00 :   ffff80001030c634:       cbz     w3, ffff80001030c9b0 <ext4_da_get_block_prep+0x3a0>
         : 1824             BUG_ON(bh->b_size != inode->i_sb->s_blocksize);
    0.00 :   ffff80001030c638:       ldr     x3, [x0, #40]
    0.00 :   ffff80001030c63c:       ldr     x5, [x2, #32]
    0.00 :   ffff80001030c640:       ldr     x4, [x3, #24]
    0.00 :   ffff80001030c644:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001030c648:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001030c64c:       cmp     x5, x4
    0.00 :   ffff80001030c650:       b.ne    ffff80001030c9c0 <ext4_da_get_block_prep+0x3b0>  // b.any
         : 1832             ext4_da_map_blocks():
         : 1705             if (invalid_block < ext4_blocks_count(EXT4_SB(inode->i_sb)->s_es))
    0.00 :   ffff80001030c654:       ldr     x3, [x3, #880]
         : 1707             ext4_da_get_block_prep():
         :
         : 1828             map.m_lblk = iblock;
         : 1829             map.m_len = 1;
    0.00 :   ffff80001030c658:       mov     w4, #0x1                        // #1
    0.00 :   ffff80001030c65c:       stp     w1, w4, [sp, #96]
         : 1832             ext4_da_map_blocks():
         : 1698             sector_t invalid_block = ~((sector_t) 0xffff);
    0.00 :   ffff80001030c660:       mov     x23, #0xffffffffffff0000        // #-65536
         : 1705             if (invalid_block < ext4_blocks_count(EXT4_SB(inode->i_sb)->s_es))
    0.00 :   ffff80001030c664:       ldr     x3, [x3, #104]
         : 1707             ext4_blocks_count():
         : 3228             }
         :
         : 3230             static inline int ext4_has_group_desc_csum(struct super_block *sb)
         : 3231             {
         : 3232             return ext4_has_feature_gdt_csum(sb) || ext4_has_metadata_csum(sb);
         : 3233             }
    0.00 :   ffff80001030c668:       ldr     w4, [x3, #96]
    0.00 :   ffff80001030c66c:       tbnz    w4, #7, ffff80001030c774 <ext4_da_get_block_prep+0x164>
         : 3236             ext4_da_map_blocks():
         : 1708             map->m_flags = 0;
    0.00 :   ffff80001030c670:       mov     x19, x2
    0.00 :   ffff80001030c674:       mov     x20, x1
    0.00 :   ffff80001030c678:       mov     x21, x0
         : 1713             if (ext4_es_lookup_extent(inode, iblock, NULL, &es)) {
    0.00 :   ffff80001030c67c:       add     x3, sp, #0x70
    0.00 :   ffff80001030c680:       mov     x2, #0x0                        // #0
         : 1708             map->m_flags = 0;
    0.00 :   ffff80001030c684:       str     wzr, [sp, #104]
         : 1713             if (ext4_es_lookup_extent(inode, iblock, NULL, &es)) {
    0.00 :   ffff80001030c688:       bl      ffff8000102fd0b0 <ext4_es_lookup_extent>
    0.00 :   ffff80001030c68c:       cbz     w0, ffff80001030c7ac <ext4_da_get_block_prep+0x19c>
         : 1716             ext4_es_is_hole():
         : 179              return (ext4_es_type(es) & EXTENT_STATUS_DELAYED) != 0;
         : 180              }
         :
         : 182              static inline int ext4_es_is_hole(struct extent_status *es)
         : 183              {
         : 184              return (ext4_es_type(es) & EXTENT_STATUS_HOLE) != 0;
    0.00 :   ffff80001030c690:       ldr     x1, [sp, #144]
         : 186              ext4_es_type():
         : 159              return (es->es_pblk & ES_TYPE_MASK) >> ES_SHIFT;
    0.00 :   ffff80001030c694:       lsr     x2, x1, #59
         : 161              ext4_da_map_blocks():
         : 1714             if (ext4_es_is_hole(&es)) {
    0.00 :   ffff80001030c698:       tbnz    w2, #3, ffff80001030c848 <ext4_da_get_block_prep+0x238>
         : 1724             if (ext4_es_is_delayed(&es) && !ext4_es_is_unwritten(&es)) {
    0.00 :   ffff80001030c69c:       tbz     w2, #2, ffff80001030c6a4 <ext4_da_get_block_prep+0x94>
    0.00 :   ffff80001030c6a0:       tbz     w2, #1, ffff80001030c9d0 <ext4_da_get_block_prep+0x3c0>
         : 1727             ext4_es_pblock():
         : 209              return (ext4_es_status(es) & EXTENT_STATUS_REFERENCED) != 0;
         : 210              }
         :
         : 212              static inline ext4_fsblk_t ext4_es_pblock(struct extent_status *es)
         : 213              {
         : 214              return es->es_pblk & ~ES_MASK;
    0.00 :   ffff80001030c6a4:       and     x3, x1, #0x7ffffffffffffff
    0.00 :   ffff80001030c6a8:       ldr     w4, [sp, #100]
         : 217              ext4_da_map_blocks():
         : 1732             retval = es.es_len - (iblock - es.es_lblk);
    0.00 :   ffff80001030c6ac:       ldp     w0, w1, [sp, #136]
    0.00 :   ffff80001030c6b0:       add     w1, w0, w1
         : 1731             map->m_pblk = ext4_es_pblock(&es) + iblock - es.es_lblk;
    0.00 :   ffff80001030c6b4:       sub     x0, x20, w0, uxtw
         : 1732             retval = es.es_len - (iblock - es.es_lblk);
    0.00 :   ffff80001030c6b8:       sub     w20, w1, w20
    0.00 :   ffff80001030c6bc:       cmp     w20, w4
         : 1731             map->m_pblk = ext4_es_pblock(&es) + iblock - es.es_lblk;
    0.00 :   ffff80001030c6c0:       add     x0, x0, x3
    0.00 :   ffff80001030c6c4:       csel    w20, w20, w4, ls  // ls = plast
    0.00 :   ffff80001030c6c8:       str     x0, [sp, #88]
         : 1735             map->m_len = retval;
    0.00 :   ffff80001030c6cc:       str     w20, [sp, #100]
         : 1736             if (ext4_es_is_written(&es))
    0.00 :   ffff80001030c6d0:       tbnz    w2, #0, ffff80001030c9a0 <ext4_da_get_block_prep+0x390>
         : 1738             else if (ext4_es_is_unwritten(&es))
    0.00 :   ffff80001030c6d4:       tbz     w2, #1, ffff80001030cb2c <ext4_da_get_block_prep+0x51c>
         : 1739             map->m_flags |= EXT4_MAP_UNWRITTEN;
    0.00 :   ffff80001030c6d8:       ldr     w0, [sp, #104]
    0.00 :   ffff80001030c6dc:       orr     w0, w0, #0x800
    0.00 :   ffff80001030c6e0:       str     w0, [sp, #104]
         : 1743             ext4_da_get_block_prep():
         : 1835             * first, we need to know whether the block is allocated already
         : 1836             * preallocated blocks are unmapped but should treated
         : 1837             * the same as allocated blocks.
         : 1838             */
         : 1839             ret = ext4_da_map_blocks(inode, iblock, &map, bh);
         : 1840             if (ret <= 0)
    0.00 :   ffff80001030c6e4:       cmp     w20, #0x0
    0.00 :   ffff80001030c6e8:       b.le    ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 1843             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001030c6ec:       ldr     x0, [x19]
         : 113              ext4_da_get_block_prep():
         : 1838             return ret;
         :
         : 1840             map_bh(bh, inode->i_sb, map.m_pblk);
    0.00 :   ffff80001030c6f0:       ldr     x2, [x21, #40]
         : 1842             set_buffer_mapped():
         : 126              BUFFER_FNS(Dirty, dirty)
         : 127              TAS_BUFFER_FNS(Dirty, dirty)
         : 128              BUFFER_FNS(Lock, locked)
         : 129              BUFFER_FNS(Req, req)
         : 130              TAS_BUFFER_FNS(Req, req)
         : 131              BUFFER_FNS(Mapped, mapped)
    0.00 :   ffff80001030c6f4:       tst     w0, #0x10
         : 133              ext4_da_get_block_prep():
    0.00 :   ffff80001030c6f8:       ldr     x1, [sp, #88]
         : 1839             set_buffer_mapped():
    0.00 :   ffff80001030c6fc:       b.eq    ffff80001030c950 <ext4_da_get_block_prep+0x340>  // b.none
         : 127              map_bh():
         :
         : 348              static inline void
         : 349              map_bh(struct buffer_head *bh, struct super_block *sb, sector_t block)
         : 350              {
         : 351              set_buffer_mapped(bh);
         : 352              bh->b_bdev = sb->s_bdev;
    0.00 :   ffff80001030c700:       ldr     x0, [x2, #200]
         : 348              bh->b_blocknr = block;
    0.00 :   ffff80001030c704:       str     x1, [x19, #24]
         : 347              bh->b_bdev = sb->s_bdev;
    0.00 :   ffff80001030c708:       str     x0, [x19, #48]
         : 349              ext4_da_get_block_prep():
         : 1839             ext4_update_bh_state(bh, map.m_flags);
    0.00 :   ffff80001030c70c:       mov     x0, x19
    0.00 :   ffff80001030c710:       ldr     w1, [sp, #104]
         : 1842             map_bh():
         : 349              bh->b_size = sb->s_blocksize;
    0.00 :   ffff80001030c714:       ldr     x2, [x2, #24]
    0.00 :   ffff80001030c718:       str     x2, [x19, #32]
         : 352              ext4_da_get_block_prep():
    0.00 :   ffff80001030c71c:       bl      ffff80001030c5a0 <ext4_update_bh_state>
         : 1840             test_bit():
    0.00 :   ffff80001030c720:       ldr     x0, [x19]
         : 107              ext4_da_get_block_prep():
         :
         : 1842             if (buffer_unwritten(bh)) {
    0.00 :   ffff80001030c724:       tst     w0, #0x800
    0.00 :   ffff80001030c728:       b.eq    ffff80001030c744 <ext4_da_get_block_prep+0x134>  // b.none
         : 1845             test_bit():
    0.00 :   ffff80001030c72c:       ldr     x0, [x19]
         : 107              set_buffer_new():
         : 127              BUFFER_FNS(New, new)
    0.00 :   ffff80001030c730:       tst     w0, #0x20
    0.00 :   ffff80001030c734:       b.eq    ffff80001030c914 <ext4_da_get_block_prep+0x304>  // b.none
         : 130              test_bit():
    0.00 :   ffff80001030c738:       ldr     x20, [x19]
    0.00 :   ffff80001030c73c:       ubfx    w20, w20, #4, #1
         : 108              set_buffer_mapped():
         : 126              BUFFER_FNS(Mapped, mapped)
    0.00 :   ffff80001030c740:       cbz     w20, ffff80001030c8fc <ext4_da_get_block_prep+0x2ec>
         : 128              ext4_da_get_block_prep():
         : 1851             * for partial write.
         : 1852             */
         : 1853             set_buffer_new(bh);
         : 1854             set_buffer_mapped(bh);
         : 1855             }
         : 1856             return 0;
    0.00 :   ffff80001030c744:       mov     w20, #0x0                       // #0
         : 1852             }
    0.00 :   ffff80001030c748:       mov     w0, w20
    0.00 :   ffff80001030c74c:       ldr     x2, [sp, #152]
    0.00 :   ffff80001030c750:       ldr     x1, [x22]
    0.00 :   ffff80001030c754:       eor     x1, x2, x1
    0.00 :   ffff80001030c758:       cbnz    x1, ffff80001030cb24 <ext4_da_get_block_prep+0x514>
    0.00 :   ffff80001030c75c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001030c760:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001030c764:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001030c768:       ldp     x29, x30, [sp], #160
    0.00 :   ffff80001030c76c:       autiasp
    0.00 :   ffff80001030c770:       ret
         : 1864             ext4_blocks_count():
    0.00 :   ffff80001030c774:       ldr     w4, [x3, #336]
         : 3229             ext4_da_map_blocks():
         : 1706             invalid_block = ~0;
    0.00 :   ffff80001030c778:       mov     x5, #0xffffffffffff0001         // #-65535
         : 1708             ext4_blocks_count():
    0.00 :   ffff80001030c77c:       ldr     w3, [x3, #4]
    0.00 :   ffff80001030c780:       mov     x19, x2
    0.00 :   ffff80001030c784:       mov     x20, x1
    0.00 :   ffff80001030c788:       mov     x21, x0
         : 3232             ext4_da_map_blocks():
         : 1713             if (ext4_es_lookup_extent(inode, iblock, NULL, &es)) {
    0.00 :   ffff80001030c78c:       mov     x2, #0x0                        // #0
         : 1708             map->m_flags = 0;
    0.00 :   ffff80001030c790:       str     wzr, [sp, #104]
         : 1710             ext4_blocks_count():
    0.00 :   ffff80001030c794:       orr     x3, x3, x4, lsl #32
         : 3229             ext4_da_map_blocks():
         : 1706             invalid_block = ~0;
    0.00 :   ffff80001030c798:       cmp     x3, x5
         : 1713             if (ext4_es_lookup_extent(inode, iblock, NULL, &es)) {
    0.00 :   ffff80001030c79c:       add     x3, sp, #0x70
         : 1706             invalid_block = ~0;
    0.00 :   ffff80001030c7a0:       csinv   x23, x23, xzr, cc  // cc = lo, ul, last
         : 1713             if (ext4_es_lookup_extent(inode, iblock, NULL, &es)) {
    0.00 :   ffff80001030c7a4:       bl      ffff8000102fd0b0 <ext4_es_lookup_extent>
    0.00 :   ffff80001030c7a8:       cbnz    w0, ffff80001030c690 <ext4_da_get_block_prep+0x80>
         : 1753             down_read(&EXT4_I(inode)->i_data_sem);
    0.00 :   ffff80001030c7ac:       sub     x20, x21, #0x140
    0.00 :   ffff80001030c7b0:       add     x24, x20, #0xf0
    0.00 :   ffff80001030c7b4:       mov     x0, x24
    0.00 :   ffff80001030c7b8:       bl      ffff800010e31a00 <down_read>
         : 1758             test_bit():
    0.00 :   ffff80001030c7bc:       ldur    x0, [x21, #-240]
         : 107              ext4_has_inline_data():
         : 3566             int *retval);
         : 3567             extern int ext4_inline_data_fiemap(struct inode *inode,
         : 3568             struct fiemap_extent_info *fieinfo,
         : 3569             int *has_inline, __u64 start, __u64 len);
         :
         : 3571             struct iomap;
    0.00 :   ffff80001030c7c0:       tst     w0, #0x10000000
    0.00 :   ffff80001030c7c4:       b.eq    ffff80001030c7d8 <ext4_da_get_block_prep+0x1c8>  // b.none
    0.00 :   ffff80001030c7c8:       ldrh    w0, [x21, #714]
    0.00 :   ffff80001030c7cc:       cbz     w0, ffff80001030c7d8 <ext4_da_get_block_prep+0x1c8>
    0.00 :   ffff80001030c7d0:       str     x25, [sp, #64]
    0.00 :   ffff80001030c7d4:       b       ffff80001030c858 <ext4_da_get_block_prep+0x248>
         : 3578             test_bit():
    0.00 :   ffff80001030c7d8:       ldur    x0, [x21, #-240]
         : 107              ext4_da_map_blocks():
         : 1757             retval = ext4_ext_map_blocks(NULL, inode, map, 0);
    0.00 :   ffff80001030c7dc:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001030c7e0:       add     x2, sp, #0x58
    0.00 :   ffff80001030c7e4:       mov     x1, x21
         : 1756             else if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))
    0.00 :   ffff80001030c7e8:       tst     w0, #0x80000
         : 1757             retval = ext4_ext_map_blocks(NULL, inode, map, 0);
    0.00 :   ffff80001030c7ec:       mov     x0, #0x0                        // #0
         : 1756             else if (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))
    0.00 :   ffff80001030c7f0:       b.ne    ffff80001030c8f0 <ext4_da_get_block_prep+0x2e0>  // b.any
         : 1759             retval = ext4_ind_map_blocks(NULL, inode, map, 0);
    0.00 :   ffff80001030c7f4:       bl      ffff8000103053e8 <ext4_ind_map_blocks>
    0.00 :   ffff80001030c7f8:       mov     w20, w0
         : 1762             if (retval == 0) {
    0.00 :   ffff80001030c7fc:       cmp     w20, #0x0
    0.00 :   ffff80001030c800:       b.eq    ffff80001030c7d0 <ext4_da_get_block_prep+0x1c0>  // b.none
         : 1779             } else if (retval > 0) {
    0.00 :   ffff80001030c804:       b.le    ffff80001030c83c <ext4_da_get_block_prep+0x22c>
         : 1783             if (unlikely(retval != map->m_len)) {
    0.00 :   ffff80001030c808:       ldr     w6, [sp, #100]
    0.00 :   ffff80001030c80c:       mov     w2, w20
    0.00 :   ffff80001030c810:       cmp     w6, w20
    0.00 :   ffff80001030c814:       b.ne    ffff80001030caf0 <ext4_da_get_block_prep+0x4e0>  // b.any
         : 1792             EXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;
    0.00 :   ffff80001030c818:       ldr     w4, [sp, #104]
         : 1793             ret = ext4_es_insert_extent(inode, map->m_lblk, map->m_len,
    0.00 :   ffff80001030c81c:       mov     x0, x21
    0.00 :   ffff80001030c820:       ldr     w1, [sp, #96]
    0.00 :   ffff80001030c824:       ldr     x3, [sp, #88]
         : 1792             EXTENT_STATUS_UNWRITTEN : EXTENT_STATUS_WRITTEN;
    0.00 :   ffff80001030c828:       ubfx    x4, x4, #11, #1
         : 1793             ret = ext4_es_insert_extent(inode, map->m_lblk, map->m_len,
    0.00 :   ffff80001030c82c:       add     w4, w4, #0x1
    0.00 :   ffff80001030c830:       bl      ffff8000102fcd30 <ext4_es_insert_extent>
         : 1795             if (ret != 0)
    0.00 :   ffff80001030c834:       cmp     w0, #0x0
    0.00 :   ffff80001030c838:       csel    w20, w20, w0, eq  // eq = none
         : 1800             up_read((&EXT4_I(inode)->i_data_sem));
    0.00 :   ffff80001030c83c:       mov     x0, x24
    0.00 :   ffff80001030c840:       bl      ffff8000100d9768 <up_read>
         : 1802             return retval;
    0.00 :   ffff80001030c844:       b       ffff80001030c6e4 <ext4_da_get_block_prep+0xd4>
         : 1716             down_read(&EXT4_I(inode)->i_data_sem);
    0.00 :   ffff80001030c848:       sub     x24, x21, #0x50
    0.00 :   ffff80001030c84c:       str     x25, [sp, #64]
    0.00 :   ffff80001030c850:       mov     x0, x24
    0.00 :   ffff80001030c854:       bl      ffff800010e31a00 <down_read>
         : 1721             ext4_insert_delayed_block():
         : 1640             struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff80001030c858:       ldr     x0, [x21, #40]
         : 1642             ext4_da_map_blocks():
         : 1770             ret = ext4_insert_delayed_block(inode, map->m_lblk);
    0.00 :   ffff80001030c85c:       ldr     w25, [sp, #96]
         : 1772             ext4_insert_delayed_block():
         : 1640             struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff80001030c860:       ldr     x20, [x0, #880]
         : 1655             if (sbi->s_cluster_ratio == 1) {
    0.00 :   ffff80001030c864:       ldr     w0, [x20, #80]
    0.00 :   ffff80001030c868:       cmp     w0, #0x1
    0.00 :   ffff80001030c86c:       b.eq    ffff80001030c988 <ext4_da_get_block_prep+0x378>  // b.none
         : 1660             if (!ext4_es_scan_clu(inode, &ext4_es_is_delonly, lblk)) {
    0.00 :   ffff80001030c870:       adrp    x1, ffff80001030b000 <ext4_convert_inline_data+0x700>
    0.00 :   ffff80001030c874:       mov     w2, w25
    0.00 :   ffff80001030c878:       add     x1, x1, #0xd8
    0.00 :   ffff80001030c87c:       mov     x0, x21
    0.00 :   ffff80001030c880:       bl      ffff8000102fcca0 <ext4_es_scan_clu>
    0.00 :   ffff80001030c884:       tst     w0, #0xff
    0.00 :   ffff80001030c888:       b.eq    ffff80001030c92c <ext4_da_get_block_prep+0x31c>  // b.none
         : 1642             bool allocated = false;
    0.00 :   ffff80001030c88c:       mov     w2, #0x0                        // #0
         : 1680             ret = ext4_es_insert_delayed_block(inode, lblk, allocated);
    0.00 :   ffff80001030c890:       mov     w1, w25
    0.00 :   ffff80001030c894:       mov     x0, x21
    0.00 :   ffff80001030c898:       bl      ffff8000102fd968 <ext4_es_insert_delayed_block>
    0.00 :   ffff80001030c89c:       mov     w20, w0
         : 1685             ext4_da_map_blocks():
         : 1771             if (ret != 0) {
    0.00 :   ffff80001030c8a0:       cbnz    w0, ffff80001030c998 <ext4_da_get_block_prep+0x388>
         : 1773             test_bit():
    0.00 :   ffff80001030c8a4:       ldr     x0, [x19]
         : 107              ext4_da_map_blocks():
         : 1776             map_bh(bh, inode->i_sb, invalid_block);
    0.00 :   ffff80001030c8a8:       ldr     x1, [x21, #40]
         : 1778             set_buffer_mapped():
    0.00 :   ffff80001030c8ac:       tst     w0, #0x10
    0.00 :   ffff80001030c8b0:       b.eq    ffff80001030ca68 <ext4_da_get_block_prep+0x458>  // b.none
         : 128              map_bh():
         : 347              bh->b_bdev = sb->s_bdev;
    0.00 :   ffff80001030c8b4:       ldr     x0, [x1, #200]
         : 348              bh->b_blocknr = block;
    0.00 :   ffff80001030c8b8:       str     x23, [x19, #24]
         : 347              bh->b_bdev = sb->s_bdev;
    0.00 :   ffff80001030c8bc:       str     x0, [x19, #48]
         : 349              test_bit():
    0.00 :   ffff80001030c8c0:       ldr     x0, [x19]
         : 107              map_bh():
         : 349              bh->b_size = sb->s_blocksize;
    0.00 :   ffff80001030c8c4:       ldr     x1, [x1, #24]
    0.00 :   ffff80001030c8c8:       str     x1, [x19, #32]
         : 352              set_buffer_new():
         : 127              BUFFER_FNS(New, new)
    0.00 :   ffff80001030c8cc:       tst     w0, #0x20
    0.00 :   ffff80001030c8d0:       b.eq    ffff80001030ca50 <ext4_da_get_block_prep+0x440>  // b.none
         : 130              test_bit():
    0.00 :   ffff80001030c8d4:       ldr     x0, [x19]
         : 107              set_buffer_delay():
         : 130              BUFFER_FNS(Delay, delay)
    0.00 :   ffff80001030c8d8:       tst     w0, #0x100
    0.00 :   ffff80001030c8dc:       b.eq    ffff80001030ca34 <ext4_da_get_block_prep+0x424>  // b.none
         : 133              ext4_da_map_blocks():
         : 1800             up_read((&EXT4_I(inode)->i_data_sem));
    0.00 :   ffff80001030c8e0:       mov     x0, x24
    0.00 :   ffff80001030c8e4:       bl      ffff8000100d9768 <up_read>
         : 1803             ext4_da_get_block_prep():
         : 1835             if (ret <= 0)
    0.00 :   ffff80001030c8e8:       ldr     x25, [sp, #64]
    0.00 :   ffff80001030c8ec:       b       ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 1838             ext4_da_map_blocks():
         : 1757             retval = ext4_ext_map_blocks(NULL, inode, map, 0);
    0.00 :   ffff80001030c8f0:       bl      ffff8000102f8660 <ext4_ext_map_blocks>
    0.00 :   ffff80001030c8f4:       mov     w20, w0
    0.00 :   ffff80001030c8f8:       b       ffff80001030c7fc <ext4_da_get_block_prep+0x1ec>
         : 1761             arch_atomic64_or():
         : 65               {                                                                       \
         : 66               __lse_ll_sc_body(op, i, v);                                     \
         : 67               }
         :
         : 69               ATOMIC64_OP(atomic64_andnot)
         : 70               ATOMIC64_OP(atomic64_or)
    0.00 :   ffff80001030c8fc:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030c900:       tst     w0, #0xff
    0.00 :   ffff80001030c904:       b.eq    ffff80001030ca2c <ext4_da_get_block_prep+0x41c>  // b.none
         : 74               __lse_atomic64_or():
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
    0.00 :   ffff80001030c908:       mov     x0, #0x10                       // #16
    0.00 :   ffff80001030c90c:       stset   x0, [x19]
    0.00 :   ffff80001030c910:       b       ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 186              arch_atomic64_or():
    0.00 :   ffff80001030c914:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030c918:       tst     w0, #0xff
    0.00 :   ffff80001030c91c:       b.eq    ffff80001030ca24 <ext4_da_get_block_prep+0x414>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030c920:       mov     x0, #0x20                       // #32
    0.00 :   ffff80001030c924:       stset   x0, [x19]
    0.00 :   ffff80001030c928:       b       ffff80001030c738 <ext4_da_get_block_prep+0x128>
         : 180              ext4_insert_delayed_block():
         : 1661             if (!ext4_es_scan_clu(inode,
    0.00 :   ffff80001030c92c:       adrp    x1, ffff80001030b000 <ext4_convert_inline_data+0x700>
    0.00 :   ffff80001030c930:       mov     w2, w25
    0.00 :   ffff80001030c934:       add     x1, x1, #0xc0
    0.00 :   ffff80001030c938:       mov     x0, x21
    0.00 :   ffff80001030c93c:       bl      ffff8000102fcca0 <ext4_es_scan_clu>
    0.00 :   ffff80001030c940:       tst     w0, #0xff
    0.00 :   ffff80001030c944:       b.eq    ffff80001030c968 <ext4_da_get_block_prep+0x358>  // b.none
         : 1675             allocated = true;
    0.00 :   ffff80001030c948:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001030c94c:       b       ffff80001030c890 <ext4_da_get_block_prep+0x280>
         : 1678             arch_atomic64_or():
    0.00 :   ffff80001030c950:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030c954:       tst     w0, #0xff
    0.00 :   ffff80001030c958:       b.eq    ffff80001030c9c8 <ext4_da_get_block_prep+0x3b8>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030c95c:       mov     x0, #0x10                       // #16
    0.00 :   ffff80001030c960:       stset   x0, [x19]
    0.00 :   ffff80001030c964:       b       ffff80001030c700 <ext4_da_get_block_prep+0xf0>
         : 180              ext4_insert_delayed_block():
         : 1663             ret = ext4_clu_mapped(inode,
    0.00 :   ffff80001030c968:       ldr     w1, [x20, #84]
    0.00 :   ffff80001030c96c:       mov     x0, x21
    0.00 :   ffff80001030c970:       lsr     w1, w25, w1
    0.00 :   ffff80001030c974:       bl      ffff8000102faab0 <ext4_clu_mapped>
    0.00 :   ffff80001030c978:       mov     w20, w0
         : 1665             if (ret < 0)
    0.00 :   ffff80001030c97c:       cmp     w0, #0x0
    0.00 :   ffff80001030c980:       b.lt    ffff80001030c998 <ext4_da_get_block_prep+0x388>  // b.tstop
         : 1667             if (ret == 0) {
    0.00 :   ffff80001030c984:       b.ne    ffff80001030c948 <ext4_da_get_block_prep+0x338>  // b.any
         : 1656             ret = ext4_da_reserve_space(inode);
    0.00 :   ffff80001030c988:       mov     x0, x21
    0.00 :   ffff80001030c98c:       bl      ffff80001030b188 <ext4_da_reserve_space>
    0.00 :   ffff80001030c990:       mov     w20, w0
         : 1657             if (ret != 0)   /* ENOSPC */
    0.00 :   ffff80001030c994:       cbz     w0, ffff80001030c88c <ext4_da_get_block_prep+0x27c>
    0.00 :   ffff80001030c998:       ldr     x25, [sp, #64]
    0.00 :   ffff80001030c99c:       b       ffff80001030c83c <ext4_da_get_block_prep+0x22c>
         : 1661             ext4_da_map_blocks():
         : 1737             map->m_flags |= EXT4_MAP_MAPPED;
    0.00 :   ffff80001030c9a0:       ldr     w0, [sp, #104]
    0.00 :   ffff80001030c9a4:       orr     w0, w0, #0x10
    0.00 :   ffff80001030c9a8:       str     w0, [sp, #104]
    0.00 :   ffff80001030c9ac:       b       ffff80001030c6e4 <ext4_da_get_block_prep+0xd4>
    0.00 :   ffff80001030c9b0:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001030c9b4:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001030c9b8:       str     x25, [sp, #64]
         : 1745             ext4_da_get_block_prep():
         : 1823             BUG_ON(create == 0);
    0.00 :   ffff80001030c9bc:       brk     #0x800
    0.00 :   ffff80001030c9c0:       str     x25, [sp, #64]
         : 1824             BUG_ON(bh->b_size != inode->i_sb->s_blocksize);
    0.00 :   ffff80001030c9c4:       brk     #0x800
         : 1826             __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001030c9c8:       b       ffff800010315898 <ext4_filemap_fault+0x148>
    0.00 :   ffff80001030c9cc:       b       ffff80001030c700 <ext4_da_get_block_prep+0xf0>
         : 230              test_bit():
    0.00 :   ffff80001030c9d0:       ldr     x0, [x19]
         : 107              ext4_da_map_blocks():
         : 1725             map_bh(bh, inode->i_sb, invalid_block);
    0.00 :   ffff80001030c9d4:       ldr     x1, [x21, #40]
         : 1727             set_buffer_mapped():
         : 126              BUFFER_FNS(Mapped, mapped)
    0.00 :   ffff80001030c9d8:       tst     w0, #0x10
    0.00 :   ffff80001030c9dc:       b.eq    ffff80001030cac0 <ext4_da_get_block_prep+0x4b0>  // b.none
         : 129              map_bh():
         : 347              bh->b_bdev = sb->s_bdev;
    0.00 :   ffff80001030c9e0:       ldr     x0, [x1, #200]
         : 348              bh->b_blocknr = block;
    0.00 :   ffff80001030c9e4:       str     x23, [x19, #24]
         : 347              bh->b_bdev = sb->s_bdev;
    0.00 :   ffff80001030c9e8:       str     x0, [x19, #48]
         : 349              test_bit():
    0.00 :   ffff80001030c9ec:       ldr     x0, [x19]
         : 107              map_bh():
         : 349              bh->b_size = sb->s_blocksize;
    0.00 :   ffff80001030c9f0:       ldr     x1, [x1, #24]
    0.00 :   ffff80001030c9f4:       str     x1, [x19, #32]
         : 352              set_buffer_new():
         : 127              BUFFER_FNS(New, new)
    0.00 :   ffff80001030c9f8:       tst     w0, #0x20
    0.00 :   ffff80001030c9fc:       b.eq    ffff80001030caa8 <ext4_da_get_block_prep+0x498>  // b.none
         : 130              test_bit():
    0.00 :   ffff80001030ca00:       ldr     x20, [x19]
    0.00 :   ffff80001030ca04:       ubfx    w20, w20, #8, #1
         : 108              set_buffer_delay():
         : 130              BUFFER_FNS(Delay, delay)
    0.00 :   ffff80001030ca08:       cbnz    w20, ffff80001030c744 <ext4_da_get_block_prep+0x134>
         : 132              arch_atomic64_or():
    0.00 :   ffff80001030ca0c:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030ca10:       tst     w0, #0xff
    0.00 :   ffff80001030ca14:       b.eq    ffff80001030cae8 <ext4_da_get_block_prep+0x4d8>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030ca18:       mov     x0, #0x100                      // #256
    0.00 :   ffff80001030ca1c:       stset   x0, [x19]
         : 179              ext4_da_get_block_prep():
         : 1835             if (ret <= 0)
    0.00 :   ffff80001030ca20:       b       ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 1837             __ll_sc_atomic64_or():
    0.00 :   ffff80001030ca24:       b       ffff8000103158b0 <ext4_filemap_fault+0x160>
    0.00 :   ffff80001030ca28:       b       ffff80001030c738 <ext4_da_get_block_prep+0x128>
    0.00 :   ffff80001030ca2c:       b       ffff8000103158c8 <ext4_filemap_fault+0x178>
    0.00 :   ffff80001030ca30:       b       ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 226              arch_atomic64_or():
    0.00 :   ffff80001030ca34:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030ca38:       tst     w0, #0xff
    0.00 :   ffff80001030ca3c:       b.eq    ffff80001030ca80 <ext4_da_get_block_prep+0x470>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030ca40:       mov     x0, #0x100                      // #256
    0.00 :   ffff80001030ca44:       stset   x0, [x19]
         : 179              ext4_da_map_blocks():
         : 1800             up_read((&EXT4_I(inode)->i_data_sem));
    0.00 :   ffff80001030ca48:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001030ca4c:       b       ffff80001030c8e0 <ext4_da_get_block_prep+0x2d0>
         : 1803             arch_atomic64_or():
    0.00 :   ffff80001030ca50:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030ca54:       tst     w0, #0xff
    0.00 :   ffff80001030ca58:       b.eq    ffff80001030ca98 <ext4_da_get_block_prep+0x488>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030ca5c:       mov     x0, #0x20                       // #32
    0.00 :   ffff80001030ca60:       stset   x0, [x19]
    0.00 :   ffff80001030ca64:       b       ffff80001030c8d4 <ext4_da_get_block_prep+0x2c4>
         : 180              arch_atomic64_or():
    0.00 :   ffff80001030ca68:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030ca6c:       tst     w0, #0xff
    0.00 :   ffff80001030ca70:       b.eq    ffff80001030caa0 <ext4_da_get_block_prep+0x490>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030ca74:       mov     x0, #0x10                       // #16
    0.00 :   ffff80001030ca78:       stset   x0, [x19]
    0.00 :   ffff80001030ca7c:       b       ffff80001030c8b4 <ext4_da_get_block_prep+0x2a4>
         : 180              __ll_sc_atomic64_or():
    0.00 :   ffff80001030ca80:       b       ffff8000103158e0 <ext4_filemap_fault+0x190>
         : 223              ext4_da_map_blocks():
    0.00 :   ffff80001030ca84:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001030ca88:       mov     x0, x24
    0.00 :   ffff80001030ca8c:       bl      ffff8000100d9768 <up_read>
         : 1803             ext4_da_get_block_prep():
         : 1835             if (ret <= 0)
    0.00 :   ffff80001030ca90:       ldr     x25, [sp, #64]
    0.00 :   ffff80001030ca94:       b       ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 1838             __ll_sc_atomic64_or():
    0.00 :   ffff80001030ca98:       b       ffff8000103158f8 <ext4_filemap_fault+0x1a8>
    0.00 :   ffff80001030ca9c:       b       ffff80001030c8d4 <ext4_da_get_block_prep+0x2c4>
    0.00 :   ffff80001030caa0:       b       ffff800010315910 <ext4_filemap_fault+0x1c0>
    0.00 :   ffff80001030caa4:       b       ffff80001030c8b4 <ext4_da_get_block_prep+0x2a4>
         : 226              arch_atomic64_or():
    0.00 :   ffff80001030caa8:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030caac:       tst     w0, #0xff
    0.00 :   ffff80001030cab0:       b.eq    ffff80001030cad8 <ext4_da_get_block_prep+0x4c8>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030cab4:       mov     x0, #0x20                       // #32
    0.00 :   ffff80001030cab8:       stset   x0, [x19]
    0.00 :   ffff80001030cabc:       b       ffff80001030ca00 <ext4_da_get_block_prep+0x3f0>
         : 180              arch_atomic64_or():
    0.00 :   ffff80001030cac0:       bl      ffff80001030b080 <system_uses_lse_atomics>
    0.00 :   ffff80001030cac4:       tst     w0, #0xff
    0.00 :   ffff80001030cac8:       b.eq    ffff80001030cae0 <ext4_da_get_block_prep+0x4d0>  // b.none
         : 68               __lse_atomic64_or():
    0.00 :   ffff80001030cacc:       mov     x0, #0x10                       // #16
    0.00 :   ffff80001030cad0:       stset   x0, [x19]
    0.00 :   ffff80001030cad4:       b       ffff80001030c9e0 <ext4_da_get_block_prep+0x3d0>
         : 180              __ll_sc_atomic64_or():
    0.00 :   ffff80001030cad8:       b       ffff800010315928 <ext4_filemap_fault+0x1d8>
    0.00 :   ffff80001030cadc:       b       ffff80001030ca00 <ext4_da_get_block_prep+0x3f0>
    0.00 :   ffff80001030cae0:       b       ffff800010315940 <ext4_filemap_fault+0x1f0>
    0.00 :   ffff80001030cae4:       b       ffff80001030c9e0 <ext4_da_get_block_prep+0x3d0>
    0.00 :   ffff80001030cae8:       b       ffff800010315958 <ext4_filemap_fault+0x208>
         : 227              ext4_da_get_block_prep():
    0.00 :   ffff80001030caec:       b       ffff80001030c748 <ext4_da_get_block_prep+0x138>
         : 1836             ext4_da_map_blocks():
         : 1784             ext4_warning(inode->i_sb,
    0.00 :   ffff80001030caf0:       ldr     x0, [x21, #40]
    0.00 :   ffff80001030caf4:       adrp    x1, ffff800010e8a000 <__func__.49343+0x10>
    0.00 :   ffff80001030caf8:       ldr     x4, [x21, #64]
    0.00 :   ffff80001030cafc:       add     x1, x1, #0x30
    0.00 :   ffff80001030cb00:       add     x1, x1, #0x60
    0.00 :   ffff80001030cb04:       mov     w5, w20
    0.00 :   ffff80001030cb08:       mov     w2, #0x6fb                      // #1787
    0.00 :   ffff80001030cb0c:       adrp    x3, ffff800011432000 <kallsyms_token_index+0x277a0>
    0.00 :   ffff80001030cb10:       add     x3, x3, #0xa50
    0.00 :   ffff80001030cb14:       bl      ffff800010339640 <__ext4_warning>
         : 1788             WARN_ON(1);
    0.00 :   ffff80001030cb18:       brk     #0x800
    0.00 :   ffff80001030cb1c:       ldr     w2, [sp, #100]
    0.00 :   ffff80001030cb20:       b       ffff80001030c818 <ext4_da_get_block_prep+0x208>
    0.00 :   ffff80001030cb24:       str     x25, [sp, #64]
         : 1793             ext4_da_get_block_prep():
         : 1852             }
    0.00 :   ffff80001030cb28:       bl      ffff800010e2b8c8 <__stack_chk_fail>
    0.00 :   ffff80001030cb2c:       str     x25, [sp, #64]
         : 1855             ext4_da_map_blocks():
         : 1741             BUG();
    0.00 :   ffff80001030cb30:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010111460 <ktime_get_coarse_real_ts64>:
         : 6                ktime_get_coarse_real_ts64():
         : 2235             }
         : 2236             EXPORT_SYMBOL_GPL(getboottime64);
         :
         : 2238             void ktime_get_coarse_real_ts64(struct timespec64 *ts)
         : 2239             {
         : 2240             struct timekeeper *tk = &tk_core.timekeeper;
    0.00 :   ffff800010111460:       adrp    x1, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff800010111464:       add     x1, x1, #0xf00
         : 2234             {
    0.00 :   ffff800010111468:       paciasp
    0.00 :   ffff80001011146c:       nop
         : 2237             __seqprop_raw_spinlock_sequence():
         : 276              lockdep_assert_preemption_disabled();
         : 277              }
         :
         : 279              #define __SEQ_RT        IS_ENABLED(CONFIG_PREEMPT_RT)
         :
         : 281              SEQCOUNT_LOCKNAME(raw_spinlock, raw_spinlock_t,  false,    s->lock,        raw_spin, raw_spin_lock(s->lock))
    0.00 :   ffff800010111470:       ldr     w2, [x1]
         : 283              ktime_get_coarse_real_ts64():
         : 2239             unsigned int seq;
         :
         : 2241             do {
         : 2242             seq = read_seqcount_begin(&tk_core.seq);
    0.00 :   ffff800010111474:       tbnz    w2, #0, ffff8000101114a8 <ktime_get_coarse_real_ts64+0x48>
    0.00 :   ffff800010111478:       dmb     ishld
         : 2240             tk_xtime():
         : 132              ts.tv_nsec = (long)(tk->tkr_mono.xtime_nsec >> tk->tkr_mono.shift);
    0.00 :   ffff80001011147c:       ldr     x3, [x1, #40]
    0.00 :   ffff800010111480:       ldr     w4, [x1, #36]
         : 135              ktime_get_coarse_real_ts64():
         :
         : 2242             *ts = tk_xtime(tk);
    0.00 :   ffff800010111484:       ldr     x5, [x1, #120]
         : 2244             tk_xtime():
         : 132              ts.tv_nsec = (long)(tk->tkr_mono.xtime_nsec >> tk->tkr_mono.shift);
    0.00 :   ffff800010111488:       lsr     x3, x3, x4
         : 134              ktime_get_coarse_real_ts64():
         : 2241             *ts = tk_xtime(tk);
    0.00 :   ffff80001011148c:       stp     x5, x3, [x0]
         : 2243             do_read_seqcount_retry():
         : 452              #define read_seqcount_retry(s, start)                                   \
         : 453              do_read_seqcount_retry(seqprop_ptr(s), start)
         :
         : 455              static inline int do_read_seqcount_retry(const seqcount_t *s, unsigned start)
         : 456              {
         : 457              smp_rmb();
    0.00 :   ffff800010111490:       dmb     ishld
         : 459              do___read_seqcount_retry():
         : 433              return unlikely(READ_ONCE(s->sequence) != start);
  100.00 :   ffff800010111494:       ldr     w3, [x1]
         : 435              ktime_get_coarse_real_ts64():
         : 2242             } while (read_seqcount_retry(&tk_core.seq, seq));
    0.00 :   ffff800010111498:       cmp     w2, w3
    0.00 :   ffff80001011149c:       b.ne    ffff800010111470 <ktime_get_coarse_real_ts64+0x10>  // b.any
         : 2243             }
    0.00 :   ffff8000101114a0:       autiasp
    0.00 :   ffff8000101114a4:       ret
         : 2246             cpu_relax():
         :
         : 13               #ifndef __ASSEMBLY__
         :
         : 15               static inline void cpu_relax(void)
         : 16               {
         : 17               asm volatile("yield" ::: "memory");
    0.00 :   ffff8000101114a8:       yield
    0.00 :   ffff8000101114ac:       b       ffff800010111470 <ktime_get_coarse_real_ts64+0x10>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101886d8 <wait_for_stable_page>:
         : 6                compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff8000101886d8:       ldr     x1, [x0, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff8000101886dc:       sub     x2, x1, #0x1
    0.00 :   ffff8000101886e0:       tst     x1, #0x1
    0.00 :   ffff8000101886e4:       csel    x0, x2, x0, ne  // ne = any
         : 193              wait_for_stable_page():
         : 2860             * @page:        The page to wait on.
         : 2861             *
         : 2862             * This function determines if the given page is related to a backing device
         : 2863             * that requires page contents to be held stable during writeback.  If so, then
         : 2864             * it will wait for any pending writeback to complete.
         : 2865             */
    0.00 :   ffff8000101886e8:       ldr     x1, [x0, #24]
    0.00 :   ffff8000101886ec:       ldr     x1, [x1]
    0.00 :   ffff8000101886f0:       ldr     x1, [x1, #40]
  100.00 :   ffff8000101886f4:       ldr     x1, [x1, #88]
    0.00 :   ffff8000101886f8:       tbnz    w1, #3, ffff800010188700 <wait_for_stable_page+0x28>
    0.00 :   ffff8000101886fc:       ret
         : 2858             * that requires page contents to be held stable during writeback.  If so, then
    0.00 :   ffff800010188700:       paciasp
    0.00 :   ffff800010188704:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010188708:       mov     x29, sp
         : 2861             void wait_for_stable_page(struct page *page)
    0.00 :   ffff80001018870c:       bl      ffff800010188680 <wait_on_page_writeback>
         : 2862             {
    0.00 :   ffff800010188710:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010188714:       autiasp
    0.00 :   ffff800010188718:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e34d10 <_raw_read_unlock>:
         : 6                _raw_read_unlock():
         : 254              EXPORT_SYMBOL(_raw_read_lock_bh);
         : 255              #endif
         :
         : 257              #ifndef CONFIG_INLINE_READ_UNLOCK
         : 258              void __lockfunc _raw_read_unlock(rwlock_t *lock)
         : 259              {
    0.00 :   ffff800010e34d10:       paciasp
    0.00 :   ffff800010e34d14:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e34d18:       mov     x29, sp
         : 263              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e34d1c:       b       ffff800010e34d58 <_raw_read_unlock+0x48>
    0.00 :   ffff800010e34d20:       b       ffff800010e34d58 <_raw_read_unlock+0x48>
         : 46               __lse_atomic_sub_return_release():
         : 140              return i;                                                       \
         : 141              }
         :
         : 143              ATOMIC_OP_SUB_RETURN(_relaxed,   )
         : 144              ATOMIC_OP_SUB_RETURN(_acquire,  a, "memory")
         : 145              ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
    0.00 :   ffff800010e34d24:       mov     w1, #0x200                      // #512
    0.00 :   ffff800010e34d28:       neg     w1, w1
    0.00 :   ffff800010e34d2c:       ldaddl  w1, w2, [x0]
  100.00 :   ffff800010e34d30:       add     w1, w1, w2
         : 150              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e34d34:       mrs     x1, sp_el0
         : 26               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34d38:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e34d3c:       sub     x0, x0, #0x1
    0.00 :   ffff800010e34d40:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34d44:       cbnz    x0, ffff800010e34d74 <_raw_read_unlock+0x64>
         : 80               __raw_read_unlock():
         :
         : 228              static inline void __raw_read_unlock(rwlock_t *lock)
         : 229              {
         : 230              rwlock_release(&lock->dep_map, _RET_IP_);
         : 231              do_raw_read_unlock(lock);
         : 232              preempt_enable();
    0.00 :   ffff800010e34d48:       bl      ffff800010e2e620 <preempt_schedule>
         : 234              _raw_read_unlock():
         : 256              __raw_read_unlock(lock);
         : 257              }
    0.00 :   ffff800010e34d4c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e34d50:       autiasp
    0.00 :   ffff800010e34d54:       ret
         : 261              __ll_sc_atomic_sub_return_release():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff800010e34d58:       mov     w1, #0x200                      // #512
    0.00 :   ffff800010e34d5c:       b       ffff800010e357d4 <_raw_read_lock_irqsave+0xdc>
         : 120              get_current():
    0.00 :   ffff800010e34d60:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34d64:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e34d68:       sub     x0, x0, #0x1
    0.00 :   ffff800010e34d6c:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34d70:       cbz     x0, ffff800010e34d48 <_raw_read_unlock+0x38>
    0.00 :   ffff800010e34d74:       ldr     x0, [x1, #8]
    0.00 :   ffff800010e34d78:       cbnz    x0, ffff800010e34d4c <_raw_read_unlock+0x3c>
         : 77               __raw_read_unlock():
    0.00 :   ffff800010e34d7c:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010e34d80:       b       ffff800010e34d4c <_raw_read_unlock+0x3c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010279928 <__set_page_dirty>:
         : 6                __set_page_dirty():
         : 602              *
         : 603              * The caller must hold lock_page_memcg().
         : 604              */
         : 605              void __set_page_dirty(struct page *page, struct address_space *mapping,
         : 606              int warn)
         : 607              {
    0.00 :   ffff800010279928:       paciasp
    0.00 :   ffff80001027992c:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010279930:       mov     x29, sp
    0.00 :   ffff800010279934:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010279938:       mov     x19, x0
         : 613              spinlock_check():
         : 329              * Map the spin_lock functions to the raw variants for PREEMPT_RT=n
         : 330              */
         :
         : 332              static __always_inline raw_spinlock_t *spinlock_check(spinlock_t *lock)
         : 333              {
         : 334              return &lock->rlock;
    0.00 :   ffff80001027993c:       add     x20, x1, #0x8
         : 336              __set_page_dirty():
         : 605              unsigned long flags;
         :
         : 607              xa_lock_irqsave(&mapping->i_pages, flags);
    0.00 :   ffff800010279940:       mov     x0, x20
         : 602              {
    0.00 :   ffff800010279944:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010279948:       mov     x21, x1
    0.00 :   ffff80001027994c:       str     x23, [sp, #48]
    0.00 :   ffff800010279950:       mov     w23, w2
         : 605              xa_lock_irqsave(&mapping->i_pages, flags);
    0.00 :   ffff800010279954:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff800010279958:       mov     x22, x0
         : 606              if (page->mapping) {    /* Race with truncate? */
  100.00 :   ffff80001027995c:       ldr     x0, [x19, #24]
    0.00 :   ffff800010279960:       cbz     x0, ffff8000102799c0 <__set_page_dirty+0x98>
         : 607              WARN_ON_ONCE(warn && !PageUptodate(page));
    0.00 :   ffff800010279964:       cbz     w23, ffff800010279988 <__set_page_dirty+0x60>
         : 609              compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010279968:       ldr     x1, [x19, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff80001027996c:       sub     x0, x1, #0x1
    0.00 :   ffff800010279970:       tst     x1, #0x1
    0.00 :   ffff800010279974:       csel    x0, x0, x19, ne  // ne = any
         : 193              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010279978:       ldr     x0, [x0]
         : 113              PageUptodate():
         :
         : 526              static inline int PageUptodate(struct page *page)
         : 527              {
         : 528              int ret;
         : 529              page = compound_head(page);
         : 530              ret = test_bit(PG_uptodate, &(page)->flags);
    0.00 :   ffff80001027997c:       tst     w0, #0x4
    0.00 :   ffff800010279980:       b.eq    ffff800010279a00 <__set_page_dirty+0xd8>  // b.none
         : 526              /*
    0.00 :   ffff800010279984:       dmb     ishld
         : 528              __set_page_dirty():
         : 608              account_page_dirtied(page, mapping);
    0.00 :   ffff800010279988:       mov     x1, x21
    0.00 :   ffff80001027998c:       mov     x0, x19
    0.00 :   ffff800010279990:       bl      ffff80001018b5c0 <account_page_dirtied>
         : 612              compound_head():
         : 184              {
    0.00 :   ffff800010279994:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010279998:       sub     x0, x1, #0x1
    0.00 :   ffff80001027999c:       tst     x1, #0x1
    0.00 :   ffff8000102799a0:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff8000102799a4:       ldr     x0, [x0]
         : 107              PageSwapCache():
         : 401              #ifdef CONFIG_THP_SWAP
    0.00 :   ffff8000102799a8:       tst     w0, #0x80000
    0.00 :   ffff8000102799ac:       b.ne    ffff8000102799e4 <__set_page_dirty+0xbc>  // b.any
         : 404              page_index():
         : 1657             static inline pgoff_t page_index(struct page *page)
         : 1658             {
         : 1659             if (unlikely(PageSwapCache(page)))
         : 1660             return __page_file_index(page);
         : 1661             return page->index;
         : 1662             }
    0.00 :   ffff8000102799b0:       ldr     x1, [x19, #32]
         : 1664             __set_page_dirty():
         : 609              __xa_set_mark(&mapping->i_pages, page_index(page),
    0.00 :   ffff8000102799b4:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000102799b8:       mov     x0, x20
    0.00 :   ffff8000102799bc:       bl      ffff8000104bef38 <__xa_set_mark>
         : 613              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff8000102799c0:       mov     x1, x22
    0.00 :   ffff8000102799c4:       mov     x0, x20
    0.00 :   ffff8000102799c8:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 418              __set_page_dirty():
         : 613              PAGECACHE_TAG_DIRTY);
         : 614              }
         : 615              xa_unlock_irqrestore(&mapping->i_pages, flags);
         : 616              }
    0.00 :   ffff8000102799cc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102799d0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102799d4:       ldr     x23, [sp, #48]
    0.00 :   ffff8000102799d8:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000102799dc:       autiasp
    0.00 :   ffff8000102799e0:       ret
         : 623              test_bit():
    0.00 :   ffff8000102799e4:       ldr     x0, [x19]
         : 107              PageSwapCache():
    0.00 :   ffff8000102799e8:       tst     w0, #0x400
    0.00 :   ffff8000102799ec:       b.eq    ffff8000102799b0 <__set_page_dirty+0x88>  // b.none
         : 403              page_index():
         : 1656             return page->index;
    0.00 :   ffff8000102799f0:       mov     x0, x19
    0.00 :   ffff8000102799f4:       bl      ffff8000101e7620 <__page_file_index>
    0.00 :   ffff8000102799f8:       mov     x1, x0
    0.00 :   ffff8000102799fc:       b       ffff8000102799b4 <__set_page_dirty+0x8c>
         : 1661             __set_page_dirty():
         : 607              WARN_ON_ONCE(warn && !PageUptodate(page));
    0.00 :   ffff800010279a00:       brk     #0x800
    0.00 :   ffff800010279a04:       b       ffff800010279988 <__set_page_dirty+0x60>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102fd0b0 <ext4_es_lookup_extent>:
         : 6                ext4_es_lookup_extent():
         : 919              * Return: 1 on found, 0 on not
         : 920              */
         : 921              int ext4_es_lookup_extent(struct inode *inode, ext4_lblk_t lblk,
         : 922              ext4_lblk_t *next_lblk,
         : 923              struct extent_status *es)
         : 924              {
    0.00 :   ffff8000102fd0b0:       paciasp
    0.00 :   ffff8000102fd0b4:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff8000102fd0b8:       mov     x29, sp
    0.00 :   ffff8000102fd0bc:       stp     x19, x20, [sp, #16]
         : 927              struct extent_status *es1 = NULL;
         : 928              struct rb_node *node;
         : 929              int found = 0;
         :
         : 931              if (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)
         : 932              return 0;
    0.00 :   ffff8000102fd0c0:       mov     w20, #0x0                       // #0
         : 926              if (EXT4_SB(inode->i_sb)->s_mount_state & EXT4_FC_REPLAY)
    0.00 :   ffff8000102fd0c4:       ldr     x4, [x0, #40]
    0.00 :   ffff8000102fd0c8:       ldr     x4, [x4, #880]
    0.00 :   ffff8000102fd0cc:       ldrh    w4, [x4, #168]
    0.00 :   ffff8000102fd0d0:       tbz     w4, #5, ffff8000102fd0e8 <ext4_es_lookup_extent+0x38>
         :
         : 988              read_unlock(&EXT4_I(inode)->i_es_lock);
         :
         : 990              trace_ext4_es_lookup_extent_exit(inode, es, found);
         : 991              return found;
         : 992              }
    0.00 :   ffff8000102fd0d4:       mov     w0, w20
    0.00 :   ffff8000102fd0d8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102fd0dc:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000102fd0e0:       autiasp
    0.00 :   ffff8000102fd0e4:       ret
         : 933              read_lock(&EXT4_I(inode)->i_es_lock);
    0.00 :   ffff8000102fd0e8:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000102fd0ec:       mov     x23, x3
    0.00 :   ffff8000102fd0f0:       add     x24, x0, #0x290
    0.00 :   ffff8000102fd0f4:       mov     w20, w1
    0.00 :   ffff8000102fd0f8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000102fd0fc:       mov     x21, x0
    0.00 :   ffff8000102fd100:       mov     x22, x2
    0.00 :   ffff8000102fd104:       mov     x0, x24
    0.00 :   ffff8000102fd108:       bl      ffff800010e352c0 <_raw_read_lock>
         : 936              es->es_lblk = es->es_len = es->es_pblk = 0;
    0.00 :   ffff8000102fd10c:       stp     xzr, xzr, [x23, #24]
         : 937              if (tree->cache_es) {
    0.00 :   ffff8000102fd110:       add     x0, x21, #0x200
    0.00 :   ffff8000102fd114:       ldr     x19, [x0, #136]
    0.00 :   ffff8000102fd118:       cbz     x19, ffff8000102fd1b8 <ext4_es_lookup_extent+0x108>
         : 939              if (in_range(lblk, es1->es_lblk, es1->es_len)) {
    0.00 :   ffff8000102fd11c:       ldr     w5, [x19, #24]
    0.00 :   ffff8000102fd120:       cmp     w5, w20
    0.00 :   ffff8000102fd124:       b.hi    ffff8000102fd1b8 <ext4_es_lookup_extent+0x108>  // b.pmore
    0.00 :   ffff8000102fd128:       ldr     w1, [x19, #28]
    0.00 :   ffff8000102fd12c:       add     w1, w5, w1
    0.00 :   ffff8000102fd130:       sub     w1, w1, #0x1
    0.00 :   ffff8000102fd134:       cmp     w1, w20
    0.00 :   ffff8000102fd138:       b.cc    ffff8000102fd1b8 <ext4_es_lookup_extent+0x108>  // b.lo, b.ul, b.last
         : 961              stats = &EXT4_SB(inode->i_sb)->s_es_stats;
    0.00 :   ffff8000102fd13c:       ldr     x0, [x21, #40]
    0.00 :   ffff8000102fd140:       ldr     x0, [x0, #880]
         : 964              es->es_lblk = es1->es_lblk;
  100.00 :   ffff8000102fd144:       str     w5, [x23, #24]
         : 965              es->es_len = es1->es_len;
    0.00 :   ffff8000102fd148:       ldr     w1, [x19, #28]
    0.00 :   ffff8000102fd14c:       str     w1, [x23, #28]
         : 966              es->es_pblk = es1->es_pblk;
    0.00 :   ffff8000102fd150:       ldr     x1, [x19, #32]
    0.00 :   ffff8000102fd154:       str     x1, [x23, #32]
         : 967              if (!ext4_es_is_referenced(es1))
    0.00 :   ffff8000102fd158:       tbnz    x1, #63, ffff8000102fd164 <ext4_es_lookup_extent+0xb4>
         : 969              ext4_es_set_referenced():
         : 194              return (ext4_es_is_delayed(es) && !ext4_es_is_unwritten(es));
         : 195              }
         :
         : 197              static inline void ext4_es_set_referenced(struct extent_status *es)
         : 198              {
         : 199              es->es_pblk |= ((ext4_fsblk_t)EXTENT_STATUS_REFERENCED) << ES_SHIFT;
    0.00 :   ffff8000102fd15c:       orr     x1, x1, #0x8000000000000000
    0.00 :   ffff8000102fd160:       str     x1, [x19, #32]
         : 202              percpu_counter_add():
         : 56               return __percpu_counter_compare(fbc, rhs, percpu_counter_batch);
         : 57               }
         :
         : 59               static inline void percpu_counter_add(struct percpu_counter *fbc, s64 amount)
         : 60               {
         : 61               percpu_counter_add_batch(fbc, amount, percpu_counter_batch);
    0.00 :   ffff8000102fd164:       adrp    x2, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
    0.00 :   ffff8000102fd168:       add     x0, x0, #0x4e0
    0.00 :   ffff8000102fd16c:       mov     x1, #0x1                        // #1
         : 65               ext4_es_lookup_extent():
    0.00 :   ffff8000102fd170:       mov     w20, #0x1                       // #1
         : 57               percpu_counter_add():
    0.00 :   ffff8000102fd174:       ldr     w2, [x2, #656]
    0.00 :   ffff8000102fd178:       bl      ffff800010495ba0 <percpu_counter_add_batch>
         : 58               ext4_es_lookup_extent():
         : 970              if (next_lblk) {
    0.00 :   ffff8000102fd17c:       cbz     x22, ffff8000102fd194 <ext4_es_lookup_extent+0xe4>
         : 971              node = rb_next(&es1->rb_node);
    0.00 :   ffff8000102fd180:       mov     x0, x19
    0.00 :   ffff8000102fd184:       bl      ffff8000104b3d50 <rb_next>
         : 972              if (node) {
    0.00 :   ffff8000102fd188:       cbz     x0, ffff8000102fd224 <ext4_es_lookup_extent+0x174>
         : 975              *next_lblk = es1->es_lblk;
    0.00 :   ffff8000102fd18c:       ldr     w0, [x0, #24]
    0.00 :   ffff8000102fd190:       str     w0, [x22]
         : 983              read_unlock(&EXT4_I(inode)->i_es_lock);
    0.00 :   ffff8000102fd194:       mov     x0, x24
    0.00 :   ffff8000102fd198:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 987              }
    0.00 :   ffff8000102fd19c:       mov     w0, w20
    0.00 :   ffff8000102fd1a0:       ldp     x19, x20, [sp, #16]
         : 986              return found;
    0.00 :   ffff8000102fd1a4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102fd1a8:       ldp     x23, x24, [sp, #48]
         : 987              }
    0.00 :   ffff8000102fd1ac:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000102fd1b0:       autiasp
    0.00 :   ffff8000102fd1b4:       ret
         : 947              node = tree->root.rb_node;
    0.00 :   ffff8000102fd1b8:       ldr     x19, [x0, #128]
    0.00 :   ffff8000102fd1bc:       nop
         : 948              while (node) {
    0.00 :   ffff8000102fd1c0:       cbz     x19, ffff8000102fd1d8 <ext4_es_lookup_extent+0x128>
         : 950              if (lblk < es1->es_lblk)
    0.00 :   ffff8000102fd1c4:       ldr     w5, [x19, #24]
    0.00 :   ffff8000102fd1c8:       cmp     w5, w20
    0.00 :   ffff8000102fd1cc:       b.ls    ffff8000102fd1fc <ext4_es_lookup_extent+0x14c>  // b.plast
         : 951              node = node->rb_left;
    0.00 :   ffff8000102fd1d0:       ldr     x19, [x19, #16]
         : 948              while (node) {
    0.00 :   ffff8000102fd1d4:       cbnz    x19, ffff8000102fd1c4 <ext4_es_lookup_extent+0x114>
         : 961              stats = &EXT4_SB(inode->i_sb)->s_es_stats;
    0.00 :   ffff8000102fd1d8:       ldr     x0, [x21, #40]
         : 963              percpu_counter_add():
    0.00 :   ffff8000102fd1dc:       adrp    x2, ffff800011c2c000 <memory_cgrp_subsys+0xe8>
    0.00 :   ffff8000102fd1e0:       mov     x1, #0x1                        // #1
    0.00 :   ffff8000102fd1e4:       mov     w20, #0x0                       // #0
    0.00 :   ffff8000102fd1e8:       ldr     w2, [x2, #656]
         : 60               ext4_es_lookup_extent():
         : 980              percpu_counter_inc(&stats->es_stats_cache_misses);
    0.00 :   ffff8000102fd1ec:       ldr     x0, [x0, #880]
         : 982              percpu_counter_add():
    0.00 :   ffff8000102fd1f0:       add     x0, x0, #0x508
    0.00 :   ffff8000102fd1f4:       bl      ffff800010495ba0 <percpu_counter_add_batch>
    0.00 :   ffff8000102fd1f8:       b       ffff8000102fd194 <ext4_es_lookup_extent+0xe4>
         : 59               ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fd1fc:       ldr     w4, [x19, #28]
    0.00 :   ffff8000102fd200:       add     w4, w5, w4
    0.00 :   ffff8000102fd204:       cmp     w5, w4
    0.00 :   ffff8000102fd208:       b.hi    ffff8000102fd220 <ext4_es_lookup_extent+0x170>  // b.pmore
         : 203              return es->es_lblk + es->es_len - 1;
    0.00 :   ffff8000102fd20c:       sub     w4, w4, #0x1
         : 205              ext4_es_lookup_extent():
         : 952              else if (lblk > ext4_es_end(es1))
    0.00 :   ffff8000102fd210:       cmp     w20, w4
    0.00 :   ffff8000102fd214:       b.ls    ffff8000102fd13c <ext4_es_lookup_extent+0x8c>  // b.plast
         : 953              node = node->rb_right;
    0.00 :   ffff8000102fd218:       ldr     x19, [x19, #8]
    0.00 :   ffff8000102fd21c:       b       ffff8000102fd1c0 <ext4_es_lookup_extent+0x110>
         : 956              ext4_es_end():
         : 202              BUG_ON(es->es_lblk + es->es_len < es->es_lblk);
    0.00 :   ffff8000102fd220:       brk     #0x800
         : 204              ext4_es_lookup_extent():
         : 977              *next_lblk = 0;
    0.00 :   ffff8000102fd224:       str     wzr, [x22]
    0.00 :   ffff8000102fd228:       b       ffff8000102fd194 <ext4_es_lookup_extent+0xe4>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100d6e28 <cpuacct_charge>:
         : 6                cpuacct_charge():
         : 340              * charge this task's execution time to its accounting group.
         : 341              *
         : 342              * called with rq->lock held.
         : 343              */
         : 344              void cpuacct_charge(struct task_struct *tsk, u64 cputime)
         : 345              {
    0.00 :   ffff8000100d6e28:       paciasp
    0.00 :   ffff8000100d6e2c:       stp     x29, x30, [sp, #-48]!
         : 348              get_irq_regs():
         : 21               */
         : 22               DECLARE_PER_CPU(struct pt_regs *, __irq_regs);
         :
         : 24               static inline struct pt_regs *get_irq_regs(void)
         : 25               {
         : 26               return __this_cpu_read(__irq_regs);
    0.00 :   ffff8000100d6e30:       adrp    x2, ffff800011777000 <lru_pvecs+0x128>
         : 28               cpuacct_charge():
    0.00 :   ffff8000100d6e34:       mov     x29, sp
    0.00 :   ffff8000100d6e38:       stp     x19, x20, [sp, #16]
         : 342              get_irq_regs():
    0.00 :   ffff8000100d6e3c:       add     x2, x2, #0xca8
         : 22               cpuacct_charge():
    0.00 :   ffff8000100d6e40:       str     x21, [sp, #32]
    0.00 :   ffff8000100d6e44:       mov     x21, x0
         : 342              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
  100.00 :   ffff8000100d6e48:       mrs     x0, tpidr_el1
         : 46               get_irq_regs():
    0.00 :   ffff8000100d6e4c:       ldr     x2, [x2, x0]
         : 22               cpuacct_charge():
    0.00 :   ffff8000100d6e50:       mov     x20, x1
         : 343              struct cpuacct *ca;
         : 344              int index = CPUACCT_STAT_SYSTEM;
         : 345              struct pt_regs *regs = get_irq_regs() ? : task_pt_regs(tsk);
    0.00 :   ffff8000100d6e54:       cbz     x2, ffff8000100d6eb8 <cpuacct_charge+0x90>
         :
         : 346              if (regs && user_mode(regs))
    0.00 :   ffff8000100d6e58:       ldr     x0, [x2, #264]
    0.00 :   ffff8000100d6e5c:       tst     x0, #0xf
    0.00 :   ffff8000100d6e60:       cset    w19, ne  // ne = any
         : 350              rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100d6e64:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              task_css():
         : 494              * See task_css_check().
         : 495              */
         : 496              static inline struct cgroup_subsys_state *task_css(struct task_struct *task,
         : 497              int subsys_id)
         : 498              {
         : 499              return task_css_check(task, subsys_id, false);
    0.00 :   ffff8000100d6e68:       ldr     x0, [x21, #2000]
    0.00 :   ffff8000100d6e6c:       ldr     x2, [x0, #16]
         : 502              css_ca():
         : 38               return css ? container_of(css, struct cpuacct, css) : NULL;
    0.00 :   ffff8000100d6e70:       cbz     x2, ffff8000100d6ea0 <cpuacct_charge+0x78>
    0.00 :   ffff8000100d6e74:       sxtw    x5, w19
    0.00 :   ffff8000100d6e78:       lsl     x5, x5, #3
    0.00 :   ffff8000100d6e7c:       nop
         : 43               cpuacct_charge():
         : 351              index = CPUACCT_STAT_USER;
         :
         : 353              rcu_read_lock();
         :
         : 355              for (ca = task_ca(tsk); ca; ca = parent_ca(ca))
         : 356              __this_cpu_add(ca->cpuusage->usages[index], cputime);
    0.00 :   ffff8000100d6e80:       ldr     x0, [x2, #200]
         : 358              __kern_my_cpu_offset():
    0.00 :   ffff8000100d6e84:       mrs     x4, tpidr_el1
         : 40               cpuacct_charge():
    0.00 :   ffff8000100d6e88:       add     x0, x0, x5
    0.00 :   ffff8000100d6e8c:       ldr     x3, [x0, x4]
    0.00 :   ffff8000100d6e90:       add     x3, x3, x20
    0.00 :   ffff8000100d6e94:       str     x3, [x0, x4]
         : 350              for (ca = task_ca(tsk); ca; ca = parent_ca(ca))
    0.00 :   ffff8000100d6e98:       ldr     x2, [x2, #192]
         : 352              css_ca():
         : 38               return css ? container_of(css, struct cpuacct, css) : NULL;
    0.00 :   ffff8000100d6e9c:       cbnz    x2, ffff8000100d6e80 <cpuacct_charge+0x58>
         : 40               rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100d6ea0:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              cpuacct_charge():
         :
         : 355              rcu_read_unlock();
         : 356              }
    0.00 :   ffff8000100d6ea4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100d6ea8:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100d6eac:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100d6eb0:       autiasp
    0.00 :   ffff8000100d6eb4:       ret
         : 343              struct pt_regs *regs = get_irq_regs() ? : task_pt_regs(tsk);
    0.00 :   ffff8000100d6eb8:       ldr     x2, [x21, #24]
    0.00 :   ffff8000100d6ebc:       mov     x0, #0x3eb0                     // #16048
         : 342              int index = CPUACCT_STAT_SYSTEM;
    0.00 :   ffff8000100d6ec0:       mov     w19, #0x1                       // #1
         : 343              struct pt_regs *regs = get_irq_regs() ? : task_pt_regs(tsk);
    0.00 :   ffff8000100d6ec4:       add     x2, x2, x0
         : 345              if (regs && user_mode(regs))
    0.00 :   ffff8000100d6ec8:       cbz     x2, ffff8000100d6e64 <cpuacct_charge+0x3c>
    0.00 :   ffff8000100d6ecc:       b       ffff8000100d6e58 <cpuacct_charge+0x30>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001027bbf0 <generic_write_end>:
         : 6                generic_write_end():
         : 2192             }
         : 2193             EXPORT_SYMBOL(block_write_begin);
         :
         : 2195             int block_write_end(struct file *file, struct address_space *mapping,
         : 2196             loff_t pos, unsigned len, unsigned copied,
         : 2197             struct page *page, void *fsdata)
    0.00 :   ffff80001027bbf0:       paciasp
    0.00 :   ffff80001027bbf4:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff80001027bbf8:       mov     x29, sp
    0.00 :   ffff80001027bbfc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001027bc00:       mov     x20, x2
    0.00 :   ffff80001027bc04:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001027bc08:       mov     w22, #0x0                       // #0
    0.00 :   ffff80001027bc0c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001027bc10:       mov     x24, x5
         : 2193             {
    0.00 :   ffff80001027bc14:       ldr     x19, [x1]
         : 2194             struct inode *inode = mapping->host;
    0.00 :   ffff80001027bc18:       ldr     x23, [x19, #80]
         : 2197             unsigned start;
         :
         : 2199             start = pos & (PAGE_SIZE - 1);
    0.00 :   ffff80001027bc1c:       bl      ffff80001027bb50 <block_write_end>
         : 2206             * The buffers that were written will now be uptodate, so we
         : 2207             * don't have to worry about a readpage reading them and
         : 2208             * overwriting a partial write. However if we have encountered
         : 2209             * a short write and only partially written into a buffer, it
         : 2210             * will not be marked uptodate, so a readpage might come in and
         : 2211             * destroy our partial write.
    0.00 :   ffff80001027bc20:       ldr     x1, [x19, #80]
         : 2197             start = pos & (PAGE_SIZE - 1);
    0.00 :   ffff80001027bc24:       mov     w21, w0
         : 2206             * destroy our partial write.
    0.00 :   ffff80001027bc28:       add     x0, x20, w0, uxtw
    0.00 :   ffff80001027bc2c:       cmp     x0, x1
    0.00 :   ffff80001027bc30:       b.le    ffff80001027bc3c <generic_write_end+0x4c>
         : 2208             *
         : 2209             * Do the simplest thing, and just treat any short write to a
    0.00 :   ffff80001027bc34:       mov     w22, #0x1                       // #1
         : 2211             i_size_write():
         : 871              #elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPTION)
         : 872              preempt_disable();
         : 873              inode->i_size = i_size;
         : 874              preempt_enable();
         : 875              #else
         : 876              inode->i_size = i_size;
    0.00 :   ffff80001027bc38:       str     x0, [x19, #80]
         : 878              generic_write_end():
         : 2211             * non uptodate page as a zero-length write, and force the
         : 2212             * caller to redo the whole thing.
         : 2213             */
    0.00 :   ffff80001027bc3c:       mov     x0, x24
    0.00 :   ffff80001027bc40:       bl      ffff80001017d860 <unlock_page>
         : 2216             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff80001027bc44:       ldr     x0, [x24, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff80001027bc48:       sub     x1, x0, #0x1
    0.00 :   ffff80001027bc4c:       tst     x0, #0x1
    0.00 :   ffff80001027bc50:       csel    x24, x1, x24, ne  // ne = any
         : 193              page_ref_dec_and_test():
         : 148              return ret;
         : 149              }
         :
         : 151              static inline int page_ref_dec_and_test(struct page *page)
         : 152              {
         : 153              int ret = atomic_dec_and_test(&page->_refcount);
  100.00 :   ffff80001027bc54:       add     x1, x24, #0x34
         : 155              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001027bc58:       b       ffff80001027bc9c <generic_write_end+0xac>
    0.00 :   ffff80001027bc5c:       b       ffff80001027bc9c <generic_write_end+0xac>
         : 46               __lse_atomic_sub_return():
         : 141              }
         :
         : 143              ATOMIC_OP_SUB_RETURN(_relaxed,   )
         : 144              ATOMIC_OP_SUB_RETURN(_acquire,  a, "memory")
         : 145              ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
         : 146              ATOMIC_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff80001027bc60:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001027bc64:       neg     w0, w0
    0.00 :   ffff80001027bc68:       ldaddal w0, w2, [x1]
    0.00 :   ffff80001027bc6c:       add     w0, w0, w2
         : 151              put_page():
         : 1242             put_devmap_managed_page(page);
         : 1243             return;
         : 1244             }
         :
         : 1246             if (put_page_testzero(page))
         : 1247             __put_page(page);
    0.00 :   ffff80001027bc70:       cbz     w0, ffff80001027bca8 <generic_write_end+0xb8>
         : 1249             generic_write_end():
         : 2214             if (!PageUptodate(page))
         : 2215             copied = 0;
         :
    0.00 :   ffff80001027bc74:       cmp     x23, x20
    0.00 :   ffff80001027bc78:       b.lt    ffff80001027bcb8 <generic_write_end+0xc8>  // b.tstop
         : 2222             flush_dcache_page(page);
         :
         : 2224             /* This could be a short (even 0-length) commit */
         : 2225             __block_commit_write(inode, page, start, start+copied);
         :
         : 2227             return copied;
    0.00 :   ffff80001027bc7c:       cbnz    w22, ffff80001027bccc <generic_write_end+0xdc>
         : 2225             }
         : 2226             EXPORT_SYMBOL(block_write_end);
         :
    0.00 :   ffff80001027bc80:       mov     w0, w21
    0.00 :   ffff80001027bc84:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001027bc88:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001027bc8c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001027bc90:       ldp     x29, x30, [sp], #64
    0.00 :   ffff80001027bc94:       autiasp
    0.00 :   ffff80001027bc98:       ret
         : 2235             __ll_sc_atomic_sub_return():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001027bc9c:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001027bca0:       b       ffff800010280310 <__arm64_sys_bdflush+0x4d8>
         : 120              put_page():
    0.00 :   ffff80001027bca4:       cbnz    w0, ffff80001027bc74 <generic_write_end+0x84>
         : 1243             }
    0.00 :   ffff80001027bca8:       mov     x0, x24
    0.00 :   ffff80001027bcac:       bl      ffff80001018d6f0 <__put_page>
         : 1246             generic_write_end():
         :
    0.00 :   ffff80001027bcb0:       cmp     x23, x20
    0.00 :   ffff80001027bcb4:       b.ge    ffff80001027bc7c <generic_write_end+0x8c>  // b.tcont
         : 2215             page_zero_new_buffers(page, start+copied, start+len);
    0.00 :   ffff80001027bcb8:       mov     x2, x20
    0.00 :   ffff80001027bcbc:       mov     x1, x23
    0.00 :   ffff80001027bcc0:       mov     x0, x19
    0.00 :   ffff80001027bcc4:       bl      ffff800010191528 <pagecache_isize_extended>
         : 2222             return copied;
    0.00 :   ffff80001027bcc8:       cbz     w22, ffff80001027bc80 <generic_write_end+0x90>
         : 2224             mark_inode_dirty():
         : 2404             #define I_DIRTY_ALL (I_DIRTY | I_DIRTY_TIME)
         :
         : 2406             extern void __mark_inode_dirty(struct inode *, int);
         : 2407             static inline void mark_inode_dirty(struct inode *inode)
         : 2408             {
         : 2409             __mark_inode_dirty(inode, I_DIRTY);
    0.00 :   ffff80001027bccc:       mov     x0, x19
    0.00 :   ffff80001027bcd0:       mov     w1, #0x7                        // #7
    0.00 :   ffff80001027bcd4:       bl      ffff80001026bf70 <__mark_inode_dirty>
         : 2413             generic_write_end():
         :
    0.00 :   ffff80001027bcd8:       mov     w0, w21
    0.00 :   ffff80001027bcdc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001027bce0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001027bce4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001027bce8:       ldp     x29, x30, [sp], #64
    0.00 :   ffff80001027bcec:       autiasp
    0.00 :   ffff80001027bcf0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010467dc8 <iov_iter_copy_from_user_atomic>:
         : 6                iov_iter_copy_from_user_atomic():
         :
         : 1043             void iov_iter_advance(struct iov_iter *i, size_t size)
         : 1044             {
         : 1045             if (unlikely(i->count < size))
         : 1046             size = i->count;
         : 1047             if (likely(iter_is_iovec(i) || iov_iter_is_kvec(i))) {
    0.00 :   ffff800010467dc8:       paciasp
    0.00 :   ffff800010467dcc:       stp     x29, x30, [sp, #-176]!
    0.00 :   ffff800010467dd0:       mov     x29, sp
    0.00 :   ffff800010467dd4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010467dd8:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010467ddc:       add     x20, x20, #0x948
    0.00 :   ffff800010467de0:       ldr     x4, [x20]
    0.00 :   ffff800010467de4:       str     x4, [sp, #168]
    0.00 :   ffff800010467de8:       mov     x4, #0x0                        // #0
    0.00 :   ffff800010467dec:       stp     x23, x24, [sp, #48]
         : 1058             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010467df0:       mrs     x4, sp_el0
         : 26               iov_iter_copy_from_user_atomic():
    0.00 :   ffff800010467df4:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010467df8:       mov     x23, x1
    0.00 :   ffff800010467dfc:       mov     x28, x3
         : 1045             __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010467e00:       ldr     w1, [x4, #8]
         : 47               pc += val;
    0.00 :   ffff800010467e04:       add     w1, w1, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010467e08:       str     w1, [x4, #8]
         : 50               pagefault_disabled_inc():
         : 229              }
         : 230              #endif
         :
         : 232              static __always_inline void pagefault_disabled_inc(void)
         : 233              {
         : 234              current->pagefault_disabled++;
    0.00 :   ffff800010467e0c:       ldr     w1, [x4, #2448]
    0.00 :   ffff800010467e10:       add     w1, w1, #0x1
    0.00 :   ffff800010467e14:       str     w1, [x4, #2448]
         : 238              page_copy_sane():
         : 939              kunmap_atomic(kaddr);
    0.00 :   ffff800010467e18:       add     x1, x2, x3
         : 948              return bytes;
    0.00 :   ffff800010467e1c:       cmp     x1, #0x1, lsl #12
    0.00 :   ffff800010467e20:       ccmp    x3, x1, #0x2, ls  // ls = plast
    0.00 :   ffff800010467e24:       b.ls    ffff800010467e5c <iov_iter_copy_from_user_atomic+0x94>  // b.plast
         : 952              compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010467e28:       ldr     x3, [x0, #8]
         : 188              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 190              if (unlikely(head & 1))
         : 191              return head - 1;
    0.00 :   ffff800010467e2c:       mov     x4, x0
         :
    0.00 :   ffff800010467e30:       tbnz    w3, #0, ffff800010468048 <iov_iter_copy_from_user_atomic+0x280>
         : 188              page_copy_sane():
         : 954              struct pipe_inode_info *pipe = i->pipe;
    0.00 :   ffff800010467e34:       cmp     x28, x1
    0.00 :   ffff800010467e38:       b.hi    ffff800010468004 <iov_iter_copy_from_user_atomic+0x23c>  // b.pmore
         : 957              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010467e3c:       ldr     x6, [x4]
         : 113              compound_order():
         : 944              }
         :
         : 946              static inline unsigned int compound_order(struct page *page)
         : 947              {
         : 948              if (!PageHead(page))
         : 949              return 0;
    0.00 :   ffff800010467e40:       mov     x3, #0x1000                     // #4096
    0.00 :   ffff800010467e44:       tst     w6, #0x10000
    0.00 :   ffff800010467e48:       b.eq    ffff800010467e54 <iov_iter_copy_from_user_atomic+0x8c>  // b.none
         : 946              return page[1].compound_order;
         : 947              }
    0.00 :   ffff800010467e4c:       ldrb    w4, [x4, #81]
    0.00 :   ffff800010467e50:       lsl     x3, x3, x4
         : 950              page_copy_sane():
    0.00 :   ffff800010467e54:       cmp     x1, x3
    0.00 :   ffff800010467e58:       b.hi    ffff800010468004 <iov_iter_copy_from_user_atomic+0x23c>  // b.pmore
         : 956              iov_iter_is_pipe():
         : 78               {
         : 79               return iov_iter_type(i) == ITER_PIPE;
         : 80               }
         :
         : 82               static inline bool iov_iter_is_discard(const struct iov_iter *i)
         : 83               {
    0.00 :   ffff800010467e5c:       ldr     w4, [x23]
         : 85               iov_iter_type():
         : 58               {
    0.00 :   ffff800010467e60:       and     w1, w4, #0xfffffffe
         : 60               iov_iter_copy_from_user_atomic():
         : 1048             /* iovec and kvec have identical layouts */
         : 1049             iov_iter_iovec_advance(i, size);
         : 1050             } else if (iov_iter_is_bvec(i)) {
         : 1051             iov_iter_bvec_advance(i, size);
         : 1052             } else if (iov_iter_is_pipe(i)) {
         : 1053             pipe_advance(i, size);
    0.00 :   ffff800010467e64:       sub     w1, w1, #0x20
    0.00 :   ffff800010467e68:       and     w1, w1, #0xffffffdf
    0.00 :   ffff800010467e6c:       cbz     w1, ffff800010467fc0 <iov_iter_copy_from_user_atomic+0x1f8>
         : 1053             } else if (unlikely(iov_iter_is_xarray(i))) {
         : 1054             i->iov_offset += size;
         : 1055             i->count -= size;
         : 1056             } else if (iov_iter_is_discard(i)) {
         : 1057             i->count -= size;
    0.00 :   ffff800010467e70:       cbz     x28, ffff800010468040 <iov_iter_copy_from_user_atomic+0x278>
    0.00 :   ffff800010467e74:       stp     x21, x22, [sp, #32]
         : 1060             lowmem_page_address():
         : 1601             #include <linux/vmstat.h>
         :
         : 1603             static __always_inline void *lowmem_page_address(const struct page *page)
         : 1604             {
         : 1605             return page_to_virt(page);
         : 1606             }
    0.00 :   ffff800010467e78:       mov     x22, #0x40000000000             // #4398046511104
    0.00 :   ffff800010467e7c:       add     x19, x0, x22
    0.00 :   ffff800010467e80:       mov     x21, #0xffff000000000000        // #-281474976710656
    0.00 :   ffff800010467e84:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010467e88:       lsr     x19, x19, #6
         : 1612             iov_iter_copy_from_user_atomic():
    0.00 :   ffff800010467e8c:       ldr     x25, [x23, #8]
         : 1054             lowmem_page_address():
    0.00 :   ffff800010467e90:       add     x19, x21, x19, lsl #12
         : 1602             iov_iter_copy_from_user_atomic():
         : 1043             /* iovec and kvec have identical layouts */
    0.00 :   ffff800010467e94:       add     x19, x19, x2
         : 1053             i->count -= size;
    0.00 :   ffff800010467e98:       tbnz    w4, #4, ffff80001046805c <iov_iter_copy_from_user_atomic+0x294>
    0.00 :   ffff800010467e9c:       tbnz    w4, #3, ffff800010468104 <iov_iter_copy_from_user_atomic+0x33c>
    0.00 :   ffff800010467ea0:       tbnz    w4, #6, ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>
    0.00 :   ffff800010467ea4:       ldr     x22, [x23, #24]
    0.00 :   ffff800010467ea8:       tbnz    w4, #7, ffff800010468140 <iov_iter_copy_from_user_atomic+0x378>
    0.00 :   ffff800010467eac:       ldr     x21, [x22, #8]
    0.00 :   ffff800010467eb0:       sub     x21, x21, x25
    0.00 :   ffff800010467eb4:       cmp     x21, x28
    0.00 :   ffff800010467eb8:       csel    x21, x21, x28, ls  // ls = plast
    0.00 :   ffff800010467ebc:       cbz     x21, ffff800010468324 <iov_iter_copy_from_user_atomic+0x55c>
    0.00 :   ffff800010467ec0:       ldr     x1, [x22]
    0.00 :   ffff800010467ec4:       mov     x2, x21
    0.00 :   ffff800010467ec8:       mov     x0, x19
    0.00 :   ffff800010467ecc:       add     x19, x19, x21
    0.00 :   ffff800010467ed0:       add     x1, x1, x25
    0.00 :   ffff800010467ed4:       sub     x21, x28, x21
    0.00 :   ffff800010467ed8:       bl      ffff800010465848 <copyin>
    0.00 :   ffff800010467edc:       sxtw    x0, w0
    0.00 :   ffff800010467ee0:       add     x21, x21, x0
    0.00 :   ffff800010467ee4:       cmp     x0, #0x0
    0.00 :   ffff800010467ee8:       ccmp    x21, #0x0, #0x4, eq  // eq = none
    0.00 :   ffff800010467eec:       b.ne    ffff8000104682ec <iov_iter_copy_from_user_atomic+0x524>  // b.any
    0.00 :   ffff800010467ef0:       sub     x0, x28, x21
    0.00 :   ffff800010467ef4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010467ef8:       ldp     x25, x26, [sp, #64]
         : 1056             get_current():
    0.00 :   ffff800010467efc:       mrs     x1, sp_el0
         : 20               pagefault_disabled_dec():
         : 234              }
         :
         : 236              static __always_inline void pagefault_disabled_dec(void)
         : 237              {
         : 238              current->pagefault_disabled--;
    0.00 :   ffff800010467f00:       ldr     w2, [x1, #2448]
    0.00 :   ffff800010467f04:       sub     w2, w2, #0x1
    0.00 :   ffff800010467f08:       str     w2, [x1, #2448]
         : 242              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010467f0c:       ldr     x2, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010467f10:       sub     x2, x2, #0x1
    0.00 :   ffff800010467f14:       str     w2, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010467f18:       cbnz    x2, ffff800010467fb4 <iov_iter_copy_from_user_atomic+0x1ec>
         : 80               iov_iter_copy_from_user_atomic():
         : 1046             iov_iter_bvec_advance(i, size);
    0.00 :   ffff800010467f1c:       str     x0, [sp, #104]
         : 1048             __kunmap_atomic():
         : 203              {
         : 204              #ifdef ARCH_HAS_FLUSH_ON_KUNMAP
         : 205              kunmap_flush_on_unmap(addr);
         : 206              #endif
         : 207              pagefault_enable();
         : 208              preempt_enable();
    0.00 :   ffff800010467f20:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010467f24:       ldr     x0, [sp, #104]
         : 211              iov_iter_copy_from_user_atomic():
         : 1063             void iov_iter_revert(struct iov_iter *i, size_t unroll)
         : 1064             {
         : 1065             if (!unroll)
         : 1066             return;
         : 1067             if (WARN_ON(unroll > MAX_RW_COUNT))
         : 1068             return;
    0.00 :   ffff800010467f28:       ldr     x2, [sp, #168]
    0.00 :   ffff800010467f2c:       ldr     x1, [x20]
    0.00 :   ffff800010467f30:       eor     x1, x2, x1
    0.00 :   ffff800010467f34:       cbnz    x1, ffff800010468354 <iov_iter_copy_from_user_atomic+0x58c>
    0.00 :   ffff800010467f38:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010467f3c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010467f40:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010467f44:       ldp     x29, x30, [sp], #176
    0.00 :   ffff800010467f48:       autiasp
    0.00 :   ffff800010467f4c:       ret
    0.00 :   ffff800010467f50:       mov     x23, x28
         : 1053             i->count -= size;
    0.00 :   ffff800010467f54:       add     x22, x22, #0x10
    0.00 :   ffff800010467f58:       ldr     x21, [x22, #8]
    0.00 :   ffff800010467f5c:       cmp     x21, x23
    0.00 :   ffff800010467f60:       csel    x21, x21, x23, ls  // ls = plast
    0.00 :   ffff800010467f64:       cbz     x21, ffff800010467f54 <iov_iter_copy_from_user_atomic+0x18c>
    0.00 :   ffff800010467f68:       ldr     x1, [x22]
    0.00 :   ffff800010467f6c:       mov     x0, x19
    0.00 :   ffff800010467f70:       mov     x2, x21
    0.00 :   ffff800010467f74:       add     x19, x19, x21
    0.00 :   ffff800010467f78:       bl      ffff8000104a5b40 <__memcpy>
    0.00 :   ffff800010467f7c:       subs    x23, x23, x21
    0.00 :   ffff800010467f80:       b.ne    ffff800010467f54 <iov_iter_copy_from_user_atomic+0x18c>  // b.any
    0.00 :   ffff800010467f84:       nop
    0.00 :   ffff800010467f88:       mov     x0, x28
    0.00 :   ffff800010467f8c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010467f90:       ldp     x25, x26, [sp, #64]
         : 1056             get_current():
    0.00 :   ffff800010467f94:       mrs     x1, sp_el0
         : 20               pagefault_disabled_dec():
    0.00 :   ffff800010467f98:       ldr     w2, [x1, #2448]
    0.00 :   ffff800010467f9c:       sub     w2, w2, #0x1
    0.00 :   ffff800010467fa0:       str     w2, [x1, #2448]
         : 237              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010467fa4:       ldr     x2, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010467fa8:       sub     x2, x2, #0x1
    0.00 :   ffff800010467fac:       str     w2, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010467fb0:       cbz     x2, ffff800010467f1c <iov_iter_copy_from_user_atomic+0x154>
  100.00 :   ffff800010467fb4:       ldr     x1, [x1, #8]
    0.00 :   ffff800010467fb8:       cbz     x1, ffff800010467f1c <iov_iter_copy_from_user_atomic+0x154>
    0.00 :   ffff800010467fbc:       b       ffff800010467f28 <iov_iter_copy_from_user_atomic+0x160>
         : 76               get_current():
    0.00 :   ffff800010467fc0:       mrs     x0, sp_el0
         : 20               pagefault_disabled_dec():
    0.00 :   ffff800010467fc4:       ldr     w1, [x0, #2448]
    0.00 :   ffff800010467fc8:       sub     w1, w1, #0x1
    0.00 :   ffff800010467fcc:       str     w1, [x0, #2448]
         : 237              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010467fd0:       ldr     x1, [x0, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010467fd4:       sub     x1, x1, #0x1
    0.00 :   ffff800010467fd8:       str     w1, [x0, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010467fdc:       cbnz    x1, ffff800010467ff4 <iov_iter_copy_from_user_atomic+0x22c>
         : 75               __kunmap_atomic():
    0.00 :   ffff800010467fe0:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010467fe4:       nop
         : 205              iov_iter_copy_from_user_atomic():
         : 1050             i->iov_offset += size;
    0.00 :   ffff800010467fe8:       brk     #0x800
         : 1051             i->count -= size;
    0.00 :   ffff800010467fec:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010467ff0:       b       ffff800010467f28 <iov_iter_copy_from_user_atomic+0x160>
         : 1054             __preempt_count_dec_and_test():
    0.00 :   ffff800010467ff4:       ldr     x0, [x0, #8]
    0.00 :   ffff800010467ff8:       cbnz    x0, ffff800010467fe8 <iov_iter_copy_from_user_atomic+0x220>
         : 75               __kunmap_atomic():
    0.00 :   ffff800010467ffc:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010468000:       b       ffff800010467fe8 <iov_iter_copy_from_user_atomic+0x220>
         : 205              page_copy_sane():
         : 956              unsigned int p_head = pipe->head;
    0.00 :   ffff800010468004:       brk     #0x800
         : 958              get_current():
    0.00 :   ffff800010468008:       mrs     x0, sp_el0
         : 20               pagefault_disabled_dec():
    0.00 :   ffff80001046800c:       ldr     w1, [x0, #2448]
    0.00 :   ffff800010468010:       sub     w1, w1, #0x1
    0.00 :   ffff800010468014:       str     w1, [x0, #2448]
         : 237              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010468018:       ldr     x1, [x0, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001046801c:       sub     x1, x1, #0x1
    0.00 :   ffff800010468020:       str     w1, [x0, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010468024:       cbnz    x1, ffff800010468030 <iov_iter_copy_from_user_atomic+0x268>
         : 75               iov_iter_copy_from_user_atomic():
         : 1046             iov_iter_bvec_advance(i, size);
    0.00 :   ffff800010468028:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001046802c:       b       ffff800010467f1c <iov_iter_copy_from_user_atomic+0x154>
         : 1049             __preempt_count_dec_and_test():
    0.00 :   ffff800010468030:       ldr     x0, [x0, #8]
    0.00 :   ffff800010468034:       cbnz    x0, ffff800010467fec <iov_iter_copy_from_user_atomic+0x224>
         : 75               iov_iter_copy_from_user_atomic():
    0.00 :   ffff800010468038:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001046803c:       b       ffff800010467f1c <iov_iter_copy_from_user_atomic+0x154>
    0.00 :   ffff800010468040:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010468044:       b       ffff800010467efc <iov_iter_copy_from_user_atomic+0x134>
         : 1050             compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010468048:       sub     x4, x3, #0x1
    0.00 :   ffff80001046804c:       sub     x3, x0, x4
    0.00 :   ffff800010468050:       asr     x3, x3, #6
    0.00 :   ffff800010468054:       add     x1, x1, x3, lsl #12
    0.00 :   ffff800010468058:       b       ffff800010467e34 <iov_iter_copy_from_user_atomic+0x6c>
         : 193              iov_iter_copy_from_user_atomic():
         : 1053             i->count -= size;
    0.00 :   ffff80001046805c:       mov     w27, w25
    0.00 :   ffff800010468060:       mov     w24, w28
    0.00 :   ffff800010468064:       cbz     w28, ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>
    0.00 :   ffff800010468068:       ldr     x1, [x23, #24]
    0.00 :   ffff80001046806c:       str     wzr, [sp, #104]
    0.00 :   ffff800010468070:       ldr     x0, [sp, #104]
    0.00 :   ffff800010468074:       ubfiz   x26, x0, #4, #32
         : 1055             memcpy_from_page():
         : 321              {
         : 322              char *to = kmap_local_page(page);
         :
         : 324              VM_BUG_ON(offset + len > PAGE_SIZE);
         : 325              memcpy(to + offset, from, len);
         : 326              kunmap_local(to);
    0.00 :   ffff800010468078:       mov     x0, x19
         : 328              iov_iter_copy_from_user_atomic():
    0.00 :   ffff80001046807c:       add     x6, x1, x26
    0.00 :   ffff800010468080:       ldr     x7, [x1, x26]
    0.00 :   ffff800010468084:       ldp     w25, w2, [x6, #8]
    0.00 :   ffff800010468088:       add     w2, w27, w2
    0.00 :   ffff80001046808c:       sub     w25, w25, w27
    0.00 :   ffff800010468090:       and     w1, w2, #0xfff
    0.00 :   ffff800010468094:       cmp     w25, w24
    0.00 :   ffff800010468098:       lsr     w4, w2, #12
    0.00 :   ffff80001046809c:       csel    w25, w25, w24, ls  // ls = plast
    0.00 :   ffff8000104680a0:       mov     w2, #0x1000                     // #4096
    0.00 :   ffff8000104680a4:       sub     w6, w2, w1
    0.00 :   ffff8000104680a8:       add     x4, x7, x4, lsl #6
    0.00 :   ffff8000104680ac:       cmp     w25, w6
         : 1066             lowmem_page_address():
    0.00 :   ffff8000104680b0:       add     x4, x4, x22
         : 1602             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104680b4:       csel    w25, w25, w6, ls  // ls = plast
         : 1054             bvec_iter_advance_single():
         : 131              * across multiple bvec entries, i.e. bytes <= bv[i->bi_idx].bv_len
         : 132              */
         : 133              static inline void bvec_iter_advance_single(const struct bio_vec *bv,
         : 134              struct bvec_iter *iter, unsigned int bytes)
         : 135              {
         : 136              unsigned int done = iter->bi_bvec_done + bytes;
    0.00 :   ffff8000104680b8:       add     w27, w27, w25
         : 138              lowmem_page_address():
    0.00 :   ffff8000104680bc:       lsr     x4, x4, #6
         : 1602             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104680c0:       mov     w2, w25
    0.00 :   ffff8000104680c4:       add     x19, x19, x2
         : 1055             lowmem_page_address():
    0.00 :   ffff8000104680c8:       add     x4, x21, x4, lsl #12
         : 1602             memcpy_from_page():
    0.00 :   ffff8000104680cc:       add     x1, x4, x1
    0.00 :   ffff8000104680d0:       bl      ffff8000104a5b40 <__memcpy>
         : 323              iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104680d4:       ldr     x1, [x23, #24]
         : 1054             bvec_iter_advance_single():
         :
         : 134              if (done == bv[iter->bi_idx].bv_len) {
    0.00 :   ffff8000104680d8:       add     x26, x1, x26
    0.00 :   ffff8000104680dc:       ldr     w0, [x26, #8]
    0.00 :   ffff8000104680e0:       cmp     w27, w0
    0.00 :   ffff8000104680e4:       b.ne    ffff8000104680f8 <iov_iter_copy_from_user_atomic+0x330>  // b.any
         : 135              done = 0;
         : 136              iter->bi_idx++;
    0.00 :   ffff8000104680e8:       ldr     w0, [sp, #104]
         : 134              done = 0;
    0.00 :   ffff8000104680ec:       mov     w27, #0x0                       // #0
         : 135              iter->bi_idx++;
    0.00 :   ffff8000104680f0:       add     w0, w0, #0x1
    0.00 :   ffff8000104680f4:       str     w0, [sp, #104]
         : 138              iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104680f8:       subs    w24, w24, w25
    0.00 :   ffff8000104680fc:       b.ne    ffff800010468070 <iov_iter_copy_from_user_atomic+0x2a8>  // b.any
    0.00 :   ffff800010468100:       b       ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>
    0.00 :   ffff800010468104:       ldr     x22, [x23, #24]
    0.00 :   ffff800010468108:       ldr     x21, [x22, #8]
    0.00 :   ffff80001046810c:       sub     x21, x21, x25
    0.00 :   ffff800010468110:       cmp     x21, x28
    0.00 :   ffff800010468114:       csel    x21, x21, x28, ls  // ls = plast
    0.00 :   ffff800010468118:       cbz     x21, ffff800010467f50 <iov_iter_copy_from_user_atomic+0x188>
    0.00 :   ffff80001046811c:       ldr     x1, [x22]
    0.00 :   ffff800010468120:       mov     x0, x19
    0.00 :   ffff800010468124:       mov     x2, x21
    0.00 :   ffff800010468128:       add     x19, x19, x21
    0.00 :   ffff80001046812c:       add     x1, x1, x25
    0.00 :   ffff800010468130:       bl      ffff8000104a5b40 <__memcpy>
    0.00 :   ffff800010468134:       subs    x23, x28, x21
    0.00 :   ffff800010468138:       b.eq    ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>  // b.none
    0.00 :   ffff80001046813c:       b       ffff800010467f54 <iov_iter_copy_from_user_atomic+0x18c>
    0.00 :   ffff800010468140:       ldr     x26, [x23, #32]
    0.00 :   ffff800010468144:       mov     x0, #0x3                        // #3
    0.00 :   ffff800010468148:       stp     x0, xzr, [sp, #144]
    0.00 :   ffff80001046814c:       add     x1, x25, x26
    0.00 :   ffff800010468150:       str     x22, [sp, #120]
    0.00 :   ffff800010468154:       mov     x26, x28
    0.00 :   ffff800010468158:       asr     x0, x1, #12
    0.00 :   ffff80001046815c:       str     x0, [sp, #104]
    0.00 :   ffff800010468160:       str     x0, [sp, #128]
    0.00 :   ffff800010468164:       str     wzr, [sp, #136]
    0.00 :   ffff800010468168:       str     xzr, [sp, #160]
         : 1064             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff80001046816c:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              iov_iter_copy_from_user_atomic():
    0.00 :   ffff800010468170:       mov     x1, #0xffffffffffffffff         // #-1
    0.00 :   ffff800010468174:       add     x0, sp, #0x78
    0.00 :   ffff800010468178:       bl      ffff8000104bd3f0 <xas_find>
    0.00 :   ffff80001046817c:       mov     x24, x0
    0.00 :   ffff800010468180:       cbz     x0, ffff800010468348 <iov_iter_copy_from_user_atomic+0x580>
    0.00 :   ffff800010468184:       nop
         : 1059             xas_retry():
         : 1488             * Context: Any context.
         : 1489             * Return: true if the operation needs to be retried.
         : 1490             */
         : 1491             static inline bool xas_retry(struct xa_state *xas, const void *entry)
         : 1492             {
         : 1493             if (xa_is_zero(entry))
    0.00 :   ffff800010468188:       cmp     x24, #0x406
    0.00 :   ffff80001046818c:       b.eq    ffff800010468234 <iov_iter_copy_from_user_atomic+0x46c>  // b.none
         : 1490             return true;
         : 1491             if (!xa_is_retry(entry))
    0.00 :   ffff800010468190:       cmp     x24, #0x402
    0.00 :   ffff800010468194:       b.eq    ffff8000104682e0 <iov_iter_copy_from_user_atomic+0x518>  // b.none
         : 1494             iov_iter_copy_from_user_atomic():
    0.00 :   ffff800010468198:       tbnz    w24, #0, ffff800010468330 <iov_iter_copy_from_user_atomic+0x568>
    0.00 :   ffff80001046819c:       mov     x0, x24
    0.00 :   ffff8000104681a0:       bl      ffff8000101ee070 <PageHuge>
    0.00 :   ffff8000104681a4:       cbnz    w0, ffff800010468330 <iov_iter_copy_from_user_atomic+0x568>
    0.00 :   ffff8000104681a8:       ldr     x7, [x24, #32]
         : 1058             thp_nr_pages():
         : 277              }
         :
         : 279              /**
         : 280              * thp_nr_pages - The number of regular pages in this huge page.
         : 281              * @page: The head page of a huge page.
         : 282              */
    0.00 :   ffff8000104681ac:       mov     w21, #0x200                     // #512
         : 284              iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104681b0:       ldr     x0, [sp, #104]
    0.00 :   ffff8000104681b4:       cmp     x7, x0
    0.00 :   ffff8000104681b8:       sub     w7, w0, w7
    0.00 :   ffff8000104681bc:       csel    w22, w7, wzr, cc  // cc = lo, ul, last
    0.00 :   ffff8000104681c0:       b       ffff800010468220 <iov_iter_copy_from_user_atomic+0x458>
    0.00 :   ffff8000104681c4:       ldr     x2, [x23, #32]
    0.00 :   ffff8000104681c8:       sbfiz   x1, x22, #6, #32
    0.00 :   ffff8000104681cc:       add     x1, x24, x1
         : 1056             lowmem_page_address():
    0.00 :   ffff8000104681d0:       mov     x3, #0x40000000000              // #4398046511104
         : 1602             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104681d4:       add     x2, x25, x2
         : 1054             lowmem_page_address():
    0.00 :   ffff8000104681d8:       add     x1, x1, x3
         : 1602             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104681dc:       and     x2, x2, #0xfff
    0.00 :   ffff8000104681e0:       mov     x3, #0x1000                     // #4096
    0.00 :   ffff8000104681e4:       sub     x27, x3, x2
         : 1056             lowmem_page_address():
    0.00 :   ffff8000104681e8:       lsr     x1, x1, #6
         : 1602             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104681ec:       cmp     x27, x26
         : 1054             lowmem_page_address():
    0.00 :   ffff8000104681f0:       mov     x3, #0xffff000000000000         // #-281474976710656
         : 1602             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104681f4:       csel    x27, x27, x26, ls  // ls = plast
         : 1054             lowmem_page_address():
    0.00 :   ffff8000104681f8:       add     x1, x3, x1, lsl #12
         : 1602             memcpy_from_page():
    0.00 :   ffff8000104681fc:       mov     x0, x19
    0.00 :   ffff800010468200:       add     x1, x1, x2
    0.00 :   ffff800010468204:       mov     x2, x27
    0.00 :   ffff800010468208:       bl      ffff8000104a5b40 <__memcpy>
         : 325              iov_iter_copy_from_user_atomic():
    0.00 :   ffff80001046820c:       add     x25, x25, x27
    0.00 :   ffff800010468210:       add     x19, x19, x27
    0.00 :   ffff800010468214:       subs    x26, x26, x27
    0.00 :   ffff800010468218:       b.eq    ffff8000104682d8 <iov_iter_copy_from_user_atomic+0x510>  // b.none
    0.00 :   ffff80001046821c:       add     w22, w22, #0x1
         : 1054             test_bit():
    0.00 :   ffff800010468220:       ldr     x0, [x24]
         : 107              thp_nr_pages():
    0.00 :   ffff800010468224:       tst     x0, #0x10000
    0.00 :   ffff800010468228:       csinc   w0, w21, wzr, ne  // ne = any
         : 279              iov_iter_copy_from_user_atomic():
    0.00 :   ffff80001046822c:       cmp     w22, w0
    0.00 :   ffff800010468230:       b.lt    ffff8000104681c4 <iov_iter_copy_from_user_atomic+0x3fc>  // b.tstop
         : 1055             xas_next_entry():
         : 1629             *
         : 1630             * Return: The next present entry after the one currently referred to by @xas.
         : 1631             */
         : 1632             static inline void *xas_next_entry(struct xa_state *xas, unsigned long max)
         : 1633             {
         : 1634             struct xa_node *node = xas->xa_node;
    0.00 :   ffff800010468234:       ldr     x9, [sp, #144]
         : 1636             xas_not_node():
         : 1444             return ((unsigned long)node & 3) || !node;
    0.00 :   ffff800010468238:       tst     x9, #0x3
    0.00 :   ffff80001046823c:       cset    w8, ne  // ne = any
    0.00 :   ffff800010468240:       cmp     x9, #0x0
    0.00 :   ffff800010468244:       csinc   w8, w8, wzr, ne  // ne = any
    0.00 :   ffff800010468248:       cbnz    w8, ffff8000104682c0 <iov_iter_copy_from_user_atomic+0x4f8>
         : 1450             xas_next_entry():
         : 1632             void *entry;
         :
         : 1634             if (unlikely(xas_not_node(node) || node->shift ||
    0.00 :   ffff80001046824c:       ldrb    w0, [x9]
    0.00 :   ffff800010468250:       cbnz    w0, ffff8000104682c0 <iov_iter_copy_from_user_atomic+0x4f8>
    0.00 :   ffff800010468254:       ldr     x1, [sp, #128]
    0.00 :   ffff800010468258:       ldrb    w2, [sp, #138]
    0.00 :   ffff80001046825c:       and     x0, x1, #0x3f
    0.00 :   ffff800010468260:       cmp     x0, w2, uxtb
    0.00 :   ffff800010468264:       b.ne    ffff8000104682c0 <iov_iter_copy_from_user_atomic+0x4f8>  // b.any
         : 1637             xas->xa_offset != (xas->xa_index & XA_CHUNK_MASK)))
         : 1638             return xas_find(xas, max);
         :
         : 1640             do {
         : 1641             if (unlikely(xas->xa_index >= max))
    0.00 :   ffff800010468268:       cmn     x1, #0x1
    0.00 :   ffff80001046826c:       b.eq    ffff8000104682b4 <iov_iter_copy_from_user_atomic+0x4ec>  // b.none
         : 1639             return xas_find(xas, max);
         : 1640             if (unlikely(xas->xa_offset == XA_CHUNK_MASK))
    0.00 :   ffff800010468270:       cmp     w2, #0x3f
    0.00 :   ffff800010468274:       b.eq    ffff8000104682b4 <iov_iter_copy_from_user_atomic+0x4ec>  // b.none
         : 1641             return xas_find(xas, max);
         : 1642             entry = xa_entry(xas->xa, node, xas->xa_offset + 1);
    0.00 :   ffff800010468278:       add     w7, w2, #0x1
         : 1644             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff80001046827c:       ubfiz   x0, x7, #3, #9
    0.00 :   ffff800010468280:       add     x0, x0, #0x20
    0.00 :   ffff800010468284:       add     x0, x9, x0
    0.00 :   ffff800010468288:       ldr     x24, [x0, #8]
         : 1187             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff80001046828c:       and     x0, x24, #0x3
         : 171              xas_next_entry():
         : 1642             if (unlikely(xa_is_internal(entry)))
    0.00 :   ffff800010468290:       cmp     x0, #0x2
    0.00 :   ffff800010468294:       b.eq    ffff8000104682b4 <iov_iter_copy_from_user_atomic+0x4ec>  // b.none
         : 1644             return xas_find(xas, max);
         : 1645             xas->xa_offset++;
    0.00 :   ffff800010468298:       and     w2, w7, #0xff
         : 1645             xas->xa_index++;
    0.00 :   ffff80001046829c:       add     x1, x1, #0x1
    0.00 :   ffff8000104682a0:       mov     w8, #0x1                        // #1
         : 1646             } while (!entry);
    0.00 :   ffff8000104682a4:       cbz     x24, ffff800010468268 <iov_iter_copy_from_user_atomic+0x4a0>
    0.00 :   ffff8000104682a8:       str     x1, [sp, #128]
    0.00 :   ffff8000104682ac:       strb    w2, [sp, #138]
    0.00 :   ffff8000104682b0:       b       ffff800010468188 <iov_iter_copy_from_user_atomic+0x3c0>
    0.00 :   ffff8000104682b4:       cbz     w8, ffff8000104682c0 <iov_iter_copy_from_user_atomic+0x4f8>
    0.00 :   ffff8000104682b8:       str     x1, [sp, #128]
    0.00 :   ffff8000104682bc:       strb    w2, [sp, #138]
         : 1643             return xas_find(xas, max);
    0.00 :   ffff8000104682c0:       mov     x1, #0xffffffffffffffff         // #-1
    0.00 :   ffff8000104682c4:       add     x0, sp, #0x78
    0.00 :   ffff8000104682c8:       bl      ffff8000104bd3f0 <xas_find>
    0.00 :   ffff8000104682cc:       mov     x24, x0
         : 1648             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104682d0:       cbnz    x0, ffff800010468188 <iov_iter_copy_from_user_atomic+0x3c0>
    0.00 :   ffff8000104682d4:       sub     x28, x28, x26
         : 1055             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000104682d8:       bl      ffff800010102998 <__rcu_read_unlock>
    0.00 :   ffff8000104682dc:       b       ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>
         : 718              xas_reset():
         : 1471             xas->xa_node = XAS_RESTART;
    0.00 :   ffff8000104682e0:       mov     x0, #0x3                        // #3
    0.00 :   ffff8000104682e4:       str     x0, [sp, #144]
         : 1474             xas_not_node():
         : 1444             return ((unsigned long)node & 3) || !node;
    0.00 :   ffff8000104682e8:       b       ffff8000104682c0 <iov_iter_copy_from_user_atomic+0x4f8>
         : 1446             iov_iter_copy_from_user_atomic():
    0.00 :   ffff8000104682ec:       add     x22, x22, #0x10
    0.00 :   ffff8000104682f0:       ldr     x23, [x22, #8]
    0.00 :   ffff8000104682f4:       cmp     x23, x21
    0.00 :   ffff8000104682f8:       csel    x23, x23, x21, ls  // ls = plast
    0.00 :   ffff8000104682fc:       cbz     x23, ffff800010468340 <iov_iter_copy_from_user_atomic+0x578>
    0.00 :   ffff800010468300:       ldr     x1, [x22]
    0.00 :   ffff800010468304:       mov     x0, x19
    0.00 :   ffff800010468308:       mov     x2, x23
    0.00 :   ffff80001046830c:       sub     x21, x21, x23
    0.00 :   ffff800010468310:       add     x19, x19, x23
    0.00 :   ffff800010468314:       bl      ffff800010465848 <copyin>
    0.00 :   ffff800010468318:       sxtw    x0, w0
    0.00 :   ffff80001046831c:       add     x21, x21, x0
    0.00 :   ffff800010468320:       b       ffff800010467ee4 <iov_iter_copy_from_user_atomic+0x11c>
    0.00 :   ffff800010468324:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010468328:       mov     x21, x28
    0.00 :   ffff80001046832c:       b       ffff800010467ee4 <iov_iter_copy_from_user_atomic+0x11c>
    0.00 :   ffff800010468330:       brk     #0x800
    0.00 :   ffff800010468334:       sub     x28, x28, x26
         : 1055             rcu_read_unlock():
    0.00 :   ffff800010468338:       bl      ffff800010102998 <__rcu_read_unlock>
    0.00 :   ffff80001046833c:       b       ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>
         : 712              iov_iter_copy_from_user_atomic():
    0.00 :   ffff800010468340:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010468344:       b       ffff800010467ee4 <iov_iter_copy_from_user_atomic+0x11c>
    0.00 :   ffff800010468348:       mov     x28, #0x0                       // #0
         : 1054             rcu_read_unlock():
    0.00 :   ffff80001046834c:       bl      ffff800010102998 <__rcu_read_unlock>
    0.00 :   ffff800010468350:       b       ffff800010467f88 <iov_iter_copy_from_user_atomic+0x1c0>
    0.00 :   ffff800010468354:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010468358:       stp     x25, x26, [sp, #64]
         : 714              iov_iter_copy_from_user_atomic():
         : 1063             return;
    0.00 :   ffff80001046835c:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e2ab50 <exit_el1_irq_or_nmi>:
         : 6                exit_el1_irq_or_nmi():
         : 109              lockdep_hardirqs_on(CALLER_ADDR0);
         : 110              __nmi_exit();
         : 111              }
         :
         : 113              static void noinstr enter_el1_irq_or_nmi(struct pt_regs *regs)
         : 114              {
    0.00 :   ffff800010e2ab50:       paciasp
    0.00 :   ffff800010e2ab54:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e2ab58:       mov     x29, sp
         : 110              if (IS_ENABLED(CONFIG_ARM64_PSEUDO_NMI) && !interrupts_enabled(regs))
    0.00 :   ffff800010e2ab5c:       ldr     x1, [x0, #264]
    0.00 :   ffff800010e2ab60:       tbnz    w1, #7, ffff800010e2ab98 <exit_el1_irq_or_nmi+0x48>
         : 113              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
  100.00 :   ffff800010e2ab64:       b       ffff800010e2ab7c <exit_el1_irq_or_nmi+0x2c>
         : 45               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010e2ab68:       nop
         : 23               exit_el1_irq_or_nmi():
         : 113              arm64_enter_nmi(regs);
         : 114              else
         : 115              enter_from_kernel_mode(regs);
    0.00 :   ffff800010e2ab6c:       bl      ffff800010e2a448 <exit_to_kernel_mode>
         : 114              }
    0.00 :   ffff800010e2ab70:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e2ab74:       autiasp
    0.00 :   ffff800010e2ab78:       ret
         : 118              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010e2ab7c:       adrp    x1, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010e2ab80:       ldr     x1, [x1, #1296]
         : 114              exit_el1_irq_or_nmi():
         : 110              if (IS_ENABLED(CONFIG_ARM64_PSEUDO_NMI) && !interrupts_enabled(regs))
    0.00 :   ffff800010e2ab84:       tst     w1, #0x80000
    0.00 :   ffff800010e2ab88:       b.eq    ffff800010e2ab6c <exit_el1_irq_or_nmi+0x1c>  // b.none
    0.00 :   ffff800010e2ab8c:       ldr     x1, [x0, #296]
    0.00 :   ffff800010e2ab90:       cmp     x1, #0xe0
    0.00 :   ffff800010e2ab94:       b.eq    ffff800010e2ab6c <exit_el1_irq_or_nmi+0x1c>  // b.none
         : 111              arm64_enter_nmi(regs);
    0.00 :   ffff800010e2ab98:       bl      ffff800010e2aad0 <arm64_exit_nmi>
         : 114              }
    0.00 :   ffff800010e2ab9c:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e2aba0:       autiasp
    0.00 :   ffff800010e2aba4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010233540 <ksys_write>:
         : 6                ksys_write():
         : 648              {
         : 649              return ksys_read(fd, buf, count);
         : 650              }
         :
         : 652              ssize_t ksys_write(unsigned int fd, const char __user *buf, size_t count)
         : 653              {
    0.00 :   ffff800010233540:       paciasp
    0.00 :   ffff800010233544:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff800010233548:       mov     x29, sp
    0.00 :   ffff80001023354c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010233550:       adrp    x19, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010233554:       add     x19, x19, #0x948
    0.00 :   ffff800010233558:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001023355c:       mov     x22, x1
    0.00 :   ffff800010233560:       ldr     x1, [x19]
    0.00 :   ffff800010233564:       str     x1, [sp, #72]
    0.00 :   ffff800010233568:       mov     x1, #0x0                        // #0
    0.00 :   ffff80001023356c:       str     x23, [sp, #48]
    0.00 :   ffff800010233570:       mov     x23, x2
         : 667              fdget_pos():
         : 75               return __to_fd(__fdget_raw(fd));
         : 76               }
         :
         : 78               static inline struct fd fdget_pos(int fd)
         : 79               {
         : 80               return __to_fd(__fdget_pos(fd));
    0.00 :   ffff800010233574:       bl      ffff80001025a898 <__fdget_pos>
         : 82               ksys_write():
         : 652              struct fd f = fdget_pos(fd);
         : 653              ssize_t ret = -EBADF;
         :
         : 655              if (f.file) {
    0.00 :   ffff800010233578:       ands    x21, x0, #0xfffffffffffffffc
    0.00 :   ffff80001023357c:       b.eq    ffff800010233624 <ksys_write+0xe4>  // b.none
         : 658              file_ppos():
         : 620              return file->f_mode & FMODE_STREAM ? NULL : &file->f_pos;
    0.00 :   ffff800010233580:       mov     x20, x0
    0.00 :   ffff800010233584:       ldr     w0, [x21, #68]
    0.00 :   ffff800010233588:       tbnz    w0, #21, ffff800010233604 <ksys_write+0xc4>
         : 624              ksys_write():
         : 655              loff_t pos, *ppos = file_ppos(f.file);
         : 656              if (ppos) {
         : 657              pos = *ppos;
  100.00 :   ffff80001023358c:       ldr     x4, [x21, #104]
         : 658              ppos = &pos;
         : 659              }
         : 660              ret = vfs_write(f.file, buf, count, ppos);
    0.00 :   ffff800010233590:       mov     x1, x22
    0.00 :   ffff800010233594:       mov     x2, x23
    0.00 :   ffff800010233598:       add     x3, sp, #0x40
    0.00 :   ffff80001023359c:       mov     x0, x21
         : 655              pos = *ppos;
    0.00 :   ffff8000102335a0:       str     x4, [sp, #64]
         : 658              ret = vfs_write(f.file, buf, count, ppos);
    0.00 :   ffff8000102335a4:       bl      ffff800010233098 <vfs_write>
    0.00 :   ffff8000102335a8:       mov     x22, x0
         : 659              if (ret >= 0 && ppos)
    0.00 :   ffff8000102335ac:       tbnz    x0, #63, ffff8000102335b8 <ksys_write+0x78>
         : 660              f.file->f_pos = pos;
    0.00 :   ffff8000102335b0:       ldr     x0, [sp, #64]
    0.00 :   ffff8000102335b4:       str     x0, [x21, #104]
         : 663              fdput_pos():
         : 80               }
         :
         : 82               static inline void fdput_pos(struct fd f)
         : 83               {
         : 84               if (f.flags & FDPUT_POS_UNLOCK)
    0.00 :   ffff8000102335b8:       tbnz    w20, #1, ffff8000102335ec <ksys_write+0xac>
         : 86               fdput():
         : 45               if (fd.flags & FDPUT_FPUT)
    0.00 :   ffff8000102335bc:       tbnz    w20, #0, ffff8000102335f8 <ksys_write+0xb8>
         : 47               ksys_write():
         : 665              fdput_pos(f);
         : 666              }
         :
         : 668              return ret;
         : 669              }
    0.00 :   ffff8000102335c0:       mov     x0, x22
    0.00 :   ffff8000102335c4:       ldr     x2, [sp, #72]
    0.00 :   ffff8000102335c8:       ldr     x1, [x19]
    0.00 :   ffff8000102335cc:       eor     x1, x2, x1
    0.00 :   ffff8000102335d0:       cbnz    x1, ffff80001023362c <ksys_write+0xec>
    0.00 :   ffff8000102335d4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102335d8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102335dc:       ldr     x23, [sp, #48]
    0.00 :   ffff8000102335e0:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000102335e4:       autiasp
    0.00 :   ffff8000102335e8:       ret
         : 681              fdput_pos():
         : 81               __f_unlock_pos(f.file);
    0.00 :   ffff8000102335ec:       mov     x0, x21
    0.00 :   ffff8000102335f0:       bl      ffff80001025a908 <__f_unlock_pos>
         : 84               fdput():
         : 45               if (fd.flags & FDPUT_FPUT)
    0.00 :   ffff8000102335f4:       tbz     w20, #0, ffff8000102335c0 <ksys_write+0x80>
         : 46               fput(fd.file);
    0.00 :   ffff8000102335f8:       mov     x0, x21
    0.00 :   ffff8000102335fc:       bl      ffff8000102355a8 <fput>
    0.00 :   ffff800010233600:       b       ffff8000102335c0 <ksys_write+0x80>
         : 50               ksys_write():
         : 658              ret = vfs_write(f.file, buf, count, ppos);
    0.00 :   ffff800010233604:       mov     x1, x22
    0.00 :   ffff800010233608:       mov     x2, x23
    0.00 :   ffff80001023360c:       mov     x3, #0x0                        // #0
    0.00 :   ffff800010233610:       mov     x0, x21
    0.00 :   ffff800010233614:       bl      ffff800010233098 <vfs_write>
    0.00 :   ffff800010233618:       mov     x22, x0
         : 665              fdput_pos():
         : 80               if (f.flags & FDPUT_POS_UNLOCK)
    0.00 :   ffff80001023361c:       tbz     w20, #1, ffff8000102335bc <ksys_write+0x7c>
    0.00 :   ffff800010233620:       b       ffff8000102335ec <ksys_write+0xac>
         : 83               ksys_write():
         : 650              ssize_t ret = -EBADF;
    0.00 :   ffff800010233624:       mov     x22, #0xfffffffffffffff7        // #-9
         : 664              return ret;
    0.00 :   ffff800010233628:       b       ffff8000102335c0 <ksys_write+0x80>
         : 665              }
    0.00 :   ffff80001023362c:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010110580 <hrtimer_run_queues>:
         : 6                hrtimer_run_queues():
         :
         : 1748             /*
         : 1749             * Called from run_local_timers in hardirq context every jiffy
         : 1750             */
         : 1751             void hrtimer_run_queues(void)
         : 1752             {
    0.00 :   ffff800010110580:       paciasp
    0.00 :   ffff800010110584:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010110588:       mov     x29, sp
    0.00 :   ffff80001011058c:       stp     x19, x20, [sp, #16]
         : 1748             struct hrtimer_cpu_base *cpu_base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff800010110590:       adrp    x20, ffff800011776000 <timer_bases+0x2380>
         : 1750             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010110594:       mrs     x19, tpidr_el1
         : 46               hrtimer_run_queues():
    0.00 :   ffff800010110598:       add     x20, x20, #0x180
    0.00 :   ffff80001011059c:       add     x19, x20, x19
         : 1750             __hrtimer_hres_active():
         : 647              cpu_base->hres_active : 0;
    0.00 :   ffff8000101105a0:       ldrb    w0, [x19, #16]
         : 649              hrtimer_run_queues():
         : 1752             unsigned long flags;
         : 1753             ktime_t now;
         :
         : 1755             if (__hrtimer_hres_active(cpu_base))
    0.00 :   ffff8000101105a4:       tbz     w0, #0, ffff8000101105b8 <hrtimer_run_queues+0x38>
         : 1778             raise_softirq_irqoff(HRTIMER_SOFTIRQ);
         : 1779             }
         :
         : 1781             __hrtimer_run_queues(cpu_base, now, flags, HRTIMER_ACTIVE_HARD);
         : 1782             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
         : 1783             }
  100.00 :   ffff8000101105a8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101105ac:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101105b0:       autiasp
    0.00 :   ffff8000101105b4:       ret
         : 1788             hrtimer_is_hres_enabled():
         : 720              return hrtimer_hres_enabled;
    0.00 :   ffff8000101105b8:       str     x21, [sp, #32]
    0.00 :   ffff8000101105bc:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101105c0:       add     x0, x21, #0xbf4
         : 724              hrtimer_run_queues():
         : 1762             if (tick_check_oneshot_change(!hrtimer_is_hres_enabled())) {
    0.00 :   ffff8000101105c4:       ldrb    w0, [x0, #4]
    0.00 :   ffff8000101105c8:       eor     w0, w0, #0x1
    0.00 :   ffff8000101105cc:       bl      ffff8000101215d0 <tick_check_oneshot_change>
    0.00 :   ffff8000101105d0:       cbnz    w0, ffff80001011066c <hrtimer_run_queues+0xec>
         : 1767             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff8000101105d4:       mov     x0, x19
    0.00 :   ffff8000101105d8:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 1770             hrtimer_update_base():
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff8000101105dc:       add     x1, x19, #0xb8
         : 633              hrtimer_run_queues():
         : 1767             raw_spin_lock_irqsave(&cpu_base->lock, flags);
    0.00 :   ffff8000101105e0:       mov     x20, x0
         : 1769             hrtimer_update_base():
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff8000101105e4:       add     x3, x19, #0x138
    0.00 :   ffff8000101105e8:       add     x2, x19, #0xf8
    0.00 :   ffff8000101105ec:       add     x0, x19, #0xc
    0.00 :   ffff8000101105f0:       bl      ffff800010113218 <ktime_get_update_offsets_now>
         : 634              base->clock_base[HRTIMER_BASE_REALTIME_SOFT].offset = *offs_real;
    0.00 :   ffff8000101105f4:       ldr     x1, [x19, #184]
    0.00 :   ffff8000101105f8:       str     x1, [x19, #440]
         : 635              base->clock_base[HRTIMER_BASE_BOOTTIME_SOFT].offset = *offs_boot;
    0.00 :   ffff8000101105fc:       ldr     x1, [x19, #248]
         : 631              ktime_t now = ktime_get_update_offsets_now(&base->clock_was_set_seq,
    0.00 :   ffff800010110600:       mov     x21, x0
         : 635              base->clock_base[HRTIMER_BASE_BOOTTIME_SOFT].offset = *offs_boot;
    0.00 :   ffff800010110604:       str     x1, [x19, #504]
         : 637              ktime_compare():
         : 97               *   cmp1 == cmp2: return 0
         : 98               *   cmp1  > cmp2: return >0
         : 99               */
         : 100              static inline int ktime_compare(const ktime_t cmp1, const ktime_t cmp2)
         : 101              {
         : 102              if (cmp1 < cmp2)
    0.00 :   ffff800010110608:       ldr     x0, [x19, #48]
         : 104              hrtimer_update_base():
         : 636              base->clock_base[HRTIMER_BASE_TAI_SOFT].offset = *offs_tai;
    0.00 :   ffff80001011060c:       ldr     x1, [x19, #312]
    0.00 :   ffff800010110610:       str     x1, [x19, #568]
         : 639              ktime_compare():
    0.00 :   ffff800010110614:       cmp     x0, x21
    0.00 :   ffff800010110618:       b.gt    ffff800010110638 <hrtimer_run_queues+0xb8>
         : 99               hrtimer_run_queues():
         : 1772             cpu_base->softirq_activated = 1;
    0.00 :   ffff80001011061c:       ldrb    w1, [x19, #16]
         : 1771             cpu_base->softirq_expires_next = KTIME_MAX;
    0.00 :   ffff800010110620:       mov     x0, #0x7fffffffffffffff         // #9223372036854775807
    0.00 :   ffff800010110624:       str     x0, [x19, #48]
         : 1773             raise_softirq_irqoff(HRTIMER_SOFTIRQ);
    0.00 :   ffff800010110628:       mov     w0, #0x8                        // #8
         : 1772             cpu_base->softirq_activated = 1;
    0.00 :   ffff80001011062c:       orr     w1, w1, w0
    0.00 :   ffff800010110630:       strb    w1, [x19, #16]
         : 1773             raise_softirq_irqoff(HRTIMER_SOFTIRQ);
    0.00 :   ffff800010110634:       bl      ffff8000100893a8 <raise_softirq_irqoff>
         : 1776             __hrtimer_run_queues(cpu_base, now, flags, HRTIMER_ACTIVE_HARD);
    0.00 :   ffff800010110638:       mov     x2, x20
    0.00 :   ffff80001011063c:       mov     w3, #0xf                        // #15
    0.00 :   ffff800010110640:       mov     x1, x21
    0.00 :   ffff800010110644:       mov     x0, x19
    0.00 :   ffff800010110648:       bl      ffff80001010f860 <__hrtimer_run_queues>
         : 1777             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff80001011064c:       mov     x1, x20
    0.00 :   ffff800010110650:       mov     x0, x19
    0.00 :   ffff800010110654:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1778             }
    0.00 :   ffff800010110658:       ldp     x19, x20, [sp, #16]
         : 1777             raw_spin_unlock_irqrestore(&cpu_base->lock, flags);
    0.00 :   ffff80001011065c:       ldr     x21, [sp, #32]
         : 1778             }
    0.00 :   ffff800010110660:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010110664:       autiasp
    0.00 :   ffff800010110668:       ret
         : 1782             __kern_my_cpu_offset():
    0.00 :   ffff80001011066c:       mrs     x0, tpidr_el1
         : 40               hrtimer_switch_to_hres():
         : 746              struct hrtimer_cpu_base *base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff800010110670:       add     x20, x20, x0
         : 748              if (tick_init_highres()) {
    0.00 :   ffff800010110674:       bl      ffff8000101201d8 <tick_init_highres>
    0.00 :   ffff800010110678:       cbnz    w0, ffff8000101106b0 <hrtimer_run_queues+0x130>
         : 753              base->hres_active = 1;
    0.00 :   ffff80001011067c:       ldrb    w0, [x20, #16]
         : 754              hrtimer_resolution = HIGH_RES_NSEC;
    0.00 :   ffff800010110680:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010110684:       str     w1, [x21, #3060]
         : 753              base->hres_active = 1;
    0.00 :   ffff800010110688:       orr     w0, w0, w1
    0.00 :   ffff80001011068c:       strb    w0, [x20, #16]
         : 756              tick_setup_sched_timer();
    0.00 :   ffff800010110690:       bl      ffff800010121330 <tick_setup_sched_timer>
         : 758              retrigger_next_event(NULL);
    0.00 :   ffff800010110694:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010110698:       bl      ffff80001010fa10 <retrigger_next_event>
         : 761              hrtimer_run_queues():
         : 1778             }
    0.00 :   ffff80001011069c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101106a0:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101106a4:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101106a8:       autiasp
    0.00 :   ffff8000101106ac:       ret
         : 1784             hrtimer_switch_to_hres():
         : 749              pr_warn("Could not switch to high resolution mode on CPU %u\n",
    0.00 :   ffff8000101106b0:       ldr     w1, [x20, #4]
    0.00 :   ffff8000101106b4:       adrp    x0, ffff80001141f000 <kallsyms_token_index+0x147a0>
    0.00 :   ffff8000101106b8:       add     x0, x0, #0x8d0
    0.00 :   ffff8000101106bc:       bl      ffff800010e19544 <printk>
         : 751              return;
    0.00 :   ffff8000101106c0:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101106c4:       b       ffff8000101105a8 <hrtimer_run_queues+0x28>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010113218 <ktime_get_update_offsets_now>:
         : 6                ktime_get_update_offsets_now():
         : 2288             *
         : 2289             * Called from hrtimer_interrupt() or retrigger_next_event()
         : 2290             */
         : 2291             ktime_t ktime_get_update_offsets_now(unsigned int *cwsseq, ktime_t *offs_real,
         : 2292             ktime_t *offs_boot, ktime_t *offs_tai)
         : 2293             {
    0.00 :   ffff800010113218:       paciasp
    0.00 :   ffff80001011321c:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff800010113220:       mov     x29, sp
    0.00 :   ffff800010113224:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010113228:       adrp    x19, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff80001011322c:       mov     x20, x1
    0.00 :   ffff800010113230:       add     x19, x19, #0xf00
    0.00 :   ffff800010113234:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010113238:       mov     x22, x2
    0.00 :   ffff80001011323c:       mov     x21, x3
    0.00 :   ffff800010113240:       stp     x23, x24, [sp, #48]
         : 2310             *offs_tai = tk->offs_tai;
         : 2311             }
         :
         : 2313             /* Handle leapsecond insertion adjustments */
         : 2314             if (unlikely(base >= tk->next_leap_ktime))
         : 2315             *offs_real = ktime_sub(tk->offs_real, ktime_set(1, 0));
    0.00 :   ffff800010113244:       mov     x23, #0xffffffffffff3600        // #-51712
         : 2288             {
    0.00 :   ffff800010113248:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001011324c:       mov     x26, x0
         : 2310             *offs_real = ktime_sub(tk->offs_real, ktime_set(1, 0));
    0.00 :   ffff800010113250:       movk    x23, #0xc465, lsl #16
    0.00 :   ffff800010113254:       nop
         : 2313             __seqprop_raw_spinlock_sequence():
         : 276              lockdep_assert_preemption_disabled();
         : 277              }
         :
         : 279              #define __SEQ_RT        IS_ENABLED(CONFIG_PREEMPT_RT)
         :
         : 281              SEQCOUNT_LOCKNAME(raw_spinlock, raw_spinlock_t,  false,    s->lock,        raw_spin, raw_spin_lock(s->lock))
    0.00 :   ffff800010113258:       ldr     w24, [x19]
         : 283              ktime_get_update_offsets_now():
         : 2295             seq = read_seqcount_begin(&tk_core.seq);
    0.00 :   ffff80001011325c:       tbnz    w24, #0, ffff800010113300 <ktime_get_update_offsets_now+0xe8>
    0.00 :   ffff800010113260:       dmb     ishld
         : 2296             tk_clock_read():
         : 191              struct clocksource *clock = READ_ONCE(tkr->clock);
  100.00 :   ffff800010113264:       ldr     x1, [x19, #8]
         : 193              ktime_get_update_offsets_now():
         : 2297             base = tk->tkr_mono.base;
    0.00 :   ffff800010113268:       ldr     x25, [x19, #48]
         : 2299             tk_clock_read():
         : 193              return clock->read(clock);
    0.00 :   ffff80001011326c:       mov     x0, x1
    0.00 :   ffff800010113270:       ldr     x1, [x1]
    0.00 :   ffff800010113274:       blr     x1
         : 197              clocksource_delta():
         : 32               return ret & ~(mask >> 1) ? 0 : ret;
         : 33               }
         : 34               #else
         : 35               static inline u64 clocksource_delta(u64 now, u64 last, u64 mask)
         : 36               {
         : 37               return (now - last) & mask;
    0.00 :   ffff800010113278:       ldp     x2, x1, [x19, #16]
         : 39               timekeeping_delta_to_ns():
         : 376              nsec = delta * tkr->mult + tkr->xtime_nsec;
    0.00 :   ffff80001011327c:       ldr     w4, [x19, #32]
         : 378              ktime_get_update_offsets_now():
         : 2301             if (*cwsseq != tk->clock_was_set_seq) {
    0.00 :   ffff800010113280:       ldr     w3, [x26]
         : 2303             clocksource_delta():
    0.00 :   ffff800010113284:       sub     x0, x0, x1
         : 33               timekeeping_delta_to_ns():
         : 376              nsec = delta * tkr->mult + tkr->xtime_nsec;
    0.00 :   ffff800010113288:       ldr     x1, [x19, #40]
         : 378              clocksource_delta():
    0.00 :   ffff80001011328c:       and     x0, x0, x2
         : 33               timekeeping_delta_to_ns():
         : 377              nsec >>= tkr->shift;
    0.00 :   ffff800010113290:       ldr     w2, [x19, #36]
         : 376              nsec = delta * tkr->mult + tkr->xtime_nsec;
    0.00 :   ffff800010113294:       madd    x0, x0, x4, x1
         : 378              ktime_get_update_offsets_now():
         : 2301             if (*cwsseq != tk->clock_was_set_seq) {
    0.00 :   ffff800010113298:       ldr     w1, [x19, #180]
    0.00 :   ffff80001011329c:       cmp     w3, w1
         : 2304             timekeeping_delta_to_ns():
         : 377              nsec >>= tkr->shift;
    0.00 :   ffff8000101132a0:       lsr     x0, x0, x2
         : 379              ktime_get_update_offsets_now():
         : 2299             base = ktime_add_ns(base, nsecs);
    0.00 :   ffff8000101132a4:       add     x0, x0, x25
         : 2301             if (*cwsseq != tk->clock_was_set_seq) {
    0.00 :   ffff8000101132a8:       b.eq    ffff8000101132c8 <ktime_get_update_offsets_now+0xb0>  // b.none
         : 2302             *cwsseq = tk->clock_was_set_seq;
    0.00 :   ffff8000101132ac:       str     w1, [x26]
         : 2303             *offs_real = tk->offs_real;
    0.00 :   ffff8000101132b0:       ldr     x1, [x19, #152]
    0.00 :   ffff8000101132b4:       str     x1, [x20]
         : 2304             *offs_boot = tk->offs_boot;
    0.00 :   ffff8000101132b8:       ldr     x1, [x19, #160]
    0.00 :   ffff8000101132bc:       str     x1, [x22]
         : 2305             *offs_tai = tk->offs_tai;
    0.00 :   ffff8000101132c0:       ldr     x1, [x19, #168]
    0.00 :   ffff8000101132c4:       str     x1, [x21]
         : 2309             if (unlikely(base >= tk->next_leap_ktime))
    0.00 :   ffff8000101132c8:       ldr     x1, [x19, #192]
    0.00 :   ffff8000101132cc:       cmp     x1, x0
    0.00 :   ffff8000101132d0:       b.le    ffff800010113308 <ktime_get_update_offsets_now+0xf0>
         : 2313             do_read_seqcount_retry():
         : 452              #define read_seqcount_retry(s, start)                                   \
         : 453              do_read_seqcount_retry(seqprop_ptr(s), start)
         :
         : 455              static inline int do_read_seqcount_retry(const seqcount_t *s, unsigned start)
         : 456              {
         : 457              smp_rmb();
    0.00 :   ffff8000101132d4:       dmb     ishld
         : 459              do___read_seqcount_retry():
         : 433              return unlikely(READ_ONCE(s->sequence) != start);
    0.00 :   ffff8000101132d8:       ldr     w1, [x19]
         : 435              ktime_get_update_offsets_now():
         :
         : 2313             } while (read_seqcount_retry(&tk_core.seq, seq));
    0.00 :   ffff8000101132dc:       cmp     w24, w1
    0.00 :   ffff8000101132e0:       b.ne    ffff800010113258 <ktime_get_update_offsets_now+0x40>  // b.any
         :
         : 2316             return base;
         : 2317             }
    0.00 :   ffff8000101132e4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101132e8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101132ec:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000101132f0:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000101132f4:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000101132f8:       autiasp
    0.00 :   ffff8000101132fc:       ret
         : 2325             cpu_relax():
         :
         : 13               #ifndef __ASSEMBLY__
         :
         : 15               static inline void cpu_relax(void)
         : 16               {
         : 17               asm volatile("yield" ::: "memory");
    0.00 :   ffff800010113300:       yield
    0.00 :   ffff800010113304:       b       ffff800010113258 <ktime_get_update_offsets_now+0x40>
         : 20               ktime_get_update_offsets_now():
         : 2310             *offs_real = ktime_sub(tk->offs_real, ktime_set(1, 0));
    0.00 :   ffff800010113308:       ldr     x1, [x19, #152]
    0.00 :   ffff80001011330c:       add     x1, x1, x23
    0.00 :   ffff800010113310:       str     x1, [x20]
    0.00 :   ffff800010113314:       b       ffff8000101132d4 <ktime_get_update_offsets_now+0xbc>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010b310 <profile_tick>:
         : 6                profile_tick():
         : 403              do_profile_hits(type, __pc, nr_hits);
         : 404              }
         : 405              EXPORT_SYMBOL_GPL(profile_hits);
         :
         : 407              void profile_tick(int type)
         : 408              {
    0.00 :   ffff80001010b310:       paciasp
    0.00 :   ffff80001010b314:       stp     x29, x30, [sp, #-32]!
         : 411              get_irq_regs():
         : 21               */
         : 22               DECLARE_PER_CPU(struct pt_regs *, __irq_regs);
         :
         : 24               static inline struct pt_regs *get_irq_regs(void)
         : 25               {
         : 26               return __this_cpu_read(__irq_regs);
    0.00 :   ffff80001010b318:       adrp    x1, ffff800011777000 <lru_pvecs+0x128>
         : 28               profile_tick():
    0.00 :   ffff80001010b31c:       mov     x29, sp
         : 404              get_irq_regs():
    0.00 :   ffff80001010b320:       add     x1, x1, #0xca8
         : 22               __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001010b324:       mrs     x2, tpidr_el1
         : 46               get_irq_regs():
    0.00 :   ffff80001010b328:       ldr     x3, [x1, x2]
         : 22               profile_tick():
         : 406              struct pt_regs *regs = get_irq_regs();
         :
         : 408              if (!user_mode(regs) && cpumask_available(prof_cpu_mask) &&
    0.00 :   ffff80001010b32c:       ldr     x1, [x3, #264]
    0.00 :   ffff80001010b330:       tst     x1, #0xf
    0.00 :   ffff80001010b334:       b.eq    ffff80001010b378 <profile_tick+0x68>  // b.none
         : 407              cpumask_test_cpu(smp_processor_id(), prof_cpu_mask))
    0.00 :   ffff80001010b338:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001010b33c:       adrp    x1, ffff80001176d000 <cpu_number>
    0.00 :   ffff80001010b340:       add     x1, x1, #0x0
    0.00 :   ffff80001010b344:       ldr     w2, [x1, x2]
         : 412              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001010b348:       adrp    x19, ffff800011f4c000 <__log_buf+0x1fb98>
    0.00 :   ffff80001010b34c:       add     x19, x19, #0xe90
    0.00 :   ffff80001010b350:       cmp     w2, #0x0
    0.00 :   ffff80001010b354:       add     w1, w2, #0x3f
    0.00 :   ffff80001010b358:       csel    w1, w1, w2, lt  // lt = tstop
    0.00 :   ffff80001010b35c:       add     x4, x19, #0x18
    0.00 :   ffff80001010b360:       asr     w1, w1, #6
    0.00 :   ffff80001010b364:       sxtw    x1, w1
    0.00 :   ffff80001010b368:       ldr     x1, [x4, x1, lsl #3]
    0.00 :   ffff80001010b36c:       lsr     x2, x1, x2
         : 122              profile_tick():
         : 406              if (!user_mode(regs) && cpumask_available(prof_cpu_mask) &&
    0.00 :   ffff80001010b370:       tbnz    w2, #0, ffff80001010b384 <profile_tick+0x74>
  100.00 :   ffff80001010b374:       ldp     x19, x20, [sp, #16]
         : 409              profile_hit(type, (void *)profile_pc(regs));
         : 410              }
    0.00 :   ffff80001010b378:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001010b37c:       autiasp
    0.00 :   ffff80001010b380:       ret
    0.00 :   ffff80001010b384:       mov     w20, w0
         : 408              profile_hit(type, (void *)profile_pc(regs));
    0.00 :   ffff80001010b388:       mov     x0, x3
    0.00 :   ffff80001010b38c:       bl      ffff80001001caf8 <profile_pc>
         : 411              profile_hit():
         : 62               static inline void profile_hit(int type, void *ip)
         : 63               {
         : 64               /*
         : 65               * Speedup for the common (no profiling enabled) case:
         : 66               */
         : 67               if (unlikely(prof_on == type))
    0.00 :   ffff80001010b390:       adrp    x1, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010b394:       ldr     w1, [x1, #3056]
    0.00 :   ffff80001010b398:       cmp     w20, w1
    0.00 :   ffff80001010b39c:       b.ne    ffff80001010b374 <profile_tick+0x64>  // b.any
         : 72               profile_hits():
         : 396              if (prof_on != type || !prof_buffer)
    0.00 :   ffff80001010b3a0:       ldr     x1, [x19, #64]
    0.00 :   ffff80001010b3a4:       cbz     x1, ffff80001010b374 <profile_tick+0x64>
         : 398              do_profile_hits(type, __pc, nr_hits);
    0.00 :   ffff80001010b3a8:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001010b3ac:       bl      ffff80001010a968 <do_profile_hits.isra.14>
    0.00 :   ffff80001010b3b0:       ldp     x19, x20, [sp, #16]
         : 402              profile_tick():
         : 409              }
    0.00 :   ffff80001010b3b4:       b       ffff80001010b378 <profile_tick+0x68>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100100b8 <__do_softirq>:
         : 6                __do_softirq():
         : 517              static inline bool lockdep_softirq_start(void) { return false; }
         : 518              static inline void lockdep_softirq_end(bool in_hardirq) { }
         : 519              #endif
         :
         : 521              asmlinkage __visible void __softirq_entry __do_softirq(void)
         : 522              {
    0.00 :   ffff8000100100b8:       paciasp
    0.00 :   ffff8000100100bc:       stp     x29, x30, [sp, #-144]!
         : 525              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100100c0:       mrs     x0, sp_el0
         : 26               __do_softirq():
    0.00 :   ffff8000100100c4:       mov     x29, sp
    0.00 :   ffff8000100100c8:       stp     x19, x20, [sp, #16]
         : 518              unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
    0.00 :   ffff8000100100cc:       adrp    x3, ffff800011c27000 <bit_wait_table+0xe80>
         : 517              {
    0.00 :   ffff8000100100d0:       stp     x21, x22, [sp, #32]
         : 533              * softirq. A softirq handled, such as network RX, might set PF_MEMALLOC
         : 534              * again if the socket is related to swapping.
         : 535              */
         : 536              current->flags &= ~PF_MEMALLOC;
         :
         : 538              pending = local_softirq_pending();
    0.00 :   ffff8000100100d4:       adrp    x21, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100100d8:       add     x2, x21, #0x580
         : 517              {
    0.00 :   ffff8000100100dc:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100100e0:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100100e4:       stp     x27, x28, [sp, #80]
         : 519              unsigned long old_flags = current->flags;
    0.00 :   ffff8000100100e8:       ldr     w1, [x0, #36]
         : 518              unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
    0.00 :   ffff8000100100ec:       ldr     x24, [x3, #2432]
         : 519              unsigned long old_flags = current->flags;
    0.00 :   ffff8000100100f0:       str     w1, [sp, #132]
         : 531              current->flags &= ~PF_MEMALLOC;
    0.00 :   ffff8000100100f4:       and     w1, w1, #0xfffff7ff
    0.00 :   ffff8000100100f8:       str     w1, [x0, #36]
         : 534              __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000100100fc:       ldr     w1, [x0, #8]
         : 53               __do_softirq():
         : 518              unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
    0.00 :   ffff800010010100:       add     x3, x24, #0x1
         : 533              pending = local_softirq_pending();
    0.00 :   ffff800010010104:       str     x2, [sp, #96]
         : 535              __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff800010010108:       add     w1, w1, #0x100
         : 49               __do_softirq():
         : 518              unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
    0.00 :   ffff80001001010c:       str     x3, [sp, #112]
         : 520              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010010110:       mrs     x3, tpidr_el1
         : 46               __do_softirq():
         : 533              pending = local_softirq_pending();
    0.00 :   ffff800010010114:       ldr     w24, [x2, x3]
         : 535              __preempt_count_add():
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010010118:       str     w1, [x0, #8]
         : 50               account_softirq_enter():
         : 141              #endif
         :
         : 143              static inline void account_softirq_enter(struct task_struct *tsk)
         : 144              {
         : 145              vtime_account_irq(tsk, SOFTIRQ_OFFSET);
         : 146              irqtime_account_irq(tsk, SOFTIRQ_OFFSET);
    0.00 :   ffff80001001011c:       mov     w1, #0x100                      // #256
    0.00 :   ffff800010010120:       bl      ffff8000100ba3b8 <irqtime_account_irq>
    0.00 :   ffff800010010124:       adrp    x23, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff800010010128:       add     x0, x23, #0x6b8
         : 151              __do_softirq():
         :
         : 548              local_irq_enable();
         :
         : 550              h = softirq_vec;
         :
         : 552              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff80001001012c:       adrp    x20, ffff800011c26000 <boot_args>
         :
         : 563              trace_softirq_entry(vec_nr);
         : 564              h->action(h);
         : 565              trace_softirq_exit(vec_nr);
         : 566              if (unlikely(prev_count != preempt_count())) {
         : 567              pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
    0.00 :   ffff800010010130:       adrp    x26, ffff800010e6a000 <cpu_bit_bitmap+0x3a0>
         : 547              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff800010010134:       add     x20, x20, #0xc0
    0.00 :   ffff800010010138:       str     x0, [sp, #104]
         : 562              pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
    0.00 :   ffff80001001013c:       add     x0, x26, #0x518
    0.00 :   ffff800010010140:       str     x0, [sp, #136]
         : 565              account_softirq_enter():
    0.00 :   ffff800010010144:       mov     w0, #0xa                        // #10
    0.00 :   ffff800010010148:       str     w0, [sp, #128]
         : 143              __kern_my_cpu_offset():
    0.00 :   ffff80001001014c:       mrs     x2, tpidr_el1
         : 40               arch_local_irq_enable():
         : 35               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 37               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 38               }
         :
         : 40               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010010150:       mov     x1, #0xe0                       // #224
         : 42               __do_softirq():
         : 541              set_softirq_pending(0);
    0.00 :   ffff800010010154:       ldr     x0, [sp, #96]
    0.00 :   ffff800010010158:       str     wzr, [x0, x2]
         : 544              arch_local_irq_enable():
    0.00 :   ffff80001001015c:       msr     daifclr, #0x3
         : 36               arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010010160:       nop
         : 28               __do_softirq():
         : 547              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff800010010164:       rbit    w23, w24
    0.00 :   ffff800010010168:       cmp     w24, #0x0
    0.00 :   ffff80001001016c:       clz     w23, w23
    0.00 :   ffff800010010170:       csinc   w23, wzr, w23, eq  // eq = none
    0.00 :   ffff800010010174:       cbz     w23, ffff800010010220 <__do_softirq+0x168>
    0.00 :   ffff800010010178:       adrp    x19, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff80001001017c:       mov     x26, x20
    0.00 :   ffff800010010180:       add     x19, x19, #0x778
         : 562              pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
    0.00 :   ffff800010010184:       adrp    x22, ffff800011418000 <kallsyms_token_index+0xd7a0>
    0.00 :   ffff800010010188:       add     x0, x22, #0x248
    0.00 :   ffff80001001018c:       str     x0, [sp, #120]
         : 551              h += softirq_bit - 1;
    0.00 :   ffff800010010190:       sbfiz   x22, x23, #3, #32
         : 568              vec_nr, softirq_to_name[vec_nr], h->action,
         : 569              prev_count, preempt_count());
         : 570              preempt_count_set(prev_count);
         : 571              }
         : 572              h++;
         : 573              pending >>= softirq_bit;
    0.00 :   ffff800010010194:       lsr     w24, w24, w23
         : 551              h += softirq_bit - 1;
    0.00 :   ffff800010010198:       sub     x21, x22, #0x8
         : 547              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff80001001019c:       rbit    w23, w24
         : 551              h += softirq_bit - 1;
    0.00 :   ffff8000100101a0:       add     x0, x26, x21
         : 547              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff8000100101a4:       clz     w23, w23
         : 553              vec_nr = h - softirq_vec;
    0.00 :   ffff8000100101a8:       sub     x2, x0, x20
         : 555              __kern_my_cpu_offset():
    0.00 :   ffff8000100101ac:       mrs     x5, tpidr_el1
         : 40               __do_softirq():
    0.00 :   ffff8000100101b0:       asr     x27, x2, #3
         : 554              get_current():
    0.00 :   ffff8000100101b4:       mrs     x28, sp_el0
         : 20               kstat_incr_softirqs_this_cpu():
         : 59               extern unsigned int kstat_irqs_cpu(unsigned int irq, int cpu);
         : 60               extern void kstat_incr_irq_this_cpu(unsigned int irq);
         :
         : 62               static inline void kstat_incr_softirqs_this_cpu(unsigned int irq)
         : 63               {
         : 64               __this_cpu_inc(kstat.softirqs[irq]);
    0.00 :   ffff8000100101b8:       ubfiz   x1, x27, #2, #32
         : 66               preempt_count():
         : 12               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000100101bc:       ldr     w25, [x28, #8]
         : 14               kstat_incr_softirqs_this_cpu():
    0.00 :   ffff8000100101c0:       add     x1, x1, #0x8
    0.00 :   ffff8000100101c4:       add     x1, x19, x1
    0.00 :   ffff8000100101c8:       ldr     w3, [x1, x5]
    0.00 :   ffff8000100101cc:       add     w3, w3, #0x1
    0.00 :   ffff8000100101d0:       str     w3, [x1, x5]
         : 64               __do_softirq():
         : 559              h->action(h);
    0.00 :   ffff8000100101d4:       ldr     x1, [x26, x21]
    0.00 :   ffff8000100101d8:       blr     x1
         : 562              preempt_count():
    0.00 :   ffff8000100101dc:       ldr     w0, [x28, #8]
         : 13               __do_softirq():
         : 561              if (unlikely(prev_count != preempt_count())) {
    0.00 :   ffff8000100101e0:       cmp     w0, w25
    0.00 :   ffff8000100101e4:       b.eq    ffff800010010210 <__do_softirq+0x158>  // b.none
         : 562              pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
    0.00 :   ffff8000100101e8:       ldr     x0, [sp, #136]
    0.00 :   ffff8000100101ec:       mov     w1, w27
         : 565              preempt_count():
    0.00 :   ffff8000100101f0:       ldr     w5, [x28, #8]
         : 13               __do_softirq():
    0.00 :   ffff8000100101f4:       mov     w4, w25
    0.00 :   ffff8000100101f8:       ldr     x3, [x26, x21]
    0.00 :   ffff8000100101fc:       ldr     x2, [x0, w27, uxtw #3]
    0.00 :   ffff800010010200:       ldr     x0, [sp, #120]
    0.00 :   ffff800010010204:       bl      ffff800010e19544 <printk>
         : 567              preempt_count_set():
         : 18               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010010208:       str     w25, [x28, #8]
    0.00 :   ffff80001001020c:       nop
         : 21               __do_softirq():
         : 547              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff800010010210:       cmp     w24, #0x0
         : 567              h++;
    0.00 :   ffff800010010214:       add     x26, x26, x22
         : 547              while ((softirq_bit = ffs(pending))) {
    0.00 :   ffff800010010218:       csinc   w23, wzr, w23, eq  // eq = none
    0.00 :   ffff80001001021c:       cbnz    w23, ffff800010010190 <__do_softirq+0xd8>
         : 550              __kern_my_cpu_offset():
    0.00 :   ffff800010010220:       mrs     x1, tpidr_el1
         : 40               __do_softirq():
         : 572              }
         :
         : 574              if (!IS_ENABLED(CONFIG_PREEMPT_RT) &&
         : 575              __this_cpu_read(ksoftirqd) == current)
    0.00 :   ffff800010010224:       ldr     x0, [sp, #104]
         : 571              if (!IS_ENABLED(CONFIG_PREEMPT_RT) &&
    0.00 :   ffff800010010228:       ldr     x1, [x0, x1]
         : 573              get_current():
    0.00 :   ffff80001001022c:       mrs     x0, sp_el0
         : 20               __do_softirq():
    0.00 :   ffff800010010230:       cmp     x1, x0
    0.00 :   ffff800010010234:       b.eq    ffff80001001031c <__do_softirq+0x264>  // b.none
         : 573              arch_static_branch():
    0.00 :   ffff800010010238:       nop
    0.00 :   ffff80001001023c:       mov     x0, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 56               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 57               }
         :
         : 59               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010010240:       msr     daifset, #0x3
         : 61               __kern_my_cpu_offset():
    0.00 :   ffff800010010244:       mrs     x1, tpidr_el1
         : 40               __do_softirq():
         : 577              rcu_softirq_qs();
         :
         : 579              local_irq_disable();
         :
         : 581              pending = local_softirq_pending();
    0.00 :   ffff800010010248:       ldr     x0, [sp, #96]
    0.00 :   ffff80001001024c:       ldr     w24, [x0, x1]
         : 578              if (pending) {
    0.00 :   ffff800010010250:       cbz     w24, ffff800010010288 <__do_softirq+0x1d0>
         : 579              if (time_before(jiffies, end) && !need_resched() &&
    0.00 :   ffff800010010254:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010010258:       ldr     x1, [sp, #112]
    0.00 :   ffff80001001025c:       ldr     x0, [x0, #2432]
    0.00 :   ffff800010010260:       cmp     x0, x1
    0.00 :   ffff800010010264:       b.pl    ffff800010010284 <__do_softirq+0x1cc>  // b.nfrst
         : 585              get_current():
    0.00 :   ffff800010010268:       mrs     x0, sp_el0
         : 20               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001001026c:       ldr     x0, [x0]
         : 113              __do_softirq():
    0.00 :   ffff800010010270:       tbnz    w0, #1, ffff800010010284 <__do_softirq+0x1cc>
    0.00 :   ffff800010010274:       ldr     w0, [sp, #128]
    0.00 :   ffff800010010278:       subs    w0, w0, #0x1
    0.00 :   ffff80001001027c:       str     w0, [sp, #128]
    0.00 :   ffff800010010280:       b.ne    ffff80001001014c <__do_softirq+0x94>  // b.any
         : 583              --max_restart)
         : 584              goto restart;
         :
         : 586              wakeup_softirqd();
    0.00 :   ffff800010010284:       bl      ffff8000100889b0 <wakeup_softirqd>
         : 588              get_current():
    0.00 :   ffff800010010288:       mrs     x19, sp_el0
         : 20               account_softirq_exit():
         : 147              }
         :
         : 149              static inline void account_softirq_exit(struct task_struct *tsk)
         : 150              {
         : 151              vtime_account_softirq(tsk);
         : 152              irqtime_account_irq(tsk, 0);
    0.00 :   ffff80001001028c:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010010290:       mov     x0, x19
    0.00 :   ffff800010010294:       bl      ffff8000100ba3b8 <irqtime_account_irq>
         : 156              preempt_count():
         : 12               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010010298:       ldr     w0, [x19, #8]
    0.00 :   ffff80001001029c:       ldr     w0, [x19, #8]
         : 15               __preempt_count_sub():
         : 53               }
         :
         : 55               static inline void __preempt_count_sub(int val)
         : 56               {
         : 57               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000100102a0:       ldr     w0, [x19, #8]
         : 54               pc -= val;
    0.00 :   ffff8000100102a4:       sub     w0, w0, #0x100
         : 55               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000100102a8:       str     w0, [x19, #8]
         : 57               preempt_count():
         : 12               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000100102ac:       ldr     w0, [x19, #8]
    0.00 :   ffff8000100102b0:       ldr     w2, [x19, #8]
    0.00 :   ffff8000100102b4:       ldr     w1, [x19, #8]
         : 16               softirq_handle_end():
         : 403              WARN_ON_ONCE(in_interrupt());
    0.00 :   ffff8000100102b8:       and     w0, w0, #0xf00000
    0.00 :   ffff8000100102bc:       and     w2, w2, #0xf0000
    0.00 :   ffff8000100102c0:       orr     w0, w0, w2
    0.00 :   ffff8000100102c4:       and     w1, w1, #0xff00
    0.00 :   ffff8000100102c8:       orr     w0, w0, w1
    0.00 :   ffff8000100102cc:       cbnz    w0, ffff800010010324 <__do_softirq+0x26c>
         : 410              current_restore_flags():
         : 1683             TASK_PFA_CLEAR(SPREAD_PAGE, spread_page)
         :
         : 1685             TASK_PFA_TEST(SPREAD_SLAB, spread_slab)
         : 1686             TASK_PFA_SET(SPREAD_SLAB, spread_slab)
         : 1687             TASK_PFA_CLEAR(SPREAD_SLAB, spread_slab)
         :
    0.00 :   ffff8000100102d0:       ldr     w2, [sp, #132]
         : 1690             get_current():
    0.00 :   ffff8000100102d4:       mrs     x1, sp_el0
         : 20               current_restore_flags():
         : 1682             TASK_PFA_CLEAR(SPREAD_SLAB, spread_slab)
    0.00 :   ffff8000100102d8:       ldr     w0, [x1, #36]
         :
    0.00 :   ffff8000100102dc:       and     w28, w2, #0x800
         : 1682             TASK_PFA_CLEAR(SPREAD_SLAB, spread_slab)
    0.00 :   ffff8000100102e0:       and     w0, w0, #0xfffff7ff
         :
    0.00 :   ffff8000100102e4:       orr     w28, w0, w28
    0.00 :   ffff8000100102e8:       str     w28, [x1, #36]
         : 1686             __do_softirq():
         :
         : 591              account_softirq_exit(current);
         : 592              lockdep_softirq_end(in_hardirq);
         : 593              softirq_handle_end();
         : 594              current_restore_flags(old_flags, PF_MEMALLOC);
         : 595              }
    0.00 :   ffff8000100102ec:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100102f0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100102f4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100102f8:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100102fc:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010010300:       ldp     x29, x30, [sp], #144
    0.00 :   ffff800010010304:       autiasp
    0.00 :   ffff800010010308:       ret
         : 604              arch_local_irq_enable():
         : 43               pmr_sync();
    0.00 :   ffff80001001030c:       dsb     sy
  100.00 :   ffff800010010310:       b       ffff800010010164 <__do_softirq+0xac>
         : 46               arch_static_branch():
    0.00 :   ffff800010010314:       mov     x0, #0xa0                       // #160
    0.00 :   ffff800010010318:       b       ffff800010010240 <__do_softirq+0x188>
         : 23               __do_softirq():
         : 573              rcu_softirq_qs();
    0.00 :   ffff80001001031c:       bl      ffff800010102b68 <rcu_softirq_qs>
    0.00 :   ffff800010010320:       b       ffff800010010238 <__do_softirq+0x180>
         : 576              softirq_handle_end():
         : 403              WARN_ON_ONCE(in_interrupt());
    0.00 :   ffff800010010324:       brk     #0x800
    0.00 :   ffff800010010328:       b       ffff8000100102d0 <__do_softirq+0x218>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001011ae20 <run_posix_cpu_timers>:
         : 6                run_posix_cpu_timers():
         : 1297             * This is called from the timer interrupt handler.  The irq handler has
         : 1298             * already updated our counts.  We need to check if any timers fire now.
         : 1299             * Interrupts are disabled.
         : 1300             */
         : 1301             void run_posix_cpu_timers(void)
         : 1302             {
    0.00 :   ffff80001011ae20:       paciasp
    0.00 :   ffff80001011ae24:       stp     x29, x30, [sp, #-144]!
    0.00 :   ffff80001011ae28:       mov     x29, sp
    0.00 :   ffff80001011ae2c:       stp     x19, x20, [sp, #16]
         : 1307             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001011ae30:       mrs     x19, sp_el0
         : 26               expiry_cache_is_inactive():
         : 147              return !(~pct->bases[CPUCLOCK_PROF].nextevt |
    0.00 :   ffff80001011ae34:       add     x20, x19, #0x598
         : 149              run_posix_cpu_timers():
         : 1297             {
    0.00 :   ffff80001011ae38:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001011ae3c:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
         : 1300             expiry_cache_is_inactive():
         : 147              return !(~pct->bases[CPUCLOCK_PROF].nextevt |
    0.00 :   ffff80001011ae40:       ldr     x1, [x19, #1432]
         : 149              run_posix_cpu_timers():
         : 1297             {
    0.00 :   ffff80001011ae44:       add     x22, x22, #0x948
         : 1299             expiry_cache_is_inactive():
         : 148              ~pct->bases[CPUCLOCK_VIRT].nextevt |
    0.00 :   ffff80001011ae48:       ldr     x2, [x20, #24]
         : 150              run_posix_cpu_timers():
         : 1297             {
  100.00 :   ffff80001011ae4c:       ldr     x0, [x22]
    0.00 :   ffff80001011ae50:       str     x0, [sp, #136]
    0.00 :   ffff80001011ae54:       mov     x0, #0x0                        // #0
         : 1301             expiry_cache_is_inactive():
         : 149              ~pct->bases[CPUCLOCK_SCHED].nextevt);
    0.00 :   ffff80001011ae58:       ldr     x3, [x20, #48]
         : 147              return !(~pct->bases[CPUCLOCK_PROF].nextevt |
    0.00 :   ffff80001011ae5c:       and     x0, x1, x2
         : 148              ~pct->bases[CPUCLOCK_VIRT].nextevt |
    0.00 :   ffff80001011ae60:       and     x0, x0, x3
         : 150              fastpath_timer_check():
         : 1054             if (!expiry_cache_is_inactive(pct)) {
    0.00 :   ffff80001011ae64:       cmn     x0, #0x1
    0.00 :   ffff80001011ae68:       b.eq    ffff80001011ae8c <run_posix_cpu_timers+0x6c>  // b.none
         : 1057             task_cputimers_expired():
         : 1033             if (samples[i] >= pct->bases[i].nextevt)
    0.00 :   ffff80001011ae6c:       ldr     x4, [x19, #200]
         : 1035             task_cputime():
         : 28               extern u64 task_gtime(struct task_struct *t);
         : 29               #else
         : 30               static inline void task_cputime(struct task_struct *t,
         : 31               u64 *utime, u64 *stime)
         : 32               {
         : 33               *utime = t->utime;
    0.00 :   ffff80001011ae70:       ldr     x0, [x19, #1336]
         : 35               task_cputimers_expired():
    0.00 :   ffff80001011ae74:       cmp     x3, x4
         : 1034             store_samples():
         : 209              samples[CPUCLOCK_PROF] = stime + utime;
    0.00 :   ffff80001011ae78:       ldr     x3, [x19, #1344]
         : 211              task_cputimers_expired():
         : 1033             if (samples[i] >= pct->bases[i].nextevt)
    0.00 :   ffff80001011ae7c:       ccmp    x2, x0, #0x0, hi  // hi = pmore
         : 1035             store_samples():
         : 209              samples[CPUCLOCK_PROF] = stime + utime;
    0.00 :   ffff80001011ae80:       add     x0, x0, x3
         : 211              task_cputimers_expired():
         : 1033             if (samples[i] >= pct->bases[i].nextevt)
    0.00 :   ffff80001011ae84:       ccmp    x1, x0, #0x0, hi  // hi = pmore
    0.00 :   ffff80001011ae88:       b.ls    ffff80001011af08 <run_posix_cpu_timers+0xe8>  // b.plast
         : 1036             fastpath_timer_check():
         : 1062             sig = tsk->signal;
    0.00 :   ffff80001011ae8c:       ldr     x0, [x19, #1624]
         : 1079             if (READ_ONCE(pct->timers_active) && !READ_ONCE(pct->expiry_active)) {
    0.00 :   ffff80001011ae90:       add     x1, x0, #0x110
    0.00 :   ffff80001011ae94:       ldr     w2, [x0, #344]
    0.00 :   ffff80001011ae98:       cbnz    w2, ffff80001011aec8 <run_posix_cpu_timers+0xa8>
         : 1083             dl_prio():
         :
         : 14               #define MAX_DL_PRIO             0
         :
         : 16               static inline int dl_prio(int prio)
         : 17               {
         : 18               if (unlikely(prio < MAX_DL_PRIO))
    0.00 :   ffff80001011ae9c:       ldr     w0, [x19, #100]
    0.00 :   ffff80001011aea0:       tbnz    w0, #31, ffff80001011b1cc <run_posix_cpu_timers+0x3ac>
         : 21               run_posix_cpu_timers():
         : 1317             */
         : 1318             if (!fastpath_timer_check(tsk))
         : 1319             return;
         :
         : 1321             __run_posix_cpu_timers(tsk);
         : 1322             }
    0.00 :   ffff80001011aea4:       ldr     x1, [sp, #136]
    0.00 :   ffff80001011aea8:       ldr     x0, [x22]
    0.00 :   ffff80001011aeac:       eor     x0, x1, x0
    0.00 :   ffff80001011aeb0:       cbnz    x0, ffff80001011b280 <run_posix_cpu_timers+0x460>
    0.00 :   ffff80001011aeb4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001011aeb8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001011aebc:       ldp     x29, x30, [sp], #144
    0.00 :   ffff80001011aec0:       autiasp
    0.00 :   ffff80001011aec4:       ret
         : 1332             fastpath_timer_check():
         : 1079             if (READ_ONCE(pct->timers_active) && !READ_ONCE(pct->expiry_active)) {
    0.00 :   ffff80001011aec8:       ldr     w2, [x0, #348]
    0.00 :   ffff80001011aecc:       cbnz    w2, ffff80001011ae9c <run_posix_cpu_timers+0x7c>
         : 1082             atomic64_read():
         : 838              static __always_inline s64
         : 839              atomic64_dec_return_acquire(atomic64_t *v)
         : 840              {
         : 841              instrument_atomic_read_write(v, sizeof(*v));
         : 842              return arch_atomic64_dec_return_acquire(v);
         : 843              }
    0.00 :   ffff80001011aed0:       ldr     x3, [x0, #248]
    0.00 :   ffff80001011aed4:       ldr     x2, [x0, #256]
    0.00 :   ffff80001011aed8:       ldr     x4, [x0, #264]
         : 847              store_samples():
         : 209              samples[CPUCLOCK_PROF] = stime + utime;
    0.00 :   ffff80001011aedc:       add     x2, x2, x3
         : 211              task_cputimers_expired():
         : 1033             if (samples[i] >= pct->bases[i].nextevt)
    0.00 :   ffff80001011aee0:       ldr     x0, [x0, #272]
    0.00 :   ffff80001011aee4:       cmp     x2, x0
    0.00 :   ffff80001011aee8:       b.cs    ffff80001011af08 <run_posix_cpu_timers+0xe8>  // b.hs, b.nlast
    0.00 :   ffff80001011aeec:       ldr     x0, [x1, #24]
    0.00 :   ffff80001011aef0:       cmp     x3, x0
    0.00 :   ffff80001011aef4:       b.cs    ffff80001011af08 <run_posix_cpu_timers+0xe8>  // b.hs, b.nlast
    0.00 :   ffff80001011aef8:       ldr     x0, [x1, #48]
    0.00 :   ffff80001011aefc:       cmp     x4, x0
    0.00 :   ffff80001011af00:       b.cc    ffff80001011ae9c <run_posix_cpu_timers+0x7c>  // b.lo, b.ul, b.last
    0.00 :   ffff80001011af04:       nop
         : 1044             lock_task_sighand():
         : 701              extern bool thread_group_exited(struct pid *pid);
         :
         : 703              extern struct sighand_struct *__lock_task_sighand(struct task_struct *task,
         : 704              unsigned long *flags);
         :
         : 706              static inline struct sighand_struct *lock_task_sighand(struct task_struct *task,
    0.00 :   ffff80001011af08:       add     x1, sp, #0x58
    0.00 :   ffff80001011af0c:       mov     x0, x19
    0.00 :   ffff80001011af10:       stp     x23, x24, [sp, #48]
         : 710              handle_posix_cpu_timers():
         : 1195             LIST_HEAD(firing);
    0.00 :   ffff80001011af14:       add     x23, sp, #0x60
    0.00 :   ffff80001011af18:       stp     x23, x23, [sp, #96]
         : 1198             lock_task_sighand():
    0.00 :   ffff80001011af1c:       bl      ffff800010092bb8 <__lock_task_sighand>
         : 702              handle_posix_cpu_timers():
         : 1197             if (!lock_task_sighand(tsk, &flags))
    0.00 :   ffff80001011af20:       cbz     x0, ffff80001011b084 <run_posix_cpu_timers+0x264>
         : 1206             start = READ_ONCE(jiffies);
    0.00 :   ffff80001011af24:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff80001011af28:       ldr     x0, [x0, #2432]
         : 1209             dl_prio():
    0.00 :   ffff80001011af2c:       ldr     w0, [x19, #100]
    0.00 :   ffff80001011af30:       tbnz    w0, #31, ffff80001011b25c <run_posix_cpu_timers+0x43c>
         : 15               expiry_cache_is_inactive():
         : 147              return !(~pct->bases[CPUCLOCK_PROF].nextevt |
    0.00 :   ffff80001011af34:       ldr     x2, [x20, #24]
    0.00 :   ffff80001011af38:       ldr     x0, [x19, #1432]
         : 148              ~pct->bases[CPUCLOCK_VIRT].nextevt |
    0.00 :   ffff80001011af3c:       ldr     x1, [x20, #48]
         : 147              return !(~pct->bases[CPUCLOCK_PROF].nextevt |
    0.00 :   ffff80001011af40:       and     x0, x0, x2
         : 148              ~pct->bases[CPUCLOCK_VIRT].nextevt |
    0.00 :   ffff80001011af44:       and     x0, x0, x1
         : 150              check_thread_timers():
         : 841              if (expiry_cache_is_inactive(pct))
    0.00 :   ffff80001011af48:       cmn     x0, #0x1
    0.00 :   ffff80001011af4c:       b.eq    ffff80001011b08c <run_posix_cpu_timers+0x26c>  // b.none
         : 844              task_cputime():
    0.00 :   ffff80001011af50:       ldr     x4, [x19, #1336]
         : 29               check_thread_timers():
         : 845              collect_posix_cputimers(pct, samples, firing);
    0.00 :   ffff80001011af54:       mov     x0, x20
         : 847              store_samples():
         : 209              samples[CPUCLOCK_PROF] = stime + utime;
    0.00 :   ffff80001011af58:       ldr     x3, [x19, #1344]
         : 211              check_thread_timers():
         : 845              collect_posix_cputimers(pct, samples, firing);
    0.00 :   ffff80001011af5c:       mov     x2, x23
         : 847              task_sample_cputime():
         : 219              store_samples(samples, stime, utime, p->se.sum_exec_runtime);
    0.00 :   ffff80001011af60:       ldr     x5, [x19, #200]
         : 221              store_samples():
         : 209              samples[CPUCLOCK_PROF] = stime + utime;
    0.00 :   ffff80001011af64:       add     x3, x3, x4
         : 211              check_thread_timers():
         : 845              collect_posix_cputimers(pct, samples, firing);
    0.00 :   ffff80001011af68:       add     x1, sp, #0x70
         : 847              store_samples():
         : 210              samples[CPUCLOCK_VIRT] = utime;
    0.00 :   ffff80001011af6c:       stp     x3, x4, [sp, #112]
         : 211              samples[CPUCLOCK_SCHED] = rtime;
    0.00 :   ffff80001011af70:       str     x5, [sp, #128]
         : 213              check_thread_timers():
         : 845              collect_posix_cputimers(pct, samples, firing);
    0.00 :   ffff80001011af74:       bl      ffff800010119b10 <collect_posix_cputimers>
         : 847              task_rlimit():
         :
         : 716              static inline void unlock_task_sighand(struct task_struct *task,
         : 717              unsigned long *flags)
         : 718              {
         : 719              spin_unlock_irqrestore(&task->sighand->siglock, *flags);
         : 720              }
    0.00 :   ffff80001011af78:       ldr     x20, [x19, #1624]
    0.00 :   ffff80001011af7c:       ldr     x21, [x20, #912]
         : 723              check_thread_timers():
         : 851              if (soft != RLIM_INFINITY) {
    0.00 :   ffff80001011af80:       cmn     x21, #0x1
    0.00 :   ffff80001011af84:       b.eq    ffff80001011aff8 <run_posix_cpu_timers+0x1d8>  // b.none
         : 853              unsigned long rttime = tsk->rt.timeout * (USEC_PER_SEC / HZ);
    0.00 :   ffff80001011af88:       ldr     x0, [x19, #400]
         : 855              task_rlimit_max():
         :
         : 722              static inline unsigned long task_rlimit(const struct task_struct *task,
         : 723              unsigned int limit)
         : 724              {
         : 725              return READ_ONCE(task->signal->rlim[limit].rlim_cur);
         : 726              }
    0.00 :   ffff80001011af8c:       ldr     x1, [x20, #920]
         : 728              check_thread_timers():
    0.00 :   ffff80001011af90:       lsl     x20, x0, #5
    0.00 :   ffff80001011af94:       sub     x20, x20, x0
         : 857              if (hard != RLIM_INFINITY &&
    0.00 :   ffff80001011af98:       cmn     x1, #0x1
         : 853              unsigned long rttime = tsk->rt.timeout * (USEC_PER_SEC / HZ);
    0.00 :   ffff80001011af9c:       add     x20, x0, x20, lsl #2
    0.00 :   ffff80001011afa0:       lsl     x20, x20, #5
         : 857              if (hard != RLIM_INFINITY &&
    0.00 :   ffff80001011afa4:       b.eq    ffff80001011afc4 <run_posix_cpu_timers+0x1a4>  // b.none
         : 858              check_rlimit(rttime, hard, SIGKILL, true, true))
    0.00 :   ffff80001011afa8:       mov     w4, #0x1                        // #1
    0.00 :   ffff80001011afac:       mov     w2, #0x9                        // #9
    0.00 :   ffff80001011afb0:       mov     w3, w4
    0.00 :   ffff80001011afb4:       mov     x0, x20
    0.00 :   ffff80001011afb8:       bl      ffff800010119e80 <check_rlimit>
         : 857              if (hard != RLIM_INFINITY &&
    0.00 :   ffff80001011afbc:       tst     w0, #0xff
    0.00 :   ffff80001011afc0:       b.ne    ffff80001011b08c <run_posix_cpu_timers+0x26c>  // b.any
         : 862              if (check_rlimit(rttime, soft, SIGXCPU, true, false)) {
    0.00 :   ffff80001011afc4:       mov     x0, x20
    0.00 :   ffff80001011afc8:       mov     w4, #0x0                        // #0
    0.00 :   ffff80001011afcc:       mov     w3, #0x1                        // #1
    0.00 :   ffff80001011afd0:       mov     w2, #0x18                       // #24
    0.00 :   ffff80001011afd4:       mov     x1, x21
    0.00 :   ffff80001011afd8:       bl      ffff800010119e80 <check_rlimit>
    0.00 :   ffff80001011afdc:       tst     w0, #0xff
    0.00 :   ffff80001011afe0:       b.eq    ffff80001011b08c <run_posix_cpu_timers+0x26c>  // b.none
         : 864              tsk->signal->rlim[RLIMIT_RTTIME].rlim_cur = soft;
    0.00 :   ffff80001011afe4:       ldr     x0, [x19, #1624]
         : 863              soft += USEC_PER_SEC;
    0.00 :   ffff80001011afe8:       add     x21, x21, #0xf4, lsl #12
    0.00 :   ffff80001011afec:       add     x21, x21, #0x240
         : 864              tsk->signal->rlim[RLIMIT_RTTIME].rlim_cur = soft;
    0.00 :   ffff80001011aff0:       str     x21, [x0, #912]
    0.00 :   ffff80001011aff4:       ldr     x20, [x19, #1624]
         : 867              check_process_timers():
         : 921              if (!READ_ONCE(pct->timers_active) || pct->expiry_active)
    0.00 :   ffff80001011aff8:       add     x21, x20, #0x110
    0.00 :   ffff80001011affc:       ldr     w0, [x21, #72]
    0.00 :   ffff80001011b000:       cbz     w0, ffff80001011b00c <run_posix_cpu_timers+0x1ec>
    0.00 :   ffff80001011b004:       ldr     w0, [x21, #76]
    0.00 :   ffff80001011b008:       cbz     w0, ffff80001011b094 <run_posix_cpu_timers+0x274>
         : 927              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001011b00c:       ldr     x1, [sp, #88]
    0.00 :   ffff80001011b010:       ldr     x0, [x19, #1632]
    0.00 :   ffff80001011b014:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 418              handle_posix_cpu_timers():
         : 1266             list_for_each_entry_safe(timer, next, &firing, it.cpu.elist) {
    0.00 :   ffff80001011b018:       ldr     x19, [sp, #96]
    0.00 :   ffff80001011b01c:       mov     x20, x19
    0.00 :   ffff80001011b020:       cmp     x19, x23
    0.00 :   ffff80001011b024:       ldr     x21, [x19], #-168
    0.00 :   ffff80001011b028:       sub     x21, x21, #0xa8
    0.00 :   ffff80001011b02c:       b.eq    ffff80001011b084 <run_posix_cpu_timers+0x264>  // b.none
         : 1273             spin_lock():
         :
    0.00 :   ffff80001011b030:       add     x24, x19, #0x20
    0.00 :   ffff80001011b034:       mov     x0, x24
    0.00 :   ffff80001011b038:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 358              list_del_init():
         : 204              * list_del_init - deletes entry from list and reinitialize it.
         : 205              * @entry: the element to delete from the list.
         : 206              */
         : 207              static inline void list_del_init(struct list_head *entry)
         : 208              {
         : 209              __list_del_entry(entry);
    0.00 :   ffff80001011b03c:       ldp     x1, x0, [x19, #168]
         : 211              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff80001011b040:       str     x0, [x1, #8]
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff80001011b044:       str     x1, [x0]
         : 115              INIT_LIST_HEAD():
         : 35               WRITE_ONCE(list->next, list);
    0.00 :   ffff80001011b048:       str     x20, [x19, #168]
         : 37               handle_posix_cpu_timers():
         : 1278             cpu_firing = timer->it.cpu.firing;
    0.00 :   ffff80001011b04c:       ldr     w0, [x19, #184]
         : 1280             INIT_LIST_HEAD():
         : 36               list->prev = list;
    0.00 :   ffff80001011b050:       str     x20, [x19, #176]
         : 38               handle_posix_cpu_timers():
         : 1279             timer->it.cpu.firing = 0;
    0.00 :   ffff80001011b054:       str     wzr, [x19, #184]
         : 1285             if (likely(cpu_firing >= 0))
    0.00 :   ffff80001011b058:       tbnz    w0, #31, ffff80001011b064 <run_posix_cpu_timers+0x244>
         : 1286             cpu_timer_fire(timer);
    0.00 :   ffff80001011b05c:       mov     x0, x19
    0.00 :   ffff80001011b060:       bl      ffff80001011a4a8 <cpu_timer_fire>
         : 1266             list_for_each_entry_safe(timer, next, &firing, it.cpu.elist) {
    0.00 :   ffff80001011b064:       mov     x20, x21
         : 1268             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff80001011b068:       mov     x0, x24
    0.00 :   ffff80001011b06c:       mov     x19, x21
    0.00 :   ffff80001011b070:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 398              handle_posix_cpu_timers():
    0.00 :   ffff80001011b074:       ldr     x21, [x20, #168]!
    0.00 :   ffff80001011b078:       sub     x21, x21, #0xa8
    0.00 :   ffff80001011b07c:       cmp     x20, x23
    0.00 :   ffff80001011b080:       b.ne    ffff80001011b030 <run_posix_cpu_timers+0x210>  // b.any
    0.00 :   ffff80001011b084:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001011b088:       b       ffff80001011aea4 <run_posix_cpu_timers+0x84>
    0.00 :   ffff80001011b08c:       ldr     x20, [x19, #1624]
    0.00 :   ffff80001011b090:       b       ffff80001011aff8 <run_posix_cpu_timers+0x1d8>
         : 1274             check_process_timers():
         : 928              pct->expiry_active = true;
    0.00 :   ffff80001011b094:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001011b098:       str     w0, [x21, #76]
         : 935              collect_posix_cputimers(pct, samples, firing);
    0.00 :   ffff80001011b09c:       mov     x2, x23
    0.00 :   ffff80001011b0a0:       add     x1, sp, #0x70
         : 938              atomic64_read():
    0.00 :   ffff80001011b0a4:       ldr     x4, [x20, #248]
         : 839              check_process_timers():
    0.00 :   ffff80001011b0a8:       mov     x0, x21
         : 936              atomic64_read():
    0.00 :   ffff80001011b0ac:       ldr     x3, [x20, #256]
    0.00 :   ffff80001011b0b0:       ldr     x5, [x20, #264]
         : 840              store_samples():
         : 209              samples[CPUCLOCK_PROF] = stime + utime;
    0.00 :   ffff80001011b0b4:       add     x3, x3, x4
         : 210              samples[CPUCLOCK_VIRT] = utime;
    0.00 :   ffff80001011b0b8:       stp     x3, x4, [sp, #112]
         : 211              samples[CPUCLOCK_SCHED] = rtime;
    0.00 :   ffff80001011b0bc:       str     x5, [sp, #128]
         : 213              check_process_timers():
         : 935              collect_posix_cputimers(pct, samples, firing);
    0.00 :   ffff80001011b0c0:       bl      ffff800010119b10 <collect_posix_cputimers>
         : 937              check_cpu_itimer():
         : 884              if (!it->expires)
    0.00 :   ffff80001011b0c4:       ldr     x3, [x20, #216]
    0.00 :   ffff80001011b0c8:       cbz     x3, ffff80001011b0e8 <run_posix_cpu_timers+0x2c8>
         : 887              if (cur_time >= it->expires) {
    0.00 :   ffff80001011b0cc:       ldr     x0, [sp, #112]
    0.00 :   ffff80001011b0d0:       cmp     x0, x3
    0.00 :   ffff80001011b0d4:       b.cs    ffff80001011b208 <run_posix_cpu_timers+0x3e8>  // b.hs, b.nlast
         : 899              if (it->expires && it->expires < *expires)
    0.00 :   ffff80001011b0d8:       ldr     x0, [x20, #272]
    0.00 :   ffff80001011b0dc:       cmp     x3, x0
    0.00 :   ffff80001011b0e0:       b.cs    ffff80001011b0e8 <run_posix_cpu_timers+0x2c8>  // b.hs, b.nlast
         : 900              *expires = it->expires;
    0.00 :   ffff80001011b0e4:       str     x3, [x20, #272]
         : 884              if (!it->expires)
    0.00 :   ffff80001011b0e8:       ldr     x3, [x20, #232]
    0.00 :   ffff80001011b0ec:       cbz     x3, ffff80001011b110 <run_posix_cpu_timers+0x2f0>
         : 887              if (cur_time >= it->expires) {
    0.00 :   ffff80001011b0f0:       ldr     x0, [sp, #120]
    0.00 :   ffff80001011b0f4:       cmp     x0, x3
    0.00 :   ffff80001011b0f8:       b.cs    ffff80001011b1d8 <run_posix_cpu_timers+0x3b8>  // b.hs, b.nlast
         : 899              if (it->expires && it->expires < *expires)
    0.00 :   ffff80001011b0fc:       ldr     x0, [x20, #296]
    0.00 :   ffff80001011b100:       cmp     x3, x0
    0.00 :   ffff80001011b104:       b.cs    ffff80001011b110 <run_posix_cpu_timers+0x2f0>  // b.hs, b.nlast
         : 900              *expires = it->expires;
    0.00 :   ffff80001011b108:       str     x3, [x20, #296]
    0.00 :   ffff80001011b10c:       nop
         : 903              task_rlimit():
         : 715              }
    0.00 :   ffff80001011b110:       ldr     x0, [x19, #1624]
    0.00 :   ffff80001011b114:       ldr     x24, [x0, #672]
         : 718              check_process_timers():
         : 948              if (soft != RLIM_INFINITY) {
    0.00 :   ffff80001011b118:       cmn     x24, #0x1
    0.00 :   ffff80001011b11c:       b.eq    ffff80001011b254 <run_posix_cpu_timers+0x434>  // b.none
    0.00 :   ffff80001011b120:       stp     x25, x26, [sp, #64]
         : 952              task_rlimit_max():
         : 721              }
    0.00 :   ffff80001011b124:       ldr     x1, [x0, #680]
         : 723              check_process_timers():
         : 952              u64 softns = (u64)soft * NSEC_PER_SEC;
    0.00 :   ffff80001011b128:       mov     x0, #0xca00                     // #51712
    0.00 :   ffff80001011b12c:       movk    x0, #0x3b9a, lsl #16
         : 956              if (hard != RLIM_INFINITY &&
    0.00 :   ffff80001011b130:       cmn     x1, #0x1
         : 952              u64 softns = (u64)soft * NSEC_PER_SEC;
    0.00 :   ffff80001011b134:       mul     x25, x24, x0
         : 951              u64 ptime = samples[CPUCLOCK_PROF];
    0.00 :   ffff80001011b138:       ldr     x26, [sp, #112]
         : 956              if (hard != RLIM_INFINITY &&
    0.00 :   ffff80001011b13c:       b.eq    ffff80001011b168 <run_posix_cpu_timers+0x348>  // b.none
         : 957              check_rlimit(ptime, hardns, SIGKILL, false, true))
    0.00 :   ffff80001011b140:       mul     x1, x1, x0
    0.00 :   ffff80001011b144:       mov     w4, #0x1                        // #1
    0.00 :   ffff80001011b148:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001011b14c:       mov     w2, #0x9                        // #9
    0.00 :   ffff80001011b150:       mov     x0, x26
    0.00 :   ffff80001011b154:       bl      ffff800010119e80 <check_rlimit>
         : 956              if (hard != RLIM_INFINITY &&
    0.00 :   ffff80001011b158:       tst     w0, #0xff
    0.00 :   ffff80001011b15c:       b.eq    ffff80001011b168 <run_posix_cpu_timers+0x348>  // b.none
    0.00 :   ffff80001011b160:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001011b164:       b       ffff80001011b00c <run_posix_cpu_timers+0x1ec>
         : 961              if (check_rlimit(ptime, softns, SIGXCPU, false, false)) {
    0.00 :   ffff80001011b168:       mov     x0, x26
    0.00 :   ffff80001011b16c:       mov     w4, #0x0                        // #0
    0.00 :   ffff80001011b170:       mov     w3, #0x0                        // #0
    0.00 :   ffff80001011b174:       mov     w2, #0x18                       // #24
    0.00 :   ffff80001011b178:       mov     x1, x25
    0.00 :   ffff80001011b17c:       bl      ffff800010119e80 <check_rlimit>
    0.00 :   ffff80001011b180:       tst     w0, #0xff
    0.00 :   ffff80001011b184:       b.eq    ffff80001011b19c <run_posix_cpu_timers+0x37c>  // b.none
         : 963              softns += NSEC_PER_SEC;
    0.00 :   ffff80001011b188:       mov     x0, #0xca00                     // #51712
         : 962              sig->rlim[RLIMIT_CPU].rlim_cur = soft + 1;
    0.00 :   ffff80001011b18c:       add     x24, x24, #0x1
         : 963              softns += NSEC_PER_SEC;
    0.00 :   ffff80001011b190:       movk    x0, #0x3b9a, lsl #16
    0.00 :   ffff80001011b194:       add     x25, x25, x0
         : 962              sig->rlim[RLIMIT_CPU].rlim_cur = soft + 1;
    0.00 :   ffff80001011b198:       str     x24, [x20, #672]
         : 967              if (softns < pct->bases[CPUCLOCK_PROF].nextevt)
    0.00 :   ffff80001011b19c:       ldr     x1, [x20, #272]
    0.00 :   ffff80001011b1a0:       cmp     x1, x25
    0.00 :   ffff80001011b1a4:       b.hi    ffff80001011b244 <run_posix_cpu_timers+0x424>  // b.pmore
    0.00 :   ffff80001011b1a8:       ldp     x25, x26, [sp, #64]
         : 972              expiry_cache_is_inactive():
         : 148              ~pct->bases[CPUCLOCK_VIRT].nextevt |
    0.00 :   ffff80001011b1ac:       ldr     x0, [x21, #24]
    0.00 :   ffff80001011b1b0:       ldr     x2, [x21, #48]
    0.00 :   ffff80001011b1b4:       and     x0, x0, x2
    0.00 :   ffff80001011b1b8:       and     x0, x0, x1
         : 153              check_process_timers():
         : 971              if (expiry_cache_is_inactive(pct))
    0.00 :   ffff80001011b1bc:       cmn     x0, #0x1
    0.00 :   ffff80001011b1c0:       b.eq    ffff80001011b238 <run_posix_cpu_timers+0x418>  // b.none
         : 974              pct->expiry_active = false;
    0.00 :   ffff80001011b1c4:       str     wzr, [x21, #76]
    0.00 :   ffff80001011b1c8:       b       ffff80001011b00c <run_posix_cpu_timers+0x1ec>
         : 977              fastpath_timer_check():
         : 1089             if (dl_task(tsk) && tsk->dl.dl_overrun)
    0.00 :   ffff80001011b1cc:       ldrb    w0, [x19, #524]
    0.00 :   ffff80001011b1d0:       tbz     w0, #3, ffff80001011aea4 <run_posix_cpu_timers+0x84>
    0.00 :   ffff80001011b1d4:       b       ffff80001011af08 <run_posix_cpu_timers+0xe8>
         : 1093             check_cpu_itimer():
         : 888              if (it->incr)
    0.00 :   ffff80001011b1d8:       ldr     x4, [x20, #240]
         : 896              __group_send_sig_info(signo, SEND_SIG_PRIV, tsk);
    0.00 :   ffff80001011b1dc:       mov     x2, x19
    0.00 :   ffff80001011b1e0:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001011b1e4:       mov     w0, #0x1a                       // #26
         : 889              it->expires += it->incr;
    0.00 :   ffff80001011b1e8:       add     x3, x4, x3
    0.00 :   ffff80001011b1ec:       cmp     x4, #0x0
    0.00 :   ffff80001011b1f0:       csel    x4, x3, x4, ne  // ne = any
    0.00 :   ffff80001011b1f4:       str     x4, [x20, #232]
         : 896              __group_send_sig_info(signo, SEND_SIG_PRIV, tsk);
    0.00 :   ffff80001011b1f8:       bl      ffff800010093d20 <__group_send_sig_info>
         : 899              if (it->expires && it->expires < *expires)
    0.00 :   ffff80001011b1fc:       ldr     x3, [x20, #232]
    0.00 :   ffff80001011b200:       cbz     x3, ffff80001011b110 <run_posix_cpu_timers+0x2f0>
    0.00 :   ffff80001011b204:       b       ffff80001011b0fc <run_posix_cpu_timers+0x2dc>
         : 888              if (it->incr)
    0.00 :   ffff80001011b208:       ldr     x4, [x20, #224]
         : 896              __group_send_sig_info(signo, SEND_SIG_PRIV, tsk);
    0.00 :   ffff80001011b20c:       mov     x2, x19
    0.00 :   ffff80001011b210:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001011b214:       mov     w0, #0x1b                       // #27
         : 889              it->expires += it->incr;
    0.00 :   ffff80001011b218:       add     x3, x4, x3
    0.00 :   ffff80001011b21c:       cmp     x4, #0x0
    0.00 :   ffff80001011b220:       csel    x4, x3, x4, ne  // ne = any
    0.00 :   ffff80001011b224:       str     x4, [x20, #216]
         : 896              __group_send_sig_info(signo, SEND_SIG_PRIV, tsk);
    0.00 :   ffff80001011b228:       bl      ffff800010093d20 <__group_send_sig_info>
         : 899              if (it->expires && it->expires < *expires)
    0.00 :   ffff80001011b22c:       ldr     x3, [x20, #216]
    0.00 :   ffff80001011b230:       cbz     x3, ffff80001011b0e8 <run_posix_cpu_timers+0x2c8>
    0.00 :   ffff80001011b234:       b       ffff80001011b0d8 <run_posix_cpu_timers+0x2b8>
         : 903              stop_process_timers():
         : 877              WRITE_ONCE(pct->timers_active, false);
    0.00 :   ffff80001011b238:       str     wzr, [x20, #344]
         : 879              check_process_timers():
         : 974              pct->expiry_active = false;
    0.00 :   ffff80001011b23c:       str     wzr, [x21, #76]
    0.00 :   ffff80001011b240:       b       ffff80001011b00c <run_posix_cpu_timers+0x1ec>
         : 968              pct->bases[CPUCLOCK_PROF].nextevt = softns;
    0.00 :   ffff80001011b244:       str     x25, [x20, #272]
    0.00 :   ffff80001011b248:       mov     x1, x25
    0.00 :   ffff80001011b24c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001011b250:       b       ffff80001011b1ac <run_posix_cpu_timers+0x38c>
    0.00 :   ffff80001011b254:       ldr     x1, [x20, #272]
    0.00 :   ffff80001011b258:       b       ffff80001011b1ac <run_posix_cpu_timers+0x38c>
         : 975              check_dl_overrun():
         : 806              if (tsk->dl.dl_overrun) {
    0.00 :   ffff80001011b25c:       ldrb    w0, [x19, #524]
    0.00 :   ffff80001011b260:       tbz     w0, #3, ffff80001011af34 <run_posix_cpu_timers+0x114>
         : 807              tsk->dl.dl_overrun = 0;
    0.00 :   ffff80001011b264:       and     w0, w0, #0xfffffff7
    0.00 :   ffff80001011b268:       strb    w0, [x19, #524]
         : 808              __group_send_sig_info(SIGXCPU, SEND_SIG_PRIV, tsk);
    0.00 :   ffff80001011b26c:       mov     x2, x19
    0.00 :   ffff80001011b270:       mov     x1, #0x1                        // #1
    0.00 :   ffff80001011b274:       mov     w0, #0x18                       // #24
    0.00 :   ffff80001011b278:       bl      ffff800010093d20 <__group_send_sig_info>
    0.00 :   ffff80001011b27c:       b       ffff80001011af34 <run_posix_cpu_timers+0x114>
    0.00 :   ffff80001011b280:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001011b284:       stp     x25, x26, [sp, #64]
         : 816              run_posix_cpu_timers():
         : 1317             }
    0.00 :   ffff80001011b288:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (15 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010259700 <__fget_files>:
         : 6                __fget_files():
         : 830              for ( ; set ; fd++, set >>= 1) {
         : 831              struct file *file;
         : 832              if (!(set & 1))
         : 833              continue;
         : 834              file = fdt->fd[fd];
         : 835              if (!file)
    0.00 :   ffff800010259700:       paciasp
    0.00 :   ffff800010259704:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010259708:       mov     x29, sp
    0.00 :   ffff80001025970c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010259710:       mov     w20, w1
    0.00 :   ffff800010259714:       mov     w19, w3
    0.00 :   ffff800010259718:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001025971c:       mov     x21, x0
    0.00 :   ffff800010259720:       mov     w22, w2
         : 845              rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010259724:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              __fget_files():
         : 843              }
         :
         : 845              }
         : 846              spin_unlock(&files->file_lock);
         : 847              }
         :
    0.00 :   ffff800010259728:       mov     w3, w19
         : 850              files_lookup_fd_raw():
         : 88               static inline struct file *files_lookup_fd_raw(struct files_struct *files, unsigned int fd)
         : 89               {
         : 90               struct fdtable *fdt = rcu_dereference_raw(files->fdt);
         :
         : 92               if (fd < fdt->max_fds) {
         : 93               fd = array_index_nospec(fd, fdt->max_fds);
    0.00 :   ffff80001025972c:       mov     w6, w20
         : 85               struct fdtable *fdt = rcu_dereference_raw(files->fdt);
    0.00 :   ffff800010259730:       ldr     x1, [x21, #32]
         : 87               if (fd < fdt->max_fds) {
    0.00 :   ffff800010259734:       ldr     w0, [x1]
    0.00 :   ffff800010259738:       cmp     w20, w0
    0.00 :   ffff80001025973c:       b.cs    ffff8000102597d4 <__fget_files+0xd4>  // b.hs, b.nlast
         : 88               fd = array_index_nospec(fd, fdt->max_fds);
    0.00 :   ffff800010259740:       mov     w0, w0
         : 90               array_index_mask_nospec():
         : 59               static inline unsigned long array_index_mask_nospec(unsigned long idx,
         : 60               unsigned long sz)
         : 61               {
         : 62               unsigned long mask;
         :
         : 64               asm volatile(
    0.00 :   ffff800010259744:       cmp     x6, x0
    0.00 :   ffff800010259748:       ngc     x0, xzr
         : 66               "       sbc     %0, xzr, xzr\n"
         : 67               : "=r" (mask)
         : 68               : "r" (idx), "Ir" (sz)
         : 69               : "cc");
         :
         : 71               csdb();
    0.00 :   ffff80001025974c:       csdb
         : 73               files_lookup_fd_raw():
         : 89               return rcu_dereference_raw(fdt->fd[fd]);
    0.00 :   ffff800010259750:       ldr     x1, [x1, #8]
    0.00 :   ffff800010259754:       and     w0, w20, w0
    0.00 :   ffff800010259758:       ldr     x19, [x1, x0, lsl #3]
         : 93               __fget_files():
         : 836              cond_resched();
    0.00 :   ffff80001025975c:       cbz     x19, ffff8000102597d4 <__fget_files+0xd4>
         : 841              spin_unlock(&files->file_lock);
    1.43 :   ffff800010259760:       ldr     w0, [x19, #68]
    0.00 :   ffff800010259764:       tst     w22, w0
    0.00 :   ffff800010259768:       b.ne    ffff8000102597d4 <__fget_files+0xd4>  // b.any
         : 845              arch_atomic64_fetch_add_unless():
         : 2265             * Returns original value of @v
         : 2266             */
         : 2267             static __always_inline s64
         : 2268             arch_atomic64_fetch_add_unless(atomic64_t *v, s64 a, s64 u)
         : 2269             {
         : 2270             s64 c = arch_atomic64_read(v);
    6.18 :   ffff80001025976c:       mov     x5, x19
    0.00 :   ffff800010259770:       ldr     x4, [x5, #56]!
         :
         : 2269             do {
         : 2270             if (unlikely(c == u))
    0.00 :   ffff800010259774:       cbz     x4, ffff800010259730 <__fget_files+0x30>
         : 2270             break;
         : 2271             } while (!arch_atomic64_try_cmpxchg(v, &c, c + a));
    0.00 :   ffff800010259778:       add     x2, x3, x4
         : 2273             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001025977c:       b       ffff8000102597f4 <__fget_files+0xf4>
    0.00 :   ffff800010259780:       b       ffff8000102597f4 <__fget_files+0xf4>
         : 46               __lse__cmpxchg_case_mb_64():
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
         : 381              __CMPXCHG_CASE(w, b,  mb_,  8, al, "memory")
         : 382              __CMPXCHG_CASE(w, h,  mb_, 16, al, "memory")
         : 383              __CMPXCHG_CASE(w,  ,  mb_, 32, al, "memory")
         : 384              __CMPXCHG_CASE(x,  ,  mb_, 64, al, "memory")
    0.00 :   ffff800010259784:       mov     x0, x5
    0.00 :   ffff800010259788:       mov     x1, x4
    0.00 :   ffff80001025978c:       mov     x7, x1
    0.00 :   ffff800010259790:       casal   x7, x2, [x5]
   92.39 :   ffff800010259794:       mov     x0, x7
         : 390              arch_atomic64_try_cmpxchg():
         : 2098             if (unlikely(r != o))
    0.00 :   ffff800010259798:       cmp     x0, x4
    0.00 :   ffff80001025979c:       b.ne    ffff8000102597bc <__fget_files+0xbc>  // b.any
         : 2101             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000102597a0:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              __fget_files():
         : 849              static struct file *__fget_files(struct files_struct *files, unsigned int fd,
         : 850              fmode_t mask, unsigned int refs)
         : 851              {
         : 852              struct file *file;
         :
         : 854              rcu_read_lock();
    0.00 :   ffff8000102597a4:       mov     x0, x19
    0.00 :   ffff8000102597a8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102597ac:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102597b0:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102597b4:       autiasp
    0.00 :   ffff8000102597b8:       ret
         : 861              arch_atomic64_fetch_add_unless():
         : 2268             if (unlikely(c == u))
    0.00 :   ffff8000102597bc:       mov     x4, x0
    0.00 :   ffff8000102597c0:       cbnz    x0, ffff800010259778 <__fget_files+0x78>
         : 2271             files_lookup_fd_raw():
         : 85               struct fdtable *fdt = rcu_dereference_raw(files->fdt);
    0.00 :   ffff8000102597c4:       ldr     x1, [x21, #32]
         : 87               if (fd < fdt->max_fds) {
    0.00 :   ffff8000102597c8:       ldr     w0, [x1]
    0.00 :   ffff8000102597cc:       cmp     w20, w0
    0.00 :   ffff8000102597d0:       b.cc    ffff800010259740 <__fget_files+0x40>  // b.lo, b.ul, b.last
         : 91               rcu_read_unlock():
    0.00 :   ffff8000102597d4:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              files_lookup_fd_raw():
         : 91               }
         : 92               return NULL;
    0.00 :   ffff8000102597d8:       mov     x19, #0x0                       // #0
         : 94               __fget_files():
    0.00 :   ffff8000102597dc:       mov     x0, x19
    0.00 :   ffff8000102597e0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102597e4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102597e8:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000102597ec:       autiasp
    0.00 :   ffff8000102597f0:       ret
         : 855              __ll_sc__cmpxchg_case_mb_64():
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
         : 316              __CMPXCHG_CASE(w, b,  mb_,  8, dmb ish,  , l, "memory", K)
         : 317              __CMPXCHG_CASE(w, h,  mb_, 16, dmb ish,  , l, "memory", K)
         : 318              __CMPXCHG_CASE(w,  ,  mb_, 32, dmb ish,  , l, "memory", K)
         : 319              __CMPXCHG_CASE( ,  ,  mb_, 64, dmb ish,  , l, "memory", L)
    0.00 :   ffff8000102597f4:       b       ffff80001025aef4 <f_dupfd+0x94>
    0.00 :   ffff8000102597f8:       b       ffff800010259798 <__fget_files+0x98>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bb848 <update_min_vruntime>:
         : 6                update_min_vruntime():
         :
         : 556              static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
         : 557              {
         : 558              rb_erase_cached(&se->run_node, &cfs_rq->tasks_timeline);
         : 559              }
         :
    0.00 :   ffff8000100bb848:       ldp     x3, x2, [x0, #56]
         : 554              }
    0.00 :   ffff8000100bb84c:       paciasp
         : 558              struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)
         : 559              {
         : 560              struct rb_node *left = rb_first_cached(&cfs_rq->tasks_timeline);
    0.00 :   ffff8000100bb850:       ldr     x1, [x0, #40]
         :
         : 561              if (!left)
    0.00 :   ffff8000100bb854:       cbz     x2, ffff8000100bb898 <update_min_vruntime+0x50>
         : 561              return NULL;
    0.00 :   ffff8000100bb858:       ldr     w4, [x2, #56]
    0.00 :   ffff8000100bb85c:       cbz     w4, ffff8000100bb88c <update_min_vruntime+0x44>
         :
    0.00 :   ffff8000100bb860:       ldr     x2, [x2, #80]
         : 567              return __node_2_se(left);
         : 568              }
         :
         : 570              static struct sched_entity *__pick_next_entity(struct sched_entity *se)
         : 571              {
    0.00 :   ffff8000100bb864:       cbz     x3, ffff8000100bb874 <update_min_vruntime+0x2c>
         : 573              struct rb_node *next = rb_next(&se->run_node);
         :
         : 575              if (!next)
         : 576              return NULL;
         :
         : 578              return __node_2_se(next);
    0.00 :   ffff8000100bb868:       ldr     x3, [x3, #64]
         : 580              min_vruntime():
         : 539              {
    0.00 :   ffff8000100bb86c:       cmp     x3, x2
    0.00 :   ffff8000100bb870:       csel    x2, x2, x3, pl  // pl = nfrst
         : 542              max_vruntime():
         : 528              }
  100.00 :   ffff8000100bb874:       sub     x3, x2, x1
         :
    0.00 :   ffff8000100bb878:       cmp     x3, #0x0
    0.00 :   ffff8000100bb87c:       csel    x1, x1, x2, le
         : 532              update_min_vruntime():
         : 582              struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq)
         : 583              {
         : 584              struct rb_node *last = rb_last(&cfs_rq->tasks_timeline.rb_root);
         :
         : 586              if (!last)
         : 587              return NULL;
    0.00 :   ffff8000100bb880:       autiasp
         : 577              struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq)
    0.00 :   ffff8000100bb884:       str     x1, [x0, #40]
         : 582              return NULL;
    0.00 :   ffff8000100bb888:       ret
         : 567              {
    0.00 :   ffff8000100bb88c:       cbz     x3, ffff8000100bb880 <update_min_vruntime+0x38>
         : 571              return NULL;
    0.00 :   ffff8000100bb890:       ldr     x2, [x3, #64]
    0.00 :   ffff8000100bb894:       b       ffff8000100bb874 <update_min_vruntime+0x2c>
         : 567              {
    0.00 :   ffff8000100bb898:       cbnz    x3, ffff8000100bb890 <update_min_vruntime+0x48>
         : 582              return NULL;
    0.00 :   ffff8000100bb89c:       autiasp
         : 577              struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq)
    0.00 :   ffff8000100bb8a0:       str     x1, [x0, #40]
         : 582              return NULL;
    0.00 :   ffff8000100bb8a4:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010190188 <__pagevec_lru_add>:
         : 6                __pagevec_lru_add():
         : 1052             /*
         : 1053             * Add the passed pages to the LRU, then drop the caller's refcount
         : 1054             * on them.  Reinitialises the caller's pagevec.
         : 1055             */
         : 1056             void __pagevec_lru_add(struct pagevec *pvec)
         : 1057             {
    0.00 :   ffff800010190188:       paciasp
    0.00 :   ffff80001019018c:       stp     x29, x30, [sp, #-160]!
    0.00 :   ffff800010190190:       mov     x29, sp
    0.00 :   ffff800010190194:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010190198:       mov     x24, x0
    0.00 :   ffff80001019019c:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000101901a0:       adrp    x26, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101901a4:       add     x0, x26, #0x948
    0.00 :   ffff8000101901a8:       ldr     x1, [x0]
    0.00 :   ffff8000101901ac:       str     x1, [sp, #152]
    0.00 :   ffff8000101901b0:       mov     x1, #0x0                        // #0
         : 1055             int i;
         : 1056             struct lruvec *lruvec = NULL;
         : 1057             unsigned long flags = 0;
    0.00 :   ffff8000101901b4:       stp     x0, xzr, [sp, #136]
         :
         : 1058             for (i = 0; i < pagevec_count(pvec); i++) {
    0.00 :   ffff8000101901b8:       ldrb    w1, [x24]
    0.00 :   ffff8000101901bc:       cbz     w1, ffff80001019044c <__pagevec_lru_add+0x2c4>
         : 1061             page_pgdat():
         : 1542             }
         :
         : 1544             static inline pg_data_t *page_pgdat(const struct page *page)
         : 1545             {
         : 1546             return NODE_DATA(page_to_nid(page));
         : 1547             }
    0.00 :   ffff8000101901c0:       adrp    x25, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000101901c4:       add     x0, x25, #0xf60
    0.00 :   ffff8000101901c8:       stp     x19, x20, [sp, #16]
         : 1551             __pagevec_lru_add():
         : 1054             struct lruvec *lruvec = NULL;
    0.00 :   ffff8000101901cc:       mov     x20, #0x0                       // #0
    0.00 :   ffff8000101901d0:       stp     x21, x22, [sp, #32]
         : 1057             for (i = 0; i < pagevec_count(pvec); i++) {
    0.00 :   ffff8000101901d4:       mov     w22, #0x0                       // #0
    0.00 :   ffff8000101901d8:       stp     x27, x28, [sp, #80]
         : 1060             __count_vm_events():
         : 76               this_cpu_inc(vm_event_states.event[item]);
         : 77               }
         :
         : 79               static inline void __count_vm_events(enum vm_event_item item, long delta)
         : 80               {
         : 81               raw_cpu_add(vm_event_states.event[item], delta);
    0.00 :   ffff8000101901dc:       adrp    x27, ffff800011777000 <lru_pvecs+0x128>
         : 83               page_pgdat():
    0.00 :   ffff8000101901e0:       str     x0, [sp, #120]
         : 1543             __count_vm_events():
    0.00 :   ffff8000101901e4:       add     x0, x27, #0x428
    0.00 :   ffff8000101901e8:       str     x0, [sp, #128]
    0.00 :   ffff8000101901ec:       nop
         : 79               __pagevec_lru_add():
         : 1058             struct page *page = pvec->pages[i];
    0.00 :   ffff8000101901f0:       add     x0, x24, w22, sxtw #3
    0.00 :   ffff8000101901f4:       ldr     x19, [x0, #8]
         : 1061             relock_page_lruvec_irqsave():
         : 1537             void mem_cgroup_wb_stats(struct bdi_writeback *wb, unsigned long *pfilepages,
         : 1538             unsigned long *pheadroom, unsigned long *pdirty,
         : 1539             unsigned long *pwriteback);
         :
         : 1541             void mem_cgroup_track_foreign_dirty_slowpath(struct page *page,
         : 1542             struct bdi_writeback *wb);
    0.00 :   ffff8000101901f8:       cbz     x20, ffff800010190248 <__pagevec_lru_add+0xc0>
         : 1544             page_to_nid():
         : 1374             }
    0.00 :   ffff8000101901fc:       ldr     x0, [x19]
         : 1376             page_pgdat():
         : 1542             }
    0.00 :   ffff800010190200:       ldr     x1, [sp, #120]
    0.00 :   ffff800010190204:       lsr     x0, x0, #60
    0.00 :   ffff800010190208:       ldr     x1, [x1, x0, lsl #3]
         : 1546             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff80001019020c:       nop
         : 28               page_memcg():
         : 453              return obj_cgroup_memcg(__page_objcg(page));
    0.00 :   ffff800010190210:       ldr     x2, [x19, #56]
         : 455              PageMemcgKmem():
         : 539              }
    0.00 :   ffff800010190214:       and     x0, x2, #0xfffffffffffffffc
         : 541              page_memcg():
         : 453              return obj_cgroup_memcg(__page_objcg(page));
    0.00 :   ffff800010190218:       tbz     w2, #1, ffff800010190220 <__pagevec_lru_add+0x98>
         : 455              obj_cgroup_memcg():
         : 386              }
    0.00 :   ffff80001019021c:       ldr     x0, [x0, #16]
         : 388              lruvec_holds_page_lru_lock():
         : 770              {
    0.00 :   ffff800010190220:       adrp    x3, ffff800011c2b000 <mm_slots_hash+0x10f8>
         : 772              #endif
    0.00 :   ffff800010190224:       ldr     x2, [x20, #136]
         : 770              {
    0.00 :   ffff800010190228:       cmp     x0, #0x0
    0.00 :   ffff80001019022c:       ldr     x3, [x3, #3856]
    0.00 :   ffff800010190230:       csel    x0, x3, x0, eq  // eq = none
         : 772              #endif
    0.00 :   ffff800010190234:       cmp     x1, x2
    0.00 :   ffff800010190238:       b.eq    ffff800010190538 <__pagevec_lru_add+0x3b0>  // b.none
         : 775              spin_unlock_irqrestore():
         : 409              raw_spin_unlock_bh(&lock->rlock);
         : 410              }
         :
         : 412              static __always_inline void spin_unlock_irq(spinlock_t *lock)
         : 413              {
         : 414              raw_spin_unlock_irq(&lock->rlock);
    0.00 :   ffff80001019023c:       ldr     x1, [sp, #144]
    0.00 :   ffff800010190240:       add     x0, x20, #0x50
    0.00 :   ffff800010190244:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 418              relock_page_lruvec_irqsave():
         : 1544             static inline void mem_cgroup_track_foreign_dirty(struct page *page,
         : 1545             struct bdi_writeback *wb)
         : 1546             {
         : 1547             if (mem_cgroup_disabled())
         : 1548             return;
         :
    0.00 :   ffff800010190248:       add     x1, sp, #0x90
    0.00 :   ffff80001019024c:       mov     x0, x19
    0.00 :   ffff800010190250:       bl      ffff800010223e30 <lock_page_lruvec_irqsave>
    0.00 :   ffff800010190254:       mov     x20, x0
         : 1554             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010190258:       ldr     x1, [x19, #8]
         : 191              test_and_clear_bit():
         : 52               long old;
         : 53               unsigned long mask = BIT_MASK(nr);
         :
         : 55               p += BIT_WORD(nr);
         : 56               if (!(READ_ONCE(*p) & mask))
         : 57               return 0;
    0.00 :   ffff80001019025c:       mov     w21, #0x0                       // #0
         : 59               compound_head():
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010190260:       sub     x0, x1, #0x1
    0.00 :   ffff800010190264:       tst     x1, #0x1
    0.00 :   ffff800010190268:       csel    x0, x0, x19, ne  // ne = any
         : 193              test_and_clear_bit():
         : 51               if (!(READ_ONCE(*p) & mask))
    0.00 :   ffff80001019026c:       ldr     x1, [x0]
    0.00 :   ffff800010190270:       tbz     w1, #20, ffff800010190288 <__pagevec_lru_add+0x100>
         : 54               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010190274:       b       ffff80001019052c <__pagevec_lru_add+0x3a4>
    0.00 :   ffff800010190278:       b       ffff80001019052c <__pagevec_lru_add+0x3a4>
         : 46               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OP(_relaxed,   , op, asm_op)                     \
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff80001019027c:       mov     x21, #0x100000                  // #1048576
    0.00 :   ffff800010190280:       ldclral x21, x21, [x0]
         : 210              test_and_clear_bit():
         :
         : 56               old = atomic_long_fetch_andnot(mask, (atomic_long_t *)p);
         : 57               return !!(old & mask);
    0.00 :   ffff800010190284:       ubfx    w21, w21, #20, #1
         : 59               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010190288:       ldr     x0, [x19]
         : 113              thp_nr_pages():
         : 277              }
         :
         : 279              /**
         : 280              * thp_nr_pages - The number of regular pages in this huge page.
         : 281              * @page: The head page of a huge page.
         : 282              */
    0.00 :   ffff80001019028c:       mov     w23, #0x200                     // #512
         : 284              compound_head():
         : 184              {
    0.00 :   ffff800010190290:       ldr     x1, [x19, #8]
         : 186              thp_nr_pages():
    0.00 :   ffff800010190294:       tst     x0, #0x10000
    0.00 :   ffff800010190298:       csinc   w23, w23, wzr, ne  // ne = any
         : 279              compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001019029c:       sub     x0, x1, #0x1
    0.00 :   ffff8000101902a0:       tst     x1, #0x1
    0.00 :   ffff8000101902a4:       csel    x0, x0, x19, ne  // ne = any
         : 191              arch_static_branch_jump():
    0.00 :   ffff8000101902a8:       b       ffff8000101904a8 <__pagevec_lru_add+0x320>
    0.00 :   ffff8000101902ac:       b       ffff8000101904a8 <__pagevec_lru_add+0x320>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff8000101902b0:       mov     x1, #0x10                       // #16
    0.00 :   ffff8000101902b4:       stset   x1, [x0]
         : 180              __pagevec_lru_add_fn():
         : 1031             smp_mb__after_atomic();
    0.00 :   ffff8000101902b8:       dmb     ish
         : 1033             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000101902bc:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              page_evictable():
         : 83               {
         : 84               bool ret;
         :
         : 86               /* Prevent address_space of inode and swap cache from being freed */
         : 87               rcu_read_lock();
         : 88               ret = !mapping_unevictable(page_mapping(page)) && !PageMlocked(page);
    0.00 :   ffff8000101902c0:       mov     x0, x19
    0.00 :   ffff8000101902c4:       bl      ffff8000101a1610 <page_mapping>
         : 91               mapping_unevictable():
         : 85               clear_bit(AS_UNEVICTABLE, &mapping->flags);
         : 86               }
         :
         : 88               static inline bool mapping_unevictable(struct address_space *mapping)
         : 89               {
         : 90               return mapping && test_bit(AS_UNEVICTABLE, &mapping->flags);
    0.00 :   ffff8000101902c8:       cbz     x0, ffff800010190480 <__pagevec_lru_add+0x2f8>
         : 92               test_bit():
    0.00 :   ffff8000101902cc:       ldr     x0, [x0, #112]
         : 107              mapping_unevictable():
    0.00 :   ffff8000101902d0:       tbz     w0, #3, ffff800010190480 <__pagevec_lru_add+0x2f8>
         : 86               rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000101902d4:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              compound_head():
         : 184              {
    0.00 :   ffff8000101902d8:       ldr     x1, [x19, #8]
         : 188              return head - 1;
    0.00 :   ffff8000101902dc:       sub     x0, x1, #0x1
    0.00 :   ffff8000101902e0:       tst     x1, #0x1
    0.00 :   ffff8000101902e4:       csel    x0, x0, x19, ne  // ne = any
         : 192              arch_static_branch_jump():
    0.00 :   ffff8000101902e8:       b       ffff800010190520 <__pagevec_lru_add+0x398>
    0.00 :   ffff8000101902ec:       b       ffff800010190520 <__pagevec_lru_add+0x398>
         : 40               __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff8000101902f0:       mov     x1, #0x20                       // #32
    0.00 :   ffff8000101902f4:       stclr   x1, [x0]
         : 179              compound_head():
         : 184              {
    0.00 :   ffff8000101902f8:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101902fc:       sub     x0, x1, #0x1
    0.00 :   ffff800010190300:       tst     x1, #0x1
    0.00 :   ffff800010190304:       csel    x0, x0, x19, ne  // ne = any
         : 191              arch_static_branch_jump():
    0.00 :   ffff800010190308:       b       ffff800010190518 <__pagevec_lru_add+0x390>
    0.00 :   ffff80001019030c:       b       ffff800010190518 <__pagevec_lru_add+0x390>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010190310:       mov     x1, #0x100000                   // #1048576
    0.00 :   ffff800010190314:       stset   x1, [x0]
         : 180              __pagevec_lru_add_fn():
         : 1039             if (!was_unevictable)
    0.00 :   ffff800010190318:       cbnz    w21, ffff800010190334 <__pagevec_lru_add+0x1ac>
         : 1041             __count_vm_events():
    0.00 :   ffff80001019031c:       adrp    x0, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff800010190320:       add     x0, x0, #0x418
         : 78               __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010190324:       mrs     x2, tpidr_el1
         : 46               __count_vm_events():
    0.00 :   ffff800010190328:       ldr     x1, [x0, x2]
    0.00 :   ffff80001019032c:       add     x23, x1, w23, sxtw
    0.00 :   ffff800010190330:       str     x23, [x0, x2]
         : 79               compound_head():
         : 184              {
    0.00 :   ffff800010190334:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010190338:       sub     x0, x1, #0x1
    0.00 :   ffff80001019033c:       tst     x1, #0x1
    0.00 :   ffff800010190340:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff800010190344:       ldr     x0, [x0]
         : 107              page_lru():
         : 72               {
         : 73               enum lru_list lru;
         :
         : 75               VM_BUG_ON_PAGE(PageActive(page) && PageUnevictable(page), page);
         :
         : 77               if (PageUnevictable(page))
    0.00 :   ffff800010190348:       tbnz    w0, #20, ffff8000101904b0 <__pagevec_lru_add+0x328>
         : 79               compound_head():
         : 184              {
    0.00 :   ffff80001019034c:       ldr     x2, [x19, #8]
         : 186              page_lru():
         : 75               return LRU_UNEVICTABLE;
         :
         : 77               lru = page_is_file_lru(page) ? LRU_INACTIVE_FILE : LRU_INACTIVE_ANON;
    0.00 :   ffff800010190350:       mov     w1, #0x3                        // #3
    0.00 :   ffff800010190354:       mov     w23, #0x2                       // #2
         : 80               compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff800010190358:       sub     x0, x2, #0x1
    0.00 :   ffff80001019035c:       tst     x2, #0x1
    0.00 :   ffff800010190360:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff800010190364:       ldr     x0, [x0]
         : 107              compound_head():
         : 184              {
    0.00 :   ffff800010190368:       ldr     x2, [x19, #8]
         : 186              page_lru():
    0.00 :   ffff80001019036c:       ands    x0, x0, #0x80000
    0.00 :   ffff800010190370:       csinc   w1, w1, wzr, eq  // eq = none
    0.00 :   ffff800010190374:       cmp     x0, #0x0
    0.00 :   ffff800010190378:       csel    w23, w23, wzr, eq  // eq = none
         : 79               compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001019037c:       sub     x0, x2, #0x1
    0.00 :   ffff800010190380:       tst     x2, #0x1
    0.00 :   ffff800010190384:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff800010190388:       ldr     x0, [x0]
         : 107              page_lru():
         : 76               if (PageActive(page))
    0.00 :   ffff80001019038c:       tbnz    w0, #5, ffff8000101904fc <__pagevec_lru_add+0x374>
    0.00 :   ffff800010190390:       mov     w26, w23
    0.00 :   ffff800010190394:       str     w1, [sp, #116]
    0.00 :   ffff800010190398:       lsl     x27, x26, #4
         : 81               page_zonenum():
         : 1127             }
    0.00 :   ffff80001019039c:       ldr     x21, [x19]
         : 1129             thp_nr_pages():
         : 276              * @page: The head page of a huge page.
    0.00 :   ffff8000101903a0:       mov     x7, #0x1                        // #1
         : 278              test_bit():
    0.00 :   ffff8000101903a4:       ldr     x0, [x19]
         : 107              thp_nr_pages():
         : 278              static inline int thp_nr_pages(struct page *page)
    0.00 :   ffff8000101903a8:       mov     w25, w7
         : 280              page_zonenum():
    0.00 :   ffff8000101903ac:       ubfx    x21, x21, #58, #2
         : 1128             thp_nr_pages():
         : 276              * @page: The head page of a huge page.
    0.00 :   ffff8000101903b0:       tbnz    w0, #16, ffff8000101904dc <__pagevec_lru_add+0x354>
         : 278              update_lru_size():
         : 33               __mod_lruvec_state(lruvec, NR_LRU_BASE + lru, nr_pages);
    0.00 :   ffff8000101903b4:       mov     w2, w25
    0.00 :   ffff8000101903b8:       mov     w1, w23
    0.00 :   ffff8000101903bc:       mov     x0, x20
    0.00 :   ffff8000101903c0:       str     x7, [sp, #104]
         : 31               struct pglist_data *pgdat = lruvec_pgdat(lruvec);
    0.00 :   ffff8000101903c4:       ldr     x28, [x20, #136]
         : 33               __mod_lruvec_state(lruvec, NR_LRU_BASE + lru, nr_pages);
    0.00 :   ffff8000101903c8:       bl      ffff800010221ff0 <__mod_lruvec_state>
         : 34               __mod_zone_page_state(&pgdat->node_zones[zid],
    0.00 :   ffff8000101903cc:       mov     w5, w21
    0.00 :   ffff8000101903d0:       ldr     w1, [sp, #116]
    0.00 :   ffff8000101903d4:       ldr     x7, [sp, #104]
    0.00 :   ffff8000101903d8:       add     x0, x5, x5, lsl #1
         : 39               __pagevec_lru_add():
         : 1057             for (i = 0; i < pagevec_count(pvec); i++) {
    0.00 :   ffff8000101903dc:       add     w22, w22, #0x1
         : 1059             update_lru_size():
    0.00 :   ffff8000101903e0:       add     x0, x5, x0, lsl #3
    0.00 :   ffff8000101903e4:       mov     x2, x7
    0.00 :   ffff8000101903e8:       add     x0, x28, x0, lsl #6
    0.00 :   ffff8000101903ec:       bl      ffff8000101a4ca0 <__mod_zone_page_state>
         : 37               mem_cgroup_update_lru_size(lruvec, lru, zid, nr_pages);
    0.00 :   ffff8000101903f0:       mov     w2, w21
    0.00 :   ffff8000101903f4:       mov     w1, w23
    0.00 :   ffff8000101903f8:       mov     x0, x20
    0.00 :   ffff8000101903fc:       mov     w3, w25
    0.00 :   ffff800010190400:       bl      ffff800010223ed0 <mem_cgroup_update_lru_size>
         : 43               list_add():
         : 86               * Insert a new entry after the specified head.
         : 87               * This is good for implementing stacks.
         : 88               */
         : 89               static inline void list_add(struct list_head *new, struct list_head *head)
         : 90               {
         : 91               __list_add(new, head, head->next);
    0.00 :   ffff800010190404:       lsl     x4, x26, #4
         : 93               add_page_to_lru_list():
         : 88               struct lruvec *lruvec)
         : 89               {
         : 90               enum lru_list lru = page_lru(page);
         :
         : 92               update_lru_size(lruvec, lru, page_zonenum(page), thp_nr_pages(page));
         : 93               list_add(&page->lru, &lruvec->lists[lru]);
    0.00 :   ffff800010190408:       add     x0, x19, #0x8
    0.00 :   ffff80001019040c:       add     x2, x20, x27
         : 96               list_add():
    0.00 :   ffff800010190410:       ldr     x1, [x20, x4]
         : 87               __list_add():
         : 70               next->prev = new;
    0.00 :   ffff800010190414:       str     x0, [x1, #8]
         : 72               new->prev = prev;
    0.00 :   ffff800010190418:       stp     x1, x2, [x19, #8]
         : 73               WRITE_ONCE(prev->next, new);
    0.00 :   ffff80001019041c:       str     x0, [x20, x27]
         : 75               __pagevec_lru_add():
    0.00 :   ffff800010190420:       ldrb    w1, [x24]
    0.00 :   ffff800010190424:       cmp     w1, w22
    0.00 :   ffff800010190428:       b.hi    ffff8000101901f0 <__pagevec_lru_add+0x68>  // b.pmore
         :
         : 1064             lruvec = relock_page_lruvec_irqsave(page, lruvec, &flags);
         : 1065             __pagevec_lru_add_fn(page, lruvec);
         : 1066             }
         : 1067             if (lruvec)
    0.00 :   ffff80001019042c:       cbz     x20, ffff800010190548 <__pagevec_lru_add+0x3c0>
         : 1069             spin_unlock_irqrestore():
    0.00 :   ffff800010190430:       ldr     x1, [sp, #144]
    0.00 :   ffff800010190434:       add     x0, x20, #0x50
    0.00 :   ffff800010190438:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
    0.00 :   ffff80001019043c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010190440:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010190444:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010190448:       ldrb    w1, [x24]
         : 416              __pagevec_lru_add():
         : 1065             unlock_page_lruvec_irqrestore(lruvec, flags);
         : 1066             release_pages(pvec->pages, pvec->nr);
    0.00 :   ffff80001019044c:       add     x0, x24, #0x8
    0.00 :   ffff800010190450:       bl      ffff80001018d920 <release_pages>
         : 1067             pagevec_reinit(pvec);
         : 1068             }
    0.00 :   ffff800010190454:       ldr     x0, [sp, #136]
         : 1070             pagevec_reinit():
         : 56               pvec->percpu_pvec_drained = false;
         : 57               }
         :
         : 59               static inline void pagevec_reinit(struct pagevec *pvec)
         : 60               {
         : 61               pvec->nr = 0;
    0.00 :   ffff800010190458:       strb    wzr, [x24]
         : 63               __pagevec_lru_add():
    0.00 :   ffff80001019045c:       ldr     x1, [sp, #152]
    0.00 :   ffff800010190460:       ldr     x0, [x0]
    0.00 :   ffff800010190464:       eor     x0, x1, x0
    0.00 :   ffff800010190468:       cbnz    x0, ffff800010190558 <__pagevec_lru_add+0x3d0>
    0.00 :   ffff80001019046c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010190470:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff800010190474:       ldp     x29, x30, [sp], #160
    0.00 :   ffff800010190478:       autiasp
    0.00 :   ffff80001019047c:       ret
         : 1076             compound_head():
         : 184              {
    0.00 :   ffff800010190480:       ldr     x1, [x19, #8]
         : 188              return head - 1;
    0.00 :   ffff800010190484:       sub     x0, x1, #0x1
    0.00 :   ffff800010190488:       tst     x1, #0x1
    0.00 :   ffff80001019048c:       csel    x0, x0, x19, ne  // ne = any
         : 192              test_bit():
    0.00 :   ffff800010190490:       ldr     x0, [x0]
         : 107              page_evictable():
    0.00 :   ffff800010190494:       tbnz    w0, #21, ffff8000101902d4 <__pagevec_lru_add+0x14c>
         : 84               rcu_read_unlock():
    0.00 :   ffff800010190498:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              __pagevec_lru_add_fn():
         : 1034             if (was_unevictable)
    0.00 :   ffff80001019049c:       cbz     w21, ffff800010190334 <__pagevec_lru_add+0x1ac>
         : 1036             __count_vm_events():
    0.00 :   ffff8000101904a0:       ldr     x0, [sp, #128]
    0.00 :   ffff8000101904a4:       b       ffff800010190324 <__pagevec_lru_add+0x19c>
         : 78               __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff8000101904a8:       b       ffff800010190d34 <pagevec_remove_exceptionals+0x2e4>
    0.00 :   ffff8000101904ac:       b       ffff8000101902b8 <__pagevec_lru_add+0x130>
         : 230              page_lru():
         : 72               if (PageUnevictable(page))
    0.00 :   ffff8000101904b0:       mov     w0, #0x5                        // #5
    0.00 :   ffff8000101904b4:       str     w0, [sp, #116]
         : 75               page_zonenum():
    0.00 :   ffff8000101904b8:       ldr     x21, [x19]
         : 1128             thp_nr_pages():
    0.00 :   ffff8000101904bc:       mov     x7, #0x1                        // #1
         : 277              test_bit():
    0.00 :   ffff8000101904c0:       ldr     x0, [x19]
         : 107              page_lru():
    0.00 :   ffff8000101904c4:       mov     x27, #0x40                      // #64
         : 73               return LRU_UNEVICTABLE;
    0.00 :   ffff8000101904c8:       mov     w23, #0x4                       // #4
    0.00 :   ffff8000101904cc:       mov     x26, #0x4                       // #4
         : 76               thp_nr_pages():
         : 278              static inline int thp_nr_pages(struct page *page)
    0.00 :   ffff8000101904d0:       mov     w25, w7
         : 280              page_zonenum():
    0.00 :   ffff8000101904d4:       ubfx    x21, x21, #58, #2
         : 1128             thp_nr_pages():
         : 276              * @page: The head page of a huge page.
    0.00 :   ffff8000101904d8:       tbz     w0, #16, ffff8000101903b4 <__pagevec_lru_add+0x22c>
    0.00 :   ffff8000101904dc:       mov     x7, #0x200                      // #512
         : 277              */
    0.00 :   ffff8000101904e0:       mov     w25, w7
    0.00 :   ffff8000101904e4:       b       ffff8000101903b4 <__pagevec_lru_add+0x22c>
         : 280              lruvec_holds_page_lru_lock():
         : 767              void lruvec_memcg_debug(struct lruvec *lruvec, struct page *page);
    0.00 :   ffff8000101904e8:       mov     x0, #0x2220                     // #8736
    0.00 :   ffff8000101904ec:       add     x1, x1, x0
         : 770              relock_page_lruvec_irqsave():
         :
    0.00 :   ffff8000101904f0:       cmp     x20, x1
    0.00 :   ffff8000101904f4:       b.eq    ffff800010190258 <__pagevec_lru_add+0xd0>  // b.none
    0.00 :   ffff8000101904f8:       b       ffff80001019023c <__pagevec_lru_add+0xb4>
         : 1542             page_lru():
         : 77               lru += LRU_ACTIVE;
    0.00 :   ffff8000101904fc:       mov     w6, w1
    0.00 :   ffff800010190500:       add     w0, w1, #0x1
    0.00 :   ffff800010190504:       mov     x26, x6
    0.00 :   ffff800010190508:       mov     w23, w1
    0.00 :   ffff80001019050c:       lsl     x27, x6, #4
    0.00 :   ffff800010190510:       str     w0, [sp, #116]
    0.00 :   ffff800010190514:       b       ffff80001019039c <__pagevec_lru_add+0x214>
         : 85               __ll_sc_atomic64_or():
    0.00 :   ffff800010190518:       b       ffff800010190d4c <pagevec_remove_exceptionals+0x2fc>
    0.00 :   ffff80001019051c:       b       ffff800010190318 <__pagevec_lru_add+0x190>
         : 224              __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff800010190520:       mov     x1, #0x20                       // #32
    0.00 :   ffff800010190524:       b       ffff800010190d64 <pagevec_remove_exceptionals+0x314>
    0.00 :   ffff800010190528:       b       ffff8000101902f8 <__pagevec_lru_add+0x170>
         : 238              __ll_sc_atomic64_fetch_andnot():
    0.00 :   ffff80001019052c:       mov     x1, #0x100000                   // #1048576
    0.00 :   ffff800010190530:       b       ffff800010190d7c <pagevec_remove_exceptionals+0x32c>
    0.00 :   ffff800010190534:       b       ffff800010190284 <__pagevec_lru_add+0xfc>
         : 232              lruvec_holds_page_lru_lock():
         : 772              #endif
  100.00 :   ffff800010190538:       ldr     x1, [x20, #696]
    0.00 :   ffff80001019053c:       cmp     x1, x0
    0.00 :   ffff800010190540:       b.ne    ffff80001019023c <__pagevec_lru_add+0xb4>  // b.any
    0.00 :   ffff800010190544:       b       ffff800010190258 <__pagevec_lru_add+0xd0>
    0.00 :   ffff800010190548:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001019054c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010190550:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff800010190554:       b       ffff80001019044c <__pagevec_lru_add+0x2c4>
    0.00 :   ffff800010190558:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001019055c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010190560:       stp     x27, x28, [sp, #80]
         : 784              __pagevec_lru_add():
         : 1067             }
    0.00 :   ffff800010190564:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104c4c40 <gic_eoimode1_eoi_irq>:
         : 6                gic_eoimode1_eoi_irq():
         : 542              {
         : 543              /*
         : 544              * No need to deactivate an LPI, or an interrupt that
         : 545              * is is getting forwarded to a vcpu.
         : 546              */
         : 547              if (gic_irq(d) >= 8192 || irqd_is_forwarded_to_vcpu(d))
    0.00 :   ffff8000104c4c40:       ldr     x1, [x0, #8]
    0.00 :   ffff8000104c4c44:       mov     w2, #0x1fff                     // #8191
    0.00 :   ffff8000104c4c48:       cmp     w1, w2
    0.00 :   ffff8000104c4c4c:       b.hi    ffff8000104c4c74 <gic_eoimode1_eoi_irq+0x34>  // b.pmore
         : 552              irqd_is_forwarded_to_vcpu():
         : 364              static inline bool irqd_is_wakeup_armed(struct irq_data *d)
         : 365              {
         : 366              return __irqd_to_state(d) & IRQD_WAKEUP_ARMED;
         : 367              }
         :
         : 369              static inline bool irqd_is_forwarded_to_vcpu(struct irq_data *d)
    0.00 :   ffff8000104c4c50:       ldr     x0, [x0, #16]
    0.00 :   ffff8000104c4c54:       ldr     w0, [x0]
         : 372              gic_eoimode1_eoi_irq():
    0.00 :   ffff8000104c4c58:       tbnz    w0, #20, ffff8000104c4c74 <gic_eoimode1_eoi_irq+0x34>
         : 537              {
    0.00 :   ffff8000104c4c5c:       paciasp
         : 539              gic_write_dir():
         : 37               isb();
         : 38               }
         :
         : 40               static __always_inline void gic_write_dir(u32 irq)
         : 41               {
         : 42               write_sysreg_s(irq, SYS_ICC_DIR_EL1);
    0.00 :   ffff8000104c4c60:       and     x1, x1, #0xffffffff
    0.00 :   ffff8000104c4c64:       msr     s3_0_c12_c11_1, x1
         : 38               isb();
    0.00 :   ffff8000104c4c68:       isb
         : 40               gic_eoimode1_eoi_irq():
         : 545              return;
         : 546              gic_write_dir(gic_irq(d));
         : 547              }
  100.00 :   ffff8000104c4c6c:       autiasp
    0.00 :   ffff8000104c4c70:       ret
    0.00 :   ffff8000104c4c74:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010f4e8 <__hrtimer_next_event_base>:
         : 6                __hrtimer_next_event_base():
         :
         : 507              static ktime_t __hrtimer_next_event_base(struct hrtimer_cpu_base *cpu_base,
         : 508              const struct hrtimer *exclude,
         : 509              unsigned int active,
         : 510              ktime_t expires_next)
         : 511              {
    0.00 :   ffff80001010f4e8:       paciasp
    0.00 :   ffff80001010f4ec:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff80001010f4f0:       mov     x29, sp
    0.00 :   ffff80001010f4f4:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001010f4f8:       mov     x22, x3
         : 517              __next_base():
         : 490              if (!*active)
    0.00 :   ffff80001010f4fc:       cbz     w2, ffff80001010f598 <__hrtimer_next_event_base+0xb0>
         : 492              __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff80001010f500:       mov     x21, x0
         : 20               __next_base():
         : 493              idx = __ffs(*active);
    0.00 :   ffff80001010f504:       mov     w0, w2
         : 495              __ffs():
    0.00 :   ffff80001010f508:       rbit    x0, x0
    0.00 :   ffff80001010f50c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001010f510:       clz     x0, x0
         : 16               __next_base():
         : 496              return &cpu_base->clock_base[idx];
    0.00 :   ffff80001010f514:       add     x4, x0, #0x1
    0.00 :   ffff80001010f518:       stp     x23, x24, [sp, #48]
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f51c:       mov     w24, #0x1                       // #1
    0.00 :   ffff80001010f520:       lsl     w20, w24, w0
    0.00 :   ffff80001010f524:       mov     x23, x1
         : 493              idx = __ffs(*active);
    0.00 :   ffff80001010f528:       mov     w19, w0
         : 495              __hrtimer_next_event_base():
         : 510              struct hrtimer_clock_base *base;
         : 511              ktime_t expires;
         :
         : 513              for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f52c:       adds    x4, x21, x4, lsl #6
         : 515              __next_base():
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f530:       bic     w20, w2, w20
         : 496              __hrtimer_next_event_base():
         : 510              for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f534:       b.eq    ffff80001010f590 <__hrtimer_next_event_base+0xa8>  // b.none
         : 514              struct timerqueue_node *next;
         : 515              struct hrtimer *timer;
         :
         : 517              next = timerqueue_getnext(&base->active);
    0.00 :   ffff80001010f538:       ldr     x0, [x4, #40]
         : 516              timer = container_of(next, struct hrtimer, node);
         : 517              if (timer == exclude) {
    0.00 :   ffff80001010f53c:       cmp     x23, x0
    0.00 :   ffff80001010f540:       b.eq    ffff80001010f5c0 <__hrtimer_next_event_base+0xd8>  // b.none
         : 524              if (!next)
         : 525              continue;
         :
         : 527              timer = container_of(next, struct hrtimer, node);
         : 528              }
         : 529              expires = ktime_sub(hrtimer_get_expires(timer), base->offset);
    0.00 :   ffff80001010f544:       ubfiz   x19, x19, #6, #7
    0.00 :   ffff80001010f548:       add     x19, x21, x19
    0.00 :   ffff80001010f54c:       ldr     x4, [x0, #24]
    0.00 :   ffff80001010f550:       ldr     x2, [x19, #120]
    0.00 :   ffff80001010f554:       sub     x4, x4, x2
         : 525              if (expires < expires_next) {
    0.00 :   ffff80001010f558:       cmp     x4, x22
    0.00 :   ffff80001010f55c:       b.ge    ffff80001010f568 <__hrtimer_next_event_base+0x80>  // b.tcont
         :
         : 533              /* Skip cpu_base update if a timer is being excluded. */
         : 534              if (exclude)
         : 535              continue;
         :
         : 537              if (timer->is_soft)
    0.00 :   ffff80001010f560:       mov     x22, x4
         : 529              if (exclude)
    0.00 :   ffff80001010f564:       cbz     x23, ffff80001010f5b0 <__hrtimer_next_event_base+0xc8>
         : 531              __next_base():
         : 493              idx = __ffs(*active);
    0.00 :   ffff80001010f568:       mov     w0, w20
         : 495              __ffs():
    0.00 :   ffff80001010f56c:       rbit    x0, x0
    0.00 :   ffff80001010f570:       clz     x0, x0
         : 15               __next_base():
         : 496              return &cpu_base->clock_base[idx];
    0.00 :   ffff80001010f574:       add     x4, x0, #0x1
         : 490              if (!*active)
    0.00 :   ffff80001010f578:       cbz     w20, ffff80001010f590 <__hrtimer_next_event_base+0xa8>
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f57c:       lsl     w1, w24, w0
         : 493              idx = __ffs(*active);
    0.00 :   ffff80001010f580:       mov     w19, w0
         : 495              __hrtimer_next_event_base():
         : 510              for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f584:       adds    x4, x21, x4, lsl #6
         : 512              __next_base():
         : 494              *active &= ~(1U << idx);
    0.00 :   ffff80001010f588:       bic     w20, w20, w1
         : 496              __hrtimer_next_event_base():
         : 510              for_each_active_base(base, cpu_base, active) {
    0.00 :   ffff80001010f58c:       b.ne    ffff80001010f538 <__hrtimer_next_event_base+0x50>  // b.any
    0.00 :   ffff80001010f590:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001010f594:       ldp     x23, x24, [sp, #48]
         : 545              * the clock bases so the result might be negative. Fix it up
         : 546              * to prevent a false positive in clockevents_program_event().
         : 547              */
         : 548              if (expires_next < 0)
         : 549              expires_next = 0;
         : 550              return expires_next;
    0.00 :   ffff80001010f598:       cmp     x22, #0x0
         : 546              }
    0.00 :   ffff80001010f59c:       csel    x0, x22, xzr, ge  // ge = tcont
    0.00 :   ffff80001010f5a0:       ldp     x21, x22, [sp, #32]
  100.00 :   ffff80001010f5a4:       ldp     x29, x30, [sp], #64
    0.00 :   ffff80001010f5a8:       autiasp
    0.00 :   ffff80001010f5ac:       ret
         : 532              if (timer->is_soft)
    0.00 :   ffff80001010f5b0:       ldrb    w1, [x0, #58]
    0.00 :   ffff80001010f5b4:       cbz     w1, ffff80001010f5d0 <__hrtimer_next_event_base+0xe8>
         : 533              cpu_base->softirq_next_timer = timer;
    0.00 :   ffff80001010f5b8:       str     x0, [x21, #56]
    0.00 :   ffff80001010f5bc:       b       ffff80001010f568 <__hrtimer_next_event_base+0x80>
         : 518              next = timerqueue_iterate_next(next);
    0.00 :   ffff80001010f5c0:       mov     x0, x23
    0.00 :   ffff80001010f5c4:       bl      ffff8000104b7948 <timerqueue_iterate_next>
         : 519              if (!next)
    0.00 :   ffff80001010f5c8:       cbnz    x0, ffff80001010f544 <__hrtimer_next_event_base+0x5c>
    0.00 :   ffff80001010f5cc:       b       ffff80001010f568 <__hrtimer_next_event_base+0x80>
         : 535              cpu_base->next_timer = timer;
    0.00 :   ffff80001010f5d0:       str     x0, [x21, #40]
    0.00 :   ffff80001010f5d4:       b       ffff80001010f568 <__hrtimer_next_event_base+0x80>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bfb18 <task_tick_fair>:
         : 6                task_tick_fair():
         : 10767            {
         : 10768            /*
         : 10769            * Don't need to rebalance while attached to NULL domain or
         : 10770            * runqueue CPU is not active
         : 10771            */
         : 10772            if (unlikely(on_null_domain(rq) || !cpu_active(cpu_of(rq))))
  100.00 :   ffff8000100bfb18:       paciasp
    0.00 :   ffff8000100bfb1c:       stp     x29, x30, [sp, #-144]!
    0.00 :   ffff8000100bfb20:       mov     x29, sp
    0.00 :   ffff8000100bfb24:       stp     x19, x20, [sp, #16]
         : 10771            return;
         :
         : 10773            if (time_after_eq(jiffies, rq->next_balance))
         : 10774            raise_softirq(SCHED_SOFTIRQ);
    0.00 :   ffff8000100bfb28:       adds    x20, x1, #0x80
         : 10767            if (unlikely(on_null_domain(rq) || !cpu_active(cpu_of(rq))))
    0.00 :   ffff8000100bfb2c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100bfb30:       adrp    x24, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100bfb34:       mov     x23, x1
    0.00 :   ffff8000100bfb38:       str     x0, [sp, #120]
    0.00 :   ffff8000100bfb3c:       add     x0, x24, #0x760
    0.00 :   ffff8000100bfb40:       str     x0, [sp, #104]
         : 10771            raise_softirq(SCHED_SOFTIRQ);
    0.00 :   ffff8000100bfb44:       b.eq    ffff8000100bfc14 <task_tick_fair+0xfc>  // b.none
    0.00 :   ffff8000100bfb48:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bfb4c:       mov     w21, w2
         : 10775            add_tg_cfs_propagate():
         : 3563             /*
    0.00 :   ffff8000100bfb50:       mov     x22, #0x1                       // #1
    0.00 :   ffff8000100bfb54:       stp     x25, x26, [sp, #64]
         : 3566             update_tg_load_avg():
         :
    0.00 :   ffff8000100bfb58:       adrp    x25, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100bfb5c:       add     x0, x25, #0x5c0
         : 3325             cpufreq_update_util():
         : 2509             __acquires(this_rq->lock)
         : 2510             {
         : 2511             raw_spin_rq_unlock(this_rq);
         : 2512             double_rq_lock(this_rq, busiest);
         :
         : 2514             return 1;
    0.00 :   ffff8000100bfb60:       adrp    x26, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100bfb64:       stp     x27, x28, [sp, #80]
         : 2517             update_tg_load_avg():
    0.00 :   ffff8000100bfb68:       str     x0, [sp, #96]
         : 3323             cpufreq_update_util():
    0.00 :   ffff8000100bfb6c:       add     x0, x26, #0x8c0
    0.00 :   ffff8000100bfb70:       str     x0, [sp, #112]
    0.00 :   ffff8000100bfb74:       nop
         : 2512             task_tick_fair():
         :
    0.00 :   ffff8000100bfb78:       ldr     x19, [x20, #120]
         : 10774            entity_tick():
         : 4545             {
    0.00 :   ffff8000100bfb7c:       mov     x0, x19
    0.00 :   ffff8000100bfb80:       bl      ffff8000100bc950 <update_curr>
         : 4548             cfs_rq_clock_pelt():
         : 162              #else
         :
         : 164              static inline int
         : 165              update_cfs_rq_load_avg(u64 now, struct cfs_rq *cfs_rq)
         : 166              {
         : 167              return 0;
    0.00 :   ffff8000100bfb84:       ldr     x0, [x19, #304]
         : 169              update_load_avg():
         : 3799             static inline u64 cfs_rq_last_update_time(struct cfs_rq *cfs_rq)
    0.00 :   ffff8000100bfb88:       ldr     x1, [x20, #192]
         : 3801             rq_clock_pelt():
         :
    0.00 :   ffff8000100bfb8c:       ldr     x28, [x0, #2440]
    0.00 :   ffff8000100bfb90:       ldr     x0, [x0, #2448]
    0.00 :   ffff8000100bfb94:       sub     x28, x28, x0
         : 151              update_load_avg():
    0.00 :   ffff8000100bfb98:       cbz     x1, ffff8000100bfbac <task_tick_fair+0x94>
         : 3800             {
    0.00 :   ffff8000100bfb9c:       mov     x2, x20
    0.00 :   ffff8000100bfba0:       mov     x1, x19
    0.00 :   ffff8000100bfba4:       mov     x0, x28
    0.00 :   ffff8000100bfba8:       bl      ffff8000100d4ea8 <__update_load_avg_se>
         : 3805             update_cfs_rq_load_avg():
         : 3661             *
    0.00 :   ffff8000100bfbac:       ldr     w0, [x19, #196]
    0.00 :   ffff8000100bfbb0:       cbnz    w0, ffff8000100bfc58 <task_tick_fair+0x140>
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100bfbb4:       mov     x1, x19
    0.00 :   ffff8000100bfbb8:       mov     x0, x28
    0.00 :   ffff8000100bfbbc:       bl      ffff8000100d50e8 <__update_load_avg_cfs_rq>
         : 3698             propagate_entity_load_avg():
         : 3572             * already zero and there is no pending propagation, so it will be a
    0.00 :   ffff8000100bfbc0:       ldr     x1, [x20, #128]
    0.00 :   ffff8000100bfbc4:       cbz     x1, ffff8000100bfbd0 <task_tick_fair+0xb8>
         : 3576             }
    0.00 :   ffff8000100bfbc8:       ldr     x2, [x1, #264]
    0.00 :   ffff8000100bfbcc:       cbnz    x2, ffff8000100bfd3c <task_tick_fair+0x224>
         : 3579             update_load_avg():
         :
    0.00 :   ffff8000100bfbd0:       cbnz    w0, ffff8000100bfe94 <task_tick_fair+0x37c>
         : 3819             entity_tick():
         : 4551             static_key_slow_inc_cpuslocked(&__cfs_bandwidth_used);
    0.00 :   ffff8000100bfbd4:       mov     x0, x20
    0.00 :   ffff8000100bfbd8:       bl      ffff8000100bcbb8 <update_cfs_group>
         : 4559             static bool cfs_bandwidth_used(void)
    0.00 :   ffff8000100bfbdc:       ldr     x0, [x19, #304]
         : 4558             #else /* CONFIG_JUMP_LABEL */
    0.00 :   ffff8000100bfbe0:       cbnz    w21, ffff8000100bfef8 <task_tick_fair+0x3e0>
         : 4566             #endif /* CONFIG_JUMP_LABEL */
    0.00 :   ffff8000100bfbe4:       add     x0, x0, #0xba0
    0.00 :   ffff8000100bfbe8:       bl      ffff80001010f478 <hrtimer_active>
         : 4565             void cfs_bandwidth_usage_dec(void) {}
    0.00 :   ffff8000100bfbec:       tst     w0, #0xff
    0.00 :   ffff8000100bfbf0:       b.ne    ffff8000100bfc00 <task_tick_fair+0xe8>  // b.any
         : 4570             * default: 0.1s, units: nanoseconds
    0.00 :   ffff8000100bfbf4:       ldr     w0, [x19, #16]
    0.00 :   ffff8000100bfbf8:       cmp     w0, #0x1
    0.00 :   ffff8000100bfbfc:       b.hi    ffff8000100bff00 <task_tick_fair+0x3e8>  // b.pmore
         : 4574             task_tick_fair():
         : 10771            raise_softirq(SCHED_SOFTIRQ);
    0.00 :   ffff8000100bfc00:       ldr     x20, [x20, #112]
    0.00 :   ffff8000100bfc04:       cbnz    x20, ffff8000100bfb78 <task_tick_fair+0x60>
    0.00 :   ffff8000100bfc08:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bfc0c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bfc10:       ldp     x27, x28, [sp, #80]
         : 10777            arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000100bfc14:       nop
    0.00 :   ffff8000100bfc18:       nop
         : 29               update_misfit_status():
         : 4066             return 0;
    0.00 :   ffff8000100bfc1c:       adrp    x6, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100bfc20:       add     x6, x6, #0xc40
         : 4069             task_cpu():
         : 1993             * Returns non-zero if there is another task waiting on the rwlock.
         : 1994             * Returns zero if the lock is not contended or the system / underlying
         : 1995             * rwlock implementation does not support contention detection.
         : 1996             * Technically does not depend on CONFIG_PREEMPTION, but a general need
         : 1997             * for low latency.
         : 1998             */
    0.00 :   ffff8000100bfc24:       ldr     w1, [x23, #64]
         : 2000             task_tick_fair():
         :
         : 10781            static void rq_online_fair(struct rq *rq)
         : 10782            {
         : 10783            update_sysctl();
         :
         : 10785            update_runtime_enabled(rq);
    0.00 :   ffff8000100bfc28:       mov     x0, x6
    0.00 :   ffff8000100bfc2c:       ldr     x2, [sp, #104]
    0.00 :   ffff8000100bfc30:       ldr     x1, [x2, w1, uxtw #3]
    0.00 :   ffff8000100bfc34:       add     x1, x0, x1
         : 10790            update_overutilized_status():
         : 5483             * estimated utilization, before we update schedutil.
    0.00 :   ffff8000100bfc38:       ldr     x2, [x1, #2464]
    0.00 :   ffff8000100bfc3c:       ldr     w3, [x2, #92]
    0.00 :   ffff8000100bfc40:       cbz     w3, ffff8000100c00ac <task_tick_fair+0x594>
         : 5487             task_tick_fair():
         : 10781            }
    0.00 :   ffff8000100bfc44:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bfc48:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100bfc4c:       ldp     x29, x30, [sp], #144
    0.00 :   ffff8000100bfc50:       autiasp
    0.00 :   ffff8000100bfc54:       ret
         : 10787            get_pelt_divider():
         : 42               return LOAD_AVG_MAX - 1024 + avg->period_contrib;
    0.00 :   ffff8000100bfc58:       ldr     w4, [x19, #156]
    0.00 :   ffff8000100bfc5c:       mov     w7, #0xb67e                     // #46718
         : 45               update_cfs_rq_load_avg():
         : 3665             static void attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)
    0.00 :   ffff8000100bfc60:       add     x25, x19, #0xc0
         : 3667             get_pelt_divider():
    0.00 :   ffff8000100bfc64:       add     w24, w4, w7
         : 43               update_cfs_rq_load_avg():
    0.00 :   ffff8000100bfc68:       mov     x0, x25
    0.00 :   ffff8000100bfc6c:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 3669             * See ___update_load_avg() for details.
    0.00 :   ffff8000100bfc70:       str     wzr, [x19, #196]
         : 3670             */
    0.00 :   ffff8000100bfc74:       mov     x0, x25
         : 3666             {
    0.00 :   ffff8000100bfc78:       ldp     x25, x26, [x19, #200]
    0.00 :   ffff8000100bfc7c:       stp     xzr, xzr, [x19, #200]
         : 3668             * cfs_rq->avg.period_contrib can be used for both cfs_rq and se.
    0.00 :   ffff8000100bfc80:       ldr     x27, [x19, #216]
    0.00 :   ffff8000100bfc84:       str     xzr, [x19, #216]
         : 3670             */
    0.00 :   ffff8000100bfc88:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 3672             add_tg_cfs_propagate():
         : 3563             /*
    0.00 :   ffff8000100bfc8c:       str     x22, [x19, #264]
         : 3565             update_cfs_rq_load_avg():
         : 3673             /*
    0.00 :   ffff8000100bfc90:       ldr     x7, [x19, #160]
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100bfc94:       mov     w10, w24
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100bfc98:       mov     x1, x19
    0.00 :   ffff8000100bfc9c:       mov     x0, x28
         : 3673             /*
    0.00 :   ffff8000100bfca0:       sub     x6, x7, x25
    0.00 :   ffff8000100bfca4:       cmp     x7, x6
         :
    0.00 :   ffff8000100bfca8:       mul     x2, x27, x10
         : 3673             /*
    0.00 :   ffff8000100bfcac:       csel    x6, x6, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfcb0:       str     x6, [x19, #160]
         : 3676             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100bfcb4:       ldr     x6, [x19, #272]
         : 3566             update_cfs_rq_load_avg():
         : 3689             se->avg.util_sum = se->avg.util_avg * divider;
    0.00 :   ffff8000100bfcb8:       neg     x7, x2
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100bfcbc:       ldr     x9, [x19, #136]
         : 3676             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100bfcc0:       add     x6, x6, x7, asr #10
    0.00 :   ffff8000100bfcc4:       str     x6, [x19, #272]
         : 3567             update_cfs_rq_load_avg():
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100bfcc8:       msub    x5, x25, x10, x9
    0.00 :   ffff8000100bfccc:       cmp     x9, x5
    0.00 :   ffff8000100bfcd0:       csel    x5, x5, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfcd4:       str     x5, [x19, #136]
         : 3677             *
    0.00 :   ffff8000100bfcd8:       ldr     x6, [x19, #176]
    0.00 :   ffff8000100bfcdc:       sub     x5, x6, x26
    0.00 :   ffff8000100bfce0:       cmp     x6, x5
    0.00 :   ffff8000100bfce4:       csel    x5, x5, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfce8:       str     x5, [x19, #176]
         : 3678             * XXX illustrate
    0.00 :   ffff8000100bfcec:       ldr     w5, [x19, #152]
    0.00 :   ffff8000100bfcf0:       msub    w4, w24, w26, w5
    0.00 :   ffff8000100bfcf4:       cmp     w5, w4
    0.00 :   ffff8000100bfcf8:       csel    w4, w4, wzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfcfc:       str     w4, [x19, #152]
         : 3681             se->avg.period_contrib = cfs_rq->avg.period_contrib;
    0.00 :   ffff8000100bfd00:       ldr     x4, [x19, #168]
    0.00 :   ffff8000100bfd04:       sub     x3, x4, x27
    0.00 :   ffff8000100bfd08:       cmp     x4, x3
    0.00 :   ffff8000100bfd0c:       csel    x3, x3, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfd10:       str     x3, [x19, #168]
         :
    0.00 :   ffff8000100bfd14:       ldr     x3, [x19, #144]
    0.00 :   ffff8000100bfd18:       sub     x2, x3, x2
    0.00 :   ffff8000100bfd1c:       cmp     x3, x2
    0.00 :   ffff8000100bfd20:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfd24:       str     x2, [x19, #144]
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100bfd28:       bl      ffff8000100d50e8 <__update_load_avg_cfs_rq>
         : 3696             propagate_entity_load_avg():
         : 3572             * already zero and there is no pending propagation, so it will be a
    0.00 :   ffff8000100bfd2c:       ldr     x1, [x20, #128]
    0.00 :   ffff8000100bfd30:       cbz     x1, ffff8000100bfe94 <task_tick_fair+0x37c>
         : 3576             }
    0.00 :   ffff8000100bfd34:       ldr     x0, [x1, #264]
    0.00 :   ffff8000100bfd38:       cbz     x0, ffff8000100bfe94 <task_tick_fair+0x37c>
         :
    0.00 :   ffff8000100bfd3c:       str     xzr, [x1, #264]
         : 3583             {
    0.00 :   ffff8000100bfd40:       ldr     x3, [x1, #272]
         :
    0.00 :   ffff8000100bfd44:       ldr     x0, [x20, #120]
         : 3583             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100bfd48:       ldr     x2, [x0, #272]
    0.00 :   ffff8000100bfd4c:       add     x2, x2, x3
    0.00 :   ffff8000100bfd50:       stp     x22, x2, [x0, #264]
         : 3568             propagate_entity_load_avg():
         : 3585             }
    0.00 :   ffff8000100bfd54:       ldr     x3, [x1, #176]
         : 3587             update_tg_cfs_util():
         :
    0.00 :   ffff8000100bfd58:       ldr     x2, [x20, #240]
    0.00 :   ffff8000100bfd5c:       subs    x2, x3, x2
         : 3456             long delta, running_sum, runnable_sum = gcfs_rq->prop_runnable_sum;
    0.00 :   ffff8000100bfd60:       b.eq    ffff8000100bfd9c <task_tick_fair+0x284>  // b.none
         : 3458             get_pelt_divider():
    0.00 :   ffff8000100bfd64:       ldr     w4, [x0, #156]
    0.00 :   ffff8000100bfd68:       mov     w6, #0xb67e                     // #46718
         : 44               update_tg_cfs_util():
         : 3466             /*
    0.00 :   ffff8000100bfd6c:       str     x3, [x20, #240]
         : 3468             get_pelt_divider():
    0.00 :   ffff8000100bfd70:       add     w4, w4, w6
         : 43               update_tg_cfs_util():
         : 3467             * cfs_rq->avg.period_contrib can be used for both cfs_rq and se.
    0.00 :   ffff8000100bfd74:       mul     w3, w4, w3
    0.00 :   ffff8000100bfd78:       str     w3, [x20, #216]
         : 3470             divider = get_pelt_divider(&cfs_rq->avg);
    0.00 :   ffff8000100bfd7c:       ldr     x3, [x0, #176]
    0.00 :   ffff8000100bfd80:       add     x2, x2, x3
    0.00 :   ffff8000100bfd84:       ccmp    x3, x2, #0x2, mi  // mi = first
    0.00 :   ffff8000100bfd88:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfd8c:       str     x2, [x0, #176]
         :
    0.00 :   ffff8000100bfd90:       ldr     x2, [x0, #176]
    0.00 :   ffff8000100bfd94:       mul     w4, w4, w2
    0.00 :   ffff8000100bfd98:       str     w4, [x0, #152]
         : 3475             propagate_entity_load_avg():
         :
    0.00 :   ffff8000100bfd9c:       ldr     x3, [x1, #168]
         : 3588             update_tg_cfs_runnable():
         : 3477             runnable_sum += se->avg.load_sum;
    0.00 :   ffff8000100bfda0:       ldr     x2, [x20, #232]
    0.00 :   ffff8000100bfda4:       subs    x2, x3, x2
         : 3481             * Estimate the new unweighted runnable_sum of the gcfs_rq by
    0.00 :   ffff8000100bfda8:       b.eq    ffff8000100bfde4 <task_tick_fair+0x2cc>  // b.none
         : 3483             get_pelt_divider():
    0.00 :   ffff8000100bfdac:       ldr     w4, [x0, #156]
         : 43               update_tg_cfs_runnable():
         :
    0.00 :   ffff8000100bfdb0:       mov     w5, #0xb67e                     // #46718
         : 3491             }
    0.00 :   ffff8000100bfdb4:       str     x3, [x20, #232]
         :
    0.00 :   ffff8000100bfdb8:       add     w4, w4, w5
    0.00 :   ffff8000100bfdbc:       mul     x3, x3, x4
    0.00 :   ffff8000100bfdc0:       str     x3, [x20, #208]
         : 3495             * Rescale running sum to be in the same range as runnable sum
    0.00 :   ffff8000100bfdc4:       ldr     x3, [x0, #168]
    0.00 :   ffff8000100bfdc8:       add     x2, x2, x3
    0.00 :   ffff8000100bfdcc:       ccmp    x3, x2, #0x2, mi  // mi = first
    0.00 :   ffff8000100bfdd0:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfdd4:       str     x2, [x0, #168]
         : 3496             * running_sum is in [0 : LOAD_AVG_MAX <<  SCHED_CAPACITY_SHIFT]
    0.00 :   ffff8000100bfdd8:       ldr     x2, [x0, #168]
    0.00 :   ffff8000100bfddc:       mul     x4, x2, x4
    0.00 :   ffff8000100bfde0:       str     x4, [x0, #144]
         : 3500             update_tg_cfs_load():
         : 3502             load_sum = (s64)se_weight(se) * runnable_sum;
    0.00 :   ffff8000100bfde4:       ldr     x2, [x1, #272]
         : 3508             se->avg.load_avg = load_avg;
    0.00 :   ffff8000100bfde8:       cmp     x2, #0x0
    0.00 :   ffff8000100bfdec:       b.eq    ffff8000100bfe94 <task_tick_fair+0x37c>  // b.none
         : 3511             cfs_rq->avg.load_sum = cfs_rq->avg.load_avg * divider;
    0.00 :   ffff8000100bfdf0:       str     xzr, [x1, #272]
         : 3513             get_pelt_divider():
    0.00 :   ffff8000100bfdf4:       mov     w3, #0xb67e                     // #46718
    0.00 :   ffff8000100bfdf8:       ldr     w5, [x0, #156]
    0.00 :   ffff8000100bfdfc:       add     w5, w5, w3
         : 45               update_tg_cfs_load():
         :
    0.00 :   ffff8000100bfe00:       b.lt    ffff8000100bff6c <task_tick_fair+0x454>  // b.tstop
         :
    0.00 :   ffff8000100bfe04:       ldr     x4, [x20, #200]
         : 3525             if (entity_is_task(se))
    0.00 :   ffff8000100bfe08:       mov     w1, w5
         :
    0.00 :   ffff8000100bfe0c:       add     x3, x2, x4
         : 3525             if (entity_is_task(se))
    0.00 :   ffff8000100bfe10:       cmp     x3, x1
    0.00 :   ffff8000100bfe14:       csel    x2, x3, x1, le
         : 3546             }
    0.00 :   ffff8000100bfe18:       ldr     w3, [x20, #216]
         : 3549             * Check if we need to update the load and the utilization of a blocked
    0.00 :   ffff8000100bfe1c:       ldr     x1, [x20]
         : 3546             }
    0.00 :   ffff8000100bfe20:       lsr     w3, w3, #10
         :
    0.00 :   ffff8000100bfe24:       cmp     x3, x2
    0.00 :   ffff8000100bfe28:       csel    x2, x3, x2, ge  // ge = tcont
         : 3550             se_weight():
         : 753              /*
    0.00 :   ffff8000100bfe2c:       cbz     x1, ffff8000100bff60 <task_tick_fair+0x448>
    0.00 :   ffff8000100bfe30:       lsr     x1, x1, #10
    0.00 :   ffff8000100bfe34:       mov     x3, #0x2                        // #2
    0.00 :   ffff8000100bfe38:       cmp     x1, x3
    0.00 :   ffff8000100bfe3c:       sxtw    x5, w5
    0.00 :   ffff8000100bfe40:       csel    x1, x1, x3, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfe44:       mul     x6, x1, x2
    0.00 :   ffff8000100bfe48:       msub    x4, x1, x4, x6
    0.00 :   ffff8000100bfe4c:       sdiv    x1, x6, x5
    0.00 :   ffff8000100bfe50:       lsr     x3, x4, #63
    0.00 :   ffff8000100bfe54:       and     w3, w3, #0xff
         : 765              update_tg_cfs_load():
         :
    0.00 :   ffff8000100bfe58:       str     x2, [x20, #200]
         : 3553             {
    0.00 :   ffff8000100bfe5c:       ldr     x5, [x20, #224]
         : 3556             /*
    0.00 :   ffff8000100bfe60:       str     x1, [x20, #224]
         : 3557             * If sched_entity still have not zero load or utilization, we have to
    0.00 :   ffff8000100bfe64:       ldr     x2, [x0, #160]
         : 3553             {
    0.00 :   ffff8000100bfe68:       subs    x1, x1, x5
         : 3557             * If sched_entity still have not zero load or utilization, we have to
    0.00 :   ffff8000100bfe6c:       add     x1, x1, x2
    0.00 :   ffff8000100bfe70:       ccmp    x2, x1, #0x2, mi  // mi = first
    0.00 :   ffff8000100bfe74:       csel    x1, x1, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfe78:       str     x1, [x0, #160]
         : 3558             * decay it:
    0.00 :   ffff8000100bfe7c:       cmp     w3, #0x0
    0.00 :   ffff8000100bfe80:       ldr     x2, [x0, #136]
    0.00 :   ffff8000100bfe84:       add     x1, x2, x4
    0.00 :   ffff8000100bfe88:       ccmp    x2, x1, #0x2, ne  // ne = any
    0.00 :   ffff8000100bfe8c:       csel    x1, x1, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bfe90:       str     x1, [x0, #136]
         : 3565             cfs_rq_util_change():
         :
    0.00 :   ffff8000100bfe94:       ldr     x1, [x19, #304]
         : 3280             atomic_long_add(delta, &cfs_rq->tg->load_avg);
    0.00 :   ffff8000100bfe98:       add     x0, x1, #0x80
    0.00 :   ffff8000100bfe9c:       cmp     x19, x0
    0.00 :   ffff8000100bfea0:       b.eq    ffff8000100bffa0 <task_tick_fair+0x488>  // b.none
         : 3284             update_tg_load_avg():
         :
    0.00 :   ffff8000100bfea4:       ldr     x1, [sp, #96]
    0.00 :   ffff8000100bfea8:       ldr     x0, [x19, #336]
    0.00 :   ffff8000100bfeac:       cmp     x0, x1
    0.00 :   ffff8000100bfeb0:       b.eq    ffff8000100bfbd4 <task_tick_fair+0xbc>  // b.none
         :
    0.00 :   ffff8000100bfeb4:       ldr     x1, [x19, #160]
    0.00 :   ffff8000100bfeb8:       ldr     x2, [x19, #256]
         : 3325             }
    0.00 :   ffff8000100bfebc:       subs    x1, x1, x2
    0.00 :   ffff8000100bfec0:       cneg    x3, x1, mi  // mi = first
    0.00 :   ffff8000100bfec4:       cmp     x3, x2, lsr #6
    0.00 :   ffff8000100bfec8:       b.ls    ffff8000100bfbd4 <task_tick_fair+0xbc>  // b.plast
         : 3326             #else
    0.00 :   ffff8000100bfecc:       add     x2, x0, #0x100
         : 3328             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000100bfed0:       b       ffff8000100c0154 <task_tick_fair+0x63c>
    0.00 :   ffff8000100bfed4:       b       ffff8000100c0154 <task_tick_fair+0x63c>
         : 46               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000100bfed8:       stadd   x1, [x2]
         : 186              update_tg_load_avg():
         : 3327             p_last_update_time = prev->avg.last_update_time;
    0.00 :   ffff8000100bfedc:       ldr     x0, [x19, #160]
    0.00 :   ffff8000100bfee0:       str     x0, [x19, #256]
         : 3330             entity_tick():
         : 4551             static_key_slow_inc_cpuslocked(&__cfs_bandwidth_used);
    0.00 :   ffff8000100bfee4:       mov     x0, x20
    0.00 :   ffff8000100bfee8:       bl      ffff8000100bcbb8 <update_cfs_group>
         : 4559             static bool cfs_bandwidth_used(void)
    0.00 :   ffff8000100bfeec:       ldr     x0, [x19, #304]
         : 4558             #else /* CONFIG_JUMP_LABEL */
    0.00 :   ffff8000100bfef0:       cbz     w21, ffff8000100bfbe4 <task_tick_fair+0xcc>
    0.00 :   ffff8000100bfef4:       nop
         : 4561             check_preempt_tick():
         :
    0.00 :   ffff8000100bfef8:       bl      ffff8000100b3b98 <resched_curr>
    0.00 :   ffff8000100bfefc:       b       ffff8000100bfc00 <task_tick_fair+0xe8>
         : 4389             * runqueue.
    0.00 :   ffff8000100bff00:       mov     x1, x20
    0.00 :   ffff8000100bff04:       mov     x0, x19
    0.00 :   ffff8000100bff08:       bl      ffff8000100bbe20 <sched_slice>
         : 4390             */
    0.00 :   ffff8000100bff0c:       ldr     x1, [x20, #72]
    0.00 :   ffff8000100bff10:       ldr     x2, [x20, #88]
    0.00 :   ffff8000100bff14:       sub     x1, x1, x2
         : 4391             update_stats_wait_end(cfs_rq, se);
    0.00 :   ffff8000100bff18:       cmp     x0, x1
    0.00 :   ffff8000100bff1c:       b.cc    ffff8000100c0120 <task_tick_fair+0x608>  // b.lo, b.ul, b.last
         : 4406             schedstat_set(se->statistics.slice_max,
    0.00 :   ffff8000100bff20:       adrp    x2, ffff800011c41000 <modprobe_path+0x48>
    0.00 :   ffff8000100bff24:       ldr     w2, [x2, #1740]
    0.00 :   ffff8000100bff28:       cmp     x1, x2
    0.00 :   ffff8000100bff2c:       b.cc    ffff8000100bfc00 <task_tick_fair+0xe8>  // b.lo, b.ul, b.last
         : 4411             __pick_first_entity():
         :
    0.00 :   ffff8000100bff30:       ldr     x1, [x19, #56]
         : 606              check_preempt_tick():
         :
    0.00 :   ffff8000100bff34:       ldr     x2, [x20, #80]
         : 4412             __pick_first_entity():
         : 609              /*
    0.00 :   ffff8000100bff38:       cmp     x1, #0x0
    0.00 :   ffff8000100bff3c:       sub     x3, x1, #0x10
    0.00 :   ffff8000100bff40:       csel    x1, x3, x1, ne  // ne = any
         : 613              check_preempt_tick():
         :
    0.00 :   ffff8000100bff44:       ldr     x1, [x1, #80]
         : 4415             wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se);
    0.00 :   ffff8000100bff48:       subs    x2, x2, x1
    0.00 :   ffff8000100bff4c:       ccmp    x0, x2, #0x2, pl  // pl = nfrst
    0.00 :   ffff8000100bff50:       b.cs    ffff8000100bfc00 <task_tick_fair+0xe8>  // b.hs, b.nlast
         :
    0.00 :   ffff8000100bff54:       ldr     x0, [x19, #304]
    0.00 :   ffff8000100bff58:       bl      ffff8000100b3b98 <resched_curr>
    0.00 :   ffff8000100bff5c:       b       ffff8000100bfc00 <task_tick_fair+0xe8>
         : 4420             se_weight():
    0.00 :   ffff8000100bff60:       mov     x4, #0x0                        // #0
    0.00 :   ffff8000100bff64:       mov     w3, #0x0                        // #0
    0.00 :   ffff8000100bff68:       b       ffff8000100bfe58 <task_tick_fair+0x340>
         : 756              update_tg_cfs_load():
         :
    0.00 :   ffff8000100bff6c:       ldr     x2, [x1]
    0.00 :   ffff8000100bff70:       cbz     x2, ffff8000100bff90 <task_tick_fair+0x478>
    0.00 :   ffff8000100bff74:       lsr     x2, x2, #10
    0.00 :   ffff8000100bff78:       mov     x3, #0x2                        // #2
    0.00 :   ffff8000100bff7c:       cmp     x2, x3
    0.00 :   ffff8000100bff80:       csel    x2, x2, x3, cs  // cs = hs, nlast
         : 3538             div_s64_rem():
         : 42               * Return: sets ``*remainder``, then returns dividend / divisor
         : 43               */
         : 44               static inline s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)
         : 45               {
         : 46               *remainder = dividend % divisor;
         : 47               return dividend / divisor;
    0.00 :   ffff8000100bff84:       ldr     x1, [x1, #136]
         : 41               *remainder = dividend % divisor;
    0.00 :   ffff8000100bff88:       sxtw    x2, w2
         : 42               return dividend / divisor;
    0.00 :   ffff8000100bff8c:       sdiv    x2, x1, x2
         : 44               update_tg_cfs_load():
         :
    0.00 :   ffff8000100bff90:       ldr     x4, [x20, #200]
    0.00 :   ffff8000100bff94:       cmp     x4, x2
    0.00 :   ffff8000100bff98:       csel    x2, x4, x2, ls  // ls = plast
    0.00 :   ffff8000100bff9c:       b       ffff8000100bfe18 <task_tick_fair+0x300>
         : 3542             cpufreq_update_util():
         : 2509             return 1;
    0.00 :   ffff8000100bffa0:       ldp     x3, x0, [sp, #104]
    0.00 :   ffff8000100bffa4:       ldrsw   x2, [x1, #2576]
    0.00 :   ffff8000100bffa8:       ldr     x2, [x3, x2, lsl #3]
    0.00 :   ffff8000100bffac:       ldr     x0, [x0, x2]
         : 2511             }
         :
    0.00 :   ffff8000100bffb0:       cbz     x0, ffff8000100bfea4 <task_tick_fair+0x38c>
         : 2512             #else
    0.00 :   ffff8000100bffb4:       ldr     x3, [x0]
    0.00 :   ffff8000100bffb8:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100bffbc:       ldr     x1, [x1, #2400]
    0.00 :   ffff8000100bffc0:       blr     x3
    0.00 :   ffff8000100bffc4:       b       ffff8000100bfea4 <task_tick_fair+0x38c>
         : 2518             task_tick_numa():
         : 2921             */
    0.00 :   ffff8000100bffc8:       ldr     w0, [x23, #36]
    0.00 :   ffff8000100bffcc:       and     w0, w0, #0x3ffffc
    0.00 :   ffff8000100bffd0:       and     w0, w0, #0xffe00007
    0.00 :   ffff8000100bffd4:       cbnz    w0, ffff8000100bfc18 <task_tick_fair+0x100>
    0.00 :   ffff8000100bffd8:       ldr     x0, [x23, #2232]
         : 2915             */
    0.00 :   ffff8000100bffdc:       add     x19, x23, #0x8b8
         : 2921             */
    0.00 :   ffff8000100bffe0:       cmp     x19, x0
    0.00 :   ffff8000100bffe4:       b.ne    ffff8000100bfc18 <task_tick_fair+0x100>  // b.any
         : 2933             {
    0.00 :   ffff8000100bffe8:       ldr     w20, [x23, #2184]
    0.00 :   ffff8000100bffec:       mov     w2, #0x4240                     // #16960
    0.00 :   ffff8000100bfff0:       ldr     x0, [x23, #2208]
    0.00 :   ffff8000100bfff4:       movk    w2, #0xf, lsl #16
    0.00 :   ffff8000100bfff8:       ldr     x1, [x23, #200]
    0.00 :   ffff8000100bfffc:       umaddl  x20, w20, w2, x0
    0.00 :   ffff8000100c0000:       cmp     x1, x20
    0.00 :   ffff8000100c0004:       b.ls    ffff8000100bfc18 <task_tick_fair+0x100>  // b.plast
         : 2934             }
    0.00 :   ffff8000100c0008:       cbz     x0, ffff8000100c0194 <task_tick_fair+0x67c>
         : 2938             }
    0.00 :   ffff8000100c000c:       ldr     x0, [x23, #912]
    0.00 :   ffff8000100c0010:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
         : 2936             static inline void account_numa_enqueue(struct rq *rq, struct task_struct *p)
    0.00 :   ffff8000100c0014:       str     x20, [x23, #2208]
         : 2938             }
    0.00 :   ffff8000100c0018:       ldr     x1, [x1, #2432]
    0.00 :   ffff8000100c001c:       ldr     x0, [x0, #848]
    0.00 :   ffff8000100c0020:       cmp     x1, x0
    0.00 :   ffff8000100c0024:       b.mi    ffff8000100bfc18 <task_tick_fair+0x100>  // b.first
         :
    0.00 :   ffff8000100c0028:       mov     x1, x19
    0.00 :   ffff8000100c002c:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000100c0030:       mov     x0, x23
    0.00 :   ffff8000100c0034:       bl      ffff8000100a5b80 <task_work_add>
    0.00 :   ffff8000100c0038:       b       ffff8000100bfc18 <task_tick_fair+0x100>
         : 2945             update_misfit_status():
         : 4069             static inline void
    0.00 :   ffff8000100c003c:       cbz     x23, ffff8000100c0140 <task_tick_fair+0x628>
    0.00 :   ffff8000100c0040:       ldr     w0, [x23, #676]
    0.00 :   ffff8000100c0044:       cmp     w0, #0x1
    0.00 :   ffff8000100c0048:       b.eq    ffff8000100c0140 <task_tick_fair+0x628>  // b.none
         : 4074             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c004c:       ldr     x8, [sp, #120]
    0.00 :   ffff8000100c0050:       adrp    x6, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c0054:       ldr     x4, [sp, #104]
    0.00 :   ffff8000100c0058:       add     x6, x6, #0xc40
    0.00 :   ffff8000100c005c:       ldrsw   x1, [x8, #2576]
    0.00 :   ffff8000100c0060:       mov     x2, x6
         : 5771             task_util():
         :
    0.00 :   ffff8000100c0064:       ldr     x3, [x23, #368]
         : 3900             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100c0068:       ldr     x0, [x23, #376]
         : 3905             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c006c:       ldr     x1, [x4, x1, lsl #3]
         : 5766             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100c0070:       lsr     x4, x0, #32
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100c0074:       cmp     w0, w4
         : 3907             capacity_of():
         : 5764             unsigned int slave = p->wakee_flips;
    0.00 :   ffff8000100c0078:       add     x1, x1, x2
         : 5766             _task_util_est():
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100c007c:       csel    w0, w0, w4, hi  // hi = pmore
    0.00 :   ffff8000100c0080:       orr     w0, w0, #0x1
         : 3908             task_util_est():
         : 3910             /* Update root cfs_rq's estimated utilization */
    0.00 :   ffff8000100c0084:       cmp     x0, x3
         : 3912             update_misfit_status():
         :
    0.00 :   ffff8000100c0088:       ldr     x1, [x1, #2480]
         : 4076             task_util_est():
         : 3910             /* Update root cfs_rq's estimated utilization */
    0.00 :   ffff8000100c008c:       csel    x0, x0, x3, cs  // cs = hs, nlast
         : 3912             task_fits_capacity():
         : 4061             static inline void
    0.00 :   ffff8000100c0090:       add     x0, x0, x0, lsl #2
    0.00 :   ffff8000100c0094:       lsl     x1, x1, #10
         : 4064             update_misfit_status():
         :
    0.00 :   ffff8000100c0098:       cmp     x1, x0, lsl #8
    0.00 :   ffff8000100c009c:       b.ls    ffff8000100c0160 <task_tick_fair+0x648>  // b.plast
         : 4070             util_est_enqueue(struct cfs_rq *cfs_rq, struct task_struct *p) {}
    0.00 :   ffff8000100c00a0:       ldr     x0, [sp, #120]
    0.00 :   ffff8000100c00a4:       str     xzr, [x0, #2512]
         :
    0.00 :   ffff8000100c00a8:       b       ffff8000100bfc24 <task_tick_fair+0x10c>
         : 4073             cpu_util():
         :
    0.00 :   ffff8000100c00ac:       ldrsw   x1, [x1, #2576]
    0.00 :   ffff8000100c00b0:       ldr     x3, [sp, #104]
    0.00 :   ffff8000100c00b4:       ldr     x1, [x3, x1, lsl #3]
    0.00 :   ffff8000100c00b8:       add     x0, x0, x1
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100c00bc:       add     x0, x0, #0x80
    0.00 :   ffff8000100c00c0:       ldr     x3, [x0, #176]
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c00c4:       ldr     w0, [x0, #184]
    0.00 :   ffff8000100c00c8:       str     w0, [sp, #140]
         : 6418             cfs_rq = &cpu_rq(cpu)->cfs;
    0.00 :   ffff8000100c00cc:       mov     w0, w3
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c00d0:       ldr     w4, [sp, #140]
    0.00 :   ffff8000100c00d4:       cmp     w3, w4
    0.00 :   ffff8000100c00d8:       b.ls    ffff8000100c0138 <task_tick_fair+0x620>  // b.plast
         : 6425             capacity_orig_of():
         : 2604             if (__rq_lockp(rq1) != __rq_lockp(rq2))
         : 2605             raw_spin_rq_unlock(rq2);
         : 2606             else
         : 2607             __release(rq2->lock);
         : 2608             raw_spin_rq_unlock(rq1);
         : 2609             }
    0.00 :   ffff8000100c00dc:       add     x6, x1, x6
         : 2611             cpu_util():
         :
    0.00 :   ffff8000100c00e0:       mov     w3, w0
    0.00 :   ffff8000100c00e4:       ldr     x0, [x6, #2488]
         : 6426             cpu_overutilized():
         :
    0.00 :   ffff8000100c00e8:       ldr     x1, [x6, #2480]
         : 5480             cpu_util():
         :
    0.00 :   ffff8000100c00ec:       cmp     x0, x3
    0.00 :   ffff8000100c00f0:       csel    x0, x0, x3, ls  // ls = plast
         : 6426             cpu_overutilized():
         :
    0.00 :   ffff8000100c00f4:       add     x0, x0, x0, lsl #2
    0.00 :   ffff8000100c00f8:       lsl     x1, x1, #10
         : 5481             update_overutilized_status():
         : 5483             * estimated utilization, before we update schedutil.
    0.00 :   ffff8000100c00fc:       cmp     x1, x0, lsl #8
    0.00 :   ffff8000100c0100:       b.hi    ffff8000100bfc44 <task_tick_fair+0x12c>  // b.pmore
         : 5484             */
    0.00 :   ffff8000100c0104:       mov     w0, #0x2                        // #2
    0.00 :   ffff8000100c0108:       str     w0, [x2, #92]
         : 5487             task_tick_fair():
         : 10781            }
    0.00 :   ffff8000100c010c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c0110:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c0114:       ldp     x29, x30, [sp], #144
    0.00 :   ffff8000100c0118:       autiasp
    0.00 :   ffff8000100c011c:       ret
         : 10787            check_preempt_tick():
         : 4392             __dequeue_entity(cfs_rq, se);
    0.00 :   ffff8000100c0120:       ldr     x0, [x19, #304]
    0.00 :   ffff8000100c0124:       bl      ffff8000100b3b98 <resched_curr>
         : 4397             cfs_rq->curr = se;
    0.00 :   ffff8000100c0128:       mov     x1, x20
    0.00 :   ffff8000100c012c:       mov     x0, x19
    0.00 :   ffff8000100c0130:       bl      ffff8000100bc140 <clear_buddies>
         :
    0.00 :   ffff8000100c0134:       b       ffff8000100bfc00 <task_tick_fair+0xe8>
         : 4400             cpu_util():
         : 6421             /* Discount task's util from CPU's util */
    0.00 :   ffff8000100c0138:       ldr     w0, [sp, #140]
    0.00 :   ffff8000100c013c:       b       ffff8000100c00dc <task_tick_fair+0x5c4>
         : 6424             update_misfit_status():
         : 4070             util_est_enqueue(struct cfs_rq *cfs_rq, struct task_struct *p) {}
    0.00 :   ffff8000100c0140:       ldr     x0, [sp, #120]
    0.00 :   ffff8000100c0144:       adrp    x6, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c0148:       add     x6, x6, #0xc40
    0.00 :   ffff8000100c014c:       str     xzr, [x0, #2512]
         :
    0.00 :   ffff8000100c0150:       b       ffff8000100bfc24 <task_tick_fair+0x10c>
         : 4073             __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000100c0154:       add     x0, x0, #0x100
    0.00 :   ffff8000100c0158:       b       ffff8000100c81c4 <sched_group_set_shares+0x62c>
    0.00 :   ffff8000100c015c:       b       ffff8000100bfedc <task_tick_fair+0x3c4>
         : 219              task_cfs_rq():
         : 283              else if (cfs_rq && cfs_rq->tg->css.cgroup)
    0.00 :   ffff8000100c0160:       ldr     x7, [x23, #248]
         : 285              task_h_load():
         : 8092             if (cfs_rq->last_h_load_update == now)
    0.00 :   ffff8000100c0164:       mov     x0, x7
    0.00 :   ffff8000100c0168:       bl      ffff8000100bba60 <update_cfs_rq_h_load>
         : 8093             break;
    0.00 :   ffff8000100c016c:       ldr     x2, [x7, #280]
    0.00 :   ffff8000100c0170:       ldr     x0, [x23, #352]
    0.00 :   ffff8000100c0174:       ldr     x1, [x7, #160]
    0.00 :   ffff8000100c0178:       mul     x0, x0, x2
    0.00 :   ffff8000100c017c:       add     x1, x1, #0x1
         : 8099             div64_u64():
         : 68               *
         : 69               * Return: dividend / divisor
         : 70               */
         : 71               static inline u64 div64_u64(u64 dividend, u64 divisor)
         : 72               {
         : 73               return dividend / divisor;
    0.00 :   ffff8000100c0180:       udiv    x0, x0, x1
         : 75               update_misfit_status():
         : 4083             {
    0.00 :   ffff8000100c0184:       cmp     x0, #0x0
    0.00 :   ffff8000100c0188:       csinc   x0, x0, xzr, ne  // ne = any
    0.00 :   ffff8000100c018c:       str     x0, [x8, #2512]
    0.00 :   ffff8000100c0190:       b       ffff8000100bfc24 <task_tick_fair+0x10c>
         : 4088             task_tick_numa():
         :
    0.00 :   ffff8000100c0194:       mov     x0, x23
    0.00 :   ffff8000100c0198:       bl      ffff8000100bd7f8 <task_scan_start>
    0.00 :   ffff8000100c019c:       ldr     x1, [x23, #2208]
    0.00 :   ffff8000100c01a0:       str     w0, [x23, #2184]
    0.00 :   ffff8000100c01a4:       add     x20, x20, x1
    0.00 :   ffff8000100c01a8:       b       ffff8000100c000c <task_tick_fair+0x4f4>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bbf38 <remove_entity_load_avg>:
         : 6                remove_entity_load_avg():
         :
         : 3865             static inline unsigned long _task_util_est(struct task_struct *p)
         : 3866             {
         : 3867             struct util_est ue = READ_ONCE(p->se.avg.util_est);
         :
         : 3869             return max(ue.ewma, (ue.enqueued & ~UTIL_AVG_UNCHANGED));
    0.00 :   ffff8000100bbf38:       paciasp
    0.00 :   ffff8000100bbf3c:       stp     x29, x30, [sp, #-48]!
         : 3872             sync_entity_load_avg():
         : 3856             {
    0.00 :   ffff8000100bbf40:       mov     x1, x0
         : 3858             remove_entity_load_avg():
         : 3864             return max(ue.ewma, (ue.enqueued & ~UTIL_AVG_UNCHANGED));
    0.00 :   ffff8000100bbf44:       mov     x29, sp
    0.00 :   ffff8000100bbf48:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bbf4c:       mov     x20, x0
    0.00 :   ffff8000100bbf50:       str     x21, [sp, #32]
         : 3865             }
    0.00 :   ffff8000100bbf54:       ldr     x19, [x0, #120]
         :
         : 3877             #ifdef CONFIG_UCLAMP_TASK
         : 3878             static inline unsigned long uclamp_task_util(struct task_struct *p)
         : 3879             {
         : 3880             return clamp(task_util_est(p),
         : 3881             uclamp_eff_value(p, UCLAMP_MIN),
    0.00 :   ffff8000100bbf58:       add     x21, x19, #0xc0
         : 3883             sync_entity_load_avg():
         : 3856             {
    0.00 :   ffff8000100bbf5c:       ldr     x0, [x19, #128]
    0.00 :   ffff8000100bbf60:       bl      ffff8000100d4d30 <__update_load_avg_blocked_se>
         : 3859             remove_entity_load_avg():
         : 3876             uclamp_eff_value(p, UCLAMP_MIN),
    0.00 :   ffff8000100bbf64:       mov     x0, x21
    0.00 :   ffff8000100bbf68:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 3877             uclamp_eff_value(p, UCLAMP_MAX));
  100.00 :   ffff8000100bbf6c:       ldr     w2, [x19, #196]
         : 3881             }
         : 3882             #else
         : 3883             static inline unsigned long uclamp_task_util(struct task_struct *p)
         : 3884             {
    0.00 :   ffff8000100bbf70:       mov     x1, x0
         : 3878             }
    0.00 :   ffff8000100bbf74:       ldp     x3, x4, [x19, #200]
         : 3877             uclamp_eff_value(p, UCLAMP_MAX));
    0.00 :   ffff8000100bbf78:       add     w2, w2, #0x1
    0.00 :   ffff8000100bbf7c:       str     w2, [x19, #196]
         : 3881             {
    0.00 :   ffff8000100bbf80:       mov     x0, x21
         : 3880             static inline unsigned long uclamp_task_util(struct task_struct *p)
    0.00 :   ffff8000100bbf84:       ldr     x2, [x19, #216]
         : 3878             }
    0.00 :   ffff8000100bbf88:       ldr     x5, [x20, #240]
    0.00 :   ffff8000100bbf8c:       add     x4, x4, x5
    0.00 :   ffff8000100bbf90:       str     x4, [x19, #208]
         : 3879             #else
    0.00 :   ffff8000100bbf94:       ldr     x4, [x20, #224]
    0.00 :   ffff8000100bbf98:       add     x3, x3, x4
    0.00 :   ffff8000100bbf9c:       str     x3, [x19, #200]
         : 3880             static inline unsigned long uclamp_task_util(struct task_struct *p)
    0.00 :   ffff8000100bbfa0:       ldr     x3, [x20, #232]
    0.00 :   ffff8000100bbfa4:       add     x2, x2, x3
    0.00 :   ffff8000100bbfa8:       str     x2, [x19, #216]
         : 3881             {
    0.00 :   ffff8000100bbfac:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 3882             return task_util_est(p);
    0.00 :   ffff8000100bbfb0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bbfb4:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100bbfb8:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100bbfbc:       autiasp
    0.00 :   ffff8000100bbfc0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c72f0 <trigger_load_balance>:
         : 6                on_null_domain():
         : 10100            }
         : 10101            if (need_serialize)
         : 10102            spin_unlock(&balancing);
         : 10103            out:
         : 10104            if (time_after(next_balance, sd->last_balance + interval)) {
         : 10105            next_balance = sd->last_balance + interval;
    0.00 :   ffff8000100c72f0:       ldr     x1, [x0, #2472]
         : 10107            trigger_load_balance():
         : 10732            rq_repin_lock(this_rq, rf);
         :
         : 10734            return pulled_task;
         : 10735            }
         :
         : 10737            /*
    0.00 :   ffff8000100c72f4:       cbz     x1, ffff8000100c73a0 <trigger_load_balance+0xb0>
         : 10727            rq_repin_lock(this_rq, rf);
    0.00 :   ffff8000100c72f8:       paciasp
    0.00 :   ffff8000100c72fc:       stp     x29, x30, [sp, #-112]!
         : 10730            test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100c7300:       adrp    x2, ffff800011c29000 <page_wait_table+0x14c0>
         : 113              trigger_load_balance():
    0.00 :   ffff8000100c7304:       mov     x29, sp
    0.00 :   ffff8000100c7308:       stp     x21, x22, [sp, #32]
         : 10729            test_bit():
    0.00 :   ffff8000100c730c:       add     x2, x2, #0xa70
         : 107              trigger_load_balance():
         : 10732            /*
    0.00 :   ffff8000100c7310:       ldr     w21, [x0, #2576]
         : 10734            test_bit():
    0.00 :   ffff8000100c7314:       cmp     w21, #0x0
    0.00 :   ffff8000100c7318:       add     w1, w21, #0x3f
    0.00 :   ffff8000100c731c:       csel    w1, w1, w21, lt  // lt = tstop
    0.00 :   ffff8000100c7320:       asr     w1, w1, #6
    0.00 :   ffff8000100c7324:       sxtw    x1, w1
    0.00 :   ffff8000100c7328:       ldr     x1, [x2, x1, lsl #3]
    0.00 :   ffff8000100c732c:       lsr     x1, x1, x21
         : 113              trigger_load_balance():
    0.00 :   ffff8000100c7330:       tbz     w1, #0, ffff8000100c7380 <trigger_load_balance+0x90>
         : 10735            * run_rebalance_domains is triggered when needed from the scheduler tick.
         : 10736            * Also triggered for nohz idle balancing (with nohz_balancing_kick set).
         : 10737            */
    0.00 :   ffff8000100c7334:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c7338:       adrp    x24, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000100c733c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c7340:       mov     x20, x0
    0.00 :   ffff8000100c7344:       ldr     x1, [x24, #2432]
    0.00 :   ffff8000100c7348:       ldr     x0, [x0, #2376]
    0.00 :   ffff8000100c734c:       cmp     x1, x0
    0.00 :   ffff8000100c7350:       b.pl    ffff8000100c7390 <trigger_load_balance+0xa0>  // b.nfrst
         : 10746            nohz_balancer_kick():
         :
    0.00 :   ffff8000100c7354:       ldr     x22, [x24, #2432]
         : 10178            * the first flag owns it; cleared by nohz_csd_func().
    0.00 :   ffff8000100c7358:       ldrb    w0, [x20, #2505]
    0.00 :   ffff8000100c735c:       cbnz    w0, ffff8000100c7378 <trigger_load_balance+0x88>
         : 10181            nohz_balance_exit_idle():
         : 10301            rcu_read_unlock();
    0.00 :   ffff8000100c7360:       ldr     w0, [x20, #96]
    0.00 :   ffff8000100c7364:       cbnz    w0, ffff8000100c73a4 <trigger_load_balance+0xb4>
         : 10304            atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff8000100c7368:       adrp    x19, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100c736c:       add     x19, x19, #0x7c0
    0.00 :   ffff8000100c7370:       ldr     w1, [x19, #96]
         : 37               nohz_balancer_kick():
         :
    0.00 :   ffff8000100c7374:       cbnz    w1, ffff8000100c73b0 <trigger_load_balance+0xc0>
    0.00 :   ffff8000100c7378:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c737c:       ldp     x23, x24, [sp, #48]
         : 10195            trigger_load_balance():
         : 10739            static __latent_entropy void run_rebalance_domains(struct softirq_action *h)
         : 10740            {
         : 10741            struct rq *this_rq = this_rq();
         : 10742            enum cpu_idle_type idle = this_rq->idle_balance ?
    0.00 :   ffff8000100c7380:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c7384:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000100c7388:       autiasp
    0.00 :   ffff8000100c738c:       ret
         : 10736            static __latent_entropy void run_rebalance_domains(struct softirq_action *h)
    0.00 :   ffff8000100c7390:       mov     w0, #0x7                        // #7
    0.00 :   ffff8000100c7394:       bl      ffff800010089418 <raise_softirq>
    0.00 :   ffff8000100c7398:       ldr     w21, [x20, #2576]
    0.00 :   ffff8000100c739c:       b       ffff8000100c7354 <trigger_load_balance+0x64>
    0.00 :   ffff8000100c73a0:       ret
         : 10742            nohz_balance_exit_idle():
    0.00 :   ffff8000100c73a4:       mov     x0, x20
    0.00 :   ffff8000100c73a8:       bl      ffff8000100bf200 <nohz_balance_exit_idle.part.128>
    0.00 :   ffff8000100c73ac:       b       ffff8000100c7368 <trigger_load_balance+0x78>
         : 10739            nohz_balancer_kick():
         : 10194            * of idle CPUs in the system.
  100.00 :   ffff8000100c73b0:       ldr     w2, [x19, #100]
    0.00 :   ffff8000100c73b4:       ldr     x1, [x19, #104]
    0.00 :   ffff8000100c73b8:       sub     x1, x22, x1
    0.00 :   ffff8000100c73bc:       cbz     w2, ffff8000100c73dc <trigger_load_balance+0xec>
         : 10195            */
    0.00 :   ffff8000100c73c0:       ldr     x0, [x19, #112]
    0.00 :   ffff8000100c73c4:       cmp     x0, x22
    0.00 :   ffff8000100c73c8:       b.pl    ffff8000100c73dc <trigger_load_balance+0xec>  // b.nfrst
         : 10198            unsigned long now = jiffies;
    0.00 :   ffff8000100c73cc:       tbnz    x1, #63, ffff8000100c765c <trigger_load_balance+0x36c>
         : 10196            static void nohz_balancer_kick(struct rq *rq)
    0.00 :   ffff8000100c73d0:       mov     w0, #0x2                        // #2
    0.00 :   ffff8000100c73d4:       str     w0, [sp, #100]
    0.00 :   ffff8000100c73d8:       b       ffff8000100c73e4 <trigger_load_balance+0xf4>
         : 10198            unsigned long now = jiffies;
    0.00 :   ffff8000100c73dc:       tbnz    x1, #63, ffff8000100c7378 <trigger_load_balance+0x88>
    0.00 :   ffff8000100c73e0:       str     wzr, [sp, #100]
         : 10201            int nr_busy, i, cpu = rq->cpu;
    0.00 :   ffff8000100c73e4:       ldr     w0, [x20, #4]
    0.00 :   ffff8000100c73e8:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c73ec:       add     x22, x22, #0xc30
    0.00 :   ffff8000100c73f0:       cmp     w0, #0x1
    0.00 :   ffff8000100c73f4:       b.ls    ffff8000100c74d8 <trigger_load_balance+0x1e8>  // b.plast
         : 10207            kick_ilb():
         : 10143            for_each_cpu_and(ilb, nohz.idle_cpus_mask,
    0.00 :   ffff8000100c73f8:       ldr     x0, [x24, #2432]
    0.00 :   ffff8000100c73fc:       mov     w1, #0x3                        // #3
    0.00 :   ffff8000100c7400:       str     w1, [sp, #100]
    0.00 :   ffff8000100c7404:       add     x0, x0, #0x1
    0.00 :   ffff8000100c7408:       str     x0, [x19, #104]
         : 10149            find_new_ilb():
         : 10120            rq->next_balance = next_balance;
    0.00 :   ffff8000100c740c:       adrp    x21, ffff80001176d000 <cpu_number>
         : 10117            * updated.
    0.00 :   ffff8000100c7410:       add     x19, x19, #0x40
         : 10120            rq->next_balance = next_balance;
    0.00 :   ffff8000100c7414:       add     x21, x21, #0x0
         : 10122            nohz_balancer_kick():
         : 10196            static void nohz_balancer_kick(struct rq *rq)
    0.00 :   ffff8000100c7418:       mov     w20, #0xffffffff                // #-1
    0.00 :   ffff8000100c741c:       nop
         : 10199            find_new_ilb():
         : 10117            * updated.
    0.00 :   ffff8000100c7420:       mov     w0, #0x4                        // #4
    0.00 :   ffff8000100c7424:       bl      ffff8000100d8b38 <housekeeping_cpumask>
    0.00 :   ffff8000100c7428:       mov     x1, x19
    0.00 :   ffff8000100c742c:       mov     x2, x0
    0.00 :   ffff8000100c7430:       mov     w0, w20
    0.00 :   ffff8000100c7434:       bl      ffff8000104a75d0 <cpumask_next_and>
    0.00 :   ffff8000100c7438:       ldr     w2, [x22]
    0.00 :   ffff8000100c743c:       mov     w20, w0
         : 10120            rq->next_balance = next_balance;
    0.00 :   ffff8000100c7440:       mov     x1, x21
         : 10117            * updated.
    0.00 :   ffff8000100c7444:       cmp     w0, w2
    0.00 :   ffff8000100c7448:       b.cs    ffff8000100c7378 <trigger_load_balance+0x88>  // b.hs, b.nlast
         : 10120            __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100c744c:       mrs     x2, tpidr_el1
         : 46               find_new_ilb():
         : 10120            rq->next_balance = next_balance;
    0.00 :   ffff8000100c7450:       ldr     w1, [x1, x2]
    0.00 :   ffff8000100c7454:       cmp     w1, w20
    0.00 :   ffff8000100c7458:       b.eq    ffff8000100c7420 <trigger_load_balance+0x130>  // b.none
         :
    0.00 :   ffff8000100c745c:       bl      ffff8000100b75b8 <idle_cpu>
    0.00 :   ffff8000100c7460:       cbz     w0, ffff8000100c7420 <trigger_load_balance+0x130>
         : 10126            kick_ilb():
         : 10147            continue;
    0.00 :   ffff8000100c7464:       ldr     w0, [x22]
    0.00 :   ffff8000100c7468:       cmp     w20, w0
    0.00 :   ffff8000100c746c:       b.cs    ffff8000100c7378 <trigger_load_balance+0x88>  // b.hs, b.nlast
         : 10154            }
    0.00 :   ffff8000100c7470:       sxtw    x3, w20
    0.00 :   ffff8000100c7474:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c7478:       adrp    x25, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c747c:       add     x25, x25, #0x760
    0.00 :   ffff8000100c7480:       adrp    x2, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c7484:       add     x2, x2, #0xc40
    0.00 :   ffff8000100c7488:       mov     x1, x2
    0.00 :   ffff8000100c748c:       ldr     x0, [x25, x3, lsl #3]
    0.00 :   ffff8000100c7490:       add     x1, x1, x0
         : 10164            arch_atomic_fetch_or():
         : 47               ATOMIC_FETCH_OP(_acquire, op)                                   \
         : 48               ATOMIC_FETCH_OP(_release, op)                                   \
         : 49               ATOMIC_FETCH_OP(        , op)
         :
         : 51               ATOMIC_FETCH_OPS(atomic_fetch_andnot)
         : 52               ATOMIC_FETCH_OPS(atomic_fetch_or)
    0.00 :   ffff8000100c7494:       bl      ffff8000100bb810 <system_uses_lse_atomics>
         : 54               kick_ilb():
    0.00 :   ffff8000100c7498:       add     x4, x1, #0x64
         : 10155            arch_atomic_fetch_or():
    0.00 :   ffff8000100c749c:       tst     w0, #0xff
    0.00 :   ffff8000100c74a0:       b.eq    ffff8000100c7600 <trigger_load_balance+0x310>  // b.none
         : 49               __lse_atomic_fetch_or():
         : 50               ATOMIC_FETCH_OP(_acquire,  a, op, asm_op, "memory")             \
         : 51               ATOMIC_FETCH_OP(_release,  l, op, asm_op, "memory")             \
         : 52               ATOMIC_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 54               ATOMIC_FETCH_OPS(andnot, ldclr)
         : 55               ATOMIC_FETCH_OPS(or, ldset)
    0.00 :   ffff8000100c74a4:       ldr     w23, [sp, #100]
    0.00 :   ffff8000100c74a8:       ldsetal w23, w23, [x4]
         : 58               kick_ilb():
         :
    0.00 :   ffff8000100c74ac:       tst     x23, #0x3
    0.00 :   ffff8000100c74b0:       b.ne    ffff8000100c75f0 <trigger_load_balance+0x300>  // b.any
         :
    0.00 :   ffff8000100c74b4:       ldr     x0, [x25, x3, lsl #3]
    0.00 :   ffff8000100c74b8:       add     x2, x2, x0
    0.00 :   ffff8000100c74bc:       mov     w0, w20
    0.00 :   ffff8000100c74c0:       add     x1, x2, #0x40
    0.00 :   ffff8000100c74c4:       bl      ffff800010128558 <smp_call_function_single_async>
    0.00 :   ffff8000100c74c8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c74cc:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c74d0:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c74d4:       b       ffff8000100c7380 <trigger_load_balance+0x90>
         : 10173            rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100c74d8:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              nohz_balancer_kick():
         : 10208            * We may be recently in ticked or tickless idle mode. At the first
    0.00 :   ffff8000100c74dc:       ldr     x0, [x20, #2472]
         : 10209            * busy tick after returning from idle, we will update the busy stats.
    0.00 :   ffff8000100c74e0:       cbz     x0, ffff8000100c750c <trigger_load_balance+0x21c>
         : 10215            * balancing.
    0.00 :   ffff8000100c74e4:       ldr     w1, [x20, #148]
    0.00 :   ffff8000100c74e8:       cbz     w1, ffff8000100c750c <trigger_load_balance+0x21c>
         : 10218            check_cpu_capacity():
         : 8307             struct sched_group_capacity *sgc = group->sgc;
    0.00 :   ffff8000100c74ec:       ldr     x2, [x20, #2488]
         : 8306             do {
    0.00 :   ffff8000100c74f0:       ldr     w0, [x0, #44]
    0.00 :   ffff8000100c74f4:       ldr     x3, [x20, #2480]
         : 8307             struct sched_group_capacity *sgc = group->sgc;
    0.00 :   ffff8000100c74f8:       add     x1, x2, x2, lsl #1
    0.00 :   ffff8000100c74fc:       add     x1, x2, x1, lsl #3
         : 8306             do {
    0.00 :   ffff8000100c7500:       mul     x0, x0, x3
         : 8308             nohz_balancer_kick():
         : 10215            * balancing.
    0.00 :   ffff8000100c7504:       cmp     x0, x1, lsl #2
    0.00 :   ffff8000100c7508:       b.cc    ffff8000100c75e8 <trigger_load_balance+0x2f8>  // b.lo, b.ul, b.last
         : 10221            time_after(now, READ_ONCE(nohz.next_blocked)))
    0.00 :   ffff8000100c750c:       sxtw    x1, w21
    0.00 :   ffff8000100c7510:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c7514:       adrp    x25, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c7518:       add     x25, x25, #0x760
    0.00 :   ffff8000100c751c:       str     x1, [sp, #104]
    0.00 :   ffff8000100c7520:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100c7524:       add     x0, x0, #0x8a0
    0.00 :   ffff8000100c7528:       ldr     x1, [x25, x1, lsl #3]
    0.00 :   ffff8000100c752c:       ldr     x26, [x0, x1]
         : 10222            flags = NOHZ_STATS_KICK;
    0.00 :   ffff8000100c7530:       cbz     x26, ffff8000100c7594 <trigger_load_balance+0x2a4>
    0.00 :   ffff8000100c7534:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c7538:       add     x26, x26, #0x88
    0.00 :   ffff8000100c753c:       add     x22, x22, #0xc30
    0.00 :   ffff8000100c7540:       stp     x27, x28, [sp, #80]
         : 10228            flags = NOHZ_KICK_MASK;
    0.00 :   ffff8000100c7544:       add     x27, x19, #0x40
    0.00 :   ffff8000100c7548:       mov     w28, #0xffffffff                // #-1
    0.00 :   ffff8000100c754c:       b       ffff8000100c7568 <trigger_load_balance+0x278>
         : 10232            sched_asym_prefer():
         : 759              * XXX we want to get rid of these helpers and use the full load resolution.
         : 760              */
         : 761              static inline long se_weight(struct sched_entity *se)
         : 762              {
         : 763              return scale_load_down(se->load.weight);
         : 764              }
    0.00 :   ffff8000100c7550:       bl      ffff8000100c35e8 <arch_asym_cpu_priority>
    0.00 :   ffff8000100c7554:       mov     w23, w0
    0.00 :   ffff8000100c7558:       mov     w0, w21
    0.00 :   ffff8000100c755c:       bl      ffff8000100c35e8 <arch_asym_cpu_priority>
         : 769              nohz_balancer_kick():
         : 10229            goto out;
    0.00 :   ffff8000100c7560:       cmp     w23, w0
    0.00 :   ffff8000100c7564:       b.gt    ffff8000100c764c <trigger_load_balance+0x35c>
         : 10228            flags = NOHZ_KICK_MASK;
    0.00 :   ffff8000100c7568:       mov     w0, w28
    0.00 :   ffff8000100c756c:       mov     x2, x27
    0.00 :   ffff8000100c7570:       mov     x1, x26
    0.00 :   ffff8000100c7574:       bl      ffff8000104a75d0 <cpumask_next_and>
    0.00 :   ffff8000100c7578:       ldr     w2, [x22]
    0.00 :   ffff8000100c757c:       mov     w28, w0
    0.00 :   ffff8000100c7580:       cmp     w0, w2
    0.00 :   ffff8000100c7584:       b.cc    ffff8000100c7550 <trigger_load_balance+0x260>  // b.lo, b.ul, b.last
    0.00 :   ffff8000100c7588:       ldr     x0, [sp, #104]
    0.00 :   ffff8000100c758c:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c7590:       ldr     x1, [x25, x0, lsl #3]
         : 10236            /*
    0.00 :   ffff8000100c7594:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100c7598:       add     x0, x0, #0x8a8
    0.00 :   ffff8000100c759c:       ldr     x0, [x0, x1]
         : 10237            * If there's a CFS task and the current CPU has reduced
    0.00 :   ffff8000100c75a0:       cbz     x0, ffff8000100c7614 <trigger_load_balance+0x324>
         : 10239            check_misfit_status():
         : 8317             sdg->sgc->min_capacity = min_capacity;
    0.00 :   ffff8000100c75a4:       ldr     x1, [x20, #2512]
    0.00 :   ffff8000100c75a8:       cbz     x1, ffff8000100c7630 <trigger_load_balance+0x340>
         : 8318             sdg->sgc->max_capacity = max_capacity;
    0.00 :   ffff8000100c75ac:       ldr     x2, [x20, #2464]
    0.00 :   ffff8000100c75b0:       ldr     x1, [x20, #2488]
         : 8317             sdg->sgc->min_capacity = min_capacity;
    0.00 :   ffff8000100c75b4:       ldr     x2, [x2, #4344]
    0.00 :   ffff8000100c75b8:       cmp     x1, x2
    0.00 :   ffff8000100c75bc:       b.cc    ffff8000100c75dc <trigger_load_balance+0x2ec>  // b.lo, b.ul, b.last
         : 8321             check_cpu_capacity():
         : 8306             do {
    0.00 :   ffff8000100c75c0:       ldr     w0, [x0, #44]
         : 8307             struct sched_group_capacity *sgc = group->sgc;
    0.00 :   ffff8000100c75c4:       add     x2, x1, x1, lsl #1
         : 8306             do {
    0.00 :   ffff8000100c75c8:       ldr     x3, [x20, #2480]
         : 8307             struct sched_group_capacity *sgc = group->sgc;
    0.00 :   ffff8000100c75cc:       add     x1, x1, x2, lsl #3
         : 8306             do {
    0.00 :   ffff8000100c75d0:       mul     x0, x0, x3
         : 8308             check_misfit_status():
         : 8318             sdg->sgc->max_capacity = max_capacity;
    0.00 :   ffff8000100c75d4:       cmp     x0, x1, lsl #2
    0.00 :   ffff8000100c75d8:       b.cs    ffff8000100c7630 <trigger_load_balance+0x340>  // b.hs, b.nlast
    0.00 :   ffff8000100c75dc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c75e0:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c75e4:       add     x22, x22, #0xc30
         : 8324             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100c75e8:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              nohz_balancer_kick():
         : 10277            *
    0.00 :   ffff8000100c75ec:       b       ffff8000100c73f8 <trigger_load_balance+0x108>
    0.00 :   ffff8000100c75f0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c75f4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c75f8:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c75fc:       b       ffff8000100c7380 <trigger_load_balance+0x90>
         : 10283            __ll_sc_atomic_fetch_or():
         : 123              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 124              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 125              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 127              ATOMIC_OPS(and, and, K)
         : 128              ATOMIC_OPS(or, orr, K)
    0.00 :   ffff8000100c7600:       add     x1, x1, #0x64
    0.00 :   ffff8000100c7604:       ldr     w6, [sp, #100]
    0.00 :   ffff8000100c7608:       b       ffff8000100c8378 <sched_group_set_shares+0x7e0>
    0.00 :   ffff8000100c760c:       mov     w23, w0
    0.00 :   ffff8000100c7610:       b       ffff8000100c74ac <trigger_load_balance+0x1bc>
         : 134              nohz_balancer_kick():
         : 10257            goto unlock;
    0.00 :   ffff8000100c7614:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100c7618:       add     x0, x0, #0x890
    0.00 :   ffff8000100c761c:       ldr     x0, [x0, x1]
         : 10258            }
    0.00 :   ffff8000100c7620:       cbz     x0, ffff8000100c7630 <trigger_load_balance+0x340>
         : 10260            atomic_read():
    0.00 :   ffff8000100c7624:       ldr     w0, [x0, #4]
         : 29               nohz_balancer_kick():
         : 10269            flags = NOHZ_KICK_MASK;
    0.00 :   ffff8000100c7628:       cmp     w0, #0x1
    0.00 :   ffff8000100c762c:       b.gt    ffff8000100c75dc <trigger_load_balance+0x2ec>
         : 10272            rcu_read_unlock():
    0.00 :   ffff8000100c7630:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              nohz_balancer_kick():
         : 10277            *
    0.00 :   ffff8000100c7634:       ldr     w0, [sp, #100]
    0.00 :   ffff8000100c7638:       cbz     w0, ffff8000100c75f0 <trigger_load_balance+0x300>
    0.00 :   ffff8000100c763c:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c7640:       add     x22, x22, #0xc30
    0.00 :   ffff8000100c7644:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c7648:       b       ffff8000100c740c <trigger_load_balance+0x11c>
    0.00 :   ffff8000100c764c:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c7650:       ldp     x27, x28, [sp, #80]
         : 10286            rcu_read_unlock():
    0.00 :   ffff8000100c7654:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              nohz_balancer_kick():
    0.00 :   ffff8000100c7658:       b       ffff8000100c73f8 <trigger_load_balance+0x108>
    0.00 :   ffff8000100c765c:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
         : 10196            static void nohz_balancer_kick(struct rq *rq)
    0.00 :   ffff8000100c7660:       mov     w0, #0x2                        // #2
    0.00 :   ffff8000100c7664:       add     x22, x22, #0xc30
    0.00 :   ffff8000100c7668:       str     w0, [sp, #100]
    0.00 :   ffff8000100c766c:       b       ffff8000100c740c <trigger_load_balance+0x11c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001002adb0 <armv8pmu_stop>:
         : 6                armv8pmu_stop():
         : 739              armv8pmu_disable_event_counter(event);
         :
         : 741              /*
         : 742              * Set event.
         : 743              */
         : 744              armv8pmu_write_event_type(event);
    0.00 :   ffff80001002adb0:       paciasp
         : 746              armv8pmu_pmcr_read():
         : 443              PMEVN_CASE(26, case_macro);                     \
    0.00 :   ffff80001002adb4:       mrs     x0, pmcr_el0
         : 445              armv8pmu_pmcr_write():
         : 449              }                                               \
    0.00 :   ffff80001002adb8:       isb
         : 450              } while (0)
  100.00 :   ffff80001002adbc:       and     x0, x0, #0xfe
    0.00 :   ffff80001002adc0:       msr     pmcr_el0, x0
         : 453              armv8pmu_stop():
         :
         : 743              /*
         : 744              * Enable interrupt for this counter
    0.00 :   ffff80001002adc4:       autiasp
    0.00 :   ffff80001002adc8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e34eb0 <_raw_spin_trylock>:
         : 6                _raw_spin_trylock():
         :
         : 135              #endif
         :
         : 137              #ifndef CONFIG_INLINE_SPIN_TRYLOCK
         : 138              int __lockfunc _raw_spin_trylock(raw_spinlock_t *lock)
         : 139              {
    0.00 :   ffff800010e34eb0:       paciasp
    0.00 :   ffff800010e34eb4:       stp     x29, x30, [sp, #-16]!
         : 142              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010e34eb8:       mrs     x2, sp_el0
         : 26               _raw_spin_trylock():
    0.00 :   ffff800010e34ebc:       mov     x29, sp
         : 135              __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010e34ec0:       ldr     w1, [x2, #8]
         : 53               _raw_spin_trylock():
    0.00 :   ffff800010e34ec4:       mov     x3, x0
         : 135              __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff800010e34ec8:       add     w1, w1, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010e34ecc:       str     w1, [x2, #8]
         : 50               atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff800010e34ed0:       ldr     w0, [x0]
         : 35               queued_spin_trylock():
         : 65               */
         : 66               static __always_inline int queued_spin_trylock(struct qspinlock *lock)
         : 67               {
         : 68               int val = atomic_read(&lock->val);
         :
         : 70               if (unlikely(val))
    0.00 :   ffff800010e34ed4:       cbnz    w0, ffff800010e34f04 <_raw_spin_trylock+0x54>
         : 72               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010e34ed8:       b       ffff800010e34f2c <_raw_spin_trylock+0x7c>
    0.00 :   ffff800010e34edc:       b       ffff800010e34f2c <_raw_spin_trylock+0x7c>
         : 46               __lse__cmpxchg_case_acq_32():
         : 370              __CMPXCHG_CASE(w, h,     , 16,   )
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
         : 372              __CMPXCHG_CASE(x,  ,     , 64,   )
         : 373              __CMPXCHG_CASE(w, b, acq_,  8,  a, "memory")
         : 374              __CMPXCHG_CASE(w, h, acq_, 16,  a, "memory")
         : 375              __CMPXCHG_CASE(w,  , acq_, 32,  a, "memory")
    0.00 :   ffff800010e34ee0:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010e34ee4:       mov     x0, x3
    0.00 :   ffff800010e34ee8:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e34eec:       mov     w4, w1
    0.00 :   ffff800010e34ef0:       casa    w4, w2, [x3]
    0.00 :   ffff800010e34ef4:       mov     w0, w4
    0.00 :   ffff800010e34ef8:       mov     w1, w0
         : 383              __raw_spin_trylock():
         : 91               static inline int __raw_spin_trylock(raw_spinlock_t *lock)
         : 92               {
         : 93               preempt_disable();
         : 94               if (do_raw_spin_trylock(lock)) {
         : 95               spin_acquire(&lock->dep_map, 0, 1, _RET_IP_);
         : 96               return 1;
    0.00 :   ffff800010e34efc:       mov     w0, #0x1                        // #1
         : 89               if (do_raw_spin_trylock(lock)) {
    0.00 :   ffff800010e34f00:       cbz     w1, ffff800010e34f40 <_raw_spin_trylock+0x90>
         : 91               get_current():
  100.00 :   ffff800010e34f04:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34f08:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010e34f0c:       sub     x0, x0, #0x1
    0.00 :   ffff800010e34f10:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010e34f14:       cbnz    x0, ffff800010e34f4c <_raw_spin_trylock+0x9c>
         : 80               __raw_spin_trylock():
         : 93               }
         : 94               preempt_enable();
    0.00 :   ffff800010e34f18:       bl      ffff800010e2e620 <preempt_schedule>
         : 94               return 0;
    0.00 :   ffff800010e34f1c:       mov     w0, #0x0                        // #0
         : 96               _raw_spin_trylock():
         : 136              return __raw_spin_trylock(lock);
         : 137              }
    0.00 :   ffff800010e34f20:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e34f24:       autiasp
    0.00 :   ffff800010e34f28:       ret
         : 141              __ll_sc__cmpxchg_case_acq_32():
         : 305              __CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
         : 307              __CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
         : 308              __CMPXCHG_CASE(w, b, acq_,  8,        , a,  , "memory", K)
         : 309              __CMPXCHG_CASE(w, h, acq_, 16,        , a,  , "memory", K)
         : 310              __CMPXCHG_CASE(w,  , acq_, 32,        , a,  , "memory", K)
    0.00 :   ffff800010e34f2c:       mov     x0, #0x0                        // #0
    0.00 :   ffff800010e34f30:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010e34f34:       b       ffff800010e35830 <_raw_read_lock_irqsave+0x138>
         : 314              __raw_spin_trylock():
         : 91               return 1;
    0.00 :   ffff800010e34f38:       mov     w0, #0x1                        // #1
         : 89               if (do_raw_spin_trylock(lock)) {
    0.00 :   ffff800010e34f3c:       cbnz    w1, ffff800010e34f04 <_raw_spin_trylock+0x54>
         : 91               _raw_spin_trylock():
    0.00 :   ffff800010e34f40:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e34f44:       autiasp
    0.00 :   ffff800010e34f48:       ret
         : 139              __preempt_count_dec_and_test():
    0.00 :   ffff800010e34f4c:       ldr     x0, [x1, #8]
    0.00 :   ffff800010e34f50:       cbnz    x0, ffff800010e34f1c <_raw_spin_trylock+0x6c>
         : 75               __raw_spin_trylock():
         : 93               preempt_enable();
    0.00 :   ffff800010e34f54:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010e34f58:       b       ffff800010e34f1c <_raw_spin_trylock+0x6c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100ff130 <rcu_qs>:
         : 6                rcu_qs():
         : 328              t->rcu_read_unlock_special.b.blocked = true;
         : 329              t->rcu_blocked_node = rnp;
         :
         : 331              /*
         : 332              * Verify the CPU's sanity, trace the preemption, and
         : 333              * then queue the task as required based on the states
    0.00 :   ffff8000100ff130:       adrp    x0, ffff80001177a000 <runqueues+0x3c0>
    0.00 :   ffff8000100ff134:       add     x0, x0, #0x900
    0.00 :   ffff8000100ff138:       add     x0, x0, #0x10
         : 326              /*
    0.00 :   ffff8000100ff13c:       paciasp
         : 328              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100ff140:       mrs     x1, tpidr_el1
         : 46               rcu_qs():
         : 328              * then queue the task as required based on the states
    0.00 :   ffff8000100ff144:       ldrh    w2, [x0, x1]
    0.00 :   ffff8000100ff148:       cbz     w2, ffff8000100ff158 <rcu_qs+0x28>
         : 332              * of any ongoing and expedited grace periods.
         : 333              */
         : 334              WARN_ON_ONCE((rdp->grpmask & rcu_rnp_online_cpus(rnp)) == 0);
         : 335              WARN_ON_ONCE(!list_empty(&t->rcu_node_entry));
    0.00 :   ffff8000100ff14c:       strb    wzr, [x0, x1]
         : 337              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
  100.00 :   ffff8000100ff150:       mrs     x0, sp_el0
         : 26               rcu_qs():
         : 334              trace_rcu_preempt_task(rcu_state.name,
         : 335              t->pid,
    0.00 :   ffff8000100ff154:       strb    wzr, [x0, #737]
         : 336              (rnp->qsmask & rdp->grpmask)
         : 337              ? rnp->gp_seq
    0.00 :   ffff8000100ff158:       autiasp
    0.00 :   ffff8000100ff15c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bedb8 <set_next_entity>:
         : 6                set_next_entity():
         :
         : 4422             /*
         : 4423             * Pick the next process, keeping these things in mind, in this order:
         : 4424             * 1) keep things fair between processes/task groups
         : 4425             * 2) pick the "next" process, since someone really wants that to run
         : 4426             * 3) pick the "last" process, for cache locality
    0.00 :   ffff8000100bedb8:       paciasp
    0.00 :   ffff8000100bedbc:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000100bedc0:       mov     x29, sp
    0.00 :   ffff8000100bedc4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bedc8:       mov     x20, x0
    0.00 :   ffff8000100bedcc:       mov     x19, x1
         : 4423             * 4) do not run the "skip" process, if something else is available
         : 4424             */
    0.00 :   ffff8000100bedd0:       ldr     w0, [x1, #56]
    0.00 :   ffff8000100bedd4:       cbnz    w0, ffff8000100bee00 <set_next_entity+0x48>
         : 4427             update_stats_curr_start():
         : 1061             static struct numa_group *deref_task_numa_group(struct task_struct *p)
    0.00 :   ffff8000100bedd8:       ldr     x0, [x20, #304]
    0.00 :   ffff8000100beddc:       ldr     x0, [x0, #2432]
    0.00 :   ffff8000100bede0:       str     x0, [x19, #64]
         : 1065             set_next_entity():
         : 4435             /*
         : 4436             * If curr is set we have to see if its left of the leftmost entity
         : 4437             * still in the tree, provided there was anything in the tree at all.
         : 4438             */
         : 4439             if (!left || (curr && entity_before(curr, left)))
         : 4440             left = curr;
    0.00 :   ffff8000100bede4:       str     x19, [x20, #64]
         : 4449             struct sched_entity *second;
         :
         : 4451             if (se == curr) {
         : 4452             second = __pick_first_entity(cfs_rq);
         : 4453             } else {
         : 4454             second = __pick_next_entity(se);
    0.00 :   ffff8000100bede8:       ldr     x0, [x19, #72]
    0.00 :   ffff8000100bedec:       str     x0, [x19, #88]
         : 4450             if (!second || (curr && entity_before(curr, second)))
    0.00 :   ffff8000100bedf0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bedf4:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100bedf8:       autiasp
    0.00 :   ffff8000100bedfc:       ret
         : 4455             __dequeue_entity():
         : 599              (normalized_sysctl_##name = sysctl_##name / (factor))
  100.00 :   ffff8000100bee00:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bee04:       add     x21, x1, #0x10
    0.00 :   ffff8000100bee08:       add     x22, x20, #0x30
         : 603              rb_erase_cached():
         : 150              static inline struct rb_node *
         : 151              rb_erase_cached(struct rb_node *node, struct rb_root_cached *root)
         : 152              {
         : 153              struct rb_node *leftmost = NULL;
         :
         : 155              if (root->rb_leftmost == node)
    0.00 :   ffff8000100bee0c:       ldr     x0, [x20, #56]
    0.00 :   ffff8000100bee10:       cmp     x21, x0
    0.00 :   ffff8000100bee14:       b.ne    ffff8000100bee24 <set_next_entity+0x6c>  // b.any
         : 151              leftmost = root->rb_leftmost = rb_next(node);
    0.00 :   ffff8000100bee18:       mov     x0, x21
    0.00 :   ffff8000100bee1c:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000100bee20:       str     x0, [x20, #56]
         :
         : 154              rb_erase(node, &root->rb_root);
    0.00 :   ffff8000100bee24:       mov     x1, x22
    0.00 :   ffff8000100bee28:       mov     x0, x21
    0.00 :   ffff8000100bee2c:       bl      ffff8000104b33a8 <rb_erase>
         : 158              set_next_entity():
         : 4431             * If curr is set we have to see if its left of the leftmost entity
    0.00 :   ffff8000100bee30:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000100bee34:       mov     x1, x19
    0.00 :   ffff8000100bee38:       mov     x0, x20
    0.00 :   ffff8000100bee3c:       bl      ffff8000100be318 <update_load_avg>
    0.00 :   ffff8000100bee40:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bee44:       b       ffff8000100bedd8 <set_next_entity+0x20>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bd560 <pick_next_entity>:
         : 6                pick_next_entity():
         : 4464             /*
         : 4465             * Someone really wants this to run. If it's not unfair, run it.
         : 4466             */
         : 4467             se = cfs_rq->next;
         : 4468             } else if (cfs_rq->last && wakeup_preempt_entity(cfs_rq->last, left) < 1) {
         : 4469             /*
    0.00 :   ffff8000100bd560:       paciasp
    0.00 :   ffff8000100bd564:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000100bd568:       mov     x29, sp
    0.00 :   ffff8000100bd56c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bd570:       mov     x19, x0
    0.00 :   ffff8000100bd574:       str     x21, [sp, #32]
    0.00 :   ffff8000100bd578:       mov     x21, x1
         : 4477             __pick_first_entity():
         :
    0.00 :   ffff8000100bd57c:       ldr     x0, [x0, #56]
         : 606              }
    0.00 :   ffff8000100bd580:       ldr     x1, [x19, #88]
    0.00 :   ffff8000100bd584:       cbz     x0, ffff8000100bd618 <pick_next_entity+0xb8>
         : 609              pick_next_entity():
         : 4472             se = cfs_rq->last;
         : 4473             }
         :
         : 4475             return se;
         : 4476             }
         :
    0.00 :   ffff8000100bd588:       subs    x20, x0, #0x10
    0.00 :   ffff8000100bd58c:       b.eq    ffff8000100bd610 <pick_next_entity+0xb0>  // b.none
    0.00 :   ffff8000100bd590:       cbz     x21, ffff8000100bd628 <pick_next_entity+0xc8>
         : 4473             entity_before():
         : 547              {
    0.00 :   ffff8000100bd594:       ldr     x2, [x0, #64]
    0.00 :   ffff8000100bd598:       ldr     x3, [x21, #80]
         : 550              pick_next_entity():
         :
    0.00 :   ffff8000100bd59c:       cmp     x3, x2
    0.00 :   ffff8000100bd5a0:       b.mi    ffff8000100bd610 <pick_next_entity+0xb0>  // b.first
         : 4481             {
         : 4482             /*
         : 4483             * If still on the runqueue then deactivate_task()
         : 4484             * was not called and update_curr() has to be done:
         : 4485             */
         : 4486             if (prev->on_rq)
    0.00 :   ffff8000100bd5a4:       cmp     x20, x1
    0.00 :   ffff8000100bd5a8:       b.eq    ffff8000100bd678 <pick_next_entity+0x118>  // b.none
         : 4489             __pick_next_entity():
         :
    0.00 :   ffff8000100bd5ac:       mov     x21, x20
         : 618              pick_next_entity():
         : 4496             /* Put 'current' back into the tree. */
         : 4497             __enqueue_entity(cfs_rq, prev);
         : 4498             /* in !on_rq case, update occurred at dequeue */
         : 4499             update_load_avg(cfs_rq, prev, 0);
         : 4500             }
         : 4501             cfs_rq->curr = NULL;
    0.00 :   ffff8000100bd5b0:       ldr     x0, [x19, #72]
    0.00 :   ffff8000100bd5b4:       cbz     x0, ffff8000100bd5cc <pick_next_entity+0x6c>
    0.00 :   ffff8000100bd5b8:       ldr     x0, [x0, #80]
    0.00 :   ffff8000100bd5bc:       mov     x1, x21
    0.00 :   ffff8000100bd5c0:       bl      ffff8000100bd370 <wakeup_preempt_entity.isra.99>
    0.00 :   ffff8000100bd5c4:       cmp     w0, #0x0
    0.00 :   ffff8000100bd5c8:       b.le    ffff8000100bd620 <pick_next_entity+0xc0>
         : 4501             }
         :
         : 4503             static void
         : 4504             entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr, int queued)
         : 4505             {
    0.00 :   ffff8000100bd5cc:       ldr     x0, [x19, #80]
    0.00 :   ffff8000100bd5d0:       cbz     x0, ffff8000100bd5ec <pick_next_entity+0x8c>
    0.00 :   ffff8000100bd5d4:       ldr     x0, [x0, #80]
    0.00 :   ffff8000100bd5d8:       mov     x1, x21
    0.00 :   ffff8000100bd5dc:       bl      ffff8000100bd370 <wakeup_preempt_entity.isra.99>
    0.00 :   ffff8000100bd5e0:       cmp     w0, #0x0
    0.00 :   ffff8000100bd5e4:       b.gt    ffff8000100bd5ec <pick_next_entity+0x8c>
         : 4505             /*
         : 4506             * Update run-time statistics of the 'current'.
         : 4507             */
         : 4508             update_curr(cfs_rq);
    0.00 :   ffff8000100bd5e8:       ldr     x20, [x19, #80]
         :
         : 4509             /*
         : 4510             * Ensure that runnable average is periodically updated.
  100.00 :   ffff8000100bd5ec:       mov     x0, x19
    0.00 :   ffff8000100bd5f0:       mov     x1, x20
    0.00 :   ffff8000100bd5f4:       bl      ffff8000100bc140 <clear_buddies>
         : 4511             */
         : 4512             update_load_avg(cfs_rq, curr, UPDATE_TG);
         : 4513             update_cfs_group(curr);
    0.00 :   ffff8000100bd5f8:       mov     x0, x20
    0.00 :   ffff8000100bd5fc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bd600:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100bd604:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100bd608:       autiasp
    0.00 :   ffff8000100bd60c:       ret
         : 4481             if (prev->on_rq)
    0.00 :   ffff8000100bd610:       cmp     x21, x1
    0.00 :   ffff8000100bd614:       b.eq    ffff8000100bd64c <pick_next_entity+0xec>  // b.none
    0.00 :   ffff8000100bd618:       mov     x20, x21
    0.00 :   ffff8000100bd61c:       b       ffff8000100bd5b0 <pick_next_entity+0x50>
         : 4500             entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr, int queued)
    0.00 :   ffff8000100bd620:       ldr     x20, [x19, #72]
    0.00 :   ffff8000100bd624:       b       ffff8000100bd5ec <pick_next_entity+0x8c>
         : 4481             if (prev->on_rq)
    0.00 :   ffff8000100bd628:       cmp     x20, x1
    0.00 :   ffff8000100bd62c:       b.ne    ffff8000100bd5ac <pick_next_entity+0x4c>  // b.any
         : 4484             __pick_next_entity():
         : 614              if (unlikely(se->load.weight != NICE_0_LOAD))
    0.00 :   ffff8000100bd630:       bl      ffff8000104b3d50 <rb_next>
         :
    0.00 :   ffff8000100bd634:       cbz     x0, ffff8000100bd5ac <pick_next_entity+0x4c>
         : 618              pick_next_entity():
         :
    0.00 :   ffff8000100bd638:       subs    x9, x0, #0x10
    0.00 :   ffff8000100bd63c:       b.eq    ffff8000100bd5ac <pick_next_entity+0x4c>  // b.none
    0.00 :   ffff8000100bd640:       mov     x21, x20
    0.00 :   ffff8000100bd644:       ldr     x0, [x0, #64]
    0.00 :   ffff8000100bd648:       b       ffff8000100bd664 <pick_next_entity+0x104>
         : 4494             __pick_first_entity():
         : 609              /*
    0.00 :   ffff8000100bd64c:       mov     x21, x20
         : 611              pick_next_entity():
         : 4481             if (prev->on_rq)
    0.00 :   ffff8000100bd650:       mov     x20, x1
         : 4492             __enqueue_entity(cfs_rq, prev);
    0.00 :   ffff8000100bd654:       cbz     x21, ffff8000100bd5ac <pick_next_entity+0x4c>
         :
    0.00 :   ffff8000100bd658:       mov     x9, x21
    0.00 :   ffff8000100bd65c:       ldr     x0, [x21, #80]
    0.00 :   ffff8000100bd660:       mov     x21, x20
         : 4492             __enqueue_entity(cfs_rq, prev);
    0.00 :   ffff8000100bd664:       mov     x1, x20
    0.00 :   ffff8000100bd668:       bl      ffff8000100bd370 <wakeup_preempt_entity.isra.99>
    0.00 :   ffff8000100bd66c:       cmp     w0, #0x0
    0.00 :   ffff8000100bd670:       csel    x20, x20, x9, gt
    0.00 :   ffff8000100bd674:       b       ffff8000100bd5b0 <pick_next_entity+0x50>
         : 4484             /* throttle cfs_rqs exceeding runtime */
    0.00 :   ffff8000100bd678:       cmp     x21, x20
    0.00 :   ffff8000100bd67c:       b.eq    ffff8000100bd658 <pick_next_entity+0xf8>  // b.none
         : 4487             __pick_next_entity():
         : 614              if (unlikely(se->load.weight != NICE_0_LOAD))
    0.00 :   ffff8000100bd680:       bl      ffff8000104b3d50 <rb_next>
         :
    0.00 :   ffff8000100bd684:       cbz     x0, ffff8000100bd658 <pick_next_entity+0xf8>
         : 618              pick_next_entity():
         :
    0.00 :   ffff8000100bd688:       subs    x9, x0, #0x10
    0.00 :   ffff8000100bd68c:       b.eq    ffff8000100bd654 <pick_next_entity+0xf4>  // b.none
    0.00 :   ffff8000100bd690:       ldr     x0, [x0, #64]
    0.00 :   ffff8000100bd694:       ldr     x1, [x21, #80]
    0.00 :   ffff8000100bd698:       cmp     x1, x0
    0.00 :   ffff8000100bd69c:       b.mi    ffff8000100bd6a8 <pick_next_entity+0x148>  // b.first
    0.00 :   ffff8000100bd6a0:       mov     x21, x20
    0.00 :   ffff8000100bd6a4:       b       ffff8000100bd664 <pick_next_entity+0x104>
    0.00 :   ffff8000100bd6a8:       mov     x9, x21
    0.00 :   ffff8000100bd6ac:       mov     x0, x1
    0.00 :   ffff8000100bd6b0:       mov     x21, x20
    0.00 :   ffff8000100bd6b4:       b       ffff8000100bd664 <pick_next_entity+0x104>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101a43a8 <refresh_cpu_vm_stats>:
         : 6                refresh_cpu_vm_stats():
         : 772              *
         : 773              * The function returns the number of global counters updated.
         : 774              */
         : 775              static int refresh_cpu_vm_stats(bool do_pagesets)
         : 776              {
         : 777              struct pglist_data *pgdat;
    0.00 :   ffff8000101a43a8:       paciasp
    0.00 :   ffff8000101a43ac:       stp     x29, x30, [sp, #-384]!
    0.00 :   ffff8000101a43b0:       and     w0, w0, #0xff
    0.00 :   ffff8000101a43b4:       mov     x29, sp
    0.00 :   ffff8000101a43b8:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101a43bc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101a43c0:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000101a43c4:       adrp    x23, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101a43c8:       add     x1, x23, #0x948
    0.00 :   ffff8000101a43cc:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000101a43d0:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000101a43d4:       str     w0, [sp, #112]
    0.00 :   ffff8000101a43d8:       ldr     x0, [x1]
    0.00 :   ffff8000101a43dc:       str     x0, [sp, #376]
    0.00 :   ffff8000101a43e0:       mov     x0, #0x0                        // #0
         : 778              struct zone *zone;
         : 779              int i;
         : 780              int global_zone_diff[NR_VM_ZONE_STAT_ITEMS] = { 0, };
         : 781              int global_node_diff[NR_VM_NODE_STAT_ITEMS] = { 0, };
         : 782              int changes = 0;
         :
    0.00 :   ffff8000101a43e4:       add     x0, sp, #0x34
         : 772              struct pglist_data *pgdat;
    0.00 :   ffff8000101a43e8:       str     x1, [sp, #128]
         :
    0.00 :   ffff8000101a43ec:       stur    xzr, [sp, #172]
         : 776              int global_node_diff[NR_VM_NODE_STAT_ITEMS] = { 0, };
    0.00 :   ffff8000101a43f0:       stur    xzr, [sp, #212]
         :
    0.00 :   ffff8000101a43f4:       stp     xzr, xzr, [x0, #104]
         : 776              int global_node_diff[NR_VM_NODE_STAT_ITEMS] = { 0, };
    0.00 :   ffff8000101a43f8:       stp     xzr, xzr, [x0, #128]
    0.00 :   ffff8000101a43fc:       stp     xzr, xzr, [x0, #144]
         : 780              for_each_populated_zone(zone) {
         : 781              struct per_cpu_zonestat __percpu *pzstats = zone->per_cpu_zonestats;
    0.00 :   ffff8000101a4400:       stp     xzr, xzr, [x0, #168]
    0.00 :   ffff8000101a4404:       stp     xzr, xzr, [x0, #184]
    0.00 :   ffff8000101a4408:       stp     xzr, xzr, [x0, #200]
    0.00 :   ffff8000101a440c:       stp     xzr, xzr, [x0, #216]
    0.00 :   ffff8000101a4410:       stp     xzr, xzr, [x0, #232]
    0.00 :   ffff8000101a4414:       stp     xzr, xzr, [x0, #248]
    0.00 :   ffff8000101a4418:       add     x0, sp, #0x234
    0.00 :   ffff8000101a441c:       stp     xzr, xzr, [x0, #-248]
    0.00 :   ffff8000101a4420:       stp     xzr, xzr, [x0, #-232]
    0.00 :   ffff8000101a4424:       stp     xzr, xzr, [x0, #-216]
    0.00 :   ffff8000101a4428:       add     x0, sp, #0x230
    0.00 :   ffff8000101a442c:       stur    xzr, [x0, #-196]
    0.00 :   ffff8000101a4430:       str     wzr, [sp, #372]
         : 783              #ifdef CONFIG_NUMA
         : 784              struct per_cpu_pages __percpu *pcp = zone->per_cpu_pageset;
         : 785              #endif
    0.00 :   ffff8000101a4434:       bl      ffff8000101a2d48 <first_online_pgdat>
    0.00 :   ffff8000101a4438:       cbz     x0, ffff8000101a466c <refresh_cpu_vm_stats+0x2c4>
    0.00 :   ffff8000101a443c:       mov     x26, x0
    0.00 :   ffff8000101a4440:       add     x20, sp, #0xb4
         : 790              numa_node_id():
         :
         : 90               #ifndef numa_node_id
         : 91               /* Returns the number of the current Node. */
         : 92               static inline int numa_node_id(void)
         : 93               {
         : 94               return raw_cpu_read(numa_node);
    0.00 :   ffff8000101a4444:       adrp    x0, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000101a4448:       add     x21, sp, #0x9c
    0.00 :   ffff8000101a444c:       add     x0, x0, #0x610
         : 98               __xchg_case_8():
         : 45               : cl);                                                                  \
         : 46               \
         : 47               return ret;                                                             \
         : 48               }
         :
         : 50               __XCHG_CASE(w, b,     ,  8,        ,    ,  ,  ,  ,         )
    0.00 :   ffff8000101a4450:       mov     w19, #0x0                       // #0
         : 52               refresh_cpu_vm_stats():
         : 796              atomic_long_add(v, &zone->vm_stat[i]);
         : 797              global_zone_diff[i] += v;
         : 798              #ifdef CONFIG_NUMA
         : 799              /* 3 seconds idle till flush */
         : 800              __this_cpu_write(pcp->expire, 3);
         : 801              #endif
    0.00 :   ffff8000101a4454:       mov     w22, #0x3                       // #3
         : 781              #ifdef CONFIG_NUMA
    0.00 :   ffff8000101a4458:       str     wzr, [sp, #116]
         : 783              numa_node_id():
    0.00 :   ffff8000101a445c:       str     x0, [sp, #136]
    0.00 :   ffff8000101a4460:       b       ffff8000101a4474 <refresh_cpu_vm_stats+0xcc>
         : 91               refresh_cpu_vm_stats():
         : 783              #endif
    0.00 :   ffff8000101a4464:       mov     x0, x26
    0.00 :   ffff8000101a4468:       bl      ffff8000101a2de0 <next_zone>
    0.00 :   ffff8000101a446c:       mov     x26, x0
    0.00 :   ffff8000101a4470:       cbz     x0, ffff8000101a4678 <refresh_cpu_vm_stats+0x2d0>
    0.00 :   ffff8000101a4474:       ldr     x0, [x26, #128]
    0.00 :   ffff8000101a4478:       cbz     x0, ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         :
    0.00 :   ffff8000101a447c:       ldr     x23, [x26, #88]
         : 786              int v;
    0.00 :   ffff8000101a4480:       add     x7, x26, #0x5c0
         :
    0.00 :   ffff8000101a4484:       mov     x27, #0x0                       // #0
    0.00 :   ffff8000101a4488:       add     x25, x23, #0x4f
         : 796              #endif
    0.00 :   ffff8000101a448c:       add     x24, x23, #0x40
         : 798              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000101a4490:       mrs     x1, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000101a4494:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff8000101a4498:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000101a449c:       str     w0, [x1, #8]
         : 50               refresh_cpu_vm_stats():
         : 789              if (v) {
    0.00 :   ffff8000101a44a0:       add     x0, x25, x27
         : 791              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000101a44a4:       mrs     x2, tpidr_el1
         : 46               __xchg_case_8():
    0.00 :   ffff8000101a44a8:       add     x0, x0, x2
    0.00 :   ffff8000101a44ac:       prfm    pstl1strm, [x0]
  100.00 :   ffff8000101a44b0:       ldxrb   w28, [x0]
    0.00 :   ffff8000101a44b4:       stxrb   w8, w19, [x0]
    0.00 :   ffff8000101a44b8:       cbnz    w8, ffff8000101a44b0 <refresh_cpu_vm_stats+0x108>
         : 50               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a44bc:       sxtb    w2, w28
         : 790              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000101a44c0:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000101a44c4:       sub     x0, x0, #0x1
    0.00 :   ffff8000101a44c8:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000101a44cc:       cbnz    x0, ffff8000101a45e4 <refresh_cpu_vm_stats+0x23c>
    0.00 :   ffff8000101a44d0:       str     w2, [sp, #96]
         : 81               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a44d4:       str     x7, [sp, #104]
    0.00 :   ffff8000101a44d8:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         :
    0.00 :   ffff8000101a44dc:       ldr     w2, [sp, #96]
    0.00 :   ffff8000101a44e0:       ldr     x7, [sp, #104]
    0.00 :   ffff8000101a44e4:       cbnz    w2, ffff8000101a45f0 <refresh_cpu_vm_stats+0x248>
    0.00 :   ffff8000101a44e8:       add     x27, x27, #0x1
         : 786              int v;
    0.00 :   ffff8000101a44ec:       cmp     x27, #0xa
    0.00 :   ffff8000101a44f0:       b.ne    ffff8000101a4490 <refresh_cpu_vm_stats+0xe8>  // b.any
    0.00 :   ffff8000101a44f4:       add     x6, x23, #0x42
    0.00 :   ffff8000101a44f8:       add     x8, x26, #0x610
         : 809              * Deal with draining the remote pageset of this
         : 810              * processor
         : 811              *
         : 812              * Check if there are pages remaining in this pageset
         : 813              * if not then there is nothing to expire.
         : 814              */
    0.00 :   ffff8000101a44fc:       add     x7, x23, #0x40
         : 786              int v;
    0.00 :   ffff8000101a4500:       mov     x27, #0x0                       // #0
         : 788              __xchg_case_16():
         : 46               __XCHG_CASE(w, h,     , 16,        ,    ,  ,  ,  ,         )
    0.00 :   ffff8000101a4504:       mov     w24, #0x0                       // #0
         : 48               get_current():
    0.00 :   ffff8000101a4508:       mrs     x1, sp_el0
         : 20               __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000101a450c:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff8000101a4510:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000101a4514:       str     w0, [x1, #8]
         : 50               refresh_cpu_vm_stats():
         : 804              * Deal with draining the remote pageset of this
    0.00 :   ffff8000101a4518:       mov     x0, x6
         : 806              __kern_my_cpu_offset():
    0.00 :   ffff8000101a451c:       mrs     x2, tpidr_el1
         : 40               __xchg_case_16():
    0.00 :   ffff8000101a4520:       add     x0, x0, x2
    0.00 :   ffff8000101a4524:       prfm    pstl1strm, [x0]
    0.00 :   ffff8000101a4528:       ldxrh   w28, [x0]
    0.00 :   ffff8000101a452c:       stxrh   w9, w24, [x0]
    0.00 :   ffff8000101a4530:       cbnz    w9, ffff8000101a4528 <refresh_cpu_vm_stats+0x180>
    0.00 :   ffff8000101a4534:       and     w25, w28, #0xffff
         : 52               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000101a4538:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000101a453c:       sub     x0, x0, #0x1
    0.00 :   ffff8000101a4540:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000101a4544:       cbnz    x0, ffff8000101a4620 <refresh_cpu_vm_stats+0x278>
    0.00 :   ffff8000101a4548:       stp     x6, x8, [sp, #96]
    0.00 :   ffff8000101a454c:       str     x7, [sp, #120]
         : 77               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a4550:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         : 805              * processor
    0.00 :   ffff8000101a4554:       ldp     x6, x8, [sp, #96]
    0.00 :   ffff8000101a4558:       ldr     x7, [sp, #120]
    0.00 :   ffff8000101a455c:       cbnz    w25, ffff8000101a462c <refresh_cpu_vm_stats+0x284>
    0.00 :   ffff8000101a4560:       add     x27, x27, #0x1
    0.00 :   ffff8000101a4564:       add     x6, x6, #0x2
         : 801              if (do_pagesets) {
    0.00 :   ffff8000101a4568:       cmp     x27, #0x6
    0.00 :   ffff8000101a456c:       b.ne    ffff8000101a4508 <refresh_cpu_vm_stats+0x160>  // b.any
         : 813              if (!__this_cpu_read(pcp->expire) ||
         : 814              !__this_cpu_read(pcp->count))
         : 815              continue;
         :
    0.00 :   ffff8000101a4570:       ldr     w0, [sp, #112]
    0.00 :   ffff8000101a4574:       cbz     w0, ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         : 822              if (zone_to_nid(zone) == numa_node_id()) {
         : 823              __this_cpu_write(pcp->expire, 0);
         : 824              continue;
         : 825              }
         :
         : 827              if (__this_cpu_dec_return(pcp->expire))
    0.00 :   ffff8000101a4578:       add     x0, x23, #0x40
         : 829              __kern_my_cpu_offset():
    0.00 :   ffff8000101a457c:       mrs     x1, tpidr_el1
         : 40               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a4580:       ldrsb   w2, [x0, x1]
    0.00 :   ffff8000101a4584:       cbz     w2, ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         : 823              continue;
    0.00 :   ffff8000101a4588:       mov     x4, x23
         : 822              if (__this_cpu_dec_return(pcp->expire))
    0.00 :   ffff8000101a458c:       ldr     w2, [x4, x1]
    0.00 :   ffff8000101a4590:       cbz     w2, ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         :
         : 830              if (__this_cpu_read(pcp->count)) {
         : 831              drain_zone_pages(zone, this_cpu_ptr(pcp));
         : 832              changes++;
         : 833              }
         : 834              }
    0.00 :   ffff8000101a4594:       ldr     w5, [x26, #72]
         : 836              numa_node_id():
    0.00 :   ffff8000101a4598:       ldr     x2, [sp, #136]
         : 90               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a459c:       ldr     w2, [x2, x1]
    0.00 :   ffff8000101a45a0:       cmp     w5, w2
    0.00 :   ffff8000101a45a4:       b.eq    ffff8000101a4798 <refresh_cpu_vm_stats+0x3f0>  // b.none
         : 834              #endif
         : 835              }
         :
         : 837              for_each_online_pgdat(pgdat) {
         : 838              struct per_cpu_nodestat __percpu *p = pgdat->per_cpu_nodestats;
    0.00 :   ffff8000101a45a8:       ldrb    w2, [x0, x1]
    0.00 :   ffff8000101a45ac:       sub     w2, w2, #0x1
    0.00 :   ffff8000101a45b0:       sxtb    w2, w2
    0.00 :   ffff8000101a45b4:       strb    w2, [x0, x1]
    0.00 :   ffff8000101a45b8:       cbnz    w2, ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         : 844              __kern_my_cpu_offset():
    0.00 :   ffff8000101a45bc:       mrs     x1, tpidr_el1
         : 40               refresh_cpu_vm_stats():
         :
         : 838              for (i = 0; i < NR_VM_NODE_STAT_ITEMS; i++) {
         : 839              int v;
    0.00 :   ffff8000101a45c0:       ldr     w0, [x4, x1]
    0.00 :   ffff8000101a45c4:       cbz     w0, ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         :
         : 840              v = this_cpu_xchg(p->vm_node_stat_diff[i], 0);
    0.00 :   ffff8000101a45c8:       ldr     w0, [sp, #116]
         :
    0.00 :   ffff8000101a45cc:       add     x1, x4, x1
         : 839              v = this_cpu_xchg(p->vm_node_stat_diff[i], 0);
    0.00 :   ffff8000101a45d0:       add     w0, w0, #0x1
    0.00 :   ffff8000101a45d4:       str     w0, [sp, #116]
         :
    0.00 :   ffff8000101a45d8:       mov     x0, x26
    0.00 :   ffff8000101a45dc:       bl      ffff8000101da428 <drain_zone_pages>
         : 839              v = this_cpu_xchg(p->vm_node_stat_diff[i], 0);
    0.00 :   ffff8000101a45e0:       b       ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         : 841              __preempt_count_dec_and_test():
    0.00 :   ffff8000101a45e4:       ldr     x0, [x1, #8]
    0.00 :   ffff8000101a45e8:       cbz     x0, ffff8000101a44d0 <refresh_cpu_vm_stats+0x128>
         : 75               refresh_cpu_vm_stats():
         :
    0.00 :   ffff8000101a45ec:       cbz     w2, ffff8000101a44e8 <refresh_cpu_vm_stats+0x140>
         : 792              global_zone_diff[i] += v;
    0.00 :   ffff8000101a45f0:       sxtb    x28, w28
    0.00 :   ffff8000101a45f4:       add     x0, x7, x27, lsl #3
         : 795              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101a45f8:       b       ffff8000101a465c <refresh_cpu_vm_stats+0x2b4>
    0.00 :   ffff8000101a45fc:       b       ffff8000101a465c <refresh_cpu_vm_stats+0x2b4>
         : 46               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000101a4600:       stadd   x28, [x0]
         : 186              refresh_cpu_vm_stats():
         : 793              #ifdef CONFIG_NUMA
    0.00 :   ffff8000101a4604:       ldr     w1, [x20, x27, lsl #2]
         : 796              #endif
    0.00 :   ffff8000101a4608:       mov     x0, x24
         : 798              __kern_my_cpu_offset():
    0.00 :   ffff8000101a460c:       mrs     x8, tpidr_el1
         : 40               refresh_cpu_vm_stats():
         : 793              #ifdef CONFIG_NUMA
    0.00 :   ffff8000101a4610:       add     w2, w1, w2
    0.00 :   ffff8000101a4614:       str     w2, [x20, x27, lsl #2]
         : 796              #endif
    0.00 :   ffff8000101a4618:       strb    w22, [x0, x8]
    0.00 :   ffff8000101a461c:       b       ffff8000101a44e8 <refresh_cpu_vm_stats+0x140>
         : 799              __preempt_count_dec_and_test():
    0.00 :   ffff8000101a4620:       ldr     x0, [x1, #8]
    0.00 :   ffff8000101a4624:       cbz     x0, ffff8000101a4548 <refresh_cpu_vm_stats+0x1a0>
         : 75               refresh_cpu_vm_stats():
         : 805              * processor
    0.00 :   ffff8000101a4628:       cbz     w25, ffff8000101a4560 <refresh_cpu_vm_stats+0x1b8>
         : 807              * Check if there are pages remaining in this pageset
    0.00 :   ffff8000101a462c:       and     x28, x28, #0xffff
    0.00 :   ffff8000101a4630:       add     x0, x8, x27, lsl #3
         : 810              arch_static_branch_jump():
    0.00 :   ffff8000101a4634:       b       ffff8000101a4664 <refresh_cpu_vm_stats+0x2bc>
    0.00 :   ffff8000101a4638:       b       ffff8000101a4664 <refresh_cpu_vm_stats+0x2bc>
         : 40               __lse_atomic64_add():
    0.00 :   ffff8000101a463c:       stadd   x28, [x0]
         : 180              refresh_cpu_vm_stats():
         : 808              * if not then there is nothing to expire.
    0.00 :   ffff8000101a4640:       ldr     w1, [x21, x27, lsl #2]
         : 809              */
    0.00 :   ffff8000101a4644:       mov     x0, x7
         : 811              __kern_my_cpu_offset():
    0.00 :   ffff8000101a4648:       mrs     x9, tpidr_el1
         : 40               refresh_cpu_vm_stats():
         : 808              * if not then there is nothing to expire.
    0.00 :   ffff8000101a464c:       add     w2, w1, w25
    0.00 :   ffff8000101a4650:       str     w2, [x21, x27, lsl #2]
         : 809              */
    0.00 :   ffff8000101a4654:       strb    w22, [x0, x9]
    0.00 :   ffff8000101a4658:       b       ffff8000101a4560 <refresh_cpu_vm_stats+0x1b8>
         : 812              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000101a465c:       b       ffff8000101a6c18 <quiet_vmstat+0xf0>
    0.00 :   ffff8000101a4660:       b       ffff8000101a4604 <refresh_cpu_vm_stats+0x25c>
    0.00 :   ffff8000101a4664:       b       ffff8000101a6c30 <quiet_vmstat+0x108>
    0.00 :   ffff8000101a4668:       b       ffff8000101a4640 <refresh_cpu_vm_stats+0x298>
    0.00 :   ffff8000101a466c:       add     x20, sp, #0xb4
    0.00 :   ffff8000101a4670:       add     x21, sp, #0x9c
         : 222              refresh_cpu_vm_stats():
         : 781              #ifdef CONFIG_NUMA
    0.00 :   ffff8000101a4674:       str     wzr, [sp, #116]
         : 845              if (v) {
         : 846              atomic_long_add(v, &pgdat->vm_stat[i]);
         : 847              global_node_diff[i] += v;
         : 848              }
         : 849              }
         : 850              }
    0.00 :   ffff8000101a4678:       bl      ffff8000101a2d48 <first_online_pgdat>
         : 852              __xchg_case_8():
         : 45               __XCHG_CASE(w, b,     ,  8,        ,    ,  ,  ,  ,         )
    0.00 :   ffff8000101a467c:       mov     w27, #0x0                       // #0
         : 47               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a4680:       mov     x19, x0
    0.00 :   ffff8000101a4684:       mov     x22, #0x22c0                    // #8896
    0.00 :   ffff8000101a4688:       cbz     x0, ffff8000101a4708 <refresh_cpu_vm_stats+0x360>
    0.00 :   ffff8000101a468c:       nop
         :
    0.00 :   ffff8000101a4690:       ldr     x23, [x19, #8896]
         : 848              changes += fold_diff(global_zone_diff, global_node_diff);
         : 849              return changes;
    0.00 :   ffff8000101a4694:       add     x24, x19, x22
         :
    0.00 :   ffff8000101a4698:       mov     x25, #0x1                       // #1
    0.00 :   ffff8000101a469c:       nop
         : 849              get_current():
    0.00 :   ffff8000101a46a0:       mrs     x1, sp_el0
         : 20               __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000101a46a4:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff8000101a46a8:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000101a46ac:       str     w0, [x1, #8]
         : 50               refresh_cpu_vm_stats():
         : 851              }
         :
         : 853              /*
    0.00 :   ffff8000101a46b0:       add     x0, x23, x25
         : 855              __kern_my_cpu_offset():
    0.00 :   ffff8000101a46b4:       mrs     x2, tpidr_el1
         : 40               __xchg_case_8():
    0.00 :   ffff8000101a46b8:       add     x0, x0, x2
    0.00 :   ffff8000101a46bc:       prfm    pstl1strm, [x0]
    0.00 :   ffff8000101a46c0:       ldxrb   w26, [x0]
    0.00 :   ffff8000101a46c4:       stxrb   w4, w27, [x0]
    0.00 :   ffff8000101a46c8:       cbnz    w4, ffff8000101a46c0 <refresh_cpu_vm_stats+0x318>
         : 50               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a46cc:       sxtb    w28, w26
         : 852              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000101a46d0:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000101a46d4:       sub     x0, x0, #0x1
    0.00 :   ffff8000101a46d8:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000101a46dc:       cbnz    x0, ffff8000101a4754 <refresh_cpu_vm_stats+0x3ac>
         : 75               refresh_cpu_vm_stats():
    0.00 :   ffff8000101a46e0:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff8000101a46e4:       nop
         : 852              * Fold the data for an offline cpu into the global array.
    0.00 :   ffff8000101a46e8:       cbnz    w28, ffff8000101a4764 <refresh_cpu_vm_stats+0x3bc>
    0.00 :   ffff8000101a46ec:       add     x25, x25, #0x1
         : 848              return changes;
    0.00 :   ffff8000101a46f0:       cmp     x25, #0x28
    0.00 :   ffff8000101a46f4:       b.ne    ffff8000101a46a0 <refresh_cpu_vm_stats+0x2f8>  // b.any
         : 845              }
    0.00 :   ffff8000101a46f8:       mov     x0, x19
    0.00 :   ffff8000101a46fc:       bl      ffff8000101a2d80 <next_online_pgdat>
    0.00 :   ffff8000101a4700:       mov     x19, x0
    0.00 :   ffff8000101a4704:       cbnz    x0, ffff8000101a4690 <refresh_cpu_vm_stats+0x2e8>
         : 860              */
         : 861              void cpu_vm_stats_fold(int cpu)
         : 862              {
         : 863              struct pglist_data *pgdat;
         : 864              struct zone *zone;
         : 865              int i;
    0.00 :   ffff8000101a4708:       mov     x1, x21
    0.00 :   ffff8000101a470c:       add     x2, sp, #0xdc
    0.00 :   ffff8000101a4710:       mov     x0, x20
    0.00 :   ffff8000101a4714:       bl      ffff8000101a4288 <fold_diff>
         : 866              int global_zone_diff[NR_VM_ZONE_STAT_ITEMS] = { 0, };
         : 867              int global_node_diff[NR_VM_NODE_STAT_ITEMS] = { 0, };
         :
         : 869              for_each_populated_zone(zone) {
         : 870              struct per_cpu_zonestat *pzstats;
         :
    0.00 :   ffff8000101a4718:       ldr     x1, [sp, #128]
    0.00 :   ffff8000101a471c:       ldr     x2, [sp, #376]
    0.00 :   ffff8000101a4720:       ldr     x1, [x1]
    0.00 :   ffff8000101a4724:       eor     x1, x2, x1
    0.00 :   ffff8000101a4728:       ldr     w2, [sp, #116]
    0.00 :   ffff8000101a472c:       add     w0, w0, w2
    0.00 :   ffff8000101a4730:       cbnz    x1, ffff8000101a47a0 <refresh_cpu_vm_stats+0x3f8>
    0.00 :   ffff8000101a4734:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101a4738:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101a473c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000101a4740:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000101a4744:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000101a4748:       ldp     x29, x30, [sp], #384
    0.00 :   ffff8000101a474c:       autiasp
    0.00 :   ffff8000101a4750:       ret
         : 887              __preempt_count_dec_and_test():
    0.00 :   ffff8000101a4754:       ldr     x0, [x1, #8]
    0.00 :   ffff8000101a4758:       cbnz    x0, ffff8000101a46e8 <refresh_cpu_vm_stats+0x340>
         : 75               refresh_cpu_vm_stats():
         : 851              /*
    0.00 :   ffff8000101a475c:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff8000101a4760:       b       ffff8000101a46e8 <refresh_cpu_vm_stats+0x340>
         : 853              * There cannot be any access by the offline cpu and therefore
    0.00 :   ffff8000101a4764:       sxtb    x26, w26
    0.00 :   ffff8000101a4768:       add     x0, x24, x25, lsl #3
         : 856              arch_static_branch_jump():
    0.00 :   ffff8000101a476c:       b       ffff8000101a4790 <refresh_cpu_vm_stats+0x3e8>
    0.00 :   ffff8000101a4770:       b       ffff8000101a4790 <refresh_cpu_vm_stats+0x3e8>
         : 40               __lse_atomic64_add():
    0.00 :   ffff8000101a4774:       stadd   x26, [x0]
         : 180              refresh_cpu_vm_stats():
         : 854              * synchronization is simplified.
    0.00 :   ffff8000101a4778:       add     x0, sp, #0xdc
    0.00 :   ffff8000101a477c:       add     x1, x0, x25, lsl #2
    0.00 :   ffff8000101a4780:       ldur    w0, [x1, #-4]
    0.00 :   ffff8000101a4784:       add     w28, w0, w28
    0.00 :   ffff8000101a4788:       stur    w28, [x1, #-4]
    0.00 :   ffff8000101a478c:       b       ffff8000101a46ec <refresh_cpu_vm_stats+0x344>
         : 861              __ll_sc_atomic64_add():
    0.00 :   ffff8000101a4790:       b       ffff8000101a6c5c <quiet_vmstat+0x134>
    0.00 :   ffff8000101a4794:       b       ffff8000101a4778 <refresh_cpu_vm_stats+0x3d0>
         : 212              refresh_cpu_vm_stats():
         : 830              #endif
    0.00 :   ffff8000101a4798:       strb    wzr, [x0, x1]
         : 831              }
    0.00 :   ffff8000101a479c:       b       ffff8000101a4464 <refresh_cpu_vm_stats+0xbc>
         :
    0.00 :   ffff8000101a47a0:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101fa5f0 <alloc_pages>:
         : 6                alloc_pages():
         : 2258             policy_nodemask(gfp, pol));
         :
         : 2260             return page;
         : 2261             }
         : 2262             EXPORT_SYMBOL(alloc_pages);
         :
    0.00 :   ffff8000101fa5f0:       paciasp
    0.00 :   ffff8000101fa5f4:       stp     x29, x30, [sp, #-48]!
         : 2266             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000101fa5f8:       mrs     x3, sp_el0
         : 26               alloc_pages():
    0.00 :   ffff8000101fa5fc:       mov     x29, sp
    0.00 :   ffff8000101fa600:       stp     x19, x20, [sp, #16]
         : 2262             int vma_dup_policy(struct vm_area_struct *src, struct vm_area_struct *dst)
         : 2263             {
         : 2264             struct mempolicy *pol = mpol_dup(vma_policy(src));
         :
    0.00 :   ffff8000101fa604:       and     w5, w0, #0x200000
         :
    0.00 :   ffff8000101fa608:       mov     w20, w0
    0.00 :   ffff8000101fa60c:       str     x21, [sp, #32]
    0.00 :   ffff8000101fa610:       mov     w19, w1
         : 2262             preempt_count():
         : 12               #define PREEMPT_NEED_RESCHED    BIT(32)
         : 13               #define PREEMPT_ENABLED (PREEMPT_NEED_RESCHED)
         :
         : 15               static inline int preempt_count(void)
         : 16               {
         : 17               return READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000101fa614:       ldr     w2, [x3, #8]
    0.00 :   ffff8000101fa618:       ldr     w4, [x3, #8]
  100.00 :   ffff8000101fa61c:       ldr     w0, [x3, #8]
         : 21               alloc_pages():
         :
    0.00 :   ffff8000101fa620:       and     w2, w2, #0xf00000
    0.00 :   ffff8000101fa624:       and     w4, w4, #0xf0000
    0.00 :   ffff8000101fa628:       and     w0, w0, #0xff00
    0.00 :   ffff8000101fa62c:       orr     w2, w2, w4
    0.00 :   ffff8000101fa630:       orr     w0, w0, w5
    0.00 :   ffff8000101fa634:       orr     w2, w2, w0
    0.00 :   ffff8000101fa638:       cbnz    w2, ffff8000101fa6a0 <alloc_pages+0xb0>
         : 2270             get_task_policy():
         : 158              int node;
    0.00 :   ffff8000101fa63c:       ldr     x4, [x3, #2168]
         : 161              return pol;
    0.00 :   ffff8000101fa640:       cbz     x4, ffff8000101fa6f4 <alloc_pages+0x104>
         : 163              alloc_pages():
         : 2269             return PTR_ERR(pol);
         : 2270             dst->vm_policy = pol;
         : 2271             return 0;
         : 2272             }
         :
         : 2274             /*
    0.00 :   ffff8000101fa644:       ldrh    w0, [x4, #4]
    0.00 :   ffff8000101fa648:       cmp     w0, #0x3
    0.00 :   ffff8000101fa64c:       b.eq    ffff8000101fa6b4 <alloc_pages+0xc4>  // b.none
         : 2278             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000101fa650:       mrs     x2, tpidr_el1
         : 46               numa_node_id():
         :
         : 90               #ifndef numa_node_id
         : 91               /* Returns the number of the current Node. */
         : 92               static inline int numa_node_id(void)
         : 93               {
         : 94               return raw_cpu_read(numa_node);
    0.00 :   ffff8000101fa654:       adrp    x0, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000101fa658:       add     x0, x0, #0x610
         : 97               alloc_pages():
         : 2272             * If mpol_dup() sees current->cpuset == cpuset_being_rebound, then it
         : 2273             * rebinds the mempolicy its copying by calling mpol_rebind_policy()
         : 2274             * with the mems_allowed returned by cpuset_mems_allowed().  This
    0.00 :   ffff8000101fa65c:       ldr     w2, [x0, x2]
    0.00 :   ffff8000101fa660:       mov     x1, x4
    0.00 :   ffff8000101fa664:       mov     w0, w20
    0.00 :   ffff8000101fa668:       bl      ffff8000101f7860 <policy_node>
    0.00 :   ffff8000101fa66c:       mov     w21, w0
    0.00 :   ffff8000101fa670:       mov     w0, w20
    0.00 :   ffff8000101fa674:       bl      ffff8000101fa1d0 <policy_nodemask>
    0.00 :   ffff8000101fa678:       mov     w2, w21
    0.00 :   ffff8000101fa67c:       mov     x3, x0
    0.00 :   ffff8000101fa680:       mov     w1, w19
    0.00 :   ffff8000101fa684:       mov     w0, w20
    0.00 :   ffff8000101fa688:       bl      ffff8000101dd7a8 <__alloc_pages>
         : 2277             * keeps mempolicies cpuset relative after its cpuset moves.  See
         : 2278             * further kernel/cpuset.c update_nodemask().
         : 2279             *
         : 2280             * current's mempolicy may be rebinded by the other task(the task that changes
         : 2281             * cpuset's mems), so we needn't do rebind work for current task.
    0.00 :   ffff8000101fa68c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101fa690:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101fa694:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101fa698:       autiasp
    0.00 :   ffff8000101fa69c:       ret
         : 2259             int vma_dup_policy(struct vm_area_struct *src, struct vm_area_struct *dst)
    0.00 :   ffff8000101fa6a0:       adrp    x4, ffff800011cbd000 <init_mm+0x230>
    0.00 :   ffff8000101fa6a4:       add     x4, x4, #0x4c8
         : 2269             /*
    0.00 :   ffff8000101fa6a8:       ldrh    w0, [x4, #4]
    0.00 :   ffff8000101fa6ac:       cmp     w0, #0x3
    0.00 :   ffff8000101fa6b0:       b.ne    ffff8000101fa650 <alloc_pages+0x60>  // b.any
         : 2273             get_current():
    0.00 :   ffff8000101fa6b4:       mrs     x21, sp_el0
         : 20               interleave_nodes():
         : 1917             /*
    0.00 :   ffff8000101fa6b8:       ldrsh   w0, [x21, #2176]
    0.00 :   ffff8000101fa6bc:       add     x1, x4, #0x8
    0.00 :   ffff8000101fa6c0:       bl      ffff8000104b11e0 <__next_node_in>
         : 1918             * Depending on the memory policy provide a node from which to allocate the
    0.00 :   ffff8000101fa6c4:       cmp     w0, #0xf
    0.00 :   ffff8000101fa6c8:       b.hi    ffff8000101fa6d0 <alloc_pages+0xe0>  // b.pmore
         : 1919             * next slab entry.
    0.00 :   ffff8000101fa6cc:       strh    w0, [x21, #2176]
         : 1921             alloc_pages():
         : 2270             * If mpol_dup() sees current->cpuset == cpuset_being_rebound, then it
    0.00 :   ffff8000101fa6d0:       mov     w2, w0
    0.00 :   ffff8000101fa6d4:       mov     w1, w19
    0.00 :   ffff8000101fa6d8:       mov     w0, w20
    0.00 :   ffff8000101fa6dc:       bl      ffff8000101f77b0 <alloc_page_interleave>
         : 2277             * cpuset's mems), so we needn't do rebind work for current task.
    0.00 :   ffff8000101fa6e0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101fa6e4:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101fa6e8:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101fa6ec:       autiasp
    0.00 :   ffff8000101fa6f0:       ret
         : 2283             get_task_policy():
    0.00 :   ffff8000101fa6f4:       bl      ffff8000101f7db0 <get_task_policy.part.48>
    0.00 :   ffff8000101fa6f8:       mov     x4, x0
    0.00 :   ffff8000101fa6fc:       b       ffff8000101fa644 <alloc_pages+0x54>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001016cd58 <perf_pmu_enable>:
         : 6                perf_pmu_enable():
         : 1203             int *count = this_cpu_ptr(pmu->pmu_disable_count);
         : 1204             if (!(*count)++)
         : 1205             pmu->pmu_disable(pmu);
         : 1206             }
         :
         : 1208             void perf_pmu_enable(struct pmu *pmu)
    0.00 :   ffff80001016cd58:       paciasp
    0.00 :   ffff80001016cd5c:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001016cd60:       mov     x29, sp
         : 1212             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001016cd64:       mrs     x4, tpidr_el1
         : 46               perf_pmu_enable():
         : 1204             {
    0.00 :   ffff80001016cd68:       ldr     x1, [x0, #64]
         : 1205             int *count = this_cpu_ptr(pmu->pmu_disable_count);
    0.00 :   ffff80001016cd6c:       ldr     w2, [x1, x4]
    0.00 :   ffff80001016cd70:       sub     w2, w2, #0x1
    0.00 :   ffff80001016cd74:       str     w2, [x1, x4]
    0.00 :   ffff80001016cd78:       cbnz    w2, ffff80001016cd84 <perf_pmu_enable+0x2c>
         : 1206             if (!--(*count))
    0.00 :   ffff80001016cd7c:       ldr     x1, [x0, #96]
    0.00 :   ffff80001016cd80:       blr     x1
         : 1207             pmu->pmu_enable(pmu);
    0.00 :   ffff80001016cd84:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001016cd88:       autiasp
  100.00 :   ffff80001016cd8c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010100b70 <note_gp_changes>:
         : 6                note_gp_changes():
         : 1718             EXPORT_SYMBOL_GPL(rcu_gp_set_torture_wait);
         :
         : 1720             /* Actually implement the aforementioned wait. */
         : 1721             static void rcu_gp_torture_wait(void)
         : 1722             {
         : 1723             unsigned long duration;
    0.00 :   ffff800010100b70:       paciasp
    0.00 :   ffff800010100b74:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010100b78:       mov     x29, sp
    0.00 :   ffff800010100b7c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010100b80:       str     x21, [sp, #32]
         : 1729             arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010100b84:       mrs     x21, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010100b88:       and     w1, w21, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff800010100b8c:       cbz     w1, ffff800010100c1c <note_gp_changes+0xac>
         : 118              note_gp_changes():
         :
         : 1725             if (!IS_ENABLED(CONFIG_RCU_TORTURE_TEST))
         : 1726             return;
         : 1727             duration = xchg(&sleep_duration, 0UL);
         : 1728             if (duration > 0) {
         : 1729             pr_alert("%s: Waiting %lu jiffies\n", __func__, duration);
    0.00 :   ffff800010100b90:       ldr     x20, [x0, #24]
         : 1725             schedule_timeout_idle(duration);
    0.00 :   ffff800010100b94:       ldr     x2, [x0]
         : 1727             rcu_seq_current():
         : 99               }
         :
         : 101              /* Return the current value the update side's sequence number, no ordering. */
         : 102              static inline unsigned long rcu_seq_current(unsigned long *sp)
         : 103              {
         : 104              return READ_ONCE(*sp);
    0.00 :   ffff800010100b98:       ldr     x1, [x20, #8]
         : 106              note_gp_changes():
    0.00 :   ffff800010100b9c:       cmp     x2, x1
    0.00 :   ffff800010100ba0:       b.ne    ffff800010100bcc <note_gp_changes+0x5c>  // b.any
         : 1726             pr_alert("%s: Wait complete\n", __func__);
    0.00 :   ffff800010100ba4:       ldrb    w1, [x0, #20]
         : 1725             schedule_timeout_idle(duration);
    0.00 :   ffff800010100ba8:       tst     w1, #0xff
    0.00 :   ffff800010100bac:       b.ne    ffff800010100bcc <note_gp_changes+0x5c>  // b.any
         : 1728             arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff800010100bb0:       msr     daif, x21
         : 129              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010100bb4:       nop
         : 28               note_gp_changes():
         : 1736             * Handler for on_each_cpu() to invoke the target CPU's RCU core
         : 1737             * processing.
         : 1738             */
         : 1739             static void rcu_strict_gp_boundary(void *unused)
         : 1740             {
         : 1741             invoke_rcu_core();
    0.00 :   ffff800010100bb8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010100bbc:       ldr     x21, [sp, #32]
    0.00 :   ffff800010100bc0:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010100bc4:       autiasp
    0.00 :   ffff800010100bc8:       ret
         : 1727             }
    0.00 :   ffff800010100bcc:       mov     x19, x0
    0.00 :   ffff800010100bd0:       mov     x0, x20
    0.00 :   ffff800010100bd4:       bl      ffff800010e34eb0 <_raw_spin_trylock>
         : 1726             pr_alert("%s: Wait complete\n", __func__);
    0.00 :   ffff800010100bd8:       cbz     w0, ffff800010100bb0 <note_gp_changes+0x40>
         : 1731             * Handler for on_each_cpu() to invoke the target CPU's RCU core
    0.00 :   ffff800010100bdc:       mov     x1, x19
    0.00 :   ffff800010100be0:       mov     x0, x20
    0.00 :   ffff800010100be4:       bl      ffff8000101009b0 <__note_gp_changes>
    0.00 :   ffff800010100be8:       and     w19, w0, #0xff
         : 1732             * processing.
    0.00 :   ffff800010100bec:       mov     x1, x21
    0.00 :   ffff800010100bf0:       mov     x0, x20
    0.00 :   ffff800010100bf4:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1734             static void rcu_strict_gp_boundary(void *unused)
    0.00 :   ffff800010100bf8:       cbz     w19, ffff800010100bb8 <note_gp_changes+0x48>
         : 1735             {
    0.00 :   ffff800010100bfc:       bl      ffff8000100fdb58 <rcu_gp_kthread_wake>
    0.00 :   ffff800010100c00:       b       ffff800010100bb8 <note_gp_changes+0x48>
         : 1738             arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff800010100c04:       dsb     sy
         : 137              note_gp_changes():
         : 1736             invoke_rcu_core();
  100.00 :   ffff800010100c08:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010100c0c:       ldr     x21, [sp, #32]
    0.00 :   ffff800010100c10:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010100c14:       autiasp
    0.00 :   ffff800010100c18:       ret
         : 1742             arch_static_branch():
    0.00 :   ffff800010100c1c:       nop
    0.00 :   ffff800010100c20:       mov     x1, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010100c24:       msr     daifset, #0x3
    0.00 :   ffff800010100c28:       b       ffff800010100b90 <note_gp_changes+0x20>
         : 57               arch_static_branch():
    0.00 :   ffff800010100c2c:       mov     x1, #0xa0                       // #160
    0.00 :   ffff800010100c30:       b       ffff800010100c24 <note_gp_changes+0xb4>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000102204c0 <__mod_memcg_state.part.87>:
         : 6                __mod_memcg_state():
         : 640              * @idx: the stat item - can be enum memcg_stat_item or enum node_stat_item
         : 641              * @val: delta to add to the counter, can be negative
         : 642              */
         : 643              void __mod_memcg_state(struct mem_cgroup *memcg, int idx, int val)
         : 644              {
         : 645              if (mem_cgroup_disabled())
    0.00 :   ffff8000102204c0:       paciasp
    0.00 :   ffff8000102204c4:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff8000102204c8:       mov     x29, sp
         : 645              return;
         :
         : 647              __this_cpu_add(memcg->vmstats_percpu->state[idx], val);
         : 648              cgroup_rstat_updated(memcg->css.cgroup, smp_processor_id());
         : 649              }
    0.00 :   ffff8000102204cc:       ldr     x5, [x0, #3600]
         : 651              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000102204d0:       mrs     x4, tpidr_el1
         : 46               __mod_memcg_state():
         :
    0.00 :   ffff8000102204d4:       adrp    x3, ffff80001176d000 <cpu_number>
    0.00 :   ffff8000102204d8:       add     x3, x3, #0x0
         : 645              }
    0.00 :   ffff8000102204dc:       add     x1, x5, w1, sxtw #3
    0.00 :   ffff8000102204e0:       ldr     x5, [x1, x4]
    0.00 :   ffff8000102204e4:       add     x2, x5, w2, sxtw
    0.00 :   ffff8000102204e8:       str     x2, [x1, x4]
         : 650              __kern_my_cpu_offset():
    0.00 :   ffff8000102204ec:       mrs     x1, tpidr_el1
         : 40               __mod_memcg_state():
         :
    0.00 :   ffff8000102204f0:       ldr     w1, [x3, x1]
    0.00 :   ffff8000102204f4:       ldr     x0, [x0]
    0.00 :   ffff8000102204f8:       bl      ffff80001013ecd8 <cgroup_rstat_updated>
         : 647              /* idx can be of type enum memcg_stat_item or node_stat_item. */
  100.00 :   ffff8000102204fc:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010220500:       autiasp
    0.00 :   ffff800010220504:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010233098 <vfs_write>:
         : 6                vfs_write():
         : 586              return ret;
         : 587              }
         : 588              EXPORT_SYMBOL(kernel_write);
         :
         : 590              ssize_t vfs_write(struct file *file, const char __user *buf, size_t count, loff_t *pos)
         : 591              {
    0.00 :   ffff800010233098:       paciasp
    0.00 :   ffff80001023309c:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff8000102330a0:       mov     x29, sp
    0.00 :   ffff8000102330a4:       stp     x21, x22, [sp, #32]
         : 589              ssize_t ret;
         :
         : 591              if (!(file->f_mode & FMODE_WRITE))
    0.00 :   ffff8000102330a8:       ldr     w4, [x0, #68]
    0.00 :   ffff8000102330ac:       tbz     w4, #1, ffff80001023341c <vfs_write+0x384>
         : 591              return -EBADF;
         : 592              if (!(file->f_mode & FMODE_CAN_WRITE))
    0.00 :   ffff8000102330b0:       tbz     w4, #18, ffff8000102333a4 <vfs_write+0x30c>
         : 594              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000102330b4:       mrs     x4, sp_el0
         : 26               __range_ok():
         : 47               * Asynchronous I/O running in a kernel thread does not have the
         : 48               * TIF_TAGGED_ADDR flag of the process owning the mm, so always untag
         : 49               * the user address before checking.
         : 50               */
         : 51               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
         : 52               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff8000102330b8:       ldr     w5, [x4, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff8000102330bc:       tbz     w5, #21, ffff8000102331b8 <vfs_write+0x120>
         : 48               sign_extend64():
         : 182              * @index: 0 based bit index (0<=index<64) to sign bit
         : 183              */
         : 184              static __always_inline __s64 sign_extend64(__u64 value, int index)
         : 185              {
         : 186              __u8 shift = 63 - index;
         : 187              return (__s64)(value << shift) >> shift;
    0.00 :   ffff8000102330c0:       sbfx    x4, x1, #0, #56
         : 189              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff8000102330c4:       and     x4, x1, x4
         :
         : 52               __chk_user_ptr(addr);
         : 53               asm volatile(
    0.00 :   ffff8000102330c8:       mov     x5, #0xffffffffffff             // #281474976710655
    0.00 :   ffff8000102330cc:       adds    x4, x4, x2
    0.00 :   ffff8000102330d0:       csel    x5, xzr, x5, hi  // hi = pmore
    0.00 :   ffff8000102330d4:       csinv   x4, x4, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff8000102330d8:       sbcs    xzr, x4, x5
    0.00 :   ffff8000102330dc:       cset    x4, ls  // ls = plast
         : 60               vfs_write():
         : 593              return -EINVAL;
         : 594              if (unlikely(!access_ok(buf, count)))
    0.00 :   ffff8000102330e0:       cbz     x4, ffff800010233348 <vfs_write+0x2b0>
         : 596              return -EFAULT;
         :
         : 598              ret = rw_verify_area(WRITE, file, pos, count);
    0.00 :   ffff8000102330e4:       mov     x22, x3
    0.00 :   ffff8000102330e8:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000102330ec:       mov     x20, x0
    0.00 :   ffff8000102330f0:       mov     x3, x2
    0.00 :   ffff8000102330f4:       mov     x19, x2
    0.00 :   ffff8000102330f8:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000102330fc:       mov     x2, x22
    0.00 :   ffff800010233100:       str     x23, [sp, #48]
    0.00 :   ffff800010233104:       mov     x23, x1
    0.00 :   ffff800010233108:       mov     x1, x20
    0.00 :   ffff80001023310c:       bl      ffff8000102315a8 <rw_verify_area>
    0.00 :   ffff800010233110:       sxtw    x21, w0
         : 597              if (ret)
    0.00 :   ffff800010233114:       cbnz    x21, ffff80001023319c <vfs_write+0x104>
         : 599              file_start_write():
         : 3033             {
         : 3034             return (inode->i_mode & S_IXUGO) || S_ISDIR(inode->i_mode);
         : 3035             }
         :
         : 3037             static inline bool inode_wrong_type(const struct inode *inode, umode_t mode)
         : 3038             {
    0.00 :   ffff800010233118:       ldr     x1, [x20, #32]
    0.00 :   ffff80001023311c:       mov     x2, #0x7ffff000                 // #2147479552
    0.00 :   ffff800010233120:       cmp     x19, x2
    0.00 :   ffff800010233124:       csel    x2, x19, x2, ls  // ls = plast
    0.00 :   ffff800010233128:       ldrh    w0, [x1]
    0.00 :   ffff80001023312c:       and     w0, w0, #0xf000
    0.00 :   ffff800010233130:       cmp     w0, #0x8, lsl #12
    0.00 :   ffff800010233134:       b.eq    ffff80001023324c <vfs_write+0x1b4>  // b.none
         : 3047             vfs_write():
         : 602              return ret;
         : 603              if (count > MAX_RW_COUNT)
         : 604              count =  MAX_RW_COUNT;
         : 605              file_start_write(file);
         : 606              if (file->f_op->write)
    0.00 :   ffff800010233138:       ldr     x0, [x20, #40]
    0.00 :   ffff80001023313c:       ldr     x4, [x0, #24]
    0.00 :   ffff800010233140:       cbz     x4, ffff8000102332d8 <vfs_write+0x240>
         : 603              ret = file->f_op->write(file, buf, count, pos);
    0.00 :   ffff800010233144:       mov     x3, x22
    0.00 :   ffff800010233148:       mov     x1, x23
    0.00 :   ffff80001023314c:       mov     x0, x20
    0.00 :   ffff800010233150:       blr     x4
    0.00 :   ffff800010233154:       mov     x21, x0
         : 608              else if (file->f_op->write_iter)
         : 609              ret = new_sync_write(file, buf, count, pos);
         : 610              else
         : 611              ret = -EINVAL;
         : 612              if (ret > 0) {
    0.00 :   ffff800010233158:       cmp     x21, #0x0
    0.00 :   ffff80001023315c:       b.le    ffff800010233178 <vfs_write+0xe0>
         : 615              fsnotify_file():
         :
         : 88               static inline int fsnotify_file(struct file *file, __u32 mask)
         : 89               {
         : 90               const struct path *path = &file->f_path;
         :
         : 92               if (file->f_mode & FMODE_NONOTIFY)
    0.00 :   ffff800010233160:       ldr     w0, [x20, #68]
    0.00 :   ffff800010233164:       tbz     w0, #26, ffff8000102332fc <vfs_write+0x264>
         : 95               get_current():
    0.00 :   ffff800010233168:       mrs     x1, sp_el0
         : 20               add_wchar():
         : 19               tsk->ioac.rchar += amt;
         : 20               }
         :
         : 22               static inline void add_wchar(struct task_struct *tsk, ssize_t amt)
         : 23               {
         : 24               tsk->ioac.wchar += amt;
    0.00 :   ffff80001023316c:       ldr     x0, [x1, #1904]
    0.00 :   ffff800010233170:       add     x0, x0, x21
    0.00 :   ffff800010233174:       str     x0, [x1, #1904]
         : 28               get_current():
    0.00 :   ffff800010233178:       mrs     x1, sp_el0
         : 20               inc_syscw():
         : 29               tsk->ioac.syscr++;
         : 30               }
         :
         : 32               static inline void inc_syscw(struct task_struct *tsk)
         : 33               {
         : 34               tsk->ioac.syscw++;
    0.00 :   ffff80001023317c:       ldr     x0, [x1, #1920]
    0.00 :   ffff800010233180:       add     x0, x0, #0x1
    0.00 :   ffff800010233184:       str     x0, [x1, #1920]
         : 38               file_end_write():
         : 3047             }
         :
         : 3049             static inline bool file_start_write_trylock(struct file *file)
         : 3050             {
         : 3051             if (!S_ISREG(file_inode(file)->i_mode))
         : 3052             return true;
    0.00 :   ffff800010233188:       ldr     x2, [x20, #32]
    0.00 :   ffff80001023318c:       ldrh    w0, [x2]
    0.00 :   ffff800010233190:       and     w0, w0, #0xf000
    0.00 :   ffff800010233194:       cmp     w0, #0x8, lsl #12
    0.00 :   ffff800010233198:       b.eq    ffff8000102331cc <vfs_write+0x134>  // b.none
    0.00 :   ffff80001023319c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000102331a0:       ldr     x23, [sp, #48]
         : 3060             vfs_write():
         : 615              add_wchar(current, ret);
         : 616              }
         : 617              inc_syscw(current);
         : 618              file_end_write(file);
         : 619              return ret;
         : 620              }
    0.00 :   ffff8000102331a4:       mov     x0, x21
    0.00 :   ffff8000102331a8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102331ac:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000102331b0:       autiasp
    0.00 :   ffff8000102331b4:       ret
         : 626              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000102331b8:       ldr     x5, [x4]
         : 113              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff8000102331bc:       mov     x4, x1
    0.00 :   ffff8000102331c0:       tst     w5, #0x4000000
    0.00 :   ffff8000102331c4:       b.eq    ffff8000102330c8 <vfs_write+0x30>  // b.none
    0.00 :   ffff8000102331c8:       b       ffff8000102330c0 <vfs_write+0x28>
         : 51               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000102331cc:       ldr     w3, [x1, #8]
         : 53               file_end_write():
         : 3049             return sb_start_write_trylock(file_inode(file)->i_sb);
         : 3050             }
    0.00 :   ffff8000102331d0:       ldr     x19, [x2, #40]
         : 3052             __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff8000102331d4:       add     w2, w3, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000102331d8:       str     w2, [x1, #8]
         : 50               rcu_sync_is_idle():
         : 36               */
         : 37               static inline bool rcu_sync_is_idle(struct rcu_sync *rsp)
         : 38               {
         : 39               RCU_LOCKDEP_WARN(!rcu_read_lock_any_held(),
         : 40               "suspicious rcu_sync_is_idle() usage");
         : 41               return !READ_ONCE(rsp->gp_state); /* GP_IDLE */
    0.00 :   ffff8000102331dc:       ldr     w0, [x19, #592]
    0.00 :   ffff8000102331e0:       add     x2, x19, #0x250
         : 44               percpu_up_read():
         :
         : 106              preempt_disable();
         : 107              /*
         : 108              * Same as in percpu_down_read().
         : 109              */
         : 110              if (likely(rcu_sync_is_idle(&sem->rss))) {
    0.00 :   ffff8000102331e4:       cbnz    w0, ffff8000102333c0 <vfs_write+0x328>
         : 112              __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000102331e8:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff8000102331ec:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000102331f0:       str     w0, [x1, #8]
         : 50               __percpu_add_case_32():
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
         : 131              PERCPU_OP(add, add, stadd)
    0.00 :   ffff8000102331f4:       mov     w3, #0xffffffff                 // #-1
         : 133              percpu_up_read():
         : 106              this_cpu_dec(*sem->read_count);
    0.00 :   ffff8000102331f8:       ldr     x0, [x2, #48]
         : 108              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000102331fc:       mrs     x2, tpidr_el1
         : 41               __percpu_add_case_32():
         : 126              PERCPU_OP(add, add, stadd)
    0.00 :   ffff800010233200:       add     x0, x0, x2
    0.00 :   ffff800010233204:       ldxr    w5, [x0]
    0.00 :   ffff800010233208:       add     w5, w5, w3
    0.00 :   ffff80001023320c:       stxr    w4, w5, [x0]
    0.00 :   ffff800010233210:       cbnz    w4, ffff800010233204 <vfs_write+0x16c>
         : 132              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010233214:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010233218:       sub     x0, x0, #0x1
    0.00 :   ffff80001023321c:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010233220:       cbnz    x0, ffff800010233338 <vfs_write+0x2a0>
         : 80               percpu_up_read():
    0.00 :   ffff800010233224:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         : 107              get_current():
    0.00 :   ffff800010233228:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001023322c:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010233230:       sub     x0, x0, #0x1
    0.00 :   ffff800010233234:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010233238:       cbnz    x0, ffff80001023335c <vfs_write+0x2c4>
         : 75               percpu_up_read():
         : 121              * will also see our critical section.
         : 122              */
         : 123              this_cpu_dec(*sem->read_count);
         : 124              rcuwait_wake_up(&sem->writer);
         : 125              }
         : 126              preempt_enable();
    0.00 :   ffff80001023323c:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010233240:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010233244:       ldr     x23, [sp, #48]
    0.00 :   ffff800010233248:       b       ffff8000102331a4 <vfs_write+0x10c>
         : 131              get_current():
    0.00 :   ffff80001023324c:       mrs     x3, sp_el0
         : 20               __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010233250:       ldr     w4, [x3, #8]
         : 48               file_start_write():
         : 3035             }
    0.00 :   ffff800010233254:       ldr     x0, [x1, #40]
         : 3037             __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff800010233258:       add     w1, w4, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff80001023325c:       str     w1, [x3, #8]
         : 50               rcu_sync_is_idle():
    0.00 :   ffff800010233260:       ldr     w1, [x0, #592]
    0.00 :   ffff800010233264:       add     x0, x0, #0x250
         : 38               percpu_down_read():
         : 62               if (likely(rcu_sync_is_idle(&sem->rss)))
    0.00 :   ffff800010233268:       cbnz    w1, ffff8000102333ac <vfs_write+0x314>
         : 64               __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff80001023326c:       ldr     w1, [x3, #8]
         : 47               pc += val;
    0.00 :   ffff800010233270:       add     w1, w1, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010233274:       str     w1, [x3, #8]
         : 50               __percpu_add_case_32():
    0.00 :   ffff800010233278:       mov     w4, #0x1                        // #1
         : 127              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001023327c:       mrs     x1, tpidr_el1
         : 41               percpu_down_read():
         : 63               this_cpu_inc(*sem->read_count);
    0.00 :   ffff800010233280:       ldr     x0, [x0, #48]
         : 65               __percpu_add_case_32():
         : 126              PERCPU_OP(add, add, stadd)
    0.00 :   ffff800010233284:       add     x0, x0, x1
    0.00 :   ffff800010233288:       ldxr    w6, [x0]
    0.00 :   ffff80001023328c:       add     w6, w6, w4
    0.00 :   ffff800010233290:       stxr    w5, w6, [x0]
    0.00 :   ffff800010233294:       cbnz    w5, ffff800010233288 <vfs_write+0x1f0>
         : 132              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010233298:       ldr     x0, [x3, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001023329c:       sub     x0, x0, #0x1
    0.00 :   ffff8000102332a0:       str     w0, [x3, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102332a4:       cbnz    x0, ffff800010233368 <vfs_write+0x2d0>
    0.00 :   ffff8000102332a8:       str     x2, [sp, #72]
         : 76               percpu_down_read():
    0.00 :   ffff8000102332ac:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff8000102332b0:       ldr     x2, [sp, #72]
         : 65               get_current():
    0.00 :   ffff8000102332b4:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102332b8:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000102332bc:       sub     x0, x0, #0x1
    0.00 :   ffff8000102332c0:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102332c4:       cbnz    x0, ffff800010233350 <vfs_write+0x2b8>
    0.00 :   ffff8000102332c8:       str     x2, [sp, #72]
         : 76               percpu_down_read():
         : 70               preempt_enable();
    0.00 :   ffff8000102332cc:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff8000102332d0:       ldr     x2, [sp, #72]
    0.00 :   ffff8000102332d4:       b       ffff800010233138 <vfs_write+0xa0>
         : 74               vfs_write():
         : 604              else if (file->f_op->write_iter)
    0.00 :   ffff8000102332d8:       ldr     x0, [x0, #40]
         : 607              ret = -EINVAL;
    0.00 :   ffff8000102332dc:       mov     x21, #0xffffffffffffffea        // #-22
         : 604              else if (file->f_op->write_iter)
    0.00 :   ffff8000102332e0:       cbz     x0, ffff800010233178 <vfs_write+0xe0>
         : 605              ret = new_sync_write(file, buf, count, pos);
    0.00 :   ffff8000102332e4:       mov     x3, x22
    0.00 :   ffff8000102332e8:       mov     x1, x23
    0.00 :   ffff8000102332ec:       mov     x0, x20
    0.00 :   ffff8000102332f0:       bl      ffff800010230e10 <new_sync_write>
    0.00 :   ffff8000102332f4:       mov     x21, x0
    0.00 :   ffff8000102332f8:       b       ffff800010233158 <vfs_write+0xc0>
         : 612              fsnotify_file():
         : 90               return 0;
         :
         : 92               return fsnotify_parent(path->dentry, mask, path, FSNOTIFY_EVENT_PATH);
  100.00 :   ffff8000102332fc:       ldr     x0, [x20, #24]
         : 85               const struct path *path = &file->f_path;
    0.00 :   ffff800010233300:       add     x2, x20, #0x10
         : 87               fsnotify_parent():
         : 56               if (S_ISDIR(inode->i_mode)) {
    0.00 :   ffff800010233304:       mov     w4, #0x2                        // #2
         : 54               struct inode *inode = d_inode(dentry);
    0.00 :   ffff800010233308:       ldr     x5, [x0, #48]
         : 56               if (S_ISDIR(inode->i_mode)) {
    0.00 :   ffff80001023330c:       ldrh    w3, [x5]
    0.00 :   ffff800010233310:       and     w3, w3, #0xf000
    0.00 :   ffff800010233314:       cmp     w3, #0x4, lsl #12
    0.00 :   ffff800010233318:       b.eq    ffff800010233374 <vfs_write+0x2dc>  // b.none
         : 65               if (IS_ROOT(dentry))
    0.00 :   ffff80001023331c:       ldr     x1, [x0, #24]
    0.00 :   ffff800010233320:       cmp     x0, x1
    0.00 :   ffff800010233324:       b.eq    ffff800010233384 <vfs_write+0x2ec>  // b.none
         : 68               return __fsnotify_parent(dentry, mask, data, data_type);
    0.00 :   ffff800010233328:       mov     w1, w4
    0.00 :   ffff80001023332c:       mov     w3, #0x1                        // #1
    0.00 :   ffff800010233330:       bl      ffff800010289320 <__fsnotify_parent>
    0.00 :   ffff800010233334:       b       ffff800010233168 <vfs_write+0xd0>
         : 73               __preempt_count_dec_and_test():
    0.00 :   ffff800010233338:       ldr     x0, [x1, #8]
    0.00 :   ffff80001023333c:       cbnz    x0, ffff800010233228 <vfs_write+0x190>
         : 75               percpu_up_read():
         : 106              this_cpu_dec(*sem->read_count);
    0.00 :   ffff800010233340:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010233344:       b       ffff800010233228 <vfs_write+0x190>
         : 109              vfs_write():
         : 594              return -EFAULT;
    0.00 :   ffff800010233348:       mov     x21, #0xfffffffffffffff2        // #-14
    0.00 :   ffff80001023334c:       b       ffff8000102331a4 <vfs_write+0x10c>
         : 597              __preempt_count_dec_and_test():
    0.00 :   ffff800010233350:       ldr     x0, [x1, #8]
    0.00 :   ffff800010233354:       cbz     x0, ffff8000102332c8 <vfs_write+0x230>
    0.00 :   ffff800010233358:       b       ffff800010233138 <vfs_write+0xa0>
    0.00 :   ffff80001023335c:       ldr     x0, [x1, #8]
    0.00 :   ffff800010233360:       cbz     x0, ffff80001023323c <vfs_write+0x1a4>
    0.00 :   ffff800010233364:       b       ffff80001023319c <vfs_write+0x104>
    0.00 :   ffff800010233368:       ldr     x0, [x3, #8]
    0.00 :   ffff80001023336c:       cbz     x0, ffff8000102332a8 <vfs_write+0x210>
    0.00 :   ffff800010233370:       b       ffff8000102332b4 <vfs_write+0x21c>
         : 82               fsnotify_parent():
         : 60               if (!(dentry->d_flags & DCACHE_FSNOTIFY_PARENT_WATCHED))
    0.00 :   ffff800010233374:       ldr     w1, [x0]
         : 57               mask |= FS_ISDIR;
    0.00 :   ffff800010233378:       mov     w4, #0x2                        // #2
    0.00 :   ffff80001023337c:       movk    w4, #0x4000, lsl #16
         : 60               if (!(dentry->d_flags & DCACHE_FSNOTIFY_PARENT_WATCHED))
    0.00 :   ffff800010233380:       tbnz    w1, #14, ffff80001023331c <vfs_write+0x284>
         : 71               return fsnotify(mask, data, data_type, NULL, NULL, inode, 0);
    0.00 :   ffff800010233384:       mov     x1, x2
    0.00 :   ffff800010233388:       mov     w0, w4
    0.00 :   ffff80001023338c:       mov     w6, #0x0                        // #0
    0.00 :   ffff800010233390:       mov     x4, #0x0                        // #0
    0.00 :   ffff800010233394:       mov     x3, #0x0                        // #0
    0.00 :   ffff800010233398:       mov     w2, #0x1                        // #1
    0.00 :   ffff80001023339c:       bl      ffff800010288e60 <fsnotify>
    0.00 :   ffff8000102333a0:       b       ffff800010233168 <vfs_write+0xd0>
         : 80               vfs_write():
         : 592              return -EINVAL;
    0.00 :   ffff8000102333a4:       mov     x21, #0xffffffffffffffea        // #-22
    0.00 :   ffff8000102333a8:       b       ffff8000102331a4 <vfs_write+0x10c>
         : 595              percpu_down_read():
         : 65               __percpu_down_read(sem, false); /* Unconditional memory barrier */
    0.00 :   ffff8000102333ac:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000102333b0:       str     x2, [sp, #72]
    0.00 :   ffff8000102333b4:       bl      ffff8000100da740 <__percpu_down_read>
    0.00 :   ffff8000102333b8:       ldr     x2, [sp, #72]
    0.00 :   ffff8000102333bc:       b       ffff8000102332b4 <vfs_write+0x21c>
         : 71               percpu_up_read():
         : 112              smp_mb(); /* B matches C */
    0.00 :   ffff8000102333c0:       dmb     ish
         : 114              __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff8000102333c4:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff8000102333c8:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff8000102333cc:       str     w0, [x1, #8]
         : 50               __percpu_add_case_32():
    0.00 :   ffff8000102333d0:       mov     w3, #0xffffffff                 // #-1
         : 127              percpu_up_read():
         : 118              this_cpu_dec(*sem->read_count);
    0.00 :   ffff8000102333d4:       ldr     x0, [x2, #48]
         : 120              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000102333d8:       mrs     x2, tpidr_el1
         : 41               __percpu_add_case_32():
         : 126              PERCPU_OP(add, add, stadd)
    0.00 :   ffff8000102333dc:       add     x0, x0, x2
    0.00 :   ffff8000102333e0:       ldxr    w5, [x0]
    0.00 :   ffff8000102333e4:       add     w5, w5, w3
    0.00 :   ffff8000102333e8:       stxr    w4, w5, [x0]
    0.00 :   ffff8000102333ec:       cbnz    w4, ffff8000102333e0 <vfs_write+0x348>
         : 132              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102333f0:       ldr     x0, [x1, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff8000102333f4:       sub     x0, x0, #0x1
    0.00 :   ffff8000102333f8:       str     w0, [x1, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff8000102333fc:       cbnz    x0, ffff800010233410 <vfs_write+0x378>
         : 75               percpu_up_read():
    0.00 :   ffff800010233400:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         : 119              rcuwait_wake_up(&sem->writer);
    0.00 :   ffff800010233404:       add     x0, x19, #0x288
    0.00 :   ffff800010233408:       bl      ffff800010085290 <rcuwait_wake_up>
    0.00 :   ffff80001023340c:       b       ffff800010233228 <vfs_write+0x190>
         : 123              __preempt_count_dec_and_test():
    0.00 :   ffff800010233410:       ldr     x0, [x1, #8]
    0.00 :   ffff800010233414:       cbz     x0, ffff800010233400 <vfs_write+0x368>
    0.00 :   ffff800010233418:       b       ffff800010233404 <vfs_write+0x36c>
         : 76               vfs_write():
         : 590              return -EBADF;
    0.00 :   ffff80001023341c:       mov     x21, #0xfffffffffffffff7        // #-9
    0.00 :   ffff800010233420:       b       ffff8000102331a4 <vfs_write+0x10c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101836c8 <find_get_pages_range>:
         : 6                find_get_pages_range():
         : 2098             * reached.
         : 2099             */
         : 2100             unsigned find_get_pages_range(struct address_space *mapping, pgoff_t *start,
         : 2101             pgoff_t end, unsigned int nr_pages,
         : 2102             struct page **pages)
         : 2103             {
    0.00 :   ffff8000101836c8:       paciasp
    0.00 :   ffff8000101836cc:       stp     x29, x30, [sp, #-160]!
         : 2099             XA_STATE(xas, &mapping->i_pages, *start);
    0.00 :   ffff8000101836d0:       add     x0, x0, #0x8
         : 2098             {
    0.00 :   ffff8000101836d4:       mov     x29, sp
    0.00 :   ffff8000101836d8:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000101836dc:       mov     x27, x1
    0.00 :   ffff8000101836e0:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101836e4:       stp     x21, x22, [sp, #32]
         : 2099             XA_STATE(xas, &mapping->i_pages, *start);
    0.00 :   ffff8000101836e8:       mov     x21, #0x3                       // #3
         : 2098             {
    0.00 :   ffff8000101836ec:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000101836f0:       adrp    x25, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101836f4:       add     x25, x25, #0x948
    0.00 :   ffff8000101836f8:       ldr     x1, [x25]
    0.00 :   ffff8000101836fc:       str     x1, [sp, #152]
    0.00 :   ffff800010183700:       mov     x1, #0x0                        // #0
         : 2099             XA_STATE(xas, &mapping->i_pages, *start);
    0.00 :   ffff800010183704:       str     wzr, [sp, #120]
    0.00 :   ffff800010183708:       ldr     x1, [x27]
    0.00 :   ffff80001018370c:       stp     x0, x1, [sp, #104]
    0.00 :   ffff800010183710:       stp     x21, xzr, [sp, #128]
    0.00 :   ffff800010183714:       str     xzr, [sp, #144]
         : 2103             struct page *page;
         : 2104             unsigned ret = 0;
         :
         : 2106             if (unlikely(!nr_pages))
    0.00 :   ffff800010183718:       cbz     w3, ffff8000101838ec <find_get_pages_range+0x224>
         : 2108             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff80001018371c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010183720:       mov     w23, w3
    0.00 :   ffff800010183724:       sub     w23, w23, #0x1
    0.00 :   ffff800010183728:       mov     x19, #0x0                       // #0
    0.00 :   ffff80001018372c:       mov     x22, x2
    0.00 :   ffff800010183730:       mov     x24, x4
    0.00 :   ffff800010183734:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 658              * read-side critical section, (2) CPU 1 invokes call_rcu() to register
         : 659              * an RCU callback, (3) CPU 0 exits the RCU read-side critical section,
         : 660              * (4) CPU 2 enters a RCU read-side critical section, (5) the RCU
    0.00 :   ffff800010183738:       mov     w20, w19
         : 662              find_get_entry():
         : 1923             page = xas_find(xas, max);
    0.00 :   ffff80001018373c:       mov     x1, x22
    0.00 :   ffff800010183740:       add     x0, sp, #0x68
    0.00 :   ffff800010183744:       bl      ffff8000104bd3f0 <xas_find>
    0.00 :   ffff800010183748:       mov     x26, x0
         : 1928             xas_retry():
         : 1488             * Context: Any context.
         : 1489             * Return: true if the operation needs to be retried.
         : 1490             */
         : 1491             static inline bool xas_retry(struct xa_state *xas, const void *entry)
         : 1492             {
         : 1493             if (xa_is_zero(entry))
    0.00 :   ffff80001018374c:       cmp     x0, #0x406
    0.00 :   ffff800010183750:       b.eq    ffff80001018373c <find_get_pages_range+0x74>  // b.none
         : 1490             return true;
         : 1491             if (!xa_is_retry(entry))
    0.00 :   ffff800010183754:       cmp     x0, #0x402
    0.00 :   ffff800010183758:       b.eq    ffff800010183834 <find_get_pages_range+0x16c>  // b.none
         : 1494             find_get_entry():
         : 1934             if (!page || xa_is_value(page))
    0.00 :   ffff80001018375c:       cbz     x0, ffff80001018388c <find_get_pages_range+0x1c4>
    0.00 :   ffff800010183760:       tbnz    w0, #0, ffff80001018373c <find_get_pages_range+0x74>
         : 1937             arch_atomic_fetch_add_unless():
         : 1158             * Returns original value of @v
         : 1159             */
         : 1160             static __always_inline int
         : 1161             arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
         : 1162             {
         : 1163             int c = arch_atomic_read(v);
    0.00 :   ffff800010183764:       mov     x4, x0
    0.00 :   ffff800010183768:       ldr     w5, [x4, #52]!
         :
         : 1162             do {
         : 1163             if (unlikely(c == u))
    0.00 :   ffff80001018376c:       cbz     w5, ffff800010183834 <find_get_pages_range+0x16c>
         : 1165             arch_atomic_try_cmpxchg():
         : 990              r = arch_atomic_cmpxchg(v, o, new);
    0.00 :   ffff800010183770:       sxtw    x1, w5
         : 992              arch_atomic_fetch_add_unless():
         : 1163             break;
         : 1164             } while (!arch_atomic_try_cmpxchg(v, &c, c + a));
    0.00 :   ffff800010183774:       add     w2, w5, #0x1
         : 1166             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010183778:       b       ffff80001018383c <find_get_pages_range+0x174>
    0.00 :   ffff80001018377c:       b       ffff80001018383c <find_get_pages_range+0x174>
         : 46               __lse__cmpxchg_case_mb_32():
         : 378              __CMPXCHG_CASE(w, h, rel_, 16,  l, "memory")
         : 379              __CMPXCHG_CASE(w,  , rel_, 32,  l, "memory")
         : 380              __CMPXCHG_CASE(x,  , rel_, 64,  l, "memory")
         : 381              __CMPXCHG_CASE(w, b,  mb_,  8, al, "memory")
         : 382              __CMPXCHG_CASE(w, h,  mb_, 16, al, "memory")
         : 383              __CMPXCHG_CASE(w,  ,  mb_, 32, al, "memory")
    0.00 :   ffff800010183780:       mov     x0, x4
    0.00 :   ffff800010183784:       mov     w3, w1
    0.00 :   ffff800010183788:       casal   w3, w2, [x4]
    0.00 :   ffff80001018378c:       mov     w0, w3
         : 388              arch_atomic_try_cmpxchg():
         : 991              if (unlikely(r != o))
    0.00 :   ffff800010183790:       cmp     w0, w5
    0.00 :   ffff800010183794:       b.ne    ffff80001018382c <find_get_pages_range+0x164>  // b.any
         : 994              xas_reload():
         : 1550             *
         : 1551             * Return: The entry at this location in the xarray.
         : 1552             */
         : 1553             static inline void *xas_reload(struct xa_state *xas)
         : 1554             {
         : 1555             struct xa_node *node = xas->xa_node;
    0.00 :   ffff800010183798:       ldr     x1, [sp, #128]
         : 1554             void *entry;
         : 1555             char offset;
         :
         : 1557             if (!node)
    0.00 :   ffff80001018379c:       cbz     x1, ffff800010183848 <find_get_pages_range+0x180>
         : 1557             return xa_head(xas->xa);
         : 1558             if (IS_ENABLED(CONFIG_XARRAY_MULTI)) {
         : 1559             offset = (xas->xa_index >> node->shift) & XA_CHUNK_MASK;
    0.00 :   ffff8000101837a0:       ldr     x0, [sp, #112]
    0.00 :   ffff8000101837a4:       ldrb    w2, [x1]
    0.00 :   ffff8000101837a8:       lsr     x0, x0, x2
         : 1563             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000101837ac:       ubfiz   x0, x0, #3, #6
    0.00 :   ffff8000101837b0:       add     x0, x0, #0x20
    0.00 :   ffff8000101837b4:       add     x0, x1, x0
    0.00 :   ffff8000101837b8:       ldr     x0, [x0, #8]
         : 1187             xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000101837bc:       cmp     x0, #0xfd
         : 1251             xa_is_internal():
         : 169              return ((unsigned long)entry & 3) == 2;
    0.00 :   ffff8000101837c0:       and     x2, x0, #0x3
         : 171              xa_is_sibling():
         : 1249             return IS_ENABLED(CONFIG_XARRAY_MULTI) && xa_is_internal(entry) &&
    0.00 :   ffff8000101837c4:       ccmp    x2, #0x2, #0x0, ls  // ls = plast
    0.00 :   ffff8000101837c8:       b.ne    ffff8000101837dc <find_get_pages_range+0x114>  // b.any
         : 1252             xa_entry():
         : 1182             return rcu_dereference_check(node->slots[offset],
    0.00 :   ffff8000101837cc:       ubfx    x0, x0, #2, #8
    0.00 :   ffff8000101837d0:       add     x0, x0, #0x4
    0.00 :   ffff8000101837d4:       add     x0, x1, x0, lsl #3
    0.00 :   ffff8000101837d8:       ldr     x0, [x0, #8]
         : 1187             find_get_entry():
         : 1941             if (unlikely(page != xas_reload(xas))) {
    0.00 :   ffff8000101837dc:       cmp     x26, x0
    0.00 :   ffff8000101837e0:       b.ne    ffff800010183858 <find_get_pages_range+0x190>  // b.any
         : 1944             find_subpage():
         : 462              * to this index in the file
         : 463              */
         : 464              static inline struct page *find_subpage(struct page *head, pgoff_t index)
         : 465              {
         : 466              /* HugeTLBfs wants the head page regardless */
         : 467              if (PageHuge(head))
    0.00 :   ffff8000101837e4:       mov     x0, x26
         : 469              find_get_pages_range():
         : 2112             while ((page = find_get_entry(&xas, end, XA_PRESENT))) {
         : 2113             /* Skip over shadow, swap and DAX entries */
         : 2114             if (xa_is_value(page))
         : 2115             continue;
         :
         : 2117             pages[ret] = find_subpage(page, xas.xa_index);
    0.00 :   ffff8000101837e8:       ldr     x28, [sp, #112]
         : 2119             find_subpage():
    0.00 :   ffff8000101837ec:       bl      ffff8000101ee070 <PageHuge>
    0.00 :   ffff8000101837f0:       cbnz    w0, ffff800010183808 <find_get_pages_range+0x140>
         : 464              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101837f4:       ldr     x0, [x26]
    0.00 :   ffff8000101837f8:       ubfiz   x28, x28, #6, #9
    0.00 :   ffff8000101837fc:       add     x28, x26, x28
    0.00 :   ffff800010183800:       tst     x0, #0x10000
    0.00 :   ffff800010183804:       csel    x26, x28, x26, ne  // ne = any
         : 117              find_get_pages_range():
    0.00 :   ffff800010183808:       str     x26, [x24, x19, lsl #3]
         : 2113             if (++ret == nr_pages) {
    0.00 :   ffff80001018380c:       cmp     x23, x19
    0.00 :   ffff800010183810:       add     w20, w20, #0x1
    0.00 :   ffff800010183814:       add     x19, x19, #0x1
    0.00 :   ffff800010183818:       b.ne    ffff800010183738 <find_get_pages_range+0x70>  // b.any
         : 2114             *start = xas.xa_index + 1;
    0.00 :   ffff80001018381c:       ldr     x0, [sp, #112]
    0.00 :   ffff800010183820:       add     x0, x0, #0x1
    0.00 :   ffff800010183824:       str     x0, [x27]
         : 2115             goto out;
    0.00 :   ffff800010183828:       b       ffff800010183898 <find_get_pages_range+0x1d0>
         : 2117             arch_atomic_fetch_add_unless():
         : 1161             if (unlikely(c == u))
    0.00 :   ffff80001018382c:       mov     w5, w0
    0.00 :   ffff800010183830:       cbnz    w0, ffff800010183770 <find_get_pages_range+0xa8>
         : 1164             xas_reset():
         : 1471             xas->xa_node = XAS_RESTART;
    0.00 :   ffff800010183834:       str     x21, [sp, #128]
         : 1473             find_get_entry():
         : 1949             goto retry;
    0.00 :   ffff800010183838:       b       ffff80001018373c <find_get_pages_range+0x74>
         : 1951             __ll_sc__cmpxchg_case_mb_32():
         : 313              __CMPXCHG_CASE(w, h, rel_, 16,        ,  , l, "memory", K)
         : 314              __CMPXCHG_CASE(w,  , rel_, 32,        ,  , l, "memory", K)
         : 315              __CMPXCHG_CASE( ,  , rel_, 64,        ,  , l, "memory", L)
         : 316              __CMPXCHG_CASE(w, b,  mb_,  8, dmb ish,  , l, "memory", K)
         : 317              __CMPXCHG_CASE(w, h,  mb_, 16, dmb ish,  , l, "memory", K)
         : 318              __CMPXCHG_CASE(w,  ,  mb_, 32, dmb ish,  , l, "memory", K)
    0.00 :   ffff80001018383c:       and     x1, x1, #0xffffffff
    0.00 :   ffff800010183840:       b       ffff800010184d40 <generic_file_write_iter+0xbe8>
    0.00 :   ffff800010183844:       b       ffff800010183790 <find_get_pages_range+0xc8>
         : 322              xas_reload():
         : 1555             return xa_head(xas->xa);
    0.00 :   ffff800010183848:       ldr     x0, [sp, #104]
         : 1557             xa_head():
         : 1166             return rcu_dereference_check(xa->xa_head,
    0.00 :   ffff80001018384c:       ldr     x0, [x0, #8]
         : 1168             find_get_entry():
         : 1941             if (unlikely(page != xas_reload(xas))) {
    0.00 :   ffff800010183850:       cmp     x26, x0
    0.00 :   ffff800010183854:       b.eq    ffff8000101837e4 <find_get_pages_range+0x11c>  // b.none
         : 1944             compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010183858:       ldr     x0, [x26, #8]
         : 186              unsigned long head = READ_ONCE(page->compound_head);
         :
    0.00 :   ffff80001018385c:       tbnz    w0, #0, ffff8000101838e0 <find_get_pages_range+0x218>
         : 189              arch_static_branch_jump():
    0.00 :   ffff800010183860:       b       ffff8000101838d0 <find_get_pages_range+0x208>
    0.00 :   ffff800010183864:       b       ffff8000101838d0 <find_get_pages_range+0x208>
         : 40               __lse_atomic_sub_return():
         : 141              ATOMIC_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff800010183868:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001018386c:       neg     w0, w0
    0.00 :   ffff800010183870:       ldaddal w0, w1, [x4]
    0.00 :   ffff800010183874:       add     w0, w0, w1
         : 146              put_page():
         : 1242             put_devmap_managed_page(page);
         : 1243             return;
         : 1244             }
         :
         : 1246             if (put_page_testzero(page))
         : 1247             __put_page(page);
    0.00 :   ffff800010183878:       cbnz    w0, ffff800010183834 <find_get_pages_range+0x16c>
         : 1243             }
    0.00 :   ffff80001018387c:       mov     x0, x26
    0.00 :   ffff800010183880:       bl      ffff80001018d6f0 <__put_page>
         : 1246             xas_reset():
         : 1471             xas->xa_node = XAS_RESTART;
    0.00 :   ffff800010183884:       str     x21, [sp, #128]
         : 1473             find_get_entry():
         : 1949             goto retry;
    0.00 :   ffff800010183888:       b       ffff80001018373c <find_get_pages_range+0x74>
         : 1951             find_get_pages_range():
         : 2126             * overflow the index @start as it confuses some of the callers. This
         : 2127             * breaks the iteration when there is a page at index -1 but that is
         : 2128             * already broken anyway.
         : 2129             */
         : 2130             if (end == (pgoff_t)-1)
         : 2131             *start = (pgoff_t)-1;
    0.00 :   ffff80001018388c:       cmn     x22, #0x1
    0.00 :   ffff800010183890:       cinc    x22, x22, ne  // ne = any
    0.00 :   ffff800010183894:       str     x22, [x27]
         : 2135             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010183898:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              find_get_pages_range():
         : 2132             else
         : 2133             *start = end + 1;
         : 2134             out:
         : 2135             rcu_read_unlock();
         :
         : 2137             return ret;
    0.00 :   ffff80001018389c:       ldp     x23, x24, [sp, #48]
         : 2133             }
    0.00 :   ffff8000101838a0:       mov     w0, w20
    0.00 :   ffff8000101838a4:       ldr     x2, [sp, #152]
    0.00 :   ffff8000101838a8:       ldr     x1, [x25]
    0.00 :   ffff8000101838ac:       eor     x1, x2, x1
    0.00 :   ffff8000101838b0:       cbnz    x1, ffff8000101838f4 <find_get_pages_range+0x22c>
    0.00 :   ffff8000101838b4:       ldp     x19, x20, [sp, #16]
  100.00 :   ffff8000101838b8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101838bc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000101838c0:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000101838c4:       ldp     x29, x30, [sp], #160
    0.00 :   ffff8000101838c8:       autiasp
    0.00 :   ffff8000101838cc:       ret
         : 2146             __ll_sc_atomic_sub_return():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000101838d0:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000101838d4:       b       ffff800010184d60 <generic_file_write_iter+0xc08>
         : 115              put_page():
         : 1242             __put_page(page);
    0.00 :   ffff8000101838d8:       cbnz    w0, ffff800010183834 <find_get_pages_range+0x16c>
    0.00 :   ffff8000101838dc:       b       ffff80001018387c <find_get_pages_range+0x1b4>
         : 1245             compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101838e0:       sub     x26, x0, #0x1
    0.00 :   ffff8000101838e4:       add     x4, x0, #0x33
    0.00 :   ffff8000101838e8:       b       ffff800010183860 <find_get_pages_range+0x198>
         : 191              find_get_pages_range():
         : 2104             return 0;
    0.00 :   ffff8000101838ec:       mov     w20, #0x0                       // #0
    0.00 :   ffff8000101838f0:       b       ffff8000101838a0 <find_get_pages_range+0x1d8>
    0.00 :   ffff8000101838f4:       stp     x23, x24, [sp, #48]
         : 2133             }
    0.00 :   ffff8000101838f8:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010354718 <jbd2_journal_stop>:
         : 6                jbd2_journal_stop():
         : 1787             * do so in unusual circumstances.  In particular, expect it to
         : 1788             * return -EIO if a jbd2_journal_abort has been executed since the
         : 1789             * transaction began.
         : 1790             */
         : 1791             int jbd2_journal_stop(handle_t *handle)
         : 1792             {
  100.00 :   ffff800010354718:       paciasp
    0.00 :   ffff80001035471c:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff800010354720:       mov     x29, sp
    0.00 :   ffff800010354724:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010354728:       mov     x19, x0
    0.00 :   ffff80001035472c:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010354730:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010354734:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010354738:       add     x25, x0, #0x948
    0.00 :   ffff80001035473c:       ldr     x0, [x25]
    0.00 :   ffff800010354740:       str     x0, [sp, #104]
    0.00 :   ffff800010354744:       mov     x0, #0x0                        // #0
         : 1794             journal_t *journal;
         : 1795             int err = 0, wait_for_commit = 0;
         : 1796             tid_t tid;
         : 1797             pid_t pid;
         :
         : 1799             if (--handle->h_ref > 0) {
    0.00 :   ffff800010354748:       ldr     w0, [x19, #28]
         : 1788             transaction_t *transaction = handle->h_transaction;
    0.00 :   ffff80001035474c:       ldr     x21, [x19]
         : 1794             if (--handle->h_ref > 0) {
    0.00 :   ffff800010354750:       sub     w0, w0, #0x1
    0.00 :   ffff800010354754:       str     w0, [x19, #28]
    0.00 :   ffff800010354758:       cmp     w0, #0x0
    0.00 :   ffff80001035475c:       b.le    ffff8000103547b4 <jbd2_journal_stop+0x9c>
         : 1799             is_handle_aborted():
         : 1661             */
         :
         : 1663             static inline int is_journal_aborted(journal_t *journal)
         : 1664             {
         : 1665             return journal->j_flags & JBD2_ABORT;
         : 1666             }
    0.00 :   ffff800010354760:       ldrb    w0, [x19, #36]
         : 1668             jbd2_journal_stop():
         : 1798             jbd_debug(4, "h_ref %d -> %d\n", handle->h_ref + 1,
         : 1799             handle->h_ref);
         : 1800             if (is_handle_aborted(handle))
         : 1801             return -EIO;
    0.00 :   ffff800010354764:       mov     w20, #0xfffffffb                // #-5
         : 1803             is_handle_aborted():
    0.00 :   ffff800010354768:       tst     x0, #0x8
    0.00 :   ffff80001035476c:       ccmp    x21, #0x0, #0x4, eq  // eq = none
    0.00 :   ffff800010354770:       b.eq    ffff800010354788 <jbd2_journal_stop+0x70>  // b.none
         :
         : 1664             static inline int is_handle_aborted(handle_t *handle)
    0.00 :   ffff800010354774:       ldr     x1, [x21]
         : 1666             jbd2_journal_stop():
    0.00 :   ffff800010354778:       mov     w0, w20
         : 1799             is_journal_aborted():
         : 1656             */
    0.00 :   ffff80001035477c:       ldr     x20, [x1]
         : 1658             jbd2_journal_stop():
    0.00 :   ffff800010354780:       ands    w20, w20, #0x2
    0.00 :   ffff800010354784:       csel    w20, w20, w0, eq  // eq = none
         : 1922             free_and_exit:
         : 1923             if (handle->h_rsv_handle)
         : 1924             jbd2_free_handle(handle->h_rsv_handle);
         : 1925             jbd2_free_handle(handle);
         : 1926             return err;
         : 1927             }
    0.00 :   ffff800010354788:       mov     w0, w20
    0.00 :   ffff80001035478c:       ldr     x2, [sp, #104]
    0.00 :   ffff800010354790:       ldr     x1, [x25]
    0.00 :   ffff800010354794:       eor     x1, x2, x1
    0.00 :   ffff800010354798:       cbnz    x1, ffff800010354960 <jbd2_journal_stop+0x248>
    0.00 :   ffff80001035479c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000103547a0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000103547a4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000103547a8:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000103547ac:       autiasp
    0.00 :   ffff8000103547b0:       ret
         : 1801             if (!transaction) {
    0.00 :   ffff8000103547b4:       cbz     x21, ffff800010354918 <jbd2_journal_stop+0x200>
         : 1809             journal = transaction->t_journal;
    0.00 :   ffff8000103547b8:       stp     x23, x24, [sp, #48]
         : 1813             err = -EIO;
    0.00 :   ffff8000103547bc:       mov     w20, #0xfffffffb                // #-5
         : 1815             is_handle_aborted():
         : 1661             }
    0.00 :   ffff8000103547c0:       ldrb    w0, [x19, #36]
         : 1663             jbd2_journal_stop():
         : 1810             tid = transaction->t_tid;
    0.00 :   ffff8000103547c4:       ldr     w24, [x21, #8]
         : 1809             journal = transaction->t_journal;
    0.00 :   ffff8000103547c8:       ldr     x22, [x21]
         : 1811             is_handle_aborted():
    0.00 :   ffff8000103547cc:       tbnz    w0, #3, ffff8000103547e0 <jbd2_journal_stop+0xc8>
         : 1662             is_journal_aborted():
         : 1656             */
    0.00 :   ffff8000103547d0:       ldr     x20, [x22]
         : 1658             jbd2_journal_stop():
         : 1813             err = -EIO;
    0.00 :   ffff8000103547d4:       mov     w1, #0xfffffffb                 // #-5
    0.00 :   ffff8000103547d8:       ands    w20, w20, #0x2
    0.00 :   ffff8000103547dc:       csel    w20, w20, w1, eq  // eq = none
         : 1818             jiffies - handle->h_start_jiffies,
    0.00 :   ffff8000103547e0:       adrp    x23, ffff800011c27000 <bit_wait_table+0xe80>
         : 1820             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000103547e4:       mrs     x26, sp_el0
         : 26               jbd2_journal_stop():
    0.00 :   ffff8000103547e8:       ldr     x1, [x23, #2432]
         : 1853             if (handle->h_sync && journal->j_last_sync_writer != pid &&
    0.00 :   ffff8000103547ec:       tbz     w0, #0, ffff8000103548c8 <jbd2_journal_stop+0x1b0>
    0.00 :   ffff8000103547f0:       ldr     w1, [x22, #1152]
         : 1852             pid = current->pid;
    0.00 :   ffff8000103547f4:       ldr     w0, [x26, #1096]
         : 1853             if (handle->h_sync && journal->j_last_sync_writer != pid &&
    0.00 :   ffff8000103547f8:       cmp     w1, w0
    0.00 :   ffff8000103547fc:       b.eq    ffff800010354808 <jbd2_journal_stop+0xf0>  // b.none
    0.00 :   ffff800010354800:       ldr     w1, [x22, #1172]
    0.00 :   ffff800010354804:       cbnz    w1, ffff800010354860 <jbd2_journal_stop+0x148>
         : 1880             transaction->t_synchronous_commit = 1;
    0.00 :   ffff800010354808:       ldrb    w0, [x21, #200]
    0.00 :   ffff80001035480c:       orr     w0, w0, #0x1
    0.00 :   ffff800010354810:       strb    w0, [x21, #200]
         : 1887             if (handle->h_sync ||
    0.00 :   ffff800010354814:       ldrb    w0, [x19, #36]
    0.00 :   ffff800010354818:       tbz     w0, #0, ffff8000103548c8 <jbd2_journal_stop+0x1b0>
         : 1896             jbd2_log_start_commit(journal, tid);
    0.00 :   ffff80001035481c:       mov     w1, w24
    0.00 :   ffff800010354820:       mov     x0, x22
    0.00 :   ffff800010354824:       bl      ffff80001035d0c8 <jbd2_log_start_commit>
         : 1902             if (handle->h_sync && !(current->flags & PF_MEMALLOC))
    0.00 :   ffff800010354828:       ldrb    w0, [x19, #36]
    0.00 :   ffff80001035482c:       tbnz    w0, #0, ffff8000103548ec <jbd2_journal_stop+0x1d4>
         : 1912             stop_this_handle(handle);
    0.00 :   ffff800010354830:       mov     x0, x19
    0.00 :   ffff800010354834:       bl      ffff8000103534b0 <stop_this_handle>
    0.00 :   ffff800010354838:       ldp     x23, x24, [sp, #48]
         : 1918             if (handle->h_rsv_handle)
    0.00 :   ffff80001035483c:       adrp    x21, ffff800011f64000 <kernfs_pr_cont_buf+0xcd0>
    0.00 :   ffff800010354840:       ldr     x1, [x19, #8]
    0.00 :   ffff800010354844:       ldr     x0, [x21, #2080]
    0.00 :   ffff800010354848:       cbz     x1, ffff800010354854 <jbd2_journal_stop+0x13c>
         : 1923             jbd2_free_handle():
         : 1569             }
    0.00 :   ffff80001035484c:       bl      ffff8000102097f0 <kmem_cache_free>
    0.00 :   ffff800010354850:       ldr     x0, [x21, #2080]
    0.00 :   ffff800010354854:       mov     x1, x19
    0.00 :   ffff800010354858:       bl      ffff8000102097f0 <kmem_cache_free>
         : 1574             jbd2_journal_stop():
         : 1921             return err;
    0.00 :   ffff80001035485c:       b       ffff800010354788 <jbd2_journal_stop+0x70>
         : 1857             journal->j_last_sync_writer = pid;
    0.00 :   ffff800010354860:       stp     x27, x28, [sp, #80]
         : 1859             read_lock(&journal->j_state_lock);
    0.00 :   ffff800010354864:       add     x27, x22, #0x44
         : 1857             journal->j_last_sync_writer = pid;
    0.00 :   ffff800010354868:       str     w0, [x22, #1152]
         : 1859             read_lock(&journal->j_state_lock);
    0.00 :   ffff80001035486c:       mov     x0, x27
    0.00 :   ffff800010354870:       bl      ffff800010e352c0 <_raw_read_lock>
         : 1861             read_unlock(&journal->j_state_lock);
    0.00 :   ffff800010354874:       mov     x0, x27
         : 1860             commit_time = journal->j_average_commit_time;
    0.00 :   ffff800010354878:       ldr     x28, [x22, #1160]
         : 1861             read_unlock(&journal->j_state_lock);
    0.00 :   ffff80001035487c:       bl      ffff800010e34d10 <_raw_read_unlock>
         : 1863             trans_time = ktime_to_ns(ktime_sub(ktime_get(),
    0.00 :   ffff800010354880:       bl      ffff800010110e30 <ktime_get>
         : 1868             commit_time = min_t(u64, commit_time,
    0.00 :   ffff800010354884:       ldr     w27, [x22, #1172]
         : 1866             commit_time = max_t(u64, commit_time,
    0.00 :   ffff800010354888:       ldr     w1, [x22, #1168]
    0.00 :   ffff80001035488c:       mov     w3, #0x3e8                      // #1000
         : 1863             trans_time = ktime_to_ns(ktime_sub(ktime_get(),
    0.00 :   ffff800010354890:       ldr     x2, [x21, #192]
         : 1868             commit_time = min_t(u64, commit_time,
    0.00 :   ffff800010354894:       mul     w27, w27, w3
         : 1866             commit_time = max_t(u64, commit_time,
    0.00 :   ffff800010354898:       mul     w1, w1, w3
         : 1863             trans_time = ktime_to_ns(ktime_sub(ktime_get(),
    0.00 :   ffff80001035489c:       sub     x0, x0, x2
         : 1866             commit_time = max_t(u64, commit_time,
    0.00 :   ffff8000103548a0:       cmp     x1, x28
    0.00 :   ffff8000103548a4:       csel    x1, x1, x28, cs  // cs = hs, nlast
         : 1868             commit_time = min_t(u64, commit_time,
    0.00 :   ffff8000103548a8:       cmp     x1, x27
    0.00 :   ffff8000103548ac:       csel    x27, x1, x27, ls  // ls = plast
         : 1871             if (trans_time < commit_time) {
    0.00 :   ffff8000103548b0:       cmp     x0, x27
    0.00 :   ffff8000103548b4:       b.cc    ffff800010354938 <jbd2_journal_stop+0x220>  // b.lo, b.ul, b.last
         : 1879             if (handle->h_sync)
    0.00 :   ffff8000103548b8:       ldrb    w0, [x19, #36]
    0.00 :   ffff8000103548bc:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000103548c0:       tbnz    w0, #0, ffff800010354808 <jbd2_journal_stop+0xf0>
    0.00 :   ffff8000103548c4:       nop
         : 1888             time_after_eq(jiffies, transaction->t_expires)) {
    0.00 :   ffff8000103548c8:       ldr     x1, [x23, #2432]
    0.00 :   ffff8000103548cc:       ldr     x0, [x21, #184]
    0.00 :   ffff8000103548d0:       cmp     x1, x0
    0.00 :   ffff8000103548d4:       b.mi    ffff800010354830 <jbd2_journal_stop+0x118>  // b.first
         : 1896             jbd2_log_start_commit(journal, tid);
    0.00 :   ffff8000103548d8:       mov     w1, w24
    0.00 :   ffff8000103548dc:       mov     x0, x22
    0.00 :   ffff8000103548e0:       bl      ffff80001035d0c8 <jbd2_log_start_commit>
         : 1902             if (handle->h_sync && !(current->flags & PF_MEMALLOC))
    0.00 :   ffff8000103548e4:       ldrb    w0, [x19, #36]
    0.00 :   ffff8000103548e8:       tbz     w0, #0, ffff800010354830 <jbd2_journal_stop+0x118>
         : 1905             get_current():
    0.00 :   ffff8000103548ec:       mrs     x0, sp_el0
         : 20               jbd2_journal_stop():
    0.00 :   ffff8000103548f0:       ldr     w0, [x0, #36]
    0.00 :   ffff8000103548f4:       tbnz    w0, #11, ffff800010354830 <jbd2_journal_stop+0x118>
         : 1912             stop_this_handle(handle);
    0.00 :   ffff8000103548f8:       mov     x0, x19
    0.00 :   ffff8000103548fc:       bl      ffff8000103534b0 <stop_this_handle>
         : 1915             err = jbd2_log_wait_commit(journal, tid);
    0.00 :   ffff800010354900:       mov     w1, w24
    0.00 :   ffff800010354904:       mov     x0, x22
    0.00 :   ffff800010354908:       bl      ffff80001035b5d8 <jbd2_log_wait_commit>
    0.00 :   ffff80001035490c:       mov     w20, w0
    0.00 :   ffff800010354910:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff800010354914:       b       ffff80001035483c <jbd2_journal_stop+0x124>
         : 1922             get_current():
    0.00 :   ffff800010354918:       mrs     x1, sp_el0
         : 20               memalloc_nofs_restore():
         : 263              *
         : 264              * This functions marks the beginning of the GFP_NOFS allocation scope.
         : 265              * All further allocations will implicitly drop __GFP_FS flag and so
         : 266              * they are safe for the FS critical section from the allocation recursion
         : 267              * point of view. Use memalloc_nofs_restore to end the scope with flags
         : 268              * returned by this function.
    0.00 :   ffff80001035491c:       ldr     w0, [x1, #36]
         : 270              jbd2_journal_stop():
         : 1790             int err = 0, wait_for_commit = 0;
    0.00 :   ffff800010354920:       mov     w20, #0x0                       // #0
         : 1792             memalloc_nofs_restore():
    0.00 :   ffff800010354924:       ldr     w2, [x19, #52]
    0.00 :   ffff800010354928:       and     w0, w0, #0xfffbffff
    0.00 :   ffff80001035492c:       orr     w0, w0, w2
    0.00 :   ffff800010354930:       str     w0, [x1, #36]
         : 267              jbd2_journal_stop():
         : 1807             goto free_and_exit;
    0.00 :   ffff800010354934:       b       ffff80001035483c <jbd2_journal_stop+0x124>
         : 1872             ktime_t expires = ktime_add_ns(ktime_get(),
    0.00 :   ffff800010354938:       bl      ffff800010110e30 <ktime_get>
    0.00 :   ffff80001035493c:       add     x0, x0, x27
         : 1874             set_current_state(TASK_UNINTERRUPTIBLE);
    0.00 :   ffff800010354940:       mov     x1, #0x2                        // #2
    0.00 :   ffff800010354944:       str     x1, [x26, #16]
         : 1872             ktime_t expires = ktime_add_ns(ktime_get(),
    0.00 :   ffff800010354948:       str     x0, [sp, #96]
         : 1874             set_current_state(TASK_UNINTERRUPTIBLE);
    0.00 :   ffff80001035494c:       dmb     ish
         : 1875             schedule_hrtimeout(&expires, HRTIMER_MODE_ABS);
    0.00 :   ffff800010354950:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010354954:       add     x0, sp, #0x60
    0.00 :   ffff800010354958:       bl      ffff800010e341e0 <schedule_hrtimeout>
    0.00 :   ffff80001035495c:       b       ffff8000103548b8 <jbd2_journal_stop+0x1a0>
    0.00 :   ffff800010354960:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010354964:       stp     x27, x28, [sp, #80]
         : 1922             }
    0.00 :   ffff800010354968:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010495ba0 <percpu_counter_add_batch>:
         : 6                percpu_counter_add_batch():
         : 83               * is explicitly protected by an irq-safe spinlock whereas the fast patch uses
         : 84               * this_cpu_add which is irq-safe by definition. Hence there is no need muck
         : 85               * with irq state before calling this one
         : 86               */
         : 87               void percpu_counter_add_batch(struct percpu_counter *fbc, s64 amount, s32 batch)
         : 88               {
    0.00 :   ffff800010495ba0:       paciasp
    0.00 :   ffff800010495ba4:       stp     x29, x30, [sp, #-48]!
         : 91               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010495ba8:       mrs     x4, sp_el0
         : 26               percpu_counter_add_batch():
    0.00 :   ffff800010495bac:       mov     x29, sp
    0.00 :   ffff800010495bb0:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010495bb4:       mov     x19, x0
    0.00 :   ffff800010495bb8:       str     x21, [sp, #32]
         : 87               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010495bbc:       ldr     w3, [x4, #8]
         : 47               pc += val;
    0.00 :   ffff800010495bc0:       add     w3, w3, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010495bc4:       str     w3, [x4, #8]
         : 50               __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010495bc8:       mrs     x5, tpidr_el1
         : 46               percpu_counter_add_batch():
         : 87               s64 count;
         :
         : 89               preempt_disable();
         : 90               count = __this_cpu_read(*fbc->counters) + amount;
    0.00 :   ffff800010495bcc:       ldr     x3, [x0, #32]
    0.00 :   ffff800010495bd0:       ldr     w20, [x3, x5]
         : 88               if (abs(count) >= batch) {
    0.00 :   ffff800010495bd4:       adds    x21, x1, w20, sxtw
    0.00 :   ffff800010495bd8:       cneg    x3, x21, mi  // mi = first
    0.00 :   ffff800010495bdc:       cmp     x3, w2, sxtw
    0.00 :   ffff800010495be0:       b.lt    ffff800010495c50 <percpu_counter_add_batch+0xb0>  // b.tstop
         : 90               unsigned long flags;
         : 91               raw_spin_lock_irqsave(&fbc->lock, flags);
    0.00 :   ffff800010495be4:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 93               fbc->count += count;
         : 94               __this_cpu_sub(*fbc->counters, count - amount);
         : 95               raw_spin_unlock_irqrestore(&fbc->lock, flags);
    0.00 :   ffff800010495be8:       mov     x1, x0
         : 91               fbc->count += count;
    0.00 :   ffff800010495bec:       ldr     x0, [x19, #8]
         : 93               __kern_my_cpu_offset():
    0.00 :   ffff800010495bf0:       mrs     x4, tpidr_el1
         : 40               percpu_counter_add_batch():
         : 92               __this_cpu_sub(*fbc->counters, count - amount);
    0.00 :   ffff800010495bf4:       ldr     x2, [x19, #32]
         : 91               fbc->count += count;
    0.00 :   ffff800010495bf8:       add     x21, x0, x21
    0.00 :   ffff800010495bfc:       str     x21, [x19, #8]
         : 93               raw_spin_unlock_irqrestore(&fbc->lock, flags);
    0.00 :   ffff800010495c00:       mov     x0, x19
         : 92               __this_cpu_sub(*fbc->counters, count - amount);
    0.00 :   ffff800010495c04:       ldr     w3, [x2, x4]
    0.00 :   ffff800010495c08:       sub     w20, w3, w20
    0.00 :   ffff800010495c0c:       str     w20, [x2, x4]
         : 93               raw_spin_unlock_irqrestore(&fbc->lock, flags);
    0.00 :   ffff800010495c10:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 95               get_current():
  100.00 :   ffff800010495c14:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010495c18:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010495c1c:       sub     x0, x0, #0x1
    0.00 :   ffff800010495c20:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010495c24:       cbnz    x0, ffff800010495c40 <percpu_counter_add_batch+0xa0>
         : 80               percpu_counter_add_batch():
         : 97               } else {
         : 98               this_cpu_add(*fbc->counters, amount);
         : 99               }
         : 100              preempt_enable();
    0.00 :   ffff800010495c28:       bl      ffff800010e2e620 <preempt_schedule>
         : 98               }
    0.00 :   ffff800010495c2c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010495c30:       ldr     x21, [sp, #32]
    0.00 :   ffff800010495c34:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010495c38:       autiasp
    0.00 :   ffff800010495c3c:       ret
         : 104              __preempt_count_dec_and_test():
    0.00 :   ffff800010495c40:       ldr     x0, [x1, #8]
    0.00 :   ffff800010495c44:       cbnz    x0, ffff800010495c2c <percpu_counter_add_batch+0x8c>
         : 75               percpu_counter_add_batch():
         : 97               preempt_enable();
    0.00 :   ffff800010495c48:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff800010495c4c:       b       ffff800010495c2c <percpu_counter_add_batch+0x8c>
         : 100              __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010495c50:       ldr     w0, [x4, #8]
         : 47               pc += val;
    0.00 :   ffff800010495c54:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010495c58:       str     w0, [x4, #8]
         : 50               __kern_my_cpu_offset():
    0.00 :   ffff800010495c5c:       mrs     x2, tpidr_el1
         : 40               percpu_counter_add_batch():
         : 95               this_cpu_add(*fbc->counters, amount);
    0.00 :   ffff800010495c60:       ldr     x0, [x19, #32]
         : 97               __percpu_add_case_32():
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
         : 131              PERCPU_OP(add, add, stadd)
    0.00 :   ffff800010495c64:       add     x0, x0, x2
    0.00 :   ffff800010495c68:       ldxr    w5, [x0]
    0.00 :   ffff800010495c6c:       add     w5, w5, w1
    0.00 :   ffff800010495c70:       stxr    w3, w5, [x0]
    0.00 :   ffff800010495c74:       cbnz    w3, ffff800010495c68 <percpu_counter_add_batch+0xc8>
         : 137              __preempt_count_dec_and_test():
         : 61               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010495c78:       ldr     x0, [x4, #8]
         : 64               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff800010495c7c:       sub     x0, x0, #0x1
    0.00 :   ffff800010495c80:       str     w0, [x4, #8]
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010495c84:       cbnz    x0, ffff800010495c90 <percpu_counter_add_batch+0xf0>
         : 75               percpu_counter_add_batch():
    0.00 :   ffff800010495c88:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010495c8c:       b       ffff800010495c14 <percpu_counter_add_batch+0x74>
         : 97               __preempt_count_dec_and_test():
    0.00 :   ffff800010495c90:       ldr     x0, [x4, #8]
    0.00 :   ffff800010495c94:       cbnz    x0, ffff800010495c14 <percpu_counter_add_batch+0x74>
         : 75               percpu_counter_add_batch():
    0.00 :   ffff800010495c98:       bl      ffff800010e2e658 <preempt_schedule_notrace>
    0.00 :   ffff800010495c9c:       b       ffff800010495c14 <percpu_counter_add_batch+0x74>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010420dc0 <crypto_shash_update>:
         : 6                crypto_shash_update():
         : 111              shash->update(desc, data + unaligned_len, len - unaligned_len);
         : 112              }
         :
         : 114              int crypto_shash_update(struct shash_desc *desc, const u8 *data,
         : 115              unsigned int len)
         : 116              {
    0.00 :   ffff800010420dc0:       paciasp
    0.00 :   ffff800010420dc4:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010420dc8:       mov     x29, sp
         : 120              crypto_shash_alg():
         : 774              return container_of(alg, struct shash_alg, base);
         : 775              }
         :
         : 777              static inline struct shash_alg *crypto_shash_alg(struct crypto_shash *tfm)
         : 778              {
         : 779              return __crypto_shash_alg(crypto_shash_tfm(tfm)->__crt_alg);
    0.00 :   ffff800010420dcc:       ldr     x3, [x0]
    0.00 :   ffff800010420dd0:       ldr     x3, [x3, #144]
         : 782              crypto_shash_update():
         : 114              struct crypto_shash *tfm = desc->tfm;
         : 115              struct shash_alg *shash = crypto_shash_alg(tfm);
         : 116              unsigned long alignmask = crypto_shash_alignmask(tfm);
    0.00 :   ffff800010420dd4:       ldr     w4, [x3, #44]
         :
         : 117              if ((unsigned long)data & alignmask)
    0.00 :   ffff800010420dd8:       tst     x1, x4
    0.00 :   ffff800010420ddc:       b.ne    ffff800010420df4 <crypto_shash_update+0x34>  // b.any
         : 119              return shash_update_unaligned(desc, data, len);
         :
         : 121              return shash->update(desc, data, len);
  100.00 :   ffff800010420de0:       ldur    x3, [x3, #-248]
    0.00 :   ffff800010420de4:       blr     x3
         : 120              }
    0.00 :   ffff800010420de8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010420dec:       autiasp
    0.00 :   ffff800010420df0:       ret
         : 117              return shash_update_unaligned(desc, data, len);
    0.00 :   ffff800010420df4:       bl      ffff800010420ca0 <shash_update_unaligned>
         : 120              }
    0.00 :   ffff800010420df8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010420dfc:       autiasp
    0.00 :   ffff800010420e00:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001027a690 <__brelse>:
         : 6                __brelse():
         : 1168             struct page *page = bh->b_page;
         : 1169             struct address_space *mapping = NULL;
         :
         : 1171             lock_page_memcg(page);
         : 1172             if (!TestSetPageDirty(page)) {
         : 1173             mapping = page_mapping(page);
    0.00 :   ffff80001027a690:       paciasp
    0.00 :   ffff80001027a694:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff80001027a698:       mov     x29, sp
         : 1177             atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff80001027a69c:       ldr     w1, [x0, #96]
         : 35               __brelse():
         : 1169             if (mapping)
    0.00 :   ffff80001027a6a0:       cbnz    w1, ffff80001027a6b4 <__brelse+0x24>
    0.00 :   ffff80001027a6a4:       bl      ffff800010279c48 <__brelse.part.52>
         : 1174             __set_page_dirty(page, mapping, 0);
         : 1175             }
         : 1176             unlock_page_memcg(page);
         : 1177             if (mapping)
         : 1178             __mark_inode_dirty(mapping->host, I_DIRTY_PAGES);
    0.00 :   ffff80001027a6a8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001027a6ac:       autiasp
    0.00 :   ffff80001027a6b0:       ret
         : 1182             put_bh():
         : 284              atomic_inc(&bh->b_count);
         : 285              }
         :
         : 287              static inline void put_bh(struct buffer_head *bh)
         : 288              {
         : 289              smp_mb__before_atomic();
    0.00 :   ffff80001027a6b4:       dmb     ish
         : 285              atomic_dec(&bh->b_count);
  100.00 :   ffff80001027a6b8:       add     x2, x0, #0x60
         : 287              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001027a6bc:       b       ffff80001027a6dc <__brelse+0x4c>
    0.00 :   ffff80001027a6c0:       b       ffff80001027a6dc <__brelse+0x4c>
         : 46               __lse_atomic_sub():
         :
         : 114              #undef ATOMIC_FETCH_OP_AND
         :
         : 116              static inline void __lse_atomic_sub(int i, atomic_t *v)
         : 117              {
         : 118              asm volatile(
    0.00 :   ffff80001027a6c4:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001027a6c8:       neg     w1, w1
    0.00 :   ffff80001027a6cc:       stadd   w1, [x2]
         : 122              __brelse():
    0.00 :   ffff80001027a6d0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001027a6d4:       autiasp
    0.00 :   ffff80001027a6d8:       ret
         : 1177             __ll_sc_atomic_sub():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001027a6dc:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001027a6e0:       add     x0, x0, #0x60
    0.00 :   ffff80001027a6e4:       b       ffff80001027ffdc <__arm64_sys_bdflush+0x1a4>
         : 121              __brelse():
    0.00 :   ffff80001027a6e8:       ldp     x29, x30, [sp], #16
    0.00 :   ffff80001027a6ec:       autiasp
    0.00 :   ffff80001027a6f0:       ret
 Percent |	Source code & Disassembly of libpthread-2.31.so for cycles (1 samples, percent: local period)
-------------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3     Disassembly of section .text:
         :
         : 5     00000000000130d4 <__pthread_disable_asynccancel>:
         : 6     __pthread_disable_asynccancel():
    0.00 :   130d4:  tbnz    w0, #1, 13130 <__pthread_disable_asynccancel+0x5c>
    0.00 :   130d8:  stp     x29, x30, [sp, #-48]!
    0.00 :   130dc:  mrs     x2, tpidr_el0
    0.00 :   130e0:  mov     x29, sp
    0.00 :   130e4:  stp     x21, x22, [sp, #32]
    0.00 :   130e8:  sub     x22, x2, #0x700
    0.00 :   130ec:  stp     x19, x20, [sp, #16]
    0.00 :   130f0:  sub     x20, x2, #0x5f8
    0.00 :   130f4:  ldr     w19, [x22, #264]
    0.00 :   130f8:  and     w21, w19, #0xfffffffd
    0.00 :   130fc:  mov     x2, x20
    0.00 :   13100:  mov     w1, w21
  100.00 :   13104:  mov     w0, w19
    0.00 :   13108:  bl      166c0 <__aarch64_cas4_acq>
    0.00 :   1310c:  cmp     w19, w0
    0.00 :   13110:  b.ne    13134 <__pthread_disable_asynccancel+0x60>  // b.any
    0.00 :   13114:  and     w19, w19, #0xc
    0.00 :   13118:  cmp     w19, #0x4
    0.00 :   1311c:  b.eq    1313c <__pthread_disable_asynccancel+0x68>  // b.none
    0.00 :   13120:  ldp     x19, x20, [sp, #16]
    0.00 :   13124:  ldp     x21, x22, [sp, #32]
    0.00 :   13128:  ldp     x29, x30, [sp], #48
    0.00 :   1312c:  ret
    0.00 :   13130:  ret
    0.00 :   13134:  mov     w19, w0
    0.00 :   13138:  b       130f8 <__pthread_disable_asynccancel+0x24>
    0.00 :   1313c:  mov     x5, #0x1                        // #1
    0.00 :   13140:  mov     x4, #0x881                      // #2177
    0.00 :   13144:  mov     w2, w21
    0.00 :   13148:  mov     x0, x20
    0.00 :   1314c:  mov     x1, #0x80                       // #128
    0.00 :   13150:  mov     x3, #0x0                        // #0
    0.00 :   13154:  mov     x8, #0x62                       // #98
    0.00 :   13158:  svc     #0x0
    0.00 :   1315c:  cmn     x0, #0x1, lsl #12
    0.00 :   13160:  b.hi    13178 <__pthread_disable_asynccancel+0xa4>  // b.pmore
    0.00 :   13164:  ldr     w21, [x22, #264]
    0.00 :   13168:  and     w0, w21, #0xc
    0.00 :   1316c:  cmp     w0, #0x4
    0.00 :   13170:  b.ne    13120 <__pthread_disable_asynccancel+0x4c>  // b.any
    0.00 :   13174:  b       13144 <__pthread_disable_asynccancel+0x70>
    0.00 :   13178:  add     w0, w0, #0xb
    0.00 :   1317c:  cmp     w0, #0xb
    0.00 :   13180:  b.hi    13190 <__pthread_disable_asynccancel+0xbc>  // b.pmore
    0.00 :   13184:  lsl     x0, x5, x0
    0.00 :   13188:  tst     x0, x4
    0.00 :   1318c:  b.ne    13164 <__pthread_disable_asynccancel+0x90>  // b.any
    0.00 :   13190:  adrp    x0, 16000 <thrd_create+0x30>
    0.00 :   13194:  add     x0, x0, #0xaa0
    0.00 :   13198:  bl      65b0 <__libc_fatal@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000103532c0 <jbd2_write_access_granted.isra.20.part.21>:
         : 6                jbd2_write_access_granted():
         : 1137             JBUFFER_TRACE(jh, "exit");
         : 1138             return error;
         : 1139             }
         :
         : 1141             /* Fast check whether buffer is already attached to the required transaction */
         : 1142             static bool jbd2_write_access_granted(handle_t *handle, struct buffer_head *bh,
    0.00 :   ffff8000103532c0:       paciasp
    0.00 :   ffff8000103532c4:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000103532c8:       mov     x29, sp
  100.00 :   ffff8000103532cc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000103532d0:       mov     x19, x1
    0.00 :   ffff8000103532d4:       and     w20, w2, #0xff
    0.00 :   ffff8000103532d8:       str     x21, [sp, #32]
    0.00 :   ffff8000103532dc:       mov     x21, x0
         : 1151             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000103532e0:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000103532e4:       ldr     x0, [x19]
         : 113              jbd2_write_access_granted():
         : 1159             * happen jh gets freed, reallocated, and attached to the transaction
         : 1160             * just after we get pointer to it from bh. So we have to be careful
         : 1161             * and recheck jh still belongs to our bh before we return success.
         : 1162             */
         : 1163             rcu_read_lock();
         : 1164             if (!buffer_jbd(bh))
    0.00 :   ffff8000103532e8:       tst     w0, #0x10000
    0.00 :   ffff8000103532ec:       b.eq    ffff800010353350 <jbd2_write_access_granted.isra.20.part.21+0x90>  // b.none
         : 1162             goto out;
         : 1163             /* This should be bh2jh() but that doesn't work with inline functions */
         : 1164             jh = READ_ONCE(bh->b_private);
    0.00 :   ffff8000103532f0:       ldr     x1, [x19, #64]
         : 1163             if (!jh)
    0.00 :   ffff8000103532f4:       cbz     x1, ffff800010353350 <jbd2_write_access_granted.isra.20.part.21+0x90>
         : 1166             goto out;
         : 1167             /* For undo access buffer must have data copied */
         : 1168             if (undo && !jh->b_committed_data)
    0.00 :   ffff8000103532f8:       cbnz    w20, ffff800010353348 <jbd2_write_access_granted.isra.20.part.21+0x88>
         : 1168             goto out;
         : 1169             if (READ_ONCE(jh->b_transaction) != handle->h_transaction &&
    0.00 :   ffff8000103532fc:       ldr     x2, [x1, #40]
    0.00 :   ffff800010353300:       ldr     x0, [x21]
    0.00 :   ffff800010353304:       cmp     x2, x0
    0.00 :   ffff800010353308:       b.eq    ffff80001035331c <jbd2_write_access_granted.isra.20.part.21+0x5c>  // b.none
         : 1169             READ_ONCE(jh->b_next_transaction) != handle->h_transaction)
    0.00 :   ffff80001035330c:       ldr     x2, [x1, #48]
         : 1141             bool ret = false;
    0.00 :   ffff800010353310:       mov     w20, #0x0                       // #0
         : 1168             if (READ_ONCE(jh->b_transaction) != handle->h_transaction &&
    0.00 :   ffff800010353314:       cmp     x0, x2
    0.00 :   ffff800010353318:       b.ne    ffff800010353354 <jbd2_write_access_granted.isra.20.part.21+0x94>  // b.any
         : 1180             * while we were checking. Paired with implicit barrier in that path.
         : 1181             * 2) So that access to bh done after jbd2_write_access_granted()
         : 1182             * doesn't get reordered and see inconsistent state of concurrent
         : 1183             * do_get_write_access().
         : 1184             */
         : 1185             smp_mb();
    0.00 :   ffff80001035331c:       dmb     ish
         : 1181             if (unlikely(jh->b_bh != bh))
    0.00 :   ffff800010353320:       ldr     x0, [x1]
    0.00 :   ffff800010353324:       cmp     x0, x19
    0.00 :   ffff800010353328:       cset    w20, eq  // eq = none
         : 1185             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff80001035332c:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              jbd2_write_access_granted():
         : 1187             goto out;
         : 1188             ret = true;
         : 1189             out:
         : 1190             rcu_read_unlock();
         : 1191             return ret;
         : 1192             }
    0.00 :   ffff800010353330:       mov     w0, w20
    0.00 :   ffff800010353334:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010353338:       ldr     x21, [sp, #32]
    0.00 :   ffff80001035333c:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010353340:       autiasp
    0.00 :   ffff800010353344:       ret
         : 1166             if (undo && !jh->b_committed_data)
    0.00 :   ffff800010353348:       ldr     x0, [x1, #32]
    0.00 :   ffff80001035334c:       cbnz    x0, ffff8000103532fc <jbd2_write_access_granted.isra.20.part.21+0x3c>
         : 1141             bool ret = false;
    0.00 :   ffff800010353350:       mov     w20, #0x0                       // #0
         : 1143             rcu_read_unlock():
    0.00 :   ffff800010353354:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              jbd2_write_access_granted():
         : 1187             }
    0.00 :   ffff800010353358:       mov     w0, w20
    0.00 :   ffff80001035335c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010353360:       ldr     x21, [sp, #32]
    0.00 :   ffff800010353364:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010353368:       autiasp
    0.00 :   ffff80001035336c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001030d3b8 <ext4_inode_csum.isra.79>:
         : 6                ext4_inode_csum():
         : 52               #include "acl.h"
         : 53               #include "truncate.h"
         :
         : 55               #include <trace/events/ext4.h>
         :
         : 57               static __u32 ext4_inode_csum(struct inode *inode, struct ext4_inode *raw,
    0.00 :   ffff80001030d3b8:       paciasp
    0.00 :   ffff80001030d3bc:       stp     x29, x30, [sp, #-96]!
    0.00 :   ffff80001030d3c0:       mov     x29, sp
    0.00 :   ffff80001030d3c4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001030d3c8:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001030d3cc:       add     x20, x20, #0x948
    0.00 :   ffff80001030d3d0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001030d3d4:       ldr     x4, [x20]
    0.00 :   ffff80001030d3d8:       str     x4, [sp, #88]
    0.00 :   ffff80001030d3dc:       mov     x4, #0x0                        // #0
         : 55               struct ext4_inode_info *ei)
         : 56               {
         : 57               struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff80001030d3e0:       ldr     x4, [x0]
         : 57               __u32 csum;
         : 58               __u16 dummy_csum = 0;
    0.00 :   ffff80001030d3e4:       strh    wzr, [sp, #70]
         : 55               struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
    0.00 :   ffff80001030d3e8:       ldr     x22, [x4, #880]
         : 61               int offset = offsetof(struct ext4_inode, i_checksum_lo);
         : 62               unsigned int csum_size = sizeof(dummy_csum);
         :
         : 64               csum = ext4_chksum(sbi, ei->i_csum_seed, (__u8 *)raw, offset);
    0.00 :   ffff80001030d3ec:       ldr     x4, [x22, #1136]
         : 66               ext4_chksum():
         : 2373             #define DX_HASH_TEA                     2
         : 2374             #define DX_HASH_LEGACY_UNSIGNED         3
         : 2375             #define DX_HASH_HALF_MD4_UNSIGNED       4
         : 2376             #define DX_HASH_TEA_UNSIGNED            5
         : 2377             #define DX_HASH_SIPHASH                 6
         :
    0.00 :   ffff80001030d3f0:       ldr     w5, [x4]
  100.00 :   ffff80001030d3f4:       str     x23, [sp, #48]
    0.00 :   ffff80001030d3f8:       cmp     w5, #0x4
    0.00 :   ffff80001030d3fc:       b.ne    ffff80001030d4b4 <ext4_inode_csum.isra.79+0xfc>  // b.any
         : 2375             static inline u32 ext4_chksum(struct ext4_sb_info *sbi, u32 crc,
         : 2376             const void *address, unsigned int length)
    0.00 :   ffff80001030d400:       mov     x23, x2
    0.00 :   ffff80001030d404:       mov     x19, x0
    0.00 :   ffff80001030d408:       mov     x21, x1
         : 2378             {
         : 2379             struct {
         : 2380             struct shash_desc shash;
    0.00 :   ffff80001030d40c:       mov     w2, #0x7c                       // #124
    0.00 :   ffff80001030d410:       add     x0, sp, #0x48
         : 2375             const void *address, unsigned int length)
    0.00 :   ffff80001030d414:       str     x4, [sp, #72]
         : 2376             {
    0.00 :   ffff80001030d418:       str     w3, [sp, #80]
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d41c:       bl      ffff800010420dc0 <crypto_shash_update>
    0.00 :   ffff80001030d420:       cbnz    w0, ffff80001030d4b8 <ext4_inode_csum.isra.79+0x100>
         : 2381             ext4_inode_csum():
         : 62               csum = ext4_chksum(sbi, csum, (__u8 *)&dummy_csum, csum_size);
    0.00 :   ffff80001030d424:       ldr     x3, [x22, #1136]
         : 64               ext4_chksum():
         :
    0.00 :   ffff80001030d428:       ldr     w0, [x3]
    0.00 :   ffff80001030d42c:       cmp     w0, #0x4
    0.00 :   ffff80001030d430:       b.ne    ffff80001030d4b4 <ext4_inode_csum.isra.79+0xfc>  // b.any
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d434:       mov     w2, #0x2                        // #2
    0.00 :   ffff80001030d438:       add     x1, sp, #0x46
    0.00 :   ffff80001030d43c:       add     x0, sp, #0x48
         : 2375             const void *address, unsigned int length)
    0.00 :   ffff80001030d440:       str     x3, [sp, #72]
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d444:       bl      ffff800010420dc0 <crypto_shash_update>
    0.00 :   ffff80001030d448:       cbnz    w0, ffff80001030d4b8 <ext4_inode_csum.isra.79+0x100>
         : 2381             ext4_inode_csum():
         : 64               offset += csum_size;
         : 65               csum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,
    0.00 :   ffff80001030d44c:       ldr     x3, [x22, #1136]
    0.00 :   ffff80001030d450:       add     x1, x21, #0x7e
         : 68               ext4_chksum():
         :
    0.00 :   ffff80001030d454:       ldr     w0, [x3]
    0.00 :   ffff80001030d458:       cmp     w0, #0x4
    0.00 :   ffff80001030d45c:       b.ne    ffff80001030d4b4 <ext4_inode_csum.isra.79+0xfc>  // b.any
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d460:       mov     w2, #0x2                        // #2
    0.00 :   ffff80001030d464:       add     x0, sp, #0x48
         : 2375             const void *address, unsigned int length)
    0.00 :   ffff80001030d468:       str     x3, [sp, #72]
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d46c:       bl      ffff800010420dc0 <crypto_shash_update>
    0.00 :   ffff80001030d470:       cbnz    w0, ffff80001030d4b8 <ext4_inode_csum.isra.79+0x100>
         : 2381             ext4_inode_csum():
         : 67               EXT4_GOOD_OLD_INODE_SIZE - offset);
         :
         : 69               if (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {
    0.00 :   ffff80001030d474:       ldr     x1, [x19]
         : 71               ext4_chksum():
         : 2380             char ctx[4];
         : 2381             } desc;
    0.00 :   ffff80001030d478:       ldr     w0, [sp, #80]
         : 2383             ext4_inode_csum():
    0.00 :   ffff80001030d47c:       ldr     x1, [x1, #880]
    0.00 :   ffff80001030d480:       ldr     w1, [x1, #180]
    0.00 :   ffff80001030d484:       cmp     w1, #0x80
    0.00 :   ffff80001030d488:       b.gt    ffff80001030d4bc <ext4_inode_csum.isra.79+0x104>
         : 82               csum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,
         : 83               EXT4_INODE_SIZE(inode->i_sb) - offset);
         : 84               }
         :
         : 86               return csum;
         : 87               }
    0.00 :   ffff80001030d48c:       ldr     x2, [sp, #88]
    0.00 :   ffff80001030d490:       ldr     x1, [x20]
    0.00 :   ffff80001030d494:       eor     x1, x2, x1
    0.00 :   ffff80001030d498:       cbnz    x1, ffff80001030d57c <ext4_inode_csum.isra.79+0x1c4>
    0.00 :   ffff80001030d49c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001030d4a0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001030d4a4:       ldr     x23, [sp, #48]
    0.00 :   ffff80001030d4a8:       ldp     x29, x30, [sp], #96
    0.00 :   ffff80001030d4ac:       autiasp
    0.00 :   ffff80001030d4b0:       ret
         : 98               ext4_chksum():
         :
    0.00 :   ffff80001030d4b4:       brk     #0x800
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d4b8:       brk     #0x800
         : 2380             ext4_inode_csum():
         : 69               csum = ext4_chksum(sbi, csum, (__u8 *)raw +
    0.00 :   ffff80001030d4bc:       ldr     x3, [x22, #1136]
    0.00 :   ffff80001030d4c0:       add     x1, x21, #0x80
         : 72               ext4_chksum():
         :
    0.00 :   ffff80001030d4c4:       ldr     w0, [x3]
    0.00 :   ffff80001030d4c8:       cmp     w0, #0x4
    0.00 :   ffff80001030d4cc:       b.ne    ffff80001030d4b4 <ext4_inode_csum.isra.79+0xfc>  // b.any
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d4d0:       mov     w2, #0x2                        // #2
    0.00 :   ffff80001030d4d4:       add     x0, sp, #0x48
         : 2375             const void *address, unsigned int length)
    0.00 :   ffff80001030d4d8:       str     x3, [sp, #72]
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d4dc:       bl      ffff800010420dc0 <crypto_shash_update>
    0.00 :   ffff80001030d4e0:       cbnz    w0, ffff80001030d4b8 <ext4_inode_csum.isra.79+0x100>
         : 2381             ext4_inode_csum():
         : 72               if (EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi)) {
    0.00 :   ffff80001030d4e4:       ldrh    w0, [x23]
    0.00 :   ffff80001030d4e8:       mov     x1, #0x82                       // #130
         : 75               ext4_chksum():
         : 2380             } desc;
    0.00 :   ffff80001030d4ec:       ldr     w4, [sp, #80]
         : 2382             ext4_inode_csum():
         : 68               offset = offsetof(struct ext4_inode, i_checksum_hi);
    0.00 :   ffff80001030d4f0:       mov     w5, w1
         : 72               if (EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi)) {
    0.00 :   ffff80001030d4f4:       add     w0, w0, #0x80
    0.00 :   ffff80001030d4f8:       cmp     w0, #0x83
    0.00 :   ffff80001030d4fc:       ldr     x3, [x22, #1136]
    0.00 :   ffff80001030d500:       b.gt    ffff80001030d540 <ext4_inode_csum.isra.79+0x188>
         : 78               EXT4_INODE_SIZE(inode->i_sb) - offset);
    0.00 :   ffff80001030d504:       ldr     x0, [x19]
         : 77               csum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,
    0.00 :   ffff80001030d508:       add     x1, x21, x1
         : 79               ext4_chksum():
         :
    0.00 :   ffff80001030d50c:       ldr     w2, [x3]
         : 2375             ext4_inode_csum():
         : 78               EXT4_INODE_SIZE(inode->i_sb) - offset);
    0.00 :   ffff80001030d510:       ldr     x0, [x0, #880]
         : 80               ext4_chksum():
    0.00 :   ffff80001030d514:       cmp     w2, #0x4
         : 2374             ext4_inode_csum():
    0.00 :   ffff80001030d518:       ldr     w2, [x0, #180]
    0.00 :   ffff80001030d51c:       sub     w2, w2, w5
         : 80               ext4_chksum():
    0.00 :   ffff80001030d520:       b.ne    ffff80001030d4b4 <ext4_inode_csum.isra.79+0xfc>  // b.any
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d524:       add     x0, sp, #0x48
         : 2375             const void *address, unsigned int length)
    0.00 :   ffff80001030d528:       str     x3, [sp, #72]
         : 2376             {
    0.00 :   ffff80001030d52c:       str     w4, [sp, #80]
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d530:       bl      ffff800010420dc0 <crypto_shash_update>
    0.00 :   ffff80001030d534:       cbnz    w0, ffff80001030d4b8 <ext4_inode_csum.isra.79+0x100>
         : 2380             } desc;
    0.00 :   ffff80001030d538:       ldr     w0, [sp, #80]
         : 2382             ext4_inode_csum():
         : 81               return csum;
    0.00 :   ffff80001030d53c:       b       ffff80001030d48c <ext4_inode_csum.isra.79+0xd4>
         : 83               ext4_chksum():
         :
    0.00 :   ffff80001030d540:       ldr     w0, [x3]
    0.00 :   ffff80001030d544:       cmp     w0, #0x4
    0.00 :   ffff80001030d548:       b.ne    ffff80001030d4b4 <ext4_inode_csum.isra.79+0xfc>  // b.any
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d54c:       add     x1, sp, #0x46
    0.00 :   ffff80001030d550:       mov     w2, #0x2                        // #2
    0.00 :   ffff80001030d554:       add     x0, sp, #0x48
         : 2375             const void *address, unsigned int length)
    0.00 :   ffff80001030d558:       str     x3, [sp, #72]
         : 2376             {
    0.00 :   ffff80001030d55c:       str     w4, [sp, #80]
         : 2378             struct shash_desc shash;
    0.00 :   ffff80001030d560:       bl      ffff800010420dc0 <crypto_shash_update>
    0.00 :   ffff80001030d564:       cbnz    w0, ffff80001030d4b8 <ext4_inode_csum.isra.79+0x100>
         : 2380             } desc;
    0.00 :   ffff80001030d568:       mov     x1, #0x84                       // #132
    0.00 :   ffff80001030d56c:       ldr     w4, [sp, #80]
         : 2383             ext4_inode_csum():
         : 75               offset += csum_size;
    0.00 :   ffff80001030d570:       mov     w5, w1
    0.00 :   ffff80001030d574:       ldr     x3, [x22, #1136]
    0.00 :   ffff80001030d578:       b       ffff80001030d504 <ext4_inode_csum.isra.79+0x14c>
         : 82               }
    0.00 :   ffff80001030d57c:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101b8d80 <__do_fault>:
         : 6                __do_fault():
         : 3654             put_swap_device(si);
         : 3655             return ret;
         : 3656             out_nomap:
         : 3657             pte_unmap_unlock(vmf->pte, vmf->ptl);
         : 3658             out_page:
         : 3659             unlock_page(page);
    0.00 :   ffff8000101b8d80:       paciasp
    0.00 :   ffff8000101b8d84:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000101b8d88:       mov     x29, sp
    0.00 :   ffff8000101b8d8c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101b8d90:       mov     x19, x0
         : 3673             * but allow concurrent faults), and pte mapped but not yet locked.
         : 3674             * We return with mmap_lock still held, but pte unmapped and unlocked.
         : 3675             */
         : 3676             static vm_fault_t do_anonymous_page(struct vm_fault *vmf)
         : 3677             {
         : 3678             struct vm_area_struct *vma = vmf->vma;
    0.00 :   ffff8000101b8d94:       ldr     x0, [x0, #40]
         : 3655             out_release:
    0.00 :   ffff8000101b8d98:       ldr     x20, [x19]
         : 3673             struct vm_area_struct *vma = vmf->vma;
    0.00 :   ffff8000101b8d9c:       ldr     x0, [x0]
    0.00 :   ffff8000101b8da0:       cbnz    x0, ffff8000101b8dac <__do_fault+0x2c>
    0.00 :   ffff8000101b8da4:       ldr     x0, [x19, #96]
    0.00 :   ffff8000101b8da8:       cbz     x0, ffff8000101b8df8 <__do_fault+0x78>
         : 3680             vm_fault_t ret = 0;
         : 3681             pte_t entry;
         :
         : 3683             /* File mapping without ->vm_ops ? */
         : 3684             if (vma->vm_flags & VM_SHARED)
         : 3685             return VM_FAULT_SIGBUS;
    0.00 :   ffff8000101b8dac:       ldr     x1, [x20, #144]
    0.00 :   ffff8000101b8db0:       mov     x0, x19
    0.00 :   ffff8000101b8db4:       ldr     x1, [x1, #40]
    0.00 :   ffff8000101b8db8:       blr     x1
    0.00 :   ffff8000101b8dbc:       mov     w20, w0
         :
    0.00 :   ffff8000101b8dc0:       mov     w0, #0x1d73                     // #7539
    0.00 :   ffff8000101b8dc4:       tst     w20, w0
    0.00 :   ffff8000101b8dc8:       b.ne    ffff8000101b8de4 <__do_fault+0x64>  // b.any
         : 3685             /*
         : 3686             * Use pte_alloc() instead of pte_alloc_map().  We can't run
         : 3687             * pte_offset_map() on pmds where a huge pmd might be created
         : 3688             * from a different thread.
    0.00 :   ffff8000101b8dcc:       ldr     x0, [x19, #72]
         : 3690             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000101b8dd0:       and     w1, w20, #0x200
    0.00 :   ffff8000101b8dd4:       ldr     x2, [x0]
         : 114              __do_fault():
    0.00 :   ffff8000101b8dd8:       tst     w2, #0x400000
    0.00 :   ffff8000101b8ddc:       b.ne    ffff8000101b8e58 <__do_fault+0xd8>  // b.any
         : 3693             * parallel threads are excluded by other means.
         : 3694             *
         : 3695             * Here we only have mmap_read_lock(mm).
         : 3696             */
         : 3697             if (pte_alloc(vma->vm_mm, vmf->pmd))
         : 3698             return VM_FAULT_OOM;
  100.00 :   ffff8000101b8de0:       cbz     w1, ffff8000101b8e98 <__do_fault+0x118>
         :
         : 3700             /* See comment in handle_pte_fault() */
         : 3701             if (unlikely(pmd_trans_unstable(vmf->pmd)))
         : 3702             return 0;
         :
         : 3704             /* Use the zero-page for reads */
    0.00 :   ffff8000101b8de4:       mov     w0, w20
    0.00 :   ffff8000101b8de8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101b8dec:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101b8df0:       autiasp
    0.00 :   ffff8000101b8df4:       ret
         : 3710             __pte_alloc_one():
         : 63               */
         : 64               static inline pgtable_t __pte_alloc_one(struct mm_struct *mm, gfp_t gfp)
         : 65               {
         : 66               struct page *pte;
         :
         : 68               pte = alloc_page(gfp);
    0.00 :   ffff8000101b8df8:       mov     w0, #0xdc0                      // #3520
    0.00 :   ffff8000101b8dfc:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000101b8e00:       movk    w0, #0x40, lsl #16
    0.00 :   ffff8000101b8e04:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101b8e08:       bl      ffff8000101fa5f0 <alloc_pages>
    0.00 :   ffff8000101b8e0c:       mov     x21, x0
         : 64               if (!pte)
    0.00 :   ffff8000101b8e10:       cbz     x0, ffff8000101b8f14 <__do_fault+0x194>
         : 66               __SetPageTable():
         : 766              * (see mm/page_alloc.c).
         : 767              */
         : 768              PAGE_TYPE_OPS(Buddy, buddy)
         :
         : 770              /*
         : 771              * PageOffline() indicates that the page is logically offline although the
    0.00 :   ffff8000101b8e14:       ldr     w0, [x0, #48]
         : 773              ptlock_init():
         : 2222             * slab code uses page->slab_cache, which share storage with page->ptl.
         : 2223             */
         : 2224             VM_BUG_ON_PAGE(*(unsigned long *)&page->ptl, page);
         : 2225             if (!ptlock_alloc(page))
         : 2226             return false;
         : 2227             spin_lock_init(ptlock_ptr(page));
    0.00 :   ffff8000101b8e18:       str     wzr, [x21, #40]
         : 2229             __SetPageTable():
    0.00 :   ffff8000101b8e1c:       and     w0, w0, #0xfffffdff
    0.00 :   ffff8000101b8e20:       str     w0, [x21, #48]
         : 768              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101b8e24:       mrs     x22, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101b8e28:       and     w0, w22, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff8000101b8e2c:       cbz     w0, ffff8000101b8ee4 <__do_fault+0x164>
         : 118              mod_lruvec_page_state():
         : 483              enum node_stat_item idx, int val)
         : 484              {
         : 485              unsigned long flags;
         :
         : 487              local_irq_save(flags);
         : 488              __mod_lruvec_state(lruvec, idx, val);
    0.00 :   ffff8000101b8e30:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000101b8e34:       mov     w1, #0x25                       // #37
    0.00 :   ffff8000101b8e38:       mov     x0, x21
    0.00 :   ffff8000101b8e3c:       bl      ffff800010222048 <__mod_lruvec_page_state>
         : 493              arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101b8e40:       msr     daif, x22
         : 129              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000101b8e44:       nop
         : 28               __do_fault():
         : 3674             struct page *page;
    0.00 :   ffff8000101b8e48:       str     x21, [x19, #96]
         :
    0.00 :   ffff8000101b8e4c:       dmb     ishst
    0.00 :   ffff8000101b8e50:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101b8e54:       b       ffff8000101b8dac <__do_fault+0x2c>
         : 3686             *
    0.00 :   ffff8000101b8e58:       cbnz    w1, ffff8000101b8ef4 <__do_fault+0x174>
         : 3688             compound_head():
         : 184              {
    0.00 :   ffff8000101b8e5c:       ldr     x1, [x0, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101b8e60:       sub     x2, x1, #0x1
    0.00 :   ffff8000101b8e64:       tst     x1, #0x1
    0.00 :   ffff8000101b8e68:       csel    x0, x2, x0, ne  // ne = any
         : 191              page_ref_dec_and_test():
         : 148              return ret;
         : 149              }
         :
         : 151              static inline int page_ref_dec_and_test(struct page *page)
         : 152              {
         : 153              int ret = atomic_dec_and_test(&page->_refcount);
    0.00 :   ffff8000101b8e6c:       add     x2, x0, #0x34
         : 155              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101b8e70:       b       ffff8000101b8eb8 <__do_fault+0x138>
    0.00 :   ffff8000101b8e74:       b       ffff8000101b8eb8 <__do_fault+0x138>
         : 46               __lse_atomic_sub_return():
         : 141              }
         :
         : 143              ATOMIC_OP_SUB_RETURN(_relaxed,   )
         : 144              ATOMIC_OP_SUB_RETURN(_acquire,  a, "memory")
         : 145              ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
         : 146              ATOMIC_OP_SUB_RETURN(        , al, "memory")
    0.00 :   ffff8000101b8e78:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000101b8e7c:       neg     w1, w1
    0.00 :   ffff8000101b8e80:       ldaddal w1, w3, [x2]
    0.00 :   ffff8000101b8e84:       add     w1, w1, w3
         : 151              put_page():
         : 1242             __put_page(page);
    0.00 :   ffff8000101b8e88:       cbz     w1, ffff8000101b8f00 <__do_fault+0x180>
         : 1244             __do_fault():
         : 3690             * Here we only have mmap_read_lock(mm).
    0.00 :   ffff8000101b8e8c:       mov     w20, #0x10                      // #16
         : 3689             *
    0.00 :   ffff8000101b8e90:       str     xzr, [x19, #72]
         : 3690             * Here we only have mmap_read_lock(mm).
    0.00 :   ffff8000101b8e94:       b       ffff8000101b8de4 <__do_fault+0x64>
         : 3692             compound_head():
         : 184              {
    0.00 :   ffff8000101b8e98:       ldr     x2, [x0, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff8000101b8e9c:       sub     x1, x2, #0x1
    0.00 :   ffff8000101b8ea0:       tst     x2, #0x1
    0.00 :   ffff8000101b8ea4:       csel    x1, x1, x0, ne  // ne = any
         : 191              test_and_set_bit_lock():
         : 25               {
         : 26               long old;
         : 27               unsigned long mask = BIT_MASK(nr);
         :
         : 29               p += BIT_WORD(nr);
         : 30               if (READ_ONCE(*p) & mask)
    0.00 :   ffff8000101b8ea8:       ldr     x2, [x1]
    0.00 :   ffff8000101b8eac:       tbz     w2, #0, ffff8000101b8ec4 <__do_fault+0x144>
         : 33               lock_page():
         : 625              */
         : 626              static inline void lock_page(struct page *page)
         : 627              {
         : 628              might_sleep();
         : 629              if (!trylock_page(page))
         : 630              __lock_page(page);
    0.00 :   ffff8000101b8eb0:       bl      ffff80001017eb08 <__lock_page>
    0.00 :   ffff8000101b8eb4:       b       ffff8000101b8de4 <__do_fault+0x64>
         : 633              __ll_sc_atomic_sub_return():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000101b8eb8:       mov     w3, #0x1                        // #1
    0.00 :   ffff8000101b8ebc:       b       ffff8000101c05e8 <copy_huge_page_from_user+0x2e0>
    0.00 :   ffff8000101b8ec0:       b       ffff8000101b8e88 <__do_fault+0x108>
         : 121              arch_static_branch_jump():
    0.00 :   ffff8000101b8ec4:       b       ffff8000101b8f08 <__do_fault+0x188>
    0.00 :   ffff8000101b8ec8:       b       ffff8000101b8f08 <__do_fault+0x188>
         : 40               __lse_atomic64_fetch_or_acquire():
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
         : 208              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff8000101b8ecc:       mov     x2, #0x1                        // #1
    0.00 :   ffff8000101b8ed0:       ldseta  x2, x2, [x1]
         : 211              lock_page():
         : 624              if (!trylock_page(page))
    0.00 :   ffff8000101b8ed4:       tbz     w2, #0, ffff8000101b8de4 <__do_fault+0x64>
    0.00 :   ffff8000101b8ed8:       b       ffff8000101b8eb0 <__do_fault+0x130>
         : 627              arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff8000101b8edc:       dsb     sy
    0.00 :   ffff8000101b8ee0:       b       ffff8000101b8e48 <__do_fault+0xc8>
         : 138              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff8000101b8ee4:       nop
    0.00 :   ffff8000101b8ee8:       mov     x0, #0x60                       // #96
         : 24               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101b8eec:       msr     daifset, #0x3
    0.00 :   ffff8000101b8ef0:       b       ffff8000101b8e30 <__do_fault+0xb0>
         : 57               __do_fault():
         : 3687             * pte_alloc_map() is safe to use under mmap_write_lock(mm) or when
    0.00 :   ffff8000101b8ef4:       bl      ffff80001017d860 <unlock_page>
    0.00 :   ffff8000101b8ef8:       ldr     x0, [x19, #72]
    0.00 :   ffff8000101b8efc:       b       ffff8000101b8e5c <__do_fault+0xdc>
         : 3691             put_page():
         : 1243             }
    0.00 :   ffff8000101b8f00:       bl      ffff80001018d6f0 <__put_page>
    0.00 :   ffff8000101b8f04:       b       ffff8000101b8e8c <__do_fault+0x10c>
         : 1246             __ll_sc_atomic64_fetch_or_acquire():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff8000101b8f08:       b       ffff8000101c0608 <copy_huge_page_from_user+0x300>
         : 229              lock_page():
    0.00 :   ffff8000101b8f0c:       tbz     w2, #0, ffff8000101b8de4 <__do_fault+0x64>
    0.00 :   ffff8000101b8f10:       b       ffff8000101b8eb0 <__do_fault+0x130>
         : 626              __do_fault():
         : 3674             struct page *page;
    0.00 :   ffff8000101b8f14:       str     xzr, [x19, #96]
         : 3676             pte_t entry;
    0.00 :   ffff8000101b8f18:       mov     w20, #0x1                       // #1
    0.00 :   ffff8000101b8f1c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101b8f20:       b       ffff8000101b8de4 <__do_fault+0x64>
         : 3680             arch_static_branch():
    0.00 :   ffff8000101b8f24:       mov     x0, #0xa0                       // #160
    0.00 :   ffff8000101b8f28:       b       ffff8000101b8eec <__do_fault+0x16c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001018ec70 <mark_page_accessed>:
         : 6                mark_page_accessed():
         : 425              *
         : 426              * When a newly allocated page is not yet visible, so safe for non-atomic ops,
         : 427              * __SetPageReferenced(page) may be substituted for mark_page_accessed(page).
         : 428              */
         : 429              void mark_page_accessed(struct page *page)
         : 430              {
  100.00 :   ffff80001018ec70:       paciasp
    0.00 :   ffff80001018ec74:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff80001018ec78:       mov     x29, sp
    0.00 :   ffff80001018ec7c:       str     x19, [sp, #16]
    0.00 :   ffff80001018ec80:       mov     x19, x0
         : 436              compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff80001018ec84:       ldr     x0, [x0, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff80001018ec88:       sub     x1, x0, #0x1
    0.00 :   ffff80001018ec8c:       tst     x0, #0x1
    0.00 :   ffff80001018ec90:       csel    x19, x1, x19, ne  // ne = any
         : 184              {
    0.00 :   ffff80001018ec94:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ec98:       sub     x0, x1, #0x1
    0.00 :   ffff80001018ec9c:       tst     x1, #0x1
    0.00 :   ffff80001018eca0:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001018eca4:       ldr     x0, [x0]
         : 113              mark_page_accessed():
         : 428              page = compound_head(page);
         :
         : 430              if (!PageReferenced(page)) {
    0.00 :   ffff80001018eca8:       tst     w0, #0x2
    0.00 :   ffff80001018ecac:       b.ne    ffff80001018ecf4 <mark_page_accessed+0x84>  // b.any
         : 433              compound_head():
         : 184              {
    0.00 :   ffff80001018ecb0:       ldr     x0, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ecb4:       sub     x1, x0, #0x1
    0.00 :   ffff80001018ecb8:       tst     x0, #0x1
    0.00 :   ffff80001018ecbc:       csel    x19, x1, x19, ne  // ne = any
         : 191              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001018ecc0:       b       ffff80001018ece0 <mark_page_accessed+0x70>
    0.00 :   ffff80001018ecc4:       b       ffff80001018ece0 <mark_page_accessed+0x70>
         : 46               __lse_atomic64_or():
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
    0.00 :   ffff80001018ecc8:       mov     x0, #0x2                        // #2
    0.00 :   ffff80001018eccc:       stset   x0, [x19]
         : 185              mark_page_accessed():
         : 452              ClearPageReferenced(page);
         : 453              workingset_activation(page);
         : 454              }
         : 455              if (page_is_idle(page))
         : 456              clear_page_idle(page);
         : 457              }
    0.00 :   ffff80001018ecd0:       ldr     x19, [sp, #16]
    0.00 :   ffff80001018ecd4:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001018ecd8:       autiasp
    0.00 :   ffff80001018ecdc:       ret
         : 462              __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001018ece0:       b       ffff800010190bd8 <pagevec_remove_exceptionals+0x188>
         : 229              mark_page_accessed():
    0.00 :   ffff80001018ece4:       ldr     x19, [sp, #16]
    0.00 :   ffff80001018ece8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001018ecec:       autiasp
    0.00 :   ffff80001018ecf0:       ret
         : 456              compound_head():
         : 184              {
    0.00 :   ffff80001018ecf4:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ecf8:       sub     x0, x1, #0x1
    0.00 :   ffff80001018ecfc:       tst     x1, #0x1
    0.00 :   ffff80001018ed00:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001018ed04:       ldr     x0, [x0]
         : 107              mark_page_accessed():
         : 430              } else if (PageUnevictable(page)) {
    0.00 :   ffff80001018ed08:       tst     w0, #0x100000
    0.00 :   ffff80001018ed0c:       b.ne    ffff80001018ecd0 <mark_page_accessed+0x60>  // b.any
         : 433              compound_head():
         : 184              {
    0.00 :   ffff80001018ed10:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ed14:       sub     x0, x1, #0x1
    0.00 :   ffff80001018ed18:       tst     x1, #0x1
    0.00 :   ffff80001018ed1c:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001018ed20:       ldr     x0, [x0]
         : 107              mark_page_accessed():
         : 436              } else if (!PageActive(page)) {
    0.00 :   ffff80001018ed24:       tst     w0, #0x20
    0.00 :   ffff80001018ed28:       b.ne    ffff80001018ecd0 <mark_page_accessed+0x60>  // b.any
         : 439              compound_head():
         : 184              {
    0.00 :   ffff80001018ed2c:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ed30:       sub     x0, x1, #0x1
    0.00 :   ffff80001018ed34:       tst     x1, #0x1
    0.00 :   ffff80001018ed38:       csel    x0, x0, x19, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001018ed3c:       ldr     x0, [x0]
         : 107              mark_page_accessed():
         : 443              if (PageLRU(page))
    0.00 :   ffff80001018ed40:       tst     w0, #0x10
    0.00 :   ffff80001018ed44:       b.eq    ffff80001018ee68 <mark_page_accessed+0x1f8>  // b.none
         : 446              compound_head():
         : 184              {
    0.00 :   ffff80001018ed48:       ldr     x0, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ed4c:       sub     x1, x0, #0x1
    0.00 :   ffff80001018ed50:       tst     x0, #0x1
    0.00 :   ffff80001018ed54:       csel    x1, x1, x19, ne  // ne = any
         : 184              {
    0.00 :   ffff80001018ed58:       ldr     x2, [x1, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ed5c:       sub     x0, x2, #0x1
    0.00 :   ffff80001018ed60:       tst     x2, #0x1
    0.00 :   ffff80001018ed64:       csel    x0, x0, x1, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001018ed68:       ldr     x0, [x0]
         : 107              activate_page():
         : 353              if (PageLRU(page) && !PageActive(page) && !PageUnevictable(page)) {
    0.00 :   ffff80001018ed6c:       tst     w0, #0x10
    0.00 :   ffff80001018ed70:       b.eq    ffff80001018ee30 <mark_page_accessed+0x1c0>  // b.none
         : 356              compound_head():
         : 184              {
    0.00 :   ffff80001018ed74:       ldr     x2, [x1, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ed78:       sub     x0, x2, #0x1
    0.00 :   ffff80001018ed7c:       tst     x2, #0x1
    0.00 :   ffff80001018ed80:       csel    x0, x0, x1, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001018ed84:       ldr     x0, [x0]
         : 107              activate_page():
    0.00 :   ffff80001018ed88:       tst     w0, #0x20
    0.00 :   ffff80001018ed8c:       b.ne    ffff80001018ee30 <mark_page_accessed+0x1c0>  // b.any
         : 355              compound_head():
         : 184              {
    0.00 :   ffff80001018ed90:       ldr     x2, [x1, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ed94:       sub     x0, x2, #0x1
    0.00 :   ffff80001018ed98:       tst     x2, #0x1
    0.00 :   ffff80001018ed9c:       csel    x0, x0, x1, ne  // ne = any
         : 191              test_bit():
    0.00 :   ffff80001018eda0:       ldr     x0, [x0]
         : 107              activate_page():
    0.00 :   ffff80001018eda4:       tst     w0, #0x100000
    0.00 :   ffff80001018eda8:       b.ne    ffff80001018ee30 <mark_page_accessed+0x1c0>  // b.any
         : 355              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001018edac:       mrs     x2, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff80001018edb0:       ldr     w0, [x2, #8]
         : 47               pc += val;
    0.00 :   ffff80001018edb4:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff80001018edb8:       str     w0, [x2, #8]
         : 50               compound_head():
         : 184              {
    0.00 :   ffff80001018edbc:       ldr     x3, [x1, #8]
         : 186              activate_page():
         : 357              pvec = this_cpu_ptr(&lru_pvecs.activate_page);
    0.00 :   ffff80001018edc0:       adrp    x0, ffff800011776000 <timer_bases+0x2380>
    0.00 :   ffff80001018edc4:       add     x0, x0, #0xed8
         : 360              compound_head():
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018edc8:       sub     x2, x3, #0x1
         : 189              activate_page():
    0.00 :   ffff80001018edcc:       add     x0, x0, #0x200
         : 358              compound_head():
    0.00 :   ffff80001018edd0:       tst     x3, #0x1
    0.00 :   ffff80001018edd4:       csel    x2, x2, x1, ne  // ne = any
         : 189              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001018edd8:       mrs     x4, tpidr_el1
         : 46               page_ref_inc():
         : 116              return ret;
         : 117              }
         :
         : 119              static inline void page_ref_inc(struct page *page)
         : 120              {
         : 121              atomic_inc(&page->_refcount);
    0.00 :   ffff80001018eddc:       add     x2, x2, #0x34
         : 123              activate_page():
    0.00 :   ffff80001018ede0:       add     x4, x0, x4
         : 358              arch_static_branch_jump():
    0.00 :   ffff80001018ede4:       b       ffff80001018eefc <mark_page_accessed+0x28c>
    0.00 :   ffff80001018ede8:       b       ffff80001018eefc <mark_page_accessed+0x28c>
         : 40               __lse_atomic_add():
         : 26               ATOMIC_OP(add, stadd)
    0.00 :   ffff80001018edec:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001018edf0:       stadd   w0, [x2]
         : 29               activate_page():
         : 359              if (pagevec_add_and_need_flush(pvec, page))
    0.00 :   ffff80001018edf4:       mov     x0, x4
    0.00 :   ffff80001018edf8:       bl      ffff80001018d3e8 <pagevec_add_and_need_flush>
    0.00 :   ffff80001018edfc:       tst     w0, #0xff
    0.00 :   ffff80001018ee00:       b.eq    ffff80001018ee18 <mark_page_accessed+0x1a8>  // b.none
         : 360              pagevec_lru_move_fn(pvec, __activate_page);
    0.00 :   ffff80001018ee04:       adrp    x1, ffff80001018e000 <pagevec_move_tail_fn+0x100>
    0.00 :   ffff80001018ee08:       mov     x0, x4
    0.00 :   ffff80001018ee0c:       add     x1, x1, #0x208
    0.00 :   ffff80001018ee10:       bl      ffff80001018dd28 <pagevec_lru_move_fn>
    0.00 :   ffff80001018ee14:       nop
         : 366              get_current():
    0.00 :   ffff80001018ee18:       mrs     x1, sp_el0
         : 20               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001018ee1c:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001018ee20:       sub     x0, x0, #0x1
    0.00 :   ffff80001018ee24:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001018ee28:       cbnz    x0, ffff80001018eee4 <mark_page_accessed+0x274>
         : 80               activate_page():
         : 361              local_unlock(&lru_pvecs.lock);
    0.00 :   ffff80001018ee2c:       bl      ffff800010e2e620 <preempt_schedule>
         : 363              compound_head():
         : 184              {
    0.00 :   ffff80001018ee30:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018ee34:       sub     x0, x1, #0x1
    0.00 :   ffff80001018ee38:       tst     x1, #0x1
    0.00 :   ffff80001018ee3c:       csel    x0, x0, x19, ne  // ne = any
         : 191              arch_static_branch_jump():
    0.00 :   ffff80001018ee40:       b       ffff80001018eed8 <mark_page_accessed+0x268>
    0.00 :   ffff80001018ee44:       b       ffff80001018eed8 <mark_page_accessed+0x268>
         : 40               __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff80001018ee48:       mov     x1, #0x2                        // #2
    0.00 :   ffff80001018ee4c:       stclr   x1, [x0]
         : 179              mark_page_accessed():
         : 448              workingset_activation(page);
    0.00 :   ffff80001018ee50:       mov     x0, x19
    0.00 :   ffff80001018ee54:       bl      ffff8000101b3da8 <workingset_activation>
         : 452              }
    0.00 :   ffff80001018ee58:       ldr     x19, [sp, #16]
    0.00 :   ffff80001018ee5c:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001018ee60:       autiasp
    0.00 :   ffff80001018ee64:       ret
         : 457              get_current():
    0.00 :   ffff80001018ee68:       mrs     x1, sp_el0
         : 20               __preempt_count_add():
         : 46               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff80001018ee6c:       ldr     w0, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff80001018ee70:       add     w0, w0, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff80001018ee74:       str     w0, [x1, #8]
         : 50               __lru_cache_activate_page():
         : 390              pvec = this_cpu_ptr(&lru_pvecs.lru_add);
    0.00 :   ffff80001018ee78:       adrp    x1, ffff800011776000 <timer_bases+0x2380>
    0.00 :   ffff80001018ee7c:       add     x1, x1, #0xed8
         : 393              __kern_my_cpu_offset():
    0.00 :   ffff80001018ee80:       mrs     x0, tpidr_el1
         : 40               pagevec_count():
         : 61               pvec->nr = 0;
         : 62               }
         :
         : 64               static inline unsigned pagevec_count(struct pagevec *pvec)
         : 65               {
         : 66               return pvec->nr;
    0.00 :   ffff80001018ee84:       ldrb    w2, [x1, x0]
         : 68               __lru_cache_activate_page():
    0.00 :   ffff80001018ee88:       add     x1, x1, x0
         : 402              for (i = pagevec_count(pvec) - 1; i >= 0; i--) {
    0.00 :   ffff80001018ee8c:       sub     w0, w2, #0x1
    0.00 :   ffff80001018ee90:       cbnz    w2, ffff80001018eea4 <mark_page_accessed+0x234>
    0.00 :   ffff80001018ee94:       b       ffff80001018ee18 <mark_page_accessed+0x1a8>
    0.00 :   ffff80001018ee98:       sub     w0, w0, #0x1
    0.00 :   ffff80001018ee9c:       cmn     w0, #0x1
    0.00 :   ffff80001018eea0:       b.eq    ffff80001018ee18 <mark_page_accessed+0x1a8>  // b.none
         : 403              struct page *pagevec_page = pvec->pages[i];
    0.00 :   ffff80001018eea4:       add     x2, x1, w0, sxtw #3
         : 405              if (pagevec_page == page) {
    0.00 :   ffff80001018eea8:       ldr     x2, [x2, #8]
    0.00 :   ffff80001018eeac:       cmp     x19, x2
    0.00 :   ffff80001018eeb0:       b.ne    ffff80001018ee98 <mark_page_accessed+0x228>  // b.any
         : 409              compound_head():
         : 184              {
    0.00 :   ffff80001018eeb4:       ldr     x1, [x19, #8]
         : 187              if (unlikely(head & 1))
    0.00 :   ffff80001018eeb8:       sub     x0, x1, #0x1
    0.00 :   ffff80001018eebc:       tst     x1, #0x1
    0.00 :   ffff80001018eec0:       csel    x0, x0, x19, ne  // ne = any
         : 191              arch_static_branch_jump():
    0.00 :   ffff80001018eec4:       b       ffff80001018eef4 <mark_page_accessed+0x284>
    0.00 :   ffff80001018eec8:       b       ffff80001018eef4 <mark_page_accessed+0x284>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff80001018eecc:       mov     x1, #0x20                       // #32
    0.00 :   ffff80001018eed0:       stset   x1, [x0]
    0.00 :   ffff80001018eed4:       b       ffff80001018ee18 <mark_page_accessed+0x1a8>
         : 181              __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff80001018eed8:       mov     x1, #0x2                        // #2
    0.00 :   ffff80001018eedc:       b       ffff800010190bf8 <pagevec_remove_exceptionals+0x1a8>
    0.00 :   ffff80001018eee0:       b       ffff80001018ee50 <mark_page_accessed+0x1e0>
         : 238              __preempt_count_dec_and_test():
         : 73               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001018eee4:       ldr     x0, [x1, #8]
    0.00 :   ffff80001018eee8:       cbnz    x0, ffff80001018ee30 <mark_page_accessed+0x1c0>
         : 76               activate_page():
         : 361              local_unlock(&lru_pvecs.lock);
    0.00 :   ffff80001018eeec:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff80001018eef0:       b       ffff80001018ee30 <mark_page_accessed+0x1c0>
         : 364              __ll_sc_atomic64_or():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001018eef4:       b       ffff800010190c10 <pagevec_remove_exceptionals+0x1c0>
    0.00 :   ffff80001018eef8:       b       ffff80001018ee18 <mark_page_accessed+0x1a8>
         : 225              __ll_sc_atomic_add():
         : 111              ATOMIC_OPS(add, add, I)
    0.00 :   ffff80001018eefc:       b       ffff800010190c28 <pagevec_remove_exceptionals+0x1d8>
    0.00 :   ffff80001018ef00:       b       ffff80001018edf4 <mark_page_accessed+0x184>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010203eb0 <slab_post_alloc_hook>:
         : 6                slab_post_alloc_hook():
         : 511              * kasan_slab_alloc and initialization memset must be
         : 512              * kept together to avoid discrepancies in behavior.
         : 513              *
         : 514              * As p[i] might get tagged, memset and kmemleak hook come after KASAN.
         : 515              */
         : 516              for (i = 0; i < size; i++) {
    0.00 :   ffff800010203eb0:       paciasp
    0.00 :   ffff800010203eb4:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff800010203eb8:       mov     x29, sp
    0.00 :   ffff800010203ebc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010203ec0:       mov     x19, x4
    0.00 :   ffff800010203ec4:       mov     x20, x0
    0.00 :   ffff800010203ec8:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010203ecc:       mov     x21, x1
    0.00 :   ffff800010203ed0:       stp     x23, x24, [sp, #48]
    0.00 :   ffff800010203ed4:       mov     x23, x4
    0.00 :   ffff800010203ed8:       stp     x25, x26, [sp, #64]
    0.00 :   ffff800010203edc:       mov     x26, x3
         : 514              p[i] = kasan_slab_alloc(s, p[i], flags, init);
         : 515              if (p[i] && init && !kasan_has_integrated_init())
         : 516              memset(p[i], 0, s->object_size);
    0.00 :   ffff800010203ee0:       adrp    x3, ffff800011c29000 <page_wait_table+0x14c0>
         : 511              for (i = 0; i < size; i++) {
    0.00 :   ffff800010203ee4:       stp     x27, x28, [sp, #80]
    0.00 :   ffff800010203ee8:       add     x24, x4, x26, lsl #3
    0.00 :   ffff800010203eec:       mov     w27, w2
         : 514              memset(p[i], 0, s->object_size);
    0.00 :   ffff800010203ef0:       ldr     w22, [x3, #3512]
         :
         : 524              memcg_slab_post_alloc_hook(s, objcg, flags, size, p);
         : 525              }
         :
         : 527              #ifndef CONFIG_SLOB
         : 528              /*
    0.00 :   ffff800010203ef4:       and     w25, w5, #0xff
    0.00 :   ffff800010203ef8:       cbnz    x26, ffff800010203f08 <slab_post_alloc_hook+0x58>
    0.00 :   ffff800010203efc:       b       ffff800010203f30 <slab_post_alloc_hook+0x80>
    0.00 :   ffff800010203f00:       cmp     x24, x23
    0.00 :   ffff800010203f04:       b.eq    ffff800010203f30 <slab_post_alloc_hook+0x80>  // b.none
         : 524              * The slab lists for all objects.
    0.00 :   ffff800010203f08:       ldr     x0, [x23]
         : 525              */
    0.00 :   ffff800010203f0c:       add     x23, x23, #0x8
    0.00 :   ffff800010203f10:       cmp     x0, #0x0
    0.00 :   ffff800010203f14:       ccmp    w25, #0x0, #0x4, ne  // ne = any
    0.00 :   ffff800010203f18:       b.eq    ffff800010203f00 <slab_post_alloc_hook+0x50>  // b.none
         : 526              struct kmem_cache_node {
    0.00 :   ffff800010203f1c:       ldr     w2, [x20, #28]
    0.00 :   ffff800010203f20:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010203f24:       bl      ffff8000104a5e40 <__memset>
         : 523              /*
    0.00 :   ffff800010203f28:       cmp     x24, x23
    0.00 :   ffff800010203f2c:       b.ne    ffff800010203f08 <slab_post_alloc_hook+0x58>  // b.any
         : 526              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010203f30:       b       ffff8000102040dc <slab_post_alloc_hook+0x22c>
         : 45               memcg_slab_post_alloc_hook():
         : 309              continue;
    0.00 :   ffff800010203f34:       cbz     x21, ffff8000102040dc <slab_post_alloc_hook+0x22c>
         : 311              slab_post_alloc_hook():
         : 514              memset(p[i], 0, s->object_size);
    0.00 :   ffff800010203f38:       and     w22, w22, w27
    0.00 :   ffff800010203f3c:       add     x24, x19, x26, lsl #3
         : 517              memcg_slab_post_alloc_hook():
         : 312              off = obj_to_index(s, page, p[i]);
    0.00 :   ffff800010203f40:       and     w0, w22, #0xffbfffff
    0.00 :   ffff800010203f44:       str     w0, [sp, #108]
         : 313              obj_cgroup_get(objcg);
    0.00 :   ffff800010203f48:       cbz     x26, ffff8000102040d4 <slab_post_alloc_hook+0x224>
         : 315              page_pgdat():
         : 1542             }
         :
         : 1544             static inline pg_data_t *page_pgdat(const struct page *page)
         : 1545             {
         : 1546             return NODE_DATA(page_to_nid(page));
         : 1547             }
    0.00 :   ffff800010203f4c:       adrp    x23, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff800010203f50:       add     x23, x23, #0xf60
         : 1550             virt_to_head_page():
         :
    0.00 :   ffff800010203f54:       mov     x26, #0x1000000000000           // #281474976710656
    0.00 :   ffff800010203f58:       mov     x25, #0xfffffc0000000000        // #-4398046511104
    0.00 :   ffff800010203f5c:       nop
         : 901              memcg_slab_post_alloc_hook():
         : 314              page_objcgs(page)[off] = objcg;
    0.00 :   ffff800010203f60:       ldr     x0, [x19]
    0.00 :   ffff800010203f64:       cbz     x0, ffff80001020413c <slab_post_alloc_hook+0x28c>
         : 317              virt_to_head_page():
    0.00 :   ffff800010203f68:       add     x4, x0, x26
    0.00 :   ffff800010203f6c:       lsr     x4, x4, #12
    0.00 :   ffff800010203f70:       add     x22, x25, x4, lsl #6
         : 900              compound_head():
         : 184              };
         :
         : 186              #ifndef __GENERATING_BOUNDS_H
         :
         : 188              static inline unsigned long _compound_head(const struct page *page)
         : 189              {
    0.00 :   ffff800010203f74:       ldr     x1, [x22, #8]
         : 187              unsigned long head = READ_ONCE(page->compound_head);
         :
         : 189              if (unlikely(head & 1))
    0.00 :   ffff800010203f78:       sub     x2, x1, #0x1
    0.00 :   ffff800010203f7c:       tst     x1, #0x1
    0.00 :   ffff800010203f80:       csel    x22, x22, x2, eq  // eq = none
         : 193              page_objcgs():
         : 554              * kernel stack pages.
         : 555              */
         : 556              static inline struct obj_cgroup **page_objcgs(struct page *page)
         : 557              {
         : 558              unsigned long memcg_data = READ_ONCE(page->memcg_data);
         :
    0.00 :   ffff800010203f84:       ldr     x1, [x22, #56]
         : 561              memcg_slab_post_alloc_hook():
         : 317              } else {
    0.00 :   ffff800010203f88:       tst     x1, #0xfffffffffffffffc
    0.00 :   ffff800010203f8c:       b.ne    ffff800010203fac <slab_post_alloc_hook+0xfc>  // b.any
         : 318              obj_cgroup_uncharge(objcg, obj_full_size(s));
    0.00 :   ffff800010203f90:       ldr     w2, [sp, #108]
    0.00 :   ffff800010203f94:       mov     w3, #0x0                        // #0
    0.00 :   ffff800010203f98:       mov     x1, x20
    0.00 :   ffff800010203f9c:       mov     x0, x22
    0.00 :   ffff800010203fa0:       bl      ffff8000102245d0 <memcg_alloc_page_obj_cgroups>
         : 317              } else {
    0.00 :   ffff800010203fa4:       cbnz    w0, ffff80001020413c <slab_post_alloc_hook+0x28c>
    0.00 :   ffff800010203fa8:       ldr     x0, [x19]
         : 320              lowmem_page_address():
         : 1601             #include <linux/vmstat.h>
         :
         : 1603             static __always_inline void *lowmem_page_address(const struct page *page)
         : 1604             {
         : 1605             return page_to_virt(page);
         : 1606             }
    0.00 :   ffff800010203fac:       mov     x1, #0x40000000000              // #4398046511104
    0.00 :   ffff800010203fb0:       add     x1, x22, x1
    0.00 :   ffff800010203fb4:       mov     x5, #0xffff000000000000         // #-281474976710656
         : 1610             reciprocal_divide():
         : 35               */
         : 36               struct reciprocal_value reciprocal_value(u32 d);
         :
         : 38               static inline u32 reciprocal_divide(u32 a, struct reciprocal_value R)
         : 39               {
         : 40               u32 t = (u32)(((u64)a * R.m) >> 32);
    0.00 :   ffff800010203fb8:       ldr     w3, [x20, #32]
         : 42               lowmem_page_address():
    0.00 :   ffff800010203fbc:       lsr     x1, x1, #6
         : 1602             reciprocal_divide():
         : 36               return (t + ((a - t) >> R.sh1)) >> R.sh2;
    0.00 :   ffff800010203fc0:       ldrb    w28, [x20, #36]
    0.00 :   ffff800010203fc4:       ldrb    w2, [x20, #37]
         : 39               lowmem_page_address():
    0.00 :   ffff800010203fc8:       add     x1, x5, x1, lsl #12
         : 1602             __obj_to_index():
         :
         : 183              /* Determine object index from a given position */
         : 184              static inline unsigned int __obj_to_index(const struct kmem_cache *cache,
         : 185              void *addr, void *obj)
         : 186              {
         : 187              return reciprocal_divide(kasan_reset_tag(obj) - addr,
    0.00 :   ffff800010203fcc:       sub     x0, x0, x1
         : 189              reciprocal_divide():
         : 35               u32 t = (u32)(((u64)a * R.m) >> 32);
    0.00 :   ffff800010203fd0:       and     x1, x0, #0xffffffff
    0.00 :   ffff800010203fd4:       mul     x1, x1, x3
    0.00 :   ffff800010203fd8:       lsr     x1, x1, #32
         : 36               return (t + ((a - t) >> R.sh1)) >> R.sh2;
    0.00 :   ffff800010203fdc:       sub     w0, w0, w1
    0.00 :   ffff800010203fe0:       lsr     w28, w0, w28
    0.00 :   ffff800010203fe4:       add     w28, w28, w1
    0.00 :   ffff800010203fe8:       lsr     w28, w28, w2
         : 41               rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010203fec:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              __ref_is_percpu():
         : 174              * READ_ONCE() is required when fetching it.
         : 175              *
         : 176              * The dependency ordering from the READ_ONCE() pairs
         : 177              * with smp_store_release() in __percpu_ref_switch_to_percpu().
         : 178              */
         : 179              percpu_ptr = READ_ONCE(ref->percpu_count_ptr);
    0.00 :   ffff800010203ff0:       ldr     x0, [x21]
         : 182              * Theoretically, the following could test just ATOMIC; however,
         : 183              * then we'd have to mask off DEAD separately as DEAD may be
         : 184              * visible without ATOMIC if we race with percpu_ref_kill().  DEAD
         : 185              * implies ATOMIC anyway.  Test them together.
         : 186              */
         : 187              if (unlikely(percpu_ptr & __PERCPU_REF_ATOMIC_DEAD))
    0.00 :   ffff800010203ff4:       tst     x0, #0x3
    0.00 :   ffff800010203ff8:       b.ne    ffff800010204158 <slab_post_alloc_hook+0x2a8>  // b.any
         : 190              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010203ffc:       mrs     x1, sp_el0
         : 26               __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff800010204000:       ldr     w2, [x1, #8]
         : 47               pc += val;
    0.00 :   ffff800010204004:       add     w2, w2, #0x1
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff800010204008:       str     w2, [x1, #8]
         : 50               __percpu_add_case_64():
         :
         : 127              PERCPU_RW_OPS(8)
         : 128              PERCPU_RW_OPS(16)
         : 129              PERCPU_RW_OPS(32)
         : 130              PERCPU_RW_OPS(64)
         : 131              PERCPU_OP(add, add, stadd)
    0.00 :   ffff80001020400c:       mov     x3, #0x1                        // #1
         : 133              __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010204010:       mrs     x2, tpidr_el1
         : 41               __percpu_add_case_64():
         : 126              PERCPU_OP(add, add, stadd)
    0.00 :   ffff800010204014:       add     x0, x0, x2
    0.00 :   ffff800010204018:       ldxr    x6, [x0]
    0.00 :   ffff80001020401c:       add     x6, x6, x3
    0.00 :   ffff800010204020:       stxr    w5, x6, [x0]
    0.00 :   ffff800010204024:       cbnz    w5, ffff800010204018 <slab_post_alloc_hook+0x168>
         : 132              __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010204028:       ldr     x0, [x1, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001020402c:       sub     x0, x0, #0x1
    0.00 :   ffff800010204030:       str     w0, [x1, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff800010204034:       cbnz    x0, ffff8000102040fc <slab_post_alloc_hook+0x24c>
         : 80               percpu_ref_get_many():
         : 205              unsigned long __percpu *percpu_count;
         :
         : 207              rcu_read_lock();
         :
         : 209              if (__ref_is_percpu(ref, &percpu_count))
         : 210              this_cpu_add(*percpu_count, nr);
    0.00 :   ffff800010204038:       bl      ffff800010e2e658 <preempt_schedule_notrace>
         : 212              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff80001020403c:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              page_objcgs():
    0.00 :   ffff800010204040:       ldr     x0, [x22, #56]
         : 559              VM_BUG_ON_PAGE(memcg_data && !(memcg_data & MEMCG_DATA_OBJCGS), page);
         : 560              VM_BUG_ON_PAGE(memcg_data & MEMCG_DATA_KMEM, page);
         :
         : 562              return (struct obj_cgroup **)(memcg_data & ~MEMCG_DATA_FLAGS_MASK);
         : 563              }
    0.00 :   ffff800010204044:       and     x0, x0, #0xfffffffffffffffc
         : 565              memcg_slab_post_alloc_hook():
         : 326              {
    0.00 :   ffff800010204048:       str     x21, [x0, w28, uxtw #3]
         : 328              page_to_nid():
         : 1374             }
    0.00 :   ffff80001020404c:       ldr     x0, [x22]
         : 1376             cache_vmstat_idx():
         : 207              return (s->flags & SLAB_RECLAIM_ACCOUNT) ?
    0.00 :   ffff800010204050:       ldr     w1, [x20, #8]
         : 209              obj_full_size():
         : 255              * For each accounted object there is an extra space which is used
    0.00 :   ffff800010204054:       ldr     w2, [x20, #24]
         : 257              page_pgdat():
         : 1542             }
    0.00 :   ffff800010204058:       lsr     x0, x0, #60
         : 1544             cache_vmstat_idx():
         : 208              NR_SLAB_RECLAIMABLE_B : NR_SLAB_UNRECLAIMABLE_B;
    0.00 :   ffff80001020405c:       tst     x1, #0x20000
         : 210              obj_full_size():
         : 255              * For each accounted object there is an extra space which is used
    0.00 :   ffff800010204060:       add     x27, x2, #0x8
         : 257              cache_vmstat_idx():
         : 208              NR_SLAB_RECLAIMABLE_B : NR_SLAB_UNRECLAIMABLE_B;
    0.00 :   ffff800010204064:       cset    w28, eq  // eq = none
         : 210              page_pgdat():
    0.00 :   ffff800010204068:       ldr     x22, [x23, x0, lsl #3]
         : 1543             rcu_read_lock():
         : 655              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff80001020406c:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 657              cache_vmstat_idx():
    0.00 :   ffff800010204070:       add     w28, w28, #0x5
         : 209              obj_cgroup_memcg():
         : 386              }
    0.00 :   ffff800010204074:       ldr     x0, [x21, #16]
         : 388              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010204078:       nop
         : 23               mem_cgroup_lruvec():
         : 728              goto out;
         : 729              }
         :
         : 731              if (!memcg)
         : 732              memcg = root_mem_cgroup;
         :
    0.00 :   ffff80001020407c:       adrp    x4, ffff800011c2b000 <mm_slots_hash+0x10f8>
         : 730              mz = memcg->nodeinfo[pgdat->node_id];
         : 731              lruvec = &mz->lruvec;
    0.00 :   ffff800010204080:       ldrsw   x3, [x22, #8512]
         :
    0.00 :   ffff800010204084:       cmp     x0, #0x0
    0.00 :   ffff800010204088:       ldr     x4, [x4, #3856]
    0.00 :   ffff80001020408c:       csel    x0, x4, x0, eq  // eq = none
         : 730              lruvec = &mz->lruvec;
    0.00 :   ffff800010204090:       add     x0, x0, x3, lsl #3
         : 731              out:
    0.00 :   ffff800010204094:       ldr     x0, [x0, #3960]
         : 738              * Since a node can be onlined after the mem_cgroup was created,
         : 739              * we have to be prepared to initialize lruvec->pgdat here;
         : 740              * and if offlined then reonlined, we need to reinitialize it.
         : 741              */
         : 742              if (unlikely(lruvec->pgdat != pgdat))
         : 743              lruvec->pgdat = pgdat;
    0.00 :   ffff800010204098:       ldr     x3, [x0, #136]
    0.00 :   ffff80001020409c:       cmp     x22, x3
    0.00 :   ffff8000102040a0:       b.ne    ffff800010204124 <slab_post_alloc_hook+0x274>  // b.any
         : 747              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000102040a4:       mrs     x22, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000102040a8:       and     w1, w22, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff8000102040ac:       cbz     w1, ffff80001020412c <slab_post_alloc_hook+0x27c>
         : 118              mod_memcg_lruvec_state():
         : 1034             local_irq_save(flags);
         : 1035             __count_memcg_events(memcg, idx, count);
         : 1036             local_irq_restore(flags);
         : 1037             }
         :
         : 1039             static inline void count_memcg_page_event(struct page *page,
    0.00 :   ffff8000102040b0:       mov     w2, w27
    0.00 :   ffff8000102040b4:       mov     w1, w28
    0.00 :   ffff8000102040b8:       bl      ffff800010221ed0 <__mod_memcg_lruvec_state>
         : 1043             arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
    0.00 :   ffff8000102040bc:       msr     daif, x22
         : 129              arch_static_branch():
    0.00 :   ffff8000102040c0:       nop
         : 22               rcu_read_unlock():
         : 710              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000102040c4:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              *
    0.00 :   ffff8000102040c8:       add     x19, x19, #0x8
         : 713              memcg_slab_post_alloc_hook():
         : 313              obj_cgroup_get(objcg);
    0.00 :   ffff8000102040cc:       cmp     x19, x24
    0.00 :   ffff8000102040d0:       b.ne    ffff800010203f60 <slab_post_alloc_hook+0xb0>  // b.any
         : 316              percpu_ref_put():
         : 338              *
         : 339              * This function is safe to call as long as @ref is between init and exit.
         : 340              */
         : 341              static inline void percpu_ref_put(struct percpu_ref *ref)
         : 342              {
         : 343              percpu_ref_put_many(ref, 1);
    0.00 :   ffff8000102040d4:       mov     x0, x21
    0.00 :   ffff8000102040d8:       bl      ffff800010203de0 <percpu_ref_put_many.constprop.111>
         : 346              slab_post_alloc_hook():
         : 532              spinlock_t list_lock;
         :
         : 534              #ifdef CONFIG_SLAB
         : 535              struct list_head slabs_partial; /* partial list first, better asm code */
         : 536              struct list_head slabs_full;
         : 537              struct list_head slabs_free;
    0.00 :   ffff8000102040dc:       ldp     x19, x20, [sp, #16]
  100.00 :   ffff8000102040e0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000102040e4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000102040e8:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000102040ec:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000102040f0:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000102040f4:       autiasp
    0.00 :   ffff8000102040f8:       ret
         : 546              __preempt_count_dec_and_test():
    0.00 :   ffff8000102040fc:       ldr     x0, [x1, #8]
    0.00 :   ffff800010204100:       cbz     x0, ffff800010204038 <slab_post_alloc_hook+0x188>
    0.00 :   ffff800010204104:       b       ffff80001020403c <slab_post_alloc_hook+0x18c>
         : 76               arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff800010204108:       dsb     sy
    0.00 :   ffff80001020410c:       b       ffff8000102040c4 <slab_post_alloc_hook+0x214>
         : 138              mem_cgroup_lruvec():
         : 723              goto out;
    0.00 :   ffff800010204110:       mov     x0, #0x2220                     // #8736
    0.00 :   ffff800010204114:       add     x0, x22, x0
         : 738              lruvec->pgdat = pgdat;
    0.00 :   ffff800010204118:       ldr     x3, [x0, #136]
    0.00 :   ffff80001020411c:       cmp     x22, x3
    0.00 :   ffff800010204120:       b.eq    ffff8000102040a4 <slab_post_alloc_hook+0x1f4>  // b.none
         : 739              return lruvec;
    0.00 :   ffff800010204124:       str     x22, [x0, #136]
    0.00 :   ffff800010204128:       b       ffff8000102040a4 <slab_post_alloc_hook+0x1f4>
         : 742              arch_static_branch():
    0.00 :   ffff80001020412c:       nop
    0.00 :   ffff800010204130:       mov     x1, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010204134:       msr     daifset, #0x3
    0.00 :   ffff800010204138:       b       ffff8000102040b0 <slab_post_alloc_hook+0x200>
         : 57               obj_full_size():
         : 255              * For each accounted object there is an extra space which is used
    0.00 :   ffff80001020413c:       ldr     w1, [x20, #24]
         : 257              memcg_slab_post_alloc_hook():
         : 330              struct page *page;
    0.00 :   ffff800010204140:       mov     x0, x21
    0.00 :   ffff800010204144:       add     x1, x1, #0x8
    0.00 :   ffff800010204148:       bl      ffff800010224e28 <obj_cgroup_uncharge>
    0.00 :   ffff80001020414c:       b       ffff8000102040c8 <slab_post_alloc_hook+0x218>
         : 335              arch_static_branch():
    0.00 :   ffff800010204150:       mov     x1, #0xa0                       // #160
    0.00 :   ffff800010204154:       b       ffff800010204134 <slab_post_alloc_hook+0x284>
         : 23               percpu_ref_get_many():
         : 207              atomic_long_add(nr, &ref->data->count);
    0.00 :   ffff800010204158:       ldr     x1, [x21, #8]
         : 209              arch_atomic64_add():
         : 67               }
         :
         : 69               ATOMIC64_OP(atomic64_andnot)
         : 70               ATOMIC64_OP(atomic64_or)
         : 71               ATOMIC64_OP(atomic64_xor)
         : 72               ATOMIC64_OP(atomic64_add)
    0.00 :   ffff80001020415c:       bl      ffff800010202150 <system_uses_lse_atomics>
    0.00 :   ffff800010204160:       tst     w0, #0xff
    0.00 :   ffff800010204164:       b.eq    ffff800010204174 <slab_post_alloc_hook+0x2c4>  // b.none
         : 76               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff800010204168:       mov     x0, #0x1                        // #1
    0.00 :   ffff80001020416c:       stadd   x0, [x1]
    0.00 :   ffff800010204170:       b       ffff80001020403c <slab_post_alloc_hook+0x18c>
         : 188              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff800010204174:       b       ffff80001020b554 <slabinfo_write+0x104>
    0.00 :   ffff800010204178:       b       ffff80001020403c <slab_post_alloc_hook+0x18c>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010e2b6a8 <arch_cpu_idle>:
         : 6                arch_cpu_idle():
         : 125              pm_power_off();
         : 126              }
         :
         : 128              /*
         : 129              * Restart requires that the secondary CPUs stop performing any activity
         : 130              * while the primary CPU resets the system. Systems with multiple CPUs must
    0.00 :   ffff800010e2b6a8:       paciasp
    0.00 :   ffff800010e2b6ac:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010e2b6b0:       mov     x29, sp
         : 130              * provide a HW restart implementation, to ensure that all CPUs reset at once.
         : 131              * This is required so that any code running after reset on the primary CPU
         : 132              * doesn't have to co-ordinate with other CPUs to ensure they aren't still
         : 133              * executing pre-reset code, and using RAM that the primary CPU's code wishes
         : 134              * to use. Implementing such co-ordination would be essentially impossible.
    0.00 :   ffff800010e2b6b4:       bl      ffff800010e2b660 <cpu_do_idle>
         : 136              arch_local_irq_enable():
         : 35               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 37               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 38               }
         :
         : 40               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010e2b6b8:       mov     x0, #0xe0                       // #224
    0.00 :   ffff800010e2b6bc:       msr     daifclr, #0x3
         : 43               arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
  100.00 :   ffff800010e2b6c0:       nop
         : 28               arch_cpu_idle():
         : 132              */
         : 133              void machine_restart(char *cmd)
    0.00 :   ffff800010e2b6c4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e2b6c8:       autiasp
    0.00 :   ffff800010e2b6cc:       ret
         : 137              arch_local_irq_enable():
         : 43               ARM64_HAS_IRQ_PRIO_MASKING)
         : 44               :
         : 45               : "r" ((unsigned long) GIC_PRIO_IRQON)
         : 46               : "memory");
         :
         : 48               pmr_sync();
    0.00 :   ffff800010e2b6d0:       dsb     sy
         : 50               arch_cpu_idle():
    0.00 :   ffff800010e2b6d4:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010e2b6d8:       autiasp
    0.00 :   ffff800010e2b6dc:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010355650 <jbd2_journal_dirty_metadata>:
         : 6                jbd2_journal_dirty_metadata():
         : 1457             * data present for that commit).  In that case, we don't relink the
         : 1458             * buffer: that only gets done when the old transaction finally
         : 1459             * completes its commit.
         : 1460             */
         : 1461             int jbd2_journal_dirty_metadata(handle_t *handle, struct buffer_head *bh)
         : 1462             {
    0.00 :   ffff800010355650:       paciasp
    0.00 :   ffff800010355654:       sub     sp, sp, #0x60
    0.00 :   ffff800010355658:       stp     x29, x30, [sp, #16]
    0.00 :   ffff80001035565c:       add     x29, sp, #0x10
    0.00 :   ffff800010355660:       stp     x19, x20, [sp, #32]
    0.00 :   ffff800010355664:       stp     x23, x24, [sp, #64]
         : 1469             is_handle_aborted():
         : 1661             */
         :
         : 1663             static inline int is_journal_aborted(journal_t *journal)
         : 1664             {
         : 1665             return journal->j_flags & JBD2_ABORT;
         : 1666             }
  100.00 :   ffff800010355668:       ldrb    w2, [x0, #36]
         : 1668             jbd2_journal_dirty_metadata():
         : 1458             transaction_t *transaction = handle->h_transaction;
    0.00 :   ffff80001035566c:       ldr     x20, [x0]
         : 1460             is_handle_aborted():
    0.00 :   ffff800010355670:       tst     x2, #0x8
    0.00 :   ffff800010355674:       ccmp    x20, #0x0, #0x4, eq  // eq = none
    0.00 :   ffff800010355678:       b.eq    ffff800010355720 <jbd2_journal_dirty_metadata+0xd0>  // b.none
         :
         : 1664             static inline int is_handle_aborted(handle_t *handle)
    0.00 :   ffff80001035567c:       ldr     x24, [x20]
         : 1666             is_journal_aborted():
         : 1656             */
    0.00 :   ffff800010355680:       ldr     x2, [x24]
         : 1658             jbd2_journal_dirty_metadata():
         : 1463             journal_t *journal;
         : 1464             struct journal_head *jh;
         : 1465             int ret = 0;
         :
         : 1467             if (is_handle_aborted(handle))
    0.00 :   ffff800010355684:       and     w23, w2, #0x2
    0.00 :   ffff800010355688:       tbnz    w2, #1, ffff800010355720 <jbd2_journal_dirty_metadata+0xd0>
         : 1470             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001035568c:       ldr     x2, [x1]
         : 113              jbd2_journal_dirty_metadata():
         : 1465             return -EROFS;
         : 1466             if (!buffer_jbd(bh))
    0.00 :   ffff800010355690:       tst     w2, #0x10000
    0.00 :   ffff800010355694:       b.eq    ffff800010355958 <jbd2_journal_dirty_metadata+0x308>  // b.none
    0.00 :   ffff800010355698:       stp     x21, x22, [sp, #48]
    0.00 :   ffff80001035569c:       mov     x19, x0
         :
         : 1473             /*
         : 1474             * We don't grab jh reference here since the buffer must be part
         : 1475             * of the running transaction.
         : 1476             */
         : 1477             jh = bh2jh(bh);
    0.00 :   ffff8000103556a0:       mov     x22, x1
    0.00 :   ffff8000103556a4:       str     x25, [sp, #80]
    0.00 :   ffff8000103556a8:       ldr     x21, [x1, #64]
         : 1482             * This and the following assertions are unreliable since we may see jh
         : 1483             * in inconsistent state unless we grab bh_state lock. But this is
         : 1484             * crucial to catch bugs so let's do a reliable check until the
         : 1485             * lockless handling is fully proven.
         : 1486             */
         : 1487             if (data_race(jh->b_transaction != transaction &&
    0.00 :   ffff8000103556ac:       ldr     x0, [x21, #40]
    0.00 :   ffff8000103556b0:       cmp     x0, x20
    0.00 :   ffff8000103556b4:       b.eq    ffff800010355804 <jbd2_journal_dirty_metadata+0x1b4>  // b.none
    0.00 :   ffff8000103556b8:       ldr     x0, [x21, #48]
    0.00 :   ffff8000103556bc:       cmp     x0, x20
    0.00 :   ffff8000103556c0:       b.eq    ffff800010355740 <jbd2_journal_dirty_metadata+0xf0>  // b.none
         : 1485             spin_lock():
         : 354              # define spin_lock_init(_lock)                  \
         : 355              do {                                            \
         : 356              spinlock_check(_lock);                  \
         : 357              *(_lock) = __SPIN_LOCK_UNLOCKED(_lock); \
         : 358              } while (0)
         :
    0.00 :   ffff8000103556c4:       add     x25, x21, #0x8
    0.00 :   ffff8000103556c8:       mov     x0, x25
    0.00 :   ffff8000103556cc:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 363              jbd2_journal_dirty_metadata():
         : 1485             jh->b_next_transaction != transaction)) {
         : 1486             spin_lock(&jh->b_state_lock);
         : 1487             J_ASSERT_JH(jh, jh->b_transaction == transaction ||
    0.00 :   ffff8000103556d0:       ldr     x0, [x21, #40]
    0.00 :   ffff8000103556d4:       cmp     x0, x20
    0.00 :   ffff8000103556d8:       b.ne    ffff800010355904 <jbd2_journal_dirty_metadata+0x2b4>  // b.any
         : 1491             spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000103556dc:       mov     x0, x25
    0.00 :   ffff8000103556e0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 402              jbd2_journal_dirty_metadata():
         : 1489             jh->b_next_transaction == transaction);
         : 1490             spin_unlock(&jh->b_state_lock);
         : 1491             }
         : 1492             if (jh->b_modified == 1) {
    0.00 :   ffff8000103556e4:       ldr     w0, [x21, #20]
    0.00 :   ffff8000103556e8:       cmp     w0, #0x1
    0.00 :   ffff8000103556ec:       b.ne    ffff800010355848 <jbd2_journal_dirty_metadata+0x1f8>  // b.any
         : 1491             /* If it's in our transaction it must be in BJ_Metadata list. */
         : 1492             if (data_race(jh->b_transaction == transaction &&
    0.00 :   ffff8000103556f0:       ldr     x0, [x21, #40]
    0.00 :   ffff8000103556f4:       cmp     x0, x20
    0.00 :   ffff8000103556f8:       b.eq    ffff800010355810 <jbd2_journal_dirty_metadata+0x1c0>  // b.none
         : 1599             out_unlock_bh:
         : 1600             spin_unlock(&jh->b_state_lock);
         : 1601             out:
         : 1602             JBUFFER_TRACE(jh, "exit");
         : 1603             return ret;
         : 1604             }
    0.00 :   ffff8000103556fc:       mov     w0, w23
    0.00 :   ffff800010355700:       ldp     x29, x30, [sp, #16]
    0.00 :   ffff800010355704:       ldp     x19, x20, [sp, #32]
    0.00 :   ffff800010355708:       ldp     x21, x22, [sp, #48]
    0.00 :   ffff80001035570c:       ldp     x23, x24, [sp, #64]
    0.00 :   ffff800010355710:       ldr     x25, [sp, #80]
    0.00 :   ffff800010355714:       add     sp, sp, #0x60
    0.00 :   ffff800010355718:       autiasp
    0.00 :   ffff80001035571c:       ret
         : 1464             return -EROFS;
    0.00 :   ffff800010355720:       mov     w23, #0xffffffe2                // #-30
         : 1599             }
    0.00 :   ffff800010355724:       mov     w0, w23
    0.00 :   ffff800010355728:       ldp     x29, x30, [sp, #16]
    0.00 :   ffff80001035572c:       ldp     x19, x20, [sp, #32]
    0.00 :   ffff800010355730:       ldp     x23, x24, [sp, #64]
    0.00 :   ffff800010355734:       add     sp, sp, #0x60
    0.00 :   ffff800010355738:       autiasp
    0.00 :   ffff80001035573c:       ret
         : 1489             if (jh->b_modified == 1) {
    0.00 :   ffff800010355740:       ldr     w0, [x21, #20]
    0.00 :   ffff800010355744:       cmp     w0, #0x1
    0.00 :   ffff800010355748:       b.eq    ffff8000103556fc <jbd2_journal_dirty_metadata+0xac>  // b.none
    0.00 :   ffff80001035574c:       add     x25, x21, #0x8
         : 1494             spin_lock():
         :
    0.00 :   ffff800010355750:       mov     x0, x25
    0.00 :   ffff800010355754:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 357              jbd2_journal_dirty_metadata():
         : 1511             if (jh->b_modified == 0) {
    0.00 :   ffff800010355758:       ldr     w0, [x21, #20]
    0.00 :   ffff80001035575c:       cbnz    w0, ffff8000103557a8 <jbd2_journal_dirty_metadata+0x158>
         : 1514             jbd2_handle_buffer_credits():
         : 1781             tid = journal->j_running_transaction->t_tid;
         : 1782             read_unlock(&journal->j_state_lock);
         : 1783             return tid;
         : 1784             }
         :
         : 1786             static inline int jbd2_handle_buffer_credits(handle_t *handle)
    0.00 :   ffff800010355760:       ldrb    w0, [x19, #36]
    0.00 :   ffff800010355764:       ldr     x1, [x19]
    0.00 :   ffff800010355768:       tbnz    w0, #2, ffff800010355770 <jbd2_journal_dirty_metadata+0x120>
         : 1782             {
    0.00 :   ffff80001035576c:       ldr     x1, [x1]
         : 1787             journal_t *journal;
         :
         : 1789             if (!handle->h_reserved)
         : 1790             journal = handle->h_transaction->t_journal;
         : 1791             else
    0.00 :   ffff800010355770:       ldr     w0, [x19, #24]
    0.00 :   ffff800010355774:       ldr     w2, [x1, #1044]
    0.00 :   ffff800010355778:       sub     w0, w0, #0x1
         : 1786             journal = handle->h_transaction->t_journal;
    0.00 :   ffff80001035577c:       ldr     w1, [x19, #16]
         : 1787             else
    0.00 :   ffff800010355780:       add     w0, w0, w2
    0.00 :   ffff800010355784:       sdiv    w0, w0, w2
         : 1786             journal = handle->h_transaction->t_journal;
    0.00 :   ffff800010355788:       sub     w0, w1, w0
         : 1788             jbd2_journal_dirty_metadata():
         : 1517             if (WARN_ON_ONCE(jbd2_handle_buffer_credits(handle) <= 0)) {
    0.00 :   ffff80001035578c:       cmp     w0, #0x0
    0.00 :   ffff800010355790:       b.le    ffff800010355948 <jbd2_journal_dirty_metadata+0x2f8>
         : 1521             jh->b_modified = 1;
    0.00 :   ffff800010355794:       mov     w0, #0x1                        // #1
    0.00 :   ffff800010355798:       str     w0, [x21, #20]
         : 1522             handle->h_total_credits--;
    0.00 :   ffff80001035579c:       ldr     w0, [x19, #16]
    0.00 :   ffff8000103557a0:       sub     w0, w0, #0x1
    0.00 :   ffff8000103557a4:       str     w0, [x19, #16]
         : 1532             if (jh->b_transaction == transaction && jh->b_jlist == BJ_Metadata) {
    0.00 :   ffff8000103557a8:       ldr     x3, [x21, #40]
    0.00 :   ffff8000103557ac:       cmp     x3, x20
    0.00 :   ffff8000103557b0:       b.eq    ffff800010355850 <jbd2_journal_dirty_metadata+0x200>  // b.none
         : 1536             test_bit():
    0.00 :   ffff8000103557b4:       ldr     x0, [x22]
         : 107              set_buffer_jbddirty():
         : 331              BUFFER_FNS(JBDDirty, jbddirty)
    0.00 :   ffff8000103557b8:       tst     w0, #0x200000
    0.00 :   ffff8000103557bc:       b.eq    ffff800010355868 <jbd2_journal_dirty_metadata+0x218>  // b.none
         : 334              jbd2_journal_dirty_metadata():
         : 1561             if (unlikely(((jh->b_transaction !=
    0.00 :   ffff8000103557c0:       ldr     x0, [x24, #120]
    0.00 :   ffff8000103557c4:       ldr     x7, [x21, #48]
    0.00 :   ffff8000103557c8:       cmp     x0, x3
    0.00 :   ffff8000103557cc:       b.ne    ffff800010355960 <jbd2_journal_dirty_metadata+0x310>  // b.any
    0.00 :   ffff8000103557d0:       cmp     x7, x20
    0.00 :   ffff8000103557d4:       b.ne    ffff800010355960 <jbd2_journal_dirty_metadata+0x310>  // b.any
         : 1563             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000103557d8:       mov     x0, x25
    0.00 :   ffff8000103557dc:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 397              jbd2_journal_dirty_metadata():
         : 1599             }
    0.00 :   ffff8000103557e0:       mov     w0, w23
    0.00 :   ffff8000103557e4:       ldp     x29, x30, [sp, #16]
    0.00 :   ffff8000103557e8:       ldp     x19, x20, [sp, #32]
    0.00 :   ffff8000103557ec:       ldp     x21, x22, [sp, #48]
    0.00 :   ffff8000103557f0:       ldp     x23, x24, [sp, #64]
    0.00 :   ffff8000103557f4:       ldr     x25, [sp, #80]
    0.00 :   ffff8000103557f8:       add     sp, sp, #0x60
    0.00 :   ffff8000103557fc:       autiasp
    0.00 :   ffff800010355800:       ret
         : 1489             if (jh->b_modified == 1) {
    0.00 :   ffff800010355804:       ldr     w0, [x21, #20]
    0.00 :   ffff800010355808:       cmp     w0, #0x1
    0.00 :   ffff80001035580c:       b.ne    ffff80001035574c <jbd2_journal_dirty_metadata+0xfc>  // b.any
         : 1491             if (data_race(jh->b_transaction == transaction &&
    0.00 :   ffff800010355810:       ldr     w0, [x21, #16]
    0.00 :   ffff800010355814:       cmp     w0, #0x1
    0.00 :   ffff800010355818:       b.eq    ffff8000103556fc <jbd2_journal_dirty_metadata+0xac>  // b.none
         : 1495             spin_lock():
         :
    0.00 :   ffff80001035581c:       add     x24, x21, #0x8
    0.00 :   ffff800010355820:       mov     x0, x24
    0.00 :   ffff800010355824:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 358              jbd2_journal_dirty_metadata():
         : 1494             if (jh->b_transaction == transaction &&
    0.00 :   ffff800010355828:       ldr     x0, [x21, #40]
    0.00 :   ffff80001035582c:       cmp     x0, x20
    0.00 :   ffff800010355830:       b.eq    ffff8000103558bc <jbd2_journal_dirty_metadata+0x26c>  // b.none
         : 1498             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff800010355834:       mov     x0, x24
    0.00 :   ffff800010355838:       bl      ffff800010e349f0 <_raw_spin_unlock>
    0.00 :   ffff80001035583c:       ldp     x21, x22, [sp, #48]
    0.00 :   ffff800010355840:       ldr     x25, [sp, #80]
    0.00 :   ffff800010355844:       b       ffff800010355724 <jbd2_journal_dirty_metadata+0xd4>
    0.00 :   ffff800010355848:       ldr     x24, [x20]
    0.00 :   ffff80001035584c:       b       ffff800010355750 <jbd2_journal_dirty_metadata+0x100>
         : 402              jbd2_journal_dirty_metadata():
         : 1532             if (jh->b_transaction == transaction && jh->b_jlist == BJ_Metadata) {
    0.00 :   ffff800010355850:       ldr     w0, [x21, #16]
    0.00 :   ffff800010355854:       cmp     w0, #0x1
    0.00 :   ffff800010355858:       b.eq    ffff800010355914 <jbd2_journal_dirty_metadata+0x2c4>  // b.none
         : 1536             test_bit():
    0.00 :   ffff80001035585c:       ldr     x0, [x22]
         : 107              set_buffer_jbddirty():
    0.00 :   ffff800010355860:       tst     w0, #0x200000
    0.00 :   ffff800010355864:       b.ne    ffff80001035588c <jbd2_journal_dirty_metadata+0x23c>  // b.any
         : 333              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010355868:       b       ffff80001035587c <jbd2_journal_dirty_metadata+0x22c>
    0.00 :   ffff80001035586c:       b       ffff80001035587c <jbd2_journal_dirty_metadata+0x22c>
         : 46               __lse_atomic64_or():
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010355870:       mov     x0, #0x200000                   // #2097152
    0.00 :   ffff800010355874:       stset   x0, [x22]
    0.00 :   ffff800010355878:       b       ffff800010355880 <jbd2_journal_dirty_metadata+0x230>
         : 186              __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001035587c:       b       ffff800010356704 <jbd2_journal_begin_ordered_truncate+0x324>
         : 229              jbd2_journal_dirty_metadata():
         : 1559             if (jh->b_transaction != transaction) {
    0.00 :   ffff800010355880:       ldr     x3, [x21, #40]
    0.00 :   ffff800010355884:       cmp     x3, x20
    0.00 :   ffff800010355888:       b.ne    ffff8000103557c0 <jbd2_journal_dirty_metadata+0x170>  // b.any
         : 1588             J_ASSERT_JH(jh, jh->b_frozen_data == NULL);
    0.00 :   ffff80001035588c:       ldr     x0, [x21, #24]
    0.00 :   ffff800010355890:       cbnz    x0, ffff800010355954 <jbd2_journal_dirty_metadata+0x304>
         : 1591             spin_lock():
         :
    0.00 :   ffff800010355894:       add     x24, x24, #0x3d8
    0.00 :   ffff800010355898:       mov     x0, x24
    0.00 :   ffff80001035589c:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 358              jbd2_journal_dirty_metadata():
         : 1592             __jbd2_journal_file_buffer(jh, transaction, BJ_Metadata);
    0.00 :   ffff8000103558a0:       mov     x1, x20
    0.00 :   ffff8000103558a4:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000103558a8:       mov     x0, x21
    0.00 :   ffff8000103558ac:       bl      ffff800010354c50 <__jbd2_journal_file_buffer>
         : 1597             spin_unlock():
         : 394              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff8000103558b0:       mov     x0, x24
    0.00 :   ffff8000103558b4:       bl      ffff800010e349f0 <_raw_spin_unlock>
    0.00 :   ffff8000103558b8:       b       ffff8000103557d8 <jbd2_journal_dirty_metadata+0x188>
         : 398              jbd2_journal_dirty_metadata():
         : 1495             jh->b_jlist != BJ_Metadata)
    0.00 :   ffff8000103558bc:       ldr     w4, [x21, #16]
         : 1494             if (jh->b_transaction == transaction &&
    0.00 :   ffff8000103558c0:       cmp     w4, #0x1
    0.00 :   ffff8000103558c4:       b.eq    ffff800010355834 <jbd2_journal_dirty_metadata+0x1e4>  // b.none
         : 1496             pr_err("JBD2: assertion failure: h_type=%u "
    0.00 :   ffff8000103558c8:       ldr     x3, [x22, #24]
    0.00 :   ffff8000103558cc:       adrp    x0, ffff800011439000 <kallsyms_token_index+0x2e7a0>
    0.00 :   ffff8000103558d0:       ldrh    w1, [x19, #36]
    0.00 :   ffff8000103558d4:       add     x0, x0, #0xdd8
    0.00 :   ffff8000103558d8:       ldr     w2, [x19, #36]
    0.00 :   ffff8000103558dc:       ubfx    x1, x1, #4, #8
    0.00 :   ffff8000103558e0:       ubfx    x2, x2, #12, #16
    0.00 :   ffff8000103558e4:       bl      ffff800010e19544 <printk>
         : 1501             J_ASSERT_JH(jh, jh->b_transaction != transaction ||
    0.00 :   ffff8000103558e8:       ldr     x0, [x21, #40]
    0.00 :   ffff8000103558ec:       cmp     x0, x20
    0.00 :   ffff8000103558f0:       b.ne    ffff800010355834 <jbd2_journal_dirty_metadata+0x1e4>  // b.any
    0.00 :   ffff8000103558f4:       ldr     w0, [x21, #16]
    0.00 :   ffff8000103558f8:       cmp     w0, #0x1
    0.00 :   ffff8000103558fc:       b.eq    ffff800010355834 <jbd2_journal_dirty_metadata+0x1e4>  // b.none
    0.00 :   ffff800010355900:       brk     #0x800
         : 1485             J_ASSERT_JH(jh, jh->b_transaction == transaction ||
    0.00 :   ffff800010355904:       ldr     x0, [x21, #48]
    0.00 :   ffff800010355908:       cmp     x0, x20
    0.00 :   ffff80001035590c:       b.eq    ffff8000103556dc <jbd2_journal_dirty_metadata+0x8c>  // b.none
    0.00 :   ffff800010355910:       brk     #0x800
         : 1534             if (unlikely(jh->b_transaction !=
    0.00 :   ffff800010355914:       ldr     x5, [x24, #112]
    0.00 :   ffff800010355918:       cmp     x20, x5
    0.00 :   ffff80001035591c:       b.eq    ffff8000103557d8 <jbd2_journal_dirty_metadata+0x188>  // b.none
         : 1536             printk(KERN_ERR "JBD2: %s: "
    0.00 :   ffff800010355920:       cbz     x5, ffff8000103559a8 <jbd2_journal_dirty_metadata+0x358>
    0.00 :   ffff800010355924:       ldr     w6, [x5, #8]
    0.00 :   ffff800010355928:       ldr     w4, [x3, #8]
    0.00 :   ffff80001035592c:       add     x1, x24, #0x390
    0.00 :   ffff800010355930:       ldr     x2, [x22, #24]
    0.00 :   ffff800010355934:       adrp    x0, ffff800011439000 <kallsyms_token_index+0x2e7a0>
         : 1546             ret = -EINVAL;
    0.00 :   ffff800010355938:       mov     w23, #0xffffffea                // #-22
         : 1536             printk(KERN_ERR "JBD2: %s: "
    0.00 :   ffff80001035593c:       add     x0, x0, #0xe28
    0.00 :   ffff800010355940:       bl      ffff800010e19544 <printk>
         : 1546             ret = -EINVAL;
    0.00 :   ffff800010355944:       b       ffff8000103557d8 <jbd2_journal_dirty_metadata+0x188>
         : 1517             if (WARN_ON_ONCE(jbd2_handle_buffer_credits(handle) <= 0)) {
    0.00 :   ffff800010355948:       brk     #0x800
         : 1518             ret = -ENOSPC;
    0.00 :   ffff80001035594c:       mov     w23, #0xffffffe4                // #-28
    0.00 :   ffff800010355950:       b       ffff8000103557d8 <jbd2_journal_dirty_metadata+0x188>
         : 1588             J_ASSERT_JH(jh, jh->b_frozen_data == NULL);
    0.00 :   ffff800010355954:       brk     #0x800
         : 1466             return -EUCLEAN;
    0.00 :   ffff800010355958:       mov     w23, #0xffffff8b                // #-117
    0.00 :   ffff80001035595c:       b       ffff800010355724 <jbd2_journal_dirty_metadata+0xd4>
         : 1564             printk(KERN_ERR "jbd2_journal_dirty_metadata: %s: "
    0.00 :   ffff800010355960:       cbz     x3, ffff8000103559b0 <jbd2_journal_dirty_metadata+0x360>
    0.00 :   ffff800010355964:       ldr     w6, [x3, #8]
    0.00 :   ffff800010355968:       cbz     x7, ffff8000103559b8 <jbd2_journal_dirty_metadata+0x368>
    0.00 :   ffff80001035596c:       ldr     w0, [x7, #8]
    0.00 :   ffff800010355970:       ldr     w1, [x21, #16]
    0.00 :   ffff800010355974:       mov     x5, x3
    0.00 :   ffff800010355978:       str     w0, [sp]
    0.00 :   ffff80001035597c:       mov     x3, x20
    0.00 :   ffff800010355980:       str     w1, [sp, #8]
    0.00 :   ffff800010355984:       adrp    x0, ffff800011439000 <kallsyms_token_index+0x2e7a0>
    0.00 :   ffff800010355988:       add     x1, x24, #0x390
    0.00 :   ffff80001035598c:       add     x0, x0, #0xe88
    0.00 :   ffff800010355990:       ldr     w4, [x20, #8]
    0.00 :   ffff800010355994:       ldr     x2, [x22, #24]
    0.00 :   ffff800010355998:       bl      ffff800010e19544 <printk>
         : 1579             WARN_ON(1);
    0.00 :   ffff80001035599c:       brk     #0x800
         : 1580             ret = -EINVAL;
    0.00 :   ffff8000103559a0:       mov     w23, #0xffffffea                // #-22
    0.00 :   ffff8000103559a4:       b       ffff8000103557d8 <jbd2_journal_dirty_metadata+0x188>
         : 1536             printk(KERN_ERR "JBD2: %s: "
    0.00 :   ffff8000103559a8:       mov     w6, #0x0                        // #0
    0.00 :   ffff8000103559ac:       b       ffff800010355928 <jbd2_journal_dirty_metadata+0x2d8>
         : 1564             printk(KERN_ERR "jbd2_journal_dirty_metadata: %s: "
    0.00 :   ffff8000103559b0:       mov     w6, #0x0                        // #0
    0.00 :   ffff8000103559b4:       cbnz    x7, ffff80001035596c <jbd2_journal_dirty_metadata+0x31c>
    0.00 :   ffff8000103559b8:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000103559bc:       b       ffff800010355970 <jbd2_journal_dirty_metadata+0x320>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100ff1a0 <dyntick_save_progress_counter>:
         : 6                dyntick_save_progress_counter():
         :
         : 1251             /*
         : 1252             * Complain if a CPU that is considered to be offline from RCU's
         : 1253             * perspective has not yet reported a quiescent state.  After all,
         : 1254             * the offline CPU should have reported a quiescent state during
         : 1255             * the CPU-offline process, or, failing that, by rcu_gp_init()
    0.00 :   ffff8000100ff1a0:       mov     x4, x0
    0.00 :   ffff8000100ff1a4:       paciasp
    0.00 :   ffff8000100ff1a8:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff8000100ff1ac:       mov     x29, sp
         : 1251             * if it ran concurrently with either the CPU going offline or the
    0.00 :   ffff8000100ff1b0:       bl      ffff8000100ff160 <rcu_dynticks_snap>
    0.00 :   ffff8000100ff1b4:       str     w0, [x4, #264]
         : 1252             * last task on a leaf rcu_node structure exiting its RCU read-side
    0.00 :   ffff8000100ff1b8:       tbz     w0, #1, ffff8000100ff1cc <dyntick_save_progress_counter+0x2c>
         : 1257             * critical section while all CPUs corresponding to that structure
         : 1258             * are offline.  This added warning detects bugs in any of these
         : 1259             * code paths.
         : 1260             *
         : 1261             * The rcu_node structure's ->lock is held here, which excludes
    0.00 :   ffff8000100ff1bc:       mov     w0, #0x0                        // #0
         : 1258             * the relevant portions the CPU-hotplug code, the grace-period
    0.00 :   ffff8000100ff1c0:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000100ff1c4:       autiasp
    0.00 :   ffff8000100ff1c8:       ret
         : 1254             * are offline.  This added warning detects bugs in any of these
    0.00 :   ffff8000100ff1cc:       ldr     x2, [x4, #24]
         : 1256             rcu_gpnum_ovf():
         : 1237             * read-side critical section that started before the beginning
    0.00 :   ffff8000100ff1d0:       mov     x3, #0x3fffffffffffffff         // #4611686018427387903
         : 1239             rcu_seq_current():
         : 99               }
         :
         : 101              /* Return the current value the update side's sequence number, no ordering. */
         : 102              static inline unsigned long rcu_seq_current(unsigned long *sp)
         : 103              {
         : 104              return READ_ONCE(*sp);
    0.00 :   ffff8000100ff1d4:       ldr     x0, [x4]
         : 106              rcu_gpnum_ovf():
    0.00 :   ffff8000100ff1d8:       ldr     x1, [x2, #8]
    0.00 :   ffff8000100ff1dc:       add     x0, x0, x3
    0.00 :   ffff8000100ff1e0:       cmp     x0, x1
    0.00 :   ffff8000100ff1e4:       b.pl    ffff8000100ff1f4 <dyntick_save_progress_counter+0x54>  // b.nfrst
         : 1239             */
    0.00 :   ffff8000100ff1e8:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100ff1ec:       strb    w0, [x4, #20]
    0.00 :   ffff8000100ff1f0:       ldr     x1, [x2, #8]
         : 1240             if (rcu_dynticks_in_eqs_since(rdp, rdp->dynticks_snap)) {
    0.00 :   ffff8000100ff1f4:       mov     x3, #0x3fffffffffffffff         // #4611686018427387903
    0.00 :   ffff8000100ff1f8:       ldr     x2, [x4, #376]
    0.00 :   ffff8000100ff1fc:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100ff200:       add     x2, x2, x3
    0.00 :   ffff8000100ff204:       cmp     x2, x1
  100.00 :   ffff8000100ff208:       b.pl    ffff8000100ff1c0 <dyntick_save_progress_counter+0x20>  // b.nfrst
         : 1241             trace_rcu_fqs(rcu_state.name, rdp->gp_seq, rdp->cpu, TPS("dti"));
    0.00 :   ffff8000100ff20c:       add     x1, x1, x3
    0.00 :   ffff8000100ff210:       str     x1, [x4, #376]
         : 1244             dyntick_save_progress_counter():
         : 1258             * the relevant portions the CPU-hotplug code, the grace-period
    0.00 :   ffff8000100ff214:       ldp     x29, x30, [sp], #16
    0.00 :   ffff8000100ff218:       autiasp
    0.00 :   ffff8000100ff21c:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104b7878 <timerqueue_add>:
         : 6                timerqueue_add():
         : 36               * Adds the timer node to the timerqueue, sorted by the node's expires
         : 37               * value. Returns true if the newly added timer is the first expiring timer in
         : 38               * the queue.
         : 39               */
         : 40               bool timerqueue_add(struct timerqueue_head *head, struct timerqueue_node *node)
         : 41               {
   50.51 :   ffff8000104b7878:       paciasp
    0.00 :   ffff8000104b787c:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000104b7880:       mov     x29, sp
    0.00 :   ffff8000104b7884:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000104b7888:       mov     x19, x1
         : 38               /* Make sure we don't add nodes that are already added */
         : 39               WARN_ON_ONCE(!RB_EMPTY_NODE(&node->node));
    0.00 :   ffff8000104b788c:       ldr     x1, [x1]
    0.00 :   ffff8000104b7890:       cmp     x19, x1
    0.00 :   ffff8000104b7894:       b.ne    ffff8000104b793c <timerqueue_add+0xc4>  // b.any
         : 43               rb_add_cached():
         : 195              */
         : 196              static __always_inline struct rb_node *
         : 197              rb_add_cached(struct rb_node *node, struct rb_root_cached *tree,
         : 198              bool (*less)(struct rb_node *, const struct rb_node *))
         : 199              {
         : 200              struct rb_node **link = &tree->rb_root.rb_node;
    0.00 :   ffff8000104b7898:       mov     x3, x0
         : 197              struct rb_node *parent = NULL;
         : 198              bool leftmost = true;
    0.00 :   ffff8000104b789c:       mov     w20, #0x1                       // #1
         : 196              struct rb_node *parent = NULL;
    0.00 :   ffff8000104b78a0:       mov     x4, #0x0                        // #0
         :
         : 200              while (*link) {
    0.00 :   ffff8000104b78a4:       ldr     x2, [x3]
    0.00 :   ffff8000104b78a8:       cbz     x2, ffff8000104b78d4 <timerqueue_add+0x5c>
    0.00 :   ffff8000104b78ac:       nop
         : 201              parent = *link;
         : 202              if (less(node, parent)) {
    0.00 :   ffff8000104b78b0:       ldr     x4, [x2, #24]
         : 204              link = &parent->rb_left;
         : 205              } else {
         : 206              link = &parent->rb_right;
    0.00 :   ffff8000104b78b4:       add     x3, x2, #0x8
         : 201              if (less(node, parent)) {
    0.00 :   ffff8000104b78b8:       ldr     x5, [x19, #24]
    0.00 :   ffff8000104b78bc:       cmp     x5, x4
    0.00 :   ffff8000104b78c0:       b.ge    ffff8000104b7904 <timerqueue_add+0x8c>  // b.tcont
         : 202              link = &parent->rb_left;
    0.00 :   ffff8000104b78c4:       add     x3, x2, #0x10
         : 205              leftmost = false;
    0.00 :   ffff8000104b78c8:       mov     x4, x2
         : 199              while (*link) {
    0.00 :   ffff8000104b78cc:       ldr     x2, [x3]
    0.00 :   ffff8000104b78d0:       cbnz    x2, ffff8000104b78b0 <timerqueue_add+0x38>
         : 202              rb_link_node():
         : 73               node->rb_left = node->rb_right = NULL;
   49.49 :   ffff8000104b78d4:       stp     x4, xzr, [x19]
    0.00 :   ffff8000104b78d8:       str     xzr, [x19, #16]
         : 75               *rb_link = node;
    0.00 :   ffff8000104b78dc:       str     x19, [x3]
         : 77               rb_insert_color_cached():
         : 139              if (leftmost)
    0.00 :   ffff8000104b78e0:       cbnz    w20, ffff8000104b7910 <timerqueue_add+0x98>
         : 141              rb_insert_color(node, &root->rb_root);
    0.00 :   ffff8000104b78e4:       mov     x1, x0
    0.00 :   ffff8000104b78e8:       mov     x0, x19
    0.00 :   ffff8000104b78ec:       bl      ffff8000104b3240 <rb_insert_color>
         : 145              timerqueue_add():
         :
         : 42               return rb_add_cached(&node->node, &head->rb_root, __timerqueue_less);
         : 43               }
    0.00 :   ffff8000104b78f0:       mov     w0, w20
    0.00 :   ffff8000104b78f4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104b78f8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000104b78fc:       autiasp
    0.00 :   ffff8000104b7900:       ret
         : 49               rb_add_cached():
         : 205              leftmost = false;
    0.00 :   ffff8000104b7904:       mov     w20, #0x0                       // #0
    0.00 :   ffff8000104b7908:       mov     x4, x2
    0.00 :   ffff8000104b790c:       b       ffff8000104b78cc <timerqueue_add+0x54>
         : 209              rb_insert_color_cached():
         : 140              root->rb_leftmost = node;
    0.00 :   ffff8000104b7910:       str     x19, [x0, #8]
         : 141              rb_insert_color(node, &root->rb_root);
    0.00 :   ffff8000104b7914:       mov     x1, x0
    0.00 :   ffff8000104b7918:       mov     x0, x19
    0.00 :   ffff8000104b791c:       bl      ffff8000104b3240 <rb_insert_color>
         : 145              rb_add_cached():
         : 212              }
         :
         : 214              rb_link_node(node, parent, link);
         : 215              rb_insert_color_cached(node, tree, leftmost);
         :
         : 217              return leftmost ? node : NULL;
    0.00 :   ffff8000104b7920:       cmp     x19, #0x0
    0.00 :   ffff8000104b7924:       cset    w20, ne  // ne = any
         : 220              timerqueue_add():
    0.00 :   ffff8000104b7928:       mov     w0, w20
    0.00 :   ffff8000104b792c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104b7930:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000104b7934:       autiasp
    0.00 :   ffff8000104b7938:       ret
         : 38               WARN_ON_ONCE(!RB_EMPTY_NODE(&node->node));
    0.00 :   ffff8000104b793c:       brk     #0x800
    0.00 :   ffff8000104b7940:       b       ffff8000104b7898 <timerqueue_add+0x20>
 Percent |	Source code & Disassembly of vmlinux for cycles (13 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010025c38 <el0_svc_common.constprop.2>:
         : 6                el0_svc_common():
         : 84               }
         :
         : 86               int syscall_trace_enter(struct pt_regs *regs);
         : 87               void syscall_trace_exit(struct pt_regs *regs);
         :
         : 89               static void el0_svc_common(struct pt_regs *regs, int scno, int sc_nr,
    0.00 :   ffff800010025c38:       paciasp
    0.00 :   ffff800010025c3c:       stp     x29, x30, [sp, #-32]!
         : 92               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010025c40:       mrs     x3, sp_el0
         : 26               el0_svc_common():
    0.00 :   ffff800010025c44:       mov     x29, sp
         : 89               const syscall_fn_t syscall_table[])
         : 90               {
         : 91               unsigned long flags = current_thread_info()->flags;
         :
         : 93               regs->orig_x0 = regs->regs[0];
    0.00 :   ffff800010025c48:       ldr     x4, [x0]
         : 87               unsigned long flags = current_thread_info()->flags;
    0.00 :   ffff800010025c4c:       ldr     x3, [x3]
         : 89               regs->orig_x0 = regs->regs[0];
    0.00 :   ffff800010025c50:       str     x4, [x0, #272]
         : 90               regs->syscallno = scno;
    0.00 :   ffff800010025c54:       str     w1, [x0, #280]
         : 92               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010025c58:       b       ffff800010025cc8 <el0_svc_common.constprop.2+0x90>
         : 45               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010025c5c:       nop
         : 23               local_daif_restore():
         : 117              * So we don't need additional synchronization here.
         : 118              */
         : 119              gic_write_pmr(pmr);
         : 120              }
         :
         : 122              write_sysreg(flags, daif);
    0.00 :   ffff800010025c60:       msr     daif, xzr
         : 124              el0_svc_common():
         : 112              * (Similarly for HVC and SMC elsewhere.)
         : 113              */
         :
         : 115              local_daif_restore(DAIF_PROCCTX);
         :
         : 117              if (flags & _TIF_MTE_ASYNC_FAULT) {
   97.15 :   ffff800010025c64:       tbnz    w3, #5, ffff800010025ce8 <el0_svc_common.constprop.2+0xb0>
         : 119              has_syscall_work():
         : 78               return unlikely(flags & _TIF_SYSCALL_WORK);
    0.00 :   ffff800010025c68:       stp     x19, x20, [sp, #16]
         : 80               el0_svc_common():
         : 122              */
         : 123              regs->regs[0] = -ERESTARTNOINTR;
         : 124              return;
         : 125              }
         :
         : 127              if (has_syscall_work(flags)) {
    0.00 :   ffff800010025c6c:       tst     x3, #0x1f00
    0.00 :   ffff800010025c70:       mov     x20, x2
    0.00 :   ffff800010025c74:       mov     x19, x0
    2.85 :   ffff800010025c78:       b.eq    ffff800010025d04 <el0_svc_common.constprop.2+0xcc>  // b.none
         : 138              * then x0 will be preserved for all system calls apart from a
         : 139              * user-issued syscall(-1). However, requesting a skip and not
         : 140              * setting the return value is unlikely to do anything sensible
         : 141              * anyway.
         : 142              */
         : 143              if (scno == NO_SYSCALL)
    0.00 :   ffff800010025c7c:       cmn     w1, #0x1
    0.00 :   ffff800010025c80:       b.ne    ffff800010025c8c <el0_svc_common.constprop.2+0x54>  // b.any
         : 139              regs->regs[0] = -ENOSYS;
    0.00 :   ffff800010025c84:       mov     x0, #0xffffffffffffffda         // #-38
    0.00 :   ffff800010025c88:       str     x0, [x19]
         : 140              scno = syscall_trace_enter(regs);
    0.00 :   ffff800010025c8c:       mov     x0, x19
    0.00 :   ffff800010025c90:       bl      ffff8000100195b0 <syscall_trace_enter>
         : 141              if (scno == NO_SYSCALL)
    0.00 :   ffff800010025c94:       cmn     w0, #0x1
    0.00 :   ffff800010025c98:       b.eq    ffff800010025cb0 <el0_svc_common.constprop.2+0x78>  // b.none
         : 145              goto trace_exit;
         : 146              }
         :
         : 148              invoke_syscall(regs, scno, sc_nr, syscall_table);
    0.00 :   ffff800010025c9c:       mov     w1, w0
    0.00 :   ffff800010025ca0:       mov     x3, x20
    0.00 :   ffff800010025ca4:       mov     w2, #0x1bf                      // #447
    0.00 :   ffff800010025ca8:       mov     x0, x19
    0.00 :   ffff800010025cac:       bl      ffff800010025b30 <invoke_syscall>
         : 161              return;
         : 162              local_daif_restore(DAIF_PROCCTX);
         : 163              }
         :
         : 165              trace_exit:
         : 166              syscall_trace_exit(regs);
    0.00 :   ffff800010025cb0:       mov     x0, x19
    0.00 :   ffff800010025cb4:       bl      ffff8000100196e8 <syscall_trace_exit>
    0.00 :   ffff800010025cb8:       ldp     x19, x20, [sp, #16]
         : 162              }
    0.00 :   ffff800010025cbc:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010025cc0:       autiasp
    0.00 :   ffff800010025cc4:       ret
         : 166              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010025cc8:       adrp    x4, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010025ccc:       ldr     x4, [x4, #1296]
         : 114              local_daif_restore():
         : 77               if (system_uses_irq_prio_masking()) {
    0.00 :   ffff800010025cd0:       tst     w4, #0x80000
    0.00 :   ffff800010025cd4:       b.eq    ffff800010025c60 <el0_svc_common.constprop.2+0x28>  // b.none
         : 80               gic_write_pmr():
         : 114              return read_sysreg_s(SYS_ICC_PMR_EL1);
         : 115              }
         :
         : 117              static __always_inline void gic_write_pmr(u32 val)
         : 118              {
         : 119              write_sysreg_s(val, SYS_ICC_PMR_EL1);
    0.00 :   ffff800010025cd8:       mov     x4, #0xe0                       // #224
    0.00 :   ffff800010025cdc:       msr     s3_0_c4_c6_0, x4
         : 122              arch_static_branch():
    0.00 :   ffff800010025ce0:       nop
    0.00 :   ffff800010025ce4:       b       ffff800010025c60 <el0_svc_common.constprop.2+0x28>
         : 23               el0_svc_common():
         : 118              regs->regs[0] = -ERESTARTNOINTR;
    0.00 :   ffff800010025ce8:       mov     x1, #0xfffffffffffffdff         // #-513
    0.00 :   ffff800010025cec:       str     x1, [x0]
         : 162              }
    0.00 :   ffff800010025cf0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010025cf4:       autiasp
    0.00 :   ffff800010025cf8:       ret
         : 166              local_daif_restore():
         : 79               pmr_sync();
    0.00 :   ffff800010025cfc:       dsb     sy
    0.00 :   ffff800010025d00:       b       ffff800010025c60 <el0_svc_common.constprop.2+0x28>
         : 82               el0_svc_common():
         : 145              invoke_syscall(regs, scno, sc_nr, syscall_table);
    0.00 :   ffff800010025d04:       mov     x3, x2
    0.00 :   ffff800010025d08:       mov     w2, #0x1bf                      // #447
    0.00 :   ffff800010025d0c:       bl      ffff800010025b30 <invoke_syscall>
         : 149              local_daif_mask():
         : 28               asm volatile(
    0.00 :   ffff800010025d10:       msr     daifset, #0xf
         : 30               arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff800010025d14:       b       ffff800010025d20 <el0_svc_common.constprop.2+0xe8>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010025d18:       nop
         : 30               return false;
    0.00 :   ffff800010025d1c:       b       ffff800010025d38 <el0_svc_common.constprop.2+0x100>
         : 32               test_bit():
    0.00 :   ffff800010025d20:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010025d24:       ldr     x0, [x0, #1296]
         : 108              local_daif_mask():
         : 35               if (system_uses_irq_prio_masking())
    0.00 :   ffff800010025d28:       tst     w0, #0x80000
    0.00 :   ffff800010025d2c:       b.eq    ffff800010025d38 <el0_svc_common.constprop.2+0x100>  // b.none
         : 38               gic_write_pmr():
    0.00 :   ffff800010025d30:       mov     x0, #0xf0                       // #240
    0.00 :   ffff800010025d34:       msr     s3_0_c4_c6_0, x0
         : 116              get_current():
    0.00 :   ffff800010025d38:       mrs     x0, sp_el0
         : 20               el0_svc_common():
         : 155              if (!has_syscall_work(flags) && !(flags & _TIF_SINGLESTEP))
    0.00 :   ffff800010025d3c:       ldr     x0, [x0]
    0.00 :   ffff800010025d40:       and     x0, x0, #0x3fff00
    0.00 :   ffff800010025d44:       and     x0, x0, #0xffffffffffe01fff
    0.00 :   ffff800010025d48:       cbz     x0, ffff800010025d88 <el0_svc_common.constprop.2+0x150>
         : 160              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff800010025d4c:       b       ffff800010025d5c <el0_svc_common.constprop.2+0x124>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010025d50:       nop
         : 23               local_daif_restore():
         : 117              write_sysreg(flags, daif);
    0.00 :   ffff800010025d54:       msr     daif, xzr
         :
         : 121              if (irq_disabled)
         : 122              trace_hardirqs_off();
    0.00 :   ffff800010025d58:       b       ffff800010025cb0 <el0_svc_common.constprop.2+0x78>
         : 124              test_bit():
    0.00 :   ffff800010025d5c:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010025d60:       ldr     x0, [x0, #1296]
         : 108              local_daif_restore():
         : 77               if (system_uses_irq_prio_masking()) {
    0.00 :   ffff800010025d64:       tst     w0, #0x80000
    0.00 :   ffff800010025d68:       b.eq    ffff800010025d54 <el0_svc_common.constprop.2+0x11c>  // b.none
         : 80               gic_write_pmr():
    0.00 :   ffff800010025d6c:       mov     x0, #0xe0                       // #224
    0.00 :   ffff800010025d70:       msr     s3_0_c4_c6_0, x0
         : 116              arch_static_branch():
    0.00 :   ffff800010025d74:       nop
         : 22               local_daif_restore():
         : 79               pmr_sync();
    0.00 :   ffff800010025d78:       b       ffff800010025d54 <el0_svc_common.constprop.2+0x11c>
    0.00 :   ffff800010025d7c:       dsb     sy
         : 117              write_sysreg(flags, daif);
    0.00 :   ffff800010025d80:       msr     daif, xzr
         : 120              trace_hardirqs_off();
    0.00 :   ffff800010025d84:       b       ffff800010025cb0 <el0_svc_common.constprop.2+0x78>
    0.00 :   ffff800010025d88:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010025d8c:       b       ffff800010025cbc <el0_svc_common.constprop.2+0x84>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010244e98 <path_lookupat.isra.56>:
         : 6                path_lookupat():
         : 2409             }
         : 2410             }
         : 2411             return s;
         : 2412             }
         :
         : 2414             static inline const char *lookup_last(struct nameidata *nd)
    0.00 :   ffff800010244e98:       paciasp
    0.00 :   ffff800010244e9c:       stp     x29, x30, [sp, #-64]!
  100.00 :   ffff800010244ea0:       mov     x29, sp
    0.00 :   ffff800010244ea4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010244ea8:       mov     x19, x0
    0.00 :   ffff800010244eac:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010244eb0:       mov     w21, w1
    0.00 :   ffff800010244eb4:       str     x23, [sp, #48]
    0.00 :   ffff800010244eb8:       mov     x23, x2
         : 2411             {
         : 2412             if (nd->last_type == LAST_NORM && nd->last.name[nd->last.len])
    0.00 :   ffff800010244ebc:       bl      ffff8000102401c8 <path_init>
    0.00 :   ffff800010244ec0:       mov     x20, x0
         : 2414             nd->flags |= LOOKUP_FOLLOW | LOOKUP_DIRECTORY;
         :
         : 2416             return walk_component(nd, WALK_TRAILING);
    0.00 :   ffff800010244ec4:       tbnz    w21, #15, ffff800010244fa4 <path_lookupat.isra.56+0x10c>
         : 2418             link_path_walk():
         : 2192             }
    0.00 :   ffff800010244ec8:       mov     w22, #0x1                       // #1
    0.00 :   ffff800010244ecc:       b       ffff800010244f14 <path_lookupat.isra.56+0x7c>
    0.00 :   ffff800010244ed0:       bl      ffff800010244a60 <link_path_walk.part.54>
         : 2394             }
    0.00 :   ffff800010244ed4:       mov     w21, w0
         : 2396             path_lookupat():
         : 2420             }
         :
         : 2422             static int handle_lookup_down(struct nameidata *nd)
         : 2423             {
         : 2424             if (!(nd->flags & LOOKUP_RCU))
         : 2425             dget(nd->path.dentry);
    0.00 :   ffff800010244ed8:       cbnz    w0, ffff800010244f3c <path_lookupat.isra.56+0xa4>
         : 2427             lookup_last():
         : 2394             }
    0.00 :   ffff800010244edc:       ldr     w0, [x19, #72]
    0.00 :   ffff800010244ee0:       cbnz    w0, ffff800010244f00 <path_lookupat.isra.56+0x68>
    0.00 :   ffff800010244ee4:       ldr     w0, [x19, #20]
    0.00 :   ffff800010244ee8:       ldr     x1, [x19, #24]
    0.00 :   ffff800010244eec:       ldrb    w0, [x1, x0]
    0.00 :   ffff800010244ef0:       cbz     w0, ffff800010244f00 <path_lookupat.isra.56+0x68>
         :
    0.00 :   ffff800010244ef4:       ldr     w0, [x19, #56]
    0.00 :   ffff800010244ef8:       orr     w0, w0, #0x3
    0.00 :   ffff800010244efc:       str     w0, [x19, #56]
         : 2397             if (flags & LOOKUP_IS_SCOPED) {
    0.00 :   ffff800010244f00:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010244f04:       mov     x0, x19
    0.00 :   ffff800010244f08:       bl      ffff800010244888 <walk_component>
    0.00 :   ffff800010244f0c:       mov     x20, x0
         : 2402             path_lookupat():
         : 2420             dget(nd->path.dentry);
    0.00 :   ffff800010244f10:       cbz     x0, ffff800010244f60 <path_lookupat.isra.56+0xc8>
         : 2422             link_path_walk():
         :
    0.00 :   ffff800010244f14:       ldr     w0, [x19, #56]
         : 2194             #endif
    0.00 :   ffff800010244f18:       cmn     x20, #0x1, lsl #12
         : 2192             }
    0.00 :   ffff800010244f1c:       str     w22, [x19, #72]
         : 36               return (long) ptr;
         : 37               }
         :
         : 39               static inline bool __must_check IS_ERR(__force const void *ptr)
         : 40               {
         : 41               return IS_ERR_VALUE((unsigned long)ptr);
    0.00 :   ffff800010244f20:       mov     x1, x19
         :
    0.00 :   ffff800010244f24:       orr     w0, w0, #0x10
    0.00 :   ffff800010244f28:       str     w0, [x19, #56]
    0.00 :   ffff800010244f2c:       mov     x0, x20
         : 2194             #endif
    0.00 :   ffff800010244f30:       b.ls    ffff800010244ed0 <path_lookupat.isra.56+0x38>  // b.plast
         :
    0.00 :   ffff800010244f34:       mov     w21, w20
         : 2197             path_lookupat():
         : 2420             dget(nd->path.dentry);
    0.00 :   ffff800010244f38:       cbz     w20, ffff800010244f00 <path_lookupat.isra.56+0x68>
         : 2438             if (unlikely(err < 0))
         : 2439             s = ERR_PTR(err);
         : 2440             }
         :
         : 2442             while (!(err = link_path_walk(s, nd)) &&
         : 2443             (s = lookup_last(nd)) != NULL)
    0.00 :   ffff800010244f3c:       mov     x0, x19
    0.00 :   ffff800010244f40:       bl      ffff800010240510 <terminate_walk>
         : 2440             ;
         : 2441             if (!err && unlikely(nd->flags & LOOKUP_MOUNTPOINT)) {
    0.00 :   ffff800010244f44:       mov     w0, w21
    0.00 :   ffff800010244f48:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010244f4c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010244f50:       ldr     x23, [sp, #48]
    0.00 :   ffff800010244f54:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010244f58:       autiasp
    0.00 :   ffff800010244f5c:       ret
         : 2423             }
    0.00 :   ffff800010244f60:       ldr     w0, [x19, #56]
    0.00 :   ffff800010244f64:       tbnz    w0, #7, ffff800010244fc4 <path_lookupat.isra.56+0x12c>
         : 2428             const char *s = path_init(nd, flags);
    0.00 :   ffff800010244f68:       mov     x0, x19
    0.00 :   ffff800010244f6c:       bl      ffff800010240c00 <complete_walk>
    0.00 :   ffff800010244f70:       mov     w21, w0
         :
    0.00 :   ffff800010244f74:       cbnz    w0, ffff800010244f3c <path_lookupat.isra.56+0xa4>
    0.00 :   ffff800010244f78:       ldr     w0, [x19, #56]
    0.00 :   ffff800010244f7c:       tbz     w0, #1, ffff800010244f94 <path_lookupat.isra.56+0xfc>
         : 2434             d_can_lookup():
         : 410              return __d_entry_type(dentry) == DCACHE_WHITEOUT_TYPE;
         : 411              }
         :
         : 413              static inline bool d_can_lookup(const struct dentry *dentry)
         : 414              {
         : 415              return __d_entry_type(dentry) == DCACHE_DIRECTORY_TYPE;
    0.00 :   ffff800010244f80:       ldr     x0, [x19, #8]
         : 417              __d_entry_type():
         : 395              return dentry->d_flags & DCACHE_ENTRY_TYPE;
    0.00 :   ffff800010244f84:       ldr     w0, [x0]
    0.00 :   ffff800010244f88:       and     w0, w0, #0x700000
         : 398              path_lookupat():
         : 2431             if (unlikely(flags & LOOKUP_DOWN) && !IS_ERR(s)) {
    0.00 :   ffff800010244f8c:       cmp     w0, #0x200, lsl #12
    0.00 :   ffff800010244f90:       b.ne    ffff800010244fe4 <path_lookupat.isra.56+0x14c>  // b.any
         : 2434             s = ERR_PTR(err);
    0.00 :   ffff800010244f94:       ldp     x0, x1, [x19]
    0.00 :   ffff800010244f98:       stp     x0, x1, [x23]
         :
    0.00 :   ffff800010244f9c:       stp     xzr, xzr, [x19]
    0.00 :   ffff800010244fa0:       b       ffff800010244f3c <path_lookupat.isra.56+0xa4>
         : 2414             return walk_component(nd, WALK_TRAILING);
    0.00 :   ffff800010244fa4:       cmn     x0, #0x1, lsl #12
    0.00 :   ffff800010244fa8:       b.hi    ffff800010244ec8 <path_lookupat.isra.56+0x30>  // b.pmore
         : 2415             }
    0.00 :   ffff800010244fac:       mov     x0, x19
    0.00 :   ffff800010244fb0:       bl      ffff8000102422d8 <handle_lookup_down>
         : 2417             static int handle_lookup_down(struct nameidata *nd)
    0.00 :   ffff800010244fb4:       cmp     w0, #0x0
    0.00 :   ffff800010244fb8:       sxtw    x0, w0
    0.00 :   ffff800010244fbc:       csel    x20, x0, x20, lt  // lt = tstop
    0.00 :   ffff800010244fc0:       b       ffff800010244ec8 <path_lookupat.isra.56+0x30>
         :
    0.00 :   ffff800010244fc4:       mov     x0, x19
    0.00 :   ffff800010244fc8:       bl      ffff8000102422d8 <handle_lookup_down>
    0.00 :   ffff800010244fcc:       mov     w21, w0
         : 2425             /* Returns 0 and nd will be valid on success; Retuns error, otherwise. */
    0.00 :   ffff800010244fd0:       ldr     w0, [x19, #56]
    0.00 :   ffff800010244fd4:       and     w0, w0, #0xffffefff
    0.00 :   ffff800010244fd8:       str     w0, [x19, #56]
         : 2427             {
    0.00 :   ffff800010244fdc:       cbz     w21, ffff800010244f68 <path_lookupat.isra.56+0xd0>
    0.00 :   ffff800010244fe0:       b       ffff800010244f3c <path_lookupat.isra.56+0xa4>
         : 2432             err = handle_lookup_down(nd);
    0.00 :   ffff800010244fe4:       mov     w21, #0xffffffec                // #-20
    0.00 :   ffff800010244fe8:       b       ffff800010244f3c <path_lookupat.isra.56+0xa4>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001001c130 <do_notify_resume>:
         : 6                do_notify_resume():
         : 916              restore_saved_sigmask();
         : 917              }
         :
         : 919              asmlinkage void do_notify_resume(struct pt_regs *regs,
         : 920              unsigned long thread_flags)
         : 921              {
    0.00 :   ffff80001001c130:       paciasp
    0.00 :   ffff80001001c134:       stp     x29, x30, [sp, #-192]!
    0.00 :   ffff80001001c138:       mov     x29, sp
    0.00 :   ffff80001001c13c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001001c140:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001001c144:       add     x22, x22, #0x948
    0.00 :   ffff80001001c148:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001001c14c:       mov     x20, x0
    0.00 :   ffff80001001c150:       mov     x19, x1
    0.00 :   ffff80001001c154:       ldr     x0, [x22]
    0.00 :   ffff80001001c158:       str     x0, [sp, #184]
    0.00 :   ffff80001001c15c:       mov     x0, #0x0                        // #0
         : 935              clear_thread_flag(TIF_MTE_ASYNC_FAULT);
         : 936              send_sig_fault(SIGSEGV, SEGV_MTEAERR,
         : 937              (void __user *)NULL, current);
         : 938              }
         :
         : 940              if (thread_flags & (_TIF_SIGPENDING | _TIF_NOTIFY_SIGNAL))
    0.00 :   ffff80001001c160:       mov     x21, #0x41                      // #65
         : 916              {
    0.00 :   ffff80001001c164:       stp     x23, x24, [sp, #48]
         : 918              __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff80001001c168:       mov     x23, #0x4                       // #4
         : 236              __ll_sc_atomic64_fetch_andnot():
    0.00 :   ffff80001001c16c:       mov     x24, #0x100000                  // #1048576
         : 230              do_notify_resume():
    0.00 :   ffff80001001c170:       stp     x25, x26, [sp, #64]
         : 917              do_signal():
         : 855              restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
    0.00 :   ffff80001001c174:       mov     x25, #0x2                       // #2
         : 857              do_notify_resume():
         : 916              {
    0.00 :   ffff80001001c178:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001001c17c:       nop
         : 918              if (thread_flags & _TIF_NEED_RESCHED) {
    0.00 :   ffff80001001c180:       tbz     w19, #1, ffff80001001c1fc <do_notify_resume+0xcc>
         : 920              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001001c184:       b       ffff80001001c354 <do_notify_resume+0x224>
         : 45               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001001c188:       nop
    0.00 :   ffff80001001c18c:       mov     x0, #0xc0                       // #192
         : 24               local_daif_restore():
         : 117              * So we don't need additional synchronization here.
         : 118              */
         : 119              gic_write_pmr(pmr);
         : 120              }
         :
         : 122              write_sysreg(flags, daif);
    0.00 :   ffff80001001c190:       msr     daif, x0
         : 124              do_notify_resume():
         : 922              schedule();
    0.00 :   ffff80001001c194:       bl      ffff800010e2e4a0 <schedule>
         : 924              local_daif_mask():
         : 28               asm volatile(
    0.00 :   ffff80001001c198:       msr     daifset, #0xf
         : 30               arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001001c19c:       b       ffff80001001c1e4 <do_notify_resume+0xb4>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001001c1a0:       nop
         : 23               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001001c1a4:       mrs     x0, sp_el0
         : 26               do_notify_resume():
         : 948              if (thread_flags & _TIF_FOREIGN_FPSTATE)
         : 949              fpsimd_restore_current_state();
         : 950              }
         :
         : 952              local_daif_mask();
         : 953              thread_flags = READ_ONCE(current_thread_info()->flags);
    0.00 :   ffff80001001c1a8:       ldr     x19, [x0]
         : 949              } while (thread_flags & _TIF_WORK_MASK);
    0.00 :   ffff80001001c1ac:       tst     x19, #0x7f
    0.00 :   ffff80001001c1b0:       b.ne    ffff80001001c180 <do_notify_resume+0x50>  // b.any
         : 950              }
    0.00 :   ffff80001001c1b4:       ldr     x1, [sp, #184]
    0.00 :   ffff80001001c1b8:       ldr     x0, [x22]
    0.00 :   ffff80001001c1bc:       eor     x0, x1, x0
    0.00 :   ffff80001001c1c0:       cbnz    x0, ffff80001001c560 <do_notify_resume+0x430>
    0.00 :   ffff80001001c1c4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001001c1c8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001001c1cc:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001001c1d0:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001001c1d4:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001001c1d8:       ldp     x29, x30, [sp], #192
    0.00 :   ffff80001001c1dc:       autiasp
    0.00 :   ffff80001001c1e0:       ret
         : 963              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001001c1e4:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff80001001c1e8:       ldr     x0, [x0, #1296]
         : 114              local_daif_mask():
         : 35               if (system_uses_irq_prio_masking())
    0.00 :   ffff80001001c1ec:       tbz     w0, #19, ffff80001001c1a4 <do_notify_resume+0x74>
         : 37               gic_write_pmr():
         : 114              return read_sysreg_s(SYS_ICC_PMR_EL1);
         : 115              }
         :
         : 117              static __always_inline void gic_write_pmr(u32 val)
         : 118              {
         : 119              write_sysreg_s(val, SYS_ICC_PMR_EL1);
    0.00 :   ffff80001001c1f0:       mov     x0, #0xf0                       // #240
    0.00 :   ffff80001001c1f4:       msr     s3_0_c4_c6_0, x0
    0.00 :   ffff80001001c1f8:       b       ffff80001001c1a4 <do_notify_resume+0x74>
         : 123              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001001c1fc:       b       ffff80001001c300 <do_notify_resume+0x1d0>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001001c200:       nop
         : 23               local_daif_restore():
         : 117              write_sysreg(flags, daif);
    0.00 :   ffff80001001c204:       msr     daif, xzr
         : 119              do_notify_resume():
         : 929              if (thread_flags & _TIF_MTE_ASYNC_FAULT) {
    0.00 :   ffff80001001c208:       tbnz    w19, #5, ffff80001001c328 <do_notify_resume+0x1f8>
         : 935              if (thread_flags & (_TIF_SIGPENDING | _TIF_NOTIFY_SIGNAL))
    0.00 :   ffff80001001c20c:       tst     x19, x21
    0.00 :   ffff80001001c210:       b.ne    ffff80001001c270 <do_notify_resume+0x140>  // b.any
         : 938              if (thread_flags & _TIF_NOTIFY_RESUME) {
    0.00 :   ffff80001001c214:       tbnz    w19, #2, ffff80001001c224 <do_notify_resume+0xf4>
         : 943              if (thread_flags & _TIF_FOREIGN_FPSTATE)
    0.00 :   ffff80001001c218:       tbz     w19, #3, ffff80001001c198 <do_notify_resume+0x68>
         : 944              fpsimd_restore_current_state();
    0.00 :   ffff80001001c21c:       bl      ffff8000100157e0 <fpsimd_restore_current_state>
    0.00 :   ffff80001001c220:       b       ffff80001001c198 <do_notify_resume+0x68>
         : 947              get_current():
    0.00 :   ffff80001001c224:       mrs     x0, sp_el0
         : 20               arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001001c228:       b       ffff80001001c36c <do_notify_resume+0x23c>
    0.00 :   ffff80001001c22c:       b       ffff80001001c36c <do_notify_resume+0x23c>
         : 41               __lse_atomic64_andnot():
         : 176              "       " #asm_op "     %[i], %[v]\n"                                   \
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff80001001c230:       mov     x1, x23
    0.00 :   ffff80001001c234:       stclr   x1, [x0]
         : 184              tracehook_notify_resume():
         : 187              clear_thread_flag(TIF_NOTIFY_RESUME);
         : 188              /*
         : 189              * This barrier pairs with task_work_add()->set_notify_resume() after
         : 190              * hlist_add_head(task->task_works);
         : 191              */
         : 192              smp_mb__after_atomic();
    0.00 :   ffff80001001c238:       dmb     ish
         : 194              get_current():
    0.00 :   ffff80001001c23c:       mrs     x0, sp_el0
         : 20               tracehook_notify_resume():
         : 188              if (unlikely(current->task_works))
    0.00 :   ffff80001001c240:       ldr     x0, [x0, #1720]
    0.00 :   ffff80001001c244:       cbnz    x0, ffff80001001c380 <do_notify_resume+0x250>
         : 198              key_put(current->cached_requested_key);
         : 199              current->cached_requested_key = NULL;
         : 200              }
         : 201              #endif
         :
         : 203              mem_cgroup_handle_over_high();
    0.00 :   ffff80001001c248:       bl      ffff8000102243f0 <mem_cgroup_handle_over_high>
         : 199              blkcg_maybe_throttle_current();
    0.00 :   ffff80001001c24c:       bl      ffff8000104592f0 <blkcg_maybe_throttle_current>
         : 201              get_current():
    0.00 :   ffff80001001c250:       mrs     x0, sp_el0
         : 20               rseq_handle_notify_resume():
         :
         : 2071             #ifdef CONFIG_RSEQ
         :
         : 2073             /*
         : 2074             * Map the event mask on the user-space ABI enum rseq_cs_flags
         : 2075             * for direct mask checks.
    0.00 :   ffff80001001c254:       ldr     x0, [x0, #2304]
    0.00 :   ffff80001001c258:       cbz     x0, ffff80001001c218 <do_notify_resume+0xe8>
         : 2071             */
    0.00 :   ffff80001001c25c:       mov     x1, x20
    0.00 :   ffff80001001c260:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001001c264:       bl      ffff80001017b950 <__rseq_handle_notify_resume>
         : 2075             do_notify_resume():
         : 943              if (thread_flags & _TIF_FOREIGN_FPSTATE)
    0.00 :   ffff80001001c268:       tbz     w19, #3, ffff80001001c198 <do_notify_resume+0x68>
    0.00 :   ffff80001001c26c:       b       ffff80001001c21c <do_notify_resume+0xec>
         : 946              do_signal():
         : 853              if (syscall) {
    0.00 :   ffff80001001c270:       ldr     w0, [x20, #280]
    0.00 :   ffff80001001c274:       cmn     w0, #0x1
    0.00 :   ffff80001001c278:       b.eq    ffff80001001c394 <do_notify_resume+0x264>  // b.none
         : 855              restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
    0.00 :   ffff80001001c27c:       ldp     x28, x0, [x20, #256]
         : 857              forget_syscall():
         : 213              return regs->syscallno != NO_SYSCALL;
         : 214              }
         :
         : 216              static inline void forget_syscall(struct pt_regs *regs)
         : 217              {
         : 218              regs->syscallno = NO_SYSCALL;
    0.00 :   ffff80001001c280:       mov     w1, #0xffffffff                 // #-1
         : 220              do_signal():
         : 856              retval = regs->regs[0];
    0.00 :   ffff80001001c284:       ldr     x27, [x20]
         : 858              forget_syscall():
    0.00 :   ffff80001001c288:       str     w1, [x20, #280]
         : 214              do_signal():
         : 855              restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
    0.00 :   ffff80001001c28c:       tst     x0, #0x20
    0.00 :   ffff80001001c290:       csel    x26, x25, x23, ne  // ne = any
         : 867              switch (retval) {
    0.00 :   ffff80001001c294:       cmn     w27, #0x204
         : 855              restart_addr = continue_addr - (compat_thumb_mode(regs) ? 2 : 4);
    0.00 :   ffff80001001c298:       sub     x26, x28, x26
         : 867              switch (retval) {
    0.00 :   ffff80001001c29c:       b.eq    ffff80001001c468 <do_notify_resume+0x338>  // b.none
    0.00 :   ffff80001001c2a0:       b.lt    ffff80001001c2b0 <do_notify_resume+0x180>  // b.tstop
    0.00 :   ffff80001001c2a4:       add     w0, w27, #0x202
    0.00 :   ffff80001001c2a8:       cmp     w0, #0x2
    0.00 :   ffff80001001c2ac:       b.ls    ffff80001001c468 <do_notify_resume+0x338>  // b.plast
         : 882              if (get_signal(&ksig)) {
    0.00 :   ffff80001001c2b0:       add     x0, sp, #0x60
    0.00 :   ffff80001001c2b4:       bl      ffff800010095550 <get_signal>
    0.00 :   ffff80001001c2b8:       tst     w0, #0xff
    0.00 :   ffff80001001c2bc:       b.ne    ffff80001001c484 <do_notify_resume+0x354>  // b.any
         : 905              if (syscall && regs->pc == restart_addr) {
    0.00 :   ffff80001001c2c0:       ldr     x0, [x20, #256]
    0.00 :   ffff80001001c2c4:       cmp     x26, x0
    0.00 :   ffff80001001c2c8:       b.eq    ffff80001001c4cc <do_notify_resume+0x39c>  // b.none
         : 909              get_current():
    0.00 :   ffff80001001c2cc:       mrs     x0, sp_el0
         : 20               test_and_clear_bit():
         : 51               {
         : 52               long old;
         : 53               unsigned long mask = BIT_MASK(nr);
         :
         : 55               p += BIT_WORD(nr);
         : 56               if (!(READ_ONCE(*p) & mask))
    0.00 :   ffff80001001c2d0:       ldr     x1, [x0]
    0.00 :   ffff80001001c2d4:       tbz     w1, #20, ffff80001001c214 <do_notify_resume+0xe4>
         : 59               arch_static_branch_jump():
    0.00 :   ffff80001001c2d8:       b       ffff80001001c4ec <do_notify_resume+0x3bc>
    0.00 :   ffff80001001c2dc:       b       ffff80001001c4ec <do_notify_resume+0x3bc>
         : 40               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OP(_relaxed,   , op, asm_op)                     \
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff80001001c2e0:       mov     x1, x24
    0.00 :   ffff80001001c2e4:       ldclral x1, x1, [x0]
         : 210              restore_saved_sigmask():
         : 510              }
         : 511              #endif
         :
         : 513              static inline void restore_saved_sigmask(void)
         : 514              {
         : 515              if (test_and_clear_restore_sigmask())
    0.00 :   ffff80001001c2e8:       tbz     w1, #20, ffff80001001c214 <do_notify_resume+0xe4>
         : 517              get_current():
    0.00 :   ffff80001001c2ec:       mrs     x0, sp_el0
         : 20               restore_saved_sigmask():
         : 511              __set_current_blocked(&current->saved_sigmask);
    0.00 :   ffff80001001c2f0:       add     x0, x0, #0x680
    0.00 :   ffff80001001c2f4:       bl      ffff800010093278 <__set_current_blocked>
         : 514              do_notify_resume():
         : 938              if (thread_flags & _TIF_NOTIFY_RESUME) {
    0.00 :   ffff80001001c2f8:       tbz     w19, #2, ffff80001001c218 <do_notify_resume+0xe8>
    0.00 :   ffff80001001c2fc:       b       ffff80001001c224 <do_notify_resume+0xf4>
         : 941              test_bit():
    0.00 :   ffff80001001c300:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff80001001c304:       ldr     x0, [x0, #1296]
         : 108              local_daif_restore():
         : 77               if (system_uses_irq_prio_masking()) {
    0.00 :   ffff80001001c308:       tbz     w0, #19, ffff80001001c204 <do_notify_resume+0xd4>
         : 79               gic_write_pmr():
    0.00 :   ffff80001001c30c:       mov     x0, #0xe0                       // #224
    0.00 :   ffff80001001c310:       msr     s3_0_c4_c6_0, x0
         : 116              arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001001c314:       nop
    0.00 :   ffff80001001c318:       b       ffff80001001c204 <do_notify_resume+0xd4>
         : 24               local_daif_restore():
         : 79               pmr_sync();
    0.00 :   ffff80001001c31c:       dsb     sy
         : 117              write_sysreg(flags, daif);
    0.00 :   ffff80001001c320:       msr     daif, xzr
         : 119              do_notify_resume():
         : 929              if (thread_flags & _TIF_MTE_ASYNC_FAULT) {
  100.00 :   ffff80001001c324:       tbz     w19, #5, ffff80001001c20c <do_notify_resume+0xdc>
         : 931              get_current():
    0.00 :   ffff80001001c328:       mrs     x0, sp_el0
         : 20               arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff80001001c32c:       b       ffff80001001c388 <do_notify_resume+0x258>
    0.00 :   ffff80001001c330:       b       ffff80001001c388 <do_notify_resume+0x258>
         : 41               __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff80001001c334:       mov     x1, #0x20                       // #32
    0.00 :   ffff80001001c338:       stclr   x1, [x0]
         : 179              get_current():
    0.00 :   ffff80001001c33c:       mrs     x3, sp_el0
         : 20               do_notify_resume():
         : 931              send_sig_fault(SIGSEGV, SEGV_MTEAERR,
    0.00 :   ffff80001001c340:       mov     x2, #0x0                        // #0
    0.00 :   ffff80001001c344:       mov     w1, #0x8                        // #8
    0.00 :   ffff80001001c348:       mov     w0, #0xb                        // #11
    0.00 :   ffff80001001c34c:       bl      ffff800010094bf8 <send_sig_fault>
    0.00 :   ffff80001001c350:       b       ffff80001001c20c <do_notify_resume+0xdc>
         : 937              test_bit():
    0.00 :   ffff80001001c354:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff80001001c358:       ldr     x0, [x0, #1296]
         : 108              local_daif_restore():
         : 81               } else if (system_uses_irq_prio_masking()) {
    0.00 :   ffff80001001c35c:       tbz     w0, #19, ffff80001001c18c <do_notify_resume+0x5c>
         : 83               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff80001001c360:       nop
    0.00 :   ffff80001001c364:       mov     x0, #0x60                       // #96
    0.00 :   ffff80001001c368:       b       ffff80001001c4b0 <do_notify_resume+0x380>
         : 25               __ll_sc_atomic64_andnot():
    0.00 :   ffff80001001c36c:       b       ffff80001001c5ac <do_notify_resume+0x47c>
         : 230              tracehook_notify_resume():
         : 187              smp_mb__after_atomic();
    0.00 :   ffff80001001c370:       dmb     ish
         : 189              get_current():
    0.00 :   ffff80001001c374:       mrs     x0, sp_el0
         : 20               tracehook_notify_resume():
         : 188              if (unlikely(current->task_works))
    0.00 :   ffff80001001c378:       ldr     x0, [x0, #1720]
    0.00 :   ffff80001001c37c:       cbz     x0, ffff80001001c248 <do_notify_resume+0x118>
         : 189              task_work_run();
    0.00 :   ffff80001001c380:       bl      ffff8000100a5dc0 <task_work_run>
    0.00 :   ffff80001001c384:       b       ffff80001001c248 <do_notify_resume+0x118>
         : 192              __ll_sc_atomic64_andnot():
    0.00 :   ffff80001001c388:       mov     x1, #0x20                       // #32
    0.00 :   ffff80001001c38c:       b       ffff80001001c5c4 <do_notify_resume+0x494>
    0.00 :   ffff80001001c390:       b       ffff80001001c33c <do_notify_resume+0x20c>
         : 232              do_signal():
         : 882              if (get_signal(&ksig)) {
    0.00 :   ffff80001001c394:       add     x0, sp, #0x60
    0.00 :   ffff80001001c398:       bl      ffff800010095550 <get_signal>
    0.00 :   ffff80001001c39c:       tst     w0, #0xff
    0.00 :   ffff80001001c3a0:       b.eq    ffff80001001c2cc <do_notify_resume+0x19c>  // b.none
         : 887              get_current():
    0.00 :   ffff80001001c3a4:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff80001001c3a8:       ldr     x3, [x0]
         : 107              sigmask_to_save():
         :
         : 529              static inline sigset_t *sigmask_to_save(void)
         : 530              {
         : 531              sigset_t *res = &current->blocked;
         : 532              if (unlikely(test_restore_sigmask()))
         : 533              res = &current->saved_sigmask;
    0.00 :   ffff80001001c3ac:       add     x26, x0, #0x680
         : 535              __preempt_count_add():
         : 46               return !current_thread_info()->preempt.need_resched;
         : 47               }
         :
         : 49               static inline void __preempt_count_add(int val)
         : 50               {
         : 51               u32 pc = READ_ONCE(current_thread_info()->preempt.count);
    0.00 :   ffff80001001c3b0:       ldr     w1, [x0, #8]
         : 53               sigmask_to_save():
    0.00 :   ffff80001001c3b4:       add     x2, x0, #0x670
         : 529              handle_signal():
         : 808              int usig = ksig->sig;
    0.00 :   ffff80001001c3b8:       ldr     w27, [sp, #176]
         : 810              sigmask_to_save():
    0.00 :   ffff80001001c3bc:       tst     x3, #0x100000
         : 529              __preempt_count_add():
         : 47               pc += val;
    0.00 :   ffff80001001c3c0:       add     w1, w1, #0x1
         : 49               sigmask_to_save():
    0.00 :   ffff80001001c3c4:       csel    x26, x2, x26, eq  // eq = none
         : 529              __preempt_count_add():
         : 48               WRITE_ONCE(current_thread_info()->preempt.count, pc);
    0.00 :   ffff80001001c3c8:       str     w1, [x0, #8]
         : 50               __set_bit():
         : 21               *p  |= mask;
    0.00 :   ffff80001001c3cc:       ldr     x1, [x0, #2320]
    0.00 :   ffff80001001c3d0:       orr     x1, x1, #0x2
    0.00 :   ffff80001001c3d4:       str     x1, [x0, #2320]
         : 25               __preempt_count_dec_and_test():
         : 61               }
         :
         : 63               static inline bool __preempt_count_dec_and_test(void)
         : 64               {
         : 65               struct thread_info *ti = current_thread_info();
         : 66               u64 pc = READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001001c3d8:       ldr     x1, [x0, #8]
         :
         : 65               /* Update only the count field, leaving need_resched unchanged */
         : 66               WRITE_ONCE(ti->preempt.count, --pc);
    0.00 :   ffff80001001c3dc:       sub     x1, x1, #0x1
    0.00 :   ffff80001001c3e0:       str     w1, [x0, #8]
         : 73               * need of a reschedule. Otherwise, we need to reload the
         : 74               * preempt_count in case the need_resched flag was cleared by an
         : 75               * interrupt occurring between the non-atomic READ_ONCE/WRITE_ONCE
         : 76               * pair.
         : 77               */
         : 78               return !pc || !READ_ONCE(ti->preempt_count);
    0.00 :   ffff80001001c3e4:       cbnz    x1, ffff80001001c4bc <do_notify_resume+0x38c>
         : 80               rseq_signal_deliver():
         : 2079             RSEQ_EVENT_SIGNAL_BIT   = RSEQ_CS_FLAG_NO_RESTART_ON_SIGNAL_BIT,
         : 2080             RSEQ_EVENT_MIGRATE_BIT  = RSEQ_CS_FLAG_NO_RESTART_ON_MIGRATE_BIT,
         : 2081             };
         :
         : 2083             enum rseq_event_mask {
         : 2084             RSEQ_EVENT_PREEMPT      = (1U << RSEQ_EVENT_PREEMPT_BIT),
    0.00 :   ffff80001001c3e8:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff80001001c3ec:       nop
         : 2087             get_current():
    0.00 :   ffff80001001c3f0:       mrs     x0, sp_el0
         : 20               rseq_handle_notify_resume():
         : 2070             * for direct mask checks.
    0.00 :   ffff80001001c3f4:       ldr     x0, [x0, #2304]
    0.00 :   ffff80001001c3f8:       cbz     x0, ffff80001001c408 <do_notify_resume+0x2d8>
         : 2071             */
    0.00 :   ffff80001001c3fc:       mov     x1, x20
    0.00 :   ffff80001001c400:       add     x0, sp, #0x60
    0.00 :   ffff80001001c404:       bl      ffff80001017b950 <__rseq_handle_notify_resume>
         : 2075             get_current():
    0.00 :   ffff80001001c408:       mrs     x0, sp_el0
         : 20               test_bit():
         : 106              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001001c40c:       ldr     x0, [x0]
         : 108              handle_signal():
         : 816              if (is_compat_task()) {
    0.00 :   ffff80001001c410:       tbz     w0, #22, ffff80001001c524 <do_notify_resume+0x3f4>
         : 817              if (ksig->ka.sa.sa_flags & SA_SIGINFO)
    0.00 :   ffff80001001c414:       ldr     x0, [sp, #104]
         : 818              ret = compat_setup_rt_frame(usig, ksig, oldset, regs);
    0.00 :   ffff80001001c418:       mov     x2, x26
         : 817              if (ksig->ka.sa.sa_flags & SA_SIGINFO)
    0.00 :   ffff80001001c41c:       tbnz    w0, #2, ffff80001001c4f4 <do_notify_resume+0x3c4>
         : 820              ret = compat_setup_frame(usig, ksig, oldset, regs);
    0.00 :   ffff80001001c420:       mov     w0, w27
    0.00 :   ffff80001001c424:       mov     x3, x20
    0.00 :   ffff80001001c428:       add     x1, sp, #0x60
    0.00 :   ffff80001001c42c:       bl      ffff800010029008 <compat_setup_frame>
    0.00 :   ffff80001001c430:       mov     w27, w0
         : 826              get_current():
    0.00 :   ffff80001001c434:       mrs     x26, sp_el0
         : 20               handle_signal():
         : 828              ret |= !valid_user_regs(&regs->user_regs, current);
    0.00 :   ffff80001001c438:       mov     x0, x20
    0.00 :   ffff80001001c43c:       mov     x1, x26
    0.00 :   ffff80001001c440:       bl      ffff800010019830 <valid_user_regs>
    0.00 :   ffff80001001c444:       cmp     w0, #0x0
         : 833              test_bit():
    0.00 :   ffff80001001c448:       ldr     x2, [x26]
         : 107              handle_signal():
    0.00 :   ffff80001001c44c:       cset    w0, eq  // eq = none
         : 831              signal_setup_done(ret, ksig, test_thread_flag(TIF_SINGLESTEP));
    0.00 :   ffff80001001c450:       orr     w0, w0, w27
    0.00 :   ffff80001001c454:       add     x1, sp, #0x60
    0.00 :   ffff80001001c458:       ubfx    w2, w2, #21, #1
    0.00 :   ffff80001001c45c:       bl      ffff800010095140 <signal_setup_done>
         : 836              do_notify_resume():
         : 938              if (thread_flags & _TIF_NOTIFY_RESUME) {
    0.00 :   ffff80001001c460:       tbz     w19, #2, ffff80001001c218 <do_notify_resume+0xe8>
    0.00 :   ffff80001001c464:       b       ffff80001001c224 <do_notify_resume+0xf4>
         : 941              do_signal():
         : 872              regs->regs[0] = regs->orig_x0;
    0.00 :   ffff80001001c468:       ldr     x0, [x20, #272]
    0.00 :   ffff80001001c46c:       str     x0, [x20]
         : 873              regs->pc = restart_addr;
    0.00 :   ffff80001001c470:       str     x26, [x20, #256]
         : 882              if (get_signal(&ksig)) {
    0.00 :   ffff80001001c474:       add     x0, sp, #0x60
    0.00 :   ffff80001001c478:       bl      ffff800010095550 <get_signal>
    0.00 :   ffff80001001c47c:       tst     w0, #0xff
    0.00 :   ffff80001001c480:       b.eq    ffff80001001c2c0 <do_notify_resume+0x190>  // b.none
         : 888              if (regs->pc == restart_addr &&
    0.00 :   ffff80001001c484:       ldr     x0, [x20, #256]
    0.00 :   ffff80001001c488:       cmp     x26, x0
    0.00 :   ffff80001001c48c:       b.ne    ffff80001001c3a4 <do_notify_resume+0x274>  // b.any
         : 890              retval == -ERESTART_RESTARTBLOCK ||
    0.00 :   ffff80001001c490:       and     w0, w27, #0xfffffffd
         : 888              if (regs->pc == restart_addr &&
    0.00 :   ffff80001001c494:       cmn     w0, #0x204
    0.00 :   ffff80001001c498:       b.ne    ffff80001001c540 <do_notify_resume+0x410>  // b.any
         : 893              regs->regs[0] = -EINTR;
    0.00 :   ffff80001001c49c:       mov     x0, #0xfffffffffffffffc         // #-4
    0.00 :   ffff80001001c4a0:       str     x0, [x20]
         : 894              regs->pc = continue_addr;
    0.00 :   ffff80001001c4a4:       str     x28, [x20, #256]
    0.00 :   ffff80001001c4a8:       b       ffff80001001c3a4 <do_notify_resume+0x274>
         : 897              arch_static_branch():
    0.00 :   ffff80001001c4ac:       mov     x0, #0xa0                       // #160
         : 22               gic_write_pmr():
    0.00 :   ffff80001001c4b0:       msr     s3_0_c4_c6_0, x0
    0.00 :   ffff80001001c4b4:       mov     x0, #0x0                        // #0
    0.00 :   ffff80001001c4b8:       b       ffff80001001c190 <do_notify_resume+0x60>
         : 117              __preempt_count_dec_and_test():
    0.00 :   ffff80001001c4bc:       ldr     x0, [x0, #8]
    0.00 :   ffff80001001c4c0:       cbnz    x0, ffff80001001c3f0 <do_notify_resume+0x2c0>
         : 75               rseq_signal_deliver():
         : 2079             RSEQ_EVENT_PREEMPT      = (1U << RSEQ_EVENT_PREEMPT_BIT),
    0.00 :   ffff80001001c4c4:       bl      ffff800010e2e620 <preempt_schedule>
    0.00 :   ffff80001001c4c8:       b       ffff80001001c3f0 <do_notify_resume+0x2c0>
         : 2082             do_signal():
         : 906              if (retval == -ERESTART_RESTARTBLOCK)
    0.00 :   ffff80001001c4cc:       cmn     w27, #0x204
    0.00 :   ffff80001001c4d0:       b.eq    ffff80001001c50c <do_notify_resume+0x3dc>  // b.none
         : 909              get_current():
    0.00 :   ffff80001001c4d4:       mrs     x0, sp_el0
         : 20               do_signal():
         : 908              user_rewind_single_step(current);
    0.00 :   ffff80001001c4d8:       bl      ffff800010014500 <user_rewind_single_step>
         : 910              get_current():
    0.00 :   ffff80001001c4dc:       mrs     x0, sp_el0
         : 20               test_and_clear_bit():
    0.00 :   ffff80001001c4e0:       ldr     x1, [x0]
    0.00 :   ffff80001001c4e4:       tbz     w1, #20, ffff80001001c214 <do_notify_resume+0xe4>
    0.00 :   ffff80001001c4e8:       b       ffff80001001c2d8 <do_notify_resume+0x1a8>
         : 54               __ll_sc_atomic64_fetch_andnot():
    0.00 :   ffff80001001c4ec:       b       ffff80001001c5dc <do_notify_resume+0x4ac>
    0.00 :   ffff80001001c4f0:       b       ffff80001001c2e8 <do_notify_resume+0x1b8>
         : 231              handle_signal():
         : 818              ret = compat_setup_rt_frame(usig, ksig, oldset, regs);
    0.00 :   ffff80001001c4f4:       mov     w0, w27
    0.00 :   ffff80001001c4f8:       mov     x3, x20
    0.00 :   ffff80001001c4fc:       add     x1, sp, #0x60
    0.00 :   ffff80001001c500:       bl      ffff800010028e00 <compat_setup_rt_frame>
    0.00 :   ffff80001001c504:       mov     w27, w0
    0.00 :   ffff80001001c508:       b       ffff80001001c434 <do_notify_resume+0x304>
         : 825              get_current():
    0.00 :   ffff80001001c50c:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff80001001c510:       ldr     x0, [x0]
         : 107              setup_restart_syscall():
         : 796              if (is_compat_task())
    0.00 :   ffff80001001c514:       tbnz    w0, #22, ffff80001001c554 <do_notify_resume+0x424>
         : 799              regs->regs[8] = __NR_restart_syscall;
    0.00 :   ffff80001001c518:       mov     x0, #0x80                       // #128
    0.00 :   ffff80001001c51c:       str     x0, [x20, #64]
    0.00 :   ffff80001001c520:       b       ffff80001001c4d4 <do_notify_resume+0x3a4>
         : 803              handle_signal():
         : 822              ret = setup_rt_frame(usig, ksig, oldset, regs);
    0.00 :   ffff80001001c524:       mov     w0, w27
    0.00 :   ffff80001001c528:       mov     x2, x26
    0.00 :   ffff80001001c52c:       mov     x3, x20
    0.00 :   ffff80001001c530:       add     x1, sp, #0x60
    0.00 :   ffff80001001c534:       bl      ffff80001001a9c8 <setup_rt_frame>
    0.00 :   ffff80001001c538:       mov     w27, w0
    0.00 :   ffff80001001c53c:       b       ffff80001001c434 <do_notify_resume+0x304>
         : 830              do_signal():
         : 890              retval == -ERESTART_RESTARTBLOCK ||
    0.00 :   ffff80001001c540:       cmn     w27, #0x200
    0.00 :   ffff80001001c544:       b.ne    ffff80001001c3a4 <do_notify_resume+0x274>  // b.any
         : 892              !(ksig.ka.sa.sa_flags & SA_RESTART)))) {
    0.00 :   ffff80001001c548:       ldr     x0, [sp, #104]
         : 891              (retval == -ERESTARTSYS &&
    0.00 :   ffff80001001c54c:       tbnz    w0, #28, ffff80001001c3a4 <do_notify_resume+0x274>
    0.00 :   ffff80001001c550:       b       ffff80001001c49c <do_notify_resume+0x36c>
         : 894              setup_restart_syscall():
         : 797              compat_setup_restart_syscall(regs);
    0.00 :   ffff80001001c554:       mov     x0, x20
    0.00 :   ffff80001001c558:       bl      ffff800010029158 <compat_setup_restart_syscall>
    0.00 :   ffff80001001c55c:       b       ffff80001001c4d4 <do_notify_resume+0x3a4>
         : 801              do_notify_resume():
         : 950              }
    0.00 :   ffff80001001c560:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104bb830 <vsnprintf>:
         : 6                vsnprintf():
         : 2683             }
         :
         : 2685             static void
         : 2686             set_field_width(struct printf_spec *spec, int width)
         : 2687             {
         : 2688             spec->field_width = width;
    0.00 :   ffff8000104bb830:       paciasp
    0.00 :   ffff8000104bb834:       stp     x29, x30, [sp, #-144]!
    0.00 :   ffff8000104bb838:       mov     x29, sp
    0.00 :   ffff8000104bb83c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000104bb840:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000104bb844:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000104bb848:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000104bb84c:       mov     x23, x0
    0.00 :   ffff8000104bb850:       add     x4, x24, #0x948
         : 2690             spec->field_width = clamp(width, -FIELD_WIDTH_MAX, FIELD_WIDTH_MAX);
         : 2691             }
         : 2692             }
         :
         : 2694             static void
         : 2695             set_precision(struct printf_spec *spec, int prec)
    0.00 :   ffff8000104bb854:       mov     x0, #0x7fffffff                 // #2147483647
         : 2683             spec->field_width = width;
    0.00 :   ffff8000104bb858:       ldr     x5, [x4]
    0.00 :   ffff8000104bb85c:       str     x5, [sp, #136]
    0.00 :   ffff8000104bb860:       mov     x5, #0x0                        // #0
         : 2690             set_precision(struct printf_spec *spec, int prec)
    0.00 :   ffff8000104bb864:       cmp     x1, x0
    0.00 :   ffff8000104bb868:       ldp     x20, x0, [x3]
    0.00 :   ffff8000104bb86c:       stp     x4, x0, [sp, #104]
    0.00 :   ffff8000104bb870:       ldr     w22, [x3, #24]
         : 2686             }
    0.00 :   ffff8000104bb874:       str     xzr, [sp, #128]
         : 2690             set_precision(struct printf_spec *spec, int prec)
    0.00 :   ffff8000104bb878:       b.hi    ffff8000104bbdc0 <vsnprintf+0x590>  // b.pmore
    0.00 :   ffff8000104bb87c:       stp     x25, x26, [sp, #64]
         : 2694             {
         : 2695             spec->precision = prec;
         : 2696             if (WARN_ONCE(spec->precision != prec, "precision %d too large", prec)) {
         : 2697             spec->precision = clamp(prec, 0, PRECISION_MAX);
    0.00 :   ffff8000104bb880:       add     x19, x23, x1
    0.00 :   ffff8000104bb884:       mov     x25, x1
    0.00 :   ffff8000104bb888:       stp     x27, x28, [sp, #80]
         : 2697             }
         : 2698             }
         :
    0.00 :   ffff8000104bb88c:       cmp     x23, x19
    0.00 :   ffff8000104bb890:       mov     x27, x2
    0.00 :   ffff8000104bb894:       b.ls    ffff8000104bb8a0 <vsnprintf+0x70>  // b.plast
         : 2699             /**
         : 2700             * vsnprintf - Format a string and place it in a buffer
    0.00 :   ffff8000104bb898:       mvn     x25, x23
         : 2698             /**
    0.00 :   ffff8000104bb89c:       mov     x19, #0xffffffffffffffff        // #-1
    0.00 :   ffff8000104bb8a0:       ldrb    w0, [x27]
         : 2758             case FORMAT_TYPE_NONE: {
         : 2759             int copy = read;
         : 2760             if (str < end) {
         : 2761             if (copy > end - str)
         : 2762             copy = end - str;
         : 2763             memcpy(str, old_fmt, copy);
    0.00 :   ffff8000104bb8a4:       adrp    x21, ffff800010eaf000 <fontdata_8x16+0xd98>
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bb8a8:       mov     x28, x23
         : 2758             memcpy(str, old_fmt, copy);
    0.00 :   ffff8000104bb8ac:       add     x21, x21, #0x7f8
         :
  100.00 :   ffff8000104bb8b0:       mov     w26, #0x20                      // #32
    0.00 :   ffff8000104bb8b4:       nop
         : 2702             * @fmt: The format string to use
    0.00 :   ffff8000104bb8b8:       cbz     w0, ffff8000104bb8fc <vsnprintf+0xcc>
         : 2704             *
    0.00 :   ffff8000104bb8bc:       add     x1, sp, #0x80
    0.00 :   ffff8000104bb8c0:       mov     x0, x27
    0.00 :   ffff8000104bb8c4:       bl      ffff8000104b83a0 <format_decode>
         : 2708             *  - ``%n`` is unsupported
    0.00 :   ffff8000104bb8c8:       ldrb    w1, [sp, #128]
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bb8cc:       sxtw    x3, w0
    0.00 :   ffff8000104bb8d0:       add     x24, x27, x3
         : 2708             *  - ``%n`` is unsupported
    0.00 :   ffff8000104bb8d4:       cmp     w1, #0x3
    0.00 :   ffff8000104bb8d8:       b.eq    ffff8000104bbb10 <vsnprintf+0x2e0>  // b.none
    0.00 :   ffff8000104bb8dc:       b.ls    ffff8000104bba10 <vsnprintf+0x1e0>  // b.plast
    0.00 :   ffff8000104bb8e0:       cmp     w1, #0x5
    0.00 :   ffff8000104bb8e4:       b.eq    ffff8000104bbbcc <vsnprintf+0x39c>  // b.none
    0.00 :   ffff8000104bb8e8:       b.cc    ffff8000104bbb98 <vsnprintf+0x368>  // b.lo, b.ul, b.last
    0.00 :   ffff8000104bb8ec:       cmp     w1, #0x6
    0.00 :   ffff8000104bb8f0:       b.eq    ffff8000104bbaf0 <vsnprintf+0x2c0>  // b.none
    0.00 :   ffff8000104bb8f4:       cmp     w1, #0x7
    0.00 :   ffff8000104bb8f8:       b.ne    ffff8000104bb938 <vsnprintf+0x108>  // b.any
         : 2823             * specifiers and arguments would be out of
         : 2824             * sync.
         : 2825             */
         : 2826             goto out;
         :
         : 2828             default:
    0.00 :   ffff8000104bb8fc:       cbnz    x25, ffff8000104bbc24 <vsnprintf+0x3f4>
         : 2831             num = va_arg(args, long long);
         : 2832             break;
         : 2833             case FORMAT_TYPE_ULONG:
         : 2834             num = va_arg(args, unsigned long);
         : 2835             break;
         : 2836             case FORMAT_TYPE_LONG:
    0.00 :   ffff8000104bb900:       sub     w0, w28, w23
    0.00 :   ffff8000104bb904:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000104bb908:       ldp     x27, x28, [sp, #80]
         : 2833             num = va_arg(args, long);
         : 2834             break;
    0.00 :   ffff8000104bb90c:       ldr     x1, [sp, #104]
    0.00 :   ffff8000104bb910:       ldr     x2, [sp, #136]
    0.00 :   ffff8000104bb914:       ldr     x1, [x1]
    0.00 :   ffff8000104bb918:       eor     x1, x2, x1
    0.00 :   ffff8000104bb91c:       cbnz    x1, ffff8000104bbfc4 <vsnprintf+0x794>
    0.00 :   ffff8000104bb920:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104bb924:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000104bb928:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000104bb92c:       ldp     x29, x30, [sp], #144
    0.00 :   ffff8000104bb930:       autiasp
    0.00 :   ffff8000104bb934:       ret
         :
    0.00 :   ffff8000104bb938:       cmp     w1, #0xc
    0.00 :   ffff8000104bb93c:       b.eq    ffff8000104bbe08 <vsnprintf+0x5d8>  // b.none
    0.00 :   ffff8000104bb940:       b.ls    ffff8000104bb9bc <vsnprintf+0x18c>  // b.plast
    0.00 :   ffff8000104bb944:       cmp     w1, #0x10
    0.00 :   ffff8000104bb948:       b.eq    ffff8000104bbd58 <vsnprintf+0x528>  // b.none
    0.00 :   ffff8000104bb94c:       b.hi    ffff8000104bb978 <vsnprintf+0x148>  // b.pmore
    0.00 :   ffff8000104bb950:       cmp     w1, #0xd
    0.00 :   ffff8000104bb954:       b.eq    ffff8000104bbcdc <vsnprintf+0x4ac>  // b.none
    0.00 :   ffff8000104bb958:       cmp     w1, #0xe
    0.00 :   ffff8000104bb95c:       b.ne    ffff8000104bb9f8 <vsnprintf+0x1c8>  // b.any
         : 2809             ++str;
    0.00 :   ffff8000104bb960:       tbnz    w22, #31, ffff8000104bbe68 <vsnprintf+0x638>
    0.00 :   ffff8000104bb964:       mov     x0, x20
    0.00 :   ffff8000104bb968:       add     x1, x20, #0xb
    0.00 :   ffff8000104bb96c:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bb970:       ldrsh   x2, [x0]
         : 2810             break;
    0.00 :   ffff8000104bb974:       b       ffff8000104bb99c <vsnprintf+0x16c>
    0.00 :   ffff8000104bb978:       cmp     w1, #0x11
    0.00 :   ffff8000104bb97c:       b.eq    ffff8000104bb988 <vsnprintf+0x158>  // b.none
    0.00 :   ffff8000104bb980:       cmp     w1, #0x12
    0.00 :   ffff8000104bb984:       b.ne    ffff8000104bb9f8 <vsnprintf+0x1c8>  // b.any
         : 2797             break;
    0.00 :   ffff8000104bb988:       tbnz    w22, #31, ffff8000104bbd38 <vsnprintf+0x508>
    0.00 :   ffff8000104bb98c:       add     x1, x20, #0xf
    0.00 :   ffff8000104bb990:       mov     x0, x20
    0.00 :   ffff8000104bb994:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bb998:       ldr     x2, [x0]
         : 2818             * specifiers and arguments would be out of
    0.00 :   ffff8000104bb99c:       mov     x0, x28
    0.00 :   ffff8000104bb9a0:       ldr     x3, [sp, #128]
    0.00 :   ffff8000104bb9a4:       mov     x1, x19
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bb9a8:       mov     x27, x24
         : 2818             * specifiers and arguments would be out of
    0.00 :   ffff8000104bb9ac:       bl      ffff8000104b7c60 <number>
    0.00 :   ffff8000104bb9b0:       mov     x28, x0
    0.00 :   ffff8000104bb9b4:       ldrb    w0, [x24]
    0.00 :   ffff8000104bb9b8:       b       ffff8000104bb8b8 <vsnprintf+0x88>
    0.00 :   ffff8000104bb9bc:       cmp     w1, #0x9
    0.00 :   ffff8000104bb9c0:       b.eq    ffff8000104bb988 <vsnprintf+0x158>  // b.none
    0.00 :   ffff8000104bb9c4:       b.ls    ffff8000104bb9f0 <vsnprintf+0x1c0>  // b.plast
    0.00 :   ffff8000104bb9c8:       cmp     w1, #0xa
    0.00 :   ffff8000104bb9cc:       b.eq    ffff8000104bb988 <vsnprintf+0x158>  // b.none
    0.00 :   ffff8000104bb9d0:       cmp     w1, #0xb
    0.00 :   ffff8000104bb9d4:       b.ne    ffff8000104bb9f8 <vsnprintf+0x1c8>  // b.any
         : 2800             str = pointer(fmt, str, end, va_arg(args, void *),
    0.00 :   ffff8000104bb9d8:       tbnz    w22, #31, ffff8000104bbed4 <vsnprintf+0x6a4>
    0.00 :   ffff8000104bb9dc:       mov     x0, x20
    0.00 :   ffff8000104bb9e0:       add     x1, x20, #0xb
    0.00 :   ffff8000104bb9e4:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bb9e8:       ldrb    w2, [x0]
         : 2801             spec);
    0.00 :   ffff8000104bb9ec:       b       ffff8000104bb99c <vsnprintf+0x16c>
    0.00 :   ffff8000104bb9f0:       cmp     w1, #0x8
    0.00 :   ffff8000104bb9f4:       b.eq    ffff8000104bb988 <vsnprintf+0x158>  // b.none
         : 2815             * checking, but there is no safe or sane way
    0.00 :   ffff8000104bb9f8:       tbnz    w22, #31, ffff8000104bbe20 <vsnprintf+0x5f0>
    0.00 :   ffff8000104bb9fc:       mov     x0, x20
    0.00 :   ffff8000104bba00:       add     x1, x20, #0xb
    0.00 :   ffff8000104bba04:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bba08:       ldr     w2, [x0]
    0.00 :   ffff8000104bba0c:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2708             *  - ``%n`` is unsupported
    0.00 :   ffff8000104bba10:       cmp     w1, #0x1
    0.00 :   ffff8000104bba14:       b.eq    ffff8000104bbab8 <vsnprintf+0x288>  // b.none
    0.00 :   ffff8000104bba18:       b.hi    ffff8000104bba58 <vsnprintf+0x228>  // b.pmore
         : 2711             * See pointer() or Documentation/core-api/printk-formats.rst for more
    0.00 :   ffff8000104bba1c:       cmp     x28, x19
    0.00 :   ffff8000104bba20:       b.cs    ffff8000104bba48 <vsnprintf+0x218>  // b.hs, b.nlast
         : 2712             * extensive description.
    0.00 :   ffff8000104bba24:       sub     x2, x19, x28
         : 2714             * **Please update the documentation in both places when making changes**
    0.00 :   ffff8000104bba28:       mov     x1, x27
    0.00 :   ffff8000104bba2c:       cmp     x3, x2
    0.00 :   ffff8000104bba30:       mov     x0, x28
    0.00 :   ffff8000104bba34:       sxtw    x2, w2
    0.00 :   ffff8000104bba38:       str     x3, [sp, #120]
    0.00 :   ffff8000104bba3c:       csel    x2, x2, x3, gt
    0.00 :   ffff8000104bba40:       bl      ffff8000104a5b40 <__memcpy>
    0.00 :   ffff8000104bba44:       ldr     x3, [sp, #120]
         : 2716             * The return value is the number of characters which would
    0.00 :   ffff8000104bba48:       add     x28, x28, x3
         : 2717             * be generated for the given input, excluding the trailing
    0.00 :   ffff8000104bba4c:       ldrb    w0, [x24]
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bba50:       mov     x27, x24
         : 2717             * be generated for the given input, excluding the trailing
    0.00 :   ffff8000104bba54:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         : 2725             */
    0.00 :   ffff8000104bba58:       tbnz    w22, #31, ffff8000104bbc94 <vsnprintf+0x464>
    0.00 :   ffff8000104bba5c:       add     x1, x20, #0xb
    0.00 :   ffff8000104bba60:       mov     x0, x20
    0.00 :   ffff8000104bba64:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bba68:       ldr     w27, [x0]
         : 2731             set_precision():
         : 2648             */
    0.00 :   ffff8000104bba6c:       ldrh    w0, [sp, #134]
    0.00 :   ffff8000104bba70:       sxth    w1, w27
         : 2649             fallthrough;
    0.00 :   ffff8000104bba74:       cmp     w27, w1
         : 2648             */
    0.00 :   ffff8000104bba78:       bfxil   w0, w1, #0, #16
    0.00 :   ffff8000104bba7c:       strh    w0, [sp, #134]
         : 2649             fallthrough;
    0.00 :   ffff8000104bba80:       b.eq    ffff8000104bbae4 <vsnprintf+0x2b4>  // b.none
    0.00 :   ffff8000104bba84:       adrp    x3, ffff800011efe000 <errmap+0xc38>
    0.00 :   ffff8000104bba88:       add     x3, x3, #0xb4d
    0.00 :   ffff8000104bba8c:       ldrb    w0, [x3, #2]
    0.00 :   ffff8000104bba90:       cbz     w0, ffff8000104bbfa4 <vsnprintf+0x774>
         :
    0.00 :   ffff8000104bba94:       cmp     w27, #0x0
    0.00 :   ffff8000104bba98:       mov     w1, #0x7fff                     // #32767
    0.00 :   ffff8000104bba9c:       csel    w2, w27, wzr, ge  // ge = tcont
    0.00 :   ffff8000104bbaa0:       ldrb    w0, [x24]
    0.00 :   ffff8000104bbaa4:       cmp     w2, w1
         : 2656             vsnprintf():
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bbaa8:       mov     x27, x24
         : 2708             set_precision():
         :
    0.00 :   ffff8000104bbaac:       csel    w2, w2, w1, le
    0.00 :   ffff8000104bbab0:       strh    w2, [sp, #134]
    0.00 :   ffff8000104bbab4:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         : 2654             vsnprintf():
         : 2721             * return is greater than or equal to @size, the resulting
    0.00 :   ffff8000104bbab8:       tbnz    w22, #31, ffff8000104bbc34 <vsnprintf+0x404>
    0.00 :   ffff8000104bbabc:       add     x1, x20, #0xb
    0.00 :   ffff8000104bbac0:       mov     x0, x20
    0.00 :   ffff8000104bbac4:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bbac8:       ldr     w27, [x0]
         : 2727             set_field_width():
         : 2639             break;
    0.00 :   ffff8000104bbacc:       ldrb    w1, [sp, #128]
    0.00 :   ffff8000104bbad0:       sbfx    x0, x27, #0, #24
         : 2640             case 'u':
    0.00 :   ffff8000104bbad4:       cmp     w27, w0
         : 2639             break;
    0.00 :   ffff8000104bbad8:       orr     w0, w1, w0, lsl #8
    0.00 :   ffff8000104bbadc:       str     w0, [sp, #128]
         : 2640             case 'u':
    0.00 :   ffff8000104bbae0:       b.ne    ffff8000104bbdcc <vsnprintf+0x59c>  // b.any
    0.00 :   ffff8000104bbae4:       ldrb    w0, [x24]
         : 2643             vsnprintf():
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bbae8:       mov     x27, x24
    0.00 :   ffff8000104bbaec:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         :
    0.00 :   ffff8000104bbaf0:       cmp     x28, x19
    0.00 :   ffff8000104bbaf4:       b.cs    ffff8000104bbb00 <vsnprintf+0x2d0>  // b.hs, b.nlast
         : 2764             case FORMAT_TYPE_WIDTH:
    0.00 :   ffff8000104bbaf8:       mov     w0, #0x25                       // #37
    0.00 :   ffff8000104bbafc:       strb    w0, [x28]
         : 2765             set_field_width(&spec, va_arg(args, int));
    0.00 :   ffff8000104bbb00:       add     x28, x28, #0x1
         : 2766             break;
    0.00 :   ffff8000104bbb04:       ldrb    w0, [x24]
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bbb08:       mov     x27, x24
         : 2766             break;
    0.00 :   ffff8000104bbb0c:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         :
    0.00 :   ffff8000104bbb10:       ldrb    w0, [sp, #132]
    0.00 :   ffff8000104bbb14:       tbz     w0, #1, ffff8000104bbcf4 <vsnprintf+0x4c4>
         :
    0.00 :   ffff8000104bbb18:       tbnz    w22, #31, ffff8000104bbc74 <vsnprintf+0x444>
    0.00 :   ffff8000104bbb1c:       add     x1, x20, #0xb
    0.00 :   ffff8000104bbb20:       mov     x0, x20
    0.00 :   ffff8000104bbb24:       and     x20, x1, #0xfffffffffffffff8
         : 2740             /* Make sure end is always >= buf */
    0.00 :   ffff8000104bbb28:       cmp     x28, x19
    0.00 :   ffff8000104bbb2c:       b.cs    ffff8000104bbb38 <vsnprintf+0x308>  // b.hs, b.nlast
         :
    0.00 :   ffff8000104bbb30:       ldr     w0, [x0]
    0.00 :   ffff8000104bbb34:       strb    w0, [x28]
         : 2743             size = end - buf;
    0.00 :   ffff8000104bbb38:       ldr     w0, [sp, #128]
         : 2742             end = ((void *)-1);
    0.00 :   ffff8000104bbb3c:       add     x28, x28, #0x1
         : 2743             size = end - buf;
    0.00 :   ffff8000104bbb40:       mov     w1, w0
    0.00 :   ffff8000104bbb44:       sbfx    x0, x0, #8, #24
    0.00 :   ffff8000104bbb48:       sub     w0, w0, #0x1
    0.00 :   ffff8000104bbb4c:       sbfx    x0, x0, #0, #24
    0.00 :   ffff8000104bbb50:       cmp     w0, #0x0
    0.00 :   ffff8000104bbb54:       bfi     w1, w0, #8, #24
    0.00 :   ffff8000104bbb58:       str     w1, [sp, #128]
    0.00 :   ffff8000104bbb5c:       b.le    ffff8000104bbae4 <vsnprintf+0x2b4>
         : 2744             }
    0.00 :   ffff8000104bbb60:       cmp     x19, x28
    0.00 :   ffff8000104bbb64:       b.ls    ffff8000104bbb6c <vsnprintf+0x33c>  // b.plast
         :
    0.00 :   ffff8000104bbb68:       strb    w26, [x28]
         : 2743             size = end - buf;
    0.00 :   ffff8000104bbb6c:       ldr     w1, [sp, #128]
         : 2746             while (*fmt) {
    0.00 :   ffff8000104bbb70:       add     x28, x28, #0x1
         : 2743             size = end - buf;
    0.00 :   ffff8000104bbb74:       mov     w0, w1
    0.00 :   ffff8000104bbb78:       sbfx    x1, x1, #8, #24
    0.00 :   ffff8000104bbb7c:       sub     w1, w1, #0x1
    0.00 :   ffff8000104bbb80:       sbfx    x1, x1, #0, #24
    0.00 :   ffff8000104bbb84:       cmp     w1, #0x0
    0.00 :   ffff8000104bbb88:       bfi     w0, w1, #8, #24
    0.00 :   ffff8000104bbb8c:       str     w0, [sp, #128]
    0.00 :   ffff8000104bbb90:       b.gt    ffff8000104bbb60 <vsnprintf+0x330>
    0.00 :   ffff8000104bbb94:       b       ffff8000104bbae4 <vsnprintf+0x2b4>
         : 2752             switch (spec.type) {
    0.00 :   ffff8000104bbb98:       tbnz    w22, #31, ffff8000104bbc54 <vsnprintf+0x424>
    0.00 :   ffff8000104bbb9c:       add     x0, x20, #0xf
    0.00 :   ffff8000104bbba0:       mov     x1, x20
    0.00 :   ffff8000104bbba4:       and     x20, x0, #0xfffffffffffffff8
    0.00 :   ffff8000104bbba8:       ldr     x2, [x1]
    0.00 :   ffff8000104bbbac:       mov     x0, x28
    0.00 :   ffff8000104bbbb0:       ldr     x3, [sp, #128]
    0.00 :   ffff8000104bbbb4:       mov     x1, x19
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bbbb8:       mov     x27, x24
         : 2752             switch (spec.type) {
    0.00 :   ffff8000104bbbbc:       bl      ffff8000104b8e58 <string>
    0.00 :   ffff8000104bbbc0:       mov     x28, x0
         : 2753             case FORMAT_TYPE_NONE: {
    0.00 :   ffff8000104bbbc4:       ldrb    w0, [x24]
    0.00 :   ffff8000104bbbc8:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         : 2756             if (copy > end - str)
    0.00 :   ffff8000104bbbcc:       tbnz    w22, #31, ffff8000104bbcb4 <vsnprintf+0x484>
    0.00 :   ffff8000104bbbd0:       add     x1, x20, #0xf
    0.00 :   ffff8000104bbbd4:       mov     x0, x20
    0.00 :   ffff8000104bbbd8:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bbbdc:       ldr     x3, [x0]
    0.00 :   ffff8000104bbbe0:       mov     x1, x28
    0.00 :   ffff8000104bbbe4:       ldr     x4, [sp, #128]
    0.00 :   ffff8000104bbbe8:       mov     x2, x19
    0.00 :   ffff8000104bbbec:       mov     x0, x24
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bbbf0:       mov     x27, x24
         : 2756             if (copy > end - str)
    0.00 :   ffff8000104bbbf4:       bl      ffff8000104bb528 <pointer>
    0.00 :   ffff8000104bbbf8:       mov     x28, x0
         : 2758             memcpy(str, old_fmt, copy);
    0.00 :   ffff8000104bbbfc:       ldrb    w0, [x24]
    0.00 :   ffff8000104bbc00:       ldrb    w1, [x21, w0, sxtw]
    0.00 :   ffff8000104bbc04:       tst     x1, #0x7
    0.00 :   ffff8000104bbc08:       b.eq    ffff8000104bb8b8 <vsnprintf+0x88>  // b.none
    0.00 :   ffff8000104bbc0c:       nop
    0.00 :   ffff8000104bbc10:       ldrb    w0, [x27, #1]!
    0.00 :   ffff8000104bbc14:       ldrb    w1, [x21, w0, sxtw]
    0.00 :   ffff8000104bbc18:       tst     x1, #0x7
    0.00 :   ffff8000104bbc1c:       b.ne    ffff8000104bbc10 <vsnprintf+0x3e0>  // b.any
    0.00 :   ffff8000104bbc20:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         : 2824             switch (spec.type) {
    0.00 :   ffff8000104bbc24:       cmp     x28, x19
    0.00 :   ffff8000104bbc28:       b.cs    ffff8000104bbcd4 <vsnprintf+0x4a4>  // b.hs, b.nlast
         : 2825             case FORMAT_TYPE_LONG_LONG:
    0.00 :   ffff8000104bbc2c:       strb    wzr, [x28]
    0.00 :   ffff8000104bbc30:       b       ffff8000104bb900 <vsnprintf+0xd0>
         : 2721             * return is greater than or equal to @size, the resulting
    0.00 :   ffff8000104bbc34:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbc38:       cmp     w1, #0x0
    0.00 :   ffff8000104bbc3c:       b.le    ffff8000104bbda0 <vsnprintf+0x570>
    0.00 :   ffff8000104bbc40:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbc44:       mov     x0, x20
    0.00 :   ffff8000104bbc48:       mov     w22, w1
    0.00 :   ffff8000104bbc4c:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbc50:       b       ffff8000104bbac8 <vsnprintf+0x298>
         : 2752             switch (spec.type) {
    0.00 :   ffff8000104bbc54:       add     w0, w22, #0x8
    0.00 :   ffff8000104bbc58:       cmp     w0, #0x0
    0.00 :   ffff8000104bbc5c:       b.le    ffff8000104bbd90 <vsnprintf+0x560>
    0.00 :   ffff8000104bbc60:       add     x2, x20, #0xf
    0.00 :   ffff8000104bbc64:       mov     x1, x20
    0.00 :   ffff8000104bbc68:       mov     w22, w0
    0.00 :   ffff8000104bbc6c:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbc70:       b       ffff8000104bbba8 <vsnprintf+0x378>
         :
    0.00 :   ffff8000104bbc74:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbc78:       cmp     w1, #0x0
    0.00 :   ffff8000104bbc7c:       b.le    ffff8000104bbd70 <vsnprintf+0x540>
    0.00 :   ffff8000104bbc80:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbc84:       mov     x0, x20
    0.00 :   ffff8000104bbc88:       mov     w22, w1
    0.00 :   ffff8000104bbc8c:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbc90:       b       ffff8000104bbb28 <vsnprintf+0x2f8>
         : 2725             */
    0.00 :   ffff8000104bbc94:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbc98:       cmp     w1, #0x0
    0.00 :   ffff8000104bbc9c:       b.le    ffff8000104bbdb0 <vsnprintf+0x580>
    0.00 :   ffff8000104bbca0:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbca4:       mov     x0, x20
    0.00 :   ffff8000104bbca8:       mov     w22, w1
    0.00 :   ffff8000104bbcac:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbcb0:       b       ffff8000104bba68 <vsnprintf+0x238>
         : 2756             if (copy > end - str)
    0.00 :   ffff8000104bbcb4:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbcb8:       cmp     w1, #0x0
    0.00 :   ffff8000104bbcbc:       b.le    ffff8000104bbd80 <vsnprintf+0x550>
    0.00 :   ffff8000104bbcc0:       add     x2, x20, #0xf
    0.00 :   ffff8000104bbcc4:       mov     x0, x20
    0.00 :   ffff8000104bbcc8:       mov     w22, w1
    0.00 :   ffff8000104bbccc:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbcd0:       b       ffff8000104bbbdc <vsnprintf+0x3ac>
         : 2827             break;
    0.00 :   ffff8000104bbcd4:       sturb   wzr, [x19, #-1]
    0.00 :   ffff8000104bbcd8:       b       ffff8000104bb900 <vsnprintf+0xd0>
         : 2806             case FORMAT_TYPE_PERCENT_CHAR:
    0.00 :   ffff8000104bbcdc:       tbnz    w22, #31, ffff8000104bbe44 <vsnprintf+0x614>
    0.00 :   ffff8000104bbce0:       mov     x0, x20
    0.00 :   ffff8000104bbce4:       add     x1, x20, #0xb
    0.00 :   ffff8000104bbce8:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bbcec:       ldrh    w2, [x0]
         : 2807             if (str < end)
    0.00 :   ffff8000104bbcf0:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2732             /* Reject out-of-range values early.  Large positive sizes are
    0.00 :   ffff8000104bbcf4:       ldr     w0, [sp, #128]
    0.00 :   ffff8000104bbcf8:       b       ffff8000104bbd10 <vsnprintf+0x4e0>
         : 2733             used for unknown buffer sizes. */
    0.00 :   ffff8000104bbcfc:       cmp     x19, x28
    0.00 :   ffff8000104bbd00:       b.ls    ffff8000104bbd08 <vsnprintf+0x4d8>  // b.plast
         : 2734             if (WARN_ON_ONCE(size > INT_MAX))
    0.00 :   ffff8000104bbd04:       strb    w26, [x28]
         : 2732             /* Reject out-of-range values early.  Large positive sizes are
    0.00 :   ffff8000104bbd08:       ldr     w0, [sp, #128]
         : 2735             return 0;
    0.00 :   ffff8000104bbd0c:       add     x28, x28, #0x1
         : 2732             /* Reject out-of-range values early.  Large positive sizes are
    0.00 :   ffff8000104bbd10:       mov     w1, w0
    0.00 :   ffff8000104bbd14:       sbfx    x0, x0, #8, #24
    0.00 :   ffff8000104bbd18:       sub     w0, w0, #0x1
    0.00 :   ffff8000104bbd1c:       sbfx    x0, x0, #0, #24
    0.00 :   ffff8000104bbd20:       cmp     w0, #0x0
    0.00 :   ffff8000104bbd24:       bfi     w1, w0, #8, #24
    0.00 :   ffff8000104bbd28:       str     w1, [sp, #128]
    0.00 :   ffff8000104bbd2c:       b.gt    ffff8000104bbcfc <vsnprintf+0x4cc>
         :
    0.00 :   ffff8000104bbd30:       tbz     w22, #31, ffff8000104bbb1c <vsnprintf+0x2ec>
    0.00 :   ffff8000104bbd34:       b       ffff8000104bbc74 <vsnprintf+0x444>
         : 2797             break;
    0.00 :   ffff8000104bbd38:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbd3c:       cmp     w1, #0x0
    0.00 :   ffff8000104bbd40:       b.le    ffff8000104bbef8 <vsnprintf+0x6c8>
    0.00 :   ffff8000104bbd44:       add     x2, x20, #0xf
    0.00 :   ffff8000104bbd48:       mov     x0, x20
    0.00 :   ffff8000104bbd4c:       mov     w22, w1
    0.00 :   ffff8000104bbd50:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbd54:       b       ffff8000104bb998 <vsnprintf+0x168>
         : 2812             case FORMAT_TYPE_INVALID:
    0.00 :   ffff8000104bbd58:       tbnz    w22, #31, ffff8000104bbe8c <vsnprintf+0x65c>
    0.00 :   ffff8000104bbd5c:       mov     x0, x20
    0.00 :   ffff8000104bbd60:       add     x1, x20, #0xb
    0.00 :   ffff8000104bbd64:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bbd68:       ldrsw   x2, [x0]
         : 2813             /*
    0.00 :   ffff8000104bbd6c:       b       ffff8000104bb99c <vsnprintf+0x16c>
         :
    0.00 :   ffff8000104bbd70:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbd74:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbd78:       mov     w22, w1
    0.00 :   ffff8000104bbd7c:       b       ffff8000104bbb28 <vsnprintf+0x2f8>
         : 2756             if (copy > end - str)
    0.00 :   ffff8000104bbd80:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbd84:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbd88:       mov     w22, w1
    0.00 :   ffff8000104bbd8c:       b       ffff8000104bbbdc <vsnprintf+0x3ac>
         : 2752             switch (spec.type) {
    0.00 :   ffff8000104bbd90:       ldr     x1, [sp, #112]
    0.00 :   ffff8000104bbd94:       add     x1, x1, w22, sxtw
    0.00 :   ffff8000104bbd98:       mov     w22, w0
    0.00 :   ffff8000104bbd9c:       b       ffff8000104bbba8 <vsnprintf+0x378>
         : 2721             * return is greater than or equal to @size, the resulting
    0.00 :   ffff8000104bbda0:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbda4:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbda8:       mov     w22, w1
    0.00 :   ffff8000104bbdac:       b       ffff8000104bbac8 <vsnprintf+0x298>
         : 2725             */
    0.00 :   ffff8000104bbdb0:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbdb4:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbdb8:       mov     w22, w1
    0.00 :   ffff8000104bbdbc:       b       ffff8000104bba68 <vsnprintf+0x238>
         : 2690             set_precision(struct printf_spec *spec, int prec)
    0.00 :   ffff8000104bbdc0:       brk     #0x800
         : 2691             {
    0.00 :   ffff8000104bbdc4:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000104bbdc8:       b       ffff8000104bb90c <vsnprintf+0xdc>
         : 2694             set_field_width():
         : 2640             case 'u':
    0.00 :   ffff8000104bbdcc:       adrp    x3, ffff800011efe000 <errmap+0xc38>
    0.00 :   ffff8000104bbdd0:       add     x3, x3, #0xb4d
    0.00 :   ffff8000104bbdd4:       ldrb    w1, [x3, #1]
    0.00 :   ffff8000104bbdd8:       cbz     w1, ffff8000104bbf80 <vsnprintf+0x750>
         : 2641             break;
    0.00 :   ffff8000104bbddc:       mov     w1, #0xff800001                 // #-8388607
    0.00 :   ffff8000104bbde0:       cmp     w27, w1
    0.00 :   ffff8000104bbde4:       csel    w2, w27, w1, ge  // ge = tcont
    0.00 :   ffff8000104bbde8:       mov     w1, #0x7fffff                   // #8388607
    0.00 :   ffff8000104bbdec:       cmp     w2, w1
         : 2647             vsnprintf():
         : 2706             * extensions and a few limitations:
    0.00 :   ffff8000104bbdf0:       mov     x27, x24
         : 2708             set_field_width():
         : 2641             break;
    0.00 :   ffff8000104bbdf4:       csel    w2, w2, w1, le
    0.00 :   ffff8000104bbdf8:       bfi     w0, w2, #8, #24
    0.00 :   ffff8000104bbdfc:       str     w0, [sp, #128]
    0.00 :   ffff8000104bbe00:       ldrb    w0, [x24]
    0.00 :   ffff8000104bbe04:       b       ffff8000104bb8b8 <vsnprintf+0x88>
         : 2647             vsnprintf():
         : 2803             fmt++;
    0.00 :   ffff8000104bbe08:       tbnz    w22, #31, ffff8000104bbeb0 <vsnprintf+0x680>
    0.00 :   ffff8000104bbe0c:       mov     x0, x20
    0.00 :   ffff8000104bbe10:       add     x1, x20, #0xb
    0.00 :   ffff8000104bbe14:       and     x20, x1, #0xfffffffffffffff8
    0.00 :   ffff8000104bbe18:       ldrsb   x2, [x0]
         : 2804             break;
    0.00 :   ffff8000104bbe1c:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2815             * checking, but there is no safe or sane way
    0.00 :   ffff8000104bbe20:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbe24:       cmp     w1, #0x0
    0.00 :   ffff8000104bbe28:       b.le    ffff8000104bbf08 <vsnprintf+0x6d8>
    0.00 :   ffff8000104bbe2c:       mov     x0, x20
    0.00 :   ffff8000104bbe30:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbe34:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbe38:       mov     w22, w1
    0.00 :   ffff8000104bbe3c:       ldr     w2, [x0]
    0.00 :   ffff8000104bbe40:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2806             case FORMAT_TYPE_PERCENT_CHAR:
    0.00 :   ffff8000104bbe44:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbe48:       cmp     w1, #0x0
    0.00 :   ffff8000104bbe4c:       b.le    ffff8000104bbf30 <vsnprintf+0x700>
    0.00 :   ffff8000104bbe50:       mov     x0, x20
    0.00 :   ffff8000104bbe54:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbe58:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbe5c:       mov     w22, w1
    0.00 :   ffff8000104bbe60:       ldrh    w2, [x0]
         : 2807             if (str < end)
    0.00 :   ffff8000104bbe64:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2809             ++str;
    0.00 :   ffff8000104bbe68:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbe6c:       cmp     w1, #0x0
    0.00 :   ffff8000104bbe70:       b.le    ffff8000104bbf58 <vsnprintf+0x728>
    0.00 :   ffff8000104bbe74:       mov     x0, x20
    0.00 :   ffff8000104bbe78:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbe7c:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbe80:       mov     w22, w1
    0.00 :   ffff8000104bbe84:       ldrsh   x2, [x0]
         : 2810             break;
    0.00 :   ffff8000104bbe88:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2812             case FORMAT_TYPE_INVALID:
    0.00 :   ffff8000104bbe8c:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbe90:       cmp     w1, #0x0
    0.00 :   ffff8000104bbe94:       b.le    ffff8000104bbf1c <vsnprintf+0x6ec>
    0.00 :   ffff8000104bbe98:       mov     x0, x20
    0.00 :   ffff8000104bbe9c:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbea0:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbea4:       mov     w22, w1
    0.00 :   ffff8000104bbea8:       ldrsw   x2, [x0]
         : 2813             /*
    0.00 :   ffff8000104bbeac:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2803             fmt++;
    0.00 :   ffff8000104bbeb0:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbeb4:       cmp     w1, #0x0
    0.00 :   ffff8000104bbeb8:       b.le    ffff8000104bbf44 <vsnprintf+0x714>
    0.00 :   ffff8000104bbebc:       mov     x0, x20
    0.00 :   ffff8000104bbec0:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbec4:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbec8:       mov     w22, w1
    0.00 :   ffff8000104bbecc:       ldrsb   x2, [x0]
         : 2804             break;
    0.00 :   ffff8000104bbed0:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2800             str = pointer(fmt, str, end, va_arg(args, void *),
    0.00 :   ffff8000104bbed4:       add     w1, w22, #0x8
    0.00 :   ffff8000104bbed8:       cmp     w1, #0x0
    0.00 :   ffff8000104bbedc:       b.le    ffff8000104bbf6c <vsnprintf+0x73c>
    0.00 :   ffff8000104bbee0:       mov     x0, x20
    0.00 :   ffff8000104bbee4:       add     x2, x20, #0xb
    0.00 :   ffff8000104bbee8:       and     x20, x2, #0xfffffffffffffff8
    0.00 :   ffff8000104bbeec:       mov     w22, w1
    0.00 :   ffff8000104bbef0:       ldrb    w2, [x0]
         : 2801             spec);
    0.00 :   ffff8000104bbef4:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2797             break;
    0.00 :   ffff8000104bbef8:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbefc:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf00:       mov     w22, w1
    0.00 :   ffff8000104bbf04:       b       ffff8000104bb998 <vsnprintf+0x168>
         : 2815             * checking, but there is no safe or sane way
    0.00 :   ffff8000104bbf08:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbf0c:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf10:       mov     w22, w1
    0.00 :   ffff8000104bbf14:       ldr     w2, [x0]
    0.00 :   ffff8000104bbf18:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2812             case FORMAT_TYPE_INVALID:
    0.00 :   ffff8000104bbf1c:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbf20:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf24:       mov     w22, w1
    0.00 :   ffff8000104bbf28:       ldrsw   x2, [x0]
         : 2813             /*
    0.00 :   ffff8000104bbf2c:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2806             case FORMAT_TYPE_PERCENT_CHAR:
    0.00 :   ffff8000104bbf30:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbf34:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf38:       mov     w22, w1
    0.00 :   ffff8000104bbf3c:       ldrh    w2, [x0]
         : 2807             if (str < end)
    0.00 :   ffff8000104bbf40:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2803             fmt++;
    0.00 :   ffff8000104bbf44:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbf48:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf4c:       mov     w22, w1
    0.00 :   ffff8000104bbf50:       ldrsb   x2, [x0]
         : 2804             break;
    0.00 :   ffff8000104bbf54:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2809             ++str;
    0.00 :   ffff8000104bbf58:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbf5c:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf60:       mov     w22, w1
    0.00 :   ffff8000104bbf64:       ldrsh   x2, [x0]
         : 2810             break;
    0.00 :   ffff8000104bbf68:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2800             str = pointer(fmt, str, end, va_arg(args, void *),
    0.00 :   ffff8000104bbf6c:       ldr     x0, [sp, #112]
    0.00 :   ffff8000104bbf70:       add     x0, x0, w22, sxtw
    0.00 :   ffff8000104bbf74:       mov     w22, w1
    0.00 :   ffff8000104bbf78:       ldrb    w2, [x0]
         : 2801             spec);
    0.00 :   ffff8000104bbf7c:       b       ffff8000104bb99c <vsnprintf+0x16c>
         : 2803             set_field_width():
         : 2640             case 'u':
    0.00 :   ffff8000104bbf80:       mov     w4, #0x1                        // #1
    0.00 :   ffff8000104bbf84:       mov     w1, w27
    0.00 :   ffff8000104bbf88:       adrp    x0, ffff800011447000 <kallsyms_token_index+0x3c7a0>
    0.00 :   ffff8000104bbf8c:       add     x0, x0, #0xb68
    0.00 :   ffff8000104bbf90:       strb    w4, [x3, #1]
    0.00 :   ffff8000104bbf94:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff8000104bbf98:       brk     #0x800
    0.00 :   ffff8000104bbf9c:       ldr     w0, [sp, #128]
    0.00 :   ffff8000104bbfa0:       b       ffff8000104bbddc <vsnprintf+0x5ac>
         : 2650             set_precision():
         : 2649             fallthrough;
    0.00 :   ffff8000104bbfa4:       mov     w4, #0x1                        // #1
    0.00 :   ffff8000104bbfa8:       mov     w1, w27
    0.00 :   ffff8000104bbfac:       adrp    x0, ffff800011447000 <kallsyms_token_index+0x3c7a0>
    0.00 :   ffff8000104bbfb0:       add     x0, x0, #0xb88
    0.00 :   ffff8000104bbfb4:       strb    w4, [x3, #2]
    0.00 :   ffff8000104bbfb8:       bl      ffff800010e18038 <__warn_printk>
    0.00 :   ffff8000104bbfbc:       brk     #0x800
    0.00 :   ffff8000104bbfc0:       b       ffff8000104bba94 <vsnprintf+0x264>
    0.00 :   ffff8000104bbfc4:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000104bbfc8:       stp     x27, x28, [sp, #80]
         : 2660             vsnprintf():
         : 2833             break;
    0.00 :   ffff8000104bbfcc:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010979088 <hclge_service_task>:
         : 6                hclge_service_task():
         : 4323             /* start from vport 1 for PF is always alive */
         : 4324             for (i = 1; i < hdev->num_alloc_vport; i++) {
         : 4325             struct hclge_vport *vport = &hdev->vport[i];
         :
         : 4327             if (time_after(jiffies, vport->last_active_jiffies + 8 * HZ))
         : 4328             clear_bit(HCLGE_VPORT_STATE_ALIVE, &vport->state);
    0.00 :   ffff800010979088:       paciasp
    0.00 :   ffff80001097908c:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff800010979090:       mov     x29, sp
    0.00 :   ffff800010979094:       stp     x19, x20, [sp, #16]
         :
         : 4326             /* If vf is not alive, set to default value */
    0.00 :   ffff800010979098:       sub     x19, x0, #0x578
         : 4323             clear_bit(HCLGE_VPORT_STATE_ALIVE, &vport->state);
    0.00 :   ffff80001097909c:       mov     x20, x0
    0.00 :   ffff8000109790a0:       stp     x21, x22, [sp, #32]
         : 4326             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000109790a4:       sub     x22, x0, #0x8, lsl #12
         : 113              hclge_service_task():
         : 4327             if (!test_bit(HCLGE_VPORT_STATE_ALIVE, &vport->state))
         : 4328             vport->mps = HCLGE_MAC_DEFAULT_FRAME;
    0.00 :   ffff8000109790a8:       mov     x0, x19
         : 4323             clear_bit(HCLGE_VPORT_STATE_ALIVE, &vport->state);
    0.00 :   ffff8000109790ac:       stp     x25, x26, [sp, #64]
         : 4327             vport->mps = HCLGE_MAC_DEFAULT_FRAME;
    0.00 :   ffff8000109790b0:       bl      ffff800010978b30 <hclge_reset_service_task>
         : 4328             }
    0.00 :   ffff8000109790b4:       mov     x0, x19
    0.00 :   ffff8000109790b8:       bl      ffff800010971a00 <hclge_mailbox_service_task>
         : 4331             hclge_periodic_service_task():
         : 4277             if (msix_sts_reg & HCLGE_VECTOR0_REG_MSIX_MASK) {
    0.00 :   ffff8000109790bc:       mov     x0, #0xfa                       // #250
    0.00 :   ffff8000109790c0:       bl      ffff80001010dbf8 <round_jiffies_relative>
         : 4280             test_bit():
    0.00 :   ffff8000109790c4:       ldr     x25, [x22, #32368]
    0.00 :   ffff8000109790c8:       ubfx    w25, w25, #15, #1
         : 108              hclge_periodic_service_task():
         : 4279             (hdev, &hdev->default_reset_request))
    0.00 :   ffff8000109790cc:       cbz     w25, ffff8000109790f8 <hclge_service_task+0x70>
         : 4281             hclge_service_task():
         :
         : 4336             static void hclge_periodic_service_task(struct hclge_dev *hdev)
         : 4337             {
         : 4338             unsigned long delta = round_jiffies_relative(HZ);
         :
         : 4340             if (test_bit(HCLGE_STATE_RST_FAIL, &hdev->state))
    0.00 :   ffff8000109790d0:       mov     x0, x19
    0.00 :   ffff8000109790d4:       bl      ffff800010978b30 <hclge_reset_service_task>
         : 4336             return;
    0.00 :   ffff8000109790d8:       mov     x0, x19
    0.00 :   ffff8000109790dc:       bl      ffff800010971a00 <hclge_mailbox_service_task>
         :
    0.00 :   ffff8000109790e0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000109790e4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000109790e8:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000109790ec:       ldp     x29, x30, [sp], #112
    0.00 :   ffff8000109790f0:       autiasp
    0.00 :   ffff8000109790f4:       ret
         : 4344             hclge_periodic_service_task():
         :
    0.00 :   ffff8000109790f8:       stp     x23, x24, [sp, #48]
         : 4287             hclge_sync_mac_table():
         : 8916             break;
         : 8917             case HCLGE_MAC_TO_ADD:
         : 8918             new_node = kzalloc(sizeof(*new_node), GFP_ATOMIC);
         : 8919             if (!new_node)
         : 8920             goto stop_traverse;
         : 8921             ether_addr_copy(new_node->mac_addr, mac_node->mac_addr);
    0.00 :   ffff8000109790fc:       sub     x23, x20, #0x2, lsl #12
    0.00 :   ffff800010979100:       mov     x24, x0
         : 8924             hclge_periodic_service_task():
         :
    0.00 :   ffff800010979104:       mov     x0, x19
    0.00 :   ffff800010979108:       stp     x27, x28, [sp, #80]
    0.00 :   ffff80001097910c:       bl      ffff800010972810 <hclge_update_link_status>
         : 4289             hclge_sync_mac_table():
         : 8916             ether_addr_copy(new_node->mac_addr, mac_node->mac_addr);
    0.00 :   ffff800010979110:       ldrh    w0, [x23, #7922]
    0.00 :   ffff800010979114:       cbz     w0, ffff8000109796b4 <hclge_service_task+0x62c>
    0.00 :   ffff800010979118:       ldr     x0, [x20, #104]
         : 8920             hclge_need_sync_mac_table():
         : 8903             &vport->uc_mac_list : &vport->mc_mac_list;
    0.00 :   ffff80001097911c:       mov     x27, #0x668                     // #1640
         : 8905             hclge_sync_mac_table():
         : 8916             ether_addr_copy(new_node->mac_addr, mac_node->mac_addr);
    0.00 :   ffff800010979120:       mov     x28, #0x0                       // #0
         : 8918             hclge_need_sync_mac_table():
         : 8903             &vport->uc_mac_list : &vport->mc_mac_list;
    0.00 :   ffff800010979124:       movk    x27, #0x2, lsl #16
         : 8905             __ll_sc_atomic64_fetch_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff800010979128:       mov     x26, #0x2                       // #2
    0.00 :   ffff80001097912c:       nop
         : 237              hclge_sync_mac_table():
         : 8917             new_node->state = mac_node->state;
    0.00 :   ffff800010979130:       add     x21, x0, x28
         : 8919             hclge_need_sync_mac_table():
         : 8903             &vport->uc_mac_list : &vport->mc_mac_list;
    0.00 :   ffff800010979134:       ldrh    w3, [x21, #622]
    0.00 :   ffff800010979138:       ldr     x2, [x21, #624]
         : 8906             test_bit():
    0.00 :   ffff80001097913c:       ubfx    x1, x3, #6, #10
         : 107              hclge_need_sync_mac_table():
    0.00 :   ffff800010979140:       add     x2, x2, x27
         : 8904             test_bit():
    0.00 :   ffff800010979144:       ldr     x1, [x2, x1, lsl #3]
    0.00 :   ffff800010979148:       lsr     x1, x1, x3
         : 108              hclge_need_sync_mac_table():
    0.00 :   ffff80001097914c:       tbnz    w1, #0, ffff800010979190 <hclge_service_task+0x108>
         : 8904             test_and_clear_bit():
         : 51               {
         : 52               long old;
         : 53               unsigned long mask = BIT_MASK(nr);
         :
         : 55               p += BIT_WORD(nr);
         : 56               if (!(READ_ONCE(*p) & mask))
    0.00 :   ffff800010979150:       ldr     x1, [x21, #1032]
         : 58               hclge_need_sync_mac_table():
         :
    0.00 :   ffff800010979154:       add     x2, x21, #0x408
         : 8908             test_and_clear_bit():
    0.00 :   ffff800010979158:       tbz     w1, #1, ffff800010979190 <hclge_service_task+0x108>
         : 52               arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001097915c:       b       ffff800010979370 <hclge_service_task+0x2e8>
    0.00 :   ffff800010979160:       b       ffff800010979370 <hclge_service_task+0x2e8>
         : 46               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OP(_relaxed,   , op, asm_op)                     \
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff800010979164:       mov     x0, x26
    0.00 :   ffff800010979168:       ldclral x0, x0, [x2]
    0.00 :   ffff80001097916c:       mov     x2, x0
         : 211              hclge_sync_mac_table():
         : 8922             list_add_tail(&new_node->node, &tmp_add_list);
         : 8923             break;
         : 8924             default:
         : 8925             break;
         : 8926             }
    0.00 :   ffff800010979170:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010979174:       mov     x0, x21
         : 8929             hclge_need_sync_mac_table():
         :
    0.00 :   ffff800010979178:       tbz     w2, #1, ffff80001097918c <hclge_service_task+0x104>
         : 8908             hclge_sync_mac_table():
         : 8922             }
    0.00 :   ffff80001097917c:       bl      ffff800010970880 <hclge_sync_vport_mac_table>
         : 8923             }
    0.00 :   ffff800010979180:       mov     x0, x21
    0.00 :   ffff800010979184:       mov     w1, #0x1                        // #1
    0.00 :   ffff800010979188:       bl      ffff800010970880 <hclge_sync_vport_mac_table>
    0.00 :   ffff80001097918c:       ldr     x0, [x19, #1504]
         : 8916             ether_addr_copy(new_node->mac_addr, mac_node->mac_addr);
    0.00 :   ffff800010979190:       add     w25, w25, #0x1
    0.00 :   ffff800010979194:       ldrh    w1, [x23, #7922]
    0.00 :   ffff800010979198:       add     x28, x28, #0x470
    0.00 :   ffff80001097919c:       cmp     w25, w1
    0.00 :   ffff8000109791a0:       b.lt    ffff800010979130 <hclge_service_task+0xa8>  // b.tstop
         : 8922             hclge_sync_promisc_mode():
         : 12389            kfree(desc_src);
         : 12390            out:
         : 12391            kfree(bd_num_list);
         : 12392            return ret;
         : 12393            }
         :
    0.00 :   ffff8000109791a4:       ldrb    w2, [x0, #1081]
    0.00 :   ffff8000109791a8:       add     x26, x19, #0x3e8
    0.00 :   ffff8000109791ac:       ldrb    w1, [x0, #1080]
    0.00 :   ffff8000109791b0:       cmp     w2, w1
    0.00 :   ffff8000109791b4:       b.eq    ffff8000109791d0 <hclge_service_task+0x148>  // b.none
         : 12400            arch_static_branch_jump():
    0.00 :   ffff8000109791b8:       b       ffff80001097952c <hclge_service_task+0x4a4>
    0.00 :   ffff8000109791bc:       b       ffff80001097952c <hclge_service_task+0x4a4>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff8000109791c0:       mov     x1, #0x4000                     // #16384
    0.00 :   ffff8000109791c4:       stset   x1, [x26]
         : 180              hclge_sync_promisc_mode():
         : 12391            static int hclge_fetch_pf_reg(struct hclge_dev *hdev, void *data,
         : 12392            struct hnae3_knic_private_info *kinfo)
    0.00 :   ffff8000109791c8:       ldrb    w1, [x0, #1080]
    0.00 :   ffff8000109791cc:       strb    w1, [x0, #1081]
         : 12395            test_bit():
    0.00 :   ffff8000109791d0:       ldr     x1, [x22, #32368]
         : 107              hclge_sync_promisc_mode():
         : 12394            {
         : 12395            #define HCLGE_RING_REG_OFFSET           0x200
         : 12396            #define HCLGE_RING_INT_REG_OFFSET       0x4
    0.00 :   ffff8000109791d4:       tst     w1, #0x4000
    0.00 :   ffff8000109791d8:       b.ne    ffff800010979548 <hclge_service_task+0x4c0>  // b.any
         : 12399            test_and_clear_bit():
    0.00 :   ffff8000109791dc:       ldr     x0, [x22, #32368]
    0.00 :   ffff8000109791e0:       tbz     w0, #17, ffff800010979220 <hclge_service_task+0x198>
         : 53               arch_static_branch_jump():
    0.00 :   ffff8000109791e4:       b       ffff80001097951c <hclge_service_task+0x494>
    0.00 :   ffff8000109791e8:       b       ffff80001097951c <hclge_service_task+0x494>
         : 40               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff8000109791ec:       mov     x0, #0x20000                    // #131072
    0.00 :   ffff8000109791f0:       add     x1, x19, #0x3e8
    0.00 :   ffff8000109791f4:       ldclral x0, x0, [x1]
         : 206              hclge_sync_fd_table():
         : 7473             return -EINVAL;
    0.00 :   ffff8000109791f8:       tbz     w0, #17, ffff800010979220 <hclge_service_task+0x198>
         : 7475             hclge_clear_fd_rules_in_list():
         : 6638             rule->unused_tuple = unused;
    0.00 :   ffff8000109791fc:       ldr     x0, [x19, #8]
         : 6640             test_bit():
    0.00 :   ffff800010979200:       ldr     x0, [x0, #80]
         : 107              hclge_clear_fd_rules_in_list():
    0.00 :   ffff800010979204:       tbz     w0, #0, ffff800010979220 <hclge_service_task+0x198>
         : 6639             hclge_sync_fd_table():
         : 7474             }
    0.00 :   ffff800010979208:       add     x1, x19, #0x20, lsl #12
         : 7476             hclge_clear_fd_rules_in_list():
    0.00 :   ffff80001097920c:       mov     x0, x19
         : 7475             hclge_sync_fd_table():
    0.00 :   ffff800010979210:       ldr     w1, [x1, #2280]
    0.00 :   ffff800010979214:       cmp     w1, #0x1
         : 7476             hclge_clear_fd_rules_in_list():
    0.00 :   ffff800010979218:       cset    w1, eq  // eq = none
    0.00 :   ffff80001097921c:       bl      ffff80001096fcf0 <hclge_clear_fd_rules_in_list.part.74>
         : 7476             hclge_sync_fd_table():
         : 7479             spin_unlock_bh(&hdev->fd_rule_lock);
    0.00 :   ffff800010979220:       mov     x0, x19
    0.00 :   ffff800010979224:       mov     w1, #0x0                        // #0
    0.00 :   ffff800010979228:       bl      ffff8000109717e8 <hclge_sync_fd_user_def_cfg>
         : 7483             test_and_clear_bit():
    0.00 :   ffff80001097922c:       ldr     x0, [x22, #32368]
    0.00 :   ffff800010979230:       tbz     w0, #16, ffff8000109792c4 <hclge_service_task+0x23c>
         : 53               arch_static_branch_jump():
    0.00 :   ffff800010979234:       b       ffff80001097950c <hclge_service_task+0x484>
    0.00 :   ffff800010979238:       b       ffff80001097950c <hclge_service_task+0x484>
         : 40               __lse_atomic64_fetch_andnot():
    0.00 :   ffff80001097923c:       mov     x0, #0x10000                    // #65536
    0.00 :   ffff800010979240:       add     x1, x19, #0x3e8
    0.00 :   ffff800010979244:       ldclral x0, x0, [x1]
         : 205              hclge_sync_fd_list():
         :
    0.00 :   ffff800010979248:       tbz     w0, #16, ffff8000109792c4 <hclge_service_task+0x23c>
         : 7440             spin_lock_bh():
         :
         : 360              #endif
         :
         : 362              static __always_inline void spin_lock(spinlock_t *lock)
         : 363              {
         : 364              raw_spin_lock(&lock->rlock);
    0.00 :   ffff80001097924c:       add     x28, x20, #0x20, lsl #12
         : 366              hclge_sync_fd_list():
         : 7449             struct hclge_fd_rule *rule;
    0.00 :   ffff800010979250:       mov     w27, #0x2                       // #2
         : 7451             spin_lock_bh():
    0.00 :   ffff800010979254:       add     x28, x28, #0x158
    0.00 :   ffff800010979258:       mov     x0, x28
    0.00 :   ffff80001097925c:       bl      ffff800010e34ca0 <_raw_spin_lock_bh>
         : 362              hclge_sync_fd_list():
         : 7443             return ret;
    0.00 :   ffff800010979260:       add     x0, x20, #0x20, lsl #12
    0.00 :   ffff800010979264:       ldr     x21, [x0, #336]
    0.00 :   ffff800010979268:       cbz     x21, ffff8000109792bc <hclge_service_task+0x234>
    0.00 :   ffff80001097926c:       nop
         : 7444             }
    0.00 :   ffff800010979270:       ldr     w1, [x21, #180]
         : 7443             return ret;
    0.00 :   ffff800010979274:       ldr     x25, [x21]
         : 7444             }
    0.00 :   ffff800010979278:       cmp     w1, #0x1
    0.00 :   ffff80001097927c:       cbz     w1, ffff800010979684 <hclge_service_task+0x5fc>
    0.00 :   ffff800010979280:       b.ne    ffff8000109792b4 <hclge_service_task+0x22c>  // b.any
         : 7452             hlist_for_each_entry_safe(rule, node, &hdev->fd_rule_list, rule_node) {
    0.00 :   ffff800010979284:       ldrh    w2, [x21, #172]
    0.00 :   ffff800010979288:       mov     w4, #0x0                        // #0
    0.00 :   ffff80001097928c:       mov     x3, #0x0                        // #0
    0.00 :   ffff800010979290:       mov     x0, x19
    0.00 :   ffff800010979294:       bl      ffff80001096eee0 <hclge_fd_tcam_config.constprop.111>
         : 7454             return rule;
    0.00 :   ffff800010979298:       cbnz    w0, ffff80001097969c <hclge_service_task+0x614>
         :
    0.00 :   ffff80001097929c:       ldrh    w1, [x21, #172]
    0.00 :   ffff8000109792a0:       mov     x0, x19
    0.00 :   ffff8000109792a4:       bl      ffff800010971248 <hclge_fd_dec_rule_cnt>
         : 7457             return NULL;
    0.00 :   ffff8000109792a8:       mov     x1, x21
    0.00 :   ffff8000109792ac:       mov     x0, x19
    0.00 :   ffff8000109792b0:       bl      ffff80001096a328 <hclge_fd_free_node>
         : 7443             return ret;
    0.00 :   ffff8000109792b4:       mov     x21, x25
    0.00 :   ffff8000109792b8:       cbnz    x25, ffff800010979270 <hclge_service_task+0x1e8>
         : 7446             spin_unlock_bh():
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
         : 400              } while (0)
         :
         : 402              static __always_inline void spin_unlock(spinlock_t *lock)
         : 403              {
         : 404              raw_spin_unlock(&lock->rlock);
    0.00 :   ffff8000109792bc:       mov     x0, x28
    0.00 :   ffff8000109792c0:       bl      ffff800010e34af0 <_raw_spin_unlock_bh>
         : 407              hclge_periodic_service_task():
         : 4290             {
  100.00 :   ffff8000109792c4:       adrp    x25, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000109792c8:       add     x1, x19, #0x20, lsl #12
    0.00 :   ffff8000109792cc:       ldr     x0, [x25, #2432]
    0.00 :   ffff8000109792d0:       ldr     x21, [x1, #1760]
    0.00 :   ffff8000109792d4:       sub     x0, x0, #0xfa
    0.00 :   ffff8000109792d8:       cmp     x0, x21
    0.00 :   ffff8000109792dc:       b.mi    ffff8000109794e0 <hclge_service_task+0x458>  // b.first
         :
    0.00 :   ffff8000109792e0:       add     x1, x19, #0x20, lsl #12
    0.00 :   ffff8000109792e4:       ldr     x0, [x1, #1752]
    0.00 :   ffff8000109792e8:       add     x0, x0, #0x1
    0.00 :   ffff8000109792ec:       str     x0, [x1, #1752]
         : 4304             hclge_update_vport_alive():
         : 4263             hclge_handle_error_info_log(ae_dev);
    0.00 :   ffff8000109792f0:       ldrh    w0, [x23, #7922]
    0.00 :   ffff8000109792f4:       cmp     w0, #0x1
    0.00 :   ffff8000109792f8:       b.ls    ffff80001097938c <hclge_service_task+0x304>  // b.plast
    0.00 :   ffff8000109792fc:       adrp    x5, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff800010979300:       mov     x3, #0x470                      // #1136
    0.00 :   ffff800010979304:       add     x5, x5, #0x980
    0.00 :   ffff800010979308:       mov     w2, #0x1                        // #1
         :
    0.00 :   ffff80001097930c:       mov     x8, #0x7d0                      // #2000
         : 4268             __ll_sc_atomic64_andnot():
    0.00 :   ffff800010979310:       mov     x4, #0x1                        // #1
         : 230              hclge_update_vport_alive():
         : 4271             {
    0.00 :   ffff800010979314:       mov     w7, #0x5f6                      // #1526
    0.00 :   ffff800010979318:       b       ffff80001097933c <hclge_service_task+0x2b4>
         : 4274             test_bit():
    0.00 :   ffff80001097931c:       ldr     x1, [x0, #1032]
         : 107              hclge_update_vport_alive():
         : 4263             hclge_handle_error_info_log(ae_dev);
    0.00 :   ffff800010979320:       add     w2, w2, #0x1
    0.00 :   ffff800010979324:       add     x3, x3, #0x470
         : 4270             static void hclge_misc_err_recovery(struct hclge_dev *hdev)
    0.00 :   ffff800010979328:       tbnz    w1, #0, ffff800010979330 <hclge_service_task+0x2a8>
         : 4271             {
    0.00 :   ffff80001097932c:       str     w7, [x0, #1048]
         : 4263             hclge_handle_error_info_log(ae_dev);
    0.00 :   ffff800010979330:       ldrh    w0, [x23, #7922]
    0.00 :   ffff800010979334:       cmp     w2, w0
    0.00 :   ffff800010979338:       b.ge    ffff80001097938c <hclge_service_task+0x304>  // b.tcont
         : 4264             hclge_handle_mac_tnl(hdev);
    0.00 :   ffff80001097933c:       ldr     x0, [x20, #104]
         :
    0.00 :   ffff800010979340:       ldr     x1, [x5]
         : 4264             hclge_handle_mac_tnl(hdev);
    0.00 :   ffff800010979344:       add     x0, x0, x3
         :
    0.00 :   ffff800010979348:       sub     x1, x8, x1
    0.00 :   ffff80001097934c:       ldr     x6, [x0, #1040]
    0.00 :   ffff800010979350:       cmn     x1, x6
    0.00 :   ffff800010979354:       b.pl    ffff80001097931c <hclge_service_task+0x294>  // b.nfrst
         : 4267             hclge_handle_err_reset_request(hdev);
    0.00 :   ffff800010979358:       add     x6, x0, #0x408
         : 4269             arch_static_branch_jump():
    0.00 :   ffff80001097935c:       b       ffff800010979380 <hclge_service_task+0x2f8>
    0.00 :   ffff800010979360:       b       ffff800010979380 <hclge_service_task+0x2f8>
         : 40               __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff800010979364:       mov     x1, x4
    0.00 :   ffff800010979368:       stclr   x1, [x6]
    0.00 :   ffff80001097936c:       b       ffff80001097931c <hclge_service_task+0x294>
         : 180              __ll_sc_atomic64_fetch_andnot():
    0.00 :   ffff800010979370:       add     x3, x21, #0x408
    0.00 :   ffff800010979374:       b       ffff80001097c050 <hclge_get_regs_len+0x8d0>
    0.00 :   ffff800010979378:       mov     x2, x0
    0.00 :   ffff80001097937c:       b       ffff800010979170 <hclge_service_task+0xe8>
         : 233              __ll_sc_atomic64_andnot():
    0.00 :   ffff800010979380:       add     x9, x0, #0x408
    0.00 :   ffff800010979384:       b       ffff80001097c06c <hclge_get_regs_len+0x8ec>
    0.00 :   ffff800010979388:       b       ffff80001097931c <hclge_service_task+0x294>
         : 232              test_bit():
    0.00 :   ffff80001097938c:       ldr     x21, [x22, #32368]
    0.00 :   ffff800010979390:       ubfx    w21, w21, #1, #1
         : 108              hclge_periodic_service_task():
         : 4302             if (!test_and_clear_bit(HCLGE_STATE_RST_SERVICE_SCHED, &hdev->state))
    0.00 :   ffff800010979394:       cbnz    w21, ffff8000109794b4 <hclge_service_task+0x42c>
         :
    0.00 :   ffff800010979398:       add     x1, x19, #0x20, lsl #12
    0.00 :   ffff80001097939c:       mov     x0, #0x3a07                     // #14855
    0.00 :   ffff8000109793a0:       movk    x0, #0xa06d, lsl #16
    0.00 :   ffff8000109793a4:       movk    x0, #0x6d3, lsl #32
    0.00 :   ffff8000109793a8:       ldr     x2, [x1, #1752]
    0.00 :   ffff8000109793ac:       movk    x0, #0x6d3a, lsl #48
    0.00 :   ffff8000109793b0:       umulh   x0, x2, x0
    0.00 :   ffff8000109793b4:       lsr     x0, x0, #7
    0.00 :   ffff8000109793b8:       add     x0, x0, x0, lsl #2
    0.00 :   ffff8000109793bc:       lsl     x1, x0, #4
    0.00 :   ffff8000109793c0:       sub     x0, x1, x0
    0.00 :   ffff8000109793c4:       cmp     x2, x0, lsl #2
    0.00 :   ffff8000109793c8:       b.eq    ffff8000109795a4 <hclge_service_task+0x51c>  // b.none
         : 4310             clear_bit(HCLGE_STATE_RST_HANDLING, &hdev->state);
    0.00 :   ffff8000109793cc:       mov     x0, x19
    0.00 :   ffff8000109793d0:       bl      ffff8000109741d8 <hclge_update_port_info>
         : 4313             hclge_sync_vlan_filter():
         : 10294            if (ret) {
    0.00 :   ffff8000109793d4:       ldrh    w0, [x19, #1130]
         : 10296            clear_bit():
         : 23               atomic_long_andnot(BIT_MASK(nr), (atomic_long_t *)p);
    0.00 :   ffff8000109793d8:       mov     x27, #0x1                       // #1
         : 25               hclge_sync_vlan_filter():
    0.00 :   ffff8000109793dc:       str     xzr, [sp, #96]
    0.00 :   ffff8000109793e0:       str     wzr, [sp, #108]
    0.00 :   ffff8000109793e4:       cbz     w0, ffff800010979490 <hclge_service_task+0x408>
         : 10295            dev_err(&hdev->pdev->dev,
    0.00 :   ffff8000109793e8:       ldr     x0, [sp, #96]
         : 10297            find_first_bit():
         : 117              unsigned long val = *addr & GENMASK(size - 1, 0);
         :
         : 119              return val ? __ffs(val) : size;
         : 120              }
         :
         : 122              return _find_first_bit(addr, size);
    0.00 :   ffff8000109793ec:       mov     x1, #0x1000                     // #4096
         : 124              hclge_sync_vlan_filter():
    0.00 :   ffff8000109793f0:       ldr     x22, [x19, #1504]
    0.00 :   ffff8000109793f4:       add     x22, x22, x0
         : 10297            vport->vport_id, old_vlan_info->vlan_tag, ret);
    0.00 :   ffff8000109793f8:       add     x23, x22, #0x50
         : 10299            find_first_bit():
    0.00 :   ffff8000109793fc:       mov     x0, x23
    0.00 :   ffff800010979400:       b       ffff80001097945c <hclge_service_task+0x3d4>
         : 119              hclge_sync_vlan_filter():
         :
    0.00 :   ffff800010979404:       ldrh    w1, [x22, #622]
    0.00 :   ffff800010979408:       mov     w3, #0x1                        // #1
    0.00 :   ffff80001097940c:       mov     w2, w28
    0.00 :   ffff800010979410:       mov     x0, x19
    0.00 :   ffff800010979414:       bl      ffff800010972b90 <hclge_set_vlan_filter_hw.isra.73>
         :
    0.00 :   ffff800010979418:       cmp     w0, #0x0
         : 10305            clear_bit():
         : 22               p += BIT_WORD(nr);
    0.00 :   ffff80001097941c:       ubfx    x1, x28, #6, #10
         : 24               hclge_sync_vlan_filter():
    0.00 :   ffff800010979420:       ccmn    w0, #0x16, #0x4, ne  // ne = any
    0.00 :   ffff800010979424:       b.ne    ffff800010979490 <hclge_service_task+0x408>  // b.any
         : 10305            clear_bit():
    0.00 :   ffff800010979428:       add     x0, x23, x1, lsl #3
         : 23               atomic_long_andnot(BIT_MASK(nr), (atomic_long_t *)p);
    0.00 :   ffff80001097942c:       lsl     x1, x27, x28
         : 25               arch_static_branch_jump():
    0.00 :   ffff800010979430:       b       ffff8000109794d8 <hclge_service_task+0x450>
    0.00 :   ffff800010979434:       b       ffff8000109794d8 <hclge_service_task+0x450>
         : 40               __lse_atomic64_andnot():
    0.00 :   ffff800010979438:       stclr   x1, [x0]
         : 177              hclge_sync_vlan_filter():
         : 10307            return ret;
    0.00 :   ffff80001097943c:       mov     w1, w28
    0.00 :   ffff800010979440:       mov     x0, x22
         : 10309            out:
    0.00 :   ffff800010979444:       add     w21, w21, #0x1
         : 10307            return ret;
    0.00 :   ffff800010979448:       bl      ffff80001096eb78 <hclge_rm_vport_vlan_table.constprop.103>
         : 10309            find_first_bit():
    0.00 :   ffff80001097944c:       mov     x1, #0x1000                     // #4096
    0.00 :   ffff800010979450:       mov     x0, x23
         : 119              hclge_sync_vlan_filter():
         : 10310            vport->port_base_vlan_cfg.state = state;
    0.00 :   ffff800010979454:       cmp     w21, #0x3b
    0.00 :   ffff800010979458:       b.gt    ffff800010979490 <hclge_service_task+0x408>
         : 10313            find_first_bit():
    0.00 :   ffff80001097945c:       bl      ffff80001046ced8 <_find_first_bit>
         : 118              hclge_sync_vlan_filter():
         : 10297            vport->vport_id, old_vlan_info->vlan_tag, ret);
    0.00 :   ffff800010979460:       and     w28, w0, #0xffff
         : 10299            }
    0.00 :   ffff800010979464:       cmp     w28, #0x1, lsl #12
    0.00 :   ffff800010979468:       b.ne    ffff800010979404 <hclge_service_task+0x37c>  // b.any
    0.00 :   ffff80001097946c:       ldr     x2, [sp, #96]
         : 10294            if (ret) {
    0.00 :   ffff800010979470:       ldr     w1, [sp, #108]
    0.00 :   ffff800010979474:       ldrh    w0, [x19, #1130]
    0.00 :   ffff800010979478:       add     x2, x2, #0x470
    0.00 :   ffff80001097947c:       add     w1, w1, #0x1
    0.00 :   ffff800010979480:       str     x2, [sp, #96]
    0.00 :   ffff800010979484:       str     w1, [sp, #108]
    0.00 :   ffff800010979488:       cmp     w1, w0
    0.00 :   ffff80001097948c:       b.lt    ffff8000109793e8 <hclge_service_task+0x360>  // b.tstop
         : 10303            hclge_periodic_service_task():
         :
    0.00 :   ffff800010979490:       add     x21, x19, #0x20, lsl #12
    0.00 :   ffff800010979494:       mov     x0, #0xcccccccccccccccc         // #-3689348814741910324
    0.00 :   ffff800010979498:       movk    x0, #0xcccd
    0.00 :   ffff80001097949c:       ldr     x1, [x21, #1752]
    0.00 :   ffff8000109794a0:       umulh   x0, x1, x0
    0.00 :   ffff8000109794a4:       lsr     x0, x0, #2
    0.00 :   ffff8000109794a8:       add     x0, x0, x0, lsl #2
    0.00 :   ffff8000109794ac:       cmp     x1, x0
    0.00 :   ffff8000109794b0:       b.eq    ffff800010979600 <hclge_service_task+0x578>  // b.none
         : 4316             int i;
    0.00 :   ffff8000109794b4:       add     x0, x19, #0x20, lsl #12
    0.00 :   ffff8000109794b8:       ldr     x1, [x25, #2432]
    0.00 :   ffff8000109794bc:       str     x1, [x0, #1760]
         : 4319             for (i = 1; i < hdev->num_alloc_vport; i++) {
    0.00 :   ffff8000109794c0:       mov     x1, x24
    0.00 :   ffff8000109794c4:       mov     x0, x19
    0.00 :   ffff8000109794c8:       bl      ffff800010974578 <hclge_task_schedule>
    0.00 :   ffff8000109794cc:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000109794d0:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000109794d4:       b       ffff8000109790d0 <hclge_service_task+0x48>
         : 4326             __ll_sc_atomic64_andnot():
    0.00 :   ffff8000109794d8:       b       ffff80001097c084 <hclge_get_regs_len+0x904>
    0.00 :   ffff8000109794dc:       b       ffff80001097943c <hclge_service_task+0x3b4>
         : 231              hclge_periodic_service_task():
         : 4291             if (!test_and_clear_bit(HCLGE_STATE_ERR_SERVICE_SCHED, &hdev->state))
    0.00 :   ffff8000109794e0:       ldr     x27, [x25, #2432]
         :
    0.00 :   ffff8000109794e4:       mov     x0, #0xfa                       // #250
    0.00 :   ffff8000109794e8:       bl      ffff80001010dbf8 <round_jiffies_relative>
         : 4291             if (!test_and_clear_bit(HCLGE_STATE_ERR_SERVICE_SCHED, &hdev->state))
    0.00 :   ffff8000109794ec:       sub     x24, x27, x21
         :
    0.00 :   ffff8000109794f0:       cmp     x24, x0
    0.00 :   ffff8000109794f4:       b.cs    ffff8000109792e0 <hclge_service_task+0x258>  // b.hs, b.nlast
         : 4294             if (hnae3_dev_ras_imp_supported(hdev))
    0.00 :   ffff8000109794f8:       sub     x24, x21, x27
    0.00 :   ffff8000109794fc:       mov     x0, #0xfa                       // #250
    0.00 :   ffff800010979500:       bl      ffff80001010dbf8 <round_jiffies_relative>
    0.00 :   ffff800010979504:       add     x24, x24, x0
         : 4295             hclge_handle_err_recovery(hdev);
    0.00 :   ffff800010979508:       b       ffff8000109794c0 <hclge_service_task+0x438>
         : 4297             __ll_sc_atomic64_fetch_andnot():
    0.00 :   ffff80001097950c:       mov     x1, #0x10000                    // #65536
    0.00 :   ffff800010979510:       add     x4, x19, #0x3e8
    0.00 :   ffff800010979514:       b       ffff80001097c09c <hclge_get_regs_len+0x91c>
    0.00 :   ffff800010979518:       b       ffff800010979248 <hclge_service_task+0x1c0>
    0.00 :   ffff80001097951c:       mov     x1, #0x20000                    // #131072
    0.00 :   ffff800010979520:       add     x4, x19, #0x3e8
    0.00 :   ffff800010979524:       b       ffff80001097c0b8 <hclge_get_regs_len+0x938>
    0.00 :   ffff800010979528:       b       ffff8000109791f8 <hclge_service_task+0x170>
         : 237              __ll_sc_atomic64_or():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff80001097952c:       add     x3, x19, #0x3e8
    0.00 :   ffff800010979530:       b       ffff80001097c0d4 <hclge_get_regs_len+0x954>
         : 225              hclge_sync_promisc_mode():
         : 12391            struct hnae3_knic_private_info *kinfo)
    0.00 :   ffff800010979534:       ldrb    w1, [x0, #1080]
    0.00 :   ffff800010979538:       strb    w1, [x0, #1081]
         : 12394            test_bit():
    0.00 :   ffff80001097953c:       ldr     x1, [x22, #32368]
         : 107              hclge_sync_promisc_mode():
         : 12394            #define HCLGE_RING_INT_REG_OFFSET       0x4
    0.00 :   ffff800010979540:       tst     w1, #0x4000
    0.00 :   ffff800010979544:       b.eq    ffff8000109791dc <hclge_service_task+0x154>  // b.none
         : 12385            out:
    0.00 :   ffff800010979548:       add     x25, x0, #0x278
         :
    0.00 :   ffff80001097954c:       ldrb    w3, [x0, #1081]
    0.00 :   ffff800010979550:       ldrb    w21, [x25, #160]
         : 12396            int i, j, reg_num, separator_num;
    0.00 :   ffff800010979554:       mov     w2, #0x12                       // #18
    0.00 :   ffff800010979558:       mov     w1, #0x9                        // #9
    0.00 :   ffff80001097955c:       mov     x0, x25
         :
    0.00 :   ffff800010979560:       orr     w21, w21, w3
    0.00 :   ffff800010979564:       and     w21, w21, #0xff
         : 12396            int i, j, reg_num, separator_num;
    0.00 :   ffff800010979568:       tst     w21, w2
    0.00 :   ffff80001097956c:       cset    w2, ne  // ne = any
    0.00 :   ffff800010979570:       tst     w21, w1
    0.00 :   ffff800010979574:       cset    w1, ne  // ne = any
    0.00 :   ffff800010979578:       bl      ffff80001096a940 <hclge_set_promisc_mode>
         : 12398            int data_num_sum;
         : 12399            u32 *reg = data;
    0.00 :   ffff80001097957c:       cbnz    w0, ffff8000109791dc <hclge_service_task+0x154>
         : 12401            arch_static_branch_jump():
    0.00 :   ffff800010979580:       b       ffff8000109796d0 <hclge_service_task+0x648>
    0.00 :   ffff800010979584:       b       ffff8000109796d0 <hclge_service_task+0x648>
         : 40               __lse_atomic64_andnot():
    0.00 :   ffff800010979588:       mov     x0, #0x4000                     // #16384
    0.00 :   ffff80001097958c:       add     x1, x19, #0x3e8
    0.00 :   ffff800010979590:       stclr   x0, [x1]
         : 179              hclge_sync_promisc_mode():
         :
         : 12401            /* fetching per-PF registers valus from PF PCIe register space */
    0.00 :   ffff800010979594:       ubfx    x1, x21, #5, #1
    0.00 :   ffff800010979598:       mov     x0, x25
    0.00 :   ffff80001097959c:       bl      ffff80001096c288 <hclge_enable_vlan_filter>
    0.00 :   ffff8000109795a0:       b       ffff8000109791dc <hclge_service_task+0x154>
         : 12406            hclge_update_stats_for_all():
         : 708              handle = &hdev->vport[0].nic;
    0.00 :   ffff8000109795a4:       ldr     x1, [x19, #1504]
         : 709              if (handle->client) {
    0.00 :   ffff8000109795a8:       add     x0, x1, #0x278
    0.00 :   ffff8000109795ac:       ldr     x1, [x1, #632]
    0.00 :   ffff8000109795b0:       cbz     x1, ffff8000109795d8 <hclge_service_task+0x550>
         : 710              status = hclge_tqps_update_stats(handle);
    0.00 :   ffff8000109795b4:       bl      ffff80001096b7f8 <hclge_tqps_update_stats>
         : 711              if (status) {
    0.00 :   ffff8000109795b8:       cbz     w0, ffff8000109795d8 <hclge_service_task+0x550>
         : 712              dev_err(&hdev->pdev->dev,
    0.00 :   ffff8000109795bc:       ldr     x3, [x19]
    0.00 :   ffff8000109795c0:       mov     w2, w0
    0.00 :   ffff8000109795c4:       adrp    x1, ffff80001150b000 <kallsyms_token_index+0x1007a0>
    0.00 :   ffff8000109795c8:       add     x1, x1, #0x218
    0.00 :   ffff8000109795cc:       add     x0, x3, #0xc0
    0.00 :   ffff8000109795d0:       bl      ffff800010e1fd58 <_dev_err>
    0.00 :   ffff8000109795d4:       nop
         : 718              status = hclge_mac_update_stats(hdev);
    0.00 :   ffff8000109795d8:       mov     x0, x19
    0.00 :   ffff8000109795dc:       bl      ffff800010970d60 <hclge_mac_update_stats>
         : 719              if (status)
    0.00 :   ffff8000109795e0:       cbz     w0, ffff8000109793cc <hclge_service_task+0x344>
         : 720              dev_err(&hdev->pdev->dev,
    0.00 :   ffff8000109795e4:       ldr     x3, [x19]
    0.00 :   ffff8000109795e8:       mov     w2, w0
    0.00 :   ffff8000109795ec:       adrp    x1, ffff80001150b000 <kallsyms_token_index+0x1007a0>
    0.00 :   ffff8000109795f0:       add     x1, x1, #0x1f0
    0.00 :   ffff8000109795f4:       add     x0, x3, #0xc0
    0.00 :   ffff8000109795f8:       bl      ffff800010e1fd58 <_dev_err>
    0.00 :   ffff8000109795fc:       b       ffff8000109793cc <hclge_service_task+0x344>
         : 728              spin_lock_bh():
         : 359              raw_spin_lock(&lock->rlock);
    0.00 :   ffff800010979600:       add     x20, x20, #0x20, lsl #12
    0.00 :   ffff800010979604:       add     x20, x20, #0x158
    0.00 :   ffff800010979608:       mov     x0, x20
         : 363              hclge_rfs_filter_expire():
         : 7122             struct hclge_dev *hdev = vport->back;
    0.00 :   ffff80001097960c:       ldr     x27, [x19, #1504]
         : 7124             spin_lock_bh():
    0.00 :   ffff800010979610:       bl      ffff800010e34ca0 <_raw_spin_lock_bh>
         : 360              hclge_rfs_filter_expire():
         : 7127             return -EOPNOTSUPP;
    0.00 :   ffff800010979614:       ldr     w23, [x21, #2280]
    0.00 :   ffff800010979618:       cmp     w23, #0x1
    0.00 :   ffff80001097961c:       b.ne    ffff80001097962c <hclge_service_task+0x5a4>  // b.any
         : 7131             */
    0.00 :   ffff800010979620:       ldr     x21, [x21, #1736]
         : 7133             __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010979624:       mov     x28, #0x10000                   // #65536
         : 179              hclge_rfs_filter_expire():
    0.00 :   ffff800010979628:       cbnz    x21, ffff800010979670 <hclge_service_task+0x5e8>
         : 7132             spin_unlock_bh():
         : 399              raw_spin_unlock(&lock->rlock);
    0.00 :   ffff80001097962c:       mov     x0, x20
    0.00 :   ffff800010979630:       bl      ffff800010e34af0 <_raw_spin_unlock_bh>
    0.00 :   ffff800010979634:       b       ffff8000109794b4 <hclge_service_task+0x42c>
         : 403              hclge_rfs_filter_expire():
         : 7134             hdev->fd_active_type != HCLGE_FD_RULE_NONE) {
    0.00 :   ffff800010979638:       ldrh    w2, [x21, #152]
    0.00 :   ffff80001097963c:       ldrh    w1, [x21, #168]
    0.00 :   ffff800010979640:       ldrh    w3, [x21, #172]
    0.00 :   ffff800010979644:       ldr     x0, [x27, #672]
    0.00 :   ffff800010979648:       bl      ffff800010cd2d58 <rps_may_expire_flow>
    0.00 :   ffff80001097964c:       tst     w0, #0xff
    0.00 :   ffff800010979650:       b.eq    ffff800010979668 <hclge_service_task+0x5e0>  // b.none
         : 7136             return -EOPNOTSUPP;
    0.00 :   ffff800010979654:       str     w23, [x21, #180]
         : 7138             arch_static_branch_jump():
    0.00 :   ffff800010979658:       b       ffff8000109796c8 <hclge_service_task+0x640>
    0.00 :   ffff80001097965c:       b       ffff8000109796c8 <hclge_service_task+0x640>
         : 40               __lse_atomic64_or():
    0.00 :   ffff800010979660:       mov     x0, x28
    0.00 :   ffff800010979664:       stset   x0, [x26]
         : 179              hclge_rfs_filter_expire():
         : 7131             */
    0.00 :   ffff800010979668:       mov     x21, x22
    0.00 :   ffff80001097966c:       cbz     x22, ffff80001097962c <hclge_service_task+0x5a4>
         : 7132             spin_lock_bh(&hdev->fd_rule_lock);
    0.00 :   ffff800010979670:       ldr     w0, [x21, #180]
         : 7131             */
    0.00 :   ffff800010979674:       ldr     x22, [x21]
         : 7132             spin_lock_bh(&hdev->fd_rule_lock);
    0.00 :   ffff800010979678:       cmp     w0, #0x2
    0.00 :   ffff80001097967c:       b.ne    ffff800010979668 <hclge_service_task+0x5e0>  // b.any
    0.00 :   ffff800010979680:       b       ffff800010979638 <hclge_service_task+0x5b0>
         : 7136             hclge_sync_fd_list():
         : 7446             static struct hclge_fd_rule *hclge_find_cls_flower(struct hclge_dev *hdev,
    0.00 :   ffff800010979684:       mov     x1, x21
    0.00 :   ffff800010979688:       mov     x0, x19
    0.00 :   ffff80001097968c:       bl      ffff80001096f330 <hclge_fd_config_rule>
         : 7447             unsigned long cookie)
    0.00 :   ffff800010979690:       cbnz    w0, ffff80001097969c <hclge_service_task+0x614>
         : 7449             struct hclge_fd_rule *rule;
    0.00 :   ffff800010979694:       str     w27, [x21, #180]
         : 7450             struct hlist_node *node;
    0.00 :   ffff800010979698:       b       ffff8000109792b4 <hclge_service_task+0x22c>
         : 7452             arch_static_branch_jump():
    0.00 :   ffff80001097969c:       b       ffff8000109796bc <hclge_service_task+0x634>
    0.00 :   ffff8000109796a0:       b       ffff8000109796bc <hclge_service_task+0x634>
         : 40               __lse_atomic64_or():
    0.00 :   ffff8000109796a4:       mov     x0, #0x10000                    // #65536
    0.00 :   ffff8000109796a8:       add     x1, x19, #0x3e8
    0.00 :   ffff8000109796ac:       stset   x0, [x1]
    0.00 :   ffff8000109796b0:       b       ffff8000109792bc <hclge_service_task+0x234>
    0.00 :   ffff8000109796b4:       ldr     x0, [x20, #104]
    0.00 :   ffff8000109796b8:       b       ffff8000109791a4 <hclge_service_task+0x11c>
         : 183              __ll_sc_atomic64_or():
    0.00 :   ffff8000109796bc:       add     x2, x19, #0x3e8
    0.00 :   ffff8000109796c0:       b       ffff80001097c0ec <hclge_get_regs_len+0x96c>
    0.00 :   ffff8000109796c4:       b       ffff8000109792bc <hclge_service_task+0x234>
    0.00 :   ffff8000109796c8:       b       ffff80001097c104 <hclge_get_regs_len+0x984>
    0.00 :   ffff8000109796cc:       b       ffff800010979668 <hclge_service_task+0x5e0>
         : 227              __ll_sc_atomic64_andnot():
         : 229              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff8000109796d0:       mov     x0, #0x4000                     // #16384
    0.00 :   ffff8000109796d4:       add     x3, x19, #0x3e8
    0.00 :   ffff8000109796d8:       b       ffff80001097c11c <hclge_get_regs_len+0x99c>
    0.00 :   ffff8000109796dc:       b       ffff800010979594 <hclge_service_task+0x50c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010354c50 <__jbd2_journal_file_buffer>:
         : 6                __jbd2_journal_file_buffer():
         : 2488             /*
         : 2489             * File a buffer on the given transaction list.
         : 2490             */
         : 2491             void __jbd2_journal_file_buffer(struct journal_head *jh,
         : 2492             transaction_t *transaction, int jlist)
         : 2493             {
    0.00 :   ffff800010354c50:       paciasp
    0.00 :   ffff800010354c54:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff800010354c58:       mov     x29, sp
         : 2494             struct journal_head **list = NULL;
         : 2495             int was_dirty = 0;
         : 2496             struct buffer_head *bh = jh2bh(jh);
         :
         : 2498             lockdep_assert_held(&jh->b_state_lock);
         : 2499             assert_spin_locked(&transaction->t_journal->j_list_lock);
    0.00 :   ffff800010354c5c:       ldr     x3, [x1]
         : 2501             atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff800010354c60:       ldr     w3, [x3, #984]
         : 35               __jbd2_journal_file_buffer():
    0.00 :   ffff800010354c64:       cbz     w3, ffff800010354e00 <__jbd2_journal_file_buffer+0x1b0>
         :
         : 2497             J_ASSERT_JH(jh, jh->b_jlist < BJ_Types);
    0.00 :   ffff800010354c68:       ldr     w4, [x0, #16]
    0.00 :   ffff800010354c6c:       cmp     w4, #0x4
    0.00 :   ffff800010354c70:       b.hi    ffff800010354e10 <__jbd2_journal_file_buffer+0x1c0>  // b.pmore
         : 2497             J_ASSERT_JH(jh, jh->b_transaction == transaction ||
    0.00 :   ffff800010354c74:       ldr     x3, [x0, #40]
    0.00 :   ffff800010354c78:       cmp     x3, #0x0
    0.00 :   ffff800010354c7c:       ccmp    x3, x1, #0x4, ne  // ne = any
    0.00 :   ffff800010354c80:       b.ne    ffff800010354e88 <__jbd2_journal_file_buffer+0x238>  // b.any
         : 2500             jh->b_transaction == NULL);
         :
         : 2502             if (jh->b_transaction && jh->b_jlist == jlist)
    0.00 :   ffff800010354c84:       cbz     x3, ffff800010354c90 <__jbd2_journal_file_buffer+0x40>
    0.00 :   ffff800010354c88:       cmp     w4, w2
    0.00 :   ffff800010354c8c:       b.eq    ffff800010354d68 <__jbd2_journal_file_buffer+0x118>  // b.none
    0.00 :   ffff800010354c90:       stp     x19, x20, [sp, #16]
         : 2503             return;
         :
         : 2505             if (jlist == BJ_Metadata || jlist == BJ_Reserved ||
    0.00 :   ffff800010354c94:       cmp     w2, #0x1
    0.00 :   ffff800010354c98:       mov     x19, x0
    0.00 :   ffff800010354c9c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010354ca0:       mov     x20, x1
    0.00 :   ffff800010354ca4:       mov     w22, w2
    0.00 :   ffff800010354ca8:       str     x23, [sp, #48]
    0.00 :   ffff800010354cac:       ccmp    w2, #0x4, #0x4, ne  // ne = any
         : 2491             struct buffer_head *bh = jh2bh(jh);
    0.00 :   ffff800010354cb0:       ldr     x21, [x0]
         : 2503             if (jlist == BJ_Metadata || jlist == BJ_Reserved ||
    0.00 :   ffff800010354cb4:       b.ne    ffff800010354d74 <__jbd2_journal_file_buffer+0x124>  // b.any
         : 2505             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010354cb8:       ldr     x0, [x21]
         : 113              __jbd2_journal_file_buffer():
         : 2512             * instead of buffer_dirty. We should not see a dirty bit set
         : 2513             * here because we clear it in do_get_write_access but e.g.
         : 2514             * tune2fs can modify the sb and set the dirty bit at any time
         : 2515             * so we try to gracefully handle that.
         : 2516             */
         : 2517             if (buffer_dirty(bh))
    0.00 :   ffff800010354cbc:       tst     w0, #0x2
    0.00 :   ffff800010354cc0:       b.eq    ffff800010354cd8 <__jbd2_journal_file_buffer+0x88>  // b.none
         : 2520             warn_dirty_buffer():
         : 902              printk(KERN_WARNING
    0.00 :   ffff800010354cc4:       ldr     x2, [x21, #24]
    0.00 :   ffff800010354cc8:       adrp    x0, ffff800011439000 <kallsyms_token_index+0x2e7a0>
    0.00 :   ffff800010354ccc:       ldr     x1, [x21, #48]
    0.00 :   ffff800010354cd0:       add     x0, x0, #0xcf0
    0.00 :   ffff800010354cd4:       bl      ffff800010e19544 <printk>
         : 908              test_and_clear_bit():
         : 51               {
         : 52               long old;
         : 53               unsigned long mask = BIT_MASK(nr);
         :
         : 55               p += BIT_WORD(nr);
         : 56               if (!(READ_ONCE(*p) & mask))
    0.00 :   ffff800010354cd8:       ldr     x0, [x21]
    0.00 :   ffff800010354cdc:       tbnz    w0, #1, ffff800010354dc0 <__jbd2_journal_file_buffer+0x170>
    0.00 :   ffff800010354ce0:       ldr     x0, [x21]
    0.00 :   ffff800010354ce4:       tbnz    w0, #21, ffff800010354e48 <__jbd2_journal_file_buffer+0x1f8>
    0.00 :   ffff800010354ce8:       ldr     x3, [x19, #40]
         : 62               __jbd2_journal_file_buffer():
         : 2490             int was_dirty = 0;
    0.00 :   ffff800010354cec:       mov     w23, #0x0                       // #0
         : 2519             if (test_clear_buffer_dirty(bh) ||
         : 2520             test_clear_buffer_jbddirty(bh))
         : 2521             was_dirty = 1;
         : 2522             }
         :
         : 2524             if (jh->b_transaction)
    0.00 :   ffff800010354cf0:       cbz     x3, ffff800010354d88 <__jbd2_journal_file_buffer+0x138>
         : 2520             __jbd2_journal_temp_unlink_buffer(jh);
    0.00 :   ffff800010354cf4:       mov     x0, x19
    0.00 :   ffff800010354cf8:       bl      ffff800010353630 <__jbd2_journal_temp_unlink_buffer>
         : 2523             else
         : 2524             jbd2_journal_grab_journal_head(bh);
         : 2525             jh->b_transaction = transaction;
    0.00 :   ffff800010354cfc:       str     x20, [x19, #40]
         :
         : 2526             switch (jlist) {
    0.00 :   ffff800010354d00:       cmp     w22, #0x2
    0.00 :   ffff800010354d04:       b.eq    ffff800010354e34 <__jbd2_journal_file_buffer+0x1e4>  // b.none
    0.00 :   ffff800010354d08:       b.gt    ffff800010354d94 <__jbd2_journal_file_buffer+0x144>
    0.00 :   ffff800010354d0c:       cbz     w22, ffff800010354e20 <__jbd2_journal_file_buffer+0x1d0>
         : 2489             struct journal_head **list = NULL;
    0.00 :   ffff800010354d10:       mov     x1, #0x0                        // #0
         : 2525             switch (jlist) {
    0.00 :   ffff800010354d14:       cmp     w22, #0x1
    0.00 :   ffff800010354d18:       b.ne    ffff800010354d2c <__jbd2_journal_file_buffer+0xdc>  // b.any
         : 2531             case BJ_None:
         : 2532             J_ASSERT_JH(jh, !jh->b_committed_data);
         : 2533             J_ASSERT_JH(jh, !jh->b_frozen_data);
         : 2534             return;
         : 2535             case BJ_Metadata:
         : 2536             transaction->t_nr_buffers++;
    0.00 :   ffff800010354d1c:       ldr     w0, [x20, #24]
         : 2532             list = &transaction->t_buffers;
    0.00 :   ffff800010354d20:       add     x1, x20, #0x28
         : 2531             transaction->t_nr_buffers++;
    0.00 :   ffff800010354d24:       add     w0, w0, #0x1
    0.00 :   ffff800010354d28:       str     w0, [x20, #24]
         : 2534             __blist_add_buffer():
         : 1943             if (!*list) {
    0.00 :   ffff800010354d2c:       ldr     x0, [x1]
    0.00 :   ffff800010354d30:       cbz     x0, ffff800010354db4 <__jbd2_journal_file_buffer+0x164>
    0.00 :   ffff800010354d34:       nop
         : 1948             struct journal_head *first = *list, *last = first->b_tprev;
    0.00 :   ffff800010354d38:       ldr     x1, [x0, #64]
         : 1949             jh->b_tprev = last;
    0.00 :   ffff800010354d3c:       stp     x0, x1, [x19, #56]
         : 1951             last->b_tnext = first->b_tprev = jh;
    0.00 :   ffff800010354d40:       str     x19, [x0, #64]
    0.00 :   ffff800010354d44:       str     x19, [x1, #56]
         : 1954             __jbd2_journal_file_buffer():
         : 2546             list = &transaction->t_reserved_list;
         : 2547             break;
         : 2548             }
         :
         : 2550             __blist_add_buffer(list, jh);
         : 2551             jh->b_jlist = jlist;
    0.00 :   ffff800010354d48:       str     w22, [x19, #16]
         :
         : 2549             if (was_dirty)
    0.00 :   ffff800010354d4c:       cbz     w23, ffff800010354d5c <__jbd2_journal_file_buffer+0x10c>
         : 2551             test_bit():
    0.00 :   ffff800010354d50:       ldr     x0, [x21]
         : 107              set_buffer_jbddirty():
         : 331              BH_JBDPrivateStart,     /* First bit available for private use by FS */
         : 332              };
         :
         : 334              BUFFER_FNS(JBD, jbd)
         : 335              BUFFER_FNS(JWrite, jwrite)
         : 336              BUFFER_FNS(JBDDirty, jbddirty)
    0.00 :   ffff800010354d54:       tst     w0, #0x200000
    0.00 :   ffff800010354d58:       b.eq    ffff800010354de0 <__jbd2_journal_file_buffer+0x190>  // b.none
    0.00 :   ffff800010354d5c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010354d60:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010354d64:       ldr     x23, [sp, #48]
         : 342              __jbd2_journal_file_buffer():
         : 2550             set_buffer_jbddirty(bh);
         : 2551             }
    0.00 :   ffff800010354d68:       ldp     x29, x30, [sp], #64
    0.00 :   ffff800010354d6c:       autiasp
    0.00 :   ffff800010354d70:       ret
         : 2504             jlist == BJ_Shadow || jlist == BJ_Forget) {
    0.00 :   ffff800010354d74:       sub     w0, w2, #0x2
         : 2490             int was_dirty = 0;
    0.00 :   ffff800010354d78:       mov     w23, #0x0                       // #0
         : 2504             jlist == BJ_Shadow || jlist == BJ_Forget) {
    0.00 :   ffff800010354d7c:       cmp     w0, #0x1
    0.00 :   ffff800010354d80:       b.ls    ffff800010354cb8 <__jbd2_journal_file_buffer+0x68>  // b.plast
         : 2519             if (jh->b_transaction)
    0.00 :   ffff800010354d84:       cbnz    x3, ffff800010354cf4 <__jbd2_journal_file_buffer+0xa4>
         : 2522             jbd2_journal_grab_journal_head(bh);
    0.00 :   ffff800010354d88:       mov     x0, x21
    0.00 :   ffff800010354d8c:       bl      ffff80001035f078 <jbd2_journal_grab_journal_head>
    0.00 :   ffff800010354d90:       b       ffff800010354cfc <__jbd2_journal_file_buffer+0xac>
         : 2525             switch (jlist) {
    0.00 :   ffff800010354d94:       cmp     w22, #0x3
         : 2538             list = &transaction->t_shadow_list;
    0.00 :   ffff800010354d98:       add     x1, x20, #0x48
         : 2525             switch (jlist) {
    0.00 :   ffff800010354d9c:       b.eq    ffff800010354d2c <__jbd2_journal_file_buffer+0xdc>  // b.none
         : 2489             struct journal_head **list = NULL;
    0.00 :   ffff800010354da0:       add     x1, x20, #0x20
    0.00 :   ffff800010354da4:       cmp     w22, #0x4
    0.00 :   ffff800010354da8:       csel    x1, x1, xzr, eq  // eq = none
         : 2493             __blist_add_buffer():
         : 1943             if (!*list) {
    0.00 :   ffff800010354dac:       ldr     x0, [x1]
    0.00 :   ffff800010354db0:       cbnz    x0, ffff800010354d38 <__jbd2_journal_file_buffer+0xe8>
         : 1944             jh->b_tnext = jh->b_tprev = jh;
  100.00 :   ffff800010354db4:       stp     x19, x19, [x19, #56]
         : 1945             *list = jh;
    0.00 :   ffff800010354db8:       str     x19, [x1]
    0.00 :   ffff800010354dbc:       b       ffff800010354d48 <__jbd2_journal_file_buffer+0xf8>
         : 1948             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010354dc0:       b       ffff800010354e3c <__jbd2_journal_file_buffer+0x1ec>
    0.00 :   ffff800010354dc4:       b       ffff800010354e3c <__jbd2_journal_file_buffer+0x1ec>
         : 46               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OP(_relaxed,   , op, asm_op)                     \
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff800010354dc8:       mov     x0, #0x2                        // #2
    0.00 :   ffff800010354dcc:       ldclral x0, x0, [x21]
         : 210              __jbd2_journal_file_buffer():
         : 2514             if (test_clear_buffer_dirty(bh) ||
    0.00 :   ffff800010354dd0:       tbz     w0, #1, ffff800010354ce0 <__jbd2_journal_file_buffer+0x90>
         : 2516             was_dirty = 1;
    0.00 :   ffff800010354dd4:       mov     w23, #0x1                       // #1
    0.00 :   ffff800010354dd8:       ldr     x3, [x19, #40]
    0.00 :   ffff800010354ddc:       b       ffff800010354cf0 <__jbd2_journal_file_buffer+0xa0>
         : 2520             arch_static_branch_jump():
    0.00 :   ffff800010354de0:       b       ffff800010354e64 <__jbd2_journal_file_buffer+0x214>
    0.00 :   ffff800010354de4:       b       ffff800010354e64 <__jbd2_journal_file_buffer+0x214>
         : 40               __lse_atomic64_or():
         : 177              ATOMIC64_OP(or, stset)
    0.00 :   ffff800010354de8:       mov     x0, #0x200000                   // #2097152
    0.00 :   ffff800010354dec:       stset   x0, [x21]
    0.00 :   ffff800010354df0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010354df4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010354df8:       ldr     x23, [sp, #48]
    0.00 :   ffff800010354dfc:       b       ffff800010354d68 <__jbd2_journal_file_buffer+0x118>
    0.00 :   ffff800010354e00:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010354e04:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010354e08:       str     x23, [sp, #48]
         : 187              __jbd2_journal_file_buffer():
         : 2494             assert_spin_locked(&transaction->t_journal->j_list_lock);
    0.00 :   ffff800010354e0c:       brk     #0x800
    0.00 :   ffff800010354e10:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010354e14:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010354e18:       str     x23, [sp, #48]
         : 2496             J_ASSERT_JH(jh, jh->b_jlist < BJ_Types);
    0.00 :   ffff800010354e1c:       brk     #0x800
         : 2527             J_ASSERT_JH(jh, !jh->b_committed_data);
    0.00 :   ffff800010354e20:       ldr     x0, [x19, #32]
    0.00 :   ffff800010354e24:       cbnz    x0, ffff800010354e84 <__jbd2_journal_file_buffer+0x234>
         : 2528             J_ASSERT_JH(jh, !jh->b_frozen_data);
    0.00 :   ffff800010354e28:       ldr     x0, [x19, #24]
    0.00 :   ffff800010354e2c:       cbz     x0, ffff800010354d5c <__jbd2_journal_file_buffer+0x10c>
    0.00 :   ffff800010354e30:       brk     #0x800
         : 2535             list = &transaction->t_forget;
    0.00 :   ffff800010354e34:       add     x1, x20, #0x30
         : 2536             break;
    0.00 :   ffff800010354e38:       b       ffff800010354d2c <__jbd2_journal_file_buffer+0xdc>
         : 2538             __ll_sc_atomic64_fetch_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff800010354e3c:       mov     x1, #0x2                        // #2
    0.00 :   ffff800010354e40:       b       ffff800010356654 <jbd2_journal_begin_ordered_truncate+0x274>
    0.00 :   ffff800010354e44:       b       ffff800010354dd0 <__jbd2_journal_file_buffer+0x180>
         : 238              arch_static_branch_jump():
    0.00 :   ffff800010354e48:       b       ffff800010354e78 <__jbd2_journal_file_buffer+0x228>
    0.00 :   ffff800010354e4c:       b       ffff800010354e78 <__jbd2_journal_file_buffer+0x228>
         : 40               __lse_atomic64_fetch_andnot():
         : 202              ATOMIC64_FETCH_OPS(andnot, ldclr)
    0.00 :   ffff800010354e50:       mov     x23, #0x200000                  // #2097152
    0.00 :   ffff800010354e54:       ldclral x23, x23, [x21]
         : 205              test_and_clear_bit():
         : 55               return 0;
         :
         : 57               old = atomic_long_fetch_andnot(mask, (atomic_long_t *)p);
         : 58               return !!(old & mask);
    0.00 :   ffff800010354e58:       ubfx    w23, w23, #21, #1
    0.00 :   ffff800010354e5c:       ldr     x3, [x19, #40]
         : 61               __jbd2_journal_file_buffer():
    0.00 :   ffff800010354e60:       b       ffff800010354cf0 <__jbd2_journal_file_buffer+0xa0>
         : 56               __ll_sc_atomic64_or():
         : 222              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff800010354e64:       b       ffff800010356670 <jbd2_journal_begin_ordered_truncate+0x290>
    0.00 :   ffff800010354e68:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010354e6c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010354e70:       ldr     x23, [sp, #48]
    0.00 :   ffff800010354e74:       b       ffff800010354d68 <__jbd2_journal_file_buffer+0x118>
         : 228              __ll_sc_atomic64_fetch_andnot():
         : 229              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff800010354e78:       mov     x0, #0x200000                   // #2097152
    0.00 :   ffff800010354e7c:       b       ffff800010356688 <jbd2_journal_begin_ordered_truncate+0x2a8>
    0.00 :   ffff800010354e80:       b       ffff800010354e58 <__jbd2_journal_file_buffer+0x208>
         : 233              __jbd2_journal_file_buffer():
         : 2527             J_ASSERT_JH(jh, !jh->b_committed_data);
    0.00 :   ffff800010354e84:       brk     #0x800
    0.00 :   ffff800010354e88:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010354e8c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010354e90:       str     x23, [sp, #48]
         : 2497             J_ASSERT_JH(jh, jh->b_transaction == transaction ||
    0.00 :   ffff800010354e94:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100be898 <update_blocked_averages>:
         : 6                update_blocked_averages():
         : 8116             static unsigned long task_h_load(struct task_struct *p)
         : 8117             {
         : 8118             struct cfs_rq *cfs_rq = task_cfs_rq(p);
         :
         : 8120             update_cfs_rq_h_load(cfs_rq);
         : 8121             return div64_ul(p->se.avg.load_avg * cfs_rq->h_load,
    0.00 :   ffff8000100be898:       paciasp
    0.00 :   ffff8000100be89c:       stp     x29, x30, [sp, #-160]!
         : 8118             cfs_rq_load_avg(cfs_rq) + 1);
         : 8119             }
  100.00 :   ffff8000100be8a0:       adrp    x4, ffff800011779000 <cpu_armpmu>
         : 8116             return div64_ul(p->se.avg.load_avg * cfs_rq->h_load,
    0.00 :   ffff8000100be8a4:       mov     x29, sp
    0.00 :   ffff8000100be8a8:       stp     x21, x22, [sp, #32]
         : 8118             }
    0.00 :   ffff8000100be8ac:       adrp    x22, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100be8b0:       add     x22, x22, #0x760
    0.00 :   ffff8000100be8b4:       add     x4, x4, #0xc40
         : 8116             return div64_ul(p->se.avg.load_avg * cfs_rq->h_load,
    0.00 :   ffff8000100be8b8:       stp     x27, x28, [sp, #80]
         : 8118             }
    0.00 :   ffff8000100be8bc:       ldr     x0, [x22, w0, sxtw #3]
         : 8116             return div64_ul(p->se.avg.load_avg * cfs_rq->h_load,
    0.00 :   ffff8000100be8c0:       stp     x19, x20, [sp, #16]
         : 8118             }
    0.00 :   ffff8000100be8c4:       add     x28, x4, x0
         : 8116             return div64_ul(p->se.avg.load_avg * cfs_rq->h_load,
    0.00 :   ffff8000100be8c8:       stp     x23, x24, [sp, #48]
         : 8118             rq_lock_irqsave():
         :
         : 1319             static inline void raw_spin_rq_unlock_irq(struct rq *rq)
         : 1320             {
         : 1321             raw_spin_rq_unlock(rq);
         : 1322             local_irq_enable();
         : 1323             }
    0.00 :   ffff8000100be8cc:       mov     x0, x28
         : 1325             update_blocked_averages():
    0.00 :   ffff8000100be8d0:       stp     x25, x26, [sp, #64]
         : 8117             rq_lock_irqsave():
    0.00 :   ffff8000100be8d4:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
         : 1319             update_blocked_load_tick():
         : 7950             }
    0.00 :   ffff8000100be8d8:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
         : 7952             rq_lock_irqsave():
    0.00 :   ffff8000100be8dc:       str     x0, [sp, #96]
         : 1319             update_blocked_averages():
         : 8123             #else
         : 8124             static bool __update_blocked_fair(struct rq *rq, bool *done)
         : 8125             {
         : 8126             struct cfs_rq *cfs_rq = &rq->cfs;
         : 8127             bool decayed;
    0.00 :   ffff8000100be8e0:       mov     x0, x28
         : 8129             update_blocked_load_tick():
         : 7950             }
    0.00 :   ffff8000100be8e4:       ldr     x1, [x1, #2432]
    0.00 :   ffff8000100be8e8:       str     x1, [x28, #24]
         : 7953             update_blocked_averages():
         : 8123             bool decayed;
    0.00 :   ffff8000100be8ec:       bl      ffff8000100b3950 <update_rq_clock>
         : 8125             __update_blocked_others():
         : 7976             static inline void update_blocked_load_status(struct rq *rq, bool has_blocked)
    0.00 :   ffff8000100be8f0:       ldr     x1, [x28, #2352]
         : 7980             }
    0.00 :   ffff8000100be8f4:       adrp    x0, ffff800011570000 <kallsyms_token_index+0x1657a0>
         : 7982             topology_get_thermal_pressure():
         :
         : 57               DECLARE_PER_CPU(unsigned long, thermal_pressure);
         :
         : 59               static inline unsigned long topology_get_thermal_pressure(int cpu)
         : 60               {
         : 61               return per_cpu(thermal_pressure, cpu);
    0.00 :   ffff8000100be8f8:       ldrsw   x2, [x28, #2576]
         : 63               __update_blocked_others():
    0.00 :   ffff8000100be8fc:       add     x0, x0, #0xff0
         : 7981             rq_clock_pelt():
         : 147              /* rq->task_clock normalized against any time this cfs_rq has spent throttled */
         : 148              static inline u64 cfs_rq_clock_pelt(struct cfs_rq *cfs_rq)
         : 149              {
         : 150              if (unlikely(cfs_rq->throttle_count))
         : 151              return cfs_rq->throttled_clock_task - cfs_rq->throttled_clock_task_time;
         :
    0.00 :   ffff8000100be900:       ldr     x20, [x28, #2440]
         : 154              topology_get_thermal_pressure():
    0.00 :   ffff8000100be904:       adrp    x3, ffff800011778000 <ipi_to_irq>
         : 57               __update_blocked_others():
         : 7976             static inline void update_blocked_load_status(struct rq *rq, bool has_blocked)
    0.00 :   ffff8000100be908:       ldr     x21, [x1, #120]
         : 7978             topology_get_thermal_pressure():
    0.00 :   ffff8000100be90c:       add     x3, x3, #0x718
    0.00 :   ffff8000100be910:       ldr     x5, [x22, x2, lsl #3]
         : 58               __update_blocked_others():
         : 7980             }
    0.00 :   ffff8000100be914:       cmp     x21, x0
         : 7982             rq_clock_pelt():
    0.00 :   ffff8000100be918:       ldr     x0, [x28, #2448]
         : 148              __update_blocked_others():
    0.00 :   ffff8000100be91c:       cset    w2, eq  // eq = none
    0.00 :   ffff8000100be920:       mov     x1, x28
         : 7982             rq_clock_pelt():
    0.00 :   ffff8000100be924:       sub     x20, x20, x0
         : 148              __update_blocked_others():
    0.00 :   ffff8000100be928:       mov     x0, x20
         : 7981             topology_get_thermal_pressure():
    0.00 :   ffff8000100be92c:       ldr     x23, [x5, x3]
         : 57               __update_blocked_others():
    0.00 :   ffff8000100be930:       bl      ffff8000100d5300 <update_rt_rq_load_avg>
         : 7981             #else
    0.00 :   ffff8000100be934:       adrp    x1, ffff800011571000 <rt_sched_class+0x10>
    0.00 :   ffff8000100be938:       add     x1, x1, #0xb8
    0.00 :   ffff8000100be93c:       cmp     x21, x1
         : 7980             }
    0.00 :   ffff8000100be940:       mov     w19, w0
         : 7981             #else
    0.00 :   ffff8000100be944:       cset    w2, eq  // eq = none
    0.00 :   ffff8000100be948:       mov     x0, x20
    0.00 :   ffff8000100be94c:       mov     x1, x28
    0.00 :   ffff8000100be950:       bl      ffff8000100d5500 <update_dl_rq_load_avg>
    0.00 :   ffff8000100be954:       orr     w20, w19, w0
         : 7987             rq_clock_thermal():
         : 1211             */
    0.00 :   ffff8000100be958:       adrp    x1, ffff800011f28000 <ucounts_hashtable+0x1a88>
         : 1213             __update_blocked_others():
         : 7982             static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq) { return false; }
    0.00 :   ffff8000100be95c:       mov     x2, x23
         : 7984             rq_clock_thermal():
    0.00 :   ffff8000100be960:       ldr     x5, [x28, #2432]
    0.00 :   ffff8000100be964:       ldr     w3, [x1, #1984]
         : 1213             __update_blocked_others():
    0.00 :   ffff8000100be968:       mov     x1, x28
    0.00 :   ffff8000100be96c:       lsr     x0, x5, x3
    0.00 :   ffff8000100be970:       bl      ffff8000100d5700 <update_thermal_load_avg>
    0.00 :   ffff8000100be974:       mov     w19, w0
         : 7983             static inline bool others_have_blocked(struct rq *rq) { return false; }
    0.00 :   ffff8000100be978:       mov     x1, #0x0                        // #0
    0.00 :   ffff8000100be97c:       mov     x0, x28
    0.00 :   ffff8000100be980:       bl      ffff8000100d5900 <update_irq_load_avg>
         : 7982             static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq) { return false; }
    0.00 :   ffff8000100be984:       orr     w0, w19, w0
         : 7984             others_have_blocked():
         : 7931             p = list_first_entry(tasks, struct task_struct, se.group_node);
    0.00 :   ffff8000100be988:       ldr     x1, [x28, #2672]
         : 7933             __update_blocked_others():
         : 7982             static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq) { return false; }
    0.00 :   ffff8000100be98c:       orr     w0, w0, w20
         : 7980             }
    0.00 :   ffff8000100be990:       cmp     w0, #0x0
    0.00 :   ffff8000100be994:       cset    w24, ne  // ne = any
         : 7983             others_have_blocked():
         : 7931             p = list_first_entry(tasks, struct task_struct, se.group_node);
    0.00 :   ffff8000100be998:       cbnz    x1, ffff8000100bea38 <update_blocked_averages+0x1a0>
         : 7934             attach_task(env->dst_rq, p);
    0.00 :   ffff8000100be99c:       ldr     x0, [x28, #2736]
    0.00 :   ffff8000100be9a0:       cbnz    x0, ffff8000100bea38 <update_blocked_averages+0x1a0>
         : 7937             thermal_load_avg():
         : 15               return READ_ONCE(rq->avg_thermal.load_avg);
    0.00 :   ffff8000100be9a4:       ldr     x0, [x28, #2848]
         : 17               others_have_blocked():
         : 7937             rq_unlock(env->dst_rq, &rf);
    0.00 :   ffff8000100be9a8:       cbnz    x0, ffff8000100bea38 <update_blocked_averages+0x1a0>
         : 7941             static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq)
    0.00 :   ffff8000100be9ac:       ldr     x0, [x28, #2800]
    0.00 :   ffff8000100be9b0:       cbnz    x0, ffff8000100bea38 <update_blocked_averages+0x1a0>
         : 7944             __update_blocked_fair():
         :
    0.00 :   ffff8000100be9b4:       ldr     x19, [x28, #2320]
    0.00 :   ffff8000100be9b8:       add     x26, x28, #0x910
         : 8023             update_blocked_averages():
         : 8117             cfs_rq_load_avg(cfs_rq) + 1);
    0.00 :   ffff8000100be9bc:       mov     w23, #0x1                       // #1
         : 8119             __update_blocked_fair():
         : 8014             #ifdef CONFIG_FAIR_GROUP_SCHED
    0.00 :   ffff8000100be9c0:       ldr     w25, [x28, #2576]
         :
    0.00 :   ffff8000100be9c4:       sub     x27, x19, #0x140
    0.00 :   ffff8000100be9c8:       cmp     x26, x19
    0.00 :   ffff8000100be9cc:       ldr     x20, [x27, #320]
    0.00 :   ffff8000100be9d0:       sub     x20, x20, #0x140
    0.00 :   ffff8000100be9d4:       b.ne    ffff8000100bea5c <update_blocked_averages+0x1c4>  // b.any
         : 8026             update_blocked_load_status():
         :
    0.00 :   ffff8000100be9d8:       str     wzr, [x28, #32]
    0.00 :   ffff8000100be9dc:       nop
         : 7959             update_blocked_averages():
         :
         : 8130             decayed = update_cfs_rq_load_avg(cfs_rq_clock_pelt(cfs_rq), cfs_rq);
         : 8131             if (cfs_rq_has_blocked(cfs_rq))
         : 8132             *done = false;
         :
         : 8134             return decayed;
    0.00 :   ffff8000100be9e0:       cbz     w24, ffff8000100bea0c <update_blocked_averages+0x174>
         : 8136             cpufreq_update_util():
         : 2509             __acquires(this_rq->lock)
         : 2510             {
         : 2511             raw_spin_rq_unlock(this_rq);
         : 2512             double_rq_lock(this_rq, busiest);
         :
         : 2514             return 1;
    0.00 :   ffff8000100be9e4:       ldrsw   x1, [x28, #2576]
    0.00 :   ffff8000100be9e8:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100be9ec:       add     x0, x0, #0x8c0
    0.00 :   ffff8000100be9f0:       ldr     x1, [x22, x1, lsl #3]
    0.00 :   ffff8000100be9f4:       ldr     x0, [x0, x1]
         : 2511             }
         :
    0.00 :   ffff8000100be9f8:       cbz     x0, ffff8000100bea0c <update_blocked_averages+0x174>
         : 2512             #else
    0.00 :   ffff8000100be9fc:       ldr     x3, [x0]
    0.00 :   ffff8000100bea00:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100bea04:       ldr     x1, [x28, #2400]
    0.00 :   ffff8000100bea08:       blr     x3
         : 2517             rq_unlock_irqrestore():
         :
    0.00 :   ffff8000100bea0c:       ldr     x1, [sp, #96]
    0.00 :   ffff8000100bea10:       mov     x0, x28
    0.00 :   ffff8000100bea14:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1355             update_blocked_averages():
         : 8132             }
         :
         : 8134             static unsigned long task_h_load(struct task_struct *p)
    0.00 :   ffff8000100bea18:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bea1c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100bea20:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100bea24:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100bea28:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100bea2c:       ldp     x29, x30, [sp], #160
    0.00 :   ffff8000100bea30:       autiasp
    0.00 :   ffff8000100bea34:       ret
         : 8143             __update_blocked_fair():
         :
    0.00 :   ffff8000100bea38:       ldr     x19, [x28, #2320]
    0.00 :   ffff8000100bea3c:       add     x26, x28, #0x910
    0.00 :   ffff8000100bea40:       mov     w23, #0x0                       // #0
         : 8014             #ifdef CONFIG_FAIR_GROUP_SCHED
    0.00 :   ffff8000100bea44:       ldr     w25, [x28, #2576]
         :
    0.00 :   ffff8000100bea48:       sub     x27, x19, #0x140
    0.00 :   ffff8000100bea4c:       cmp     x26, x19
    0.00 :   ffff8000100bea50:       ldr     x20, [x27, #320]
    0.00 :   ffff8000100bea54:       sub     x20, x20, #0x140
    0.00 :   ffff8000100bea58:       b.eq    ffff8000100be9e0 <update_blocked_averages+0x148>  // b.none
         : 8031             }
    0.00 :   ffff8000100bea5c:       sbfiz   x0, x25, #3, #32
         :
    0.00 :   ffff8000100bea60:       add     x1, x28, #0x80
         :
    0.00 :   ffff8000100bea64:       mov     w21, #0x0                       // #0
         : 8031             }
    0.00 :   ffff8000100bea68:       str     x0, [sp, #136]
         : 8033             update_tg_load_avg():
         :
    0.00 :   ffff8000100bea6c:       adrp    x0, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100bea70:       add     x0, x0, #0x5c0
    0.00 :   ffff8000100bea74:       str     x0, [sp, #144]
         : 3326             __update_blocked_fair():
         :
    0.00 :   ffff8000100bea78:       str     x1, [sp, #152]
    0.00 :   ffff8000100bea7c:       b       ffff8000100beaa4 <update_blocked_averages+0x20c>
         : 8029             cfs_rq_has_blocked():
         : 7923             struct list_head *tasks = &env->tasks;
    0.00 :   ffff8000100bea80:       ldr     x0, [x27, #176]
         : 7925             __update_blocked_fair():
         :
    0.00 :   ffff8000100bea84:       add     x19, x20, #0x140
    0.00 :   ffff8000100bea88:       mov     x27, x20
         : 8044             struct sched_entity *se;
    0.00 :   ffff8000100bea8c:       cmp     x0, #0x0
         :
    0.00 :   ffff8000100bea90:       ldr     x0, [x20, #320]
         : 8044             struct sched_entity *se;
    0.00 :   ffff8000100bea94:       csel    w23, w23, wzr, eq  // eq = none
         :
    0.00 :   ffff8000100bea98:       cmp     x26, x19
    0.00 :   ffff8000100bea9c:       sub     x20, x0, #0x140
    0.00 :   ffff8000100beaa0:       b.eq    ffff8000100beb7c <update_blocked_averages+0x2e4>  // b.none
         : 8024             cfs_rq_clock_pelt():
         : 162              #else
         :
         : 164              static inline int
         : 165              update_cfs_rq_load_avg(u64 now, struct cfs_rq *cfs_rq)
         : 166              {
         : 167              return 0;
    0.00 :   ffff8000100beaa4:       ldr     x0, [x27, #304]
         : 169              update_cfs_rq_load_avg():
         : 3661             *
    0.00 :   ffff8000100beaa8:       ldr     w1, [x27, #196]
         : 3663             rq_clock_pelt():
         :
    0.00 :   ffff8000100beaac:       ldr     x2, [x0, #2440]
    0.00 :   ffff8000100beab0:       ldr     x0, [x0, #2448]
    0.00 :   ffff8000100beab4:       sub     x25, x2, x0
         : 151              update_cfs_rq_load_avg():
    0.00 :   ffff8000100beab8:       cbnz    w1, ffff8000100beb90 <update_blocked_averages+0x2f8>
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100beabc:       mov     x0, x25
    0.00 :   ffff8000100beac0:       mov     x1, x27
    0.00 :   ffff8000100beac4:       bl      ffff8000100d50e8 <__update_load_avg_cfs_rq>
         : 3698             __update_blocked_fair():
         :
    0.00 :   ffff8000100beac8:       cbnz    w0, ffff8000100bec88 <update_blocked_averages+0x3f0>
    0.00 :   ffff8000100beacc:       ldr     x0, [x27, #336]
         : 8031             }
    0.00 :   ffff8000100bead0:       ldr     x1, [sp, #136]
    0.00 :   ffff8000100bead4:       ldr     x0, [x0, #200]
    0.00 :   ffff8000100bead8:       ldr     x1, [x0, x1]
         :
    0.00 :   ffff8000100beadc:       cbz     x1, ffff8000100beafc <update_blocked_averages+0x264>
         : 8034             skip_blocked_update():
         : 3607             static inline int
    0.00 :   ffff8000100beae0:       ldr     x0, [x1, #224]
    0.00 :   ffff8000100beae4:       cbnz    x0, ffff8000100becc4 <update_blocked_averages+0x42c>
    0.00 :   ffff8000100beae8:       ldr     x0, [x1, #240]
    0.00 :   ffff8000100beaec:       cbnz    x0, ffff8000100becc4 <update_blocked_averages+0x42c>
         : 3614             if (cfs_rq->removed.nr) {
    0.00 :   ffff8000100beaf0:       ldr     x0, [x1, #128]
    0.00 :   ffff8000100beaf4:       ldr     x0, [x0, #264]
    0.00 :   ffff8000100beaf8:       cbnz    x0, ffff8000100becc4 <update_blocked_averages+0x42c>
         : 3618             cfs_rq_is_decayed():
         : 7995             /*
    0.00 :   ffff8000100beafc:       ldr     x0, [x27]
    0.00 :   ffff8000100beb00:       cbnz    x0, ffff8000100beb58 <update_blocked_averages+0x2c0>
         : 7998             */
    0.00 :   ffff8000100beb04:       ldr     x0, [x27, #136]
    0.00 :   ffff8000100beb08:       cbnz    x0, ffff8000100beb58 <update_blocked_averages+0x2c0>
         : 8001             thermal_pressure = arch_scale_thermal_pressure(cpu_of(rq));
    0.00 :   ffff8000100beb0c:       ldr     w0, [x27, #152]
    0.00 :   ffff8000100beb10:       cbnz    w0, ffff8000100beb58 <update_blocked_averages+0x2c0>
         : 8004             update_dl_rq_load_avg(now, rq, curr_class == &dl_sched_class) |
    0.00 :   ffff8000100beb14:       ldr     x0, [x27, #144]
    0.00 :   ffff8000100beb18:       cbnz    x0, ffff8000100beb58 <update_blocked_averages+0x2c0>
         : 8007             list_del_leaf_cfs_rq():
         :
    0.00 :   ffff8000100beb1c:       ldr     w0, [x27, #312]
    0.00 :   ffff8000100beb20:       cbz     w0, ffff8000100beb58 <update_blocked_averages+0x2c0>
         : 382              /* Iterate thr' all leaf cfs_rq's on a runqueue */
    0.00 :   ffff8000100beb24:       ldr     x1, [x27, #304]
         : 391              if (se->cfs_rq == pse->cfs_rq)
    0.00 :   ffff8000100beb28:       ldr     x0, [x27, #328]
    0.00 :   ffff8000100beb2c:       ldr     x2, [x1, #2336]
    0.00 :   ffff8000100beb30:       cmp     x19, x2
    0.00 :   ffff8000100beb34:       b.eq    ffff8000100becfc <update_blocked_averages+0x464>  // b.none
         : 396              list_del_rcu():
         : 166              /**
         : 167              * hlist_del_init_rcu - deletes entry from hash list with re-initialization
         : 168              * @n: the element to delete from the hash list.
         : 169              *
         : 170              * Note: list_unhashed() on the node return true after this. It is
         : 171              * useful for RCU based read lockfree traversal if the writer side
    0.00 :   ffff8000100beb38:       ldr     x1, [x27, #320]
         : 173              __list_del():
         : 112              * This is only for internal list manipulation where we know
         : 113              * the prev/next entries already!
         : 114              */
         : 115              static inline void __list_del(struct list_head * prev, struct list_head * next)
         : 116              {
         : 117              next->prev = prev;
    0.00 :   ffff8000100beb3c:       str     x0, [x1, #8]
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000100beb40:       str     x1, [x0]
         : 115              list_del_rcu():
         : 167              * must know if the list entry is still hashed or already unhashed.
    0.00 :   ffff8000100beb44:       mov     x0, #0x122                      // #290
    0.00 :   ffff8000100beb48:       movk    x0, #0xdead, lsl #48
         : 170              list_del_leaf_cfs_rq():
         : 395              }
    0.00 :   ffff8000100beb4c:       str     wzr, [x27, #312]
         : 397              list_del_rcu():
    0.00 :   ffff8000100beb50:       str     x0, [x27, #328]
         : 168              list_del_leaf_cfs_rq():
    0.00 :   ffff8000100beb54:       nop
         : 168              cfs_rq_has_blocked():
         : 7920             */
    0.00 :   ffff8000100beb58:       ldr     x0, [x27, #160]
    0.00 :   ffff8000100beb5c:       cbz     x0, ffff8000100bea80 <update_blocked_averages+0x1e8>
         : 7923             __update_blocked_fair():
         :
    0.00 :   ffff8000100beb60:       ldr     x0, [x20, #320]
    0.00 :   ffff8000100beb64:       add     x19, x20, #0x140
    0.00 :   ffff8000100beb68:       mov     x27, x20
         : 8044             struct sched_entity *se;
    0.00 :   ffff8000100beb6c:       mov     w23, #0x0                       // #0
         :
    0.00 :   ffff8000100beb70:       cmp     x26, x19
    0.00 :   ffff8000100beb74:       sub     x20, x0, #0x140
    0.00 :   ffff8000100beb78:       b.ne    ffff8000100beaa4 <update_blocked_averages+0x20c>  // b.any
    0.00 :   ffff8000100beb7c:       orr     w24, w21, w24
    0.00 :   ffff8000100beb80:       and     w24, w24, #0xff
         : 8026             update_blocked_load_status():
         : 7955             return true;
    0.00 :   ffff8000100beb84:       cbz     w23, ffff8000100be9e0 <update_blocked_averages+0x148>
         :
    0.00 :   ffff8000100beb88:       str     wzr, [x28, #32]
    0.00 :   ffff8000100beb8c:       b       ffff8000100be9e0 <update_blocked_averages+0x148>
         : 7959             get_pelt_divider():
         : 42               return LOAD_AVG_MAX - 1024 + avg->period_contrib;
    0.00 :   ffff8000100beb90:       ldr     w6, [x27, #156]
         : 44               update_cfs_rq_load_avg():
         : 3665             static void attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)
    0.00 :   ffff8000100beb94:       add     x1, x27, #0xc0
         : 3667             get_pelt_divider():
    0.00 :   ffff8000100beb98:       mov     w2, #0xb67e                     // #46718
         : 43               update_cfs_rq_load_avg():
    0.00 :   ffff8000100beb9c:       mov     x0, x1
         : 3666             get_pelt_divider():
    0.00 :   ffff8000100beba0:       add     w6, w6, w2
         : 43               update_cfs_rq_load_avg():
    0.00 :   ffff8000100beba4:       str     x1, [sp, #104]
         : 3666             get_pelt_divider():
    0.00 :   ffff8000100beba8:       str     w6, [sp, #132]
         : 43               update_cfs_rq_load_avg():
    0.00 :   ffff8000100bebac:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 3669             * See ___update_load_avg() for details.
    0.00 :   ffff8000100bebb0:       str     wzr, [x27, #196]
         : 3670             */
    0.00 :   ffff8000100bebb4:       ldr     x1, [sp, #104]
         : 3668             * cfs_rq->avg.period_contrib can be used for both cfs_rq and se.
    0.00 :   ffff8000100bebb8:       ldp     x10, x5, [x27, #208]
         : 3670             */
    0.00 :   ffff8000100bebbc:       mov     x0, x1
         : 3667             /*
    0.00 :   ffff8000100bebc0:       ldr     x1, [x27, #200]
         : 3666             {
    0.00 :   ffff8000100bebc4:       stp     xzr, xzr, [x27, #200]
         : 3668             * cfs_rq->avg.period_contrib can be used for both cfs_rq and se.
    0.00 :   ffff8000100bebc8:       str     xzr, [x27, #216]
         : 3666             {
    0.00 :   ffff8000100bebcc:       stp     x5, x10, [sp, #104]
         : 3667             /*
    0.00 :   ffff8000100bebd0:       str     x1, [sp, #120]
         : 3670             */
    0.00 :   ffff8000100bebd4:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 3673             /*
    0.00 :   ffff8000100bebd8:       ldr     x1, [sp, #120]
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100bebdc:       mov     x0, x25
         : 3673             /*
    0.00 :   ffff8000100bebe0:       ldr     x8, [x27, #160]
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100bebe4:       ldr     w6, [sp, #132]
         : 3673             /*
    0.00 :   ffff8000100bebe8:       sub     x7, x8, x1
    0.00 :   ffff8000100bebec:       cmp     x8, x7
    0.00 :   ffff8000100bebf0:       csel    x7, x7, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bebf4:       str     x7, [x27, #160]
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100bebf8:       mov     w9, w6
    0.00 :   ffff8000100bebfc:       ldr     x7, [x27, #136]
         : 3677             *
    0.00 :   ffff8000100bec00:       ldp     x5, x10, [sp, #104]
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100bec04:       msub    x1, x1, x9, x7
    0.00 :   ffff8000100bec08:       cmp     x7, x1
    0.00 :   ffff8000100bec0c:       csel    x1, x1, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bec10:       str     x1, [x27, #136]
         :
    0.00 :   ffff8000100bec14:       mul     x2, x5, x9
         : 3684             add_tg_cfs_propagate():
         : 3563             /*
    0.00 :   ffff8000100bec18:       mov     x9, #0x1                        // #1
    0.00 :   ffff8000100bec1c:       str     x9, [x27, #264]
         : 3566             update_cfs_rq_load_avg():
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100bec20:       mov     x1, x27
         : 3677             *
    0.00 :   ffff8000100bec24:       ldr     x9, [x27, #176]
         : 3689             se->avg.util_sum = se->avg.util_avg * divider;
    0.00 :   ffff8000100bec28:       neg     x8, x2
         : 3677             *
    0.00 :   ffff8000100bec2c:       sub     x7, x9, x10
    0.00 :   ffff8000100bec30:       cmp     x9, x7
    0.00 :   ffff8000100bec34:       csel    x7, x7, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bec38:       str     x7, [x27, #176]
         : 3682             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100bec3c:       ldr     x7, [x27, #272]
         : 3566             update_cfs_rq_load_avg():
         : 3678             * XXX illustrate
    0.00 :   ffff8000100bec40:       ldr     w9, [x27, #152]
         : 3680             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100bec44:       add     x7, x7, x8, asr #10
    0.00 :   ffff8000100bec48:       str     x7, [x27, #272]
         : 3567             update_cfs_rq_load_avg():
         : 3678             * XXX illustrate
    0.00 :   ffff8000100bec4c:       msub    w6, w6, w10, w9
    0.00 :   ffff8000100bec50:       cmp     w9, w6
    0.00 :   ffff8000100bec54:       csel    w6, w6, wzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bec58:       str     w6, [x27, #152]
         : 3681             se->avg.period_contrib = cfs_rq->avg.period_contrib;
    0.00 :   ffff8000100bec5c:       ldr     x6, [x27, #168]
    0.00 :   ffff8000100bec60:       sub     x5, x6, x5
    0.00 :   ffff8000100bec64:       cmp     x6, x5
    0.00 :   ffff8000100bec68:       csel    x5, x5, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bec6c:       str     x5, [x27, #168]
         :
    0.00 :   ffff8000100bec70:       ldr     x5, [x27, #144]
    0.00 :   ffff8000100bec74:       sub     x2, x5, x2
    0.00 :   ffff8000100bec78:       cmp     x5, x2
    0.00 :   ffff8000100bec7c:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100bec80:       str     x2, [x27, #144]
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100bec84:       bl      ffff8000100d50e8 <__update_load_avg_cfs_rq>
         : 3696             update_tg_load_avg():
         :
    0.00 :   ffff8000100bec88:       ldr     x3, [sp, #144]
         :
    0.00 :   ffff8000100bec8c:       ldr     x1, [x27, #160]
    0.00 :   ffff8000100bec90:       ldr     x2, [x27, #256]
         :
    0.00 :   ffff8000100bec94:       ldr     x0, [x27, #336]
         :
    0.00 :   ffff8000100bec98:       sub     x1, x1, x2
         :
    0.00 :   ffff8000100bec9c:       cmp     x0, x3
    0.00 :   ffff8000100beca0:       b.eq    ffff8000100becb4 <update_blocked_averages+0x41c>  // b.none
         : 3325             }
    0.00 :   ffff8000100beca4:       cmp     x1, #0x0
    0.00 :   ffff8000100beca8:       cneg    x5, x1, lt  // lt = tstop
    0.00 :   ffff8000100becac:       cmp     x5, x2, lsr #6
    0.00 :   ffff8000100becb0:       b.hi    ffff8000100becd4 <update_blocked_averages+0x43c>  // b.pmore
         : 3330             __update_blocked_fair():
         : 8027             if (cfs_rq->avg.runnable_sum)
    0.00 :   ffff8000100becb4:       ldr     x1, [sp, #152]
    0.00 :   ffff8000100becb8:       cmp     x27, x1
    0.00 :   ffff8000100becbc:       csinc   w21, w21, wzr, ne  // ne = any
    0.00 :   ffff8000100becc0:       b       ffff8000100bead0 <update_blocked_averages+0x238>
         : 8033             static bool __update_blocked_fair(struct rq *rq, bool *done)
    0.00 :   ffff8000100becc4:       ldr     x0, [x1, #120]
    0.00 :   ffff8000100becc8:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100beccc:       bl      ffff8000100be318 <update_load_avg>
    0.00 :   ffff8000100becd0:       b       ffff8000100beafc <update_blocked_averages+0x264>
         : 8038             update_tg_load_avg():
         : 3326             #else
    0.00 :   ffff8000100becd4:       add     x0, x0, #0x100
         : 3328             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000100becd8:       b       ffff8000100bece8 <update_blocked_averages+0x450>
    0.00 :   ffff8000100becdc:       b       ffff8000100bece8 <update_blocked_averages+0x450>
         : 46               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000100bece0:       stadd   x1, [x0]
    0.00 :   ffff8000100bece4:       b       ffff8000100becec <update_blocked_averages+0x454>
         : 187              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000100bece8:       b       ffff8000100c80d4 <sched_group_set_shares+0x53c>
         : 217              update_tg_load_avg():
         : 3327             p_last_update_time = prev->avg.last_update_time;
    0.00 :   ffff8000100becec:       ldr     x1, [x27, #160]
    0.00 :   ffff8000100becf0:       str     x1, [x27, #256]
    0.00 :   ffff8000100becf4:       ldr     x0, [x27, #336]
    0.00 :   ffff8000100becf8:       b       ffff8000100becb4 <update_blocked_averages+0x41c>
         : 3332             list_del_leaf_cfs_rq():
         : 392              return se->cfs_rq;
    0.00 :   ffff8000100becfc:       str     x0, [x1, #2336]
    0.00 :   ffff8000100bed00:       ldr     x0, [x27, #328]
    0.00 :   ffff8000100bed04:       b       ffff8000100beb38 <update_blocked_averages+0x2a0>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c6da8 <_nohz_idle_balance.isra.127>:
         : 6                _nohz_idle_balance():
         : 10410            out:
         : 10411            /*
         : 10412            * Each time a cpu enter idle, we assume that it has blocked load and
         : 10413            * enable the periodic update of the load of idle cpus
         : 10414            */
         : 10415            WRITE_ONCE(nohz.has_blocked, 1);
    0.00 :   ffff8000100c6da8:       paciasp
    0.00 :   ffff8000100c6dac:       stp     x29, x30, [sp, #-128]!
         : 10415            }
         :
         : 10417            static bool update_nohz_stats(struct rq *rq)
         : 10418            {
         : 10419            unsigned int cpu = rq->cpu;
    0.00 :   ffff8000100c6db0:       mov     x2, #0x3a98                     // #15000
         : 10410            WRITE_ONCE(nohz.has_blocked, 1);
    0.00 :   ffff8000100c6db4:       mov     x29, sp
    0.00 :   ffff8000100c6db8:       stp     x25, x26, [sp, #64]
         : 10414            {
    0.00 :   ffff8000100c6dbc:       adrp    x25, ffff800011c27000 <bit_wait_table+0xe80>
         : 10410            WRITE_ONCE(nohz.has_blocked, 1);
    0.00 :   ffff8000100c6dc0:       stp     x19, x20, [sp, #16]
         :
         : 10433            return rq->has_blocked_load;
         : 10434            }
         :
         : 10436            /*
         : 10437            * Internal function that runs load balance for all idle cpus. The load balance
    0.00 :   ffff8000100c6dc4:       adrp    x20, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100c6dc8:       add     x20, x20, #0x7c0
         : 10410            WRITE_ONCE(nohz.has_blocked, 1);
    0.00 :   ffff8000100c6dcc:       stp     x21, x22, [sp, #32]
         : 10432            * Internal function that runs load balance for all idle cpus. The load balance
    0.00 :   ffff8000100c6dd0:       add     x21, x20, #0x40
         : 10410            WRITE_ONCE(nohz.has_blocked, 1);
    0.00 :   ffff8000100c6dd4:       str     w1, [sp, #112]
         : 10414            {
    0.00 :   ffff8000100c6dd8:       ldr     x1, [x25, #2432]
         : 10432            * Internal function that runs load balance for all idle cpus. The load balance
    0.00 :   ffff8000100c6ddc:       str     wzr, [x21, #36]
         : 10414            {
    0.00 :   ffff8000100c6de0:       str     x1, [sp, #120]
         : 10415            unsigned int cpu = rq->cpu;
    0.00 :   ffff8000100c6de4:       add     x19, x1, x2
         : 10438            * can be a simple update of blocked load or a complete load balance with
         : 10439            * tasks movement depending of flags.
         : 10440            */
         : 10441            static void _nohz_idle_balance(struct rq *this_rq, unsigned int flags,
         : 10442            enum cpu_idle_type idle)
         : 10443            {
    0.00 :   ffff8000100c6de8:       dmb     ish
         : 10444            /* Earliest time when we have to do rebalance again */
         : 10445            unsigned long now = jiffies;
         : 10446            unsigned long next_balance = now + 60*HZ;
         : 10447            bool has_blocked_load = false;
         : 10448            int update_next_balance = 0;
         : 10449            int this_cpu = this_rq->cpu;
    0.00 :   ffff8000100c6dec:       add     w22, w0, #0x1
    0.00 :   ffff8000100c6df0:       mov     x1, x21
    0.00 :   ffff8000100c6df4:       mov     w2, w22
    0.00 :   ffff8000100c6df8:       mov     w3, #0x0                        // #0
    0.00 :   ffff8000100c6dfc:       bl      ffff8000104a74b8 <cpumask_next_wrap>
    0.00 :   ffff8000100c6e00:       cmp     w0, #0xff
    0.00 :   ffff8000100c6e04:       b.hi    ffff8000100c6fc8 <_nohz_idle_balance.isra.127+0x220>  // b.pmore
         : 10417            if (!rq->has_blocked_load)
    0.00 :   ffff8000100c6e08:       mov     w21, #0x0                       // #0
         :
         : 10479            /*
         : 10480            * If this CPU gets work to do, stop the load balancing
         : 10481            * work being done for other CPUs. Next load
         : 10482            * balancing owner will pick it up.
         : 10483            */
    0.00 :   ffff8000100c6e0c:       mov     w26, #0x1                       // #1
    0.00 :   ffff8000100c6e10:       stp     x23, x24, [sp, #48]
         : 10458            WRITE_ONCE(nohz.has_blocked, 0);
    0.00 :   ffff8000100c6e14:       adrp    x24, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c6e18:       adrp    x23, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c6e1c:       add     x24, x24, #0xc40
    0.00 :   ffff8000100c6e20:       add     x23, x23, #0x760
    0.00 :   ffff8000100c6e24:       stp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c6e28:       mov     w27, w0
         :
    0.00 :   ffff8000100c6e2c:       str     wzr, [sp, #100]
    0.00 :   ffff8000100c6e30:       b       ffff8000100c6e68 <_nohz_idle_balance.isra.127+0xc0>
         : 10478            */
    0.00 :   ffff8000100c6e34:       subs    x1, x0, x19
    0.00 :   ffff8000100c6e38:       csel    x19, x19, x0, pl  // pl = nfrst
    0.00 :   ffff8000100c6e3c:       cmp     x1, #0x0
    0.00 :   ffff8000100c6e40:       csel    w21, w21, w26, ge  // ge = tcont
         : 10444            int this_cpu = this_rq->cpu;
    0.00 :   ffff8000100c6e44:       add     x28, x20, #0x40
    0.00 :   ffff8000100c6e48:       mov     w0, w27
    0.00 :   ffff8000100c6e4c:       mov     x1, x28
    0.00 :   ffff8000100c6e50:       mov     w3, #0x1                        // #1
    0.00 :   ffff8000100c6e54:       mov     w2, w22
    0.00 :   ffff8000100c6e58:       bl      ffff8000104a74b8 <cpumask_next_wrap>
    0.00 :   ffff8000100c6e5c:       mov     w27, w0
    0.00 :   ffff8000100c6e60:       cmp     w0, #0xff
    0.00 :   ffff8000100c6e64:       b.hi    ffff8000100c6f64 <_nohz_idle_balance.isra.127+0x1bc>  // b.pmore
         : 10445            int balance_cpu;
    0.00 :   ffff8000100c6e68:       mov     w0, w27
    0.00 :   ffff8000100c6e6c:       bl      ffff8000100b75b8 <idle_cpu>
    0.00 :   ffff8000100c6e70:       cbz     w0, ffff8000100c6e44 <_nohz_idle_balance.isra.127+0x9c>
         : 10449            get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100c6e74:       mrs     x0, sp_el0
         : 26               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100c6e78:       ldr     x0, [x0]
         : 113              _nohz_idle_balance():
         : 10453            * set the has_blocked flag and trig another update of idle load.
    0.00 :   ffff8000100c6e7c:       tbnz    w0, #1, ffff8000100c6f80 <_nohz_idle_balance.isra.127+0x1d8>
         : 10458            WRITE_ONCE(nohz.has_blocked, 0);
    0.00 :   ffff8000100c6e80:       ldr     x0, [x23, w27, sxtw #3]
    0.00 :   ffff8000100c6e84:       mov     x2, x24
    0.00 :   ffff8000100c6e88:       add     x28, x2, x0
         : 10462            update_nohz_stats():
         : 10391            rq->nohz_tick_stopped = 1;
    0.00 :   ffff8000100c6e8c:       ldr     w0, [x28, #32]
    0.00 :   ffff8000100c6e90:       cbz     w0, ffff8000100c6f30 <_nohz_idle_balance.isra.127+0x188>
         : 10389            return;
    0.00 :   ffff8000100c6e94:       ldr     w0, [x28, #2576]
         : 10391            test_bit():
    0.00 :   ffff8000100c6e98:       add     x4, x20, #0x40
    0.00 :   ffff8000100c6e9c:       cmp     w0, #0x0
    0.00 :   ffff8000100c6ea0:       add     w1, w0, #0x3f
    0.00 :   ffff8000100c6ea4:       csel    w1, w1, w0, lt  // lt = tstop
    0.00 :   ffff8000100c6ea8:       asr     w1, w1, #6
    0.00 :   ffff8000100c6eac:       sxtw    x1, w1
    0.00 :   ffff8000100c6eb0:       ldr     x1, [x4, x1, lsl #3]
    0.00 :   ffff8000100c6eb4:       lsr     x1, x1, x0
         : 114              update_nohz_stats():
         : 10394            atomic_inc(&nohz.nr_cpus);
    0.00 :   ffff8000100c6eb8:       tbz     w1, #0, ffff8000100c6f30 <_nohz_idle_balance.isra.127+0x188>
         : 10397            * Ensures that if nohz_idle_balance() fails to observe our
    0.00 :   ffff8000100c6ebc:       ldr     x5, [x28, #24]
    0.00 :   ffff8000100c6ec0:       add     x1, x25, #0x980
    0.00 :   ffff8000100c6ec4:       ldr     x4, [x25, #2432]
    0.00 :   ffff8000100c6ec8:       cmp     x5, x4
    0.00 :   ffff8000100c6ecc:       b.mi    ffff8000100c6f3c <_nohz_idle_balance.isra.127+0x194>  // b.first
    0.00 :   ffff8000100c6ed0:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c6ed4:       str     w0, [sp, #100]
         : 10405            _nohz_idle_balance():
         : 10466            /*
    0.00 :   ffff8000100c6ed8:       ldr     x1, [x1]
    0.00 :   ffff8000100c6edc:       ldr     x0, [x28, #2376]
    0.00 :   ffff8000100c6ee0:       cmp     x1, x0
    0.00 :   ffff8000100c6ee4:       b.mi    ffff8000100c6e34 <_nohz_idle_balance.isra.127+0x8c>  // b.first
         : 10471            rq_lock_irqsave():
         :
         : 1319             static inline void raw_spin_rq_unlock_irq(struct rq *rq)
         : 1320             {
         : 1321             raw_spin_rq_unlock(rq);
         : 1322             local_irq_enable();
         : 1323             }
  100.00 :   ffff8000100c6ee8:       mov     x0, x28
    0.00 :   ffff8000100c6eec:       bl      ffff800010e34d88 <_raw_spin_lock_irqsave>
    0.00 :   ffff8000100c6ef0:       mov     x1, x0
         : 1327             _nohz_idle_balance():
         : 10470            for_each_cpu_wrap(balance_cpu,  nohz.idle_cpus_mask, this_cpu+1) {
    0.00 :   ffff8000100c6ef4:       mov     x0, x28
         : 10472            rq_lock_irqsave():
    0.00 :   ffff8000100c6ef8:       str     x1, [sp, #104]
         : 1319             _nohz_idle_balance():
    0.00 :   ffff8000100c6efc:       bl      ffff8000100b3950 <update_rq_clock>
         : 10471            rq_unlock_irqrestore():
         : 1351             }
         :
         : 1353             #else
         : 1354             static inline void update_idle_core(struct rq *rq) { }
         : 1355             #endif
         :
    0.00 :   ffff8000100c6f00:       ldr     x1, [sp, #104]
    0.00 :   ffff8000100c6f04:       mov     x0, x28
    0.00 :   ffff8000100c6f08:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1360             _nohz_idle_balance():
         :
    0.00 :   ffff8000100c6f0c:       ldr     x0, [sp, #112]
    0.00 :   ffff8000100c6f10:       tbnz    w0, #0, ffff8000100c6f1c <_nohz_idle_balance.isra.127+0x174>
    0.00 :   ffff8000100c6f14:       ldr     x0, [x28, #2376]
    0.00 :   ffff8000100c6f18:       b       ffff8000100c6e34 <_nohz_idle_balance.isra.127+0x8c>
         : 10474            /*
    0.00 :   ffff8000100c6f1c:       mov     x0, x28
    0.00 :   ffff8000100c6f20:       mov     w1, #0x0                        // #0
    0.00 :   ffff8000100c6f24:       bl      ffff8000100c6a40 <rebalance_domains>
    0.00 :   ffff8000100c6f28:       ldr     x0, [x28, #2376]
    0.00 :   ffff8000100c6f2c:       b       ffff8000100c6e34 <_nohz_idle_balance.isra.127+0x8c>
    0.00 :   ffff8000100c6f30:       adrp    x1, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000100c6f34:       add     x1, x1, #0x980
    0.00 :   ffff8000100c6f38:       b       ffff8000100c6ed8 <_nohz_idle_balance.isra.127+0x130>
         : 10483            update_nohz_stats():
         : 10400            */
    0.00 :   ffff8000100c6f3c:       str     x1, [sp, #104]
    0.00 :   ffff8000100c6f40:       bl      ffff8000100be898 <update_blocked_averages>
         :
    0.00 :   ffff8000100c6f44:       ldr     w0, [x28, #32]
    0.00 :   ffff8000100c6f48:       ldr     w1, [sp, #100]
    0.00 :   ffff8000100c6f4c:       cmp     w0, #0x0
    0.00 :   ffff8000100c6f50:       cset    w0, ne  // ne = any
    0.00 :   ffff8000100c6f54:       orr     w0, w1, w0
    0.00 :   ffff8000100c6f58:       str     w0, [sp, #100]
    0.00 :   ffff8000100c6f5c:       ldr     x1, [sp, #104]
    0.00 :   ffff8000100c6f60:       b       ffff8000100c6ed8 <_nohz_idle_balance.isra.127+0x130>
         : 10411            _nohz_idle_balance():
         :
         : 10489            rq = cpu_rq(balance_cpu);
         :
         : 10491            has_blocked_load |= update_nohz_stats(rq);
         :
         : 10493            /*
    0.00 :   ffff8000100c6f64:       cbz     w21, ffff8000100c6f6c <_nohz_idle_balance.isra.127+0x1c4>
         : 10489            * If time for next balance is due,
    0.00 :   ffff8000100c6f68:       str     x19, [x20, #104]
         : 10491            * do the balance.
         : 10492            */
    0.00 :   ffff8000100c6f6c:       ldr     x1, [sp, #120]
         : 10496            if (time_after_eq(jiffies, rq->next_balance)) {
         : 10497            struct rq_flags rf;
         :
         : 10499            rq_lock_irqsave(rq, &rf);
         : 10500            update_rq_clock(rq);
    0.00 :   ffff8000100c6f70:       ldr     w0, [sp, #100]
         : 10491            */
    0.00 :   ffff8000100c6f74:       add     x1, x1, #0x8
    0.00 :   ffff8000100c6f78:       str     x1, [x20, #112]
         : 10496            update_rq_clock(rq);
    0.00 :   ffff8000100c6f7c:       cbz     w0, ffff8000100c6fa8 <_nohz_idle_balance.isra.127+0x200>
         : 10497            rq_unlock_irqrestore(rq, &rf);
    0.00 :   ffff8000100c6f80:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c6f84:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c6f88:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c6f8c:       str     w0, [x20, #100]
         :
    0.00 :   ffff8000100c6f90:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c6f94:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c6f98:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c6f9c:       ldp     x29, x30, [sp], #128
    0.00 :   ffff8000100c6fa0:       autiasp
    0.00 :   ffff8000100c6fa4:       ret
    0.00 :   ffff8000100c6fa8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c6fac:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c6fb0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c6fb4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c6fb8:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c6fbc:       ldp     x29, x30, [sp], #128
    0.00 :   ffff8000100c6fc0:       autiasp
    0.00 :   ffff8000100c6fc4:       ret
         : 10491            */
    0.00 :   ffff8000100c6fc8:       ldr     x0, [sp, #120]
    0.00 :   ffff8000100c6fcc:       add     x0, x0, #0x8
    0.00 :   ffff8000100c6fd0:       str     x0, [x21, #48]
         : 10496            update_rq_clock(rq);
    0.00 :   ffff8000100c6fd4:       b       ffff8000100c6f90 <_nohz_idle_balance.isra.127+0x1e8>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010972810 <hclge_update_link_status>:
         : 6                hclge_update_link_status():
         : 2906             struct hclge_vport *vport;
         : 2907             int ret;
         : 2908             u16 i;
         :
         : 2910             for (i = 0; i < pci_num_vf(hdev->pdev); i++) {
         : 2911             vport = &hdev->vport[i + HCLGE_VF_VPORT_START_NUM];
    0.00 :   ffff800010972810:       paciasp
    0.00 :   ffff800010972814:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff800010972818:       mov     x29, sp
    0.00 :   ffff80001097281c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010972820:       mov     x19, x0
    0.00 :   ffff800010972824:       stp     x21, x22, [sp, #32]
    0.00 :   ffff800010972828:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001097282c:       add     x21, x21, #0x948
         :
         : 2911             if (!test_bit(HCLGE_VPORT_STATE_ALIVE, &vport->state) ||
         : 2912             vport->vf_info.link_state != IFLA_VF_LINK_STATE_AUTO)
         : 2913             continue;
    0.00 :   ffff800010972830:       ldr     x20, [x19, #1520]
         : 2906             vport = &hdev->vport[i + HCLGE_VF_VPORT_START_NUM];
    0.00 :   ffff800010972834:       ldr     x0, [x21]
    0.00 :   ffff800010972838:       str     x0, [sp, #72]
    0.00 :   ffff80001097283c:       mov     x0, #0x0                        // #0
         :
         : 2915             ret = hclge_push_vf_link_status(vport);
         : 2916             if (ret) {
         : 2917             dev_err(&hdev->pdev->dev,
    0.00 :   ffff800010972840:       cbz     x20, ffff80001097284c <hclge_update_link_status+0x3c>
         : 2919             test_and_set_bit():
         : 38               {
         : 39               long old;
         : 40               unsigned long mask = BIT_MASK(nr);
         :
         : 42               p += BIT_WORD(nr);
         : 43               if (READ_ONCE(*p) & mask)
    0.00 :   ffff800010972844:       ldr     x0, [x19, #1000]
    0.00 :   ffff800010972848:       tbz     w0, #13, ffff800010972870 <hclge_update_link_status+0x60>
         : 46               hclge_update_link_status():
         :
         : 2938             if (test_and_set_bit(HCLGE_STATE_LINK_UPDATING, &hdev->state))
         : 2939             return;
         :
         : 2941             ret = hclge_get_mac_phy_link(hdev, &state);
         : 2942             if (ret) {
    0.00 :   ffff80001097284c:       ldr     x1, [sp, #72]
    0.00 :   ffff800010972850:       ldr     x0, [x21]
    0.00 :   ffff800010972854:       eor     x0, x1, x0
    0.00 :   ffff800010972858:       cbnz    x0, ffff800010972a00 <hclge_update_link_status+0x1f0>
    0.00 :   ffff80001097285c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010972860:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010972864:       ldp     x29, x30, [sp], #80
    0.00 :   ffff800010972868:       autiasp
    0.00 :   ffff80001097286c:       ret
    0.00 :   ffff800010972870:       stp     x23, x24, [sp, #48]
         : 2917             }
    0.00 :   ffff800010972874:       add     x22, x19, #0x3e8
         :
    0.00 :   ffff800010972878:       ldr     x24, [x19, #1504]
         : 2909             vport->vf_info.link_state != IFLA_VF_LINK_STATE_AUTO)
    0.00 :   ffff80001097287c:       ldr     x23, [x19, #1528]
         : 2911             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010972880:       b       ffff8000109728ec <hclge_update_link_status+0xdc>
    0.00 :   ffff800010972884:       b       ffff8000109728ec <hclge_update_link_status+0xdc>
         : 46               __lse_atomic64_fetch_or():
         : 203              ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")           \
         : 204              ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")           \
         : 205              ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 207              ATOMIC64_FETCH_OPS(andnot, ldclr)
         : 208              ATOMIC64_FETCH_OPS(or, ldset)
    0.00 :   ffff800010972888:       mov     x0, #0x2000                     // #8192
    0.00 :   ffff80001097288c:       ldsetal x0, x0, [x22]
         : 211              hclge_update_link_status():
         : 2917             }
    0.00 :   ffff800010972890:       tbnz    w0, #13, ffff8000109729f0 <hclge_update_link_status+0x1e0>
         : 2919             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
  100.00 :   ffff800010972894:       ldr     x0, [x19, #1000]
         : 113              hclge_get_mac_phy_link():
         : 2872             dev_err(&hdev->pdev->dev, "get link status cmd failed %d\n",
    0.00 :   ffff800010972898:       str     wzr, [sp, #68]
         : 2870             ret = hclge_cmd_send(&hdev->hw, &desc, 1);
    0.00 :   ffff80001097289c:       ldr     x1, [x19, #80]
         : 2872             test_bit():
    0.00 :   ffff8000109728a0:       ubfx    w0, w0, #1, #1
         : 107              hclge_get_mac_phy_link():
         : 2874             return ret;
    0.00 :   ffff8000109728a4:       cbnz    w0, ffff8000109728f8 <hclge_update_link_status+0xe8>
         : 2877             req = (struct hclge_link_status_cmd *)desc.data;
    0.00 :   ffff8000109728a8:       cbz     x1, ffff8000109728c0 <hclge_update_link_status+0xb0>
    0.00 :   ffff8000109728ac:       ldr     w2, [x1, #992]
    0.00 :   ffff8000109728b0:       cmp     w2, #0x4
    0.00 :   ffff8000109728b4:       b.ne    ffff8000109728fc <hclge_update_link_status+0xec>  // b.any
    0.00 :   ffff8000109728b8:       ldrb    w1, [x1, #989]
    0.00 :   ffff8000109728bc:       tbz     w1, #5, ffff8000109728fc <hclge_update_link_status+0xec>
         :
    0.00 :   ffff8000109728c0:       add     x1, sp, #0x44
    0.00 :   ffff8000109728c4:       mov     x0, x19
    0.00 :   ffff8000109728c8:       bl      ffff80001096b480 <hclge_get_mac_link_status>
         : 2884             hclge_update_link_status():
         : 2921             static void hclge_update_link_status(struct hclge_dev *hdev)
    0.00 :   ffff8000109728cc:       cbz     w0, ffff8000109729f8 <hclge_update_link_status+0x1e8>
         : 2923             arch_static_branch_jump():
    0.00 :   ffff8000109728d0:       b       ffff8000109729dc <hclge_update_link_status+0x1cc>
    0.00 :   ffff8000109728d4:       b       ffff8000109729dc <hclge_update_link_status+0x1cc>
         : 40               __lse_atomic64_andnot():
         : 176              ATOMIC64_OP(andnot, stclr)
    0.00 :   ffff8000109728d8:       mov     x0, #0x2000                     // #8192
    0.00 :   ffff8000109728dc:       add     x1, x19, #0x3e8
    0.00 :   ffff8000109728e0:       stclr   x0, [x1]
    0.00 :   ffff8000109728e4:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000109728e8:       b       ffff80001097284c <hclge_update_link_status+0x3c>
         : 182              __ll_sc_atomic64_fetch_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff8000109728ec:       add     x3, x19, #0x3e8
    0.00 :   ffff8000109728f0:       b       ffff80001097bbd4 <hclge_get_regs_len+0x454>
    0.00 :   ffff8000109728f4:       b       ffff800010972890 <hclge_update_link_status+0x80>
         : 231              hclge_get_mac_phy_link():
         : 2874             return ret;
    0.00 :   ffff8000109728f8:       mov     w0, #0x0                        // #0
         : 2876             hclge_update_link_status():
         : 2926             struct hnae3_client *client = hdev->nic_client;
    0.00 :   ffff8000109728fc:       ldr     w1, [x19, #76]
    0.00 :   ffff800010972900:       cmp     w1, w0
    0.00 :   ffff800010972904:       b.eq    ffff8000109728d0 <hclge_update_link_status+0xc0>  // b.none
         : 2927             int state;
    0.00 :   ffff800010972908:       ldr     x2, [x20, #32]
    0.00 :   ffff80001097290c:       cmp     w0, #0x0
    0.00 :   ffff800010972910:       cset    w1, ne  // ne = any
    0.00 :   ffff800010972914:       add     x0, x24, #0x278
    0.00 :   ffff800010972918:       ldr     x2, [x2, #16]
    0.00 :   ffff80001097291c:       blr     x2
         : 2928             int ret;
    0.00 :   ffff800010972920:       ldr     w1, [sp, #68]
    0.00 :   ffff800010972924:       mov     x0, x19
    0.00 :   ffff800010972928:       cmp     w1, #0x0
    0.00 :   ffff80001097292c:       cset    w1, ne  // ne = any
    0.00 :   ffff800010972930:       bl      ffff800010981cf8 <hclge_config_mac_tnl_int>
         :
    0.00 :   ffff800010972934:       cbz     x23, ffff800010972958 <hclge_update_link_status+0x148>
    0.00 :   ffff800010972938:       ldr     x1, [x23, #32]
    0.00 :   ffff80001097293c:       ldr     w0, [sp, #68]
    0.00 :   ffff800010972940:       ldr     x2, [x1, #16]
    0.00 :   ffff800010972944:       cbz     x2, ffff80001097295c <hclge_update_link_status+0x14c>
         : 2930             if (!client)
    0.00 :   ffff800010972948:       cmp     w0, #0x0
    0.00 :   ffff80001097294c:       add     x0, x24, #0x340
    0.00 :   ffff800010972950:       cset    w1, ne  // ne = any
    0.00 :   ffff800010972954:       blr     x2
    0.00 :   ffff800010972958:       ldr     w0, [sp, #68]
         : 2936             hclge_push_link_status():
         :
    0.00 :   ffff80001097295c:       adrp    x23, ffff80001150b000 <kallsyms_token_index+0x1007a0>
         :
    0.00 :   ffff800010972960:       mov     w20, #0x0                       // #0
         :
    0.00 :   ffff800010972964:       add     x23, x23, #0x4c0
         : 2900             hclge_update_link_status():
         :
    0.00 :   ffff800010972968:       str     w0, [x19, #76]
         : 2933             if (test_and_set_bit(HCLGE_STATE_LINK_UPDATING, &hdev->state))
    0.00 :   ffff80001097296c:       b       ffff8000109729c8 <hclge_update_link_status+0x1b8>
         : 2935             hclge_push_link_status():
         : 2890             if (test_bit(HCLGE_STATE_DOWN, &hdev->state))
    0.00 :   ffff800010972970:       and     x0, x20, #0xffff
    0.00 :   ffff800010972974:       add     x1, x0, #0x1
    0.00 :   ffff800010972978:       ldr     x2, [x19, #1504]
    0.00 :   ffff80001097297c:       add     x0, x1, x1, lsl #3
    0.00 :   ffff800010972980:       lsl     x0, x0, #3
    0.00 :   ffff800010972984:       sub     x0, x0, x1
    0.00 :   ffff800010972988:       add     x0, x2, x0, lsl #4
         : 2898             test_bit():
    0.00 :   ffff80001097298c:       ldr     x1, [x0, #1032]
         : 107              hclge_push_link_status():
         :
    0.00 :   ffff800010972990:       tbz     w1, #0, ffff8000109729c0 <hclge_update_link_status+0x1b0>
    0.00 :   ffff800010972994:       ldr     w1, [x0, #1052]
    0.00 :   ffff800010972998:       cbnz    w1, ffff8000109729c0 <hclge_update_link_status+0x1b0>
         : 2896             return hclge_get_mac_link_status(hdev, link_status);
    0.00 :   ffff80001097299c:       bl      ffff8000109801a8 <hclge_push_vf_link_status>
         : 2897             }
    0.00 :   ffff8000109729a0:       cbz     w0, ffff8000109729c0 <hclge_update_link_status+0x1b0>
         :
    0.00 :   ffff8000109729a4:       ldr     x4, [x19]
    0.00 :   ffff8000109729a8:       mov     w3, w0
    0.00 :   ffff8000109729ac:       mov     w2, w20
    0.00 :   ffff8000109729b0:       mov     x1, x23
    0.00 :   ffff8000109729b4:       add     x0, x4, #0xc0
    0.00 :   ffff8000109729b8:       bl      ffff800010e1fd58 <_dev_err>
    0.00 :   ffff8000109729bc:       nop
         :
    0.00 :   ffff8000109729c0:       add     w20, w20, #0x1
    0.00 :   ffff8000109729c4:       and     w20, w20, #0xffff
    0.00 :   ffff8000109729c8:       ldr     x0, [x19]
    0.00 :   ffff8000109729cc:       bl      ffff800010585888 <pci_num_vf>
    0.00 :   ffff8000109729d0:       cmp     w20, w0
    0.00 :   ffff8000109729d4:       b.lt    ffff800010972970 <hclge_update_link_status+0x160>  // b.tstop
    0.00 :   ffff8000109729d8:       b       ffff8000109728d0 <hclge_update_link_status+0xc0>
         : 2897             __ll_sc_atomic64_andnot():
         : 229              /*
         : 230              * GAS converts the mysterious and undocumented BIC (immediate) alias to
         : 231              * an AND (immediate) instruction with the immediate inverted. We don't
         : 232              * have a constraint for this, so fall back to register.
         : 233              */
         : 234              ATOMIC64_OPS(andnot, bic, )
    0.00 :   ffff8000109729dc:       mov     x0, #0x2000                     // #8192
    0.00 :   ffff8000109729e0:       add     x3, x19, #0x3e8
    0.00 :   ffff8000109729e4:       b       ffff80001097bbf0 <hclge_get_regs_len+0x470>
    0.00 :   ffff8000109729e8:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000109729ec:       b       ffff80001097284c <hclge_update_link_status+0x3c>
    0.00 :   ffff8000109729f0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000109729f4:       b       ffff80001097284c <hclge_update_link_status+0x3c>
    0.00 :   ffff8000109729f8:       ldr     w0, [sp, #68]
    0.00 :   ffff8000109729fc:       b       ffff8000109728fc <hclge_update_link_status+0xec>
    0.00 :   ffff800010972a00:       stp     x23, x24, [sp, #48]
         : 245              hclge_update_link_status():
         : 2937             if (ret) {
    0.00 :   ffff800010972a04:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b3cf0 <get_nohz_timer_target>:
         : 6                get_nohz_timer_target():
         : 655              void update_rq_clock(struct rq *rq)
         : 656              {
         : 657              s64 delta;
         :
         : 659              lockdep_assert_rq_held(rq);
         :
    0.00 :   ffff8000100b3cf0:       paciasp
    0.00 :   ffff8000100b3cf4:       stp     x29, x30, [sp, #-80]!
         : 656              if (rq->clock_update_flags & RQCF_ACT_SKIP)
    0.00 :   ffff8000100b3cf8:       adrp    x0, ffff80001176d000 <cpu_number>
         :
    0.00 :   ffff8000100b3cfc:       mov     x29, sp
    0.00 :   ffff8000100b3d00:       stp     x19, x20, [sp, #16]
         : 656              if (rq->clock_update_flags & RQCF_ACT_SKIP)
    0.00 :   ffff8000100b3d04:       add     x0, x0, #0x0
         : 658              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000100b3d08:       mrs     x1, tpidr_el1
         : 46               get_nohz_timer_target():
         :
    0.00 :   ffff8000100b3d0c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b3d10:       stp     x23, x24, [sp, #48]
         : 656              if (rq->clock_update_flags & RQCF_ACT_SKIP)
    0.00 :   ffff8000100b3d14:       ldr     w19, [x0, x1]
         : 658              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000100b3d18:       nop
         : 28               idle_cpu():
         : 5834             *         - in IRQ context, return from interrupt-handler to
         : 5835             *           preemptible context
         : 5836             *
         : 5837             *       - If the kernel is not preemptible (CONFIG_PREEMPTION is not set)
         : 5838             *         then at the next:
         : 5839             *
    0.00 :   ffff8000100b3d1c:       adrp    x24, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100b3d20:       sxtw    x22, w19
    0.00 :   ffff8000100b3d24:       add     x24, x24, #0x760
    0.00 :   ffff8000100b3d28:       adrp    x20, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100b3d2c:       add     x20, x20, #0xc40
    0.00 :   ffff8000100b3d30:       mov     x21, x20
    0.00 :   ffff8000100b3d34:       ldr     x0, [x24, x22, lsl #3]
    0.00 :   ffff8000100b3d38:       add     x0, x21, x0
         : 5836             *          - cond_resched() call
         : 5837             *          - explicit schedule() call
    0.00 :   ffff8000100b3d3c:       ldr     x2, [x0, #2352]
    0.00 :   ffff8000100b3d40:       ldr     x1, [x0, #2360]
    0.00 :   ffff8000100b3d44:       cmp     x2, x1
    0.00 :   ffff8000100b3d48:       b.eq    ffff8000100b3e30 <get_nohz_timer_target+0x140>  // b.none
         : 5842             get_nohz_timer_target():
         : 685              * Runs from hardirq context with interrupts disabled.
    0.00 :   ffff8000100b3d4c:       mov     w0, w19
    0.00 :   ffff8000100b3d50:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b3d54:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b3d58:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100b3d5c:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000100b3d60:       autiasp
    0.00 :   ffff8000100b3d64:       ret
         : 693              housekeeping_cpu():
         :
         : 56               static inline bool housekeeping_cpu(int cpu, enum hk_flags flags)
         : 57               {
         : 58               #ifdef CONFIG_CPU_ISOLATION
         : 59               if (static_branch_unlikely(&housekeeping_overridden))
         : 60               return housekeeping_test_cpu(cpu, flags);
    0.00 :   ffff8000100b3d68:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000100b3d6c:       mov     w0, w19
    0.00 :   ffff8000100b3d70:       bl      ffff8000100d8b78 <housekeeping_test_cpu>
         : 64               get_nohz_timer_target():
         : 659              #ifdef CONFIG_SCHED_DEBUG
    0.00 :   ffff8000100b3d74:       tst     w0, #0xff
    0.00 :   ffff8000100b3d78:       b.ne    ffff8000100b3d1c <get_nohz_timer_target+0x2c>  // b.any
         : 666              if (delta < 0)
    0.00 :   ffff8000100b3d7c:       adrp    x24, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100b3d80:       add     x24, x24, #0x760
    0.00 :   ffff8000100b3d84:       stp     x25, x26, [sp, #64]
         : 670              rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100b3d88:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              get_nohz_timer_target():
    0.00 :   ffff8000100b3d8c:       adrp    x20, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100b3d90:       ldr     x1, [x24, w19, sxtw #3]
    0.00 :   ffff8000100b3d94:       add     x20, x20, #0xc40
    0.00 :   ffff8000100b3d98:       mov     x0, x20
         : 656              if (rq->clock_update_flags & RQCF_ACT_SKIP)
    0.00 :   ffff8000100b3d9c:       mov     w23, #0xffffffff                // #-1
         : 666              if (delta < 0)
    0.00 :   ffff8000100b3da0:       add     x0, x0, x1
    0.00 :   ffff8000100b3da4:       ldr     x25, [x0, #2472]
    0.00 :   ffff8000100b3da8:       cbz     x25, ffff8000100b3e68 <get_nohz_timer_target+0x178>
    0.00 :   ffff8000100b3dac:       adrp    x22, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b3db0:       add     x22, x22, #0xc30
    0.00 :   ffff8000100b3db4:       add     x26, x25, #0x88
         : 667              return;
    0.00 :   ffff8000100b3db8:       mov     w21, #0xffffffff                // #-1
    0.00 :   ffff8000100b3dbc:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100b3dc0:       bl      ffff8000100d8b38 <housekeeping_cpumask>
    0.00 :   ffff8000100b3dc4:       mov     x1, x26
    0.00 :   ffff8000100b3dc8:       mov     x2, x0
    0.00 :   ffff8000100b3dcc:       mov     w0, w21
    0.00 :   ffff8000100b3dd0:       bl      ffff8000104a75d0 <cpumask_next_and>
    0.00 :   ffff8000100b3dd4:       ldr     w1, [x22]
    0.00 :   ffff8000100b3dd8:       mov     w21, w0
         : 675              idle_cpu():
         : 5834             *
    0.00 :   ffff8000100b3ddc:       mov     x0, x20
         : 5836             get_nohz_timer_target():
         : 667              return;
    0.00 :   ffff8000100b3de0:       cmp     w21, w1
    0.00 :   ffff8000100b3de4:       b.cs    ffff8000100b3e8c <get_nohz_timer_target+0x19c>  // b.hs, b.nlast
         : 669              update_rq_clock_task(rq, delta);
    0.00 :   ffff8000100b3de8:       cmp     w19, w21
    0.00 :   ffff8000100b3dec:       b.eq    ffff8000100b3dbc <get_nohz_timer_target+0xcc>  // b.none
         : 672              idle_cpu():
         : 5834             *
    0.00 :   ffff8000100b3df0:       ldr     x1, [x24, w21, sxtw #3]
    0.00 :   ffff8000100b3df4:       add     x0, x0, x1
         : 5836             *          - explicit schedule() call
    0.00 :   ffff8000100b3df8:       ldr     x2, [x0, #2352]
    0.00 :   ffff8000100b3dfc:       ldr     x1, [x0, #2360]
    0.00 :   ffff8000100b3e00:       cmp     x2, x1
    0.00 :   ffff8000100b3e04:       b.eq    ffff8000100b3e78 <get_nohz_timer_target+0x188>  // b.none
         : 5841             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100b3e08:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              get_nohz_timer_target():
         : 684              * High-resolution timer tick.
    0.00 :   ffff8000100b3e0c:       mov     w19, w21
         : 685              * Runs from hardirq context with interrupts disabled.
    0.00 :   ffff8000100b3e10:       mov     w0, w19
    0.00 :   ffff8000100b3e14:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b3e18:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b3e1c:       ldp     x23, x24, [sp, #48]
         : 690              rcu_read_unlock():
    0.00 :   ffff8000100b3e20:       ldp     x25, x26, [sp, #64]
         : 711              get_nohz_timer_target():
    0.00 :   ffff8000100b3e24:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000100b3e28:       autiasp
    0.00 :   ffff8000100b3e2c:       ret
         : 688              idle_cpu():
         : 5839             *          - return from syscall or exception to user-space
         : 5840             *          - return from interrupt-handler to user-space
         : 5841             *
    0.00 :   ffff8000100b3e30:       ldr     w1, [x0, #4]
    0.00 :   ffff8000100b3e34:       cbnz    w1, ffff8000100b3d4c <get_nohz_timer_target+0x5c>
         : 5843             * WARNING: must be called with preemption disabled!
         : 5844             */
         : 5845             static void __sched notrace __schedule(bool preempt)
         : 5846             {
    0.00 :   ffff8000100b3e38:       ldr     w0, [x0, #104]
    0.00 :   ffff8000100b3e3c:       cbnz    w0, ffff8000100b3d4c <get_nohz_timer_target+0x5c>
         : 5849             rcu_read_lock():
         : 655              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100b3e40:       stp     x25, x26, [sp, #64]
    0.00 :   ffff8000100b3e44:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 658              get_nohz_timer_target():
         : 656              if (rq->clock_update_flags & RQCF_ACT_SKIP)
    0.00 :   ffff8000100b3e48:       mov     w23, w19
         : 666              if (delta < 0)
    0.00 :   ffff8000100b3e4c:       ldr     x0, [x24, x22, lsl #3]
    0.00 :   ffff8000100b3e50:       add     x21, x21, x0
    0.00 :   ffff8000100b3e54:       ldr     x25, [x21, #2472]
         : 656              if (rq->clock_update_flags & RQCF_ACT_SKIP)
    0.00 :   ffff8000100b3e58:       mov     w21, w19
         : 666              if (delta < 0)
    0.00 :   ffff8000100b3e5c:       cbnz    x25, ffff8000100b3dac <get_nohz_timer_target+0xbc>
         : 679              if (hrtimer_active(&rq->hrtick_timer))
    0.00 :   ffff8000100b3e60:       cmn     w21, #0x1
    0.00 :   ffff8000100b3e64:       b.ne    ffff8000100b3e08 <get_nohz_timer_target+0x118>  // b.any
         : 680              hrtimer_cancel(&rq->hrtick_timer);
    0.00 :   ffff8000100b3e68:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100b3e6c:       bl      ffff8000100d8c08 <housekeeping_any_cpu>
    0.00 :   ffff8000100b3e70:       mov     w21, w0
    0.00 :   ffff8000100b3e74:       b       ffff8000100b3e08 <get_nohz_timer_target+0x118>
         : 685              idle_cpu():
         : 5839             *
    0.00 :   ffff8000100b3e78:       ldr     w1, [x0, #4]
    0.00 :   ffff8000100b3e7c:       cbnz    w1, ffff8000100b3e08 <get_nohz_timer_target+0x118>
         : 5843             {
  100.00 :   ffff8000100b3e80:       ldr     w0, [x0, #104]
    0.00 :   ffff8000100b3e84:       cbz     w0, ffff8000100b3dbc <get_nohz_timer_target+0xcc>
    0.00 :   ffff8000100b3e88:       b       ffff8000100b3e08 <get_nohz_timer_target+0x118>
         : 5847             get_nohz_timer_target():
         : 666              if (delta < 0)
    0.00 :   ffff8000100b3e8c:       ldr     x25, [x25]
    0.00 :   ffff8000100b3e90:       cbnz    x25, ffff8000100b3db4 <get_nohz_timer_target+0xc4>
    0.00 :   ffff8000100b3e94:       mov     w21, w23
    0.00 :   ffff8000100b3e98:       b       ffff8000100b3e60 <get_nohz_timer_target+0x170>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010121180 <tick_nohz_idle_exit>:
         : 6                tick_nohz_idle_exit():
         : 1234             }
         :
         : 1236             static void tick_nohz_account_idle_time(struct tick_sched *ts,
         : 1237             ktime_t now)
         : 1238             {
         : 1239             unsigned long ticks;
    0.00 :   ffff800010121180:       paciasp
    0.00 :   ffff800010121184:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010121188:       mov     x29, sp
         : 1243             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
  100.00 :   ffff80001012118c:       mrs     x0, tpidr_el1
         : 46               tick_nohz_idle_exit():
    0.00 :   ffff800010121190:       stp     x19, x20, [sp, #16]
         :
    0.00 :   ffff800010121194:       adrp    x19, ffff800011776000 <timer_bases+0x2380>
    0.00 :   ffff800010121198:       add     x19, x19, #0x6b8
    0.00 :   ffff80001012119c:       add     x19, x19, x0
         : 1234             unsigned long ticks;
    0.00 :   ffff8000101211a0:       stp     x21, x22, [sp, #32]
         : 1236             arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000101211a4:       nop
    0.00 :   ffff8000101211a8:       mov     x0, #0x60                       // #96
         : 29               arch_local_irq_disable():
         : 54               u32 pmr = read_sysreg_s(SYS_ICC_PMR_EL1);
         :
         : 56               WARN_ON_ONCE(pmr != GIC_PRIO_IRQON && pmr != GIC_PRIO_IRQOFF);
         : 57               }
         :
         : 59               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101211ac:       msr     daifset, #0x3
         : 61               tick_nohz_idle_exit():
         : 1241             ts->idle_exittime = now;
         :
         : 1243             if (vtime_accounting_enabled_this_cpu())
         : 1244             return;
         : 1245             /*
         : 1246             * We stopped the tick in idle. Update process times would miss the
    0.00 :   ffff8000101211b0:       ldrb    w0, [x19, #76]
    0.00 :   ffff8000101211b4:       tbz     w0, #0, ffff800010121250 <tick_nohz_idle_exit+0xd0>
         : 1242             * time we slept as update_process_times does only a 1 tick
    0.00 :   ffff8000101211b8:       ldr     x0, [x19, #176]
    0.00 :   ffff8000101211bc:       cbnz    x0, ffff800010121248 <tick_nohz_idle_exit+0xc8>
         : 1244             * accounting. Enforce that this is accounted to idle !
         : 1245             */
    0.00 :   ffff8000101211c0:       ldrb    w0, [x19, #76]
    0.00 :   ffff8000101211c4:       and     w0, w0, #0xfffffffe
    0.00 :   ffff8000101211c8:       strb    w0, [x19, #76]
         : 1245             ticks = jiffies - ts->idle_jiffies;
    0.00 :   ffff8000101211cc:       ubfx    x21, x0, #2, #1
         : 1246             /*
    0.00 :   ffff8000101211d0:       ubfx    x20, x0, #1, #1
         : 1248             * We might be one off. Do not randomly account a huge number of ticks!
         : 1249             */
    0.00 :   ffff8000101211d4:       orr     w0, w21, w20
    0.00 :   ffff8000101211d8:       cbnz    w0, ffff80001012121c <tick_nohz_idle_exit+0x9c>
         : 1252             arch_local_irq_enable():
         : 35               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101211dc:       mov     x0, #0xe0                       // #224
    0.00 :   ffff8000101211e0:       msr     daifclr, #0x3
         : 38               arch_static_branch():
    0.00 :   ffff8000101211e4:       nop
         : 22               tick_nohz_idle_exit():
         : 1258             void tick_nohz_idle_restart_tick(void)
         : 1259             {
         : 1260             struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
         :
         : 1262             if (ts->tick_stopped) {
         : 1263             ktime_t now = ktime_get();
    0.00 :   ffff8000101211e8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101211ec:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101211f0:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101211f4:       autiasp
    0.00 :   ffff8000101211f8:       ret
         : 1269             arch_static_branch():
    0.00 :   ffff8000101211fc:       mov     x0, #0xa0                       // #160
    0.00 :   ffff800010121200:       b       ffff8000101211ac <tick_nohz_idle_exit+0x2c>
         : 23               arch_local_irq_enable():
         : 43               pmr_sync();
    0.00 :   ffff800010121204:       dsb     sy
         : 45               tick_nohz_idle_exit():
    0.00 :   ffff800010121208:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001012120c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010121210:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010121214:       autiasp
    0.00 :   ffff800010121218:       ret
         : 1249             if (ticks && ticks < LONG_MAX)
    0.00 :   ffff80001012121c:       bl      ffff800010110e30 <ktime_get>
    0.00 :   ffff800010121220:       mov     x22, x0
         : 1251             }
    0.00 :   ffff800010121224:       cbz     w21, ffff800010121238 <tick_nohz_idle_exit+0xb8>
         :
    0.00 :   ffff800010121228:       mov     x1, x0
    0.00 :   ffff80001012122c:       mov     x0, x19
    0.00 :   ffff800010121230:       bl      ffff800010120758 <tick_nohz_stop_idle>
         : 1254             {
    0.00 :   ffff800010121234:       cbz     w20, ffff8000101211dc <tick_nohz_idle_exit+0x5c>
         : 1255             struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
    0.00 :   ffff800010121238:       mov     x1, x22
    0.00 :   ffff80001012123c:       mov     x0, x19
    0.00 :   ffff800010121240:       bl      ffff800010120628 <__tick_nohz_idle_restart_tick>
    0.00 :   ffff800010121244:       b       ffff8000101211dc <tick_nohz_idle_exit+0x5c>
         : 1242             * time we slept as update_process_times does only a 1 tick
    0.00 :   ffff800010121248:       brk     #0x800
    0.00 :   ffff80001012124c:       b       ffff8000101211c0 <tick_nohz_idle_exit+0x40>
         : 1241             * We stopped the tick in idle. Update process times would miss the
    0.00 :   ffff800010121250:       brk     #0x800
    0.00 :   ffff800010121254:       b       ffff8000101211b8 <tick_nohz_idle_exit+0x38>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010120298 <update_ts_time_stats>:
         : 6                update_ts_time_stats():
         : 593              {
         : 594              struct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);
         :
         : 596              return ts->tick_stopped;
         : 597              }
         :
    0.00 :   ffff800010120298:       paciasp
    0.00 :   ffff80001012029c:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000101202a0:       mov     x29, sp
    0.00 :   ffff8000101202a4:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101202a8:       mov     x20, x1
    0.00 :   ffff8000101202ac:       mov     x19, x2
    0.00 :   ffff8000101202b0:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101202b4:       mov     x21, x3
         : 596              bool tick_nohz_tick_stopped_cpu(int cpu)
         : 597              {
         : 598              struct tick_sched *ts = per_cpu_ptr(&tick_cpu_sched, cpu);
    0.00 :   ffff8000101202b8:       ldrb    w1, [x1, #76]
    0.00 :   ffff8000101202bc:       tbnz    w1, #2, ffff8000101202f8 <update_ts_time_stats+0x60>
         :
         : 606              /**
         : 607              * tick_nohz_update_jiffies - update jiffies when idle was interrupted
         : 608              *
         : 609              * Called from interrupt entry when the CPU was idle
         : 610              *
    0.00 :   ffff8000101202c0:       cbz     x21, ffff8000101202e4 <update_ts_time_stats+0x4c>
         : 612              ktime_divns():
         : 155              /*
         : 156              * 32-bit implementation cannot handle negative divisors,
         : 157              * so catch them on 64bit as well.
         : 158              */
         : 159              WARN_ON(div < 0);
         : 160              return kt / div;
    0.00 :   ffff8000101202c4:       mov     x2, #0xf7cf                     // #63439
    0.00 :   ffff8000101202c8:       movk    x2, #0xe353, lsl #16
    0.00 :   ffff8000101202cc:       movk    x2, #0x9ba5, lsl #32
    0.00 :   ffff8000101202d0:       movk    x2, #0x20c4, lsl #48
    0.00 :   ffff8000101202d4:       smulh   x2, x19, x2
    0.00 :   ffff8000101202d8:       asr     x2, x2, #7
    0.00 :   ffff8000101202dc:       sub     x19, x2, x19, asr #63
         : 168              update_ts_time_stats():
         : 606              * In case the sched_tick was stopped on this CPU, we have to check if jiffies
    0.00 :   ffff8000101202e0:       str     x19, [x21]
         : 608              * must be updated. Otherwise an interrupt handler could use a stale jiffy
         : 609              * value. We do this unconditionally on any CPU, as we don't know whether the
    0.00 :   ffff8000101202e4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101202e8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101202ec:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101202f0:       autiasp
  100.00 :   ffff8000101202f4:       ret
         :
    0.00 :   ffff8000101202f8:       ldr     x22, [x20, #120]
    0.00 :   ffff8000101202fc:       sub     x22, x2, x22
         : 598              return ts->tick_stopped;
    0.00 :   ffff800010120300:       bl      ffff8000100b6cd0 <nr_iowait_cpu>
    0.00 :   ffff800010120304:       cbz     x0, ffff80001012031c <update_ts_time_stats+0x84>
         : 599              }
    0.00 :   ffff800010120308:       ldr     x0, [x20, #152]
         : 602              * tick_nohz_update_jiffies - update jiffies when idle was interrupted
    0.00 :   ffff80001012030c:       str     x19, [x20, #120]
         : 599              }
    0.00 :   ffff800010120310:       add     x22, x0, x22
    0.00 :   ffff800010120314:       str     x22, [x20, #152]
         : 602              * tick_nohz_update_jiffies - update jiffies when idle was interrupted
    0.00 :   ffff800010120318:       b       ffff8000101202c0 <update_ts_time_stats+0x28>
         : 601              /**
    0.00 :   ffff80001012031c:       ldr     x0, [x20, #144]
         : 602              * tick_nohz_update_jiffies - update jiffies when idle was interrupted
    0.00 :   ffff800010120320:       str     x19, [x20, #120]
         : 601              /**
    0.00 :   ffff800010120324:       add     x22, x0, x22
    0.00 :   ffff800010120328:       str     x22, [x20, #144]
         : 602              * tick_nohz_update_jiffies - update jiffies when idle was interrupted
    0.00 :   ffff80001012032c:       b       ffff8000101202c0 <update_ts_time_stats+0x28>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010016c60 <__switch_to>:
         : 6                __switch_to():
         : 560              start_backtrace(&frame, thread_saved_fp(p), thread_saved_pc(p));
         :
         : 562              do {
         : 563              if (unwind_frame(p, &frame))
         : 564              goto out;
         : 565              if (!in_sched_functions(frame.pc)) {
    0.00 :   ffff800010016c60:       paciasp
    0.00 :   ffff800010016c64:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010016c68:       mov     x29, sp
    0.00 :   ffff800010016c6c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010016c70:       mov     x19, x1
    0.00 :   ffff800010016c74:       str     x21, [sp, #32]
    0.00 :   ffff800010016c78:       mov     x21, x0
         : 563              ret = frame.pc;
         : 564              goto out;
         : 565              }
    0.00 :   ffff800010016c7c:       mov     x0, x1
    0.00 :   ffff800010016c80:       bl      ffff800010015428 <fpsimd_thread_switch>
         : 568              tls_preserve_current_state():
         : 446              * ARM erratum 1418040 handling, affecting the 32bit view of CNTVCT.
    0.00 :   ffff800010016c84:       mrs     x1, tpidr_el0
         : 448              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010016c88:       mrs     x0, sp_el0
         : 26               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010016c8c:       ldr     x3, [x0]
         : 113              tls_preserve_current_state():
    0.00 :   ffff800010016c90:       add     x2, x0, #0xa38
    0.00 :   ffff800010016c94:       add     x0, x0, #0xa30
    0.00 :   ffff800010016c98:       tst     w3, #0x400000
    0.00 :   ffff800010016c9c:       csel    x0, x0, x2, eq  // eq = none
    0.00 :   ffff800010016ca0:       str     x1, [x0]
         : 451              test_bit():
    0.00 :   ffff800010016ca4:       ldr     x0, [x19]
         : 107              tls_thread_switch():
         : 453              struct task_struct *next)
    0.00 :   ffff800010016ca8:       tst     w0, #0x400000
    0.00 :   ffff800010016cac:       b.eq    ffff800010016e28 <__switch_to+0x1c8>  // b.none
         : 454              {
    0.00 :   ffff800010016cb0:       ldr     x0, [x19, #2608]
    0.00 :   ffff800010016cb4:       msr     tpidrro_el0, x0
         : 457              test_bit():
    0.00 :   ffff800010016cb8:       ldr     x0, [x19]
         : 107              tls_thread_switch():
         : 458              if (!IS_ENABLED(CONFIG_ARM64_ERRATUM_1418040))
    0.00 :   ffff800010016cbc:       tst     w0, #0x400000
    0.00 :   ffff800010016cc0:       b.ne    ffff800010016da8 <__switch_to+0x148>  // b.any
    0.00 :   ffff800010016cc4:       ldr     x0, [x19, #2608]
    0.00 :   ffff800010016cc8:       msr     tpidr_el0, x0
         : 463              __switch_to():
         : 565              } while (count++ < 16);
         :
    0.00 :   ffff800010016ccc:       mov     x0, x19
    0.00 :   ffff800010016cd0:       bl      ffff80001002d908 <hw_breakpoint_thread_switch>
         : 569              entry_task_switch():
         : 495              */
    0.00 :   ffff800010016cd4:       adrp    x0, ffff80001176d000 <cpu_number>
    0.00 :   ffff800010016cd8:       add     x0, x0, #0x2a8
         : 498              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010016cdc:       mrs     x1, tpidr_el1
         : 46               entry_task_switch():
    0.00 :   ffff800010016ce0:       str     x19, [x0, x1]
         : 496              ssbs_thread_switch():
         : 471              else
    0.00 :   ffff800010016ce4:       ldr     w0, [x19, #36]
    0.00 :   ffff800010016ce8:       tbnz    w0, #21, ffff800010016cfc <__switch_to+0x9c>
         : 474              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010016cec:       b       ffff800010016e18 <__switch_to+0x1b8>
         : 45               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010016cf0:       nop
         : 23               ssbs_thread_switch():
         : 481              * in-kernel PAC. It will be cleared on kernel exit if needed.
    0.00 :   ffff800010016cf4:       mov     x0, x19
    0.00 :   ffff800010016cf8:       bl      ffff800010026948 <spectre_v4_enable_task_mitigation>
         : 484              test_bit():
    0.00 :   ffff800010016cfc:       ldr     x0, [x21]
    0.00 :   ffff800010016d00:       ldr     x20, [x19]
         : 108              erratum_1418040_thread_switch():
         : 517              ptrauth_thread_switch_user(next);
    0.00 :   ffff800010016d04:       ubfx    w0, w0, #22, #1
         : 515              ssbs_thread_switch(next);
    0.00 :   ffff800010016d08:       ubfx    w20, w20, #22, #1
         : 517              ptrauth_thread_switch_user(next);
    0.00 :   ffff800010016d0c:       cmp     w0, w20
    0.00 :   ffff800010016d10:       b.eq    ffff800010016d3c <__switch_to+0xdc>  // b.none
    0.00 :   ffff800010016d14:       mov     w0, #0x2e                       // #46
    0.00 :   ffff800010016d18:       bl      ffff8000100236e0 <this_cpu_has_cap>
    0.00 :   ffff800010016d1c:       tst     w0, #0xff
    0.00 :   ffff800010016d20:       b.eq    ffff800010016d3c <__switch_to+0xdc>  // b.none
         : 520              * Complete any pending TLB or cache maintenance on this CPU in case
    0.00 :   ffff800010016d24:       mrs     x0, cntkctl_el1
         : 523              * call.
    0.00 :   ffff800010016d28:       orr     x1, x0, #0x2
    0.00 :   ffff800010016d2c:       cmp     w20, #0x0
    0.00 :   ffff800010016d30:       and     x0, x0, #0xfffffffffffffffd
    0.00 :   ffff800010016d34:       csel    x0, x0, x1, ne  // ne = any
         : 527              /*
    0.00 :   ffff800010016d38:       msr     cntkctl_el1, x0
         : 529              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff800010016d3c:       b       ffff800010016dd4 <__switch_to+0x174>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010016d40:       nop
         : 23               arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff800010016d44:       b       ffff800010016db0 <__switch_to+0x150>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010016d48:       nop
         : 23               __switch_to():
         : 578              if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
         : 579              sp -= get_random_int() & ~PAGE_MASK;
         : 580              return sp & ~0xf;
         : 581              }
         :
         : 583              /*
    0.00 :   ffff800010016d4c:       dsb     ish
         : 587              {
         : 588              current->mm->context.flags = is_compat_task() ? MMCF_AARCH32 : 0;
         :
         : 590              ptrauth_thread_init_user();
         : 591              mte_thread_init_user();
         :
  100.00 :   ffff800010016d50:       ldr     x1, [x19, #3560]
    0.00 :   ffff800010016d54:       ldr     x0, [x21, #3560]
    0.00 :   ffff800010016d58:       cmp     x0, x1
    0.00 :   ffff800010016d5c:       b.eq    ffff800010016d88 <__switch_to+0x128>  // b.none
         : 597              update_sctlr_el1():
         :
    0.00 :   ffff800010016d60:       mrs     x2, sctlr_el1
    0.00 :   ffff800010016d64:       mov     x0, #0xffffffffffffdfff         // #-8193
    0.00 :   ffff800010016d68:       movk    x0, #0xb7ff, lsl #16
    0.00 :   ffff800010016d6c:       movk    x0, #0xff3f, lsl #32
    0.00 :   ffff800010016d70:       and     x0, x2, x0
    0.00 :   ffff800010016d74:       orr     x0, x0, x1
    0.00 :   ffff800010016d78:       cmp     x2, x0
    0.00 :   ffff800010016d7c:       b.eq    ffff800010016d84 <__switch_to+0x124>  // b.none
    0.00 :   ffff800010016d80:       msr     sctlr_el1, x0
         :
    0.00 :   ffff800010016d84:       isb
         : 541              __switch_to():
         : 591              if (task_spec_ssb_noexec(current)) {
         : 592              arch_prctl_spec_ctrl_set(current, PR_SPEC_STORE_BYPASS,
         : 593              PR_SPEC_ENABLE);
         : 594              }
    0.00 :   ffff800010016d88:       mov     x1, x19
    0.00 :   ffff800010016d8c:       mov     x0, x21
    0.00 :   ffff800010016d90:       bl      ffff800010014754 <cpu_switch_to>
         : 594              }
         :
         : 596              #ifdef CONFIG_ARM64_TAGGED_ADDR_ABI
    0.00 :   ffff800010016d94:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010016d98:       ldr     x21, [sp, #32]
    0.00 :   ffff800010016d9c:       ldp     x29, x30, [sp], #48
    0.00 :   ffff800010016da0:       autiasp
    0.00 :   ffff800010016da4:       ret
         : 602              tls_thread_switch():
         : 458              if (!IS_ENABLED(CONFIG_ARM64_ERRATUM_1418040))
    0.00 :   ffff800010016da8:       ldr     x0, [x19, #2616]
    0.00 :   ffff800010016dac:       b       ffff800010016cc8 <__switch_to+0x68>
         : 461              test_bit():
    0.00 :   ffff800010016db0:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010016db4:       ldr     x0, [x0, #1296]
         : 108              ptrauth_keys_install_user():
         : 53               __ptrauth_key_install_nosync(APIB, keys->apib);
         : 54               __ptrauth_key_install_nosync(APDA, keys->apda);
         : 55               __ptrauth_key_install_nosync(APDB, keys->apdb);
         : 56               }
         :
         : 58               if (system_supports_generic_auth())
    0.00 :   ffff800010016db8:       tst     w0, #0x10000
    0.00 :   ffff800010016dbc:       b.eq    ffff800010016d4c <__switch_to+0xec>  // b.none
         : 54               __ptrauth_key_install_nosync(APGA, keys->apga);
    0.00 :   ffff800010016dc0:       ldr     x0, [x19, #3528]
    0.00 :   ffff800010016dc4:       msr     apgakeylo_el1, x0
    0.00 :   ffff800010016dc8:       ldr     x0, [x19, #3536]
    0.00 :   ffff800010016dcc:       msr     apgakeyhi_el1, x0
    0.00 :   ffff800010016dd0:       b       ffff800010016d4c <__switch_to+0xec>
         : 60               test_bit():
    0.00 :   ffff800010016dd4:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010016dd8:       ldr     x0, [x0, #1296]
         : 108              ptrauth_keys_install_user():
         : 47               if (system_supports_address_auth()) {
    0.00 :   ffff800010016ddc:       tst     w0, #0x8
    0.00 :   ffff800010016de0:       b.eq    ffff800010016d44 <__switch_to+0xe4>  // b.none
         : 48               __ptrauth_key_install_nosync(APIB, keys->apib);
    0.00 :   ffff800010016de4:       ldr     x0, [x19, #3480]
    0.00 :   ffff800010016de8:       msr     apibkeylo_el1, x0
    0.00 :   ffff800010016dec:       ldr     x0, [x19, #3488]
    0.00 :   ffff800010016df0:       msr     apibkeyhi_el1, x0
         : 49               __ptrauth_key_install_nosync(APDA, keys->apda);
    0.00 :   ffff800010016df4:       ldr     x0, [x19, #3496]
    0.00 :   ffff800010016df8:       msr     apdakeylo_el1, x0
    0.00 :   ffff800010016dfc:       ldr     x0, [x19, #3504]
    0.00 :   ffff800010016e00:       msr     apdakeyhi_el1, x0
         : 50               __ptrauth_key_install_nosync(APDB, keys->apdb);
    0.00 :   ffff800010016e04:       ldr     x0, [x19, #3512]
    0.00 :   ffff800010016e08:       msr     apdbkeylo_el1, x0
    0.00 :   ffff800010016e0c:       ldr     x0, [x19, #3520]
    0.00 :   ffff800010016e10:       msr     apdbkeyhi_el1, x0
    0.00 :   ffff800010016e14:       b       ffff800010016d44 <__switch_to+0xe4>
         : 56               test_bit():
    0.00 :   ffff800010016e18:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010016e1c:       ldr     x0, [x0, #1296]
         : 108              ssbs_thread_switch():
         : 478              {
    0.00 :   ffff800010016e20:       tbz     x0, #39, ffff800010016cf4 <__switch_to+0x94>
    0.00 :   ffff800010016e24:       b       ffff800010016cfc <__switch_to+0x9c>
         : 481              arch_static_branch_jump():
         : 38               asm_volatile_goto(
    0.00 :   ffff800010016e28:       b       ffff800010016e38 <__switch_to+0x1d8>
         : 40               arch_static_branch():
         : 21               asm_volatile_goto(
    0.00 :   ffff800010016e2c:       nop
         : 23               tls_thread_switch():
         : 456              u64 val;
    0.00 :   ffff800010016e30:       msr     tpidrro_el0, xzr
    0.00 :   ffff800010016e34:       b       ffff800010016cb8 <__switch_to+0x58>
         : 459              test_bit():
    0.00 :   ffff800010016e38:       adrp    x0, ffff800011f1e000 <reset_devices>
    0.00 :   ffff800010016e3c:       ldr     x0, [x0, #1296]
         : 108              tls_thread_switch():
         : 455              bool prev32, next32;
    0.00 :   ffff800010016e40:       tbnz    x0, #41, ffff800010016cb8 <__switch_to+0x58>
         : 456              u64 val;
    0.00 :   ffff800010016e44:       msr     tpidrro_el0, xzr
    0.00 :   ffff800010016e48:       b       ffff800010016cb8 <__switch_to+0x58>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001024dce0 <do_sys_poll>:
         : 6                do_sys_poll():
         : 972              #define N_STACK_PPS ((sizeof(stack_pps) - sizeof(struct poll_list))  / \
         : 973              sizeof(struct pollfd))
         :
         : 975              static int do_sys_poll(struct pollfd __user *ufds, unsigned int nfds,
         : 976              struct timespec64 *end_time)
         : 977              {
    0.00 :   ffff80001024dce0:       paciasp
    0.00 :   ffff80001024dce4:       sub     sp, sp, #0x420
    0.00 :   ffff80001024dce8:       adrp    x3, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001024dcec:       add     x4, x3, #0x948
         : 982              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001024dcf0:       mrs     x3, sp_el0
         : 26               do_sys_poll():
    0.00 :   ffff80001024dcf4:       stp     x29, x30, [sp]
    0.00 :   ffff80001024dcf8:       mov     x29, sp
    0.00 :   ffff80001024dcfc:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001024dd00:       stp     x23, x24, [sp, #48]
         : 981              faster - use long to make sure the buffer is aligned properly
         : 982              on 64 bit archs to avoid unaligned access */
         : 983              long stack_pps[POLL_STACK_ALLOC/sizeof(long)];
         : 984              struct poll_list *const head = (struct poll_list *)stack_pps;
         : 985              struct poll_list *walk = head;
         : 986              unsigned long todo = nfds;
    0.00 :   ffff80001024dd04:       mov     w23, w1
         : 988              task_rlimit():
         :
         : 716              static inline void unlock_task_sighand(struct task_struct *task,
         : 717              unsigned long *flags)
         : 718              {
         : 719              spin_unlock_irqrestore(&task->sighand->siglock, *flags);
         : 720              }
    0.00 :   ffff80001024dd08:       ldr     x3, [x3, #1624]
         : 722              do_sys_poll():
         : 972              {
    0.00 :   ffff80001024dd0c:       ldr     x5, [x4]
    0.00 :   ffff80001024dd10:       str     x5, [sp, #1048]
    0.00 :   ffff80001024dd14:       mov     x5, #0x0                        // #0
         : 981              unsigned long todo = nfds;
    0.00 :   ffff80001024dd18:       stp     x0, x23, [sp, #96]
         : 983              task_rlimit():
    0.00 :   ffff80001024dd1c:       ldr     x0, [x3, #784]
         : 716              do_sys_poll():
         : 972              {
    0.00 :   ffff80001024dd20:       stp     x2, x4, [sp, #136]
         :
         : 984              if (nfds > rlimit(RLIMIT_NOFILE))
    0.00 :   ffff80001024dd24:       cmp     x23, x0
    0.00 :   ffff80001024dd28:       b.hi    ffff80001024e240 <do_sys_poll+0x560>  // b.pmore
         : 986              return -EINVAL;
         :
         : 988              len = min_t(unsigned int, nfds, N_STACK_PPS);
    0.00 :   ffff80001024dd2c:       cmp     w1, #0x1e
    0.00 :   ffff80001024dd30:       mov     w21, #0x1e                      // #30
         : 980              struct poll_list *walk = head;
    0.00 :   ffff80001024dd34:       add     x22, sp, #0xa8
         : 986              len = min_t(unsigned int, nfds, N_STACK_PPS);
    0.00 :   ffff80001024dd38:       csel    w21, w1, w21, ls  // ls = plast
    0.00 :   ffff80001024dd3c:       stp     x19, x20, [sp, #16]
         : 989              __range_ok():
         : 51               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
         : 52               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
         : 53               addr = untagged_addr(addr);
         :
         : 55               __chk_user_ptr(addr);
         : 56               asm volatile(
    0.00 :   ffff80001024dd40:       mov     x19, #0xffffffffffff            // #281474976710655
         : 58               do_sys_poll():
         :
         : 1002             todo -= walk->len;
         : 1003             if (!todo)
         : 1004             break;
         :
         : 1006             len = min(todo, POLLFD_PER_PAGE);
    0.00 :   ffff80001024dd44:       mov     x20, #0x1fe                     // #510
    0.00 :   ffff80001024dd48:       b       ffff80001024dda4 <do_sys_poll+0xc4>
         : 1009             sign_extend64():
         : 182              * @index: 0 based bit index (0<=index<64) to sign bit
         : 183              */
         : 184              static __always_inline __s64 sign_extend64(__u64 value, int index)
         : 185              {
         : 186              __u8 shift = 63 - index;
         : 187              return (__s64)(value << shift) >> shift;
    0.00 :   ffff80001024dd4c:       sbfx    x2, x0, #0, #56
         : 189              __uaccess_mask_ptr():
         : 244              asm volatile(
         : 245              "       bics    xzr, %3, %2\n"
         : 246              "       csel    %0, %1, xzr, eq\n"
         : 247              : "=&r" (safe_ptr)
         : 248              : "r" (ptr), "r" (TASK_SIZE_MAX - 1),
         : 249              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024dd50:       and     x2, x0, x2
         : 239              asm volatile(
    0.00 :   ffff80001024dd54:       bics    xzr, x2, x19
    0.00 :   ffff80001024dd58:       csel    x1, x0, xzr, eq  // eq = none
         : 247              : "cc");
         :
         : 249              csdb();
    0.00 :   ffff80001024dd5c:       csdb
         : 251              _copy_from_user():
         : 159              {
         : 160              unsigned long res = n;
         : 161              might_fault();
         : 162              if (!should_fail_usercopy() && likely(access_ok(from, n))) {
         : 163              instrument_copy_from_user(to, from, n);
         : 164              res = raw_copy_from_user(to, from, n);
    0.00 :   ffff80001024dd60:       mov     x2, x21
    0.00 :   ffff80001024dd64:       mov     x0, x24
    0.00 :   ffff80001024dd68:       bl      ffff8000104a4e40 <__arch_copy_from_user>
         : 161              }
         : 162              if (unlikely(res))
    0.00 :   ffff80001024dd6c:       cbnz    x0, ffff80001024e248 <do_sys_poll+0x568>
         : 164              do_sys_poll():
         : 997              todo -= walk->len;
    0.00 :   ffff80001024dd70:       ldrsw   x0, [x22, #8]
         : 998              if (!todo)
    0.00 :   ffff80001024dd74:       subs    x23, x23, x0
    0.00 :   ffff80001024dd78:       b.eq    ffff80001024de64 <do_sys_poll+0x184>  // b.none
         : 1001             len = min(todo, POLLFD_PER_PAGE);
    0.00 :   ffff80001024dd7c:       cmp     x23, #0x1fe
         : 1003             kmalloc():
         : 561              * in one or more of the following additional @flags:
         : 562              *
         : 563              * %__GFP_HIGH
         : 564              *       This allocation has high priority and may use emergency pools.
         : 565              *
         : 566              * %__GFP_NOFAIL
    0.00 :   ffff80001024dd80:       mov     w1, #0xcc0                      // #3264
         : 568              do_sys_poll():
    0.00 :   ffff80001024dd84:       csel    x0, x23, x20, ls  // ls = plast
    0.00 :   ffff80001024dd88:       mov     w21, w0
         : 1003             __ab_c_size():
         : 305              */
         : 306              static inline __must_check size_t __ab_c_size(size_t a, size_t b, size_t c)
         : 307              {
         : 308              size_t bytes;
         :
         : 310              if (check_mul_overflow(a, b, &bytes))
    0.00 :   ffff80001024dd8c:       lsl     x0, x0, #3
         : 312              kmalloc():
    0.00 :   ffff80001024dd90:       add     x0, x0, #0x10
    0.00 :   ffff80001024dd94:       bl      ffff800010208430 <__kmalloc>
         : 563              do_sys_poll():
         : 1002             walk = walk->next = kmalloc(struct_size(walk, entries, len),
    0.00 :   ffff80001024dd98:       str     x0, [x22]
         : 1004             GFP_KERNEL);
         : 1005             if (!walk) {
    0.00 :   ffff80001024dd9c:       mov     x22, x0
    0.00 :   ffff80001024dda0:       cbz     x0, ffff80001024e0d8 <do_sys_poll+0x3f8>
         : 988              walk->next = NULL;
    0.00 :   ffff80001024dda4:       str     xzr, [x22]
         : 989              walk->len = len;
    0.00 :   ffff80001024dda8:       str     w21, [x22, #8]
         : 990              if (!len)
    0.00 :   ffff80001024ddac:       cbz     w21, ffff80001024de64 <do_sys_poll+0x184>
         : 993              if (copy_from_user(walk->entries, ufds + nfds-todo,
    0.00 :   ffff80001024ddb0:       ldp     x3, x0, [sp, #96]
         : 995              get_current():
    0.00 :   ffff80001024ddb4:       mrs     x1, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024ddb8:       ldr     w2, [x1, #36]
         : 49               do_sys_poll():
    0.00 :   ffff80001024ddbc:       sbfiz   x21, x21, #3, #32
    0.00 :   ffff80001024ddc0:       add     x24, x22, #0xc
    0.00 :   ffff80001024ddc4:       sub     x0, x0, x23
    0.00 :   ffff80001024ddc8:       add     x0, x3, x0, lsl #3
         : 997              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024ddcc:       tbnz    w2, #21, ffff80001024dddc <do_sys_poll+0xfc>
         : 48               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001024ddd0:       ldr     x2, [x1]
         : 113              __range_ok():
    0.00 :   ffff80001024ddd4:       mov     x1, x0
    0.00 :   ffff80001024ddd8:       tbz     w2, #26, ffff80001024dde4 <do_sys_poll+0x104>
         : 48               sign_extend64():
    0.00 :   ffff80001024dddc:       sbfx    x1, x0, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024dde0:       and     x1, x0, x1
         : 51               asm volatile(
    0.00 :   ffff80001024dde4:       mov     x2, x19
    0.00 :   ffff80001024dde8:       adds    x1, x1, x21
    0.00 :   ffff80001024ddec:       csel    x2, xzr, x2, hi  // hi = pmore
    0.00 :   ffff80001024ddf0:       csinv   x1, x1, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024ddf4:       sbcs    xzr, x1, x2
    0.00 :   ffff80001024ddf8:       cset    x1, ls  // ls = plast
         : 58               _copy_from_user():
         : 157              if (!should_fail_usercopy() && likely(access_ok(from, n))) {
    0.00 :   ffff80001024ddfc:       cbnz    x1, ffff80001024dd4c <do_sys_poll+0x6c>
         : 162              memset(to + (n - res), 0, res);
    0.00 :   ffff80001024de00:       mov     x2, x21
    0.00 :   ffff80001024de04:       mov     x0, x24
    0.00 :   ffff80001024de08:       mov     w1, #0x0                        // #0
         : 166              do_sys_poll():
         : 974              int err = -EFAULT, fdcount, len;
    0.00 :   ffff80001024de0c:       mov     w21, #0xfffffff2                // #-14
         : 976              _copy_from_user():
    0.00 :   ffff80001024de10:       bl      ffff8000104a5e40 <__memset>
         : 163              do_sys_poll():
         : 1028             }
         : 1029             user_write_access_end();
         :
         : 1031             err = fdcount;
         : 1032             out_fds:
         : 1033             walk = head->next;
    0.00 :   ffff80001024de14:       ldr     x0, [sp, #168]
         : 1029             while (walk) {
    0.00 :   ffff80001024de18:       cbz     x0, ffff80001024de30 <do_sys_poll+0x150>
    0.00 :   ffff80001024de1c:       nop
         : 1031             struct poll_list *pos = walk;
         : 1032             walk = walk->next;
    0.00 :   ffff80001024de20:       ldr     x19, [x0]
         : 1032             kfree(pos);
    0.00 :   ffff80001024de24:       bl      ffff800010206230 <kfree>
    0.00 :   ffff80001024de28:       mov     x0, x19
         : 1029             while (walk) {
    0.00 :   ffff80001024de2c:       cbnz    x19, ffff80001024de20 <do_sys_poll+0x140>
    0.00 :   ffff80001024de30:       ldp     x19, x20, [sp, #16]
         :
         : 1042             Efault:
         : 1043             user_write_access_end();
         : 1044             err = -EFAULT;
         : 1045             goto out_fds;
         : 1046             }
    0.00 :   ffff80001024de34:       mov     w0, w21
    0.00 :   ffff80001024de38:       ldr     x1, [sp, #144]
    0.00 :   ffff80001024de3c:       ldr     x2, [sp, #1048]
    0.00 :   ffff80001024de40:       ldr     x1, [x1]
    0.00 :   ffff80001024de44:       eor     x1, x2, x1
    0.00 :   ffff80001024de48:       cbnz    x1, ffff80001024e258 <do_sys_poll+0x578>
    0.00 :   ffff80001024de4c:       ldp     x29, x30, [sp]
    0.00 :   ffff80001024de50:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001024de54:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001024de58:       add     sp, sp, #0x420
    0.00 :   ffff80001024de5c:       autiasp
    0.00 :   ffff80001024de60:       ret
         : 1059             net_busy_loop_on():
         : 36               extern unsigned int sysctl_net_busy_read __read_mostly;
         : 37               extern unsigned int sysctl_net_busy_poll __read_mostly;
         :
         : 39               static inline bool net_busy_loop_on(void)
         : 40               {
         : 41               return sysctl_net_busy_poll;
    0.00 :   ffff80001024de64:       adrp    x1, ffff800011c2f000 <tegra_xhci_hc_driver+0x100>
         : 43               init_poll_funcptr():
         : 77               return p ? p->_key : ~(__poll_t)0;
         : 78               }
         :
         : 80               static inline void init_poll_funcptr(poll_table *pt, poll_queue_proc qproc)
         : 81               {
         : 82               pt->_qproc = qproc;
    0.00 :   ffff80001024de68:       adrp    x0, ffff80001024c000 <compat_filldir+0x2a0>
         : 78               pt->_key   = ~(__poll_t)0; /* all events enabled */
    0.00 :   ffff80001024de6c:       mov     w3, #0xffffffff                 // #-1
         : 77               pt->_qproc = qproc;
    0.00 :   ffff80001024de70:       add     x0, x0, #0xfd0
         : 79               net_busy_loop_on():
    0.00 :   ffff80001024de74:       ldr     w23, [x1, #1128]
         : 37               do_poll():
         : 888              __poll_t busy_flag = net_busy_loop_on() ? POLL_BUSY_LOOP : 0;
    0.00 :   ffff80001024de78:       mov     w2, #0x8000                     // #32768
         : 890              get_current():
    0.00 :   ffff80001024de7c:       mrs     x1, sp_el0
         : 20               poll_initwait():
         : 124              pwq->polling_task = current;
    0.00 :   ffff80001024de80:       stp     xzr, x1, [sp, #440]
         : 126              do_poll():
         : 888              __poll_t busy_flag = net_busy_loop_on() ? POLL_BUSY_LOOP : 0;
    0.00 :   ffff80001024de84:       cmp     w23, #0x0
    0.00 :   ffff80001024de88:       csel    w23, w23, w2, eq  // eq = none
         : 892              if (end_time && !end_time->tv_sec && !end_time->tv_nsec) {
    0.00 :   ffff80001024de8c:       ldr     x1, [sp, #136]
    0.00 :   ffff80001024de90:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001024de94:       stp     x27, x28, [sp, #80]
         : 896              init_poll_funcptr():
    0.00 :   ffff80001024de98:       str     x0, [sp, #424]
         : 78               pt->_key   = ~(__poll_t)0; /* all events enabled */
    0.00 :   ffff80001024de9c:       str     w3, [sp, #432]
         : 80               poll_initwait():
         : 125              pwq->triggered = 0;
    0.00 :   ffff80001024dea0:       str     xzr, [sp, #456]
         : 128              pwq->inline_index = 0;
    0.00 :   ffff80001024dea4:       str     wzr, [sp, #464]
         : 130              do_poll():
         : 892              if (end_time && !end_time->tv_sec && !end_time->tv_nsec) {
    0.00 :   ffff80001024dea8:       cbz     x1, ffff80001024e0fc <do_sys_poll+0x41c>
    0.00 :   ffff80001024deac:       ldr     x0, [x1]
    0.00 :   ffff80001024deb0:       cbnz    x0, ffff80001024e0e0 <do_sys_poll+0x400>
    0.00 :   ffff80001024deb4:       ldr     x0, [x1, #8]
    0.00 :   ffff80001024deb8:       cbnz    x0, ffff80001024e0e0 <do_sys_poll+0x400>
         : 894              timed_out = 1;
    0.00 :   ffff80001024debc:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001024dec0:       str     w0, [sp, #120]
         : 893              pt->_qproc = NULL;
    0.00 :   ffff80001024dec4:       str     xzr, [sp, #424]
         : 897              if (end_time && !timed_out)
    0.00 :   ffff80001024dec8:       ldr     x0, [sp, #136]
         : 887              u64 slack = 0;
    0.00 :   ffff80001024decc:       str     xzr, [sp, #128]
         : 897              if (end_time && !timed_out)
    0.00 :   ffff80001024ded0:       cmp     x0, #0x0
    0.00 :   ffff80001024ded4:       cset    w0, ne  // ne = any
    0.00 :   ffff80001024ded8:       str     w0, [sp, #124]
         : 949              busy_flag = 0;
    0.00 :   ffff80001024dedc:       str     xzr, [sp, #112]
    0.00 :   ffff80001024dee0:       str     xzr, [sp, #152]
    0.00 :   ffff80001024dee4:       nop
         : 904              for (walk = list; walk != NULL; walk = walk->next) {
    0.00 :   ffff80001024dee8:       add     x19, sp, #0xa8
         : 902              bool can_busy_loop = false;
    0.00 :   ffff80001024deec:       mov     w22, #0x0                       // #0
    0.00 :   ffff80001024def0:       mov     w21, #0x0                       // #0
    0.00 :   ffff80001024def4:       nop
         : 908              pfd_end = pfd + walk->len;
    0.00 :   ffff80001024def8:       ldrsw   x20, [x19, #8]
         : 907              pfd = walk->entries;
    0.00 :   ffff80001024defc:       add     x28, x19, #0xc
         : 908              pfd_end = pfd + walk->len;
    0.00 :   ffff80001024df00:       add     x20, x28, x20, lsl #3
         : 909              for (; pfd != pfd_end; pfd++) {
    0.00 :   ffff80001024df04:       cmp     x28, x20
    0.00 :   ffff80001024df08:       b.eq    ffff80001024dfa0 <do_sys_poll+0x2c0>  // b.none
         : 912              do_pollfd():
         : 877              pollfd->revents = mangle_poll(mask);
    0.00 :   ffff80001024df0c:       mov     w24, #0x20                      // #32
    0.00 :   ffff80001024df10:       b       ffff80001024df88 <do_sys_poll+0x2a8>
         : 880              fdget():
         : 65               return (struct fd){(struct file *)(v & ~3),v & 3};
         : 66               }
         :
         : 68               static inline struct fd fdget(unsigned int fd)
         : 69               {
         : 70               return __to_fd(__fdget(fd));
    0.00 :   ffff80001024df14:       bl      ffff800010259908 <__fdget>
    0.00 :   ffff80001024df18:       mov     x25, x0
         : 73               do_pollfd():
         : 863              if (!f.file)
    0.00 :   ffff80001024df1c:       ands    x26, x0, #0xfffffffffffffffc
    0.00 :   ffff80001024df20:       b.eq    ffff80001024e118 <do_sys_poll+0x438>  // b.none
         : 866              vfs_poll():
         : 88               return file->f_op->poll;
         : 89               }
         :
         : 91               static inline __poll_t vfs_poll(struct file *file, struct poll_table_struct *pt)
         : 92               {
         : 93               if (unlikely(!file->f_op->poll))
    0.00 :   ffff80001024df24:       ldr     x0, [x26, #40]
         : 95               do_pollfd():
         : 867              filter = demangle_poll(pollfd->events) | EPOLLERR | EPOLLHUP;
    0.00 :   ffff80001024df28:       mov     w1, #0x27ff                     // #10239
    0.00 :   ffff80001024df2c:       ldrh    w3, [x28, #4]
    0.00 :   ffff80001024df30:       and     w3, w3, w1
         : 871              vfs_poll():
  100.00 :   ffff80001024df34:       ldr     x6, [x0, #72]
         : 89               do_pollfd():
    0.00 :   ffff80001024df38:       orr     w27, w3, #0x18
         : 868              pwait->_key = filter | busy_flag;
    0.00 :   ffff80001024df3c:       orr     w0, w27, w23
    0.00 :   ffff80001024df40:       str     w0, [sp, #432]
         : 871              vfs_poll():
    0.00 :   ffff80001024df44:       cbz     x6, ffff80001024e110 <do_sys_poll+0x430>
         : 90               return DEFAULT_POLLMASK;
         : 91               return file->f_op->poll(file, pt);
    0.00 :   ffff80001024df48:       add     x1, sp, #0x1a8
    0.00 :   ffff80001024df4c:       mov     x0, x26
    0.00 :   ffff80001024df50:       blr     x6
         : 95               do_pollfd():
         : 871              *can_busy_poll = true;
    0.00 :   ffff80001024df54:       tst     w0, w23
         : 872              mask &= filter;         /* Mask out unneeded events. */
    0.00 :   ffff80001024df58:       and     w27, w27, w0
         : 871              *can_busy_poll = true;
    0.00 :   ffff80001024df5c:       csinc   w22, w22, wzr, eq  // eq = none
         : 873              fdput():
         : 45               if (fd.flags & FDPUT_FPUT)
    0.00 :   ffff80001024df60:       tbnz    w25, #0, ffff80001024e104 <do_sys_poll+0x424>
         : 47               do_pollfd():
         : 877              pollfd->revents = mangle_poll(mask);
    0.00 :   ffff80001024df64:       strh    w27, [x28, #6]
         : 879              do_poll():
         : 917              if (do_pollfd(pfd, pt, &can_busy_loop,
    0.00 :   ffff80001024df68:       cbz     w27, ffff80001024df7c <do_sys_poll+0x29c>
         : 919              count++;
    0.00 :   ffff80001024df6c:       add     w21, w21, #0x1
         : 923              can_busy_loop = false;
    0.00 :   ffff80001024df70:       mov     w22, #0x0                       // #0
         : 922              busy_flag = 0;
    0.00 :   ffff80001024df74:       mov     w23, #0x0                       // #0
         : 920              pt->_qproc = NULL;
    0.00 :   ffff80001024df78:       str     xzr, [sp, #424]
         : 909              for (; pfd != pfd_end; pfd++) {
    0.00 :   ffff80001024df7c:       add     x28, x28, #0x8
    0.00 :   ffff80001024df80:       cmp     x20, x28
    0.00 :   ffff80001024df84:       b.eq    ffff80001024dfa0 <do_sys_poll+0x2c0>  // b.none
         : 913              do_pollfd():
         : 855              int fd = pollfd->fd;
    0.00 :   ffff80001024df88:       ldr     w0, [x28]
         : 859              if (fd < 0)
    0.00 :   ffff80001024df8c:       tbz     w0, #31, ffff80001024df14 <do_sys_poll+0x234>
         : 877              pollfd->revents = mangle_poll(mask);
    0.00 :   ffff80001024df90:       strh    wzr, [x28, #6]
         : 879              do_poll():
         : 909              for (; pfd != pfd_end; pfd++) {
    0.00 :   ffff80001024df94:       add     x28, x28, #0x8
    0.00 :   ffff80001024df98:       cmp     x20, x28
    0.00 :   ffff80001024df9c:       b.ne    ffff80001024df88 <do_sys_poll+0x2a8>  // b.any
         : 904              for (walk = list; walk != NULL; walk = walk->next) {
    0.00 :   ffff80001024dfa0:       ldr     x19, [x19]
    0.00 :   ffff80001024dfa4:       cbnz    x19, ffff80001024def8 <do_sys_poll+0x218>
         : 931              pt->_qproc = NULL;
    0.00 :   ffff80001024dfa8:       str     xzr, [sp, #424]
         : 932              if (!count) {
    0.00 :   ffff80001024dfac:       cbnz    w21, ffff80001024e120 <do_sys_poll+0x440>
         : 934              get_current():
    0.00 :   ffff80001024dfb0:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff80001024dfb4:       ldr     x1, [x0]
         : 107              do_poll():
         : 933              count = wait->error;
    0.00 :   ffff80001024dfb8:       ldr     w21, [sp, #460]
         : 935              signal_pending():
         : 370              if (unlikely(test_tsk_thread_flag(p, TIF_NOTIFY_SIGNAL)))
    0.00 :   ffff80001024dfbc:       tbnz    w1, #6, ffff80001024dfc8 <do_sys_poll+0x2e8>
         : 372              test_bit():
    0.00 :   ffff80001024dfc0:       ldr     x0, [x0]
         : 107              do_poll():
         : 934              if (signal_pending(current))
    0.00 :   ffff80001024dfc4:       tbz     w0, #0, ffff80001024e120 <do_sys_poll+0x440>
    0.00 :   ffff80001024dfc8:       mov     w21, #0xfffffdfe                // #-514
         : 937              do_sys_poll():
         : 1012             poll_freewait(&table);
    0.00 :   ffff80001024dfcc:       add     x0, sp, #0x1a8
    0.00 :   ffff80001024dfd0:       bl      ffff80001024ce18 <poll_freewait>
         : 1015             get_current():
    0.00 :   ffff80001024dfd4:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024dfd8:       ldr     w1, [x0, #36]
         : 49               do_sys_poll():
         : 1014             if (!user_write_access_begin(ufds, nfds * sizeof(*ufds)))
    0.00 :   ffff80001024dfdc:       ldr     x2, [sp, #104]
    0.00 :   ffff80001024dfe0:       lsl     x27, x2, #3
         : 1017             __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024dfe4:       tbnz    w1, #21, ffff80001024dff8 <do_sys_poll+0x318>
         : 48               test_bit():
    0.00 :   ffff80001024dfe8:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024dfec:       ldr     x0, [sp, #96]
    0.00 :   ffff80001024dff0:       tst     w1, #0x4000000
    0.00 :   ffff80001024dff4:       b.eq    ffff80001024e004 <do_sys_poll+0x324>  // b.none
         : 49               sign_extend64():
    0.00 :   ffff80001024dff8:       ldr     x1, [sp, #96]
    0.00 :   ffff80001024dffc:       sbfx    x0, x1, #0, #56
         : 184              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024e000:       and     x0, x1, x0
         : 51               asm volatile(
    0.00 :   ffff80001024e004:       mov     x4, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024e008:       mov     x1, x4
    0.00 :   ffff80001024e00c:       adds    x0, x0, x27
    0.00 :   ffff80001024e010:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024e014:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024e018:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024e01c:       cset    x0, ls  // ls = plast
         : 59               do_sys_poll():
         : 1022             unsafe_put_user(fds->revents, &ufds->revents, Efault);
    0.00 :   ffff80001024e020:       mov     w7, #0x0                        // #0
         : 1017             for (walk = head; walk; walk = walk->next) {
    0.00 :   ffff80001024e024:       add     x8, sp, #0xa8
         : 1014             if (!user_write_access_begin(ufds, nfds * sizeof(*ufds)))
    0.00 :   ffff80001024e028:       cbz     x0, ffff80001024e0c8 <do_sys_poll+0x3e8>
         : 1021             for (j = walk->len; j; fds++, ufds++, j--)
    0.00 :   ffff80001024e02c:       ldr     w5, [x8, #8]
         : 1018             struct pollfd *fds = walk->entries;
    0.00 :   ffff80001024e030:       add     x3, x8, #0xc
         : 1021             for (j = walk->len; j; fds++, ufds++, j--)
    0.00 :   ffff80001024e034:       cbz     w5, ffff80001024e200 <do_sys_poll+0x520>
    0.00 :   ffff80001024e038:       ldr     x1, [sp, #96]
    0.00 :   ffff80001024e03c:       sub     w5, w5, #0x1
    0.00 :   ffff80001024e040:       add     x0, x1, #0xe
    0.00 :   ffff80001024e044:       add     x1, x1, #0x6
    0.00 :   ffff80001024e048:       add     x5, x0, w5, uxtw #3
    0.00 :   ffff80001024e04c:       b       ffff80001024e08c <do_sys_poll+0x3ac>
         : 1029             sign_extend64():
    0.00 :   ffff80001024e050:       sbfx    x0, x1, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024e054:       and     x0, x0, x1
         : 239              asm volatile(
    0.00 :   ffff80001024e058:       bics    xzr, x0, x4
    0.00 :   ffff80001024e05c:       csel    x6, x1, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024e060:       csdb
         : 249              do_sys_poll():
         : 1022             unsafe_put_user(fds->revents, &ufds->revents, Efault);
    0.00 :   ffff80001024e064:       mov     w0, w7
    0.00 :   ffff80001024e068:       ldrh    w2, [x3, #6]
    0.00 :   ffff80001024e06c:       sttrh   w2, [x6]
    0.00 :   ffff80001024e070:       cbnz    w0, ffff80001024e0c8 <do_sys_poll+0x3e8>
    0.00 :   ffff80001024e074:       add     x0, x1, #0x2
    0.00 :   ffff80001024e078:       str     x0, [sp, #96]
    0.00 :   ffff80001024e07c:       add     x1, x1, #0x8
         : 1021             for (j = walk->len; j; fds++, ufds++, j--)
    0.00 :   ffff80001024e080:       add     x3, x3, #0x8
    0.00 :   ffff80001024e084:       cmp     x5, x1
    0.00 :   ffff80001024e088:       b.eq    ffff80001024e200 <do_sys_poll+0x520>  // b.none
         : 1025             get_current():
    0.00 :   ffff80001024e08c:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024e090:       ldr     w2, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024e094:       tbnz    w2, #21, ffff80001024e0a4 <do_sys_poll+0x3c4>
         : 48               test_bit():
    0.00 :   ffff80001024e098:       ldr     x2, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024e09c:       mov     x0, x1
    0.00 :   ffff80001024e0a0:       tbz     w2, #26, ffff80001024e0ac <do_sys_poll+0x3cc>
         : 48               sign_extend64():
    0.00 :   ffff80001024e0a4:       sbfx    x0, x1, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024e0a8:       and     x0, x0, x1
         : 51               asm volatile(
    0.00 :   ffff80001024e0ac:       mov     x2, x4
    0.00 :   ffff80001024e0b0:       adds    x0, x0, #0x2
    0.00 :   ffff80001024e0b4:       csel    x2, xzr, x2, hi  // hi = pmore
    0.00 :   ffff80001024e0b8:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024e0bc:       sbcs    xzr, x0, x2
    0.00 :   ffff80001024e0c0:       cset    x0, ls  // ls = plast
         : 58               do_sys_poll():
         : 1022             unsafe_put_user(fds->revents, &ufds->revents, Efault);
    0.00 :   ffff80001024e0c4:       cbnz    x0, ffff80001024e050 <do_sys_poll+0x370>
         : 974              int err = -EFAULT, fdcount, len;
    0.00 :   ffff80001024e0c8:       mov     w21, #0xfffffff2                // #-14
    0.00 :   ffff80001024e0cc:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001024e0d0:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001024e0d4:       b       ffff80001024de14 <do_sys_poll+0x134>
         : 1005             err = -ENOMEM;
    0.00 :   ffff80001024e0d8:       mov     w21, #0xfffffff4                // #-12
    0.00 :   ffff80001024e0dc:       b       ffff80001024de14 <do_sys_poll+0x134>
         : 1008             do_poll():
         : 898              slack = select_estimate_accuracy(end_time);
    0.00 :   ffff80001024e0e0:       ldr     x0, [sp, #136]
    0.00 :   ffff80001024e0e4:       str     wzr, [sp, #120]
    0.00 :   ffff80001024e0e8:       bl      ffff80001024d360 <select_estimate_accuracy>
    0.00 :   ffff80001024e0ec:       str     x0, [sp, #128]
         : 897              if (end_time && !timed_out)
    0.00 :   ffff80001024e0f0:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001024e0f4:       str     w0, [sp, #124]
    0.00 :   ffff80001024e0f8:       b       ffff80001024dedc <do_sys_poll+0x1fc>
         : 886              int timed_out = 0, count = 0;
    0.00 :   ffff80001024e0fc:       str     wzr, [sp, #120]
    0.00 :   ffff80001024e100:       b       ffff80001024dec8 <do_sys_poll+0x1e8>
         : 889              fdput():
         : 46               fput(fd.file);
    0.00 :   ffff80001024e104:       mov     x0, x26
    0.00 :   ffff80001024e108:       bl      ffff8000102355a8 <fput>
    0.00 :   ffff80001024e10c:       b       ffff80001024df64 <do_sys_poll+0x284>
         : 50               vfs_poll():
         : 89               return DEFAULT_POLLMASK;
    0.00 :   ffff80001024e110:       mov     w0, #0x145                      // #325
    0.00 :   ffff80001024e114:       b       ffff80001024df54 <do_sys_poll+0x274>
         : 92               do_pollfd():
         : 877              pollfd->revents = mangle_poll(mask);
    0.00 :   ffff80001024e118:       strh    w24, [x28, #6]
         : 878              return mask;
    0.00 :   ffff80001024e11c:       b       ffff80001024df6c <do_sys_poll+0x28c>
         : 880              do_poll():
         : 937              if (count || timed_out)
    0.00 :   ffff80001024e120:       ldr     w0, [sp, #120]
    0.00 :   ffff80001024e124:       orr     w0, w0, w21
    0.00 :   ffff80001024e128:       str     w0, [sp, #120]
    0.00 :   ffff80001024e12c:       cbnz    w0, ffff80001024dfcc <do_sys_poll+0x2ec>
         : 941              if (can_busy_loop && !need_resched()) {
    0.00 :   ffff80001024e130:       cbz     w22, ffff80001024e158 <do_sys_poll+0x478>
         : 943              get_current():
    0.00 :   ffff80001024e134:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff80001024e138:       ldr     x0, [x0]
         : 107              do_poll():
    0.00 :   ffff80001024e13c:       tbnz    w0, #1, ffff80001024e158 <do_sys_poll+0x478>
         : 942              if (!busy_start) {
    0.00 :   ffff80001024e140:       ldr     x0, [sp, #152]
    0.00 :   ffff80001024e144:       cbz     x0, ffff80001024e1e8 <do_sys_poll+0x508>
         : 945              busy_loop_timeout():
         :
         : 77               /* in poll/select we use the global sysctl_net_ll_poll value */
         : 78               static inline bool busy_loop_timeout(unsigned long start_time)
         : 79               {
         : 80               #ifdef CONFIG_NET_RX_BUSY_POLL
         : 81               unsigned long bp_usec = READ_ONCE(sysctl_net_busy_poll);
    0.00 :   ffff80001024e148:       adrp    x0, ffff800011c2f000 <tegra_xhci_hc_driver+0x100>
    0.00 :   ffff80001024e14c:       ldr     w0, [x0, #1128]
    0.00 :   ffff80001024e150:       mov     w0, w0
         :
         : 79               if (bp_usec) {
    0.00 :   ffff80001024e154:       cbnz    x0, ffff80001024e214 <do_sys_poll+0x534>
         : 81               do_poll():
         : 956              if (end_time && !to) {
    0.00 :   ffff80001024e158:       ldr     x0, [sp, #112]
    0.00 :   ffff80001024e15c:       cmp     x0, #0x0
    0.00 :   ffff80001024e160:       ldr     w0, [sp, #124]
    0.00 :   ffff80001024e164:       ccmp    w0, #0x0, #0x4, eq  // eq = none
    0.00 :   ffff80001024e168:       b.eq    ffff80001024e1a0 <do_sys_poll+0x4c0>  // b.none
         : 957              expire = timespec64_to_ktime(*end_time);
    0.00 :   ffff80001024e16c:       ldr     x1, [sp, #136]
         : 959              ktime_set():
         : 40               *
         : 41               * Return: The ktime_t representation of the value.
         : 42               */
         : 43               static inline ktime_t ktime_set(const s64 secs, const unsigned long nsecs)
         : 44               {
         : 45               if (unlikely(secs >= KTIME_SEC_MAX))
    0.00 :   ffff80001024e170:       mov     x2, #0x7d03                     // #32003
    0.00 :   ffff80001024e174:       movk    x2, #0x25c1, lsl #16
    0.00 :   ffff80001024e178:       movk    x2, #0x2, lsl #32
    0.00 :   ffff80001024e17c:       ldp     x0, x1, [x1]
    0.00 :   ffff80001024e180:       cmp     x0, x2
    0.00 :   ffff80001024e184:       b.gt    ffff80001024e1f8 <do_sys_poll+0x518>
         : 43               return KTIME_MAX;
         :
         : 45               return secs * NSEC_PER_SEC + (s64)nsecs;
    0.00 :   ffff80001024e188:       mov     x2, #0xca00                     // #51712
    0.00 :   ffff80001024e18c:       movk    x2, #0x3b9a, lsl #16
    0.00 :   ffff80001024e190:       madd    x0, x0, x2, x1
         : 49               do_poll():
         : 958              to = &expire;
    0.00 :   ffff80001024e194:       add     x1, sp, #0xa0
    0.00 :   ffff80001024e198:       str     x1, [sp, #112]
         : 957              expire = timespec64_to_ktime(*end_time);
    0.00 :   ffff80001024e19c:       str     x0, [sp, #160]
         : 959              get_current():
    0.00 :   ffff80001024e1a0:       mrs     x19, sp_el0
         : 20               poll_schedule_timeout():
         : 241              set_current_state(state);
    0.00 :   ffff80001024e1a4:       mov     x0, #0x1                        // #1
    0.00 :   ffff80001024e1a8:       str     x0, [x19, #16]
    0.00 :   ffff80001024e1ac:       dmb     ish
         : 242              if (!pwq->triggered)
    0.00 :   ffff80001024e1b0:       ldr     w0, [sp, #456]
    0.00 :   ffff80001024e1b4:       cbnz    w0, ffff80001024e22c <do_sys_poll+0x54c>
         : 243              rc = schedule_hrtimeout_range(expires, slack, HRTIMER_MODE_ABS);
    0.00 :   ffff80001024e1b8:       ldr     x0, [sp, #112]
    0.00 :   ffff80001024e1bc:       mov     w2, #0x0                        // #0
    0.00 :   ffff80001024e1c0:       ldr     x1, [sp, #128]
    0.00 :   ffff80001024e1c4:       bl      ffff800010e341c0 <schedule_hrtimeout_range>
         : 244              __set_current_state(TASK_RUNNING);
    0.00 :   ffff80001024e1c8:       str     xzr, [x19, #16]
         : 257              smp_store_mb(pwq->triggered, 0);
    0.00 :   ffff80001024e1cc:       str     wzr, [sp, #456]
    0.00 :   ffff80001024e1d0:       dmb     ish
         : 260              do_poll():
         : 961              if (!poll_schedule_timeout(wait, TASK_INTERRUPTIBLE, to, slack))
    0.00 :   ffff80001024e1d4:       cmp     w0, #0x0
         : 949              busy_flag = 0;
    0.00 :   ffff80001024e1d8:       mov     w23, #0x0                       // #0
         : 961              if (!poll_schedule_timeout(wait, TASK_INTERRUPTIBLE, to, slack))
    0.00 :   ffff80001024e1dc:       cset    w0, eq  // eq = none
    0.00 :   ffff80001024e1e0:       str     w0, [sp, #120]
    0.00 :   ffff80001024e1e4:       b       ffff80001024dee8 <do_sys_poll+0x208>
         : 965              local_clock():
         : 50               return sched_clock();
         : 51               }
         :
         : 53               static inline u64 local_clock(void)
         : 54               {
         : 55               return sched_clock();
    0.00 :   ffff80001024e1e8:       bl      ffff80001011fee8 <sched_clock>
         : 57               busy_loop_current_time():
         : 66               return (unsigned long)(local_clock() >> 10);
    0.00 :   ffff80001024e1ec:       lsr     x0, x0, #10
    0.00 :   ffff80001024e1f0:       str     x0, [sp, #152]
         : 69               do_poll():
         : 944              continue;
    0.00 :   ffff80001024e1f4:       b       ffff80001024dee8 <do_sys_poll+0x208>
         : 946              ktime_set():
         : 41               return KTIME_MAX;
    0.00 :   ffff80001024e1f8:       mov     x0, #0x7fffffffffffffff         // #9223372036854775807
    0.00 :   ffff80001024e1fc:       b       ffff80001024e194 <do_sys_poll+0x4b4>
         : 44               do_sys_poll():
         : 1017             for (walk = head; walk; walk = walk->next) {
    0.00 :   ffff80001024e200:       ldr     x8, [x8]
    0.00 :   ffff80001024e204:       cbnz    x8, ffff80001024e02c <do_sys_poll+0x34c>
    0.00 :   ffff80001024e208:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001024e20c:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff80001024e210:       b       ffff80001024de14 <do_sys_poll+0x134>
         : 1023             busy_loop_timeout():
         : 79               unsigned long end_time = start_time + bp_usec;
    0.00 :   ffff80001024e214:       ldr     x1, [sp, #152]
    0.00 :   ffff80001024e218:       add     x19, x1, x0
         : 82               local_clock():
    0.00 :   ffff80001024e21c:       bl      ffff80001011fee8 <sched_clock>
         : 51               busy_loop_timeout():
         : 82               unsigned long now = busy_loop_current_time();
         :
         : 84               return time_after(now, end_time);
    0.00 :   ffff80001024e220:       sub     x0, x19, x0, lsr #10
    0.00 :   ffff80001024e224:       tbz     x0, #63, ffff80001024dee8 <do_sys_poll+0x208>
    0.00 :   ffff80001024e228:       b       ffff80001024e158 <do_sys_poll+0x478>
         : 88               poll_schedule_timeout():
         : 244              __set_current_state(TASK_RUNNING);
    0.00 :   ffff80001024e22c:       str     xzr, [x19, #16]
         : 257              smp_store_mb(pwq->triggered, 0);
    0.00 :   ffff80001024e230:       str     wzr, [sp, #456]
    0.00 :   ffff80001024e234:       dmb     ish
         : 260              do_poll():
         : 949              busy_flag = 0;
    0.00 :   ffff80001024e238:       mov     w23, #0x0                       // #0
    0.00 :   ffff80001024e23c:       b       ffff80001024dee8 <do_sys_poll+0x208>
         : 952              do_sys_poll():
         : 984              return -EINVAL;
    0.00 :   ffff80001024e240:       mov     w21, #0xffffffea                // #-22
    0.00 :   ffff80001024e244:       b       ffff80001024de34 <do_sys_poll+0x154>
    0.00 :   ffff80001024e248:       sub     x1, x21, x0
         : 988              _copy_from_user():
         : 159              res = raw_copy_from_user(to, from, n);
    0.00 :   ffff80001024e24c:       mov     x21, x0
    0.00 :   ffff80001024e250:       add     x24, x24, x1
    0.00 :   ffff80001024e254:       b       ffff80001024de00 <do_sys_poll+0x120>
    0.00 :   ffff80001024e258:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001024e25c:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001024e260:       stp     x27, x28, [sp, #80]
         : 166              do_sys_poll():
         : 1041             }
    0.00 :   ffff80001024e264:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c70b0 <nohz_balance_enter_idle>:
         : 6                test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100c70b0:       cmp     w0, #0x0
    0.00 :   ffff8000100c70b4:       add     w1, w0, #0x3f
    0.00 :   ffff8000100c70b8:       csel    w1, w1, w0, lt  // lt = tstop
         : 115              nohz_balance_enter_idle():
         : 10332            if (likely(!rq->nohz_tick_stopped))
         : 10333            return;
         :
         : 10335            rq->nohz_tick_stopped = 0;
         : 10336            cpumask_clear_cpu(rq->cpu, nohz.idle_cpus_mask);
         : 10337            atomic_dec(&nohz.nr_cpus);
    0.00 :   ffff8000100c70bc:       paciasp
    0.00 :   ffff8000100c70c0:       stp     x29, x30, [sp, #-64]!
         : 10340            test_bit():
    0.00 :   ffff8000100c70c4:       adrp    x2, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100c70c8:       asr     w1, w1, #6
         : 108              nohz_balance_enter_idle():
    0.00 :   ffff8000100c70cc:       mov     x29, sp
         : 10333            test_bit():
    0.00 :   ffff8000100c70d0:       add     x2, x2, #0xa70
    0.00 :   ffff8000100c70d4:       sxtw    x1, w1
         : 108              nohz_balance_enter_idle():
    0.00 :   ffff8000100c70d8:       stp     x19, x20, [sp, #16]
         :
    0.00 :   ffff8000100c70dc:       adrp    x20, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c70e0:       add     x20, x20, #0xc40
         : 10332            atomic_dec(&nohz.nr_cpus);
    0.00 :   ffff8000100c70e4:       stp     x21, x22, [sp, #32]
         : 10334            test_bit():
    0.00 :   ffff8000100c70e8:       and     w22, w0, #0x3f
    0.00 :   ffff8000100c70ec:       ldr     x1, [x2, x1, lsl #3]
    0.00 :   ffff8000100c70f0:       lsr     x1, x1, x22
         : 109              nohz_balance_enter_idle():
         : 10338            set_cpu_sd_state_busy(rq->cpu);
         : 10339            }
         :
         : 10341            static void set_cpu_sd_state_idle(int cpu)
         : 10342            {
    0.00 :   ffff8000100c70f4:       tbnz    w1, #0, ffff8000100c710c <nohz_balance_enter_idle+0x5c>
         : 10385            * meantime. We set the nohz.has_blocked flag to trig a check of the
         : 10386            * *_avg. The CPU is already part of nohz.idle_cpus_mask so the clear
         : 10387            * of nohz.has_blocked can only happen after checking the new load
         : 10388            */
         : 10389            if (rq->nohz_tick_stopped)
         : 10390            goto out;
    0.00 :   ffff8000100c70f8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c70fc:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c7100:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000100c7104:       autiasp
    0.00 :   ffff8000100c7108:       ret
    0.00 :   ffff8000100c710c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c7110:       sxtw    x24, w0
         :
    0.00 :   ffff8000100c7114:       adrp    x23, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c7118:       add     x23, x23, #0x760
  100.00 :   ffff8000100c711c:       mov     x19, x24
    0.00 :   ffff8000100c7120:       ldr     x21, [x23, x24, lsl #3]
         : 10338            arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff8000100c7124:       nop
         : 28               nohz_balance_enter_idle():
    0.00 :   ffff8000100c7128:       add     x20, x21, x20
         : 10350            rcu_read_unlock();
    0.00 :   ffff8000100c712c:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c7130:       adrp    x21, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100c7134:       add     x21, x21, #0x7c0
         : 10358            {
    0.00 :   ffff8000100c7138:       ldr     w1, [x20, #96]
         : 10350            rcu_read_unlock();
    0.00 :   ffff8000100c713c:       str     w0, [x20, #32]
         : 10358            {
    0.00 :   ffff8000100c7140:       cbnz    w1, ffff8000100c71e4 <nohz_balance_enter_idle+0x134>
         : 10360            on_null_domain():
         : 10100            next_balance = sd->last_balance + interval;
    0.00 :   ffff8000100c7144:       ldr     x1, [x20, #2472]
         : 10102            nohz_balance_enter_idle():
         :
    0.00 :   ffff8000100c7148:       cbz     x1, ffff8000100c7218 <nohz_balance_enter_idle+0x168>
         : 10364            set_bit():
         : 16               * See Documentation/atomic_bitops.txt for details.
         : 17               */
         :
         : 19               static __always_inline void set_bit(unsigned int nr, volatile unsigned long *p)
         : 20               {
         : 21               p += BIT_WORD(nr);
    0.00 :   ffff8000100c714c:       adrp    x21, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100c7150:       add     x21, x21, #0x7c0
    0.00 :   ffff8000100c7154:       add     x1, x21, #0x40
    0.00 :   ffff8000100c7158:       lsr     w19, w19, #6
         : 26               nohz_balance_enter_idle():
         : 10365            return;
    0.00 :   ffff8000100c715c:       str     w0, [x20, #96]
         : 10367            set_bit():
         : 17               atomic_long_or(BIT_MASK(nr), (atomic_long_t *)p);
    0.00 :   ffff8000100c7160:       mov     x0, #0x1                        // #1
         : 16               p += BIT_WORD(nr);
    0.00 :   ffff8000100c7164:       add     x19, x1, x19, lsl #3
         : 17               atomic_long_or(BIT_MASK(nr), (atomic_long_t *)p);
    0.00 :   ffff8000100c7168:       lsl     x22, x0, x22
         : 19               arch_atomic64_or():
         : 65               {                                                                       \
         : 66               __lse_ll_sc_body(op, i, v);                                     \
         : 67               }
         :
         : 69               ATOMIC64_OP(atomic64_andnot)
         : 70               ATOMIC64_OP(atomic64_or)
    0.00 :   ffff8000100c716c:       bl      ffff8000100bb810 <system_uses_lse_atomics>
    0.00 :   ffff8000100c7170:       tst     w0, #0xff
    0.00 :   ffff8000100c7174:       b.eq    ffff8000100c723c <nohz_balance_enter_idle+0x18c>  // b.none
         : 74               __lse_atomic64_or():
         : 177              : [i] "+r" (i), [v] "+Q" (v->counter)                           \
         : 178              : "r" (v));                                                     \
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
    0.00 :   ffff8000100c7178:       stset   x22, [x19]
         : 184              arch_atomic_add():
         : 28               ATOMIC_OP(atomic_add)
    0.00 :   ffff8000100c717c:       bl      ffff8000100bb810 <system_uses_lse_atomics>
    0.00 :   ffff8000100c7180:       tst     w0, #0xff
    0.00 :   ffff8000100c7184:       b.eq    ffff8000100c7230 <nohz_balance_enter_idle+0x180>  // b.none
         : 32               __lse_atomic_add():
         : 26               ATOMIC_OP(add, stadd)
    0.00 :   ffff8000100c7188:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c718c:       add     x1, x21, #0x60
    0.00 :   ffff8000100c7190:       stadd   w0, [x1]
         : 30               nohz_balance_enter_idle():
         : 10375            */
    0.00 :   ffff8000100c7194:       dmb     ish
         : 10377            rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100c7198:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              set_cpu_sd_state_idle():
         : 10316            sd->nohz_idle = 0;
    0.00 :   ffff8000100c719c:       ldr     x1, [x23, x24, lsl #3]
    0.00 :   ffff8000100c71a0:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100c71a4:       add     x0, x0, #0x880
    0.00 :   ffff8000100c71a8:       ldr     x0, [x0, x1]
         : 10318            atomic_inc(&sd->shared->nr_busy_cpus);
    0.00 :   ffff8000100c71ac:       cbz     x0, ffff8000100c71e0 <nohz_balance_enter_idle+0x130>
    0.00 :   ffff8000100c71b0:       ldr     w1, [x0, #52]
    0.00 :   ffff8000100c71b4:       cbnz    w1, ffff8000100c71e0 <nohz_balance_enter_idle+0x130>
         :
    0.00 :   ffff8000100c71b8:       ldr     x2, [x0, #120]
         : 10320            rcu_read_unlock();
    0.00 :   ffff8000100c71bc:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000100c71c0:       str     w1, [x0, #52]
         :
    0.00 :   ffff8000100c71c4:       add     x3, x2, #0x4
         : 10324            arch_atomic_sub():
         : 30               ATOMIC_OP(atomic_sub)
    0.00 :   ffff8000100c71c8:       bl      ffff8000100bb810 <system_uses_lse_atomics>
    0.00 :   ffff8000100c71cc:       tst     w0, #0xff
    0.00 :   ffff8000100c71d0:       b.eq    ffff8000100c7244 <nohz_balance_enter_idle+0x194>  // b.none
         : 34               __lse_atomic_sub():
         : 113              asm volatile(
    0.00 :   ffff8000100c71d4:       add     x0, x2, #0x4
    0.00 :   ffff8000100c71d8:       neg     w1, w1
    0.00 :   ffff8000100c71dc:       stadd   w1, [x0]
         : 117              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100c71e0:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              nohz_balance_enter_idle():
         : 10384            if (rq->nohz_tick_stopped)
    0.00 :   ffff8000100c71e4:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100c71e8:       str     w0, [x21, #100]
         : 10385            goto out;
    0.00 :   ffff8000100c71ec:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c71f0:       ldp     x21, x22, [sp, #32]
         : 10384            if (rq->nohz_tick_stopped)
    0.00 :   ffff8000100c71f4:       ldp     x23, x24, [sp, #48]
         : 10385            goto out;
    0.00 :   ffff8000100c71f8:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000100c71fc:       autiasp
    0.00 :   ffff8000100c7200:       ret
         : 10389            housekeeping_cpu():
         :
         : 56               static inline bool housekeeping_cpu(int cpu, enum hk_flags flags)
         : 57               {
         : 58               #ifdef CONFIG_CPU_ISOLATION
         : 59               if (static_branch_unlikely(&housekeeping_overridden))
         : 60               return housekeeping_test_cpu(cpu, flags);
    0.00 :   ffff8000100c7204:       mov     w1, #0x8                        // #8
    0.00 :   ffff8000100c7208:       mov     w0, w24
    0.00 :   ffff8000100c720c:       bl      ffff8000100d8b78 <housekeeping_test_cpu>
         : 64               nohz_balance_enter_idle():
         : 10342            sd = rcu_dereference(per_cpu(sd_llc, cpu));
    0.00 :   ffff8000100c7210:       tst     w0, #0xff
    0.00 :   ffff8000100c7214:       b.ne    ffff8000100c7128 <nohz_balance_enter_idle+0x78>  // b.any
         : 10385            goto out;
    0.00 :   ffff8000100c7218:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c721c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c7220:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c7224:       ldp     x29, x30, [sp], #64
    0.00 :   ffff8000100c7228:       autiasp
    0.00 :   ffff8000100c722c:       ret
         : 10392            __ll_sc_atomic_add():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff8000100c7230:       add     x2, x21, #0x60
    0.00 :   ffff8000100c7234:       b       ffff8000100c8310 <sched_group_set_shares+0x778>
    0.00 :   ffff8000100c7238:       b       ffff8000100c7194 <nohz_balance_enter_idle+0xe4>
         : 120              __ll_sc_atomic64_or():
         : 222              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 223              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 224              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 226              ATOMIC64_OPS(and, and, L)
         : 227              ATOMIC64_OPS(or, orr, L)
    0.00 :   ffff8000100c723c:       b       ffff8000100c8328 <sched_group_set_shares+0x790>
    0.00 :   ffff8000100c7240:       b       ffff8000100c717c <nohz_balance_enter_idle+0xcc>
         : 230              __ll_sc_atomic_sub():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000100c7244:       add     x2, x2, #0x4
    0.00 :   ffff8000100c7248:       b       ffff8000100c8340 <sched_group_set_shares+0x7a8>
         : 115              rcu_read_unlock():
    0.00 :   ffff8000100c724c:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              *
    0.00 :   ffff8000100c7250:       b       ffff8000100c71e4 <nohz_balance_enter_idle+0x134>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104a5400 <__arch_copy_to_user>:
         : 6                __arch_copy_to_user():
         : 56               user_stp 9998f, \reg1, \reg2, \ptr, \val
         : 57               .endm
         :
         : 59               end     .req    x5
         : 60               SYM_FUNC_START(__arch_copy_to_user)
         : 61               add     end, x0, x2
    0.00 :   ffff8000104a5400:       add     x5, x0, x2
         : 42               C_l     .req    x11
         : 43               C_h     .req    x12
         : 44               D_l     .req    x13
         : 45               D_h     .req    x14
         :
         : 47               mov     dst, dstin
    0.00 :   ffff8000104a5404:       mov     x6, x0
         : 43               cmp     count, #16
    0.00 :   ffff8000104a5408:       cmp     x2, #0x10
         : 45               /*When memory length is less than 16, the accessed are not aligned.*/
         : 46               b.lo    .Ltiny15
    0.00 :   ffff8000104a540c:       b.cc    ffff8000104a54ac <__arch_copy_to_user+0xac>  // b.lo, b.ul, b.last
         :
         : 48               neg     tmp2, src
    0.00 :   ffff8000104a5410:       neg     x4, x1
         : 48               ands    tmp2, tmp2, #15/* Bytes to reach alignment. */
    0.00 :   ffff8000104a5414:       ands    x4, x4, #0xf
         : 49               b.eq    .LSrcAligned
    0.00 :   ffff8000104a5418:       b.eq    ffff8000104a5460 <__arch_copy_to_user+0x60>  // b.none
         : 50               sub     count, count, tmp2
    0.00 :   ffff8000104a541c:       sub     x2, x2, x4
         : 57               * Copy the leading memory data from src to dst in an increasing
         : 58               * address order.By this way,the risk of overwriting the source
         : 59               * memory data is eliminated when the distance between src and
         : 60               * dst is less than 16. The memory accesses here are alignment.
         : 61               */
         : 62               tbz     tmp2, #0, 1f
    0.00 :   ffff8000104a5420:       tbz     w4, #0, ffff8000104a5430 <__arch_copy_to_user+0x30>
         : 58               ldrb1   tmp1w, src, #1
    0.00 :   ffff8000104a5424:       ldrb    w3, [x1], #1
         : 59               strb1   tmp1w, dst, #1
    0.00 :   ffff8000104a5428:       sttrb   w3, [x6]
    0.00 :   ffff8000104a542c:       add     x6, x6, #0x1
         : 61               1:
         : 62               tbz     tmp2, #1, 2f
    0.00 :   ffff8000104a5430:       tbz     w4, #1, ffff8000104a5440 <__arch_copy_to_user+0x40>
         : 62               ldrh1   tmp1w, src, #2
    0.00 :   ffff8000104a5434:       ldrh    w3, [x1], #2
         : 63               strh1   tmp1w, dst, #2
    0.00 :   ffff8000104a5438:       sttrh   w3, [x6]
    0.00 :   ffff8000104a543c:       add     x6, x6, #0x2
         : 65               2:
         : 66               tbz     tmp2, #2, 3f
    0.00 :   ffff8000104a5440:       tbz     w4, #2, ffff8000104a5450 <__arch_copy_to_user+0x50>
         : 66               ldr1    tmp1w, src, #4
    0.00 :   ffff8000104a5444:       ldr     w3, [x1], #4
         : 67               str1    tmp1w, dst, #4
    0.00 :   ffff8000104a5448:       sttr    w3, [x6]
    0.00 :   ffff8000104a544c:       add     x6, x6, #0x4
         : 69               3:
         : 70               tbz     tmp2, #3, .LSrcAligned
    0.00 :   ffff8000104a5450:       tbz     w4, #3, ffff8000104a5460 <__arch_copy_to_user+0x60>
         : 70               ldr1    tmp1, src, #8
    0.00 :   ffff8000104a5454:       ldr     x3, [x1], #8
         : 71               str1    tmp1, dst, #8
    0.00 :   ffff8000104a5458:       sttr    x3, [x6]
    0.00 :   ffff8000104a545c:       add     x6, x6, #0x8
         :
         : 75               .LSrcAligned:
         : 76               cmp     count, #64
    0.00 :   ffff8000104a5460:       cmp     x2, #0x40
         : 75               b.ge    .Lcpy_over64
    0.00 :   ffff8000104a5464:       b.ge    ffff8000104a54f0 <__arch_copy_to_user+0xf0>  // b.tcont
         : 85               .Ltail63:
         : 86               /*
         : 87               * Copy up to 48 bytes of data. At this point we only need the
         : 88               * bottom 6 bits of count to be accurate.
         : 89               */
         : 90               ands    tmp1, count, #0x30
    0.00 :   ffff8000104a5468:       ands    x3, x2, #0x30
         : 86               b.eq    .Ltiny15
    0.00 :   ffff8000104a546c:       b.eq    ffff8000104a54ac <__arch_copy_to_user+0xac>  // b.none
         : 87               cmp     tmp1w, #0x20
    0.00 :   ffff8000104a5470:       cmp     w3, #0x20
         : 88               b.eq    1f
    0.00 :   ffff8000104a5474:       b.eq    ffff8000104a548c <__arch_copy_to_user+0x8c>  // b.none
         : 89               b.lt    2f
    0.00 :   ffff8000104a5478:       b.lt    ffff8000104a549c <__arch_copy_to_user+0x9c>  // b.tstop
         : 90               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a547c:       ldp     x7, x8, [x1], #16
         : 91               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5480:       sttr    x7, [x6]
    0.00 :   ffff8000104a5484:       sttr    x8, [x6, #8]
    0.00 :   ffff8000104a5488:       add     x6, x6, #0x10
         : 93               1:
         : 94               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a548c:       ldp     x7, x8, [x1], #16
         : 94               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5490:       sttr    x7, [x6]
    0.00 :   ffff8000104a5494:       sttr    x8, [x6, #8]
    0.00 :   ffff8000104a5498:       add     x6, x6, #0x10
         : 96               2:
         : 97               ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a549c:       ldp     x7, x8, [x1], #16
         : 97               stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a54a0:       sttr    x7, [x6]
    0.00 :   ffff8000104a54a4:       sttr    x8, [x6, #8]
    0.00 :   ffff8000104a54a8:       add     x6, x6, #0x10
         : 110              * precondition that src address is at least 16 bytes bigger than dst
         : 111              * address,otherwise some source data will be overwritten when memove
         : 112              * call memcpy directly. To make memmove simpler and decouple the
         : 113              * memcpy's dependency on memmove, withdrew the original process.
         : 114              */
         : 115              tbz     count, #3, 1f
    0.00 :   ffff8000104a54ac:       tbz     w2, #3, ffff8000104a54bc <__arch_copy_to_user+0xbc>
         : 111              ldr1    tmp1, src, #8
    0.00 :   ffff8000104a54b0:       ldr     x3, [x1], #8
         : 112              str1    tmp1, dst, #8
    0.00 :   ffff8000104a54b4:       sttr    x3, [x6]
    0.00 :   ffff8000104a54b8:       add     x6, x6, #0x8
         : 114              1:
         : 115              tbz     count, #2, 2f
    0.00 :   ffff8000104a54bc:       tbz     w2, #2, ffff8000104a54cc <__arch_copy_to_user+0xcc>
         : 115              ldr1    tmp1w, src, #4
    0.00 :   ffff8000104a54c0:       ldr     w3, [x1], #4
         : 116              str1    tmp1w, dst, #4
    0.00 :   ffff8000104a54c4:       sttr    w3, [x6]
    0.00 :   ffff8000104a54c8:       add     x6, x6, #0x4
         : 118              2:
         : 119              tbz     count, #1, 3f
    0.00 :   ffff8000104a54cc:       tbz     w2, #1, ffff8000104a54dc <__arch_copy_to_user+0xdc>
         : 119              ldrh1   tmp1w, src, #2
    0.00 :   ffff8000104a54d0:       ldrh    w3, [x1], #2
         : 120              strh1   tmp1w, dst, #2
    0.00 :   ffff8000104a54d4:       sttrh   w3, [x6]
    0.00 :   ffff8000104a54d8:       add     x6, x6, #0x2
         : 122              3:
         : 123              tbz     count, #0, .Lexitfunc
    0.00 :   ffff8000104a54dc:       tbz     w2, #0, ffff8000104a5610 <__arch_copy_to_user+0x210>
         : 123              ldrb1   tmp1w, src, #1
    0.00 :   ffff8000104a54e0:       ldrb    w3, [x1], #1
         : 124              strb1   tmp1w, dst, #1
    0.00 :   ffff8000104a54e4:       sttrb   w3, [x6]
    0.00 :   ffff8000104a54e8:       add     x6, x6, #0x1
         :
         : 127              b       .Lexitfunc
    0.00 :   ffff8000104a54ec:       b       ffff8000104a5610 <__arch_copy_to_user+0x210>
         :
         : 130              .Lcpy_over64:
         : 131              subs    count, count, #128
    0.00 :   ffff8000104a54f0:       subs    x2, x2, #0x80
         : 130              b.ge    .Lcpy_body_large
    0.00 :   ffff8000104a54f4:       b.ge    ffff8000104a5580 <__arch_copy_to_user+0x180>  // b.tcont
         : 135              /*
         : 136              * Less than 128 bytes to copy, so handle 64 here and then jump
         : 137              * to the tail.
         : 138              */
         : 139              ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a54f8:       ldp     x7, x8, [x1], #16
         : 136              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a54fc:       sttr    x7, [x6]
    0.00 :   ffff8000104a5500:       sttr    x8, [x6, #8]
    0.00 :   ffff8000104a5504:       add     x6, x6, #0x10
         : 137              ldp1    B_l, B_h, src, #16
    0.00 :   ffff8000104a5508:       ldp     x9, x10, [x1], #16
         : 138              ldp1    C_l, C_h, src, #16
    0.00 :   ffff8000104a550c:       ldp     x11, x12, [x1], #16
         : 139              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a5510:       sttr    x9, [x6]
    0.00 :   ffff8000104a5514:       sttr    x10, [x6, #8]
    0.00 :   ffff8000104a5518:       add     x6, x6, #0x10
         : 140              stp1    C_l, C_h, dst, #16
    0.00 :   ffff8000104a551c:       sttr    x11, [x6]
    0.00 :   ffff8000104a5520:       sttr    x12, [x6, #8]
    0.00 :   ffff8000104a5524:       add     x6, x6, #0x10
         : 141              ldp1    D_l, D_h, src, #16
    0.00 :   ffff8000104a5528:       ldp     x13, x14, [x1], #16
         : 142              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a552c:       sttr    x13, [x6]
    0.00 :   ffff8000104a5530:       sttr    x14, [x6, #8]
    0.00 :   ffff8000104a5534:       add     x6, x6, #0x10
         :
         : 145              tst     count, #0x3f
    0.00 :   ffff8000104a5538:       tst     x2, #0x3f
         : 145              b.ne    .Ltail63
    0.00 :   ffff8000104a553c:       b.ne    ffff8000104a5468 <__arch_copy_to_user+0x68>  // b.any
         : 146              b       .Lexitfunc
    0.00 :   ffff8000104a5540:       b       ffff8000104a5610 <__arch_copy_to_user+0x210>
    0.00 :   ffff8000104a5544:       nop
    0.00 :   ffff8000104a5548:       nop
    0.00 :   ffff8000104a554c:       nop
    0.00 :   ffff8000104a5550:       nop
    0.00 :   ffff8000104a5554:       nop
    0.00 :   ffff8000104a5558:       nop
    0.00 :   ffff8000104a555c:       nop
    0.00 :   ffff8000104a5560:       nop
    0.00 :   ffff8000104a5564:       nop
    0.00 :   ffff8000104a5568:       nop
    0.00 :   ffff8000104a556c:       nop
    0.00 :   ffff8000104a5570:       nop
    0.00 :   ffff8000104a5574:       nop
    0.00 :   ffff8000104a5578:       nop
    0.00 :   ffff8000104a557c:       nop
         : 155              * 64 bytes per line this ensures the entire loop is in one line.
         : 156              */
         : 157              .p2align        L1_CACHE_SHIFT
         : 158              .Lcpy_body_large:
         : 159              /* pre-get 64 bytes data. */
         : 160              ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a5580:       ldp     x7, x8, [x1], #16
         : 156              ldp1    B_l, B_h, src, #16
    0.00 :   ffff8000104a5584:       ldp     x9, x10, [x1], #16
         : 157              ldp1    C_l, C_h, src, #16
    0.00 :   ffff8000104a5588:       ldp     x11, x12, [x1], #16
         : 158              ldp1    D_l, D_h, src, #16
    0.00 :   ffff8000104a558c:       ldp     x13, x14, [x1], #16
         : 164              1:
         : 165              /*
         : 166              * interlace the load of next 64 bytes data block with store of the last
         : 167              * loaded 64 bytes data.
         : 168              */
         : 169              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a5590:       sttr    x7, [x6]
  100.00 :   ffff8000104a5594:       sttr    x8, [x6, #8]
    0.00 :   ffff8000104a5598:       add     x6, x6, #0x10
         : 165              ldp1    A_l, A_h, src, #16
    0.00 :   ffff8000104a559c:       ldp     x7, x8, [x1], #16
         : 166              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a55a0:       sttr    x9, [x6]
    0.00 :   ffff8000104a55a4:       sttr    x10, [x6, #8]
    0.00 :   ffff8000104a55a8:       add     x6, x6, #0x10
         : 167              ldp1    B_l, B_h, src, #16
    0.00 :   ffff8000104a55ac:       ldp     x9, x10, [x1], #16
         : 168              stp1    C_l, C_h, dst, #16
    0.00 :   ffff8000104a55b0:       sttr    x11, [x6]
    0.00 :   ffff8000104a55b4:       sttr    x12, [x6, #8]
    0.00 :   ffff8000104a55b8:       add     x6, x6, #0x10
         : 169              ldp1    C_l, C_h, src, #16
    0.00 :   ffff8000104a55bc:       ldp     x11, x12, [x1], #16
         : 170              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a55c0:       sttr    x13, [x6]
    0.00 :   ffff8000104a55c4:       sttr    x14, [x6, #8]
    0.00 :   ffff8000104a55c8:       add     x6, x6, #0x10
         : 171              ldp1    D_l, D_h, src, #16
    0.00 :   ffff8000104a55cc:       ldp     x13, x14, [x1], #16
         : 172              subs    count, count, #64
    0.00 :   ffff8000104a55d0:       subs    x2, x2, #0x40
         : 173              b.ge    1b
    0.00 :   ffff8000104a55d4:       b.ge    ffff8000104a5590 <__arch_copy_to_user+0x190>  // b.tcont
         : 174              stp1    A_l, A_h, dst, #16
    0.00 :   ffff8000104a55d8:       sttr    x7, [x6]
    0.00 :   ffff8000104a55dc:       sttr    x8, [x6, #8]
    0.00 :   ffff8000104a55e0:       add     x6, x6, #0x10
         : 175              stp1    B_l, B_h, dst, #16
    0.00 :   ffff8000104a55e4:       sttr    x9, [x6]
    0.00 :   ffff8000104a55e8:       sttr    x10, [x6, #8]
    0.00 :   ffff8000104a55ec:       add     x6, x6, #0x10
         : 176              stp1    C_l, C_h, dst, #16
    0.00 :   ffff8000104a55f0:       sttr    x11, [x6]
    0.00 :   ffff8000104a55f4:       sttr    x12, [x6, #8]
    0.00 :   ffff8000104a55f8:       add     x6, x6, #0x10
         : 177              stp1    D_l, D_h, dst, #16
    0.00 :   ffff8000104a55fc:       sttr    x13, [x6]
    0.00 :   ffff8000104a5600:       sttr    x14, [x6, #8]
    0.00 :   ffff8000104a5604:       add     x6, x6, #0x10
         :
         : 180              tst     count, #0x3f
    0.00 :   ffff8000104a5608:       tst     x2, #0x3f
         : 180              b.ne    .Ltail63
    0.00 :   ffff8000104a560c:       b.ne    ffff8000104a5468 <__arch_copy_to_user+0x68>  // b.any
         : 58               #include "copy_template.S"
         : 59               mov     x0, #0
    0.00 :   ffff8000104a5610:       mov     x0, #0x0                        // #0
         : 59               ret
    0.00 :   ffff8000104a5614:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104b7060 <memchr_inv>:
         : 6                memchr_inv():
         : 1084             *
         : 1085             * returns the address of the first character other than @c, or %NULL
         : 1086             * if the whole buffer contains just @c.
         : 1087             */
         : 1088             void *memchr_inv(const void *start, int c, size_t bytes)
         : 1089             {
  100.00 :   ffff8000104b7060:       paciasp
         : 1089             u8 value = c;
         : 1090             u64 value64;
         : 1091             unsigned int words, prefix;
         :
         : 1093             if (bytes <= 16)
    0.00 :   ffff8000104b7064:       cmp     x2, #0x10
         : 1085             u8 value = c;
    0.00 :   ffff8000104b7068:       and     w1, w1, #0xff
         : 1089             if (bytes <= 16)
    0.00 :   ffff8000104b706c:       b.ls    ffff8000104b7144 <memchr_inv+0xe4>  // b.plast
         : 1105             value64 |= value64 << 16;
         : 1106             value64 |= value64 << 32;
         : 1107             #endif
         :
         : 1109             prefix = (unsigned long)start % 8;
         : 1110             if (prefix) {
    0.00 :   ffff8000104b7070:       ands    w3, w0, #0x7
    0.00 :   ffff8000104b7074:       b.ne    ffff8000104b710c <memchr_inv+0xac>  // b.any
         : 1116             return r;
         : 1117             start += prefix;
         : 1118             bytes -= prefix;
         : 1119             }
         :
         : 1121             words = bytes / 8;
    0.00 :   ffff8000104b7078:       lsr     x3, x2, #3
         :
         : 1119             while (words) {
    0.00 :   ffff8000104b707c:       cbz     w3, ffff8000104b71c4 <memchr_inv+0x164>
         : 1092             value64 = value;
    0.00 :   ffff8000104b7080:       and     x5, x1, #0xff
         : 1094             value64 *= 0x0101010101010101ULL;
    0.00 :   ffff8000104b7084:       mov     x6, #0x101010101010101          // #72340172838076673
         : 1119             if (*(u64 *)start != value64)
    0.00 :   ffff8000104b7088:       ldr     x4, [x0]
         : 1094             value64 *= 0x0101010101010101ULL;
    0.00 :   ffff8000104b708c:       mul     x5, x5, x6
         : 1119             if (*(u64 *)start != value64)
    0.00 :   ffff8000104b7090:       cmp     x5, x4
    0.00 :   ffff8000104b7094:       b.ne    ffff8000104b7194 <memchr_inv+0x134>  // b.any
    0.00 :   ffff8000104b7098:       sub     w3, w3, #0x1
    0.00 :   ffff8000104b709c:       add     x3, x3, #0x1
    0.00 :   ffff8000104b70a0:       add     x3, x0, x3, lsl #3
    0.00 :   ffff8000104b70a4:       b       ffff8000104b70b4 <memchr_inv+0x54>
    0.00 :   ffff8000104b70a8:       ldr     x4, [x0]
    0.00 :   ffff8000104b70ac:       cmp     x4, x5
    0.00 :   ffff8000104b70b0:       b.ne    ffff8000104b7194 <memchr_inv+0x134>  // b.any
         : 1121             return check_bytes8(start, value, 8);
         : 1122             start += 8;
    0.00 :   ffff8000104b70b4:       add     x0, x0, #0x8
         : 1118             while (words) {
    0.00 :   ffff8000104b70b8:       cmp     x0, x3
    0.00 :   ffff8000104b70bc:       b.ne    ffff8000104b70a8 <memchr_inv+0x48>  // b.any
         : 1121             check_bytes8():
         : 1065             while (bytes) {
    0.00 :   ffff8000104b70c0:       ands    w2, w2, #0x7
    0.00 :   ffff8000104b70c4:       b.eq    ffff8000104b70fc <memchr_inv+0x9c>  // b.none
         : 1066             if (*start != value)
    0.00 :   ffff8000104b70c8:       ldrb    w0, [x3]
    0.00 :   ffff8000104b70cc:       cmp     w0, w1
    0.00 :   ffff8000104b70d0:       b.ne    ffff8000104b7100 <memchr_inv+0xa0>  // b.any
    0.00 :   ffff8000104b70d4:       sub     w2, w2, #0x1
    0.00 :   ffff8000104b70d8:       add     x0, x2, #0x1
    0.00 :   ffff8000104b70dc:       add     x0, x3, x0
    0.00 :   ffff8000104b70e0:       b       ffff8000104b70f0 <memchr_inv+0x90>
    0.00 :   ffff8000104b70e4:       ldrb    w2, [x3]
    0.00 :   ffff8000104b70e8:       cmp     w2, w1
    0.00 :   ffff8000104b70ec:       b.ne    ffff8000104b7100 <memchr_inv+0xa0>  // b.any
         : 1068             start++;
    0.00 :   ffff8000104b70f0:       add     x3, x3, #0x1
         : 1065             while (bytes) {
    0.00 :   ffff8000104b70f4:       cmp     x3, x0
    0.00 :   ffff8000104b70f8:       b.ne    ffff8000104b70e4 <memchr_inv+0x84>  // b.any
         : 1071             return NULL;
    0.00 :   ffff8000104b70fc:       mov     x3, #0x0                        // #0
         : 1073             memchr_inv():
         : 1126             words--;
         : 1127             }
         :
         : 1129             return check_bytes8(start, value, bytes % 8);
         : 1130             }
    0.00 :   ffff8000104b7100:       mov     x0, x3
    0.00 :   ffff8000104b7104:       autiasp
    0.00 :   ffff8000104b7108:       ret
         : 1108             prefix = 8 - prefix;
    0.00 :   ffff8000104b710c:       mov     w5, #0x8                        // #8
    0.00 :   ffff8000104b7110:       sub     w5, w5, w3
    0.00 :   ffff8000104b7114:       add     x4, x0, x5
    0.00 :   ffff8000104b7118:       mov     x3, x0
    0.00 :   ffff8000104b711c:       nop
         : 1114             check_bytes8():
         : 1066             if (*start != value)
    0.00 :   ffff8000104b7120:       ldrb    w0, [x3]
    0.00 :   ffff8000104b7124:       cmp     w0, w1
    0.00 :   ffff8000104b7128:       b.ne    ffff8000104b71b4 <memchr_inv+0x154>  // b.any
         : 1068             start++;
    0.00 :   ffff8000104b712c:       add     x3, x3, #0x1
         : 1065             while (bytes) {
    0.00 :   ffff8000104b7130:       cmp     x3, x4
    0.00 :   ffff8000104b7134:       b.ne    ffff8000104b7120 <memchr_inv+0xc0>  // b.any
         : 1068             memchr_inv():
         : 1113             bytes -= prefix;
    0.00 :   ffff8000104b7138:       sub     x2, x2, x5
    0.00 :   ffff8000104b713c:       mov     x0, x4
    0.00 :   ffff8000104b7140:       b       ffff8000104b7078 <memchr_inv+0x18>
         : 1090             return check_bytes8(start, value, bytes);
    0.00 :   ffff8000104b7144:       mov     w3, w2
         : 1092             check_bytes8():
         : 1065             while (bytes) {
    0.00 :   ffff8000104b7148:       cbz     x2, ffff8000104b70fc <memchr_inv+0x9c>
         : 1066             if (*start != value)
    0.00 :   ffff8000104b714c:       ldrb    w2, [x0]
    0.00 :   ffff8000104b7150:       cmp     w2, w1
    0.00 :   ffff8000104b7154:       b.ne    ffff8000104b7184 <memchr_inv+0x124>  // b.any
    0.00 :   ffff8000104b7158:       sub     w3, w3, #0x1
    0.00 :   ffff8000104b715c:       add     x3, x3, #0x1
    0.00 :   ffff8000104b7160:       add     x3, x0, x3
    0.00 :   ffff8000104b7164:       b       ffff8000104b7174 <memchr_inv+0x114>
    0.00 :   ffff8000104b7168:       ldrb    w2, [x0]
    0.00 :   ffff8000104b716c:       cmp     w2, w1
    0.00 :   ffff8000104b7170:       b.ne    ffff8000104b7184 <memchr_inv+0x124>  // b.any
         : 1068             start++;
    0.00 :   ffff8000104b7174:       add     x0, x0, #0x1
         : 1065             while (bytes) {
    0.00 :   ffff8000104b7178:       cmp     x0, x3
    0.00 :   ffff8000104b717c:       b.ne    ffff8000104b7168 <memchr_inv+0x108>  // b.any
    0.00 :   ffff8000104b7180:       b       ffff8000104b70fc <memchr_inv+0x9c>
         : 1066             if (*start != value)
    0.00 :   ffff8000104b7184:       mov     x3, x0
         : 1068             memchr_inv():
         : 1126             }
    0.00 :   ffff8000104b7188:       autiasp
    0.00 :   ffff8000104b718c:       mov     x0, x3
    0.00 :   ffff8000104b7190:       ret
    0.00 :   ffff8000104b7194:       add     x3, x0, #0x8
         : 1131             check_bytes8():
         : 1066             if (*start != value)
    0.00 :   ffff8000104b7198:       ldrb    w2, [x0]
    0.00 :   ffff8000104b719c:       cmp     w2, w1
    0.00 :   ffff8000104b71a0:       b.ne    ffff8000104b7184 <memchr_inv+0x124>  // b.any
         : 1068             start++;
    0.00 :   ffff8000104b71a4:       add     x0, x0, #0x1
         : 1065             while (bytes) {
    0.00 :   ffff8000104b71a8:       cmp     x0, x3
    0.00 :   ffff8000104b71ac:       b.ne    ffff8000104b7198 <memchr_inv+0x138>  // b.any
    0.00 :   ffff8000104b71b0:       b       ffff8000104b70fc <memchr_inv+0x9c>
         : 1069             memchr_inv():
         : 1110             if (r)
    0.00 :   ffff8000104b71b4:       cbz     x3, ffff8000104b7138 <memchr_inv+0xd8>
         : 1126             }
    0.00 :   ffff8000104b71b8:       mov     x0, x3
    0.00 :   ffff8000104b71bc:       autiasp
    0.00 :   ffff8000104b71c0:       ret
         : 1118             while (words) {
    0.00 :   ffff8000104b71c4:       mov     x3, x0
    0.00 :   ffff8000104b71c8:       b       ffff8000104b70c0 <memchr_inv+0x60>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001010fd88 <hrtimer_start_range_ns>:
         : 6                hrtimer_start_range_ns():
         : 1134             *               relative (HRTIMER_MODE_REL), and pinned (HRTIMER_MODE_PINNED);
         : 1135             *               softirq based mode is considered for debug purpose only!
         : 1136             */
         : 1137             void hrtimer_start_range_ns(struct hrtimer *timer, ktime_t tim,
         : 1138             u64 delta_ns, const enum hrtimer_mode mode)
         : 1139             {
  100.00 :   ffff80001010fd88:       paciasp
    0.00 :   ffff80001010fd8c:       stp     x29, x30, [sp, #-112]!
    0.00 :   ffff80001010fd90:       mov     x29, sp
    0.00 :   ffff80001010fd94:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001010fd98:       mov     x19, x0
    0.00 :   ffff80001010fd9c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001010fda0:       mov     x21, x1
    0.00 :   ffff80001010fda4:       stp     x23, x24, [sp, #48]
    0.00 :   ffff80001010fda8:       adrp    x24, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001010fdac:       add     x24, x24, #0x948
    0.00 :   ffff80001010fdb0:       stp     x25, x26, [sp, #64]
    0.00 :   ffff80001010fdb4:       mov     w23, w3
    0.00 :   ffff80001010fdb8:       ldr     x3, [x24]
    0.00 :   ffff80001010fdbc:       str     x3, [sp, #104]
    0.00 :   ffff80001010fdc0:       mov     x3, #0x0                        // #0
    0.00 :   ffff80001010fdc4:       str     x27, [sp, #80]
         : 1144             * Check whether the HRTIMER_MODE_SOFT bit and hrtimer.is_soft
         : 1145             * match on CONFIG_PREEMPT_RT = n. With PREEMPT_RT check the hard
         : 1146             * expiry mode because unmarked timers are moved to softirq expiry.
         : 1147             */
         : 1148             if (!IS_ENABLED(CONFIG_PREEMPT_RT))
         : 1149             WARN_ON_ONCE(!(mode & HRTIMER_MODE_SOFT) ^ !timer->is_soft);
    0.00 :   ffff80001010fdc8:       eor     x0, x23, #0x4
         : 1134             {
    0.00 :   ffff80001010fdcc:       mov     x26, x2
         : 1144             WARN_ON_ONCE(!(mode & HRTIMER_MODE_SOFT) ^ !timer->is_soft);
    0.00 :   ffff80001010fdd0:       ldrb    w3, [x19, #58]
    0.00 :   ffff80001010fdd4:       ubfx    w0, w0, #2, #1
    0.00 :   ffff80001010fdd8:       cmp     w3, #0x0
    0.00 :   ffff80001010fddc:       cset    w1, eq  // eq = none
    0.00 :   ffff80001010fde0:       cmp     w1, w0
    0.00 :   ffff80001010fde4:       b.ne    ffff800010110000 <hrtimer_start_range_ns+0x278>  // b.any
         : 1148             else
         : 1149             WARN_ON_ONCE(!(mode & HRTIMER_MODE_HARD) ^ !timer->is_hard);
         :
         : 1151             base = lock_hrtimer_base(timer, &flags);
    0.00 :   ffff80001010fde8:       add     x1, sp, #0x60
    0.00 :   ffff80001010fdec:       mov     x0, x19
    0.00 :   ffff80001010fdf0:       bl      ffff80001010f290 <lock_hrtimer_base>
    0.00 :   ffff80001010fdf4:       adrp    x25, ffff800011776000 <timer_bases+0x2380>
         : 1156             remove_hrtimer():
         : 1035             u8 state = timer->state;
    0.00 :   ffff80001010fdf8:       ldrb    w2, [x19, #56]
         : 1037             hrtimer_start_range_ns():
         : 1148             base = lock_hrtimer_base(timer, &flags);
    0.00 :   ffff80001010fdfc:       mov     x20, x0
         : 1150             remove_hrtimer():
         : 1037             if (state & HRTIMER_STATE_ENQUEUED) {
    0.00 :   ffff80001010fe00:       add     x25, x25, #0x180
    0.00 :   ffff80001010fe04:       tbz     w2, #0, ffff80001010fe2c <hrtimer_start_range_ns+0xa4>
         : 1049             reprogram = base->cpu_base == this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff80001010fe08:       ldr     x1, [x20]
         : 1051             __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001010fe0c:       mrs     x3, tpidr_el1
         : 46               remove_hrtimer():
    0.00 :   ffff80001010fe10:       mov     x0, x25
    0.00 :   ffff80001010fe14:       add     x0, x0, x3
    0.00 :   ffff80001010fe18:       cmp     x1, x0
         : 1054             __remove_hrtimer(timer, base, state, reprogram);
    0.00 :   ffff80001010fe1c:       mov     x1, x20
    0.00 :   ffff80001010fe20:       cset    w3, eq  // eq = none
    0.00 :   ffff80001010fe24:       mov     x0, x19
    0.00 :   ffff80001010fe28:       bl      ffff80001010f700 <__remove_hrtimer>
         : 1059             __hrtimer_start_range_ns():
         : 1110             if (mode & HRTIMER_MODE_REL)
    0.00 :   ffff80001010fe2c:       mov     x1, x21
    0.00 :   ffff80001010fe30:       tbz     w23, #0, ffff80001010fe58 <hrtimer_start_range_ns+0xd0>
         : 1111             tim = ktime_add_safe(tim, base->get_time());
    0.00 :   ffff80001010fe34:       ldr     x0, [x20, #48]
    0.00 :   ffff80001010fe38:       blr     x0
         : 1114             ktime_add_safe():
         : 335              if (res < 0 || res < lhs || res < rhs)
    0.00 :   ffff80001010fe3c:       adds    x1, x21, x0
    0.00 :   ffff80001010fe40:       ccmp    x21, x1, #0x0, pl  // pl = nfrst
    0.00 :   ffff80001010fe44:       mov     x21, x1
    0.00 :   ffff80001010fe48:       ccmp    x0, x1, #0x0, le
    0.00 :   ffff80001010fe4c:       b.le    ffff80001010fe58 <hrtimer_start_range_ns+0xd0>
    0.00 :   ffff80001010fe50:       mov     x21, #0x7fffffffffffffff        // #9223372036854775807
         : 336              res = ktime_set(KTIME_SEC_MAX, 0);
    0.00 :   ffff80001010fe54:       mov     x1, x21
         : 335              if (res < 0 || res < lhs || res < rhs)
    0.00 :   ffff80001010fe58:       adds    x0, x26, x1
         : 336              res = ktime_set(KTIME_SEC_MAX, 0);
    0.00 :   ffff80001010fe5c:       mov     x2, #0x7fffffffffffffff         // #9223372036854775807
         : 335              if (res < 0 || res < lhs || res < rhs)
    0.00 :   ffff80001010fe60:       ccmp    x21, x0, #0x0, pl  // pl = nfrst
         : 337              __hrtimer_start_range_ns():
         : 1118             new_base = switch_hrtimer_base(timer, base, mode & HRTIMER_MODE_PINNED);
    0.00 :   ffff80001010fe64:       and     w1, w23, #0x2
         : 1120             ktime_add_safe():
         : 336              res = ktime_set(KTIME_SEC_MAX, 0);
    0.00 :   ffff80001010fe68:       ccmp    x26, x0, #0x0, le
    0.00 :   ffff80001010fe6c:       csel    x0, x0, x2, le
         : 339              hrtimer_set_expires_range_ns():
         : 254              timer->node.expires = ktime_add_safe(time, delta);
         : 255              }
         :
         : 257              static inline void hrtimer_set_expires_range_ns(struct hrtimer *timer, ktime_t time, u64 delta)
         : 258              {
         : 259              timer->_softexpires = time;
    0.00 :   ffff80001010fe70:       stp     x0, x21, [x19, #24]
         : 261              switch_hrtimer_base():
         : 232              this_cpu_base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff80001010fe74:       mov     x21, x25
         : 234              __kern_my_cpu_offset():
    0.00 :   ffff80001010fe78:       mrs     x0, tpidr_el1
         : 40               switch_hrtimer_base():
         : 230              int basenum = base->index;
    0.00 :   ffff80001010fe7c:       ldr     w23, [x20, #8]
         : 232              this_cpu_base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff80001010fe80:       add     x21, x21, x0
         : 234              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff80001010fe84:       b       ffff80001010ffc0 <hrtimer_start_range_ns+0x238>
         : 45               switch_hrtimer_base():
    0.00 :   ffff80001010fe88:       mov     x22, x21
         : 233              get_target_base():
         : 206              if (static_branch_likely(&timers_migration_enabled) && !pinned)
    0.00 :   ffff80001010fe8c:       cbz     w1, ffff80001010ffe8 <hrtimer_start_range_ns+0x260>
    0.00 :   ffff80001010fe90:       sxtw    x23, w23
         : 209              switch_hrtimer_base():
         : 251              WRITE_ONCE(timer->base, &migration_base);
    0.00 :   ffff80001010fe94:       adrp    x0, ffff800011cb5000 <rcu_state+0x1580>
    0.00 :   ffff80001010fe98:       add     x23, x23, #0x1
    0.00 :   ffff80001010fe9c:       add     x0, x0, #0xf80
    0.00 :   ffff80001010fea0:       add     x26, x0, #0x40
    0.00 :   ffff80001010fea4:       lsl     x23, x23, #6
         : 235              new_base = &new_cpu_base->clock_base[basenum];
    0.00 :   ffff80001010fea8:       add     x25, x22, x23
         : 253              raw_spin_lock(&new_base->cpu_base->lock);
    0.00 :   ffff80001010feac:       mov     x27, x23
         : 237              if (base != new_base) {
    0.00 :   ffff80001010feb0:       cmp     x20, x25
    0.00 :   ffff80001010feb4:       b.eq    ffff80001010ff20 <hrtimer_start_range_ns+0x198>  // b.none
         : 240              hrtimer_callback_running():
         : 484              * Helper function to check, whether the timer is running the callback
         : 485              * function
         : 486              */
         : 487              static inline int hrtimer_callback_running(struct hrtimer *timer)
         : 488              {
         : 489              return timer->base->running == timer;
    0.00 :   ffff80001010feb8:       ldr     x0, [x19, #48]
         : 491              switch_hrtimer_base():
         : 247              if (unlikely(hrtimer_callback_running(timer)))
    0.00 :   ffff80001010febc:       ldr     x0, [x0, #24]
    0.00 :   ffff80001010fec0:       cmp     x19, x0
    0.00 :   ffff80001010fec4:       b.eq    ffff80001010ffb8 <hrtimer_start_range_ns+0x230>  // b.none
         : 251              WRITE_ONCE(timer->base, &migration_base);
    0.00 :   ffff80001010fec8:       str     x26, [x19, #48]
         : 252              raw_spin_unlock(&base->cpu_base->lock);
    0.00 :   ffff80001010fecc:       ldr     x0, [x20]
    0.00 :   ffff80001010fed0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 253              raw_spin_lock(&new_base->cpu_base->lock);
    0.00 :   ffff80001010fed4:       ldr     x0, [x22, x27]
    0.00 :   ffff80001010fed8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 255              if (new_cpu_base != this_cpu_base &&
    0.00 :   ffff80001010fedc:       cmp     x21, x22
    0.00 :   ffff80001010fee0:       b.eq    ffff80001010ffd8 <hrtimer_start_range_ns+0x250>  // b.none
         : 256              hrtimer_check_target(timer, new_base)) {
    0.00 :   ffff80001010fee4:       ldr     x0, [x25]
         : 258              hrtimer_check_target():
         : 197              expires = ktime_sub(hrtimer_get_expires(timer), new_base->offset);
    0.00 :   ffff80001010fee8:       ldr     x1, [x19, #24]
    0.00 :   ffff80001010feec:       ldr     x3, [x25, #56]
         : 200              switch_hrtimer_base():
         : 255              if (new_cpu_base != this_cpu_base &&
    0.00 :   ffff80001010fef0:       ldr     x2, [x0, #32]
         : 257              hrtimer_check_target():
         : 197              expires = ktime_sub(hrtimer_get_expires(timer), new_base->offset);
    0.00 :   ffff80001010fef4:       sub     x1, x1, x3
         : 199              switch_hrtimer_base():
         : 255              if (new_cpu_base != this_cpu_base &&
    0.00 :   ffff80001010fef8:       cmp     x1, x2
    0.00 :   ffff80001010fefc:       b.ge    ffff80001010ffd8 <hrtimer_start_range_ns+0x250>  // b.tcont
         : 257              raw_spin_unlock(&new_base->cpu_base->lock);
    0.00 :   ffff80001010ff00:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 258              raw_spin_lock(&base->cpu_base->lock);
    0.00 :   ffff80001010ff04:       ldr     x0, [x20]
    0.00 :   ffff80001010ff08:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 260              WRITE_ONCE(timer->base, base);
    0.00 :   ffff80001010ff0c:       str     x20, [x19, #48]
         : 232              this_cpu_base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff80001010ff10:       mov     x22, x21
         : 235              new_base = &new_cpu_base->clock_base[basenum];
    0.00 :   ffff80001010ff14:       add     x25, x22, x23
         : 237              if (base != new_base) {
    0.00 :   ffff80001010ff18:       cmp     x20, x25
    0.00 :   ffff80001010ff1c:       b.ne    ffff80001010feb8 <hrtimer_start_range_ns+0x130>  // b.any
         : 265              if (new_cpu_base != this_cpu_base &&
    0.00 :   ffff80001010ff20:       cmp     x21, x22
    0.00 :   ffff80001010ff24:       ldr     x2, [x20]
    0.00 :   ffff80001010ff28:       b.eq    ffff80001010ff48 <hrtimer_start_range_ns+0x1c0>  // b.none
         : 269              hrtimer_check_target():
         : 197              expires = ktime_sub(hrtimer_get_expires(timer), new_base->offset);
    0.00 :   ffff80001010ff2c:       ldr     x0, [x19, #24]
    0.00 :   ffff80001010ff30:       ldr     x3, [x20, #56]
         : 200              switch_hrtimer_base():
         : 265              if (new_cpu_base != this_cpu_base &&
    0.00 :   ffff80001010ff34:       ldr     x1, [x2, #32]
         : 267              hrtimer_check_target():
         : 197              expires = ktime_sub(hrtimer_get_expires(timer), new_base->offset);
    0.00 :   ffff80001010ff38:       sub     x0, x0, x3
         : 199              switch_hrtimer_base():
         : 265              if (new_cpu_base != this_cpu_base &&
    0.00 :   ffff80001010ff3c:       cmp     x0, x1
    0.00 :   ffff80001010ff40:       b.lt    ffff80001010ff10 <hrtimer_start_range_ns+0x188>  // b.tstop
    0.00 :   ffff80001010ff44:       nop
         : 269              enqueue_hrtimer():
         : 984              base->cpu_base->active_bases |= 1 << base->index;
    0.00 :   ffff80001010ff48:       ldr     w4, [x20, #8]
    0.00 :   ffff80001010ff4c:       mov     w21, #0x1                       // #1
    0.00 :   ffff80001010ff50:       ldr     w3, [x2, #8]
         : 989              return timerqueue_add(&base->active, &timer->node);
    0.00 :   ffff80001010ff54:       add     x0, x20, #0x20
    0.00 :   ffff80001010ff58:       mov     x1, x19
         : 984              base->cpu_base->active_bases |= 1 << base->index;
    0.00 :   ffff80001010ff5c:       lsl     w4, w21, w4
    0.00 :   ffff80001010ff60:       orr     w3, w3, w4
    0.00 :   ffff80001010ff64:       str     w3, [x2, #8]
         : 987              WRITE_ONCE(timer->state, HRTIMER_STATE_ENQUEUED);
    0.00 :   ffff80001010ff68:       strb    w21, [x19, #56]
         : 989              return timerqueue_add(&base->active, &timer->node);
    0.00 :   ffff80001010ff6c:       bl      ffff8000104b7878 <timerqueue_add>
         : 991              hrtimer_start_range_ns():
         :
         : 1151             if (__hrtimer_start_range_ns(timer, tim, delta_ns, mode, base))
    0.00 :   ffff80001010ff70:       tst     w0, #0xff
    0.00 :   ffff80001010ff74:       b.ne    ffff80001010ffc8 <hrtimer_start_range_ns+0x240>  // b.any
         : 1154             unlock_hrtimer_base():
         : 915              raw_spin_unlock_irqrestore(&timer->base->cpu_base->lock, *flags);
    0.00 :   ffff80001010ff78:       ldr     x0, [x19, #48]
    0.00 :   ffff80001010ff7c:       ldr     x1, [sp, #96]
    0.00 :   ffff80001010ff80:       ldr     x0, [x0]
    0.00 :   ffff80001010ff84:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 920              hrtimer_start_range_ns():
         : 1154             hrtimer_reprogram(timer, true);
         :
         : 1156             unlock_hrtimer_base(timer, &flags);
         : 1157             }
    0.00 :   ffff80001010ff88:       ldr     x1, [sp, #104]
    0.00 :   ffff80001010ff8c:       ldr     x0, [x24]
    0.00 :   ffff80001010ff90:       eor     x0, x1, x0
    0.00 :   ffff80001010ff94:       cbnz    x0, ffff800010110008 <hrtimer_start_range_ns+0x280>
    0.00 :   ffff80001010ff98:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001010ff9c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001010ffa0:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001010ffa4:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff80001010ffa8:       ldr     x27, [sp, #80]
    0.00 :   ffff80001010ffac:       ldp     x29, x30, [sp], #112
    0.00 :   ffff80001010ffb0:       autiasp
    0.00 :   ffff80001010ffb4:       ret
    0.00 :   ffff80001010ffb8:       ldr     x2, [x20]
    0.00 :   ffff80001010ffbc:       b       ffff80001010ff48 <hrtimer_start_range_ns+0x1c0>
         : 1172             switch_hrtimer_base():
         : 232              this_cpu_base = this_cpu_ptr(&hrtimer_bases);
    0.00 :   ffff80001010ffc0:       mov     x22, x21
    0.00 :   ffff80001010ffc4:       b       ffff80001010fe90 <hrtimer_start_range_ns+0x108>
         : 235              hrtimer_start_range_ns():
         : 1151             hrtimer_reprogram(timer, true);
    0.00 :   ffff80001010ffc8:       mov     w1, w21
    0.00 :   ffff80001010ffcc:       mov     x0, x19
    0.00 :   ffff80001010ffd0:       bl      ffff80001010fbd8 <hrtimer_reprogram>
    0.00 :   ffff80001010ffd4:       b       ffff80001010ff78 <hrtimer_start_range_ns+0x1f0>
         : 1156             switch_hrtimer_base():
         : 263              WRITE_ONCE(timer->base, new_base);
    0.00 :   ffff80001010ffd8:       str     x25, [x19, #48]
    0.00 :   ffff80001010ffdc:       mov     x20, x25
    0.00 :   ffff80001010ffe0:       ldr     x2, [x25]
    0.00 :   ffff80001010ffe4:       b       ffff80001010ff48 <hrtimer_start_range_ns+0x1c0>
         : 268              get_target_base():
         : 207              return &per_cpu(hrtimer_bases, get_nohz_timer_target());
    0.00 :   ffff80001010ffe8:       bl      ffff8000100b3cf0 <get_nohz_timer_target>
    0.00 :   ffff80001010ffec:       adrp    x1, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff80001010fff0:       add     x1, x1, #0x760
    0.00 :   ffff80001010fff4:       ldr     x22, [x1, w0, sxtw #3]
    0.00 :   ffff80001010fff8:       add     x22, x25, x22
    0.00 :   ffff80001010fffc:       b       ffff80001010fe90 <hrtimer_start_range_ns+0x108>
         : 214              hrtimer_start_range_ns():
         : 1144             WARN_ON_ONCE(!(mode & HRTIMER_MODE_SOFT) ^ !timer->is_soft);
    0.00 :   ffff800010110000:       brk     #0x800
    0.00 :   ffff800010110004:       b       ffff80001010fde8 <hrtimer_start_range_ns+0x60>
         : 1154             }
    0.00 :   ffff800010110008:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c9090 <pick_next_task_rt>:
         : 6                pick_next_task_rt():
         :
         : 1631             return rt_task_of(rt_se);
         : 1632             }
         :
         : 1634             static struct task_struct *pick_task_rt(struct rq *rq)
         : 1635             {
  100.00 :   ffff8000100c9090:       paciasp
    0.00 :   ffff8000100c9094:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000100c9098:       mov     x29, sp
    0.00 :   ffff8000100c909c:       stp     x21, x22, [sp, #32]
         : 1633             struct task_struct *p;
         :
         : 1635             if (!sched_rt_runnable(rq))
    0.00 :   ffff8000100c90a0:       ldr     w1, [x0, #2184]
    0.00 :   ffff8000100c90a4:       cmp     w1, #0x0
    0.00 :   ffff8000100c90a8:       b.le    ffff8000100c91ec <pick_next_task_rt+0x15c>
         : 1639             sched_find_first_bit():
         : 16               * one of the 100 bits is cleared.
         : 17               */
         : 18               static inline int sched_find_first_bit(const unsigned long *b)
         : 19               {
         : 20               #if BITS_PER_LONG == 64
         : 21               if (b[0])
    0.00 :   ffff8000100c90ac:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c90b0:       ldr     x1, [x0, #512]
    0.00 :   ffff8000100c90b4:       cbnz    x1, ffff8000100c91e0 <pick_next_task_rt+0x150>
         : 25               __ffs():
         : 13               *
         : 14               * Undefined if no bit exists, so code should check against 0 first.
         : 15               */
         : 16               static __always_inline unsigned long __ffs(unsigned long word)
         : 17               {
         : 18               return __builtin_ctzl(word);
    0.00 :   ffff8000100c90b8:       ldr     x1, [x0, #520]
    0.00 :   ffff8000100c90bc:       rbit    x1, x1
    0.00 :   ffff8000100c90c0:       clz     x1, x1
         : 22               sched_find_first_bit():
         : 18               return __ffs(b[0]);
         : 19               return __ffs(b[1]) + 64;
    0.00 :   ffff8000100c90c4:       add     w1, w1, #0x40
         : 21               pick_next_rt_entity():
         : 1607             BUG_ON(idx >= MAX_RT_PRIO);
    0.00 :   ffff8000100c90c8:       cmp     w1, #0x63
    0.00 :   ffff8000100c90cc:       b.hi    ffff8000100c9204 <pick_next_task_rt+0x174>  // b.pmore
         : 1610             next = list_entry(queue->next, struct sched_rt_entity, run_list);
    0.00 :   ffff8000100c90d0:       add     x1, x0, w1, sxtw #4
    0.00 :   ffff8000100c90d4:       ldr     x2, [x1, #528]
         : 1613             _pick_next_task_rt():
         : 1622             BUG_ON(!rt_se);
    0.00 :   ffff8000100c90d8:       cbz     x2, ffff8000100c9208 <pick_next_task_rt+0x178>
         : 1624             dequeue_pushable_task():
         : 389              plist_del(&p->pushable_tasks, &rq->rt.pushable_tasks);
    0.00 :   ffff8000100c90dc:       add     x20, x0, #0x878
         : 391              list_empty():
         : 282              * list_empty - tests whether a list is empty
         : 283              * @head: the list to test.
         : 284              */
         : 285              static inline int list_empty(const struct list_head *head)
         : 286              {
         : 287              return READ_ONCE(head->next) == head;
    0.00 :   ffff8000100c90e0:       add     x22, x0, #0x800
    0.00 :   ffff8000100c90e4:       mov     x19, x0
         : 290              dequeue_pushable_task():
    0.00 :   ffff8000100c90e8:       mov     x1, x20
         : 390              set_next_task_rt():
         : 1579             p->se.exec_start = rq_clock_task(rq);
    0.00 :   ffff8000100c90ec:       ldr     x0, [x0, #2432]
    0.00 :   ffff8000100c90f0:       stur    x0, [x2, #-192]
         : 1582             rt_task_of():
         : 231              return container_of(rt_se, struct task_struct, rt);
    0.00 :   ffff8000100c90f4:       sub     x21, x2, #0x180
         : 233              dequeue_pushable_task():
         : 389              plist_del(&p->pushable_tasks, &rq->rt.pushable_tasks);
    0.00 :   ffff8000100c90f8:       add     x0, x2, #0x1d0
    0.00 :   ffff8000100c90fc:       bl      ffff8000104b1380 <plist_del>
         : 392              list_empty():
    0.00 :   ffff8000100c9100:       ldr     x1, [x22, #120]
         : 283              dequeue_pushable_task():
         : 397              rq->rt.highest_prio.next = MAX_RT_PRIO-1;
    0.00 :   ffff8000100c9104:       mov     w0, #0x63                       // #99
         : 392              if (has_pushable_tasks(rq)) {
    0.00 :   ffff8000100c9108:       cmp     x20, x1
    0.00 :   ffff8000100c910c:       b.eq    ffff8000100c911c <pick_next_task_rt+0x8c>  // b.none
         : 395              rq->rt.highest_prio.next = p->prio;
    0.00 :   ffff8000100c9110:       ldr     x0, [x19, #2168]
    0.00 :   ffff8000100c9114:       sub     x0, x0, #0x368
    0.00 :   ffff8000100c9118:       ldr     w0, [x0, #100]
         : 399              set_next_task_rt():
         : 1592             if (rq->curr->sched_class != &rt_sched_class)
    0.00 :   ffff8000100c911c:       ldr     x1, [x19, #2352]
    0.00 :   ffff8000100c9120:       str     w0, [x19, #2140]
    0.00 :   ffff8000100c9124:       adrp    x0, ffff800011570000 <kallsyms_token_index+0x1657a0>
    0.00 :   ffff8000100c9128:       add     x0, x0, #0xff0
    0.00 :   ffff8000100c912c:       ldr     x1, [x1, #120]
    0.00 :   ffff8000100c9130:       cmp     x1, x0
    0.00 :   ffff8000100c9134:       b.eq    ffff8000100c9150 <pick_next_task_rt+0xc0>  // b.none
         : 1600             rq_clock_pelt():
         : 147              /* rq->task_clock normalized against any time this cfs_rq has spent throttled */
         : 148              static inline u64 cfs_rq_clock_pelt(struct cfs_rq *cfs_rq)
         : 149              {
         : 150              if (unlikely(cfs_rq->throttle_count))
         : 151              return cfs_rq->throttled_clock_task - cfs_rq->throttled_clock_task_time;
         :
    0.00 :   ffff8000100c9138:       ldr     x3, [x19, #2440]
         : 154              set_next_task_rt():
         : 1593             update_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);
    0.00 :   ffff8000100c913c:       mov     w2, #0x0                        // #0
         : 1595             rq_clock_pelt():
    0.00 :   ffff8000100c9140:       ldr     x0, [x19, #2448]
         : 148              set_next_task_rt():
    0.00 :   ffff8000100c9144:       mov     x1, x19
    0.00 :   ffff8000100c9148:       sub     x0, x3, x0
    0.00 :   ffff8000100c914c:       bl      ffff8000100d5300 <update_rt_rq_load_avg>
         : 1596             list_empty():
    0.00 :   ffff8000100c9150:       ldr     x0, [x22, #120]
         : 283              rt_queue_push_tasks():
         : 365              if (!has_pushable_tasks(rq))
    0.00 :   ffff8000100c9154:       cmp     x20, x0
    0.00 :   ffff8000100c9158:       b.eq    ffff8000100c91c8 <pick_next_task_rt+0x138>  // b.none
         : 368              queue_balance_callback(rq, &per_cpu(rt_push_head, rq->cpu), push_rt_tasks);
    0.00 :   ffff8000100c915c:       ldrsw   x2, [x19, #2576]
    0.00 :   ffff8000100c9160:       adrp    x1, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c9164:       add     x1, x1, #0x760
    0.00 :   ffff8000100c9168:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100c916c:       add     x0, x0, #0x800
    0.00 :   ffff8000100c9170:       add     x0, x0, #0x30
    0.00 :   ffff8000100c9174:       ldr     x1, [x1, x2, lsl #3]
    0.00 :   ffff8000100c9178:       add     x3, x0, x1
         : 377              queue_balance_callback():
         : 1434             *  made to update_rq_clock() since the last time rq::lock was pinned.
         : 1435             *
         : 1436             * If inside of __schedule(), clock_update_flags will have been
         : 1437             * shifted left (a left shift is a cheap operation for the fast path
         : 1438             * to promote %RQCF_REQ_SKIP to %RQCF_ACT_SKIP), so you must use,
         : 1439             *
    0.00 :   ffff8000100c917c:       ldr     x2, [x0, x1]
    0.00 :   ffff8000100c9180:       cbnz    x2, ffff8000100c91c8 <pick_next_task_rt+0x138>
    0.00 :   ffff8000100c9184:       ldr     x4, [x19, #2496]
    0.00 :   ffff8000100c9188:       adrp    x2, ffff800011c41000 <modprobe_path+0x48>
    0.00 :   ffff8000100c918c:       add     x2, x2, #0x170
    0.00 :   ffff8000100c9190:       cmp     x4, x2
    0.00 :   ffff8000100c9194:       b.eq    ffff8000100c91c8 <pick_next_task_rt+0x138>  // b.none
         : 1437             *       if (rq-clock_update_flags >= RQCF_UPDATED)
         : 1438             *
         : 1439             * to check if %RQCF_UPDATED is set. It'll never be shifted more than
    0.00 :   ffff8000100c9198:       adrp    x2, ffff8000100c9000 <check_preempt_curr_rt+0x70>
    0.00 :   ffff8000100c919c:       add     x2, x2, #0x720
    0.00 :   ffff8000100c91a0:       str     x2, [x3, #8]
         : 1438             * one position though, because the next rq_unpin_lock() will shift it
    0.00 :   ffff8000100c91a4:       ldr     x2, [x19, #2496]
    0.00 :   ffff8000100c91a8:       str     x2, [x0, x1]
         : 1439             * back.
    0.00 :   ffff8000100c91ac:       str     x3, [x19, #2496]
         : 1441             pick_next_task_rt():
         : 1639             return NULL;
         :
         : 1641             p = _pick_next_task_rt(rq);
         :
         : 1643             return p;
         : 1644             }
    0.00 :   ffff8000100c91b0:       mov     x0, x21
    0.00 :   ffff8000100c91b4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c91b8:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c91bc:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100c91c0:       autiasp
    0.00 :   ffff8000100c91c4:       ret
    0.00 :   ffff8000100c91c8:       mov     x0, x21
    0.00 :   ffff8000100c91cc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c91d0:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c91d4:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100c91d8:       autiasp
    0.00 :   ffff8000100c91dc:       ret
         : 1657             __ffs():
    0.00 :   ffff8000100c91e0:       rbit    x1, x1
    0.00 :   ffff8000100c91e4:       clz     x1, x1
         : 15               pick_next_rt_entity():
         : 1607             BUG_ON(idx >= MAX_RT_PRIO);
    0.00 :   ffff8000100c91e8:       b       ffff8000100c90d0 <pick_next_task_rt+0x40>
         : 1609             pick_next_task_rt():
         : 1634             return NULL;
    0.00 :   ffff8000100c91ec:       mov     x21, #0x0                       // #0
         : 1639             }
    0.00 :   ffff8000100c91f0:       mov     x0, x21
    0.00 :   ffff8000100c91f4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c91f8:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100c91fc:       autiasp
    0.00 :   ffff8000100c9200:       ret
         : 1645             pick_next_rt_entity():
         : 1607             BUG_ON(idx >= MAX_RT_PRIO);
    0.00 :   ffff8000100c9204:       brk     #0x800
         : 1609             _pick_next_task_rt():
         : 1622             BUG_ON(!rt_se);
    0.00 :   ffff8000100c9208:       brk     #0x800
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b16c0 <update_rq_clock.part.106>:
         : 6                update_rq_clock():
         : 311              static_branch_disable(&__sched_core_enabled);
         : 312              }
         :
         : 314              void sched_core_get(void)
         : 315              {
         : 316              if (atomic_inc_not_zero(&sched_core_count))
    0.00 :   ffff8000100b16c0:       paciasp
    0.00 :   ffff8000100b16c4:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000100b16c8:       mov     x29, sp
    0.00 :   ffff8000100b16cc:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b16d0:       mov     x20, x0
         : 326              }
         :
         : 328              static void __sched_core_put(struct work_struct *work)
         : 329              {
         : 330              if (atomic_dec_and_mutex_lock(&sched_core_count, &sched_core_mutex)) {
         : 331              __sched_core_disable();
    0.00 :   ffff8000100b16d4:       ldr     w0, [x0, #2576]
    0.00 :   ffff8000100b16d8:       bl      ffff8000100ba338 <sched_clock_cpu>
    0.00 :   ffff8000100b16dc:       ldr     x1, [x20, #2400]
         : 327              mutex_unlock(&sched_core_mutex);
    0.00 :   ffff8000100b16e0:       subs    x2, x0, x1
    0.00 :   ffff8000100b16e4:       b.mi    ffff8000100b1780 <update_rq_clock.part.106+0xc0>  // b.first
         : 329              }
         : 330              }
    0.00 :   ffff8000100b16e8:       str     x21, [sp, #32]
         : 332              irq_time_read():
         :
         : 2468             static inline bool rq_order_less(struct rq *rq1, struct rq *rq2)
         : 2469             {
         : 2470             #ifdef CONFIG_SCHED_CORE
         : 2471             /*
         : 2472             * In order to not have {0,2},{1,3} turn into into an AB-BA,
    0.00 :   ffff8000100b16ec:       adrp    x21, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100b16f0:       add     x21, x21, #0x760
         : 2475             update_rq_clock():
    0.00 :   ffff8000100b16f4:       str     x0, [x20, #2400]
         : 330              irq_time_read():
    0.00 :   ffff8000100b16f8:       ldrsw   x1, [x20, #2576]
    0.00 :   ffff8000100b16fc:       adrp    x0, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
    0.00 :   ffff8000100b1700:       add     x0, x0, #0x7a8
         : 2470             update_rq_clock_task():
         :
    0.00 :   ffff8000100b1704:       ldr     x3, [x20, #2912]
         : 268              irq_time_read():
         : 2473             * order by core-id first and cpu-id second.
         : 2474             *
         : 2475             * Notably:
         : 2476             *
         : 2477             *       double_rq_lock(0,3); will take core-0, core-1 lock
         : 2478             *       double_rq_lock(1,2); will take core-1, core-0 lock
    0.00 :   ffff8000100b1708:       ldr     x1, [x21, x1, lsl #3]
         : 2480             update_rq_clock_task():
    0.00 :   ffff8000100b170c:       ldr     x1, [x1, x0]
         : 302              static void __sched_core_disable(void)
  100.00 :   ffff8000100b1710:       ldr     x0, [x20, #2432]
         :
    0.00 :   ffff8000100b1714:       sub     x1, x1, x3
         : 283              {
    0.00 :   ffff8000100b1718:       cmp     x2, x1
    0.00 :   ffff8000100b171c:       csel    x1, x2, x1, le
         : 287              WARN_ON_ONCE(!RB_EMPTY_ROOT(&cpu_rq(cpu)->core_tree));
    0.00 :   ffff8000100b1720:       sub     x19, x2, x1
         : 286              for_each_possible_cpu(cpu)
    0.00 :   ffff8000100b1724:       add     x3, x3, x1
         : 302              static void __sched_core_disable(void)
    0.00 :   ffff8000100b1728:       add     x0, x0, x19
    0.00 :   ffff8000100b172c:       str     x0, [x20, #2432]
         : 286              for_each_possible_cpu(cpu)
    0.00 :   ffff8000100b1730:       str     x3, [x20, #2912]
         : 305              __sched_core_flip(false);
    0.00 :   ffff8000100b1734:       cbnz    x1, ffff8000100b1790 <update_rq_clock.part.106+0xd0>
         : 307              is_idle_task():
         : 1739             * Return: The nice value [ -20 ... 0 ... 19 ].
         : 1740             */
         : 1741             static inline int task_nice(const struct task_struct *p)
         : 1742             {
         : 1743             return PRIO_TO_NICE((p)->static_prio);
         : 1744             }
    0.00 :   ffff8000100b1738:       ldr     x0, [x20, #2352]
    0.00 :   ffff8000100b173c:       ldr     w0, [x0, #36]
         : 1747             update_rq_clock_pelt():
         : 85               }
         :
         : 87               /*
         : 88               * When a rq runs at a lower compute capacity, it will need
         : 89               * more time to do the same amount of work than at max
         : 90               * capacity. In order to be invariant, we scale the delta to
    0.00 :   ffff8000100b1740:       tbnz    w0, #1, ffff8000100b179c <update_rq_clock.part.106+0xdc>
         : 92               topology_get_cpu_scale():
         :
         : 22               DECLARE_PER_CPU(unsigned long, cpu_scale);
         :
         : 24               static inline unsigned long topology_get_cpu_scale(int cpu)
         : 25               {
         : 26               return per_cpu(cpu_scale, cpu);
    0.00 :   ffff8000100b1744:       ldrsw   x2, [x20, #2576]
    0.00 :   ffff8000100b1748:       adrp    x1, ffff800011778000 <ipi_to_irq>
    0.00 :   ffff8000100b174c:       add     x1, x1, #0x700
         : 30               topology_get_freq_scale():
         :
         : 31               DECLARE_PER_CPU(unsigned long, arch_freq_scale);
         :
         : 33               static inline unsigned long topology_get_freq_scale(int cpu)
         : 34               {
         : 35               return per_cpu(arch_freq_scale, cpu);
    0.00 :   ffff8000100b1750:       adrp    x0, ffff800011778000 <ipi_to_irq>
    0.00 :   ffff8000100b1754:       add     x0, x0, #0x710
         : 38               topology_get_cpu_scale():
         : 21               return per_cpu(cpu_scale, cpu);
    0.00 :   ffff8000100b1758:       ldr     x3, [x21, x2, lsl #3]
         : 23               update_rq_clock_pelt():
         : 110              * When rq becomes idle, we have to check if it has lost idle time
         : 111              * because it was fully busy. A rq is fully used when the /Sum util_sum
         : 112              * is greater or equal to:
         : 113              * (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) << SCHED_CAPACITY_SHIFT;
         : 114              * For optimization and computing rounding purpose, we don't take into account
         : 115              * the position in the current window (period_contrib) and we use the higher
    0.00 :   ffff8000100b175c:       ldr     x4, [x20, #2440]
         : 107              * is greater or equal to:
    0.00 :   ffff8000100b1760:       ldr     x2, [x1, x3]
         : 108              * (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100b1764:       ldr     x0, [x3, x0]
         : 107              * is greater or equal to:
    0.00 :   ffff8000100b1768:       mul     x2, x19, x2
    0.00 :   ffff8000100b176c:       lsr     x2, x2, #10
         : 108              * (LOAD_AVG_MAX - 1024 + rq->cfs.avg.period_contrib) << SCHED_CAPACITY_SHIFT;
    0.00 :   ffff8000100b1770:       mul     x2, x2, x0
         : 110              * the position in the current window (period_contrib) and we use the higher
    0.00 :   ffff8000100b1774:       add     x2, x4, x2, lsr #10
    0.00 :   ffff8000100b1778:       str     x2, [x20, #2440]
    0.00 :   ffff8000100b177c:       ldr     x21, [sp, #32]
         : 114              update_rq_clock():
         :
         : 332              void sched_core_put(void)
    0.00 :   ffff8000100b1780:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b1784:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000100b1788:       autiasp
    0.00 :   ffff8000100b178c:       ret
         : 337              update_rq_clock_task():
         : 306              static_branch_disable(&__sched_core_enabled);
    0.00 :   ffff8000100b1790:       mov     x0, x20
    0.00 :   ffff8000100b1794:       bl      ffff8000100d5900 <update_irq_load_avg>
    0.00 :   ffff8000100b1798:       b       ffff8000100b1738 <update_rq_clock.part.106+0x78>
         : 310              update_rq_clock_pelt():
         : 87               * Running longer results in stealing idle time that will
    0.00 :   ffff8000100b179c:       ldr     x0, [x20, #2432]
    0.00 :   ffff8000100b17a0:       str     x0, [x20, #2440]
         : 88               * disturb the load signal compared to max capacity. This
    0.00 :   ffff8000100b17a4:       ldr     x21, [sp, #32]
    0.00 :   ffff8000100b17a8:       b       ffff8000100b1780 <update_rq_clock.part.106+0xc0>
 Percent |	Source code & Disassembly of vmlinux for cycles (7 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b1190 <check_same_owner>:
         : 6                check_same_owner():
         : 6067             /*
         : 6068             * As this skips calling sched_submit_work(), which the idle task does
         : 6069             * regardless because that function is a nop when the task is in a
         : 6070             * TASK_RUNNING state, make sure this isn't used someplace that the
         : 6071             * current task can be in any other state. Note, idle is always in the
         : 6072             * TASK_RUNNING state.
    0.00 :   ffff8000100b1190:       paciasp
    0.00 :   ffff8000100b1194:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000100b1198:       mov     x29, sp
    0.00 :   ffff8000100b119c:       stp     x19, x20, [sp, #16]
   14.34 :   ffff8000100b11a0:       mov     x20, x0
         : 6078             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100b11a4:       mrs     x0, sp_el0
         : 26               check_same_owner():
         : 6068             */
    0.00 :   ffff8000100b11a8:       ldr     x19, [x0, #1528]
         : 6070             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100b11ac:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              check_same_owner():
         : 6072             WARN_ON_ONCE(current->state);
         : 6073             do {
         : 6074             __schedule(false);
         : 6075             } while (need_resched());
    0.00 :   ffff8000100b11b0:       ldr     x1, [x20, #1520]
         : 36               #define KGIDT_INIT(value) (kgid_t){ value }
         :
         : 38               #ifdef CONFIG_MULTIUSER
         : 39               static inline uid_t __kuid_val(kuid_t uid)
         : 40               {
         : 41               return uid.val;
    0.00 :   ffff8000100b11b4:       ldr     w0, [x19, #20]
    0.00 :   ffff8000100b11b8:       mov     w19, #0x1                       // #1
         : 6073             }
   85.66 :   ffff8000100b11bc:       ldr     w2, [x1, #20]
    0.00 :   ffff8000100b11c0:       cmp     w2, w0
    0.00 :   ffff8000100b11c4:       b.eq    ffff8000100b11d4 <check_same_owner+0x44>  // b.none
    0.00 :   ffff8000100b11c8:       ldr     w1, [x1, #4]
    0.00 :   ffff8000100b11cc:       cmp     w1, w0
    0.00 :   ffff8000100b11d0:       cset    w19, eq  // eq = none
         : 6076             rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100b11d4:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              check_same_owner():
         :
         : 6078             #if defined(CONFIG_CONTEXT_TRACKING) && !defined(CONFIG_HAVE_CONTEXT_TRACKING_OFFSTACK)
         : 6079             asmlinkage __visible void __sched schedule_user(void)
         : 6080             {
    0.00 :   ffff8000100b11d8:       mov     w0, w19
    0.00 :   ffff8000100b11dc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b11e0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000100b11e4:       autiasp
    0.00 :   ffff8000100b11e8:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (6 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010416998 <security_task_setscheduler>:
         : 6                security_task_setscheduler():
         : 1851             {
         : 1852             return call_int_hook(task_setrlimit, 0, p, resource, new_rlim);
         : 1853             }
         :
         : 1855             int security_task_setscheduler(struct task_struct *p)
         : 1856             {
   37.04 :   ffff800010416998:       paciasp
    0.00 :   ffff80001041699c:       stp     x29, x30, [sp, #-32]!
         : 1852             return call_int_hook(task_setscheduler, 0, p);
    0.00 :   ffff8000104169a0:       adrp    x1, ffff800011572000 <kmalloc_caches+0x78>
         : 1851             {
    0.00 :   ffff8000104169a4:       mov     x29, sp
    0.00 :   ffff8000104169a8:       stp     x19, x20, [sp, #16]
         : 1852             return call_int_hook(task_setscheduler, 0, p);
    0.00 :   ffff8000104169ac:       ldr     x19, [x1, #2024]
    0.00 :   ffff8000104169b0:       cbz     x19, ffff8000104169d0 <security_task_setscheduler+0x38>
   49.06 :   ffff8000104169b4:       mov     x20, x0
    0.00 :   ffff8000104169b8:       ldr     x1, [x19, #24]
    0.00 :   ffff8000104169bc:       mov     x0, x20
   13.90 :   ffff8000104169c0:       blr     x1
    0.00 :   ffff8000104169c4:       cbnz    w0, ffff8000104169d4 <security_task_setscheduler+0x3c>
    0.00 :   ffff8000104169c8:       ldr     x19, [x19]
    0.00 :   ffff8000104169cc:       cbnz    x19, ffff8000104169b8 <security_task_setscheduler+0x20>
         : 1851             {
    0.00 :   ffff8000104169d0:       mov     w0, #0x0                        // #0
         : 1853             }
    0.00 :   ffff8000104169d4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104169d8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000104169dc:       autiasp
    0.00 :   ffff8000104169e0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (6 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b82c0 <__arm64_sys_sched_setaffinity>:
         : 6                __arm64_sys_sched_setaffinity():
         : 6873             p->prio = normal_prio(p);
         : 6874             if (keep_boost)
         : 6875             p->prio = rt_effective_prio(p, p->prio);
         :
         : 6877             if (dl_prio(p->prio))
         : 6878             p->sched_class = &dl_sched_class;
   13.36 :   ffff8000100b82c0:       paciasp
    0.00 :   ffff8000100b82c4:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff8000100b82c8:       mov     x2, #0x20                       // #32
    0.00 :   ffff8000100b82cc:       mov     x29, sp
    0.00 :   ffff8000100b82d0:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b82d4:       adrp    x19, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b82d8:       add     x19, x19, #0x948
    0.00 :   ffff8000100b82dc:       ldr     x1, [x19]
    0.00 :   ffff8000100b82e0:       str     x1, [sp, #72]
    0.00 :   ffff8000100b82e4:       mov     x1, #0x0                        // #0
   17.01 :   ffff8000100b82e8:       ldp     x20, x1, [x0]
    0.00 :   ffff8000100b82ec:       ldr     x0, [x0, #16]
         : 6891             get_user_cpu_mask():
         : 6857             * either.
    0.00 :   ffff8000100b82f0:       cmp     w1, #0x1f
    0.00 :   ffff8000100b82f4:       b.ls    ffff8000100b8398 <__arm64_sys_sched_setaffinity+0xd8>  // b.plast
         : 6860             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100b82f8:       mrs     x1, sp_el0
         : 26               __range_ok():
         : 47               * Asynchronous I/O running in a kernel thread does not have the
         : 48               * TIF_TAGGED_ADDR flag of the process owning the mm, so always untag
         : 49               * the user address before checking.
         : 50               */
         : 51               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
         : 52               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff8000100b82fc:       ldr     w3, [x1, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff8000100b8300:       tbz     w3, #21, ffff8000100b8384 <__arm64_sys_sched_setaffinity+0xc4>
         : 48               sign_extend64():
         : 182              * @index: 0 based bit index (0<=index<64) to sign bit
         : 183              */
         : 184              static __always_inline __s64 sign_extend64(__u64 value, int index)
         : 185              {
         : 186              __u8 shift = 63 - index;
         : 187              return (__s64)(value << shift) >> shift;
    0.00 :   ffff8000100b8304:       sbfx    x1, x0, #0, #56
         : 189              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff8000100b8308:       and     x1, x1, x0
         :
         : 52               __chk_user_ptr(addr);
         : 53               asm volatile(
    0.00 :   ffff8000100b830c:       mov     x4, #0xffffffffffff             // #281474976710655
    0.00 :   ffff8000100b8310:       mov     x3, x4
    0.00 :   ffff8000100b8314:       adds    x1, x1, x2
    0.00 :   ffff8000100b8318:       csel    x3, xzr, x3, hi  // hi = pmore
    0.00 :   ffff8000100b831c:       csinv   x1, x1, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff8000100b8320:       sbcs    xzr, x1, x3
    0.00 :   ffff8000100b8324:       cset    x1, ls  // ls = plast
         : 61               _copy_from_user():
         : 157              static inline __must_check unsigned long
         : 158              _copy_from_user(void *to, const void __user *from, unsigned long n)
         : 159              {
         : 160              unsigned long res = n;
         : 161              might_fault();
         : 162              if (!should_fail_usercopy() && likely(access_ok(from, n))) {
    0.00 :   ffff8000100b8328:       cbz     x1, ffff8000100b834c <__arm64_sys_sched_setaffinity+0x8c>
         : 164              sign_extend64():
    0.00 :   ffff8000100b832c:       sbfx    x3, x0, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              asm volatile(
         : 245              "       bics    xzr, %3, %2\n"
         : 246              "       csel    %0, %1, xzr, eq\n"
         : 247              : "=&r" (safe_ptr)
         : 248              : "r" (ptr), "r" (TASK_SIZE_MAX - 1),
         : 249              "r" (untagged_addr(ptr))
    0.00 :   ffff8000100b8330:       and     x3, x3, x0
         : 239              asm volatile(
    0.00 :   ffff8000100b8334:       bics    xzr, x3, x4
    0.00 :   ffff8000100b8338:       csel    x1, x0, xzr, eq  // eq = none
         : 247              : "cc");
         :
         : 249              csdb();
   53.68 :   ffff8000100b833c:       csdb
         : 251              _copy_from_user():
         : 159              instrument_copy_from_user(to, from, n);
         : 160              res = raw_copy_from_user(to, from, n);
    0.00 :   ffff8000100b8340:       add     x0, sp, #0x28
    0.00 :   ffff8000100b8344:       bl      ffff8000104a4e40 <__arch_copy_from_user>
    0.00 :   ffff8000100b8348:       mov     x2, x0
         : 161              }
         : 162              if (unlikely(res))
    0.00 :   ffff8000100b834c:       mov     x0, #0xfffffffffffffff2         // #-14
    0.00 :   ffff8000100b8350:       cbnz    x2, ffff8000100b8364 <__arm64_sys_sched_setaffinity+0xa4>
         : 165              __do_sys_sched_setaffinity():
         :
         : 6885             /*
         : 6886             * Check the target process has a UID that matches the current process's:
         : 6887             */
         : 6888             static bool check_same_owner(struct task_struct *p)
         : 6889             {
    0.00 :   ffff8000100b8354:       mov     w0, w20
    0.00 :   ffff8000100b8358:       add     x1, sp, #0x28
    0.00 :   ffff8000100b835c:       bl      ffff8000100b8050 <sched_setaffinity>
    0.00 :   ffff8000100b8360:       sxtw    x0, w0
         : 6894             __arm64_sys_sched_setaffinity():
         : 6873             p->sched_class = &dl_sched_class;
    0.00 :   ffff8000100b8364:       ldr     x2, [sp, #72]
    0.00 :   ffff8000100b8368:       ldr     x1, [x19]
    0.00 :   ffff8000100b836c:       eor     x1, x2, x1
    0.00 :   ffff8000100b8370:       cbnz    x1, ffff8000100b83a8 <__arm64_sys_sched_setaffinity+0xe8>
    0.00 :   ffff8000100b8374:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b8378:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000100b837c:       autiasp
    0.00 :   ffff8000100b8380:       ret
         : 6882             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
   15.95 :   ffff8000100b8384:       ldr     x3, [x1]
         : 113              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff8000100b8388:       mov     x1, x0
    0.00 :   ffff8000100b838c:       tst     w3, #0x4000000
    0.00 :   ffff8000100b8390:       b.eq    ffff8000100b830c <__arm64_sys_sched_setaffinity+0x4c>  // b.none
    0.00 :   ffff8000100b8394:       b       ffff8000100b8304 <__arm64_sys_sched_setaffinity+0x44>
         : 51               bitmap_zero():
         : 236              #define BITMAP_LAST_WORD_MASK(nbits) (~0UL >> (-(nbits) & (BITS_PER_LONG - 1)))
         :
         : 238              static inline void bitmap_zero(unsigned long *dst, unsigned int nbits)
         : 239              {
         : 240              unsigned int len = BITS_TO_LONGS(nbits) * sizeof(unsigned long);
         : 241              memset(dst, 0, len);
    0.00 :   ffff8000100b8398:       and     x2, x1, #0xffffffff
    0.00 :   ffff8000100b839c:       stp     xzr, xzr, [sp, #40]
    0.00 :   ffff8000100b83a0:       stp     xzr, xzr, [sp, #56]
    0.00 :   ffff8000100b83a4:       b       ffff8000100b82f8 <__arm64_sys_sched_setaffinity+0x38>
         : 246              __arm64_sys_sched_setaffinity():
    0.00 :   ffff8000100b83a8:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (4 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010461d10 <__bitmap_and>:
         : 6                __bitmap_and():
         : 242              }
         : 243              EXPORT_SYMBOL(bitmap_cut);
         :
         : 245              int __bitmap_and(unsigned long *dst, const unsigned long *bitmap1,
         : 246              const unsigned long *bitmap2, unsigned int bits)
         : 247              {
    0.00 :   ffff800010461d10:       paciasp
         : 244              unsigned int k;
         : 245              unsigned int lim = bits/BITS_PER_LONG;
    0.00 :   ffff800010461d14:       lsr     w8, w3, #6
         : 247              unsigned long result = 0;
         :
         : 249              for (k = 0; k < lim; k++)
    0.00 :   ffff800010461d18:       cbz     w8, ffff800010461d84 <__bitmap_and+0x74>
    0.00 :   ffff800010461d1c:       mov     x4, #0x0                        // #0
         : 245              unsigned long result = 0;
    0.00 :   ffff800010461d20:       mov     x6, #0x0                        // #0
    0.00 :   ffff800010461d24:       nop
         : 248              result |= (dst[k] = bitmap1[k] & bitmap2[k]);
    0.00 :   ffff800010461d28:       ldr     x5, [x1, x4, lsl #3]
    0.00 :   ffff800010461d2c:       ldr     x7, [x2, x4, lsl #3]
    0.00 :   ffff800010461d30:       and     x5, x5, x7
    0.00 :   ffff800010461d34:       str     x5, [x0, x4, lsl #3]
    0.00 :   ffff800010461d38:       add     x4, x4, #0x1
    0.00 :   ffff800010461d3c:       orr     x6, x6, x5
         : 247              for (k = 0; k < lim; k++)
   24.77 :   ffff800010461d40:       cmp     w8, w4
    0.00 :   ffff800010461d44:       b.hi    ffff800010461d28 <__bitmap_and+0x18>  // b.pmore
         : 249              if (bits % BITS_PER_LONG)
    0.00 :   ffff800010461d48:       tst     x3, #0x3f
    0.00 :   ffff800010461d4c:       b.eq    ffff800010461d74 <__bitmap_and+0x64>  // b.none
         : 250              result |= (dst[k] = bitmap1[k] & bitmap2[k] &
    0.00 :   ffff800010461d50:       ldr     x1, [x1, x8, lsl #3]
         : 251              BITMAP_LAST_WORD_MASK(bits));
    0.00 :   ffff800010461d54:       neg     w3, w3
         : 250              result |= (dst[k] = bitmap1[k] & bitmap2[k] &
    0.00 :   ffff800010461d58:       ldr     x2, [x2, x8, lsl #3]
         : 251              BITMAP_LAST_WORD_MASK(bits));
    0.00 :   ffff800010461d5c:       mov     x4, #0xffffffffffffffff         // #-1
    0.00 :   ffff800010461d60:       lsr     x3, x4, x3
         : 250              result |= (dst[k] = bitmap1[k] & bitmap2[k] &
    0.00 :   ffff800010461d64:       and     x1, x1, x2
    0.00 :   ffff800010461d68:       and     x3, x1, x3
    0.00 :   ffff800010461d6c:       str     x3, [x0, x8, lsl #3]
    0.00 :   ffff800010461d70:       orr     x6, x6, x3
         : 252              return result != 0;
    0.00 :   ffff800010461d74:       cmp     x6, #0x0
         : 253              }
    0.00 :   ffff800010461d78:       autiasp
    0.00 :   ffff800010461d7c:       cset    w0, ne  // ne = any
   75.23 :   ffff800010461d80:       ret
         : 245              unsigned long result = 0;
    0.00 :   ffff800010461d84:       mov     x6, #0x0                        // #0
    0.00 :   ffff800010461d88:       b       ffff800010461d48 <__bitmap_and+0x38>
 Percent |	Source code & Disassembly of vmlinux for cycles (5 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101694d0 <perf_event_ctx_lock_nested.isra.98>:
         : 6                perf_event_ctx_lock_nested():
         : 1343             *
         : 1344             *    cpu_hotplug_lock
         : 1345             *      pmus_lock
         : 1346             *         cpuctx->mutex / perf_event_context::mutex
         : 1347             */
         : 1348             static struct perf_event_context *
    0.00 :   ffff8000101694d0:       paciasp
    0.00 :   ffff8000101694d4:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff8000101694d8:       mov     x29, sp
    0.00 :   ffff8000101694dc:       str     x21, [sp, #32]
    0.00 :   ffff8000101694e0:       mov     x21, x0
    0.00 :   ffff8000101694e4:       stp     x19, x20, [sp, #16]
         : 1355             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000101694e8:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              perf_event_ctx_lock_nested():
         : 1349             perf_event_ctx_lock_nested(struct perf_event *event, int nesting)
         : 1350             {
         : 1351             struct perf_event_context *ctx;
         :
         : 1353             again:
         : 1354             rcu_read_lock();
    0.00 :   ffff8000101694ec:       ldr     x19, [x21, #552]
         : 1350             ctx = READ_ONCE(event->ctx);
    0.00 :   ffff8000101694f0:       add     x3, x19, #0xac
         : 1352             atomic_read():
         :
         : 29               static __always_inline int
         : 30               atomic_read(const atomic_t *v)
         : 31               {
         : 32               instrument_atomic_read(v, sizeof(*v));
         : 33               return arch_atomic_read(v);
    0.00 :   ffff8000101694f4:       ldr     w4, [x19, #172]
         : 35               __refcount_add_not_zero():
         : 155              static inline __must_check bool __refcount_add_not_zero(int i, refcount_t *r, int *oldp)
         : 156              {
         : 157              int old = refcount_read(r);
         :
         : 159              do {
         : 160              if (!old)
    0.00 :   ffff8000101694f8:       cbz     w4, ffff800010169574 <perf_event_ctx_lock_nested.isra.98+0xa4>
  100.00 :   ffff8000101694fc:       nop
         : 157              break;
         : 158              } while (!atomic_try_cmpxchg_relaxed(&r->refs, &old, old + i));
    0.00 :   ffff800010169500:       add     w5, w4, #0x1
         : 160              arch_atomic_try_cmpxchg_relaxed():
         : 1029             #ifndef arch_atomic_try_cmpxchg_relaxed
         : 1030             static __always_inline bool
         : 1031             arch_atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
         : 1032             {
         : 1033             int r, o = *old;
         : 1034             r = arch_atomic_cmpxchg_relaxed(v, o, new);
    0.00 :   ffff800010169504:       sxtw    x1, w4
         : 1036             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff800010169508:       b       ffff80001016958c <perf_event_ctx_lock_nested.isra.98+0xbc>
    0.00 :   ffff80001016950c:       b       ffff80001016958c <perf_event_ctx_lock_nested.isra.98+0xbc>
         : 46               __lse__cmpxchg_case_32():
         : 366              return x0;                                                      \
         : 367              }
         :
         : 369              __CMPXCHG_CASE(w, b,     ,  8,   )
         : 370              __CMPXCHG_CASE(w, h,     , 16,   )
         : 371              __CMPXCHG_CASE(w,  ,     , 32,   )
    0.00 :   ffff800010169510:       mov     x0, x3
    0.00 :   ffff800010169514:       mov     w2, w5
    0.00 :   ffff800010169518:       mov     w6, w1
    0.00 :   ffff80001016951c:       cas     w6, w2, [x3]
    0.00 :   ffff800010169520:       mov     w0, w6
         : 377              arch_atomic_try_cmpxchg_relaxed():
         : 1030             if (unlikely(r != o))
    0.00 :   ffff800010169524:       cmp     w0, w4
    0.00 :   ffff800010169528:       b.ne    ffff80001016957c <perf_event_ctx_lock_nested.isra.98+0xac>  // b.any
         : 1033             __refcount_add_not_zero():
         :
         : 163              if (oldp)
         : 164              *oldp = old;
         :
         : 166              if (unlikely(old < 0 || old + i < 0))
    0.00 :   ffff80001016952c:       tbnz    w0, #31, ffff800010169598 <perf_event_ctx_lock_nested.isra.98+0xc8>
    0.00 :   ffff800010169530:       tbnz    w5, #31, ffff800010169598 <perf_event_ctx_lock_nested.isra.98+0xc8>
         : 169              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010169534:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              perf_event_ctx_lock_nested():
         : 1356             if (!refcount_inc_not_zero(&ctx->refcount)) {
         : 1357             rcu_read_unlock();
         : 1358             goto again;
         : 1359             }
         : 1360             rcu_read_unlock();
         :
    0.00 :   ffff800010169538:       add     x20, x19, #0x10
    0.00 :   ffff80001016953c:       mov     x0, x20
    0.00 :   ffff800010169540:       bl      ffff800010e304e0 <mutex_lock>
         : 1357             mutex_lock_nested(&ctx->mutex, nesting);
    0.00 :   ffff800010169544:       ldr     x0, [x21, #552]
    0.00 :   ffff800010169548:       cmp     x19, x0
    0.00 :   ffff80001016954c:       b.eq    ffff8000101695c0 <perf_event_ctx_lock_nested.isra.98+0xf0>  // b.none
         : 1358             if (event->ctx != ctx) {
    0.00 :   ffff800010169550:       mov     x0, x20
    0.00 :   ffff800010169554:       bl      ffff800010e2fe60 <mutex_unlock>
         : 1359             mutex_unlock(&ctx->mutex);
    0.00 :   ffff800010169558:       mov     x0, x19
    0.00 :   ffff80001016955c:       bl      ffff8000101693b8 <put_ctx>
         : 1362             rcu_read_lock():
         : 655              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010169560:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 657              perf_event_ctx_lock_nested():
         : 1349             rcu_read_lock();
    0.00 :   ffff800010169564:       ldr     x19, [x21, #552]
         : 1350             ctx = READ_ONCE(event->ctx);
    0.00 :   ffff800010169568:       add     x3, x19, #0xac
         : 1352             atomic_read():
    0.00 :   ffff80001016956c:       ldr     w4, [x19, #172]
         : 29               __refcount_add_not_zero():
         : 155              if (!old)
    0.00 :   ffff800010169570:       cbnz    w4, ffff800010169500 <perf_event_ctx_lock_nested.isra.98+0x30>
         : 157              rcu_read_unlock():
         : 710              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010169574:       bl      ffff800010102998 <__rcu_read_unlock>
         : 712              perf_event_ctx_lock_nested():
         : 1352             rcu_read_unlock();
    0.00 :   ffff800010169578:       b       ffff8000101694e8 <perf_event_ctx_lock_nested.isra.98+0x18>
         : 1354             __refcount_add_not_zero():
    0.00 :   ffff80001016957c:       mov     w4, w0
    0.00 :   ffff800010169580:       cbnz    w0, ffff800010169500 <perf_event_ctx_lock_nested.isra.98+0x30>
         : 157              rcu_read_unlock():
    0.00 :   ffff800010169584:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              perf_event_ctx_lock_nested():
    0.00 :   ffff800010169588:       b       ffff8000101694e8 <perf_event_ctx_lock_nested.isra.98+0x18>
         : 1353             __ll_sc__cmpxchg_case_32():
         : 301              * handle the 'K' constraint for the value 4294967295 - thus we use no
         : 302              * constraint for 32 bit operations.
         : 303              */
         : 304              __CMPXCHG_CASE(w, b,     ,  8,        ,  ,  ,         , K)
         : 305              __CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
         : 306              __CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
    0.00 :   ffff80001016958c:       and     x1, x1, #0xffffffff
    0.00 :   ffff800010169590:       b       ffff800010176b60 <perf_event_exit_cpu+0x120>
    0.00 :   ffff800010169594:       b       ffff800010169524 <perf_event_ctx_lock_nested.isra.98+0x54>
         : 310              __refcount_add_not_zero():
         : 163              refcount_warn_saturate(r, REFCOUNT_ADD_NOT_ZERO_OVF);
    0.00 :   ffff800010169598:       mov     x0, x3
    0.00 :   ffff80001016959c:       mov     w1, #0x0                        // #0
         : 166              perf_event_ctx_lock_nested():
         :
    0.00 :   ffff8000101695a0:       add     x20, x19, #0x10
         : 1358             __refcount_add_not_zero():
    0.00 :   ffff8000101695a4:       bl      ffff800010470e68 <refcount_warn_saturate>
         : 164              rcu_read_unlock():
    0.00 :   ffff8000101695a8:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              perf_event_ctx_lock_nested():
    0.00 :   ffff8000101695ac:       mov     x0, x20
    0.00 :   ffff8000101695b0:       bl      ffff800010e304e0 <mutex_lock>
         : 1357             mutex_lock_nested(&ctx->mutex, nesting);
    0.00 :   ffff8000101695b4:       ldr     x0, [x21, #552]
    0.00 :   ffff8000101695b8:       cmp     x19, x0
    0.00 :   ffff8000101695bc:       b.ne    ffff800010169550 <perf_event_ctx_lock_nested.isra.98+0x80>  // b.any
         : 1364             put_ctx(ctx);
         : 1365             goto again;
         : 1366             }
         :
         : 1368             return ctx;
    0.00 :   ffff8000101695c0:       mov     x0, x19
    0.00 :   ffff8000101695c4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101695c8:       ldr     x21, [sp, #32]
    0.00 :   ffff8000101695cc:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101695d0:       autiasp
    0.00 :   ffff8000101695d4:       ret
 Percent |	Source code & Disassembly of perf for cycles (4 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      0000000000217db4 <perf_cpu_map__cpu>:
         : 6      perf_cpu_map__cpu():
         : 249    out:
         : 250    return cpus;
         : 251    }
         :
         : 253    int perf_cpu_map__cpu(const struct perf_cpu_map *cpus, int idx)
         : 254    {
   73.51 :   217db4: stp     x29, x30, [sp, #-32]!
    0.00 :   217db8: adrp    x2, 34d000 <options+0x650>
    0.00 :   217dbc: mov     x29, sp
   26.49 :   217dc0: ldr     x2, [x2, #2784]
    0.00 :   217dc4: ldr     x3, [x2]
    0.00 :   217dc8: str     x3, [sp, #24]
    0.00 :   217dcc: mov     x3, #0x0                        // #0
         : 250    if (cpus && idx < cpus->nr)
    0.00 :   217dd0: cbz     x0, 217e0c <perf_cpu_map__cpu+0x58>
    0.00 :   217dd4: ldr     w2, [x0, #4]
    0.00 :   217dd8: cmp     w2, w1
    0.00 :   217ddc: b.le    217e0c <perf_cpu_map__cpu+0x58>
         : 251    return cpus->map[idx];
    0.00 :   217de0: add     x1, x0, w1, sxtw #2
    0.00 :   217de4: ldr     w0, [x1, #8]
         :
         : 255    return -1;
         : 256    }
    0.00 :   217de8: adrp    x1, 34d000 <options+0x650>
    0.00 :   217dec: ldr     x1, [x1, #2784]
    0.00 :   217df0: ldr     x2, [sp, #24]
    0.00 :   217df4: ldr     x3, [x1]
    0.00 :   217df8: subs    x2, x2, x3
    0.00 :   217dfc: mov     x3, #0x0                        // #0
    0.00 :   217e00: b.ne    217e14 <perf_cpu_map__cpu+0x60>  // b.any
    0.00 :   217e04: ldp     x29, x30, [sp], #32
    0.00 :   217e08: ret
         : 253    return -1;
    0.00 :   217e0c: mov     w0, #0xffffffff                 // #-1
    0.00 :   217e10: b       217de8 <perf_cpu_map__cpu+0x34>
         : 254    }
    0.00 :   217e14: bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (3 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010143190 <guarantee_online_cpus>:
         : 6                guarantee_online_cpus():
         : 385              * of cpu_online_mask.
         : 386              *
         : 387              * Call with callback_lock or cpuset_mutex held.
         : 388              */
         : 389              static void guarantee_online_cpus(struct cpuset *cs, struct cpumask *pmask)
         : 390              {
    0.00 :   ffff800010143190:       paciasp
    0.00 :   ffff800010143194:       stp     x29, x30, [sp, #-48]!
    0.00 :   ffff800010143198:       mov     x29, sp
    0.00 :   ffff80001014319c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000101431a0:       mov     x19, x0
    0.00 :   ffff8000101431a4:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000101431a8:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000101431ac:       mov     x22, x1
    0.00 :   ffff8000101431b0:       add     x21, x21, #0x9e8
    0.00 :   ffff8000101431b4:       nop
         : 401              cpumask_intersects():
         : 498              * @src2p: the second input
         : 499              */
         : 500              static inline bool cpumask_intersects(const struct cpumask *src1p,
         : 501              const struct cpumask *src2p)
         : 502              {
         : 503              return bitmap_intersects(cpumask_bits(src1p), cpumask_bits(src2p),
    0.00 :   ffff8000101431b8:       add     x20, x19, #0xf8
         : 505              bitmap_intersects():
         : 368              const unsigned long *src2, unsigned int nbits)
         : 369              {
         : 370              if (small_const_nbits(nbits))
         : 371              return ((*src1 & *src2) & BITMAP_LAST_WORD_MASK(nbits)) != 0;
         : 372              else
         : 373              return __bitmap_intersects(src1, src2, nbits);
    0.00 :   ffff8000101431bc:       mov     w2, #0x100                      // #256
    0.00 :   ffff8000101431c0:       mov     x0, x20
    0.00 :   ffff8000101431c4:       mov     x1, x21
    0.00 :   ffff8000101431c8:       bl      ffff800010461ef0 <__bitmap_intersects>
         : 378              guarantee_online_cpus():
         : 386              while (!cpumask_intersects(cs->effective_cpus, cpu_online_mask)) {
    0.00 :   ffff8000101431cc:       cbnz    w0, ffff8000101431fc <guarantee_online_cpus+0x6c>
         : 387              cs = parent_cs(cs);
    0.00 :   ffff8000101431d0:       ldr     x19, [x19, #192]
         : 389              css_cs():
         : 194              return css ? container_of(css, struct cpuset, css) : NULL;
    0.00 :   ffff8000101431d4:       cbnz    x19, ffff8000101431b8 <guarantee_online_cpus+0x28>
         : 196              bitmap_copy():
         : 249              memcpy(dst, src, len);
    0.00 :   ffff8000101431d8:       ldp     x0, x1, [x21]
    0.00 :   ffff8000101431dc:       stp     x0, x1, [x22]
    0.00 :   ffff8000101431e0:       ldp     x0, x1, [x21, #16]
    0.00 :   ffff8000101431e4:       stp     x0, x1, [x22, #16]
         : 254              guarantee_online_cpus():
         : 401              cpumask_copy(pmask, cpu_online_mask);
         : 402              return;
         : 403              }
         : 404              }
         : 405              cpumask_and(pmask, cs->effective_cpus, cpu_online_mask);
         : 406              }
    0.00 :   ffff8000101431e8:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000101431ec:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000101431f0:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000101431f4:       autiasp
    0.00 :   ffff8000101431f8:       ret
         : 412              bitmap_and():
         : 286              return __bitmap_and(dst, src1, src2, nbits);
    0.00 :   ffff8000101431fc:       mov     x2, x21
    0.00 :   ffff800010143200:       mov     x1, x20
    0.00 :   ffff800010143204:       mov     x0, x22
    0.00 :   ffff800010143208:       mov     w3, #0x100                      // #256
    0.00 :   ffff80001014320c:       bl      ffff800010461d10 <__bitmap_and>
         : 292              guarantee_online_cpus():
    0.00 :   ffff800010143210:       ldp     x19, x20, [sp, #16]
  100.00 :   ffff800010143214:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff800010143218:       ldp     x29, x30, [sp], #48
    0.00 :   ffff80001014321c:       autiasp
    0.00 :   ffff800010143220:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bc950 <update_curr>:
         : 6                update_curr():
         : 840              {
         : 841              u64 wait_start, prev_wait_start;
         :
         : 843              if (!schedstat_enabled())
         : 844              return;
         :
    0.00 :   ffff8000100bc950:       paciasp
    0.00 :   ffff8000100bc954:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000100bc958:       mov     x29, sp
    0.00 :   ffff8000100bc95c:       stp     x19, x20, [sp, #16]
         : 841              wait_start = rq_clock(rq_of(cfs_rq));
    0.00 :   ffff8000100bc960:       ldr     x19, [x0, #64]
         : 842              prev_wait_start = schedstat_val(se->statistics.wait_start);
   47.41 :   ffff8000100bc964:       ldr     x1, [x0, #304]
    0.00 :   ffff8000100bc968:       ldr     x1, [x1, #2432]
         :
         : 846              if (entity_is_task(se) && task_on_rq_migrating(task_of(se)) &&
         : 847              likely(wait_start > prev_wait_start))
    0.00 :   ffff8000100bc96c:       cbz     x19, ffff8000100bc9bc <update_curr+0x6c>
         : 848              wait_start -= prev_wait_start;
         :
         : 850              __schedstat_set(se->statistics.wait_start, wait_start);
   52.59 :   ffff8000100bc970:       ldr     x20, [x19, #64]
    0.00 :   ffff8000100bc974:       sub     x20, x1, x20
         : 849              }
    0.00 :   ffff8000100bc978:       cmp     x20, #0x0
    0.00 :   ffff8000100bc97c:       b.le    ffff8000100bc9bc <update_curr+0x6c>
    0.00 :   ffff8000100bc980:       mov     x9, x0
         : 853              calc_delta_fair():
         : 660              lw = cfs_rq->load;
    0.00 :   ffff8000100bc984:       mov     x2, x20
         : 662              update_curr():
         : 857              update_stats_wait_end(struct cfs_rq *cfs_rq, struct sched_entity *se)
         : 858              {
         : 859              struct task_struct *p;
         : 860              u64 delta;
         :
         : 862              if (!schedstat_enabled())
    0.00 :   ffff8000100bc988:       ldr     x0, [x19, #72]
    0.00 :   ffff8000100bc98c:       add     x0, x0, x20
    0.00 :   ffff8000100bc990:       stp     x1, x0, [x19, #64]
         : 866              calc_delta_fair():
         : 660              lw = cfs_rq->load;
    0.00 :   ffff8000100bc994:       ldr     x1, [x19]
    0.00 :   ffff8000100bc998:       cmp     x1, #0x100, lsl #12
    0.00 :   ffff8000100bc99c:       b.ne    ffff8000100bca34 <update_curr+0xe4>  // b.any
         : 664              update_curr():
         : 860              return;
         :
         : 862              /*
    0.00 :   ffff8000100bc9a0:       ldr     x1, [x19, #80]
         : 861              * When the sched_schedstat changes from 0 to 1, some sched se
    0.00 :   ffff8000100bc9a4:       mov     x0, x9
         : 860              /*
    0.00 :   ffff8000100bc9a8:       add     x1, x1, x2
    0.00 :   ffff8000100bc9ac:       str     x1, [x19, #80]
         : 861              * When the sched_schedstat changes from 0 to 1, some sched se
    0.00 :   ffff8000100bc9b0:       bl      ffff8000100bb848 <update_min_vruntime>
         : 863              * maybe already in the runqueue, the se->statistics.wait_start
         : 864              * will be 0.So it will let the delta wrong. We need to avoid this
    0.00 :   ffff8000100bc9b4:       ldr     x0, [x19, #128]
    0.00 :   ffff8000100bc9b8:       cbz     x0, ffff8000100bc9cc <update_curr+0x7c>
         : 872              return;
         :
         : 874              delta = rq_clock(rq_of(cfs_rq)) - schedstat_val(se->statistics.wait_start);
         :
         : 876              if (entity_is_task(se)) {
         : 877              p = task_of(se);
    0.00 :   ffff8000100bc9bc:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100bc9c0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000100bc9c4:       autiasp
    0.00 :   ffff8000100bc9c8:       ret
         : 882              task_of():
         : 274              for (; se; se = se->parent)
    0.00 :   ffff8000100bc9cc:       sub     x19, x19, #0x80
         : 276              cgroup_account_cputime():
         : 779              u64 val) {}
         : 780              #endif
         :
         : 782              void __cgroup_account_cputime(struct cgroup *cgrp, u64 delta_exec);
         : 783              void __cgroup_account_cputime_field(struct cgroup *cgrp,
         : 784              enum cpu_usage_stat index, u64 delta_exec);
    0.00 :   ffff8000100bc9d0:       mov     x1, x20
    0.00 :   ffff8000100bc9d4:       mov     x0, x19
    0.00 :   ffff8000100bc9d8:       bl      ffff8000100d6e28 <cpuacct_charge>
         : 788              rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100bc9dc:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              task_css_set():
         : 481              return task_css_set_check(task, false);
    0.00 :   ffff8000100bc9e0:       ldr     x0, [x19, #2000]
         : 483              task_dfl_cgroup():
         : 550              return task_css_set(task)->dfl_cgrp;
    0.00 :   ffff8000100bc9e4:       ldr     x0, [x0, #88]
         : 552              cgroup_parent():
         : 557              if (parent_css)
    0.00 :   ffff8000100bc9e8:       ldr     x1, [x0, #192]
    0.00 :   ffff8000100bc9ec:       cbz     x1, ffff8000100bc9f8 <update_curr+0xa8>
         : 560              cgroup_account_cputime():
         :
         : 785              static inline void cgroup_account_cputime(struct task_struct *task,
         : 786              u64 delta_exec)
         : 787              {
         : 788              struct cgroup *cgrp;
    0.00 :   ffff8000100bc9f0:       mov     x1, x20
    0.00 :   ffff8000100bc9f4:       bl      ffff80001013f0a0 <__cgroup_account_cputime>
         : 791              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100bc9f8:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              get_running_cputimer():
         : 81               */
         : 82               #ifdef CONFIG_POSIX_TIMERS
         : 83               static inline
         : 84               struct thread_group_cputimer *get_running_cputimer(struct task_struct *tsk)
         : 85               {
         : 86               struct thread_group_cputimer *cputimer = &tsk->signal->cputimer;
    0.00 :   ffff8000100bc9fc:       ldr     x1, [x19, #1624]
    0.00 :   ffff8000100bca00:       add     x2, x1, #0xf8
         :
         : 88               /*
         : 89               * Check whether posix CPU timers are active. If not the thread
         : 90               * group accounting is not active either. Lockless check.
         : 91               */
         : 92               if (!READ_ONCE(tsk->signal->posix_cputimers.timers_active))
    0.00 :   ffff8000100bca04:       ldr     w0, [x1, #344]
    0.00 :   ffff8000100bca08:       cbz     w0, ffff8000100bc9bc <update_curr+0x6c>
         : 95               account_group_exec_runtime():
         : 174              static inline void account_group_exec_runtime(struct task_struct *tsk,
         : 175              unsigned long long ns)
         : 176              {
         : 177              struct thread_group_cputimer *cputimer = get_running_cputimer(tsk);
         :
         : 179              if (!cputimer)
    0.00 :   ffff8000100bca0c:       ldr     x0, [x19, #1632]
    0.00 :   ffff8000100bca10:       cmp     x0, #0x0
    0.00 :   ffff8000100bca14:       ccmp    x2, #0x0, #0x4, ne  // ne = any
    0.00 :   ffff8000100bca18:       b.eq    ffff8000100bc9bc <update_curr+0x6c>  // b.none
         : 184              arch_atomic64_add():
         : 67               }
         :
         : 69               ATOMIC64_OP(atomic64_andnot)
         : 70               ATOMIC64_OP(atomic64_or)
         : 71               ATOMIC64_OP(atomic64_xor)
         : 72               ATOMIC64_OP(atomic64_add)
    0.00 :   ffff8000100bca1c:       bl      ffff8000100bb810 <system_uses_lse_atomics>
         : 74               account_group_exec_runtime():
         : 177              return;
         :
         : 179              atomic64_add(ns, &cputimer->cputime_atomic.sum_exec_runtime);
    0.00 :   ffff8000100bca20:       add     x2, x1, #0x108
         : 181              arch_atomic64_add():
    0.00 :   ffff8000100bca24:       tst     w0, #0xff
    0.00 :   ffff8000100bca28:       b.eq    ffff8000100bca4c <update_curr+0xfc>  // b.none
         : 69               __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000100bca2c:       stadd   x20, [x2]
    0.00 :   ffff8000100bca30:       b       ffff8000100bc9bc <update_curr+0x6c>
         : 187              calc_delta_fair():
         :
    0.00 :   ffff8000100bca34:       mov     x2, x19
    0.00 :   ffff8000100bca38:       mov     x1, #0x100000                   // #1048576
    0.00 :   ffff8000100bca3c:       mov     x0, x20
    0.00 :   ffff8000100bca40:       bl      ffff8000100bbcf0 <__calc_delta>
    0.00 :   ffff8000100bca44:       mov     x2, x0
         : 663              load = &lw;
    0.00 :   ffff8000100bca48:       b       ffff8000100bc9a0 <update_curr+0x50>
         : 665              __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000100bca4c:       add     x1, x1, #0x108
    0.00 :   ffff8000100bca50:       b       ffff8000100c8080 <sched_group_set_shares+0x4e8>
    0.00 :   ffff8000100bca54:       b       ffff8000100bc9bc <update_curr+0x6c>
 Percent |	Source code & Disassembly of vmlinux for cycles (2 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000104a77b0 <cpumask_any_and_distribute>:
         : 6                cpumask_any_and_distribute():
         : 248              *
         : 249              * Returns >= nr_cpu_ids if the intersection is empty.
         : 250              */
         : 251              int cpumask_any_and_distribute(const struct cpumask *src1p,
         : 252              const struct cpumask *src2p)
         : 253              {
    0.00 :   ffff8000104a77b0:       paciasp
    0.00 :   ffff8000104a77b4:       stp     x29, x30, [sp, #-48]!
         : 256              find_next_and_bit():
         :
         : 67               val = *addr1 & *addr2 & GENMASK(size - 1, offset);
         : 68               return val ? __ffs(val) : size;
         : 69               }
         :
         : 71               return _find_next_bit(addr1, addr2, size, offset, 0UL, 0);
    0.00 :   ffff8000104a77b8:       mov     x5, #0x0                        // #0
         : 73               cpumask_any_and_distribute():
    0.00 :   ffff8000104a77bc:       mov     x29, sp
    0.00 :   ffff8000104a77c0:       stp     x19, x20, [sp, #16]
         : 252              int next, prev;
         :
         : 254              /* NOTE: our first selection will skip 0. */
         : 255              prev = __this_cpu_read(distribute_cpu_mask_prev);
    0.00 :   ffff8000104a77c4:       adrp    x19, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000104a77c8:       add     x19, x19, #0xca0
         : 248              {
    0.00 :   ffff8000104a77cc:       stp     x21, x22, [sp, #32]
         : 252              prev = __this_cpu_read(distribute_cpu_mask_prev);
    0.00 :   ffff8000104a77d0:       mov     x2, x19
         : 254              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000104a77d4:       mrs     x3, tpidr_el1
         : 46               cpumask_next_and():
         : 41               nr_cpumask_bits, n + 1);
    0.00 :   ffff8000104a77d8:       ldr     w3, [x2, x3]
         : 43               cpumask_any_and_distribute():
         :
         : 256              next = cpumask_next_and(prev, src1p, src2p);
         : 257              if (next >= nr_cpu_ids)
    0.00 :   ffff8000104a77dc:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
         : 248              {
    0.00 :   ffff8000104a77e0:       mov     x22, x1
    0.00 :   ffff8000104a77e4:       mov     x21, x0
         : 251              cpumask_next_and():
         : 41               nr_cpumask_bits, n + 1);
    0.00 :   ffff8000104a77e8:       add     w3, w3, #0x1
         : 43               find_next_and_bit():
    0.00 :   ffff8000104a77ec:       mov     x4, #0x0                        // #0
    0.00 :   ffff8000104a77f0:       mov     x2, #0x100                      // #256
    0.00 :   ffff8000104a77f4:       sxtw    x3, w3
    0.00 :   ffff8000104a77f8:       bl      ffff80001046d010 <_find_next_bit>
         : 70               cpumask_any_and_distribute():
         : 255              if (next >= nr_cpu_ids)
    0.00 :   ffff8000104a77fc:       ldr     w1, [x20, #3120]
    0.00 :   ffff8000104a7800:       cmp     w1, w0
    0.00 :   ffff8000104a7804:       b.ls    ffff8000104a7824 <cpumask_any_and_distribute+0x74>  // b.plast
         : 259              __kern_my_cpu_offset():
   49.83 :   ffff8000104a7808:       mrs     x1, tpidr_el1
         : 40               cpumask_any_and_distribute():
         : 259              next = cpumask_first_and(src1p, src2p);
         :
         : 261              if (next < nr_cpu_ids)
         : 262              __this_cpu_write(distribute_cpu_mask_prev, next);
    0.00 :   ffff8000104a780c:       str     w0, [x19, x1]
         :
         : 263              return next;
         : 264              }
    0.00 :   ffff8000104a7810:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104a7814:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000104a7818:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000104a781c:       autiasp
    0.00 :   ffff8000104a7820:       ret
         : 270              find_next_and_bit():
   50.17 :   ffff8000104a7824:       mov     x2, #0x100                      // #256
    0.00 :   ffff8000104a7828:       mov     x1, x22
    0.00 :   ffff8000104a782c:       mov     x0, x21
    0.00 :   ffff8000104a7830:       mov     x5, #0x0                        // #0
    0.00 :   ffff8000104a7834:       mov     x4, #0x0                        // #0
    0.00 :   ffff8000104a7838:       mov     x3, #0x0                        // #0
    0.00 :   ffff8000104a783c:       bl      ffff80001046d010 <_find_next_bit>
         : 73               cpumask_any_and_distribute():
         : 258              if (next < nr_cpu_ids)
    0.00 :   ffff8000104a7840:       ldr     w2, [x20, #3120]
    0.00 :   ffff8000104a7844:       cmp     w2, w0
    0.00 :   ffff8000104a7848:       b.hi    ffff8000104a7808 <cpumask_any_and_distribute+0x58>  // b.pmore
         : 262              }
    0.00 :   ffff8000104a784c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000104a7850:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000104a7854:       ldp     x29, x30, [sp], #48
    0.00 :   ffff8000104a7858:       autiasp
    0.00 :   ffff8000104a785c:       ret
 Percent |	Source code & Disassembly of perf for cycles (4 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      00000000001184e0 <__evlist__enable>:
         : 6      __evlist__enable():
         : 481    {
         : 482    __evlist__disable(evlist, evsel_name);
         : 483    }
         :
         : 485    static void __evlist__enable(struct evlist *evlist, char *evsel_name)
         : 486    {
    0.00 :   1184e0: stp     x29, x30, [sp, #-96]!
    0.00 :   1184e4: adrp    x2, 34d000 <options+0x650>
    0.00 :   1184e8: mov     x29, sp
    0.00 :   1184ec: ldr     x2, [x2, #2784]
    0.00 :   1184f0: stp     x19, x20, [sp, #16]
    0.00 :   1184f4: mov     x20, x0
    0.00 :   1184f8: stp     x21, x22, [sp, #32]
    0.00 :   1184fc: mov     x22, x1
    0.00 :   118500: stp     x23, x24, [sp, #48]
         : 486    struct evsel *pos;
         : 487    struct affinity affinity;
         : 488    int cpu, i;
         :
         : 490    if (affinity__setup(&affinity) < 0)
    0.00 :   118504: add     x24, sp, #0x40
    0.00 :   118508: mov     x0, x24
         : 481    {
    0.00 :   11850c: ldr     x1, [x2]
    0.00 :   118510: str     x1, [sp, #88]
    0.00 :   118514: mov     x1, #0x0                        // #0
         : 486    if (affinity__setup(&affinity) < 0)
    0.00 :   118518: bl      18dba0 <affinity__setup>
    0.00 :   11851c: tbnz    w0, #31, 1186a0 <__evlist__enable+0x1c0>
         : 489    evlist__cpu_iter_start():
         : 373    evlist__for_each_entry(evlist, pos)
    0.00 :   118520: ldr     x0, [x20]
    0.00 :   118524: cmp     x20, x0
    0.00 :   118528: b.eq    118540 <__evlist__enable+0x60>  // b.none
    0.00 :   11852c: nop
         : 374    pos->cpu_iter = 0;
    0.00 :   118530: str     wzr, [x0, #500]
         : 373    evlist__for_each_entry(evlist, pos)
    0.00 :   118534: ldr     x0, [x0]
    0.00 :   118538: cmp     x20, x0
    0.00 :   11853c: b.ne    118530 <__evlist__enable+0x50>  // b.any
         : 377    __evlist__enable():
         : 489    return;
         :
         : 491    evlist__for_each_cpu(evlist, i, cpu) {
    0.00 :   118540: ldr     x0, [x20, #32]
    0.00 :   118544: mov     w1, #0x0                        // #0
    0.00 :   118548: mov     w23, #0x0                       // #0
    0.00 :   11854c: bl      217db4 <perf_cpu_map__cpu>
    0.00 :   118550: mov     w21, w0
    0.00 :   118554: ldr     x0, [x20, #32]
    0.00 :   118558: bl      217e20 <perf_cpu_map__nr>
    0.00 :   11855c: cmp     w0, w23
    0.00 :   118560: b.le    11862c <__evlist__enable+0x14c>
    0.00 :   118564: nop
         : 490    affinity__set(&affinity, cpu);
    0.00 :   118568: mov     w1, w21
    0.00 :   11856c: mov     x0, x24
    0.00 :   118570: bl      18dc80 <affinity__set>
         :
         : 493    evlist__for_each_entry(evlist, pos) {
    0.00 :   118574: ldr     x19, [x20]
    0.00 :   118578: cmp     x20, x19
    0.00 :   11857c: b.eq    118608 <__evlist__enable+0x128>  // b.none
    0.00 :   118580: cbnz    x22, 1185e0 <__evlist__enable+0x100>
    0.00 :   118584: b       1186ec <__evlist__enable+0x20c>
         : 499    evsel__strcmp():
         : 401    return strcmp(pos->name, evsel_name);
    0.00 :   118588: ldr     x0, [x19, #248]
    0.00 :   11858c: mov     x1, x22
    0.00 :   118590: bl      70950 <strcmp@plt>
         : 405    __evlist__enable():
         : 493    if (evsel__strcmp(pos, evsel_name))
    0.00 :   118594: cbnz    w0, 1185d4 <__evlist__enable+0xf4>
         : 495    evsel__cpu_iter_skip_no_inc():
         : 379    if (ev->cpu_iter >= ev->core.cpus->nr)
    0.00 :   118598: ldr     x2, [x19, #144]
    0.00 :   11859c: ldr     w1, [x19, #500]
    0.00 :   1185a0: ldr     w0, [x2, #4]
    0.00 :   1185a4: cmp     w1, w0
    0.00 :   1185a8: b.ge    1185d4 <__evlist__enable+0xf4>  // b.tcont
         : 381    if (cpu >= 0 && ev->core.cpus->map[ev->cpu_iter] != cpu)
    0.00 :   1185ac: tbnz    w21, #31, 1185c0 <__evlist__enable+0xe0>
    0.00 :   1185b0: add     x2, x2, w1, sxtw #2
    0.00 :   1185b4: ldr     w0, [x2, #8]
    0.00 :   1185b8: cmp     w21, w0
    0.00 :   1185bc: b.ne    1185d4 <__evlist__enable+0xf4>  // b.any
         : 387    __evlist__enable():
         : 497    continue;
         : 498    if (evsel__cpu_iter_skip(pos, cpu))
         : 499    continue;
         : 500    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   1185c0: ldr     x0, [x19, #488]
         : 502    evsel__cpu_iter_skip():
         : 389    ev->cpu_iter++;
    0.00 :   1185c4: add     w2, w1, #0x1
    0.00 :   1185c8: str     w2, [x19, #500]
         : 392    __evlist__enable():
         : 497    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   1185cc: cmp     x0, x19
    0.00 :   1185d0: b.eq    11872c <__evlist__enable+0x24c>  // b.none
         : 492    evlist__for_each_entry(evlist, pos) {
    0.00 :   1185d4: ldr     x19, [x19]
    0.00 :   1185d8: cmp     x20, x19
    0.00 :   1185dc: b.eq    118608 <__evlist__enable+0x128>  // b.none
         : 496    evsel__is_dummy_event():
         : 456    evsel->synth_sample_type & PERF_SAMPLE_BRANCH_STACK;
         : 457    }
         :
         : 459    static inline bool evsel__is_dummy_event(struct evsel *evsel)
         : 460    {
         : 461    return (evsel->core.attr.type == PERF_TYPE_SOFTWARE) &&
    0.00 :   1185e0: ldr     w2, [x19, #16]
    0.00 :   1185e4: cmp     w2, #0x1
    0.00 :   1185e8: b.ne    118588 <__evlist__enable+0xa8>  // b.any
    0.00 :   1185ec: ldr     x0, [x19, #24]
    0.00 :   1185f0: cmp     x0, #0x9
    0.00 :   1185f4: b.ne    118588 <__evlist__enable+0xa8>  // b.any
         : 468    __evlist__enable():
    0.00 :   1185f8: ldr     x19, [x19]
    0.00 :   1185fc: cmp     x20, x19
    0.00 :   118600: b.ne    1185e0 <__evlist__enable+0x100>  // b.any
    0.00 :   118604: nop
         : 489    evlist__for_each_cpu(evlist, i, cpu) {
   42.50 :   118608: ldr     x0, [x20, #32]
    0.00 :   11860c: add     w23, w23, #0x1
    0.00 :   118610: mov     w1, w23
    0.00 :   118614: bl      217db4 <perf_cpu_map__cpu>
    0.00 :   118618: mov     w21, w0
    0.00 :   11861c: ldr     x0, [x20, #32]
    0.00 :   118620: bl      217e20 <perf_cpu_map__nr>
    0.00 :   118624: cmp     w0, w23
    0.00 :   118628: b.gt    118568 <__evlist__enable+0x88>
         : 502    continue;
         : 503    evsel__enable_cpu(pos, pos->cpu_iter - 1);
         : 504    }
         : 505    }
         : 506    affinity__cleanup(&affinity);
    0.00 :   11862c: mov     x0, x24
    0.00 :   118630: bl      18dd60 <affinity__cleanup>
         : 503    evlist__for_each_entry(evlist, pos) {
    0.00 :   118634: ldr     x19, [x20]
    0.00 :   118638: cmp     x20, x19
    0.00 :   11863c: b.eq    118698 <__evlist__enable+0x1b8>  // b.none
    0.00 :   118640: cbnz    x22, 118670 <__evlist__enable+0x190>
    0.00 :   118644: b       118758 <__evlist__enable+0x278>
         : 509    evsel__strcmp():
         : 401    return strcmp(pos->name, evsel_name);
    0.00 :   118648: ldr     x0, [x19, #248]
    0.00 :   11864c: mov     x1, x22
    0.00 :   118650: bl      70950 <strcmp@plt>
         : 405    __evlist__enable():
         : 504    if (evsel__strcmp(pos, evsel_name))
    0.00 :   118654: cbnz    w0, 118664 <__evlist__enable+0x184>
         : 506    continue;
         : 507    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   118658: ldr     x0, [x19, #488]
    0.00 :   11865c: cmp     x0, x19
    0.00 :   118660: b.eq    118768 <__evlist__enable+0x288>  // b.none
         : 503    evlist__for_each_entry(evlist, pos) {
    0.00 :   118664: ldr     x19, [x19]
    0.00 :   118668: cmp     x20, x19
    0.00 :   11866c: b.eq    118698 <__evlist__enable+0x1b8>  // b.none
         : 507    evsel__is_dummy_event():
    0.00 :   118670: ldr     w0, [x19, #16]
    0.00 :   118674: cmp     w0, #0x1
    0.00 :   118678: b.ne    118648 <__evlist__enable+0x168>  // b.any
    0.00 :   11867c: ldr     x0, [x19, #24]
    0.00 :   118680: cmp     x0, #0x9
    0.00 :   118684: b.ne    118648 <__evlist__enable+0x168>  // b.any
         : 462    __evlist__enable():
    0.00 :   118688: ldr     x19, [x19]
    0.00 :   11868c: cmp     x20, x19
    0.00 :   118690: b.ne    118670 <__evlist__enable+0x190>  // b.any
    0.00 :   118694: nop
         : 516    /*
         : 517    * Even single event sets the 'enabled' for evlist,
         : 518    * so the toggle can work properly and toggle to
         : 519    * 'disabled' state.
         : 520    */
         : 521    evlist->enabled = true;
    0.00 :   118698: mov     w0, #0x1                        // #1
    0.00 :   11869c: strb    w0, [x20, #2180]
         : 517    }
    0.00 :   1186a0: adrp    x0, 34d000 <options+0x650>
    0.00 :   1186a4: ldr     x0, [x0, #2784]
    0.00 :   1186a8: ldr     x1, [sp, #88]
    0.00 :   1186ac: ldr     x2, [x0]
    0.00 :   1186b0: subs    x1, x1, x2
    0.00 :   1186b4: mov     x2, #0x0                        // #0
    0.00 :   1186b8: b.ne    118778 <__evlist__enable+0x298>  // b.any
    0.00 :   1186bc: ldp     x19, x20, [sp, #16]
    0.00 :   1186c0: ldp     x21, x22, [sp, #32]
    0.00 :   1186c4: ldp     x23, x24, [sp, #48]
    0.00 :   1186c8: ldp     x29, x30, [sp], #96
    0.00 :   1186cc: ret
         : 497    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   1186d0: ldr     x0, [x19, #168]
    0.00 :   1186d4: cbz     x0, 1186e0 <__evlist__enable+0x200>
         : 499    evsel__enable_cpu(pos, pos->cpu_iter - 1);
    0.00 :   1186d8: mov     x0, x19
    0.00 :   1186dc: bl      1218f0 <evsel__enable_cpu>
         : 492    evlist__for_each_entry(evlist, pos) {
    0.00 :   1186e0: ldr     x19, [x19]
    0.00 :   1186e4: cmp     x20, x19
    0.00 :   1186e8: b.eq    118608 <__evlist__enable+0x128>  // b.none
         : 496    evsel__cpu_iter_skip_no_inc():
         : 379    if (ev->cpu_iter >= ev->core.cpus->nr)
   39.29 :   1186ec: ldr     x0, [x19, #144]
   18.20 :   1186f0: ldr     w1, [x19, #500]
    0.00 :   1186f4: ldr     w2, [x0, #4]
    0.00 :   1186f8: cmp     w1, w2
    0.00 :   1186fc: b.ge    1186e0 <__evlist__enable+0x200>  // b.tcont
         : 381    if (cpu >= 0 && ev->core.cpus->map[ev->cpu_iter] != cpu)
    0.00 :   118700: tbnz    w21, #31, 118714 <__evlist__enable+0x234>
    0.00 :   118704: add     x0, x0, w1, sxtw #2
    0.00 :   118708: ldr     w0, [x0, #8]
    0.00 :   11870c: cmp     w21, w0
    0.00 :   118710: b.ne    1186e0 <__evlist__enable+0x200>  // b.any
         : 387    __evlist__enable():
         : 497    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   118714: ldr     x0, [x19, #488]
         : 499    evsel__cpu_iter_skip():
         : 389    ev->cpu_iter++;
    0.00 :   118718: add     w2, w1, #0x1
    0.00 :   11871c: str     w2, [x19, #500]
         : 392    __evlist__enable():
         : 497    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   118720: cmp     x0, x19
    0.00 :   118724: b.ne    1186e0 <__evlist__enable+0x200>  // b.any
    0.00 :   118728: b       1186d0 <__evlist__enable+0x1f0>
    0.00 :   11872c: ldr     x0, [x19, #168]
    0.00 :   118730: cbz     x0, 1185d4 <__evlist__enable+0xf4>
         : 499    evsel__enable_cpu(pos, pos->cpu_iter - 1);
    0.00 :   118734: mov     x0, x19
    0.00 :   118738: bl      1218f0 <evsel__enable_cpu>
    0.00 :   11873c: b       1185d4 <__evlist__enable+0xf4>
         : 506    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   118740: ldr     x0, [x19, #168]
    0.00 :   118744: cbz     x0, 11874c <__evlist__enable+0x26c>
         : 508    pos->disabled = false;
    0.00 :   118748: strb    wzr, [x19, #467]
         : 503    evlist__for_each_entry(evlist, pos) {
    0.00 :   11874c: ldr     x19, [x19]
    0.00 :   118750: cmp     x20, x19
    0.00 :   118754: b.eq    118698 <__evlist__enable+0x1b8>  // b.none
         : 506    if (!evsel__is_group_leader(pos) || !pos->core.fd)
    0.00 :   118758: ldr     x0, [x19, #488]
    0.00 :   11875c: cmp     x0, x19
    0.00 :   118760: b.ne    11874c <__evlist__enable+0x26c>  // b.any
    0.00 :   118764: b       118740 <__evlist__enable+0x260>
    0.00 :   118768: ldr     x0, [x19, #168]
    0.00 :   11876c: cbz     x0, 118664 <__evlist__enable+0x184>
         : 508    pos->disabled = false;
    0.00 :   118770: strb    wzr, [x19, #467]
    0.00 :   118774: b       118664 <__evlist__enable+0x184>
         : 517    }
    0.00 :   118778: bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of perf for cycles (2 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      000000000018d120 <cpu__max_cpu>:
         : 6      cpu__max_cpu():
         :
         : 408    return max_node_num;
         : 409    }
         :
         : 411    int cpu__max_cpu(void)
         : 412    {
    0.00 :   18d120: stp     x29, x30, [sp, #-48]!
    0.00 :   18d124: adrp    x1, 34d000 <options+0x650>
    0.00 :   18d128: mov     x29, sp
    0.00 :   18d12c: ldr     x1, [x1, #2784]
    0.00 :   18d130: str     x19, [sp, #16]
         : 408    if (unlikely(!max_cpu_num))
    0.00 :   18d134: adrp    x19, 3db000 <fncache_hash+0x150>
         : 407    {
    0.00 :   18d138: ldr     x2, [x1]
    0.00 :   18d13c: str     x2, [sp, #40]
    0.00 :   18d140: mov     x2, #0x0                        // #0
         : 408    if (unlikely(!max_cpu_num))
    0.00 :   18d144: ldr     w0, [x19, #2200]
    0.00 :   18d148: cbz     w0, 18d174 <cpu__max_cpu+0x54>
         : 412    set_max_cpu_num();
         :
         : 414    return max_cpu_num;
         : 415    }
  100.00 :   18d14c: adrp    x1, 34d000 <options+0x650>
    0.00 :   18d150: ldr     x1, [x1, #2784]
    0.00 :   18d154: ldr     x2, [sp, #40]
    0.00 :   18d158: ldr     x3, [x1]
    0.00 :   18d15c: subs    x2, x2, x3
    0.00 :   18d160: mov     x3, #0x0                        // #0
    0.00 :   18d164: b.ne    18d180 <cpu__max_cpu+0x60>  // b.any
    0.00 :   18d168: ldr     x19, [sp, #16]
    0.00 :   18d16c: ldp     x29, x30, [sp], #48
    0.00 :   18d170: ret
         : 409    set_max_cpu_num();
    0.00 :   18d174: bl      18b940 <set_max_cpu_num>
         : 411    return max_cpu_num;
    0.00 :   18d178: ldr     w0, [x19, #2200]
    0.00 :   18d17c: b       18d14c <cpu__max_cpu+0x2c>
         : 412    }
    0.00 :   18d180: bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (215 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101280e0 <generic_exec_single>:
         : 6                generic_exec_single():
         : 505              * Insert a previously allocated call_single_data_t element
         : 506              * for execution on the given CPU. data must already have
         : 507              * ->func, ->info, and ->flags set.
         : 508              */
         : 509              static int generic_exec_single(int cpu, struct __call_single_data *csd)
         : 510              {
    0.00 :   ffff8000101280e0:       paciasp
    0.00 :   ffff8000101280e4:       stp     x29, x30, [sp, #-32]!
         : 506              if (cpu == smp_processor_id()) {
    0.00 :   ffff8000101280e8:       adrp    x2, ffff80001176d000 <cpu_number>
         : 505              {
    0.00 :   ffff8000101280ec:       mov     x29, sp
         : 506              if (cpu == smp_processor_id()) {
    0.00 :   ffff8000101280f0:       add     x2, x2, #0x0
         : 505              {
    0.00 :   ffff8000101280f4:       mov     x5, x1
         : 507              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff8000101280f8:       mrs     x4, tpidr_el1
         : 46               generic_exec_single():
         : 506              if (cpu == smp_processor_id()) {
    0.00 :   ffff8000101280fc:       ldr     w2, [x2, x4]
    0.00 :   ffff800010128100:       cmp     w2, w0
    0.00 :   ffff800010128104:       b.eq    ffff800010128154 <generic_exec_single+0x74>  // b.none
         : 524              csd_lock_record(NULL);
         : 525              local_irq_restore(flags);
         : 526              return 0;
         : 527              }
         :
         : 529              if ((unsigned)cpu >= nr_cpu_ids || !cpu_online(cpu)) {
    0.00 :   ffff800010128108:       adrp    x2, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001012810c:       ldr     w2, [x2, #3120]
    0.00 :   ffff800010128110:       cmp     w0, w2
    0.00 :   ffff800010128114:       b.cs    ffff8000101281d4 <generic_exec_single+0xf4>  // b.hs, b.nlast
         : 534              test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010128118:       cmp     w0, #0x0
    0.00 :   ffff80001012811c:       add     w2, w0, #0x3f
    0.00 :   ffff800010128120:       csel    w2, w2, w0, lt  // lt = tstop
    0.00 :   ffff800010128124:       adrp    x4, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff800010128128:       add     x4, x4, #0x9e8
    0.00 :   ffff80001012812c:       asr     w2, w2, #6
    0.00 :   ffff800010128130:       sxtw    x2, w2
    0.00 :   ffff800010128134:       ldr     x2, [x4, x2, lsl #3]
    0.00 :   ffff800010128138:       lsr     x3, x2, x0
         : 121              generic_exec_single():
    0.00 :   ffff80001012813c:       tbz     w3, #0, ffff8000101281d4 <generic_exec_single+0xf4>
         : 529              csd_unlock(csd);
         : 530              return -ENXIO;
         : 531              }
         :
         : 533              __smp_call_single_queue(cpu, &csd->node.llist);
    0.00 :   ffff800010128140:       bl      ffff800010128078 <__smp_call_single_queue>
         :
         : 532              return 0;
    0.00 :   ffff800010128144:       mov     w0, #0x0                        // #0
         : 532              }
    0.00 :   ffff800010128148:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001012814c:       autiasp
    0.00 :   ffff800010128150:       ret
         : 507              smp_call_func_t func = csd->func;
    0.00 :   ffff800010128154:       str     x19, [sp, #16]
         : 509              csd_unlock():
         : 459              WARN_ON(!(csd->node.u_flags & CSD_FLAG_LOCK));
    0.00 :   ffff800010128158:       ldr     w2, [x1, #8]
         : 461              generic_exec_single():
         : 508              void *info = csd->info;
    0.00 :   ffff80001012815c:       ldp     x1, x0, [x1, #16]
         : 510              csd_unlock():
         : 459              WARN_ON(!(csd->node.u_flags & CSD_FLAG_LOCK));
    0.00 :   ffff800010128160:       tbz     w2, #0, ffff8000101281cc <generic_exec_single+0xec>
         : 464              smp_store_release(&csd->node.u_flags, 0);
    0.00 :   ffff800010128164:       mov     w2, #0x0                        // #0
    0.00 :   ffff800010128168:       add     x3, x5, #0x8
    0.00 :   ffff80001012816c:       stlr    w2, [x3]
         : 468              arch_local_save_flags():
         : 70               */
         : 71               static inline unsigned long arch_local_save_flags(void)
         : 72               {
         : 73               unsigned long flags;
         :
         : 75               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010128170:       mrs     x19, daif
         : 77               arch_irqs_disabled_flags():
         :
         : 86               static inline int arch_irqs_disabled_flags(unsigned long flags)
         : 87               {
         : 88               int res;
         :
         : 90               asm volatile(ALTERNATIVE(
    0.00 :   ffff800010128174:       and     w2, w19, #0x80
         : 92               arch_local_irq_save():
         :
         : 112              /*
         : 113              * There are too many states with IRQs disabled, just keep the current
         : 114              * state if interrupts are already disabled/masked.
         : 115              */
         : 116              if (!arch_irqs_disabled_flags(flags))
    0.00 :   ffff800010128178:       cbz     w2, ffff8000101281b4 <generic_exec_single+0xd4>
         : 118              generic_exec_single():
         : 518              func(info);
    0.00 :   ffff80001012817c:       blr     x1
         : 520              arch_local_irq_restore():
         : 122              /*
         : 123              * restore saved IRQ state
         : 124              */
         : 125              static inline void arch_local_irq_restore(unsigned long flags)
         : 126              {
         : 127              asm volatile(ALTERNATIVE(
   18.84 :   ffff800010128180:       msr     daif, x19
         : 129              arch_static_branch():
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
   77.78 :   ffff800010128184:       nop
         : 28               generic_exec_single():
         : 521              return 0;
    0.00 :   ffff800010128188:       mov     w0, #0x0                        // #0
    0.00 :   ffff80001012818c:       ldr     x19, [sp, #16]
         : 532              }
    0.00 :   ffff800010128190:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010128194:       autiasp
    0.00 :   ffff800010128198:       ret
         : 536              arch_local_irq_restore():
         : 130              ARM64_HAS_IRQ_PRIO_MASKING)
         : 131              :
         : 132              : "r" (flags)
         : 133              : "memory");
         :
         : 135              pmr_sync();
    0.00 :   ffff80001012819c:       dsb     sy
         : 137              generic_exec_single():
         : 521              return 0;
    3.38 :   ffff8000101281a0:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000101281a4:       ldr     x19, [sp, #16]
         : 532              }
    0.00 :   ffff8000101281a8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000101281ac:       autiasp
    0.00 :   ffff8000101281b0:       ret
         : 536              arch_static_branch():
    0.00 :   ffff8000101281b4:       nop
    0.00 :   ffff8000101281b8:       mov     x2, #0x60                       // #96
         : 23               arch_local_irq_disable():
         : 54               asm volatile(ALTERNATIVE(
    0.00 :   ffff8000101281bc:       msr     daifset, #0x3
    0.00 :   ffff8000101281c0:       b       ffff80001012817c <generic_exec_single+0x9c>
         : 57               arch_static_branch():
    0.00 :   ffff8000101281c4:       mov     x2, #0xa0                       // #160
    0.00 :   ffff8000101281c8:       b       ffff8000101281bc <generic_exec_single+0xdc>
         : 23               csd_unlock():
         : 459              WARN_ON(!(csd->node.u_flags & CSD_FLAG_LOCK));
    0.00 :   ffff8000101281cc:       brk     #0x800
    0.00 :   ffff8000101281d0:       b       ffff800010128164 <generic_exec_single+0x84>
    0.00 :   ffff8000101281d4:       ldr     w0, [x5, #8]
    0.00 :   ffff8000101281d8:       tbz     w0, #0, ffff8000101281f0 <generic_exec_single+0x110>
         : 464              smp_store_release(&csd->node.u_flags, 0);
    0.00 :   ffff8000101281dc:       mov     w0, #0x0                        // #0
    0.00 :   ffff8000101281e0:       add     x1, x5, #0x8
    0.00 :   ffff8000101281e4:       stlr    w0, [x1]
         : 468              generic_exec_single():
         : 526              return -ENXIO;
    0.00 :   ffff8000101281e8:       mov     w0, #0xfffffffa                 // #-6
    0.00 :   ffff8000101281ec:       b       ffff800010128148 <generic_exec_single+0x68>
         : 529              csd_unlock():
         : 459              WARN_ON(!(csd->node.u_flags & CSD_FLAG_LOCK));
    0.00 :   ffff8000101281f0:       brk     #0x800
    0.00 :   ffff8000101281f4:       b       ffff8000101281dc <generic_exec_single+0xfc>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100bbcf0 <__calc_delta>:
         : 6                __calc_delta():
         : 237              *
         : 238              * Or, weight =< lw.weight (because lw.weight is the runqueue weight), thus
         : 239              * weight/lw.weight <= 1, and therefore our shift will also be positive.
         : 240              */
         : 241              static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight *lw)
         : 242              {
  100.00 :   ffff8000100bbcf0:       paciasp
    0.00 :   ffff8000100bbcf4:       mov     x5, x0
    0.00 :   ffff8000100bbcf8:       ldr     w4, [x2, #8]
         : 238              u64 fact = scale_load_down(weight);
    0.00 :   ffff8000100bbcfc:       cbz     x1, ffff8000100bbd80 <__calc_delta+0x90>
    0.00 :   ffff8000100bbd00:       lsr     x3, x1, #10
    0.00 :   ffff8000100bbd04:       mov     x0, #0x2                        // #2
    0.00 :   ffff8000100bbd08:       cmp     x3, x0
    0.00 :   ffff8000100bbd0c:       csel    x3, x3, x0, cs  // cs = hs, nlast
         : 239              u32 fact_hi = (u32)(fact >> 32);
    0.00 :   ffff8000100bbd10:       lsr     x1, x3, #32
    0.00 :   ffff8000100bbd14:       mov     w0, w1
         : 242              __update_inv_weight():
         : 211              if (likely(lw->inv_weight))
    0.00 :   ffff8000100bbd18:       cbz     w4, ffff8000100bbd8c <__calc_delta+0x9c>
    0.00 :   ffff8000100bbd1c:       mov     w4, w4
         : 214              __calc_delta():
         : 240              int shift = WMULT_SHIFT;
    0.00 :   ffff8000100bbd20:       mov     w2, #0x20                       // #32
         : 245              int fs;
         :
         : 247              __update_inv_weight(lw);
         :
         : 249              if (unlikely(fact_hi)) {
    0.00 :   ffff8000100bbd24:       cbnz    x1, ffff8000100bbda4 <__calc_delta+0xb4>
         : 251              mul_u32_u32():
         : 152              /*
         : 153              * Many a GCC version messes this up and generates a 64x64 mult :-(
         : 154              */
         : 155              static inline u64 mul_u32_u32(u32 a, u32 b)
         : 156              {
         : 157              return (u64)a * b;
    0.00 :   ffff8000100bbd28:       and     x3, x3, #0xffffffff
    0.00 :   ffff8000100bbd2c:       mul     x3, x3, x4
         : 160              __calc_delta():
         : 253              fact >>= fs;
         : 254              }
         :
         : 256              fact = mul_u32_u32(fact, lw->inv_weight);
         :
         : 258              fact_hi = (u32)(fact >> 32);
    0.00 :   ffff8000100bbd30:       lsr     x1, x3, #32
         : 254              if (fact_hi) {
    0.00 :   ffff8000100bbd34:       cbz     x1, ffff8000100bbdb8 <__calc_delta+0xc8>
         : 256              fls():
         : 14               * This is defined the same way as ffs.
         : 15               * Note fls(0) = 0, fls(1) = 1, fls(0x80000000) = 32.
         : 16               */
         : 17               static __always_inline int fls(unsigned int x)
         : 18               {
         : 19               return x ? sizeof(x) * 8 - __builtin_clz(x) : 0;
    0.00 :   ffff8000100bbd38:       clz     w1, w1
    0.00 :   ffff8000100bbd3c:       mov     w4, #0x20                       // #32
    0.00 :   ffff8000100bbd40:       sub     w4, w4, w1
         : 23               __calc_delta():
         : 256              fs = fls(fact_hi);
         : 257              shift -= fs;
    0.00 :   ffff8000100bbd44:       sub     w1, w2, w4
         : 257              fact >>= fs;
    0.00 :   ffff8000100bbd48:       lsr     x3, x3, x4
    0.00 :   ffff8000100bbd4c:       mvn     w4, w1
    0.00 :   ffff8000100bbd50:       mov     w3, w3
    0.00 :   ffff8000100bbd54:       tst     x1, #0x40
    0.00 :   ffff8000100bbd58:       umulh   x2, x3, x5
    0.00 :   ffff8000100bbd5c:       mul     x0, x3, x5
    0.00 :   ffff8000100bbd60:       lsl     x3, x2, #1
    0.00 :   ffff8000100bbd64:       lsr     x2, x2, x1
    0.00 :   ffff8000100bbd68:       lsr     x0, x0, x1
    0.00 :   ffff8000100bbd6c:       lsl     x1, x3, x4
    0.00 :   ffff8000100bbd70:       orr     x0, x1, x0
    0.00 :   ffff8000100bbd74:       csel    x0, x0, x2, eq  // eq = none
         : 261              }
         :
         : 263              return mul_u64_u32_shr(delta_exec, fact, shift);
         : 264              }
    0.00 :   ffff8000100bbd78:       autiasp
    0.00 :   ffff8000100bbd7c:       ret
         : 267              __update_inv_weight():
         : 211              if (likely(lw->inv_weight))
    0.00 :   ffff8000100bbd80:       mov     x0, #0x0                        // #0
    0.00 :   ffff8000100bbd84:       mov     x3, #0x0                        // #0
    0.00 :   ffff8000100bbd88:       cbnz    w4, ffff8000100bbd78 <__calc_delta+0x88>
    0.00 :   ffff8000100bbd8c:       ldr     x4, [x2]
         : 214              w = scale_load_down(lw->weight);
    0.00 :   ffff8000100bbd90:       cbnz    x4, ffff8000100bbde4 <__calc_delta+0xf4>
         : 219              lw->inv_weight = WMULT_CONST;
    0.00 :   ffff8000100bbd94:       mov     w6, #0xffffffff                 // #-1
    0.00 :   ffff8000100bbd98:       mov     x4, #0xffffffff                 // #4294967295
    0.00 :   ffff8000100bbd9c:       str     w6, [x2, #8]
    0.00 :   ffff8000100bbda0:       b       ffff8000100bbd20 <__calc_delta+0x30>
         : 224              fls():
    0.00 :   ffff8000100bbda4:       clz     w0, w0
    0.00 :   ffff8000100bbda8:       sub     w0, w2, w0
         : 16               __calc_delta():
         : 247              shift -= fs;
    0.00 :   ffff8000100bbdac:       sub     w2, w2, w0
         : 248              fact >>= fs;
    0.00 :   ffff8000100bbdb0:       lsr     x3, x3, x0
    0.00 :   ffff8000100bbdb4:       b       ffff8000100bbd28 <__calc_delta+0x38>
    0.00 :   ffff8000100bbdb8:       umulh   x0, x3, x5
    0.00 :   ffff8000100bbdbc:       mvn     w6, w2
    0.00 :   ffff8000100bbdc0:       mul     x3, x3, x5
    0.00 :   ffff8000100bbdc4:       tst     x2, #0x40
    0.00 :   ffff8000100bbdc8:       lsl     x4, x0, #1
    0.00 :   ffff8000100bbdcc:       lsr     x1, x0, x2
    0.00 :   ffff8000100bbdd0:       lsr     x0, x3, x2
    0.00 :   ffff8000100bbdd4:       lsl     x2, x4, x6
    0.00 :   ffff8000100bbdd8:       orr     x0, x2, x0
    0.00 :   ffff8000100bbddc:       csel    x0, x0, x1, eq  // eq = none
    0.00 :   ffff8000100bbde0:       b       ffff8000100bbd78 <__calc_delta+0x88>
         : 262              __update_inv_weight():
         : 214              w = scale_load_down(lw->weight);
    0.00 :   ffff8000100bbde4:       lsr     x4, x4, #10
    0.00 :   ffff8000100bbde8:       mov     x6, #0x2                        // #2
    0.00 :   ffff8000100bbdec:       cmp     x4, x6
         : 216              if (BITS_PER_LONG > 32 && unlikely(w >= WMULT_CONST))
    0.00 :   ffff8000100bbdf0:       mov     x7, #0xfffffffe                 // #4294967294
         : 214              w = scale_load_down(lw->weight);
    0.00 :   ffff8000100bbdf4:       csel    x6, x4, x6, cs  // cs = hs, nlast
         : 216              if (BITS_PER_LONG > 32 && unlikely(w >= WMULT_CONST))
    0.00 :   ffff8000100bbdf8:       cmp     x4, x7
    0.00 :   ffff8000100bbdfc:       b.hi    ffff8000100bbe10 <__calc_delta+0x120>  // b.pmore
         : 221              lw->inv_weight = WMULT_CONST / w;
    0.00 :   ffff8000100bbe00:       mov     x4, #0xffffffff                 // #4294967295
    0.00 :   ffff8000100bbe04:       udiv    x4, x4, x6
    0.00 :   ffff8000100bbe08:       str     w4, [x2, #8]
    0.00 :   ffff8000100bbe0c:       b       ffff8000100bbd20 <__calc_delta+0x30>
         : 217              lw->inv_weight = 1;
    0.00 :   ffff8000100bbe10:       mov     w6, #0x1                        // #1
    0.00 :   ffff8000100bbe14:       mov     x4, #0x1                        // #1
    0.00 :   ffff8000100bbe18:       str     w6, [x2, #8]
    0.00 :   ffff8000100bbe1c:       b       ffff8000100bbd20 <__calc_delta+0x30>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100c0a08 <dequeue_task_fair>:
         : 6                dequeue_task_fair():
         : 5622             for_each_sched_entity(se) {
         : 5623             cfs_rq = cfs_rq_of(se);
         :
         : 5625             update_load_avg(cfs_rq, se, UPDATE_TG);
         : 5626             se_update_runnable(se);
         : 5627             update_cfs_group(se);
    0.00 :   ffff8000100c0a08:       paciasp
    0.00 :   ffff8000100c0a0c:       stp     x29, x30, [sp, #-128]!
    0.00 :   ffff8000100c0a10:       mov     x29, sp
    0.00 :   ffff8000100c0a14:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c0a18:       mov     x22, x1
    0.00 :   ffff8000100c0a1c:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c0a20:       mov     x23, x0
         :
         : 5626             cfs_rq->h_nr_running--;
         : 5627             cfs_rq->idle_h_nr_running -= idle_h_nr_running;
    0.00 :   ffff8000100c0a24:       and     w0, w2, #0x1
         : 5622             update_cfs_group(se);
    0.00 :   ffff8000100c0a28:       stp     x25, x26, [sp, #64]
         : 5624             idle_policy():
         : 164              */
         : 165              #define RUNTIME_INF             ((u64)~0ULL)
         :
         : 167              static inline int idle_policy(int policy)
         : 168              {
         : 169              return policy == SCHED_IDLE;
    0.00 :   ffff8000100c0a2c:       ldr     w3, [x1, #672]
         : 171              dequeue_task_fair():
         : 5625             cfs_rq->idle_h_nr_running -= idle_h_nr_running;
    0.00 :   ffff8000100c0a30:       str     w0, [sp, #112]
         : 5627             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100c0a34:       ldr     x0, [x1, #376]
         : 3905             idle_policy():
    0.00 :   ffff8000100c0a38:       cmp     w3, #0x5
         : 165              sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c0a3c:       ldr     w4, [x23, #152]
         : 5497             idle_policy():
  100.00 :   ffff8000100c0a40:       cset    w21, eq  // eq = none
         : 165              dequeue_task_fair():
         :
         : 5628             /* end evaluation on encountering a throttled cfs_rq */
    0.00 :   ffff8000100c0a44:       ldr     w1, [x23, #4]
         : 5630             _task_util_est():
         : 3903             struct task_struct *p)
    0.00 :   ffff8000100c0a48:       lsr     x3, x0, #32
         : 3905             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c0a4c:       cmp     w4, w1
         : 5497             util_est_dequeue():
         : 3952             * skip the util_est update.
    0.00 :   ffff8000100c0a50:       ldr     w4, [x23, #312]
         : 3954             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c0a54:       cset    w26, eq  // eq = none
    0.00 :   ffff8000100c0a58:       cmp     w1, #0x0
    0.00 :   ffff8000100c0a5c:       csel    w5, w26, wzr, ne  // ne = any
         : 5499             _task_util_est():
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100c0a60:       cmp     w0, w3
    0.00 :   ffff8000100c0a64:       csel    w0, w0, w3, hi  // hi = pmore
         : 3908             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c0a68:       str     w5, [sp, #116]
         : 5497             _task_util_est():
         : 3905             unsigned int enqueued;
    0.00 :   ffff8000100c0a6c:       orr     w0, w0, #0x1
         : 3907             util_est_dequeue():
         : 3953             */
    0.00 :   ffff8000100c0a70:       cmp     w0, w4
    0.00 :   ffff8000100c0a74:       csel    w0, w0, w4, ls  // ls = plast
         : 3956             dequeue_task_fair():
         : 5631             if (cfs_rq_throttled(cfs_rq))
         : 5632             goto dequeue_throttle;
         :
         : 5634             }
    0.00 :   ffff8000100c0a78:       adds    x26, x22, #0x80
         : 5636             util_est_dequeue():
         : 3953             */
    0.00 :   ffff8000100c0a7c:       sub     w0, w4, w0
         : 3954             ue = p->se.avg.util_est;
    0.00 :   ffff8000100c0a80:       str     w0, [x23, #312]
         : 3956             dequeue_task_fair():
         : 5631             }
    0.00 :   ffff8000100c0a84:       b.eq    ffff8000100c0bf0 <dequeue_task_fair+0x1e8>  // b.none
         : 5633             update_tg_load_avg():
         :
    0.00 :   ffff8000100c0a88:       adrp    x24, ffff800011f28000 <ucounts_hashtable+0x1a88>
    0.00 :   ffff8000100c0a8c:       add     x0, x24, #0x5c0
    0.00 :   ffff8000100c0a90:       stp     x19, x20, [sp, #16]
         : 3326             dequeue_task_fair():
         : 5631             }
    0.00 :   ffff8000100c0a94:       mov     w20, w2
    0.00 :   ffff8000100c0a98:       stp     x27, x28, [sp, #80]
         : 5634             cpufreq_update_util():
         : 2509             __acquires(this_rq->lock)
         : 2510             {
         : 2511             raw_spin_rq_unlock(this_rq);
         : 2512             double_rq_lock(this_rq, busiest);
         :
         : 2514             return 1;
    0.00 :   ffff8000100c0a9c:       adrp    x27, ffff80001176f000 <kvm_hyp_ctxt+0xf0>
         : 2516             update_tg_load_avg():
         :
    0.00 :   ffff8000100c0aa0:       str     x0, [sp, #104]
         : 3324             cpufreq_update_util():
    0.00 :   ffff8000100c0aa4:       add     x0, x27, #0x8c0
    0.00 :   ffff8000100c0aa8:       str     x0, [sp, #120]
    0.00 :   ffff8000100c0aac:       nop
         : 2512             dequeue_task_fair():
         :
    0.00 :   ffff8000100c0ab0:       ldr     x19, [x26, #120]
         : 5634             dequeue_entity():
         : 4333             * further than we started -- ie. we'll be penalized.
    0.00 :   ffff8000100c0ab4:       mov     x0, x19
    0.00 :   ffff8000100c0ab8:       bl      ffff8000100bc950 <update_curr>
         : 4336             cfs_rq_clock_pelt():
         : 162              #else
         :
         : 164              static inline int
         : 165              update_cfs_rq_load_avg(u64 now, struct cfs_rq *cfs_rq)
         : 166              {
         : 167              return 0;
    0.00 :   ffff8000100c0abc:       ldr     x0, [x19, #304]
         : 169              update_load_avg():
         : 3799             static inline u64 cfs_rq_last_update_time(struct cfs_rq *cfs_rq)
    0.00 :   ffff8000100c0ac0:       ldr     x1, [x26, #192]
         : 3801             rq_clock_pelt():
         :
    0.00 :   ffff8000100c0ac4:       ldr     x4, [x0, #2440]
    0.00 :   ffff8000100c0ac8:       ldr     x0, [x0, #2448]
    0.00 :   ffff8000100c0acc:       sub     x27, x4, x0
         : 151              update_load_avg():
    0.00 :   ffff8000100c0ad0:       cbz     x1, ffff8000100c0ae4 <dequeue_task_fair+0xdc>
         : 3800             {
    0.00 :   ffff8000100c0ad4:       mov     x2, x26
    0.00 :   ffff8000100c0ad8:       mov     x1, x19
    0.00 :   ffff8000100c0adc:       mov     x0, x27
    0.00 :   ffff8000100c0ae0:       bl      ffff8000100d4ea8 <__update_load_avg_se>
         : 3805             update_cfs_rq_load_avg():
         : 3661             *
    0.00 :   ffff8000100c0ae4:       ldr     w0, [x19, #196]
    0.00 :   ffff8000100c0ae8:       cbnz    w0, ffff8000100c0c94 <dequeue_task_fair+0x28c>
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100c0aec:       mov     x1, x19
    0.00 :   ffff8000100c0af0:       mov     x0, x27
    0.00 :   ffff8000100c0af4:       bl      ffff8000100d50e8 <__update_load_avg_cfs_rq>
         : 3698             propagate_entity_load_avg():
         : 3572             * already zero and there is no pending propagation, so it will be a
    0.00 :   ffff8000100c0af8:       ldr     x1, [x26, #128]
    0.00 :   ffff8000100c0afc:       cbz     x1, ffff8000100c0b08 <dequeue_task_fair+0x100>
         : 3576             }
    0.00 :   ffff8000100c0b00:       ldr     x2, [x1, #264]
    0.00 :   ffff8000100c0b04:       cbnz    x2, ffff8000100c0d80 <dequeue_task_fair+0x378>
         : 3579             update_load_avg():
         :
    0.00 :   ffff8000100c0b08:       cbnz    w0, ffff8000100c0edc <dequeue_task_fair+0x4d4>
         : 3819             dequeue_entity():
         : 4344             {
    0.00 :   ffff8000100c0b0c:       ldr     x0, [x26, #128]
         : 4346             se_update_runnable():
         : 724              /* An entity is a task if it doesn't "own" a runqueue */
    0.00 :   ffff8000100c0b10:       cbz     x0, ffff8000100c0b1c <dequeue_task_fair+0x114>
         : 725              #define entity_is_task(se)      (!se->my_q)
    0.00 :   ffff8000100c0b14:       ldr     w0, [x0, #20]
    0.00 :   ffff8000100c0b18:       str     x0, [x26, #136]
         : 728              dequeue_entity():
         :
    0.00 :   ffff8000100c0b1c:       mov     x0, x19
    0.00 :   ffff8000100c0b20:       mov     x1, x26
    0.00 :   ffff8000100c0b24:       bl      ffff8000100bc140 <clear_buddies>
         : 4350             delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;
    0.00 :   ffff8000100c0b28:       ldr     x0, [x19, #64]
    0.00 :   ffff8000100c0b2c:       cmp     x0, x26
    0.00 :   ffff8000100c0b30:       b.eq    ffff8000100c0b64 <dequeue_task_fair+0x15c>  // b.none
         : 4354             rb_erase_cached():
         : 150              static inline struct rb_node *
         : 151              rb_erase_cached(struct rb_node *node, struct rb_root_cached *root)
         : 152              {
         : 153              struct rb_node *leftmost = NULL;
         :
         : 155              if (root->rb_leftmost == node)
    0.00 :   ffff8000100c0b34:       ldr     x0, [x19, #56]
         : 157              __dequeue_entity():
         : 599              (normalized_sysctl_##name = sysctl_##name / (factor))
    0.00 :   ffff8000100c0b38:       add     x27, x26, #0x10
    0.00 :   ffff8000100c0b3c:       add     x1, x19, #0x30
         : 602              rb_erase_cached():
    0.00 :   ffff8000100c0b40:       cmp     x27, x0
    0.00 :   ffff8000100c0b44:       b.ne    ffff8000100c0b5c <dequeue_task_fair+0x154>  // b.any
         : 151              leftmost = root->rb_leftmost = rb_next(node);
    0.00 :   ffff8000100c0b48:       mov     x0, x27
    0.00 :   ffff8000100c0b4c:       str     x1, [sp, #96]
    0.00 :   ffff8000100c0b50:       bl      ffff8000104b3d50 <rb_next>
    0.00 :   ffff8000100c0b54:       str     x0, [x19, #56]
    0.00 :   ffff8000100c0b58:       ldr     x1, [sp, #96]
         :
         : 154              rb_erase(node, &root->rb_root);
    0.00 :   ffff8000100c0b5c:       mov     x0, x27
    0.00 :   ffff8000100c0b60:       bl      ffff8000104b33a8 <rb_erase>
         : 157              dequeue_entity():
         : 4352             resched_curr(rq_of(cfs_rq));
    0.00 :   ffff8000100c0b64:       str     wzr, [x26, #56]
         : 4354             update_load_sub():
         : 147              lw->weight -= dec;
    0.00 :   ffff8000100c0b68:       ldr     x1, [x26]
         : 148              lw->inv_weight = 0;
    0.00 :   ffff8000100c0b6c:       str     wzr, [x19, #8]
         : 147              lw->weight -= dec;
    0.00 :   ffff8000100c0b70:       ldr     x0, [x19]
    0.00 :   ffff8000100c0b74:       sub     x0, x0, x1
    0.00 :   ffff8000100c0b78:       str     x0, [x19]
         : 151              account_entity_dequeue():
         : 3016             * Remove and clamp on negative, from a local variable.
    0.00 :   ffff8000100c0b7c:       ldr     x0, [x26, #128]
    0.00 :   ffff8000100c0b80:       cbz     x0, ffff8000100c0f38 <dequeue_task_fair+0x530>
         : 3021             #define lsub_positive(_ptr, _val) do {                          \
    0.00 :   ffff8000100c0b84:       ldr     w0, [x19, #16]
    0.00 :   ffff8000100c0b88:       sub     w0, w0, #0x1
    0.00 :   ffff8000100c0b8c:       str     w0, [x19, #16]
         : 3025             dequeue_entity():
         : 4361             /*
    0.00 :   ffff8000100c0b90:       tbnz    w20, #0, ffff8000100c0ba4 <dequeue_task_fair+0x19c>
         : 4362             * Ensure that a task that missed wakeup preemption by a
    0.00 :   ffff8000100c0b94:       ldr     x1, [x19, #40]
    0.00 :   ffff8000100c0b98:       ldr     x0, [x26, #80]
    0.00 :   ffff8000100c0b9c:       sub     x0, x0, x1
    0.00 :   ffff8000100c0ba0:       str     x0, [x26, #80]
         : 4367             return;
    0.00 :   ffff8000100c0ba4:       mov     x0, x26
    0.00 :   ffff8000100c0ba8:       bl      ffff8000100bcbb8 <update_cfs_group>
         : 4375             if (delta > ideal_runtime)
    0.00 :   ffff8000100c0bac:       and     w0, w20, #0x6
    0.00 :   ffff8000100c0bb0:       cmp     w0, #0x2
    0.00 :   ffff8000100c0bb4:       b.eq    ffff8000100c0bc0 <dequeue_task_fair+0x1b8>  // b.none
         : 4376             resched_curr(rq_of(cfs_rq));
    0.00 :   ffff8000100c0bb8:       mov     x0, x19
    0.00 :   ffff8000100c0bbc:       bl      ffff8000100bb848 <update_min_vruntime>
         : 4379             dequeue_task_fair():
         : 5636             /* At this point se is NULL and we are at root level*/
         : 5637             sub_nr_running(rq, 1);
         :
         : 5639             /* balance early to pull high priority tasks */
    0.00 :   ffff8000100c0bc0:       ldp     w1, w0, [x19, #20]
         : 5643             rq->next_balance = jiffies;
         :
         : 5645             dequeue_throttle:
         : 5646             util_est_update(&rq->cfs, p, task_sleep);
         : 5647             hrtick_update(rq);
         : 5648             }
    0.00 :   ffff8000100c0bc4:       ldr     x2, [x19]
         :
    0.00 :   ffff8000100c0bc8:       sub     w1, w1, #0x1
         : 5636             /* balance early to pull high priority tasks */
    0.00 :   ffff8000100c0bcc:       sub     w0, w0, w21
    0.00 :   ffff8000100c0bd0:       stp     w1, w0, [x19, #20]
         : 5643             }
    0.00 :   ffff8000100c0bd4:       cbnz    x2, ffff8000100c1010 <dequeue_task_fair+0x608>
         : 5631             }
    0.00 :   ffff8000100c0bd8:       ldr     x26, [x26, #112]
         : 5654             DEFINE_PER_CPU(cpumask_var_t, select_idle_mask);
         :
         : 5656             #ifdef CONFIG_NO_HZ_COMMON
         :
         : 5658             static struct {
         : 5659             cpumask_var_t idle_cpus_mask;
    0.00 :   ffff8000100c0bdc:       orr     w20, w20, #0x1
         : 5631             }
    0.00 :   ffff8000100c0be0:       cbnz    x26, ffff8000100c0ab0 <dequeue_task_fair+0xa8>
    0.00 :   ffff8000100c0be4:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100c0be8:       ldp     x27, x28, [sp, #80]
    0.00 :   ffff8000100c0bec:       ldr     w1, [x23, #4]
         : 5677             *
         : 5678             * The load of a CPU is defined by the load of tasks currently enqueued on that
         : 5679             * CPU as well as tasks which are currently sleeping after an execution on that
         : 5680             * CPU.
         : 5681             *
         : 5682             * This method returns the load of the specified CPU by discounting the load of
    0.00 :   ffff8000100c0bf0:       ldr     w0, [sp, #116]
         : 5684             sub_nr_running():
         : 2093             #define ENQUEUE_MIGRATED        0x40
    0.00 :   ffff8000100c0bf4:       sub     w1, w1, #0x1
    0.00 :   ffff8000100c0bf8:       str     w1, [x23, #4]
         : 2096             dequeue_task_fair():
    0.00 :   ffff8000100c0bfc:       cbz     w0, ffff8000100c10c0 <dequeue_task_fair+0x6b8>
         : 5678             util_est_update():
         : 3988             */
    0.00 :   ffff8000100c0c00:       ldr     w0, [sp, #112]
    0.00 :   ffff8000100c0c04:       cbz     w0, ffff8000100c0c7c <dequeue_task_fair+0x274>
         : 3995             * When *p completes an activation we can consolidate another sample
    0.00 :   ffff8000100c0c08:       ldr     w1, [x22, #376]
    0.00 :   ffff8000100c0c0c:       ldr     x3, [x22, #376]
         : 3996             * of the task size. This is done by storing the current PELT value
    0.00 :   ffff8000100c0c10:       tbnz    w1, #0, ffff8000100c0c7c <dequeue_task_fair+0x274>
         : 3998             task_util():
         :
    0.00 :   ffff8000100c0c14:       ldr     x0, [x22, #368]
         : 3900             util_est_update():
         : 3995             * When *p completes an activation we can consolidate another sample
    0.00 :   ffff8000100c0c18:       ldr     w2, [x22, #380]
         : 4005             *
    0.00 :   ffff8000100c0c1c:       orr     w0, w0, #0x1
         : 4007             * 0.25, thus making w=1/4 ( >>= UTIL_EST_WEIGHT_SHIFT)
    0.00 :   ffff8000100c0c20:       cmp     w2, w0
    0.00 :   ffff8000100c0c24:       b.cc    ffff8000100c10b8 <dequeue_task_fair+0x6b0>  // b.lo, b.ul, b.last
         : 4017             }
    0.00 :   ffff8000100c0c28:       sub     w4, w0, w2
         : 4019             within_margin():
         :
    0.00 :   ffff8000100c0c2c:       add     w5, w4, #0x9
         : 3973             util_est_update():
         : 4019             static inline int task_fits_capacity(struct task_struct *p, long capacity)
    0.00 :   ffff8000100c0c30:       cmp     w5, #0x12
    0.00 :   ffff8000100c0c34:       b.ls    ffff8000100c1088 <dequeue_task_fair+0x680>  // b.plast
         : 4030             rq->misfit_task_load = 0;
    0.00 :   ffff8000100c0c38:       ldr     x6, [x23, #432]
         : 4032             capacity_orig_of():
         : 2604             if (__rq_lockp(rq1) != __rq_lockp(rq2))
         : 2605             raw_spin_rq_unlock(rq2);
         : 2606             else
         : 2607             __release(rq2->lock);
         : 2608             raw_spin_rq_unlock(rq1);
         : 2609             }
    0.00 :   ffff8000100c0c3c:       adrp    x5, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c0c40:       add     x5, x5, #0x760
    0.00 :   ffff8000100c0c44:       adrp    x1, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100c0c48:       add     x1, x1, #0xc40
    0.00 :   ffff8000100c0c4c:       ldrsw   x7, [x6, #2576]
         : 2615             task_util():
         :
    0.00 :   ffff8000100c0c50:       ldr     x6, [x22, #368]
         : 3900             capacity_orig_of():
    0.00 :   ffff8000100c0c54:       ldr     x5, [x5, x7, lsl #3]
    0.00 :   ffff8000100c0c58:       add     x1, x5, x1
         : 2606             util_est_update():
         : 4030             rq->misfit_task_load = 0;
    0.00 :   ffff8000100c0c5c:       ldr     x1, [x1, #2488]
    0.00 :   ffff8000100c0c60:       cmp     x6, x1
    0.00 :   ffff8000100c0c64:       b.hi    ffff8000100c0c7c <dequeue_task_fair+0x274>  // b.pmore
         :
    0.00 :   ffff8000100c0c68:       add     w2, w4, w2, lsl #2
         : 4052             static inline void update_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int not_used1)
    0.00 :   ffff8000100c0c6c:       lsr     w2, w2, #2
         : 4054             cfs_rq_util_change(cfs_rq, 0);
    0.00 :   ffff8000100c0c70:       bfxil   x3, x0, #0, #32
    0.00 :   ffff8000100c0c74:       bfi     x3, x2, #32, #32
    0.00 :   ffff8000100c0c78:       str     x3, [x22, #376]
         : 4058             dequeue_task_fair():
         : 5683             * the specified task, whenever the task is currently contributing to the CPU
         : 5684             * load.
         : 5685             */
         : 5686             static unsigned long cpu_load_without(struct rq *rq, struct task_struct *p)
         : 5687             {
         : 5688             struct cfs_rq *cfs_rq;
    0.00 :   ffff8000100c0c7c:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100c0c80:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100c0c84:       ldp     x25, x26, [sp, #64]
    0.00 :   ffff8000100c0c88:       ldp     x29, x30, [sp], #128
    0.00 :   ffff8000100c0c8c:       autiasp
    0.00 :   ffff8000100c0c90:       ret
         : 5695             get_pelt_divider():
         : 42               return LOAD_AVG_MAX - 1024 + avg->period_contrib;
    0.00 :   ffff8000100c0c94:       ldr     w5, [x19, #156]
    0.00 :   ffff8000100c0c98:       mov     w8, #0xb67e                     // #46718
         : 45               update_cfs_rq_load_avg():
         : 3665             static void attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)
    0.00 :   ffff8000100c0c9c:       add     x24, x19, #0xc0
         : 3667             get_pelt_divider():
    0.00 :   ffff8000100c0ca0:       add     w25, w5, w8
         : 43               update_cfs_rq_load_avg():
    0.00 :   ffff8000100c0ca4:       mov     x0, x24
    0.00 :   ffff8000100c0ca8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 3669             * See ___update_load_avg() for details.
    0.00 :   ffff8000100c0cac:       str     wzr, [x19, #196]
         : 3670             */
    0.00 :   ffff8000100c0cb0:       mov     x0, x24
         : 3666             {
    0.00 :   ffff8000100c0cb4:       ldp     x6, x24, [x19, #200]
    0.00 :   ffff8000100c0cb8:       stp     xzr, xzr, [x19, #200]
         : 3668             * cfs_rq->avg.period_contrib can be used for both cfs_rq and se.
    0.00 :   ffff8000100c0cbc:       ldr     x28, [x19, #216]
    0.00 :   ffff8000100c0cc0:       str     xzr, [x19, #216]
         : 3667             /*
    0.00 :   ffff8000100c0cc4:       str     x6, [sp, #96]
         : 3670             */
    0.00 :   ffff8000100c0cc8:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 3673             /*
    0.00 :   ffff8000100c0ccc:       ldr     x6, [sp, #96]
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100c0cd0:       mov     w10, w25
         : 3673             /*
    0.00 :   ffff8000100c0cd4:       ldr     x9, [x19, #160]
         : 3675             add_tg_cfs_propagate():
         : 3563             /*
    0.00 :   ffff8000100c0cd8:       mov     x0, #0x1                        // #1
         : 3565             update_cfs_rq_load_avg():
         :
    0.00 :   ffff8000100c0cdc:       mul     x2, x28, x10
         : 3673             /*
    0.00 :   ffff8000100c0ce0:       sub     x1, x9, x6
    0.00 :   ffff8000100c0ce4:       cmp     x9, x1
         : 3689             se->avg.util_sum = se->avg.util_avg * divider;
    0.00 :   ffff8000100c0ce8:       neg     x4, x2
         : 3673             /*
    0.00 :   ffff8000100c0cec:       csel    x1, x1, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0cf0:       str     x1, [x19, #160]
         : 3676             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100c0cf4:       ldr     x11, [x19, #272]
         : 3566             update_cfs_rq_load_avg():
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100c0cf8:       mov     x1, x19
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100c0cfc:       ldr     x9, [x19, #136]
         : 3676             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100c0d00:       add     x4, x11, x4, asr #10
    0.00 :   ffff8000100c0d04:       stp     x0, x4, [x19, #264]
         : 3567             update_cfs_rq_load_avg():
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100c0d08:       mov     x0, x27
         : 3674             * When we attach the @se to the @cfs_rq, we must align the decay
    0.00 :   ffff8000100c0d0c:       msub    x6, x6, x10, x9
    0.00 :   ffff8000100c0d10:       cmp     x9, x6
    0.00 :   ffff8000100c0d14:       csel    x6, x6, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0d18:       str     x6, [x19, #136]
         : 3677             *
    0.00 :   ffff8000100c0d1c:       ldr     x6, [x19, #176]
    0.00 :   ffff8000100c0d20:       sub     x4, x6, x24
    0.00 :   ffff8000100c0d24:       cmp     x6, x4
    0.00 :   ffff8000100c0d28:       csel    x4, x4, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0d2c:       str     x4, [x19, #176]
         : 3678             * XXX illustrate
    0.00 :   ffff8000100c0d30:       ldr     w4, [x19, #152]
    0.00 :   ffff8000100c0d34:       msub    w5, w25, w24, w4
    0.00 :   ffff8000100c0d38:       cmp     w4, w5
    0.00 :   ffff8000100c0d3c:       csel    w5, w5, wzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0d40:       str     w5, [x19, #152]
         : 3681             se->avg.period_contrib = cfs_rq->avg.period_contrib;
    0.00 :   ffff8000100c0d44:       ldr     x5, [x19, #168]
    0.00 :   ffff8000100c0d48:       sub     x4, x5, x28
    0.00 :   ffff8000100c0d4c:       cmp     x5, x4
    0.00 :   ffff8000100c0d50:       csel    x4, x4, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0d54:       str     x4, [x19, #168]
         :
    0.00 :   ffff8000100c0d58:       ldr     x4, [x19, #144]
    0.00 :   ffff8000100c0d5c:       sub     x2, x4, x2
    0.00 :   ffff8000100c0d60:       cmp     x4, x2
    0.00 :   ffff8000100c0d64:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0d68:       str     x2, [x19, #144]
         : 3694             if (se_weight(se)) {
    0.00 :   ffff8000100c0d6c:       bl      ffff8000100d50e8 <__update_load_avg_cfs_rq>
         : 3696             propagate_entity_load_avg():
         : 3572             * already zero and there is no pending propagation, so it will be a
    0.00 :   ffff8000100c0d70:       ldr     x1, [x26, #128]
    0.00 :   ffff8000100c0d74:       cbz     x1, ffff8000100c0edc <dequeue_task_fair+0x4d4>
         : 3576             }
    0.00 :   ffff8000100c0d78:       ldr     x0, [x1, #264]
    0.00 :   ffff8000100c0d7c:       cbz     x0, ffff8000100c0edc <dequeue_task_fair+0x4d4>
         :
    0.00 :   ffff8000100c0d80:       str     xzr, [x1, #264]
         : 3581             add_tg_cfs_propagate():
         : 3563             /*
    0.00 :   ffff8000100c0d84:       mov     x5, #0x1                        // #1
         : 3565             propagate_entity_load_avg():
         : 3583             {
    0.00 :   ffff8000100c0d88:       ldr     x4, [x1, #272]
         :
    0.00 :   ffff8000100c0d8c:       ldr     x0, [x26, #120]
         : 3583             add_tg_cfs_propagate():
         : 3564             * If there is a pending propagation, we have to update the load and
    0.00 :   ffff8000100c0d90:       ldr     x2, [x0, #272]
    0.00 :   ffff8000100c0d94:       add     x2, x2, x4
    0.00 :   ffff8000100c0d98:       stp     x5, x2, [x0, #264]
         : 3568             propagate_entity_load_avg():
         : 3585             }
    0.00 :   ffff8000100c0d9c:       ldr     x4, [x1, #176]
         : 3587             update_tg_cfs_util():
         :
    0.00 :   ffff8000100c0da0:       ldr     x2, [x26, #240]
    0.00 :   ffff8000100c0da4:       subs    x2, x4, x2
         : 3456             long delta, running_sum, runnable_sum = gcfs_rq->prop_runnable_sum;
    0.00 :   ffff8000100c0da8:       b.eq    ffff8000100c0de4 <dequeue_task_fair+0x3dc>  // b.none
         : 3458             get_pelt_divider():
    0.00 :   ffff8000100c0dac:       ldr     w5, [x0, #156]
    0.00 :   ffff8000100c0db0:       mov     w7, #0xb67e                     // #46718
         : 44               update_tg_cfs_util():
         : 3466             /*
    0.00 :   ffff8000100c0db4:       str     x4, [x26, #240]
         : 3468             get_pelt_divider():
    0.00 :   ffff8000100c0db8:       add     w5, w5, w7
         : 43               update_tg_cfs_util():
         : 3467             * cfs_rq->avg.period_contrib can be used for both cfs_rq and se.
    0.00 :   ffff8000100c0dbc:       mul     w4, w5, w4
    0.00 :   ffff8000100c0dc0:       str     w4, [x26, #216]
         : 3470             divider = get_pelt_divider(&cfs_rq->avg);
    0.00 :   ffff8000100c0dc4:       ldr     x4, [x0, #176]
    0.00 :   ffff8000100c0dc8:       add     x2, x2, x4
    0.00 :   ffff8000100c0dcc:       ccmp    x4, x2, #0x2, mi  // mi = first
    0.00 :   ffff8000100c0dd0:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0dd4:       str     x2, [x0, #176]
         :
    0.00 :   ffff8000100c0dd8:       ldr     x2, [x0, #176]
    0.00 :   ffff8000100c0ddc:       mul     w5, w5, w2
    0.00 :   ffff8000100c0de0:       str     w5, [x0, #152]
         : 3475             propagate_entity_load_avg():
         :
    0.00 :   ffff8000100c0de4:       ldr     x4, [x1, #168]
         : 3588             update_tg_cfs_runnable():
         : 3477             runnable_sum += se->avg.load_sum;
    0.00 :   ffff8000100c0de8:       ldr     x2, [x26, #232]
    0.00 :   ffff8000100c0dec:       subs    x2, x4, x2
         : 3481             * Estimate the new unweighted runnable_sum of the gcfs_rq by
    0.00 :   ffff8000100c0df0:       b.eq    ffff8000100c0e2c <dequeue_task_fair+0x424>  // b.none
         : 3483             get_pelt_divider():
    0.00 :   ffff8000100c0df4:       ldr     w5, [x0, #156]
         : 43               update_tg_cfs_runnable():
         :
    0.00 :   ffff8000100c0df8:       mov     w6, #0xb67e                     // #46718
         : 3491             }
    0.00 :   ffff8000100c0dfc:       str     x4, [x26, #232]
         :
    0.00 :   ffff8000100c0e00:       add     w5, w5, w6
    0.00 :   ffff8000100c0e04:       mul     x4, x4, x5
    0.00 :   ffff8000100c0e08:       str     x4, [x26, #208]
         : 3495             * Rescale running sum to be in the same range as runnable sum
    0.00 :   ffff8000100c0e0c:       ldr     x4, [x0, #168]
    0.00 :   ffff8000100c0e10:       add     x2, x2, x4
    0.00 :   ffff8000100c0e14:       ccmp    x4, x2, #0x2, mi  // mi = first
    0.00 :   ffff8000100c0e18:       csel    x2, x2, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0e1c:       str     x2, [x0, #168]
         : 3496             * running_sum is in [0 : LOAD_AVG_MAX <<  SCHED_CAPACITY_SHIFT]
    0.00 :   ffff8000100c0e20:       ldr     x2, [x0, #168]
    0.00 :   ffff8000100c0e24:       mul     x5, x2, x5
    0.00 :   ffff8000100c0e28:       str     x5, [x0, #144]
         : 3500             update_tg_cfs_load():
         : 3502             load_sum = (s64)se_weight(se) * runnable_sum;
    0.00 :   ffff8000100c0e2c:       ldr     x2, [x1, #272]
         : 3508             se->avg.load_avg = load_avg;
    0.00 :   ffff8000100c0e30:       cmp     x2, #0x0
    0.00 :   ffff8000100c0e34:       b.eq    ffff8000100c0edc <dequeue_task_fair+0x4d4>  // b.none
         : 3511             cfs_rq->avg.load_sum = cfs_rq->avg.load_avg * divider;
    0.00 :   ffff8000100c0e38:       str     xzr, [x1, #272]
         : 3513             get_pelt_divider():
    0.00 :   ffff8000100c0e3c:       mov     w3, #0xb67e                     // #46718
    0.00 :   ffff8000100c0e40:       ldr     w6, [x0, #156]
    0.00 :   ffff8000100c0e44:       add     w6, w6, w3
         : 45               update_tg_cfs_load():
         :
    0.00 :   ffff8000100c0e48:       b.lt    ffff8000100c0fac <dequeue_task_fair+0x5a4>  // b.tstop
         :
    0.00 :   ffff8000100c0e4c:       ldr     x5, [x26, #200]
         : 3525             if (entity_is_task(se))
    0.00 :   ffff8000100c0e50:       mov     w1, w6
         :
    0.00 :   ffff8000100c0e54:       add     x4, x2, x5
         : 3525             if (entity_is_task(se))
    0.00 :   ffff8000100c0e58:       cmp     x4, x1
    0.00 :   ffff8000100c0e5c:       csel    x2, x4, x1, le
         : 3546             }
    0.00 :   ffff8000100c0e60:       ldr     w4, [x26, #216]
         : 3549             * Check if we need to update the load and the utilization of a blocked
    0.00 :   ffff8000100c0e64:       ldr     x1, [x26]
         : 3546             }
    0.00 :   ffff8000100c0e68:       lsr     w4, w4, #10
         :
    0.00 :   ffff8000100c0e6c:       cmp     x4, x2
    0.00 :   ffff8000100c0e70:       csel    x2, x4, x2, ge  // ge = tcont
         : 3550             se_weight():
         : 753              /*
    0.00 :   ffff8000100c0e74:       cbz     x1, ffff8000100c0fa0 <dequeue_task_fair+0x598>
    0.00 :   ffff8000100c0e78:       lsr     x1, x1, #10
    0.00 :   ffff8000100c0e7c:       mov     x4, #0x2                        // #2
    0.00 :   ffff8000100c0e80:       cmp     x1, x4
    0.00 :   ffff8000100c0e84:       sxtw    x6, w6
    0.00 :   ffff8000100c0e88:       csel    x1, x1, x4, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0e8c:       mul     x7, x1, x2
    0.00 :   ffff8000100c0e90:       msub    x5, x1, x5, x7
    0.00 :   ffff8000100c0e94:       sdiv    x1, x7, x6
    0.00 :   ffff8000100c0e98:       lsr     x4, x5, #63
    0.00 :   ffff8000100c0e9c:       and     w4, w4, #0xff
         : 765              update_tg_cfs_load():
         :
    0.00 :   ffff8000100c0ea0:       str     x2, [x26, #200]
         : 3553             {
    0.00 :   ffff8000100c0ea4:       ldr     x6, [x26, #224]
         : 3556             /*
    0.00 :   ffff8000100c0ea8:       str     x1, [x26, #224]
         : 3557             * If sched_entity still have not zero load or utilization, we have to
    0.00 :   ffff8000100c0eac:       ldr     x2, [x0, #160]
         : 3553             {
    0.00 :   ffff8000100c0eb0:       subs    x1, x1, x6
         : 3557             * If sched_entity still have not zero load or utilization, we have to
    0.00 :   ffff8000100c0eb4:       add     x1, x1, x2
    0.00 :   ffff8000100c0eb8:       ccmp    x2, x1, #0x2, mi  // mi = first
    0.00 :   ffff8000100c0ebc:       csel    x1, x1, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0ec0:       str     x1, [x0, #160]
         : 3558             * decay it:
    0.00 :   ffff8000100c0ec4:       cmp     w4, #0x0
    0.00 :   ffff8000100c0ec8:       ldr     x2, [x0, #136]
    0.00 :   ffff8000100c0ecc:       add     x1, x2, x5
    0.00 :   ffff8000100c0ed0:       ccmp    x2, x1, #0x2, ne  // ne = any
    0.00 :   ffff8000100c0ed4:       csel    x1, x1, xzr, cs  // cs = hs, nlast
    0.00 :   ffff8000100c0ed8:       str     x1, [x0, #136]
         : 3565             cfs_rq_util_change():
         :
    0.00 :   ffff8000100c0edc:       ldr     x1, [x19, #304]
         : 3280             atomic_long_add(delta, &cfs_rq->tg->load_avg);
    0.00 :   ffff8000100c0ee0:       add     x0, x1, #0x80
    0.00 :   ffff8000100c0ee4:       cmp     x19, x0
    0.00 :   ffff8000100c0ee8:       b.eq    ffff8000100c0fe0 <dequeue_task_fair+0x5d8>  // b.none
         : 3284             update_tg_load_avg():
         :
    0.00 :   ffff8000100c0eec:       ldr     x0, [sp, #104]
    0.00 :   ffff8000100c0ef0:       ldr     x1, [x19, #336]
    0.00 :   ffff8000100c0ef4:       cmp     x1, x0
    0.00 :   ffff8000100c0ef8:       b.eq    ffff8000100c0b0c <dequeue_task_fair+0x104>  // b.none
         :
    0.00 :   ffff8000100c0efc:       ldr     x2, [x19, #160]
    0.00 :   ffff8000100c0f00:       ldr     x0, [x19, #256]
         : 3325             }
    0.00 :   ffff8000100c0f04:       subs    x2, x2, x0
    0.00 :   ffff8000100c0f08:       cneg    x4, x2, mi  // mi = first
    0.00 :   ffff8000100c0f0c:       cmp     x4, x0, lsr #6
    0.00 :   ffff8000100c0f10:       b.ls    ffff8000100c0b0c <dequeue_task_fair+0x104>  // b.plast
         : 3330             arch_atomic64_add():
         : 67               }
         :
         : 69               ATOMIC64_OP(atomic64_andnot)
         : 70               ATOMIC64_OP(atomic64_or)
         : 71               ATOMIC64_OP(atomic64_xor)
         : 72               ATOMIC64_OP(atomic64_add)
    0.00 :   ffff8000100c0f14:       bl      ffff8000100bb810 <system_uses_lse_atomics>
         : 74               update_tg_load_avg():
         : 3326             #else
    0.00 :   ffff8000100c0f18:       add     x4, x1, #0x100
         : 3328             arch_atomic64_add():
    0.00 :   ffff8000100c0f1c:       tst     w0, #0xff
    0.00 :   ffff8000100c0f20:       b.ne    ffff8000100c109c <dequeue_task_fair+0x694>  // b.any
         : 69               __ll_sc_atomic64_add():
         : 210              ATOMIC64_FETCH_OP (, dmb ish,  , l, "memory", __VA_ARGS__)      \
         : 211              ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)      \
         : 212              ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)      \
         : 213              ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)
         :
         : 215              ATOMIC64_OPS(add, add, I)
    0.00 :   ffff8000100c0f24:       add     x1, x1, #0x100
    0.00 :   ffff8000100c0f28:       b       ffff8000100c81dc <sched_group_set_shares+0x644>
         : 218              update_tg_load_avg():
         : 3327             p_last_update_time = prev->avg.last_update_time;
    0.00 :   ffff8000100c0f2c:       ldr     x0, [x19, #160]
    0.00 :   ffff8000100c0f30:       str     x0, [x19, #256]
    0.00 :   ffff8000100c0f34:       b       ffff8000100c0b0c <dequeue_task_fair+0x104>
         : 3331             account_entity_dequeue():
         : 3017             *
    0.00 :   ffff8000100c0f38:       ldr     x2, [x19, #304]
         : 3019             cpu_to_node():
         : 96               #endif
         :
         : 98               #ifndef cpu_to_node
         : 99               static inline int cpu_to_node(int cpu)
         : 100              {
         : 101              return per_cpu(numa_node, cpu);
    0.00 :   ffff8000100c0f3c:       adrp    x0, ffff800011c2d000 <xen_lateeoi_chip+0x68>
         : 103              account_numa_dequeue():
         :
    0.00 :   ffff8000100c0f40:       ldr     w4, [x26, #2064]
         : 1215             cpu_to_node():
    0.00 :   ffff8000100c0f44:       add     x7, x0, #0x760
    0.00 :   ffff8000100c0f48:       adrp    x0, ffff800011777000 <lru_pvecs+0x128>
    0.00 :   ffff8000100c0f4c:       add     x0, x0, #0x610
         : 99               account_numa_dequeue():
    0.00 :   ffff8000100c0f50:       cmn     w4, #0x1
         : 1214             account_entity_dequeue():
         : 3018             * A variant of sub_positive(), which does not use explicit load-store
    0.00 :   ffff8000100c0f54:       add     x1, x26, #0x28
         : 3020             account_numa_dequeue():
         : 1214             static inline unsigned long group_faults(struct task_struct *p, int nid)
    0.00 :   ffff8000100c0f58:       ldp     w5, w4, [x2, #8]
         :
    0.00 :   ffff8000100c0f5c:       cset    w8, ne  // ne = any
    0.00 :   ffff8000100c0f60:       sub     w5, w5, w8
    0.00 :   ffff8000100c0f64:       str     w5, [x2, #8]
         : 1217             task_cpu():
         : 1993             * Returns non-zero if there is another task waiting on the rwlock.
         : 1994             * Returns zero if the lock is not contended or the system / underlying
         : 1995             * rwlock implementation does not support contention detection.
         : 1996             * Technically does not depend on CONFIG_PREEMPTION, but a general need
         : 1997             * for low latency.
         : 1998             */
    0.00 :   ffff8000100c0f68:       ldur    w8, [x26, #-64]
         : 2000             account_numa_dequeue():
         : 1214             static inline unsigned long group_faults(struct task_struct *p, int nid)
    0.00 :   ffff8000100c0f6c:       ldr     w5, [x26, #2064]
         : 1216             cpu_to_node():
    0.00 :   ffff8000100c0f70:       ldr     x6, [x7, w8, sxtw #3]
         : 97               account_numa_dequeue():
    0.00 :   ffff8000100c0f74:       ldr     w0, [x6, x0]
    0.00 :   ffff8000100c0f78:       cmp     w0, w5
    0.00 :   ffff8000100c0f7c:       cset    w0, eq  // eq = none
    0.00 :   ffff8000100c0f80:       sub     w0, w4, w0
    0.00 :   ffff8000100c0f84:       str     w0, [x2, #12]
         : 1219             list_del_init():
         : 204              * list_del_init - deletes entry from list and reinitialize it.
         : 205              * @entry: the element to delete from the list.
         : 206              */
         : 207              static inline void list_del_init(struct list_head *entry)
         : 208              {
         : 209              __list_del_entry(entry);
    0.00 :   ffff8000100c0f88:       ldp     x2, x0, [x26, #40]
         : 211              __list_del():
         : 112              next->prev = prev;
    0.00 :   ffff8000100c0f8c:       str     x0, [x2, #8]
         : 113              WRITE_ONCE(prev->next, next);
    0.00 :   ffff8000100c0f90:       str     x2, [x0]
         : 115              INIT_LIST_HEAD():
         : 35               WRITE_ONCE(list->next, list);
    0.00 :   ffff8000100c0f94:       str     x1, [x26, #40]
         : 36               list->prev = list;
    0.00 :   ffff8000100c0f98:       str     x1, [x26, #48]
    0.00 :   ffff8000100c0f9c:       b       ffff8000100c0b84 <dequeue_task_fair+0x17c>
         : 39               se_weight():
    0.00 :   ffff8000100c0fa0:       mov     x5, #0x0                        // #0
    0.00 :   ffff8000100c0fa4:       mov     w4, #0x0                        // #0
    0.00 :   ffff8000100c0fa8:       b       ffff8000100c0ea0 <dequeue_task_fair+0x498>
         : 756              update_tg_cfs_load():
         :
    0.00 :   ffff8000100c0fac:       ldr     x2, [x1]
    0.00 :   ffff8000100c0fb0:       cbz     x2, ffff8000100c0fd0 <dequeue_task_fair+0x5c8>
    0.00 :   ffff8000100c0fb4:       lsr     x2, x2, #10
    0.00 :   ffff8000100c0fb8:       mov     x4, #0x2                        // #2
    0.00 :   ffff8000100c0fbc:       cmp     x2, x4
    0.00 :   ffff8000100c0fc0:       csel    x2, x2, x4, cs  // cs = hs, nlast
         : 3538             div_s64_rem():
         : 42               * Return: sets ``*remainder``, then returns dividend / divisor
         : 43               */
         : 44               static inline s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)
         : 45               {
         : 46               *remainder = dividend % divisor;
         : 47               return dividend / divisor;
    0.00 :   ffff8000100c0fc4:       ldr     x1, [x1, #136]
         : 41               *remainder = dividend % divisor;
    0.00 :   ffff8000100c0fc8:       sxtw    x2, w2
         : 42               return dividend / divisor;
    0.00 :   ffff8000100c0fcc:       sdiv    x2, x1, x2
         : 44               update_tg_cfs_load():
         :
    0.00 :   ffff8000100c0fd0:       ldr     x5, [x26, #200]
    0.00 :   ffff8000100c0fd4:       cmp     x5, x2
    0.00 :   ffff8000100c0fd8:       csel    x2, x5, x2, ls  // ls = plast
    0.00 :   ffff8000100c0fdc:       b       ffff8000100c0e60 <dequeue_task_fair+0x458>
         : 3542             cpufreq_update_util():
         : 2509             return 1;
    0.00 :   ffff8000100c0fe0:       ldrsw   x4, [x1, #2576]
    0.00 :   ffff8000100c0fe4:       adrp    x0, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100c0fe8:       add     x2, x0, #0x760
    0.00 :   ffff8000100c0fec:       ldr     x0, [sp, #120]
    0.00 :   ffff8000100c0ff0:       ldr     x2, [x2, x4, lsl #3]
    0.00 :   ffff8000100c0ff4:       ldr     x0, [x0, x2]
         :
    0.00 :   ffff8000100c0ff8:       cbz     x0, ffff8000100c0eec <dequeue_task_fair+0x4e4>
         : 2512             #else
    0.00 :   ffff8000100c0ffc:       ldr     x4, [x0]
    0.00 :   ffff8000100c1000:       mov     w2, #0x0                        // #0
    0.00 :   ffff8000100c1004:       ldr     x1, [x1, #2400]
    0.00 :   ffff8000100c1008:       blr     x4
    0.00 :   ffff8000100c100c:       b       ffff8000100c0eec <dequeue_task_fair+0x4e4>
         : 2518             dequeue_task_fair():
         : 5645             #ifdef CONFIG_SMP
    0.00 :   ffff8000100c1010:       ldr     x19, [x26, #112]
         :
    0.00 :   ffff8000100c1014:       ldr     w0, [sp, #112]
    0.00 :   ffff8000100c1018:       cmp     x19, #0x0
    0.00 :   ffff8000100c101c:       csel    w0, w0, wzr, ne  // ne = any
    0.00 :   ffff8000100c1020:       cbz     w0, ffff8000100c1080 <dequeue_task_fair+0x678>
         : 5655             set_next_buddy():
         : 6979             cfs_rq_of(se)->skip = se;
         : 6980             }
         :
         : 6982             /*
         : 6983             * Preempt the current task with a newly woken task if needed:
         : 6984             */
    0.00 :   ffff8000100c1024:       ldr     x1, [x19, #128]
    0.00 :   ffff8000100c1028:       mov     x0, x19
    0.00 :   ffff8000100c102c:       cbz     x1, ffff8000100c10a4 <dequeue_task_fair+0x69c>
         : 6985             static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_flags)
         : 6986             {
         : 6987             struct task_struct *curr = rq->curr;
         : 6988             struct sched_entity *se = &curr->se, *pse = &p->se;
         : 6989             struct cfs_rq *cfs_rq = task_cfs_rq(curr);
         : 6990             int scale = cfs_rq->nr_running >= sched_nr_latency;
    0.00 :   ffff8000100c1030:       ldr     x1, [x0, #120]
    0.00 :   ffff8000100c1034:       str     x0, [x1, #72]
         : 6982             struct task_struct *curr = rq->curr;
    0.00 :   ffff8000100c1038:       ldr     x0, [x0, #112]
    0.00 :   ffff8000100c103c:       cbnz    x0, ffff8000100c1030 <dequeue_task_fair+0x628>
         : 6985             dequeue_task_fair():
         : 5658             unsigned long next_blocked;     /* Next update of blocked load in jiffies */
    0.00 :   ffff8000100c1040:       ldr     x20, [x19, #120]
         :
    0.00 :   ffff8000100c1044:       mov     x1, x19
    0.00 :   ffff8000100c1048:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000100c104c:       mov     x0, x20
    0.00 :   ffff8000100c1050:       bl      ffff8000100be318 <update_load_avg>
         : 5661             #endif /* CONFIG_NO_HZ_COMMON */
    0.00 :   ffff8000100c1054:       ldr     x1, [x19, #128]
         :
    0.00 :   ffff8000100c1058:       mov     x0, x19
         : 5664             se_update_runnable():
         : 724              /* An entity is a task if it doesn't "own" a runqueue */
    0.00 :   ffff8000100c105c:       cbz     x1, ffff8000100c1068 <dequeue_task_fair+0x660>
         : 725              #define entity_is_task(se)      (!se->my_q)
    0.00 :   ffff8000100c1060:       ldr     w1, [x1, #20]
    0.00 :   ffff8000100c1064:       str     x1, [x19, #136]
         : 728              dequeue_task_fair():
    0.00 :   ffff8000100c1068:       bl      ffff8000100bcbb8 <update_cfs_group>
         : 5665             return cfs_rq_load_avg(&rq->cfs);
    0.00 :   ffff8000100c106c:       ldp     w1, w0, [x20, #20]
         : 5664             {
    0.00 :   ffff8000100c1070:       sub     w1, w1, #0x1
         : 5665             return cfs_rq_load_avg(&rq->cfs);
    0.00 :   ffff8000100c1074:       sub     w0, w0, w21
    0.00 :   ffff8000100c1078:       stp     w1, w0, [x20, #20]
         : 5657             unsigned long next_balance;     /* in jiffy units */
    0.00 :   ffff8000100c107c:       ldr     x19, [x19, #112]
    0.00 :   ffff8000100c1080:       cbnz    x19, ffff8000100c1040 <dequeue_task_fair+0x638>
    0.00 :   ffff8000100c1084:       b       ffff8000100c0be4 <dequeue_task_fair+0x1dc>
         : 5661             util_est_update():
         :
    0.00 :   ffff8000100c1088:       sub     w1, w1, w0
         : 4020             within_margin():
         :
    0.00 :   ffff8000100c108c:       add     w1, w1, #0x9
         : 3973             util_est_update():
         : 4020             {
    0.00 :   ffff8000100c1090:       cmp     w1, #0x12
    0.00 :   ffff8000100c1094:       b.hi    ffff8000100c0c70 <dequeue_task_fair+0x268>  // b.pmore
    0.00 :   ffff8000100c1098:       b       ffff8000100c0c7c <dequeue_task_fair+0x274>
         : 4024             __lse_atomic64_add():
         : 179              }
         :
         : 181              ATOMIC64_OP(andnot, stclr)
         : 182              ATOMIC64_OP(or, stset)
         : 183              ATOMIC64_OP(xor, steor)
         : 184              ATOMIC64_OP(add, stadd)
    0.00 :   ffff8000100c109c:       stadd   x2, [x4]
    0.00 :   ffff8000100c10a0:       b       ffff8000100c0f2c <dequeue_task_fair+0x524>
         : 187              set_next_buddy():
         : 6979             */
    0.00 :   ffff8000100c10a4:       ldr     w0, [x19, #544]
    0.00 :   ffff8000100c10a8:       cmp     w0, #0x5
    0.00 :   ffff8000100c10ac:       b.eq    ffff8000100c1040 <dequeue_task_fair+0x638>  // b.none
    0.00 :   ffff8000100c10b0:       mov     x0, x19
    0.00 :   ffff8000100c10b4:       b       ffff8000100c1030 <dequeue_task_fair+0x628>
         : 6985             util_est_update():
         : 4007             * 0.25, thus making w=1/4 ( >>= UTIL_EST_WEIGHT_SHIFT)
    0.00 :   ffff8000100c10b8:       mov     w2, w0
    0.00 :   ffff8000100c10bc:       b       ffff8000100c0c70 <dequeue_task_fair+0x268>
         : 4010             sched_idle_rq():
         : 5495             for_each_sched_entity(se) {
    0.00 :   ffff8000100c10c0:       ldr     w0, [x23, #152]
    0.00 :   ffff8000100c10c4:       cmp     w1, #0x0
    0.00 :   ffff8000100c10c8:       ccmp    w0, w1, #0x0, ne  // ne = any
    0.00 :   ffff8000100c10cc:       b.ne    ffff8000100c0c00 <dequeue_task_fair+0x1f8>  // b.any
         : 5500             dequeue_task_fair():
         : 5678             * the specified task, whenever the task is currently contributing to the CPU
    0.00 :   ffff8000100c10d0:       adrp    x0, ffff800011c27000 <bit_wait_table+0xe80>
    0.00 :   ffff8000100c10d4:       ldr     x0, [x0, #2432]
    0.00 :   ffff8000100c10d8:       str     x0, [x23, #2376]
    0.00 :   ffff8000100c10dc:       b       ffff8000100c0c00 <dequeue_task_fair+0x1f8>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010411f78 <cap_task_setscheduler>:
         : 6                cap_task_setscheduler():
         : 1199             * specified task.
         : 1200             *
         : 1201             * Return: 0 if permission is granted, -ve if denied.
         : 1202             */
         : 1203             int cap_task_setscheduler(struct task_struct *p)
         : 1204             {
  100.00 :   ffff800010411f78:       paciasp
    0.00 :   ffff800010411f7c:       stp     x29, x30, [sp, #-16]!
    0.00 :   ffff800010411f80:       mov     x29, sp
         : 1200             return cap_safe_nice(p);
    0.00 :   ffff800010411f84:       bl      ffff800010411ee8 <cap_safe_nice>
         : 1201             }
    0.00 :   ffff800010411f88:       ldp     x29, x30, [sp], #16
    0.00 :   ffff800010411f8c:       autiasp
    0.00 :   ffff800010411f90:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b4b60 <__set_cpus_allowed_ptr>:
         : 6                __set_cpus_allowed_ptr():
         : 2348             */
         :
         : 2350             /*
         : 2351             * The task moved before the stopper got to run. We're holding
         : 2352             * ->pi_lock, so the allowed mask is stable - if it got
         : 2353             * somewhere allowed, we're done.
    0.00 :   ffff8000100b4b60:       paciasp
    0.00 :   ffff8000100b4b64:       stp     x29, x30, [sp, #-80]!
    0.00 :   ffff8000100b4b68:       mov     x29, sp
    0.00 :   ffff8000100b4b6c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b4b70:       adrp    x20, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b4b74:       add     x20, x20, #0x948
    0.00 :   ffff8000100b4b78:       stp     x23, x24, [sp, #48]
    0.00 :   ffff8000100b4b7c:       mov     x23, x1
    0.00 :   ffff8000100b4b80:       ldr     x1, [x20]
    0.00 :   ffff8000100b4b84:       str     x1, [sp, #72]
    0.00 :   ffff8000100b4b88:       mov     x1, #0x0                        // #0
         : 2355             if (cpumask_test_cpu(task_cpu(p), p->cpus_ptr)) {
         : 2356             p->migration_pending = NULL;
         : 2357             complete = true;
         : 2358             goto out;
         : 2359             }
         :
    0.00 :   ffff8000100b4b8c:       add     x1, sp, #0x40
         : 2348             * somewhere allowed, we're done.
    0.00 :   ffff8000100b4b90:       mov     x19, x0
    0.00 :   ffff8000100b4b94:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b4b98:       mov     w21, w2
         :
    0.00 :   ffff8000100b4b9c:       bl      ffff8000100b2928 <task_rq_lock>
         : 2357             update_rq_clock():
         :
    0.00 :   ffff8000100b4ba0:       ldr     w1, [x0, #2392]
         : 319              __set_cpus_allowed_ptr():
         :
    0.00 :   ffff8000100b4ba4:       mov     x22, x0
         : 2357             update_rq_clock():
         :
    0.00 :   ffff8000100b4ba8:       tbnz    w1, #1, ffff8000100b4bb0 <__set_cpus_allowed_ptr+0x50>
    0.00 :   ffff8000100b4bac:       bl      ffff8000100b16c0 <update_rq_clock.part.106>
         : 320              __set_cpus_allowed_ptr():
         : 2358             /*
         : 2359             * When migrate_enable() hits a rq mis-match we can't reliably
         : 2360             * determine is_migration_disabled() and so have to chase after
    0.00 :   ffff8000100b4bb0:       ldr     w1, [x19, #36]
    0.00 :   ffff8000100b4bb4:       tbnz    w1, #21, ffff8000100b4c5c <__set_cpus_allowed_ptr+0xfc>
    0.00 :   ffff8000100b4bb8:       ldrh    w3, [x19, #728]
         : 2349             */
    0.00 :   ffff8000100b4bbc:       adrp    x2, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b4bc0:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b4bc4:       add     x2, x2, #0xa70
    0.00 :   ffff8000100b4bc8:       cmp     w3, #0x0
    0.00 :   ffff8000100b4bcc:       add     x0, x0, #0x9e8
    0.00 :   ffff8000100b4bd0:       csel    x0, x0, x2, ne  // ne = any
         :
         : 2377             if (complete)
         : 2378             complete_all(&pending->done);
         :
         : 2380             return 0;
         : 2381             }
    0.00 :   ffff8000100b4bd4:       tbz     w21, #0, ffff8000100b4bdc <__set_cpus_allowed_ptr+0x7c>
    0.00 :   ffff8000100b4bd8:       tbnz    w1, #26, ffff8000100b4c18 <__set_cpus_allowed_ptr+0xb8>
         :
         : 2382             int push_cpu_stop(void *arg)
         : 2383             {
         : 2384             struct rq *lowest_rq = NULL, *rq = this_rq();
         : 2385             struct task_struct *p = arg;
    0.00 :   ffff8000100b4bdc:       tbnz    w21, #2, ffff8000100b4bfc <__set_cpus_allowed_ptr+0x9c>
         : 2387             bitmap_equal():
         : 338              {
         : 339              if (small_const_nbits(nbits))
         : 340              return !((*src1 ^ *src2) & BITMAP_LAST_WORD_MASK(nbits));
         : 341              if (__builtin_constant_p(nbits & BITMAP_MEM_MASK) &&
         : 342              IS_ALIGNED(nbits, BITMAP_MEM_ALIGNMENT))
         : 343              return !memcmp(src1, src2, nbits / 8);
    0.00 :   ffff8000100b4be0:       ldr     x1, [x23]
    0.00 :   ffff8000100b4be4:       ldr     x2, [x19, #688]
    0.00 :   ffff8000100b4be8:       cmp     x2, x1
    0.00 :   ffff8000100b4bec:       b.eq    ffff8000100b4cd0 <__set_cpus_allowed_ptr+0x170>  // b.none
         : 348              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100b4bf0:       mrs     x1, sp_el0
         : 26               __set_cpus_allowed_ptr():
         :
         : 2386             raw_spin_lock_irq(&p->pi_lock);
         : 2387             raw_spin_rq_lock(rq);
         :
    0.00 :   ffff8000100b4bf4:       cmp     x19, x1
    0.00 :   ffff8000100b4bf8:       b.eq    ffff8000100b4c98 <__set_cpus_allowed_ptr+0x138>  // b.none
         :
         : 2399             p->migration_flags &= ~MDF_PUSH;
         :
         : 2401             if (p->sched_class->find_lock_rq)
         : 2402             lowest_rq = p->sched_class->find_lock_rq(p, rq);
         :
    0.00 :   ffff8000100b4bfc:       mov     x1, x23
    0.00 :   ffff8000100b4c00:       bl      ffff8000104a77b0 <cpumask_any_and_distribute>
    0.00 :   ffff8000100b4c04:       mov     w24, w0
         : 2399             if (!lowest_rq)
    0.00 :   ffff8000100b4c08:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b4c0c:       ldr     w0, [x0, #3120]
    0.00 :   ffff8000100b4c10:       cmp     w0, w24
    0.00 :   ffff8000100b4c14:       b.hi    ffff8000100b4c68 <__set_cpus_allowed_ptr+0x108>  // b.pmore
         :
    0.00 :   ffff8000100b4c18:       mov     w21, #0xffffffea                // #-22
         : 2379             task_rq_unlock():
         : 1310             raw_spin_rq_lock_nested(rq, 0);
         : 1311             }
         :
         : 1313             static inline void raw_spin_rq_lock_irq(struct rq *rq)
         : 1314             {
         : 1315             local_irq_disable();
    0.00 :   ffff8000100b4c1c:       mov     x0, x22
    0.00 :   ffff8000100b4c20:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 1311             raw_spin_rq_lock(rq);
    0.00 :   ffff8000100b4c24:       ldr     x1, [sp, #64]
    0.00 :   ffff8000100b4c28:       add     x0, x19, #0x6f4
    0.00 :   ffff8000100b4c2c:       bl      ffff800010e35380 <_raw_spin_unlock_irqrestore>
         : 1315             __set_cpus_allowed_ptr():
         : 2412             resched_curr(lowest_rq);
         : 2413             }
         :
         : 2415             double_unlock_balance(rq, lowest_rq);
         :
         : 2417             out_unlock:
    0.00 :   ffff8000100b4c30:       mov     w0, w21
    0.00 :   ffff8000100b4c34:       ldr     x2, [sp, #72]
    0.00 :   ffff8000100b4c38:       ldr     x1, [x20]
    0.00 :   ffff8000100b4c3c:       eor     x1, x2, x1
    0.00 :   ffff8000100b4c40:       cbnz    x1, ffff8000100b4d08 <__set_cpus_allowed_ptr+0x1a8>
    0.00 :   ffff8000100b4c44:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b4c48:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b4c4c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff8000100b4c50:       ldp     x29, x30, [sp], #80
    0.00 :   ffff8000100b4c54:       autiasp
    0.00 :   ffff8000100b4c58:       ret
         : 2369             pending->stop_pending = false;
    0.00 :   ffff8000100b4c5c:       adrp    x0, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b4c60:       add     x0, x0, #0x9e8
    0.00 :   ffff8000100b4c64:       b       ffff8000100b4bd4 <__set_cpus_allowed_ptr+0x74>
         : 2404             deactivate_task(rq, p, 0);
    0.00 :   ffff8000100b4c68:       mov     w2, w21
    0.00 :   ffff8000100b4c6c:       mov     x1, x23
    0.00 :   ffff8000100b4c70:       mov     x0, x19
    0.00 :   ffff8000100b4c74:       bl      ffff8000100b1c60 <__do_set_cpus_allowed>
         : 2406             activate_task(lowest_rq, p, 0);
    0.00 :   ffff8000100b4c78:       mov     w4, w21
    0.00 :   ffff8000100b4c7c:       mov     w3, w24
    0.00 :   ffff8000100b4c80:       add     x2, sp, #0x40
    0.00 :   ffff8000100b4c84:       mov     x1, x19
    0.00 :   ffff8000100b4c88:       mov     x0, x22
    0.00 :   ffff8000100b4c8c:       bl      ffff8000100b4638 <affine_move_task>
    0.00 :   ffff8000100b4c90:       mov     w21, w0
    0.00 :   ffff8000100b4c94:       b       ffff8000100b4c30 <__set_cpus_allowed_ptr+0xd0>
         :
  100.00 :   ffff8000100b4c98:       ldrh    w1, [x19, #728]
    0.00 :   ffff8000100b4c9c:       cbz     w1, ffff8000100b4bfc <__set_cpus_allowed_ptr+0x9c>
         : 2388             task_cpu():
         : 1993             * Returns non-zero if there is another task waiting on the rwlock.
         : 1994             * Returns zero if the lock is not contended or the system / underlying
         : 1995             * rwlock implementation does not support contention detection.
         : 1996             * Technically does not depend on CONFIG_PREEMPTION, but a general need
         : 1997             * for low latency.
         : 1998             */
    0.00 :   ffff8000100b4ca0:       ldr     w2, [x19, #64]
         : 2000             test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff8000100b4ca4:       cmp     w2, #0x0
    0.00 :   ffff8000100b4ca8:       add     w1, w2, #0x3f
    0.00 :   ffff8000100b4cac:       csel    w1, w1, w2, lt  // lt = tstop
    0.00 :   ffff8000100b4cb0:       asr     w1, w1, #6
    0.00 :   ffff8000100b4cb4:       sxtw    x1, w1
    0.00 :   ffff8000100b4cb8:       ldr     x1, [x23, x1, lsl #3]
    0.00 :   ffff8000100b4cbc:       lsr     x2, x1, x2
         : 119              __set_cpus_allowed_ptr():
    0.00 :   ffff8000100b4cc0:       tbnz    w2, #0, ffff8000100b4bfc <__set_cpus_allowed_ptr+0x9c>
    0.00 :   ffff8000100b4cc4:       brk     #0x800
         :
    0.00 :   ffff8000100b4cc8:       mov     w21, #0xfffffff0                // #-16
    0.00 :   ffff8000100b4ccc:       b       ffff8000100b4c1c <__set_cpus_allowed_ptr+0xbc>
         : 2391             bitmap_equal():
    0.00 :   ffff8000100b4cd0:       ldr     x1, [x23, #8]
    0.00 :   ffff8000100b4cd4:       ldr     x2, [x19, #696]
    0.00 :   ffff8000100b4cd8:       cmp     x2, x1
    0.00 :   ffff8000100b4cdc:       b.ne    ffff8000100b4bf0 <__set_cpus_allowed_ptr+0x90>  // b.any
    0.00 :   ffff8000100b4ce0:       ldr     x1, [x23, #16]
    0.00 :   ffff8000100b4ce4:       ldr     x2, [x19, #704]
    0.00 :   ffff8000100b4ce8:       cmp     x2, x1
    0.00 :   ffff8000100b4cec:       b.ne    ffff8000100b4bf0 <__set_cpus_allowed_ptr+0x90>  // b.any
    0.00 :   ffff8000100b4cf0:       ldr     x1, [x23, #24]
    0.00 :   ffff8000100b4cf4:       ldr     x2, [x19, #712]
    0.00 :   ffff8000100b4cf8:       cmp     x2, x1
    0.00 :   ffff8000100b4cfc:       b.ne    ffff8000100b4bf0 <__set_cpus_allowed_ptr+0x90>  // b.any
    0.00 :   ffff8000100b4d00:       mov     w21, #0x0                       // #0
    0.00 :   ffff8000100b4d04:       b       ffff8000100b4c1c <__set_cpus_allowed_ptr+0xbc>
         : 352              __set_cpus_allowed_ptr():
         : 2412             out_unlock:
    0.00 :   ffff8000100b4d08:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000100b8050 <sched_setaffinity>:
         : 6                sched_setaffinity():
         : 6766             * NOTE: numerical errors or stop class might cause us to not quite hit
         : 6767             * saturation when we should -- something for later.
         : 6768             */
         : 6769             if (util + dl_util >= max)
         : 6770             return max;
         :
  100.00 :   ffff8000100b8050:       paciasp
    0.00 :   ffff8000100b8054:       stp     x29, x30, [sp, #-144]!
    0.00 :   ffff8000100b8058:       mov     x29, sp
    0.00 :   ffff8000100b805c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b8060:       adrp    x21, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff8000100b8064:       add     x21, x21, #0x948
    0.00 :   ffff8000100b8068:       stp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b806c:       mov     w19, w0
    0.00 :   ffff8000100b8070:       ldr     x0, [x21]
    0.00 :   ffff8000100b8074:       str     x0, [sp, #136]
    0.00 :   ffff8000100b8078:       mov     x0, #0x0                        // #0
    0.00 :   ffff8000100b807c:       str     x23, [sp, #48]
    0.00 :   ffff8000100b8080:       mov     x23, x1
         : 6785             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100b8084:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              find_process_by_pid():
         : 6000             * it wants to wake up a task to maintain concurrency.
    0.00 :   ffff8000100b8088:       cbnz    w19, ffff8000100b8184 <sched_setaffinity+0x134>
         : 6002             get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff8000100b808c:       mrs     x20, sp_el0
         : 26               sched_setaffinity():
         : 6774             * include util_dl and ignore dl_bw.
         : 6775             */
         : 6776             if (type == ENERGY_UTIL)
         : 6777             util += dl_util;
         :
         : 6779             /*
    0.00 :   ffff8000100b8090:       cbz     x20, ffff8000100b82ac <sched_setaffinity+0x25c>
         : 6781             get_task_struct():
         : 104              #define sched_exec()   {}
         : 105              #endif
         :
         : 107              static inline struct task_struct *get_task_struct(struct task_struct *t)
         : 108              {
         : 109              refcount_inc(&t->usage);
    0.00 :   ffff8000100b8094:       add     x19, x20, #0x20
         : 111              arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000100b8098:       b       ffff8000100b80ac <sched_setaffinity+0x5c>
    0.00 :   ffff8000100b809c:       b       ffff8000100b80ac <sched_setaffinity+0x5c>
         : 46               __lse_atomic_fetch_add_relaxed():
         : 52               ATOMIC_FETCH_OP(        , al, op, asm_op, "memory")
         :
         : 54               ATOMIC_FETCH_OPS(andnot, ldclr)
         : 55               ATOMIC_FETCH_OPS(or, ldset)
         : 56               ATOMIC_FETCH_OPS(xor, ldeor)
         : 57               ATOMIC_FETCH_OPS(add, ldadd)
    0.00 :   ffff8000100b80a0:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100b80a4:       ldadd   w0, w0, [x19]
    0.00 :   ffff8000100b80a8:       b       ffff8000100b80b0 <sched_setaffinity+0x60>
         : 61               __ll_sc_atomic_fetch_add_relaxed():
         : 111              ATOMIC_FETCH_OP (        , dmb ish,  , l, "memory", __VA_ARGS__)\
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
    0.00 :   ffff8000100b80ac:       b       ffff8000100b9d34 <call_trace_sched_update_nr_running+0x32c>
         : 118              __refcount_add():
         : 198              int old = atomic_fetch_add_relaxed(i, &r->refs);
         :
         : 200              if (oldp)
         : 201              *oldp = old;
         :
         : 203              if (unlikely(!old))
    0.00 :   ffff8000100b80b0:       cmp     w0, #0x0
    0.00 :   ffff8000100b80b4:       b.eq    ffff8000100b823c <sched_setaffinity+0x1ec>  // b.none
         : 200              refcount_warn_saturate(r, REFCOUNT_ADD_UAF);
         : 201              else if (unlikely(old < 0 || old + i < 0))
    0.00 :   ffff8000100b80b8:       b.lt    ffff8000100b821c <sched_setaffinity+0x1cc>  // b.tstop
    0.00 :   ffff8000100b80bc:       cmn     w0, #0x1
    0.00 :   ffff8000100b80c0:       b.mi    ffff8000100b821c <sched_setaffinity+0x1cc>  // b.first
         : 205              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100b80c4:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              sched_setaffinity():
         : 6783             *
         : 6784             *              max - irq
         : 6785             *   U' = irq + --------- * U
         : 6786             *                 max
         : 6787             */
         : 6788             util = scale_irq_capacity(util, irq, max);
    0.00 :   ffff8000100b80c8:       mov     x22, #0xffffffffffffffea        // #-22
    0.00 :   ffff8000100b80cc:       ldr     w0, [x20, #36]
    0.00 :   ffff8000100b80d0:       tbnz    w0, #26, ffff8000100b8114 <sched_setaffinity+0xc4>
         : 6796             *
         : 6797             * Ideally we would like to set bw_dl as min/guaranteed freq and util +
         : 6798             * bw_dl as requested freq. However, cpufreq is not yet ready for such
         : 6799             * an interface. So, we only do the latter for now.
         : 6800             */
         : 6801             if (type == FREQUENCY_UTIL)
    0.00 :   ffff8000100b80d4:       mov     x0, x20
    0.00 :   ffff8000100b80d8:       bl      ffff8000100b1190 <check_same_owner>
    0.00 :   ffff8000100b80dc:       tst     w0, #0xff
    0.00 :   ffff8000100b80e0:       b.ne    ffff8000100b8104 <sched_setaffinity+0xb4>  // b.any
         : 6806             rcu_read_lock():
         : 655              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100b80e4:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 657              sched_setaffinity():
         : 6798             util += cpu_bw_dl(rq);
         :
    0.00 :   ffff8000100b80e8:       ldr     x0, [x20, #1520]
    0.00 :   ffff8000100b80ec:       mov     w1, #0x17                       // #23
    0.00 :   ffff8000100b80f0:       ldr     x0, [x0, #136]
    0.00 :   ffff8000100b80f4:       bl      ffff80001008d5e0 <ns_capable>
    0.00 :   ffff8000100b80f8:       tst     w0, #0xff
    0.00 :   ffff8000100b80fc:       b.eq    ffff8000100b8210 <sched_setaffinity+0x1c0>  // b.none
         : 6806             rcu_read_unlock():
         : 710              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100b8100:       bl      ffff800010102998 <__rcu_read_unlock>
         : 712              sched_setaffinity():
         : 6805             }
         :
         : 6807             unsigned long sched_cpu_util(int cpu, unsigned long max)
         : 6808             {
         : 6809             return effective_cpu_util(cpu, cpu_util_cfs(cpu_rq(cpu)), max,
         : 6810             ENERGY_UTIL, NULL);
    0.00 :   ffff8000100b8104:       mov     x0, x20
    0.00 :   ffff8000100b8108:       bl      ffff800010416998 <security_task_setscheduler>
         : 6806             }
    0.00 :   ffff8000100b810c:       cbz     w0, ffff8000100b8194 <sched_setaffinity+0x144>
    0.00 :   ffff8000100b8110:       sxtw    x22, w0
         : 6809             arch_static_branch_jump():
    0.00 :   ffff8000100b8114:       b       ffff8000100b8164 <sched_setaffinity+0x114>
    0.00 :   ffff8000100b8118:       b       ffff8000100b8164 <sched_setaffinity+0x114>
         : 40               __lse_atomic_fetch_sub_release():
         : 161              return i;                                                       \
         : 162              }
         :
         : 164              ATOMIC_FETCH_OP_SUB(_relaxed,   )
         : 165              ATOMIC_FETCH_OP_SUB(_acquire,  a, "memory")
         : 166              ATOMIC_FETCH_OP_SUB(_release,  l, "memory")
    0.00 :   ffff8000100b811c:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000100b8120:       neg     w1, w1
    0.00 :   ffff8000100b8124:       ldaddl  w1, w1, [x19]
         : 170              __refcount_sub_and_test():
         : 277              int old = atomic_fetch_sub_release(i, &r->refs);
         :
         : 279              if (oldp)
         : 280              *oldp = old;
         :
         : 282              if (old == i) {
    0.00 :   ffff8000100b8128:       cmp     w1, #0x1
    0.00 :   ffff8000100b812c:       b.eq    ffff8000100b8174 <sched_setaffinity+0x124>  // b.none
         : 282              smp_acquire__after_ctrl_dep();
         : 283              return true;
         : 284              }
         :
         : 286              if (unlikely(old < 0 || old - i < 0))
    0.00 :   ffff8000100b8130:       cmp     w1, #0x0
    0.00 :   ffff8000100b8134:       b.le    ffff8000100b822c <sched_setaffinity+0x1dc>
         : 289              sched_setaffinity():
         : 6852             p->normal_prio = normal_prio(p);
         : 6853             set_load_weight(p, true);
         : 6854             }
         :
         : 6856             /* Actually do priority change: must hold pi & rq lock. */
         : 6857             static void __setscheduler(struct rq *rq, struct task_struct *p,
    0.00 :   ffff8000100b8138:       mov     x0, x22
    0.00 :   ffff8000100b813c:       ldr     x2, [sp, #136]
    0.00 :   ffff8000100b8140:       ldr     x1, [x21]
    0.00 :   ffff8000100b8144:       eor     x1, x2, x1
    0.00 :   ffff8000100b8148:       cbnz    x1, ffff8000100b82b8 <sched_setaffinity+0x268>
    0.00 :   ffff8000100b814c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff8000100b8150:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff8000100b8154:       ldr     x23, [sp, #48]
    0.00 :   ffff8000100b8158:       ldp     x29, x30, [sp], #144
    0.00 :   ffff8000100b815c:       autiasp
    0.00 :   ffff8000100b8160:       ret
         : 6869             __ll_sc_atomic_fetch_sub_release():
         : 112              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff8000100b8164:       mov     w0, #0x1                        // #1
    0.00 :   ffff8000100b8168:       b       ffff8000100b9d4c <call_trace_sched_update_nr_running+0x344>
         : 115              __refcount_sub_and_test():
         : 277              if (old == i) {
    0.00 :   ffff8000100b816c:       cmp     w1, #0x1
    0.00 :   ffff8000100b8170:       b.ne    ffff8000100b8130 <sched_setaffinity+0xe0>  // b.any
         : 278              smp_acquire__after_ctrl_dep();
    0.00 :   ffff8000100b8174:       dmb     ishld
         : 280              put_task_struct():
         : 113              extern void __put_task_struct(struct task_struct *t);
         :
         : 115              static inline void put_task_struct(struct task_struct *t)
         : 116              {
         : 117              if (refcount_dec_and_test(&t->usage))
         : 118              __put_task_struct(t);
    0.00 :   ffff8000100b8178:       mov     x0, x20
    0.00 :   ffff8000100b817c:       bl      ffff80001007df38 <__put_task_struct>
    0.00 :   ffff8000100b8180:       b       ffff8000100b8138 <sched_setaffinity+0xe8>
         : 122              find_process_by_pid():
         : 6000             * it wants to wake up a task to maintain concurrency.
    0.00 :   ffff8000100b8184:       mov     w0, w19
    0.00 :   ffff8000100b8188:       bl      ffff8000100a5600 <find_task_by_vpid>
    0.00 :   ffff8000100b818c:       mov     x20, x0
    0.00 :   ffff8000100b8190:       b       ffff8000100b8090 <sched_setaffinity+0x40>
         : 6005             sched_setaffinity():
         : 6810             * find_process_by_pid - find a process with a matching PID value.
    0.00 :   ffff8000100b8194:       mov     x0, x20
    0.00 :   ffff8000100b8198:       add     x1, sp, #0x48
    0.00 :   ffff8000100b819c:       bl      ffff800010147118 <cpuset_cpus_allowed>
         : 6814             bitmap_and():
         : 286              static inline int bitmap_and(unsigned long *dst, const unsigned long *src1,
         : 287              const unsigned long *src2, unsigned int nbits)
         : 288              {
         : 289              if (small_const_nbits(nbits))
         : 290              return (*dst = *src1 & *src2 & BITMAP_LAST_WORD_MASK(nbits)) != 0;
         : 291              return __bitmap_and(dst, src1, src2, nbits);
    0.00 :   ffff8000100b81a0:       add     x2, sp, #0x48
    0.00 :   ffff8000100b81a4:       mov     x1, x23
    0.00 :   ffff8000100b81a8:       add     x0, sp, #0x68
    0.00 :   ffff8000100b81ac:       mov     w3, #0x100                      // #256
    0.00 :   ffff8000100b81b0:       bl      ffff800010461d10 <__bitmap_and>
         : 297              sched_setaffinity():
         : 6820             /*
    0.00 :   ffff8000100b81b4:       ldr     w0, [x20, #672]
    0.00 :   ffff8000100b81b8:       cmp     w0, #0x6
    0.00 :   ffff8000100b81bc:       b.ne    ffff8000100b81f4 <sched_setaffinity+0x1a4>  // b.any
    0.00 :   ffff8000100b81c0:       b       ffff8000100b8254 <sched_setaffinity+0x204>
         : 6834             p->policy = policy;
    0.00 :   ffff8000100b81c4:       add     x1, sp, #0x48
    0.00 :   ffff8000100b81c8:       mov     x0, x20
    0.00 :   ffff8000100b81cc:       bl      ffff800010147118 <cpuset_cpus_allowed>
         : 6838             bitmap_subset():
         : 377              const unsigned long *src2, unsigned int nbits)
         : 378              {
         : 379              if (small_const_nbits(nbits))
         : 380              return ! ((*src1 & ~(*src2)) & BITMAP_LAST_WORD_MASK(nbits));
         : 381              else
         : 382              return __bitmap_subset(src1, src2, nbits);
    0.00 :   ffff8000100b81d0:       add     x1, sp, #0x48
    0.00 :   ffff8000100b81d4:       mov     w2, #0x100                      // #256
    0.00 :   ffff8000100b81d8:       add     x0, sp, #0x68
    0.00 :   ffff8000100b81dc:       bl      ffff800010461f88 <__bitmap_subset>
         : 387              sched_setaffinity():
         :
    0.00 :   ffff8000100b81e0:       cbnz    w0, ffff8000100b824c <sched_setaffinity+0x1fc>
         : 6837             bitmap_copy():
         : 249              memcpy(dst, src, len);
    0.00 :   ffff8000100b81e4:       ldp     x0, x1, [sp, #72]
    0.00 :   ffff8000100b81e8:       stp     x0, x1, [sp, #104]
    0.00 :   ffff8000100b81ec:       ldp     x0, x1, [sp, #88]
    0.00 :   ffff8000100b81f0:       stp     x0, x1, [sp, #120]
         : 254              sched_setaffinity():
         : 6831             if (policy == SETPARAM_POLICY)
    0.00 :   ffff8000100b81f4:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000100b81f8:       add     x1, sp, #0x68
    0.00 :   ffff8000100b81fc:       mov     x0, x20
    0.00 :   ffff8000100b8200:       bl      ffff8000100b4b60 <__set_cpus_allowed_ptr>
         :
    0.00 :   ffff8000100b8204:       cbz     w0, ffff8000100b81c4 <sched_setaffinity+0x174>
    0.00 :   ffff8000100b8208:       sxtw    x22, w0
    0.00 :   ffff8000100b820c:       b       ffff8000100b8114 <sched_setaffinity+0xc4>
         : 6837             rcu_read_unlock():
    0.00 :   ffff8000100b8210:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              sched_setaffinity():
         : 6800             }
    0.00 :   ffff8000100b8214:       mov     x22, #0xffffffffffffffff        // #-1
    0.00 :   ffff8000100b8218:       b       ffff8000100b8114 <sched_setaffinity+0xc4>
         : 6803             __refcount_add():
         : 201              refcount_warn_saturate(r, REFCOUNT_ADD_OVF);
    0.00 :   ffff8000100b821c:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000100b8220:       mov     x0, x19
    0.00 :   ffff8000100b8224:       bl      ffff800010470e68 <refcount_warn_saturate>
    0.00 :   ffff8000100b8228:       b       ffff8000100b80c4 <sched_setaffinity+0x74>
         : 206              __refcount_sub_and_test():
         : 283              refcount_warn_saturate(r, REFCOUNT_SUB_UAF);
    0.00 :   ffff8000100b822c:       mov     x0, x19
    0.00 :   ffff8000100b8230:       mov     w1, #0x3                        // #3
    0.00 :   ffff8000100b8234:       bl      ffff800010470e68 <refcount_warn_saturate>
         : 287              sched_setaffinity():
         : 6851             /* Actually do priority change: must hold pi & rq lock. */
    0.00 :   ffff8000100b8238:       b       ffff8000100b8138 <sched_setaffinity+0xe8>
         : 6853             __refcount_add():
         : 199              refcount_warn_saturate(r, REFCOUNT_ADD_UAF);
    0.00 :   ffff8000100b823c:       mov     w1, #0x2                        // #2
    0.00 :   ffff8000100b8240:       mov     x0, x19
    0.00 :   ffff8000100b8244:       bl      ffff800010470e68 <refcount_warn_saturate>
    0.00 :   ffff8000100b8248:       b       ffff8000100b80c4 <sched_setaffinity+0x74>
         : 204              sched_setaffinity():
         : 6845             */
    0.00 :   ffff8000100b824c:       mov     x22, #0x0                       // #0
    0.00 :   ffff8000100b8250:       b       ffff8000100b8114 <sched_setaffinity+0xc4>
         : 6848             dl_bandwidth_enabled():
         : 276              u64                     dl_period;
         : 277              };
         :
         : 279              static inline int dl_bandwidth_enabled(void)
         : 280              {
         : 281              return sysctl_sched_rt_runtime >= 0;
    0.00 :   ffff8000100b8254:       adrp    x0, ffff800011c41000 <modprobe_path+0x48>
         : 283              sched_setaffinity():
         : 6820             /*
    0.00 :   ffff8000100b8258:       ldr     w0, [x0, #384]
    0.00 :   ffff8000100b825c:       tbnz    w0, #31, ffff8000100b81f4 <sched_setaffinity+0x1a4>
         : 6823             rcu_read_lock():
         : 655              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff8000100b8260:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 657              task_cpu():
         : 1993             * Returns non-zero if there is another task waiting on the rwlock.
         : 1994             * Returns zero if the lock is not contended or the system / underlying
         : 1995             * rwlock implementation does not support contention detection.
         : 1996             * Technically does not depend on CONFIG_PREEMPTION, but a general need
         : 1997             * for low latency.
         : 1998             */
    0.00 :   ffff8000100b8264:       ldr     w3, [x20, #64]
         : 2000             sched_setaffinity():
         : 6822             * it calls know not to change it.
    0.00 :   ffff8000100b8268:       adrp    x1, ffff800011c2d000 <xen_lateeoi_chip+0x68>
    0.00 :   ffff8000100b826c:       add     x1, x1, #0x760
    0.00 :   ffff8000100b8270:       adrp    x0, ffff800011779000 <cpu_armpmu>
    0.00 :   ffff8000100b8274:       add     x0, x0, #0xc40
         : 6827             bitmap_subset():
         : 377              return __bitmap_subset(src1, src2, nbits);
    0.00 :   ffff8000100b8278:       mov     w2, #0x100                      // #256
         : 379              sched_setaffinity():
    0.00 :   ffff8000100b827c:       ldr     x3, [x1, w3, uxtw #3]
         : 6823             bitmap_subset():
    0.00 :   ffff8000100b8280:       add     x1, sp, #0x68
         : 378              sched_setaffinity():
    0.00 :   ffff8000100b8284:       add     x0, x3, x0
         : 6823             cpumask_subset():
         : 512              * Returns 1 if *@src1p is a subset of *@src2p, else returns 0
         : 513              */
         : 514              static inline int cpumask_subset(const struct cpumask *src1p,
         : 515              const struct cpumask *src2p)
         : 516              {
         : 517              return bitmap_subset(cpumask_bits(src1p), cpumask_bits(src2p),
    0.00 :   ffff8000100b8288:       ldr     x0, [x0, #2464]
         : 519              bitmap_subset():
    0.00 :   ffff8000100b828c:       add     x0, x0, #0x18
    0.00 :   ffff8000100b8290:       bl      ffff800010461f88 <__bitmap_subset>
         : 379              sched_setaffinity():
    0.00 :   ffff8000100b8294:       cbz     w0, ffff8000100b82a0 <sched_setaffinity+0x250>
         : 6823             rcu_read_unlock():
         : 710              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100b8298:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              *
    0.00 :   ffff8000100b829c:       b       ffff8000100b81f4 <sched_setaffinity+0x1a4>
         : 710              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff8000100b82a0:       bl      ffff800010102998 <__rcu_read_unlock>
         : 712              sched_setaffinity():
         :
    0.00 :   ffff8000100b82a4:       mov     x22, #0xfffffffffffffff0        // #-16
    0.00 :   ffff8000100b82a8:       b       ffff8000100b8114 <sched_setaffinity+0xc4>
         : 6828             rcu_read_unlock():
    0.00 :   ffff8000100b82ac:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              sched_setaffinity():
         : 6776             * irq metric. Because IRQ/steal time is hidden from the task clock we
    0.00 :   ffff8000100b82b0:       mov     x22, #0xfffffffffffffffd        // #-3
    0.00 :   ffff8000100b82b4:       b       ffff8000100b8138 <sched_setaffinity+0xe8>
         : 6852             static void __setscheduler(struct rq *rq, struct task_struct *p,
    0.00 :   ffff8000100b82b8:       bl      ffff800010e2b8c8 <__stack_chk_fail>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010411ee8 <cap_safe_nice>:
         : 6                cap_safe_nice():
         : 1176             * This is insufficient now since you can call code without suid, but
         : 1177             * yet with increased caps.
         : 1178             * So we check for increased caps on the target process.
         : 1179             */
         : 1180             static int cap_safe_nice(struct task_struct *p)
         : 1181             {
  100.00 :   ffff800010411ee8:       paciasp
    0.00 :   ffff800010411eec:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff800010411ef0:       mov     x29, sp
    0.00 :   ffff800010411ef4:       str     x19, [sp, #16]
    0.00 :   ffff800010411ef8:       mov     x19, x0
         : 1187             rcu_read_lock():
         : 655              * define synchronize_sched(), only code enclosed within rcu_read_lock()
         : 656              * and rcu_read_unlock() are guaranteed to be waited for.
         : 657              *
         : 658              * Note, however, that RCU callbacks are permitted to run concurrently
         : 659              * with new RCU read-side critical sections.  One way that this can happen
         : 660              * is via the following sequence of events: (1) CPU 0 enters an RCU
    0.00 :   ffff800010411efc:       bl      ffff8000100fd6f8 <__rcu_read_lock>
         : 662              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010411f00:       mrs     x0, sp_el0
         : 26               cap_safe_nice():
         : 1180             int is_subset, ret = 0;
         :
         : 1182             rcu_read_lock();
         : 1183             is_subset = cap_issubset(__task_cred(p)->cap_permitted,
    0.00 :   ffff800010411f04:       ldr     x3, [x19, #1520]
         : 1181             current_cred()->cap_permitted);
    0.00 :   ffff800010411f08:       ldr     x2, [x0, #1528]
         : 1183             cap_drop():
         :
         : 139              static inline kernel_cap_t cap_drop(const kernel_cap_t a,
         : 140              const kernel_cap_t drop)
         : 141              {
         : 142              kernel_cap_t dest;
         : 143              CAP_BOP_ALL(dest, a, drop, &~);
    0.00 :   ffff800010411f0c:       ldp     w4, w0, [x3, #48]
    0.00 :   ffff800010411f10:       ldp     w1, w2, [x2, #48]
    0.00 :   ffff800010411f14:       bic     w1, w4, w1
    0.00 :   ffff800010411f18:       bic     w2, w0, w2
         : 148              cap_isclear():
         :
         : 154              static inline bool cap_isclear(const kernel_cap_t a)
         : 155              {
         : 156              unsigned __capi;
         : 157              CAP_FOR_EACH_U32(__capi) {
         : 158              if (a.cap[__capi] != 0)
    0.00 :   ffff800010411f1c:       orr     w1, w1, w2
    0.00 :   ffff800010411f20:       cbnz    w1, ffff800010411f40 <cap_safe_nice+0x58>
         : 161              rcu_read_unlock():
         : 710              * In almost all situations, rcu_read_unlock() is immune from deadlock.
         : 711              * In recent kernels that have consolidated synchronize_sched() and
         : 712              * synchronize_rcu_bh() into synchronize_rcu(), this deadlock immunity
         : 713              * also extends to the scheduler's runqueue and priority-inheritance
         : 714              * spinlocks, courtesy of the quiescent-state deferral that is carried
         : 715              * out when rcu_read_unlock() is invoked with interrupts disabled.
    0.00 :   ffff800010411f24:       bl      ffff800010102998 <__rcu_read_unlock>
         : 717              cap_safe_nice():
         : 1177             int is_subset, ret = 0;
    0.00 :   ffff800010411f28:       mov     w19, #0x0                       // #0
         : 1187             if (!is_subset && !ns_capable(__task_cred(p)->user_ns, CAP_SYS_NICE))
         : 1188             ret = -EPERM;
         : 1189             rcu_read_unlock();
         :
         : 1191             return ret;
         : 1192             }
    0.00 :   ffff800010411f2c:       mov     w0, w19
    0.00 :   ffff800010411f30:       ldr     x19, [sp, #16]
    0.00 :   ffff800010411f34:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010411f38:       autiasp
    0.00 :   ffff800010411f3c:       ret
         : 1182             if (!is_subset && !ns_capable(__task_cred(p)->user_ns, CAP_SYS_NICE))
    0.00 :   ffff800010411f40:       ldr     x0, [x19, #1520]
    0.00 :   ffff800010411f44:       mov     w1, #0x17                       // #23
    0.00 :   ffff800010411f48:       ldr     x0, [x0, #136]
    0.00 :   ffff800010411f4c:       bl      ffff80001008d5e0 <ns_capable>
    0.00 :   ffff800010411f50:       and     w19, w0, #0xff
    0.00 :   ffff800010411f54:       eor     w19, w19, #0x1
         : 1189             rcu_read_unlock():
    0.00 :   ffff800010411f58:       bl      ffff800010102998 <__rcu_read_unlock>
         : 711              cap_safe_nice():
    0.00 :   ffff800010411f5c:       neg     w19, w19
         : 1187             }
    0.00 :   ffff800010411f60:       mov     w0, w19
    0.00 :   ffff800010411f64:       ldr     x19, [sp, #16]
    0.00 :   ffff800010411f68:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010411f6c:       autiasp
    0.00 :   ffff800010411f70:       ret
 Percent |	Source code & Disassembly of perf for cycles (1 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3      Disassembly of section .text:
         :
         : 5      000000000018dc80 <affinity__set>:
         : 6      affinity__set():
         : 49     * It is more efficient to change perf's affinity to the target
         : 50     * CPU and then set up all events on that CPU, so we amortize
         : 51     * CPU communication.
         : 52     */
         : 53     void affinity__set(struct affinity *a, int cpu)
         : 54     {
  100.00 :   18dc80: stp     x29, x30, [sp, #-64]!
    0.00 :   18dc84: adrp    x2, 34d000 <options+0x650>
    0.00 :   18dc88: mov     x29, sp
    0.00 :   18dc8c: ldr     x2, [x2, #2784]
    0.00 :   18dc90: stp     x19, x20, [sp, #16]
    0.00 :   18dc94: mov     w19, w1
    0.00 :   18dc98: str     x21, [sp, #32]
    0.00 :   18dc9c: mov     x21, x0
    0.00 :   18dca0: ldr     x0, [x2]
    0.00 :   18dca4: str     x0, [sp, #56]
    0.00 :   18dca8: mov     x0, #0x0                        // #0
         : 66     get_cpu_set_size():
         : 14     int sz = cpu__max_cpu() + 8 - 1;
    0.00 :   18dcac: bl      18d120 <cpu__max_cpu>
         : 16     affinity__set():
         : 52     int cpu_set_size = get_cpu_set_size();
         :
         : 54     if (cpu == -1)
    0.00 :   18dcb0: cmn     w19, #0x1
    0.00 :   18dcb4: b.eq    18dd2c <affinity__set+0xac>  // b.none
         : 57     set_bit():
         : 10     #include <asm/types.h>
         : 11     #include <asm/bitsperlong.h>
         :
         : 13     static inline void set_bit(int nr, unsigned long *addr)
         : 14     {
         : 15     addr[nr / __BITS_PER_LONG] |= 1UL << (nr % __BITS_PER_LONG);
    0.00 :   18dcb8: cmp     w19, #0x0
    0.00 :   18dcbc: add     w20, w19, #0x3f
    0.00 :   18dcc0: csel    w20, w20, w19, lt  // lt = tstop
    0.00 :   18dcc4: negs    w3, w19
         : 20     affinity__set():
         : 55     return;
         : 56     a->changed = true;
         : 57     set_bit(cpu, a->sched_cpus);
    0.00 :   18dcc8: ldr     x2, [x21, #8]
         : 59     set_bit():
    0.00 :   18dccc: asr     w20, w20, #6
         : 11     get_cpu_set_size():
         : 14     int sz = cpu__max_cpu() + 8 - 1;
    0.00 :   18dcd0: add     w1, w0, #0x7
         : 16     set_bit():
    0.00 :   18dcd4: and     w19, w19, #0x3f
    0.00 :   18dcd8: sxtw    x20, w20
    0.00 :   18dcdc: and     w3, w3, #0x3f
    0.00 :   18dce0: csneg   w3, w19, w3, mi  // mi = first
         : 14     get_cpu_set_size():
         : 21     return sz / 8;
    0.00 :   18dce4: mov     w0, #0x1000                     // #4096
    0.00 :   18dce8: cmp     w1, #0x1, lsl #12
         : 24     affinity__set():
         : 54     a->changed = true;
    0.00 :   18dcec: mov     w4, #0x1                        // #1
         : 56     get_cpu_set_size():
         : 21     return sz / 8;
    0.00 :   18dcf0: csel    w1, w1, w0, ge  // ge = tcont
         : 23     set_bit():
    0.00 :   18dcf4: mov     x19, #0x1                       // #1
    0.00 :   18dcf8: ldr     x0, [x2, x20, lsl #3]
         : 12     affinity__set():
         : 54     a->changed = true;
    0.00 :   18dcfc: strb    w4, [x21, #16]
         : 56     set_bit():
    0.00 :   18dd00: lsl     x19, x19, x3
         : 11     get_cpu_set_size():
         : 21     return sz / 8;
    0.00 :   18dd04: asr     w1, w1, #3
         : 23     set_bit():
    0.00 :   18dd08: orr     x0, x0, x19
    0.00 :   18dd0c: str     x0, [x2, x20, lsl #3]
         : 12     affinity__set():
         : 61     /*
         : 62     * We ignore errors because affinity is just an optimization.
         : 63     * This could happen for example with isolated CPUs or cpusets.
         : 64     * In this case the IPIs inside the kernel's perf API still work.
         : 65     */
         : 66     sched_setaffinity(0, cpu_set_size, (cpu_set_t *)a->sched_cpus);
    0.00 :   18dd10: sxtw    x1, w1
    0.00 :   18dd14: mov     w0, #0x0                        // #0
    0.00 :   18dd18: bl      70790 <sched_setaffinity@plt>
         : 70     clear_bit():
         : 15     }
         :
         : 17     static inline void clear_bit(int nr, unsigned long *addr)
         : 18     {
         : 19     addr[nr / __BITS_PER_LONG] &= ~(1UL << (nr % __BITS_PER_LONG));
    0.00 :   18dd1c: ldr     x0, [x21, #8]
    0.00 :   18dd20: ldr     x1, [x0, x20, lsl #3]
    0.00 :   18dd24: bic     x19, x1, x19
    0.00 :   18dd28: str     x19, [x0, x20, lsl #3]
         : 24     affinity__set():
         : 63     clear_bit(cpu, a->sched_cpus);
         : 64     }
    0.00 :   18dd2c: adrp    x0, 34d000 <options+0x650>
    0.00 :   18dd30: ldr     x0, [x0, #2784]
    0.00 :   18dd34: ldr     x1, [sp, #56]
    0.00 :   18dd38: ldr     x2, [x0]
    0.00 :   18dd3c: subs    x1, x1, x2
    0.00 :   18dd40: mov     x2, #0x0                        // #0
    0.00 :   18dd44: b.ne    18dd58 <affinity__set+0xd8>  // b.any
    0.00 :   18dd48: ldp     x19, x20, [sp, #16]
    0.00 :   18dd4c: ldr     x21, [sp, #32]
    0.00 :   18dd50: ldp     x29, x30, [sp], #64
    0.00 :   18dd54: ret
    0.00 :   18dd58: bl      70360 <__stack_chk_fail@plt>
 Percent |	Source code & Disassembly of vmlinux for cycles (115 samples, percent: local period)
----------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001016a570 <remote_function>:
         : 6                remote_function():
         : 72               void                    *info;
         : 73               int                     ret;
         : 74               };
         :
         : 76               static void remote_function(void *data)
         : 77               {
    0.00 :   ffff80001016a570:       paciasp
    0.00 :   ffff80001016a574:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff80001016a578:       mov     x29, sp
         : 74               struct remote_function_call *tfc = data;
         : 75               struct task_struct *p = tfc->p;
    0.00 :   ffff80001016a57c:       ldr     x2, [x0]
         :
         : 77               if (p) {
    0.00 :   ffff80001016a580:       cbz     x2, ffff80001016a5c0 <remote_function+0x50>
         : 79               task_cpu():
         : 1993             * Returns non-zero if there is another task waiting on the rwlock.
         : 1994             * Returns zero if the lock is not contended or the system / underlying
         : 1995             * rwlock implementation does not support contention detection.
         : 1996             * Technically does not depend on CONFIG_PREEMPTION, but a general need
         : 1997             * for low latency.
         : 1998             */
    0.00 :   ffff80001016a584:       ldr     w3, [x2, #64]
         : 2000             remote_function():
         : 78               /* -EAGAIN */
         : 79               if (task_cpu(p) != smp_processor_id())
    0.00 :   ffff80001016a588:       adrp    x1, ffff80001176d000 <cpu_number>
         : 81               __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001016a58c:       mrs     x4, tpidr_el1
         : 46               remote_function():
    0.00 :   ffff80001016a590:       add     x1, x1, #0x0
    0.00 :   ffff80001016a594:       ldr     w1, [x1, x4]
    0.00 :   ffff80001016a598:       cmp     w1, w3
    0.00 :   ffff80001016a59c:       b.eq    ffff80001016a5ac <remote_function+0x3c>  // b.none
         : 92               if (p != current)
         : 93               return;
         : 94               }
         :
         : 96               tfc->ret = tfc->func(tfc->info);
         : 97               }
    0.00 :   ffff80001016a5a0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001016a5a4:       autiasp
    0.00 :   ffff80001016a5a8:       ret
         : 86               tfc->ret = -ESRCH; /* No such (running) process */
    0.00 :   ffff80001016a5ac:       mov     w1, #0xfffffffd                 // #-3
    0.00 :   ffff80001016a5b0:       str     w1, [x0, #24]
         : 89               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001016a5b4:       mrs     x1, sp_el0
         : 26               remote_function():
         : 87               if (p != current)
    0.00 :   ffff80001016a5b8:       cmp     x2, x1
    0.00 :   ffff80001016a5bc:       b.ne    ffff80001016a5a0 <remote_function+0x30>  // b.any
         : 91               tfc->ret = tfc->func(tfc->info);
    0.00 :   ffff80001016a5c0:       str     x19, [sp, #16]
    0.00 :   ffff80001016a5c4:       mov     x19, x0
    0.00 :   ffff80001016a5c8:       ldp     x1, x0, [x0, #8]
    0.00 :   ffff80001016a5cc:       blr     x1
   58.09 :   ffff80001016a5d0:       str     w0, [x19, #24]
   24.17 :   ffff80001016a5d4:       ldr     x19, [sp, #16]
         : 92               }
    0.00 :   ffff80001016a5d8:       ldp     x29, x30, [sp], #32
    0.00 :   ffff80001016a5dc:       autiasp
   17.73 :   ffff80001016a5e0:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010025b30 <invoke_syscall>:
         : 6                invoke_syscall():
         : 44               }
         :
         : 46               static void invoke_syscall(struct pt_regs *regs, unsigned int scno,
         : 47               unsigned int sc_nr,
         : 48               const syscall_fn_t syscall_table[])
         : 49               {
    0.00 :   ffff800010025b30:       paciasp
    0.00 :   ffff800010025b34:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff800010025b38:       mov     x29, sp
  100.00 :   ffff800010025b3c:       stp     x19, x20, [sp, #16]
    0.00 :   ffff800010025b40:       mov     x19, x0
         : 21               #define JUMP_LABEL_NOP_SIZE             AARCH64_INSN_SIZE
         :
         : 23               static __always_inline bool arch_static_branch(struct static_key *key,
         : 24               bool branch)
         : 25               {
         : 26               asm_volatile_goto(
    0.00 :   ffff800010025b44:       nop
         : 49               long ret;
         :
         : 51               add_random_kstack_offset();
         :
         : 53               if (scno < sc_nr) {
    0.00 :   ffff800010025b48:       cmp     w1, w2
    0.00 :   ffff800010025b4c:       b.cs    ffff800010025bd4 <invoke_syscall+0xa4>  // b.hs, b.nlast
         : 51               syscall_fn_t syscall_fn;
         : 52               syscall_fn = syscall_table[array_index_nospec(scno, sc_nr)];
    0.00 :   ffff800010025b50:       mov     w2, w2
    0.00 :   ffff800010025b54:       mov     w0, w1
         : 55               array_index_mask_nospec():
         : 59               static inline unsigned long array_index_mask_nospec(unsigned long idx,
         : 60               unsigned long sz)
         : 61               {
         : 62               unsigned long mask;
         :
         : 64               asm volatile(
    0.00 :   ffff800010025b58:       cmp     x0, x2
    0.00 :   ffff800010025b5c:       ngc     x2, xzr
         : 66               "       sbc     %0, xzr, xzr\n"
         : 67               : "=r" (mask)
         : 68               : "r" (idx), "Ir" (sz)
         : 69               : "cc");
         :
         : 71               csdb();
    0.00 :   ffff800010025b60:       csdb
         : 73               invoke_syscall():
    0.00 :   ffff800010025b64:       and     w1, w1, w2
         : 52               __invoke_syscall():
         : 38               return syscall_fn(regs);
    0.00 :   ffff800010025b68:       mov     x0, x19
    0.00 :   ffff800010025b6c:       ldr     x1, [x3, x1, lsl #3]
    0.00 :   ffff800010025b70:       blr     x1
         : 42               get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff800010025b74:       mrs     x1, sp_el0
         : 26               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff800010025b78:       ldr     x2, [x1]
    0.00 :   ffff800010025b7c:       and     x1, x0, #0xffffffff
    0.00 :   ffff800010025b80:       tst     w2, #0x400000
    0.00 :   ffff800010025b84:       csel    x0, x1, x0, ne  // ne = any
         : 116              invoke_syscall():
         : 60               }
         :
         : 62               if (is_compat_task())
         : 63               ret = lower_32_bits(ret);
         :
         : 65               regs->regs[0] = ret;
    0.00 :   ffff800010025b88:       str     x0, [x19]
         : 67               arch_static_branch():
    0.00 :   ffff800010025b8c:       nop
         : 22               invoke_syscall():
         : 74               * 16-byte (i.e. 4-bit) aligned SP at function boundaries.
         : 75               *
         : 76               * The resulting 5 bits of entropy is seen in SP[8:4].
         : 77               */
         : 78               choose_random_kstack_offset(get_random_int() & 0x1FF);
         : 79               }
    0.00 :   ffff800010025b90:       mov     sp, x29
    0.00 :   ffff800010025b94:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010025b98:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010025b9c:       autiasp
    0.00 :   ffff800010025ba0:       ret
         : 85               __kern_my_cpu_offset():
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
         : 45               "mrs %0, tpidr_el2",
         : 46               ARM64_HAS_VIRT_HOST_EXTN)
         : 47               : "=r" (off) :
         : 48               "Q" (*(const unsigned long *)current_stack_pointer));
    0.00 :   ffff800010025ba4:       mov     x4, sp
         : 50               invoke_syscall():
         : 47               add_random_kstack_offset();
    0.00 :   ffff800010025ba8:       adrp    x0, ffff80001176d000 <cpu_number>
         : 49               __kern_my_cpu_offset():
         : 39               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff800010025bac:       mrs     x5, tpidr_el1
         : 41               invoke_syscall():
    0.00 :   ffff800010025bb0:       add     x0, x0, #0x40
    0.00 :   ffff800010025bb4:       ldr     w0, [x0, x5]
    0.00 :   ffff800010025bb8:       and     x0, x0, #0x3ff
    0.00 :   ffff800010025bbc:       add     x0, x0, #0xf
    0.00 :   ffff800010025bc0:       and     x0, x0, #0x7f0
    0.00 :   ffff800010025bc4:       sub     sp, x4, x0
    0.00 :   ffff800010025bc8:       mov     x0, sp
         : 49               if (scno < sc_nr) {
    0.00 :   ffff800010025bcc:       cmp     w1, w2
    0.00 :   ffff800010025bd0:       b.cc    ffff800010025b50 <invoke_syscall+0x20>  // b.lo, b.ul, b.last
         : 52               get_current():
    0.00 :   ffff800010025bd4:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff800010025bd8:       ldr     x0, [x0]
         : 107              do_ni_syscall():
         : 26               if (is_compat_task()) {
    0.00 :   ffff800010025bdc:       tst     w0, #0x400000
    0.00 :   ffff800010025be0:       b.eq    ffff800010025bf4 <invoke_syscall+0xc4>  // b.none
         : 27               ret = compat_arm_syscall(regs, scno);
    0.00 :   ffff800010025be4:       mov     x0, x19
    0.00 :   ffff800010025be8:       bl      ffff800010029168 <compat_arm_syscall>
         : 28               if (ret != -ENOSYS)
    0.00 :   ffff800010025bec:       cmn     x0, #0x26
    0.00 :   ffff800010025bf0:       b.ne    ffff800010025b74 <invoke_syscall+0x44>  // b.any
         : 33               return sys_ni_syscall();
    0.00 :   ffff800010025bf4:       bl      ffff8000100a98c8 <sys_ni_syscall>
    0.00 :   ffff800010025bf8:       b       ffff800010025b74 <invoke_syscall+0x44>
         : 36               __kern_my_cpu_offset():
    0.00 :   ffff800010025bfc:       mrs     x0, tpidr_el1
         : 40               invoke_syscall():
         : 73               choose_random_kstack_offset(get_random_int() & 0x1FF);
    0.00 :   ffff800010025c00:       adrp    x19, ffff80001176d000 <cpu_number>
    0.00 :   ffff800010025c04:       add     x19, x19, #0x40
    0.00 :   ffff800010025c08:       ldr     w20, [x19, x0]
         : 77               get_random_int():
         :
         : 57               u32 get_random_u32(void);
         : 58               u64 get_random_u64(void);
         : 59               static inline unsigned int get_random_int(void)
         : 60               {
         : 61               return get_random_u32();
    0.00 :   ffff800010025c0c:       bl      ffff800010767930 <get_random_u32>
         : 63               invoke_syscall():
    0.00 :   ffff800010025c10:       and     w0, w0, #0x1ff
         : 74               __kern_my_cpu_offset():
    0.00 :   ffff800010025c14:       mrs     x1, tpidr_el1
         : 40               invoke_syscall():
    0.00 :   ffff800010025c18:       eor     w0, w0, w20
    0.00 :   ffff800010025c1c:       str     w0, [x19, x1]
         : 74               }
    0.00 :   ffff800010025c20:       mov     sp, x29
    0.00 :   ffff800010025c24:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010025c28:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010025c2c:       autiasp
    0.00 :   ffff800010025c30:       ret
 Percent |	Source code & Disassembly of libc-2.31.so for cycles (1 samples, percent: local period)
-------------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3     Disassembly of section .text:
         :
         : 5     00000000000cdf00 <ioctl@@GLIBC_2.17>:
    0.00 :   cdf00:  mov     x8, #0x1d                       // #29
    0.00 :   cdf04:  sxtw    x0, w0
    0.00 :   cdf08:  svc     #0x0
  100.00 :   cdf0c:  cmn     x0, #0xfff
    0.00 :   cdf10:  b.cs    cdf18 <ioctl@@GLIBC_2.17+0x18>  // b.hs, b.nlast
    0.00 :   cdf14:  ret
    0.00 :   cdf18:  b       24310 <__libc_start_main@@GLIBC_2.17+0x1e0>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff800010417bd0 <security_perf_event_write>:
         : 6                security_perf_event_write():
         : 2623             {
         : 2624             return call_int_hook(perf_event_read, 0, event);
         : 2625             }
         :
         : 2627             int security_perf_event_write(struct perf_event *event)
         : 2628             {
  100.00 :   ffff800010417bd0:       paciasp
    0.00 :   ffff800010417bd4:       stp     x29, x30, [sp, #-32]!
         : 2624             return call_int_hook(perf_event_write, 0, event);
    0.00 :   ffff800010417bd8:       adrp    x1, ffff800011572000 <kmalloc_caches+0x78>
         : 2623             {
    0.00 :   ffff800010417bdc:       mov     x29, sp
    0.00 :   ffff800010417be0:       stp     x19, x20, [sp, #16]
         : 2624             return call_int_hook(perf_event_write, 0, event);
    0.00 :   ffff800010417be4:       ldr     x19, [x1, #2432]
    0.00 :   ffff800010417be8:       cbz     x19, ffff800010417c08 <security_perf_event_write+0x38>
    0.00 :   ffff800010417bec:       mov     x20, x0
    0.00 :   ffff800010417bf0:       ldr     x1, [x19, #24]
    0.00 :   ffff800010417bf4:       mov     x0, x20
    0.00 :   ffff800010417bf8:       blr     x1
    0.00 :   ffff800010417bfc:       cbnz    w0, ffff800010417c0c <security_perf_event_write+0x3c>
    0.00 :   ffff800010417c00:       ldr     x19, [x19]
    0.00 :   ffff800010417c04:       cbnz    x19, ffff800010417bf0 <security_perf_event_write+0x20>
         : 2623             {
    0.00 :   ffff800010417c08:       mov     w0, #0x0                        // #0
         : 2625             }
    0.00 :   ffff800010417c0c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff800010417c10:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010417c14:       autiasp
    0.00 :   ffff800010417c18:       ret
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001024b648 <__arm64_sys_ioctl>:
         : 6                __arm64_sys_ioctl():
         : 1055             }
         :
         : 1057             return -ENOIOCTLCMD;
         : 1058             }
         :
         : 1060             SYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg)
    0.00 :   ffff80001024b648:       paciasp
    0.00 :   ffff80001024b64c:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff80001024b650:       mov     x1, x0
    0.00 :   ffff80001024b654:       mov     x29, sp
    0.00 :   ffff80001024b658:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001024b65c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001024b660:       str     x23, [sp, #48]
         : 1068             __se_sys_ioctl():
    0.00 :   ffff80001024b664:       ldp     x23, x19, [x0]
         : 1056             __arm64_sys_ioctl():
    0.00 :   ffff80001024b668:       ldr     x22, [x1, #16]
         : 1056             fdget():
         : 65               return (struct fd){(struct file *)(v & ~3),v & 3};
         : 66               }
         :
         : 68               static inline struct fd fdget(unsigned int fd)
         : 69               {
         : 70               return __to_fd(__fdget(fd));
    0.00 :   ffff80001024b66c:       mov     w0, w23
    0.00 :   ffff80001024b670:       bl      ffff800010259908 <__fdget>
         : 73               __do_sys_ioctl():
         : 1060             {
         : 1061             struct fd f = fdget(fd);
         : 1062             int error;
         :
         : 1064             if (!f.file)
    0.00 :   ffff80001024b674:       ands    x21, x0, #0xfffffffffffffffc
    0.00 :   ffff80001024b678:       b.eq    ffff80001024b724 <__arm64_sys_ioctl+0xdc>  // b.none
         : 1063             return -EBADF;
         :
         : 1065             error = security_file_ioctl(f.file, cmd, arg);
    0.00 :   ffff80001024b67c:       mov     x20, x0
    0.00 :   ffff80001024b680:       mov     x2, x22
    0.00 :   ffff80001024b684:       mov     w1, w19
    0.00 :   ffff80001024b688:       mov     x0, x21
    0.00 :   ffff80001024b68c:       bl      ffff800010413538 <security_file_ioctl>
         : 1064             if (error)
    0.00 :   ffff80001024b690:       cbz     w0, ffff80001024b6b8 <__arm64_sys_ioctl+0x70>
         : 1066             fdput():
         : 45               if (fd.flags & FDPUT_FPUT)
    0.00 :   ffff80001024b694:       sxtw    x19, w0
    0.00 :   ffff80001024b698:       tbnz    w20, #0, ffff80001024b700 <__arm64_sys_ioctl+0xb8>
         : 48               __arm64_sys_ioctl():
         : 1055             SYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg)
    0.00 :   ffff80001024b69c:       mov     x0, x19
    0.00 :   ffff80001024b6a0:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001024b6a4:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001024b6a8:       ldr     x23, [sp, #48]
    0.00 :   ffff80001024b6ac:       ldp     x29, x30, [sp], #64
    0.00 :   ffff80001024b6b0:       autiasp
    0.00 :   ffff80001024b6b4:       ret
         : 1063             __do_sys_ioctl():
         : 1067             goto out;
         :
         : 1069             error = do_vfs_ioctl(f.file, fd, cmd, arg);
    0.00 :   ffff80001024b6b8:       mov     w1, w23
    0.00 :   ffff80001024b6bc:       mov     x3, x22
    0.00 :   ffff80001024b6c0:       mov     w2, w19
    0.00 :   ffff80001024b6c4:       mov     x0, x21
    0.00 :   ffff80001024b6c8:       bl      ffff80001024a958 <do_vfs_ioctl>
         : 1068             if (error == -ENOIOCTLCMD)
    0.00 :   ffff80001024b6cc:       cmn     w0, #0x203
    0.00 :   ffff80001024b6d0:       b.ne    ffff80001024b694 <__arm64_sys_ioctl+0x4c>  // b.any
         : 1071             vfs_ioctl():
         : 48               if (!filp->f_op->unlocked_ioctl)
    0.00 :   ffff80001024b6d4:       ldr     x0, [x21, #40]
    0.00 :   ffff80001024b6d8:       ldr     x3, [x0, #80]
    0.00 :   ffff80001024b6dc:       cbz     x3, ffff80001024b6f8 <__arm64_sys_ioctl+0xb0>
         : 51               error = filp->f_op->unlocked_ioctl(filp, cmd, arg);
  100.00 :   ffff80001024b6e0:       mov     x2, x22
    0.00 :   ffff80001024b6e4:       mov     w1, w19
    0.00 :   ffff80001024b6e8:       mov     x0, x21
    0.00 :   ffff80001024b6ec:       blr     x3
         : 52               if (error == -ENOIOCTLCMD)
    0.00 :   ffff80001024b6f0:       cmn     w0, #0x203
    0.00 :   ffff80001024b6f4:       b.ne    ffff80001024b694 <__arm64_sys_ioctl+0x4c>  // b.any
         : 55               __arm64_sys_ioctl():
         : 1055             SYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg)
    0.00 :   ffff80001024b6f8:       mov     x19, #0xffffffffffffffe7        // #-25
         : 1057             fdput():
    0.00 :   ffff80001024b6fc:       tbz     w20, #0, ffff80001024b69c <__arm64_sys_ioctl+0x54>
         : 46               fput(fd.file);
    0.00 :   ffff80001024b700:       mov     x0, x21
    0.00 :   ffff80001024b704:       bl      ffff8000102355a8 <fput>
         : 49               __arm64_sys_ioctl():
    0.00 :   ffff80001024b708:       mov     x0, x19
    0.00 :   ffff80001024b70c:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001024b710:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001024b714:       ldr     x23, [sp, #48]
    0.00 :   ffff80001024b718:       ldp     x29, x30, [sp], #64
    0.00 :   ffff80001024b71c:       autiasp
    0.00 :   ffff80001024b720:       ret
         : 1062             __do_sys_ioctl():
         : 1061             return -EBADF;
    0.00 :   ffff80001024b724:       mov     x19, #0xfffffffffffffff7        // #-9
         : 1063             __arm64_sys_ioctl():
         : 1055             SYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg)
    0.00 :   ffff80001024b728:       b       ffff80001024b69c <__arm64_sys_ioctl+0x54>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001024a958 <do_vfs_ioctl>:
         : 6                do_vfs_ioctl():
         : 973              * When you add any new common ioctls to the switches above and below,
         : 974              * please ensure they have compatible arguments in compat mode.
         : 975              */
         : 976              static int do_vfs_ioctl(struct file *filp, unsigned int fd,
         : 977              unsigned int cmd, unsigned long arg)
         : 978              {
    0.00 :   ffff80001024a958:       paciasp
    0.00 :   ffff80001024a95c:       stp     x29, x30, [sp, #-160]!
    0.00 :   ffff80001024a960:       mov     x29, sp
    0.00 :   ffff80001024a964:       stp     x19, x20, [sp, #16]
    0.00 :   ffff80001024a968:       adrp    x19, ffff800011c29000 <page_wait_table+0x14c0>
    0.00 :   ffff80001024a96c:       add     x19, x19, #0x948
    0.00 :   ffff80001024a970:       ldr     x4, [x19]
    0.00 :   ffff80001024a974:       str     x4, [sp, #152]
    0.00 :   ffff80001024a978:       mov     x4, #0x0                        // #0
    0.00 :   ffff80001024a97c:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001024a980:       mov     w4, w1
    0.00 :   ffff80001024a984:       stp     x23, x24, [sp, #48]
         : 977              void __user *argp = (void __user *)arg;
         : 978              struct inode *inode = file_inode(filp);
         :
         : 980              switch (cmd) {
    0.00 :   ffff80001024a988:       mov     w1, #0x6602                     // #26114
    0.00 :   ffff80001024a98c:       movk    w1, #0x4008, lsl #16
         : 973              {
    0.00 :   ffff80001024a990:       mov     x21, x0
    0.00 :   ffff80001024a994:       mov     x22, x3
         : 977              switch (cmd) {
    0.00 :   ffff80001024a998:       cmp     w2, w1
         : 975              struct inode *inode = file_inode(filp);
    0.00 :   ffff80001024a99c:       ldr     x23, [x0, #32]
         : 977              switch (cmd) {
    0.00 :   ffff80001024a9a0:       b.eq    ffff80001024af50 <do_vfs_ioctl+0x5f8>  // b.none
    0.00 :   ffff80001024a9a4:       mov     w5, w2
    0.00 :   ffff80001024a9a8:       b.hi    ffff80001024aaa8 <do_vfs_ioctl+0x150>  // b.pmore
    0.00 :   ffff80001024a9ac:       mov     w1, #0x5450                     // #21584
    0.00 :   ffff80001024a9b0:       cmp     w2, w1
    0.00 :   ffff80001024a9b4:       b.eq    ffff80001024aff0 <do_vfs_ioctl+0x698>  // b.none
    0.00 :   ffff80001024a9b8:       b.ls    ffff80001024aa2c <do_vfs_ioctl+0xd4>  // b.plast
    0.00 :   ffff80001024a9bc:       mov     w1, #0x5452                     // #21586
    0.00 :   ffff80001024a9c0:       cmp     w2, w1
    0.00 :   ffff80001024a9c4:       b.eq    ffff80001024b004 <do_vfs_ioctl+0x6ac>  // b.none
    0.00 :   ffff80001024a9c8:       b.cc    ffff80001024b098 <do_vfs_ioctl+0x740>  // b.lo, b.ul, b.last
    0.00 :   ffff80001024a9cc:       mov     w1, #0x5460                     // #21600
    0.00 :   ffff80001024a9d0:       cmp     w2, w1
    0.00 :   ffff80001024a9d4:       b.eq    ffff80001024b1c0 <do_vfs_ioctl+0x868>  // b.none
    0.00 :   ffff80001024a9d8:       mov     w1, #0x9409                     // #37897
    0.00 :   ffff80001024a9dc:       movk    w1, #0x4004, lsl #16
    0.00 :   ffff80001024a9e0:       cmp     w2, w1
    0.00 :   ffff80001024a9e4:       b.ne    ffff80001024aa4c <do_vfs_ioctl+0xf4>  // b.any
         : 1019             return -EINVAL;
         :
         : 1021             return put_user(inode->i_sb->s_blocksize, (int __user *)argp);
         :
         : 1023             case FICLONE:
         : 1024             return ioctl_file_clone(filp, arg, 0, 0, 0);
    0.00 :   ffff80001024a9e8:       mov     x1, x3
    0.00 :   ffff80001024a9ec:       mov     x4, #0x0                        // #0
    0.00 :   ffff80001024a9f0:       mov     x3, #0x0                        // #0
    0.00 :   ffff80001024a9f4:       mov     x2, #0x0                        // #0
    0.00 :   ffff80001024a9f8:       bl      ffff800010249f30 <ioctl_file_clone>
    0.00 :   ffff80001024a9fc:       mov     w20, w0
         : 1053             return file_ioctl(filp, cmd, argp);
         : 1054             break;
         : 1055             }
         :
         : 1057             return -ENOIOCTLCMD;
         : 1058             }
    0.00 :   ffff80001024aa00:       mov     w0, w20
    0.00 :   ffff80001024aa04:       ldr     x2, [sp, #152]
    0.00 :   ffff80001024aa08:       ldr     x1, [x19]
    0.00 :   ffff80001024aa0c:       eor     x1, x2, x1
    0.00 :   ffff80001024aa10:       cbnz    x1, ffff80001024b630 <do_vfs_ioctl+0xcd8>
    0.00 :   ffff80001024aa14:       ldp     x19, x20, [sp, #16]
    0.00 :   ffff80001024aa18:       ldp     x21, x22, [sp, #32]
    0.00 :   ffff80001024aa1c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001024aa20:       ldp     x29, x30, [sp], #160
    0.00 :   ffff80001024aa24:       autiasp
    0.00 :   ffff80001024aa28:       ret
         : 977              switch (cmd) {
    0.00 :   ffff80001024aa2c:       mov     w1, #0x541b                     // #21531
    0.00 :   ffff80001024aa30:       cmp     w2, w1
    0.00 :   ffff80001024aa34:       b.eq    ffff80001024ae2c <do_vfs_ioctl+0x4d4>  // b.none
    0.00 :   ffff80001024aa38:       mov     w0, #0x5421                     // #21537
    0.00 :   ffff80001024aa3c:       cmp     w2, w0
    0.00 :   ffff80001024aa40:       b.eq    ffff80001024ae68 <do_vfs_ioctl+0x510>  // b.none
    0.00 :   ffff80001024aa44:       cmp     w2, #0x2
    0.00 :   ffff80001024aa48:       b.eq    ffff80001024aee8 <do_vfs_ioctl+0x590>  // b.none
         : 1047             if (S_ISREG(inode->i_mode))
    0.00 :   ffff80001024aa4c:       ldrh    w0, [x23]
    0.00 :   ffff80001024aa50:       and     w0, w0, #0xf000
    0.00 :   ffff80001024aa54:       cmp     w0, #0x8, lsl #12
    0.00 :   ffff80001024aa58:       b.ne    ffff80001024b3b8 <do_vfs_ioctl+0xa60>  // b.any
         : 1052             file_ioctl():
         : 532              switch (cmd) {
    0.00 :   ffff80001024aa5c:       mov     w0, #0x5829                     // #22569
    0.00 :   ffff80001024aa60:       movk    w0, #0x4030, lsl #16
    0.00 :   ffff80001024aa64:       cmp     w5, w0
    0.00 :   ffff80001024aa68:       b.eq    ffff80001024b5ac <do_vfs_ioctl+0xc54>  // b.none
    0.00 :   ffff80001024aa6c:       b.ls    ffff80001024b3c8 <do_vfs_ioctl+0xa70>  // b.plast
    0.00 :   ffff80001024aa70:       mov     w0, #0x582b                     // #22571
    0.00 :   ffff80001024aa74:       movk    w0, #0x4030, lsl #16
    0.00 :   ffff80001024aa78:       cmp     w5, w0
    0.00 :   ffff80001024aa7c:       b.eq    ffff80001024b5ac <do_vfs_ioctl+0xc54>  // b.none
    0.00 :   ffff80001024aa80:       b.cc    ffff80001024b4f8 <do_vfs_ioctl+0xba0>  // b.lo, b.ul, b.last
    0.00 :   ffff80001024aa84:       add     w0, w0, #0xe
    0.00 :   ffff80001024aa88:       cmp     w5, w0
    0.00 :   ffff80001024aa8c:       b.ne    ffff80001024b3b8 <do_vfs_ioctl+0xa60>  // b.any
         : 542              return ioctl_preallocate(filp, FALLOC_FL_ZERO_RANGE, p);
    0.00 :   ffff80001024aa90:       mov     x2, x22
    0.00 :   ffff80001024aa94:       mov     x0, x21
    0.00 :   ffff80001024aa98:       mov     w1, #0x10                       // #16
    0.00 :   ffff80001024aa9c:       bl      ffff80001024a3f8 <ioctl_preallocate>
    0.00 :   ffff80001024aaa0:       mov     w20, w0
    0.00 :   ffff80001024aaa4:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 549              do_vfs_ioctl():
         : 977              switch (cmd) {
    0.00 :   ffff80001024aaa8:       mov     w0, #0x581f                     // #22559
    0.00 :   ffff80001024aaac:       movk    w0, #0x801c, lsl #16
    0.00 :   ffff80001024aab0:       cmp     w2, w0
    0.00 :   ffff80001024aab4:       b.eq    ffff80001024b174 <do_vfs_ioctl+0x81c>  // b.none
    0.00 :   ffff80001024aab8:       b.ls    ffff80001024abf0 <do_vfs_ioctl+0x298>  // b.plast
    0.00 :   ffff80001024aabc:       mov     w0, #0x5878                     // #22648
    0.00 :   ffff80001024aac0:       movk    w0, #0xc004, lsl #16
    0.00 :   ffff80001024aac4:       cmp     w2, w0
    0.00 :   ffff80001024aac8:       b.eq    ffff80001024b0ac <do_vfs_ioctl+0x754>  // b.none
    0.00 :   ffff80001024aacc:       b.ls    ffff80001024acd0 <do_vfs_ioctl+0x378>  // b.plast
    0.00 :   ffff80001024aad0:       mov     w0, #0x9436                     // #37942
    0.00 :   ffff80001024aad4:       movk    w0, #0xc018, lsl #16
    0.00 :   ffff80001024aad8:       cmp     w2, w0
    0.00 :   ffff80001024aadc:       b.eq    ffff80001024b0e0 <do_vfs_ioctl+0x788>  // b.none
    0.00 :   ffff80001024aae0:       mov     w0, #0x660b                     // #26123
    0.00 :   ffff80001024aae4:       movk    w0, #0xc020, lsl #16
    0.00 :   ffff80001024aae8:       cmp     w2, w0
    0.00 :   ffff80001024aaec:       b.ne    ffff80001024aa4c <do_vfs_ioctl+0xf4>  // b.any
         : 996              ioctl_fiemap():
         : 202              struct fiemap_extent_info fieinfo = { 0, };
    0.00 :   ffff80001024aaf0:       stp     xzr, xzr, [sp, #88]
    0.00 :   ffff80001024aaf4:       str     xzr, [sp, #104]
         : 206              if (!inode->i_op->fiemap)
    0.00 :   ffff80001024aaf8:       ldr     x0, [x23, #32]
    0.00 :   ffff80001024aafc:       ldr     x0, [x0, #128]
    0.00 :   ffff80001024ab00:       cbz     x0, ffff80001024b3a4 <do_vfs_ioctl+0xa4c>
         : 210              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001024ab04:       mrs     x0, sp_el0
         : 26               __range_ok():
         : 47               * Asynchronous I/O running in a kernel thread does not have the
         : 48               * TIF_TAGGED_ADDR flag of the process owning the mm, so always untag
         : 49               * the user address before checking.
         : 50               */
         : 51               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
         : 52               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024ab08:       ldr     w0, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024ab0c:       tbz     w0, #21, ffff80001024b2c8 <do_vfs_ioctl+0x970>
         : 48               sign_extend64():
         : 182              * @index: 0 based bit index (0<=index<64) to sign bit
         : 183              */
         : 184              static __always_inline __s64 sign_extend64(__u64 value, int index)
         : 185              {
         : 186              __u8 shift = 63 - index;
         : 187              return (__s64)(value << shift) >> shift;
    0.00 :   ffff80001024ab10:       sbfx    x0, x22, #0, #56
         : 189              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024ab14:       and     x0, x0, x22
         :
         : 52               __chk_user_ptr(addr);
         : 53               asm volatile(
    0.00 :   ffff80001024ab18:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024ab1c:       mov     x1, x2
    0.00 :   ffff80001024ab20:       adds    x0, x0, #0x20
    0.00 :   ffff80001024ab24:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024ab28:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024ab2c:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024ab30:       cset    x0, ls  // ls = plast
         : 61               _copy_from_user():
         : 157              static inline __must_check unsigned long
         : 158              _copy_from_user(void *to, const void __user *from, unsigned long n)
         : 159              {
         : 160              unsigned long res = n;
         : 161              might_fault();
         : 162              if (!should_fail_usercopy() && likely(access_ok(from, n))) {
    0.00 :   ffff80001024ab34:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 164              sign_extend64():
    0.00 :   ffff80001024ab38:       sbfx    x21, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              asm volatile(
         : 245              "       bics    xzr, %3, %2\n"
         : 246              "       csel    %0, %1, xzr, eq\n"
         : 247              : "=&r" (safe_ptr)
         : 248              : "r" (ptr), "r" (TASK_SIZE_MAX - 1),
         : 249              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024ab3c:       and     x21, x21, x22
         : 239              asm volatile(
    0.00 :   ffff80001024ab40:       bics    xzr, x21, x2
    0.00 :   ffff80001024ab44:       csel    x1, x22, xzr, eq  // eq = none
         : 247              : "cc");
         :
         : 249              csdb();
    0.00 :   ffff80001024ab48:       csdb
         : 251              _copy_from_user():
         : 159              instrument_copy_from_user(to, from, n);
         : 160              res = raw_copy_from_user(to, from, n);
    0.00 :   ffff80001024ab4c:       mov     x2, #0x20                       // #32
    0.00 :   ffff80001024ab50:       add     x0, sp, #0x78
    0.00 :   ffff80001024ab54:       bl      ffff8000104a4e40 <__arch_copy_from_user>
         : 161              }
         : 162              if (unlikely(res))
    0.00 :   ffff80001024ab58:       cbnz    x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 164              ioctl_fiemap():
         : 212              if (fiemap.fm_extent_count > FIEMAP_MAX_EXTENTS)
    0.00 :   ffff80001024ab5c:       ldr     w1, [sp, #144]
    0.00 :   ffff80001024ab60:       mov     w0, #0x4924                     // #18724
    0.00 :   ffff80001024ab64:       movk    w0, #0x492, lsl #16
    0.00 :   ffff80001024ab68:       cmp     w1, w0
    0.00 :   ffff80001024ab6c:       b.hi    ffff80001024b5cc <do_vfs_ioctl+0xc74>  // b.pmore
         : 215              fieinfo.fi_flags = fiemap.fm_flags;
    0.00 :   ffff80001024ab70:       ldr     w0, [sp, #136]
         : 217              fieinfo.fi_extents_start = ufiemap->fm_extents;
    0.00 :   ffff80001024ab74:       add     x2, x22, #0x20
         : 215              fieinfo.fi_flags = fiemap.fm_flags;
    0.00 :   ffff80001024ab78:       str     w0, [sp, #88]
         : 219              error = inode->i_op->fiemap(inode, &fieinfo, fiemap.fm_start,
    0.00 :   ffff80001024ab7c:       mov     x0, x23
         : 216              fieinfo.fi_extents_max = fiemap.fm_extent_count;
    0.00 :   ffff80001024ab80:       str     w1, [sp, #96]
         : 219              error = inode->i_op->fiemap(inode, &fieinfo, fiemap.fm_start,
    0.00 :   ffff80001024ab84:       add     x1, sp, #0x58
         : 217              fieinfo.fi_extents_start = ufiemap->fm_extents;
    0.00 :   ffff80001024ab88:       str     x2, [sp, #104]
         : 219              error = inode->i_op->fiemap(inode, &fieinfo, fiemap.fm_start,
    0.00 :   ffff80001024ab8c:       ldr     x2, [sp, #120]
    0.00 :   ffff80001024ab90:       ldr     x4, [x23, #32]
    0.00 :   ffff80001024ab94:       ldr     x3, [sp, #128]
    0.00 :   ffff80001024ab98:       ldr     x4, [x4, #128]
    0.00 :   ffff80001024ab9c:       blr     x4
    0.00 :   ffff80001024aba0:       mov     w20, w0
         : 222              fiemap.fm_flags = fieinfo.fi_flags;
    0.00 :   ffff80001024aba4:       ldr     x0, [sp, #88]
    0.00 :   ffff80001024aba8:       str     x0, [sp, #136]
         : 225              get_current():
    0.00 :   ffff80001024abac:       mrs     x1, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024abb0:       ldr     w2, [x1, #36]
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024abb4:       mov     x0, x21
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024abb8:       tbnz    w2, #21, ffff80001024abc8 <do_vfs_ioctl+0x270>
         : 48               test_bit():
         : 106              * @nr: bit number to test
         : 107              * @addr: Address to start counting from
         : 108              */
         : 109              static inline int test_bit(int nr, const volatile unsigned long *addr)
         : 110              {
         : 111              return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
    0.00 :   ffff80001024abbc:       ldr     x0, [x1]
         : 113              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024abc0:       tst     w0, #0x4000000
    0.00 :   ffff80001024abc4:       csel    x0, x21, x22, ne  // ne = any
         : 51               asm volatile(
    0.00 :   ffff80001024abc8:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024abcc:       mov     x1, x2
    0.00 :   ffff80001024abd0:       adds    x0, x0, #0x20
    0.00 :   ffff80001024abd4:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024abd8:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024abdc:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024abe0:       cset    x0, ls  // ls = plast
         : 59               _copy_to_user():
         : 177              _copy_to_user(void __user *to, const void *from, unsigned long n)
         : 178              {
         : 179              might_fault();
         : 180              if (should_fail_usercopy())
         : 181              return n;
         : 182              if (access_ok(to, n)) {
    0.00 :   ffff80001024abe4:       cbnz    x0, ffff80001024b378 <do_vfs_ioctl+0xa20>
         : 184              ioctl_fionbio():
         : 553              error = get_user(on, argp);
    0.00 :   ffff80001024abe8:       mov     w20, #0xfffffff2                // #-14
    0.00 :   ffff80001024abec:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 556              do_vfs_ioctl():
         : 977              switch (cmd) {
    0.00 :   ffff80001024abf0:       mov     w0, #0x940d                     // #37901
    0.00 :   ffff80001024abf4:       movk    w0, #0x4020, lsl #16
    0.00 :   ffff80001024abf8:       cmp     w2, w0
    0.00 :   ffff80001024abfc:       b.eq    ffff80001024ad1c <do_vfs_ioctl+0x3c4>  // b.none
    0.00 :   ffff80001024ac00:       mov     w0, #0x6601                     // #26113
    0.00 :   ffff80001024ac04:       movk    w0, #0x8008, lsl #16
    0.00 :   ffff80001024ac08:       cmp     w2, w0
    0.00 :   ffff80001024ac0c:       b.eq    ffff80001024ad8c <do_vfs_ioctl+0x434>  // b.none
    0.00 :   ffff80001024ac10:       mov     w0, #0x5820                     // #22560
    0.00 :   ffff80001024ac14:       movk    w0, #0x401c, lsl #16
    0.00 :   ffff80001024ac18:       cmp     w2, w0
    0.00 :   ffff80001024ac1c:       b.ne    ffff80001024aa4c <do_vfs_ioctl+0xf4>  // b.any
         : 990              mnt_user_ns():
         : 81               } __randomize_layout;
         :
         : 83               static inline struct user_namespace *mnt_user_ns(const struct vfsmount *mnt)
         : 84               {
         : 85               /* Pairs with smp_store_release() in do_idmap_mount(). */
         : 86               return smp_load_acquire(&mnt->mnt_userns);
    0.00 :   ffff80001024ac20:       ldr     x0, [x21, #16]
    0.00 :   ffff80001024ac24:       add     x0, x0, #0x18
    0.00 :   ffff80001024ac28:       ldar    x24, [x0]
         : 90               get_current():
    0.00 :   ffff80001024ac2c:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024ac30:       ldr     w1, [x0, #36]
         : 49               ioctl_fssetxattr():
         : 949              struct dentry *dentry = file->f_path.dentry;
    0.00 :   ffff80001024ac34:       ldr     x23, [x21, #24]
         : 951              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024ac38:       tbz     w1, #21, ffff80001024b278 <do_vfs_ioctl+0x920>
         : 48               sign_extend64():
    0.00 :   ffff80001024ac3c:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024ac40:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024ac44:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024ac48:       mov     x1, x2
    0.00 :   ffff80001024ac4c:       adds    x0, x0, #0x1c
    0.00 :   ffff80001024ac50:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024ac54:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024ac58:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024ac5c:       cset    x0, ls  // ls = plast
         : 59               _copy_from_user():
         : 157              if (!should_fail_usercopy() && likely(access_ok(from, n))) {
    0.00 :   ffff80001024ac60:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 159              sign_extend64():
    0.00 :   ffff80001024ac64:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024ac68:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024ac6c:       bics    xzr, x0, x2
    0.00 :   ffff80001024ac70:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024ac74:       csdb
         : 249              _copy_from_user():
         : 159              res = raw_copy_from_user(to, from, n);
    0.00 :   ffff80001024ac78:       mov     x2, #0x1c                       // #28
    0.00 :   ffff80001024ac7c:       add     x0, sp, #0x78
    0.00 :   ffff80001024ac80:       bl      ffff8000104a4e40 <__arch_copy_from_user>
         : 161              if (unlikely(res))
    0.00 :   ffff80001024ac84:       cbnz    x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 163              copy_fsxattr_from_user():
         : 776              fileattr_fill_xflags(fa, xfa.fsx_xflags);
    0.00 :   ffff80001024ac88:       ldr     w1, [sp, #120]
    0.00 :   ffff80001024ac8c:       add     x0, sp, #0x58
    0.00 :   ffff80001024ac90:       bl      ffff800010249e00 <fileattr_fill_xflags>
         : 777              fa->fsx_extsize = xfa.fsx_extsize;
    0.00 :   ffff80001024ac94:       ldur    x2, [sp, #124]
         : 779              ioctl_fssetxattr():
         : 955              err = mnt_want_write_file(file);
    0.00 :   ffff80001024ac98:       mov     x0, x21
         : 957              copy_fsxattr_from_user():
         : 779              fa->fsx_projid = xfa.fsx_projid;
    0.00 :   ffff80001024ac9c:       ldur    x1, [sp, #132]
    0.00 :   ffff80001024aca0:       stp     x2, x1, [sp, #96]
         : 782              ioctl_fssetxattr():
         : 955              err = mnt_want_write_file(file);
    0.00 :   ffff80001024aca4:       bl      ffff80001025e518 <mnt_want_write_file>
    0.00 :   ffff80001024aca8:       mov     w20, w0
         : 956              if (!err) {
    0.00 :   ffff80001024acac:       cbnz    w0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 957              err = vfs_fileattr_set(mnt_userns, dentry, &fa);
    0.00 :   ffff80001024acb0:       add     x2, sp, #0x58
    0.00 :   ffff80001024acb4:       mov     x1, x23
    0.00 :   ffff80001024acb8:       mov     x0, x24
    0.00 :   ffff80001024acbc:       bl      ffff80001024a0b0 <vfs_fileattr_set>
    0.00 :   ffff80001024acc0:       mov     w20, w0
         : 958              mnt_drop_write_file(file);
    0.00 :   ffff80001024acc4:       mov     x0, x21
    0.00 :   ffff80001024acc8:       bl      ffff80001025e8c8 <mnt_drop_write_file>
         : 961              do_vfs_ioctl():
         : 1044             return ioctl_fssetxattr(filp, argp);
    0.00 :   ffff80001024accc:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 977              switch (cmd) {
    0.00 :   ffff80001024acd0:       mov     w0, #0x5877                     // #22647
    0.00 :   ffff80001024acd4:       movk    w0, #0xc004, lsl #16
    0.00 :   ffff80001024acd8:       cmp     w2, w0
    0.00 :   ffff80001024acdc:       b.ne    ffff80001024aa4c <do_vfs_ioctl+0xf4>  // b.any
         : 982              ioctl_fsfreeze():
         : 595              struct super_block *sb = file_inode(filp)->i_sb;
    0.00 :   ffff80001024ace0:       ldr     x20, [x23, #40]
         : 597              if (!ns_capable(sb->s_user_ns, CAP_SYS_ADMIN))
    0.00 :   ffff80001024ace4:       mov     w1, #0x15                       // #21
    0.00 :   ffff80001024ace8:       ldr     x0, [x20, #1144]
    0.00 :   ffff80001024acec:       bl      ffff80001008d5e0 <ns_capable>
    0.00 :   ffff80001024acf0:       tst     w0, #0xff
    0.00 :   ffff80001024acf4:       b.eq    ffff80001024b3c0 <do_vfs_ioctl+0xa68>  // b.none
         : 601              if (sb->s_op->freeze_fs == NULL && sb->s_op->freeze_super == NULL)
    0.00 :   ffff80001024acf8:       ldr     x0, [x20, #48]
    0.00 :   ffff80001024acfc:       ldr     x1, [x0, #80]
    0.00 :   ffff80001024ad00:       cbz     x1, ffff80001024b39c <do_vfs_ioctl+0xa44>
         : 605              if (sb->s_op->freeze_super)
    0.00 :   ffff80001024ad04:       ldr     x1, [x0, #72]
    0.00 :   ffff80001024ad08:       cbz     x1, ffff80001024b59c <do_vfs_ioctl+0xc44>
         : 606              return sb->s_op->freeze_super(sb);
    0.00 :   ffff80001024ad0c:       mov     x0, x20
    0.00 :   ffff80001024ad10:       blr     x1
    0.00 :   ffff80001024ad14:       mov     w20, w0
    0.00 :   ffff80001024ad18:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 611              get_current():
    0.00 :   ffff80001024ad1c:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024ad20:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024ad24:       tbz     w1, #21, ffff80001024b28c <do_vfs_ioctl+0x934>
         : 48               sign_extend64():
    0.00 :   ffff80001024ad28:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024ad2c:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024ad30:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024ad34:       mov     x1, x2
    0.00 :   ffff80001024ad38:       adds    x0, x0, #0x20
    0.00 :   ffff80001024ad3c:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024ad40:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024ad44:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024ad48:       cset    x0, ls  // ls = plast
         : 59               _copy_from_user():
         : 157              if (!should_fail_usercopy() && likely(access_ok(from, n))) {
    0.00 :   ffff80001024ad4c:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 159              sign_extend64():
    0.00 :   ffff80001024ad50:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024ad54:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024ad58:       bics    xzr, x0, x2
    0.00 :   ffff80001024ad5c:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024ad60:       csdb
         : 249              _copy_from_user():
         : 159              res = raw_copy_from_user(to, from, n);
    0.00 :   ffff80001024ad64:       mov     x2, #0x20                       // #32
    0.00 :   ffff80001024ad68:       add     x0, sp, #0x58
    0.00 :   ffff80001024ad6c:       bl      ffff8000104a4e40 <__arch_copy_from_user>
         : 161              if (unlikely(res))
    0.00 :   ffff80001024ad70:       cbnz    x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 163              ioctl_file_clone_range():
         : 262              return ioctl_file_clone(file, args.src_fd, args.src_offset,
    0.00 :   ffff80001024ad74:       ldp     x1, x2, [sp, #88]
    0.00 :   ffff80001024ad78:       mov     x0, x21
    0.00 :   ffff80001024ad7c:       ldp     x3, x4, [sp, #104]
    0.00 :   ffff80001024ad80:       bl      ffff800010249f30 <ioctl_file_clone>
    0.00 :   ffff80001024ad84:       mov     w20, w0
    0.00 :   ffff80001024ad88:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 269              do_vfs_ioctl():
         : 1035             return ioctl_getflags(filp, argp);
    0.00 :   ffff80001024ad8c:       ldr     x0, [x21, #24]
         : 1037             ioctl_getflags():
         : 905              struct fileattr fa = { .flags_valid = true }; /* hint only */
    0.00 :   ffff80001024ad90:       str     wzr, [sp, #112]
    0.00 :   ffff80001024ad94:       mov     w1, #0x1                        // #1
    0.00 :   ffff80001024ad98:       stp     xzr, xzr, [sp, #88]
    0.00 :   ffff80001024ad9c:       str     xzr, [sp, #104]
    0.00 :   ffff80001024ada0:       strb    w1, [sp, #112]
         : 911              vfs_fileattr_get():
         : 736              if (!inode->i_op->fileattr_get)
    0.00 :   ffff80001024ada4:       ldr     x1, [x0, #48]
    0.00 :   ffff80001024ada8:       ldr     x1, [x1, #32]
    0.00 :   ffff80001024adac:       ldr     x2, [x1, #176]
    0.00 :   ffff80001024adb0:       cbz     x2, ffff80001024b3b8 <do_vfs_ioctl+0xa60>
         : 739              return inode->i_op->fileattr_get(dentry, fa);
    0.00 :   ffff80001024adb4:       add     x1, sp, #0x58
    0.00 :   ffff80001024adb8:       blr     x2
    0.00 :   ffff80001024adbc:       mov     w20, w0
         : 743              ioctl_getflags():
         : 909              if (!err)
    0.00 :   ffff80001024adc0:       cbnz    w0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 911              get_current():
    0.00 :   ffff80001024adc4:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024adc8:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024adcc:       tbnz    w1, #21, ffff80001024ade0 <do_vfs_ioctl+0x488>
         : 48               test_bit():
    0.00 :   ffff80001024add0:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024add4:       mov     x0, x22
    0.00 :   ffff80001024add8:       tst     w1, #0x4000000
    0.00 :   ffff80001024addc:       b.eq    ffff80001024ade8 <do_vfs_ioctl+0x490>  // b.none
         : 49               sign_extend64():
    0.00 :   ffff80001024ade0:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024ade4:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024ade8:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024adec:       mov     x1, x2
    0.00 :   ffff80001024adf0:       adds    x0, x0, #0x4
    0.00 :   ffff80001024adf4:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024adf8:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024adfc:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024ae00:       cset    x0, ls  // ls = plast
         : 59               ioctl_getflags():
         : 910              err = put_user(fa.flags, argp);
    0.00 :   ffff80001024ae04:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 912              sign_extend64():
    0.00 :   ffff80001024ae08:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024ae0c:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024ae10:       bics    xzr, x0, x2
    0.00 :   ffff80001024ae14:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024ae18:       csdb
         : 249              ioctl_getflags():
    0.00 :   ffff80001024ae1c:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024ae20:       ldr     w0, [sp, #88]
    0.00 :   ffff80001024ae24:       sttr    w0, [x1]
         : 913              do_vfs_ioctl():
         : 142              return false;
    0.00 :   ffff80001024ae28:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 1028             if (!S_ISREG(inode->i_mode))
    0.00 :   ffff80001024ae2c:       ldrh    w1, [x23]
    0.00 :   ffff80001024ae30:       and     w1, w1, #0xf000
    0.00 :   ffff80001024ae34:       cmp     w1, #0x8, lsl #12
    0.00 :   ffff80001024ae38:       b.eq    ffff80001024b308 <do_vfs_ioctl+0x9b0>  // b.none
         : 1033             vfs_ioctl():
         : 48               if (!filp->f_op->unlocked_ioctl)
    0.00 :   ffff80001024ae3c:       ldr     x1, [x0, #40]
    0.00 :   ffff80001024ae40:       ldr     x3, [x1, #80]
    0.00 :   ffff80001024ae44:       cbz     x3, ffff80001024ae60 <do_vfs_ioctl+0x508>
         : 51               error = filp->f_op->unlocked_ioctl(filp, cmd, arg);
    0.00 :   ffff80001024ae48:       mov     x2, x22
    0.00 :   ffff80001024ae4c:       mov     w1, w5
    0.00 :   ffff80001024ae50:       blr     x3
         : 52               if (error == -ENOIOCTLCMD)
    0.00 :   ffff80001024ae54:       cmn     w0, #0x203
         : 51               error = filp->f_op->unlocked_ioctl(filp, cmd, arg);
    0.00 :   ffff80001024ae58:       mov     w20, w0
         : 52               if (error == -ENOIOCTLCMD)
    0.00 :   ffff80001024ae5c:       b.ne    ffff80001024aa00 <do_vfs_ioctl+0xa8>  // b.any
         : 53               error = -ENOTTY;
    0.00 :   ffff80001024ae60:       mov     w20, #0xffffffe7                // #-25
    0.00 :   ffff80001024ae64:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 56               get_current():
    0.00 :   ffff80001024ae68:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024ae6c:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024ae70:       tbz     w1, #21, ffff80001024b2a0 <do_vfs_ioctl+0x948>
         : 48               sign_extend64():
    0.00 :   ffff80001024ae74:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024ae78:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024ae7c:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024ae80:       mov     x1, x2
    0.00 :   ffff80001024ae84:       adds    x0, x0, #0x4
    0.00 :   ffff80001024ae88:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024ae8c:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024ae90:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024ae94:       cset    x0, ls  // ls = plast
         : 59               ioctl_fionbio():
         : 553              error = get_user(on, argp);
    0.00 :   ffff80001024ae98:       mov     w20, #0xfffffff2                // #-14
    0.00 :   ffff80001024ae9c:       cbz     x0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 556              sign_extend64():
    0.00 :   ffff80001024aea0:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024aea4:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024aea8:       bics    xzr, x0, x2
    0.00 :   ffff80001024aeac:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024aeb0:       csdb
         : 249              ioctl_fionbio():
    0.00 :   ffff80001024aeb4:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024aeb8:       ldtr    w22, [x1]
         : 554              if (error)
    0.00 :   ffff80001024aebc:       cbnz    w20, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 556              spin_lock():
         : 354              # define spin_lock_init(_lock)                  \
         : 355              do {                                            \
         : 356              spinlock_check(_lock);                  \
         : 357              *(_lock) = __SPIN_LOCK_UNLOCKED(_lock); \
         : 358              } while (0)
         :
    0.00 :   ffff80001024aec0:       add     x23, x21, #0x30
    0.00 :   ffff80001024aec4:       mov     x0, x23
    0.00 :   ffff80001024aec8:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 363              ioctl_fionbio():
         : 564              filp->f_flags |= flag;
    0.00 :   ffff80001024aecc:       ldr     w0, [x21, #64]
         : 563              if (on)
    0.00 :   ffff80001024aed0:       cbz     w22, ffff80001024b5c4 <do_vfs_ioctl+0xc6c>
         : 564              filp->f_flags |= flag;
    0.00 :   ffff80001024aed4:       orr     w0, w0, #0x800
    0.00 :   ffff80001024aed8:       str     w0, [x21, #64]
         : 567              spin_unlock():
         : 394              raw_spin_lock_irqsave(spinlock_check(lock), flags);     \
         : 395              } while (0)
         :
         : 397              #define spin_lock_irqsave_nested(lock, flags, subclass)                 \
         : 398              do {                                                                    \
         : 399              raw_spin_lock_irqsave_nested(spinlock_check(lock), flags, subclass); \
    0.00 :   ffff80001024aedc:       mov     x0, x23
    0.00 :   ffff80001024aee0:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 402              ioctl_fionbio():
         : 568              return error;
    0.00 :   ffff80001024aee4:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 570              do_vfs_ioctl():
         : 1013             if (!inode->i_sb->s_blocksize)
    0.00 :   ffff80001024aee8:       ldr     x0, [x23, #40]
    0.00 :   ffff80001024aeec:       ldr     x0, [x0, #24]
    0.00 :   ffff80001024aef0:       cbz     x0, ffff80001024b5cc <do_vfs_ioctl+0xc74>
         : 1017             get_current():
    0.00 :   ffff80001024aef4:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024aef8:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024aefc:       tbz     w1, #21, ffff80001024b2e0 <do_vfs_ioctl+0x988>
         : 48               sign_extend64():
    0.00 :   ffff80001024af00:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024af04:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024af08:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024af0c:       mov     x1, x2
    0.00 :   ffff80001024af10:       adds    x0, x0, #0x4
    0.00 :   ffff80001024af14:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024af18:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024af1c:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024af20:       cset    x0, ls  // ls = plast
         : 59               do_vfs_ioctl():
         : 1016             return put_user(inode->i_sb->s_blocksize, (int __user *)argp);
    0.00 :   ffff80001024af24:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 1018             sign_extend64():
    0.00 :   ffff80001024af28:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024af2c:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024af30:       bics    xzr, x0, x2
    0.00 :   ffff80001024af34:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024af38:       csdb
         : 249              do_vfs_ioctl():
    0.00 :   ffff80001024af3c:       ldr     x2, [x23, #40]
    0.00 :   ffff80001024af40:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024af44:       ldr     x0, [x2, #24]
    0.00 :   ffff80001024af48:       sttr    w0, [x1]
         : 142              return false;
    0.00 :   ffff80001024af4c:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 144              mnt_user_ns():
    0.00 :   ffff80001024af50:       ldr     x0, [x0, #16]
    0.00 :   ffff80001024af54:       add     x0, x0, #0x18
    0.00 :   ffff80001024af58:       ldar    x23, [x0]
         : 84               get_current():
    0.00 :   ffff80001024af5c:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024af60:       ldr     w1, [x0, #36]
         : 49               ioctl_setflags():
         : 917              struct dentry *dentry = file->f_path.dentry;
    0.00 :   ffff80001024af64:       ldr     x24, [x21, #24]
         : 919              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024af68:       tbz     w1, #21, ffff80001024b2b4 <do_vfs_ioctl+0x95c>
         : 48               sign_extend64():
    0.00 :   ffff80001024af6c:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024af70:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024af74:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024af78:       mov     x1, x2
    0.00 :   ffff80001024af7c:       adds    x0, x0, #0x4
    0.00 :   ffff80001024af80:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024af84:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024af88:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024af8c:       cset    x0, ls  // ls = plast
         : 59               ioctl_setflags():
         : 922              err = get_user(flags, argp);
    0.00 :   ffff80001024af90:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 924              sign_extend64():
    0.00 :   ffff80001024af94:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024af98:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024af9c:       bics    xzr, x0, x2
    0.00 :   ffff80001024afa0:       csel    x3, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024afa4:       csdb
         : 249              ioctl_setflags():
    0.00 :   ffff80001024afa8:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024afac:       ldtr    w22, [x3]
         : 923              if (!err) {
    0.00 :   ffff80001024afb0:       cbnz    w20, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 924              err = mnt_want_write_file(file);
    0.00 :   ffff80001024afb4:       mov     x0, x21
    0.00 :   ffff80001024afb8:       bl      ffff80001025e518 <mnt_want_write_file>
    0.00 :   ffff80001024afbc:       mov     w20, w0
         : 925              if (!err) {
    0.00 :   ffff80001024afc0:       cbnz    w0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 926              fileattr_fill_flags(&fa, flags);
    0.00 :   ffff80001024afc4:       mov     w1, w22
    0.00 :   ffff80001024afc8:       add     x0, sp, #0x58
    0.00 :   ffff80001024afcc:       bl      ffff800010249e98 <fileattr_fill_flags>
         : 927              err = vfs_fileattr_set(mnt_userns, dentry, &fa);
    0.00 :   ffff80001024afd0:       add     x2, sp, #0x58
    0.00 :   ffff80001024afd4:       mov     x1, x24
    0.00 :   ffff80001024afd8:       mov     x0, x23
    0.00 :   ffff80001024afdc:       bl      ffff80001024a0b0 <vfs_fileattr_set>
    0.00 :   ffff80001024afe0:       mov     w20, w0
         : 928              mnt_drop_write_file(file);
    0.00 :   ffff80001024afe4:       mov     x0, x21
    0.00 :   ffff80001024afe8:       bl      ffff80001025e8c8 <mnt_drop_write_file>
    0.00 :   ffff80001024afec:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 932              do_vfs_ioctl():
         : 983              set_close_on_exec(fd, 0);
    0.00 :   ffff80001024aff0:       mov     w0, w4
    0.00 :   ffff80001024aff4:       mov     w1, #0x0                        // #0
         : 984              return 0;
    0.00 :   ffff80001024aff8:       mov     w20, #0x0                       // #0
         : 983              set_close_on_exec(fd, 0);
    0.00 :   ffff80001024affc:       bl      ffff80001025a928 <set_close_on_exec>
         : 984              return 0;
    0.00 :   ffff80001024b000:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 986              get_current():
    0.00 :   ffff80001024b004:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b008:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b00c:       tbz     w1, #21, ffff80001024b264 <do_vfs_ioctl+0x90c>
         : 48               sign_extend64():
    0.00 :   ffff80001024b010:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b014:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024b018:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b01c:       mov     x1, x2
    0.00 :   ffff80001024b020:       adds    x0, x0, #0x4
    0.00 :   ffff80001024b024:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024b028:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b02c:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024b030:       cset    x0, ls  // ls = plast
         : 59               ioctl_fionbio():
         : 553              error = get_user(on, argp);
    0.00 :   ffff80001024b034:       mov     w20, #0xfffffff2                // #-14
         : 555              ioctl_fioasync():
         : 577              error = get_user(on, argp);
    0.00 :   ffff80001024b038:       cbz     x0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 579              sign_extend64():
    0.00 :   ffff80001024b03c:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024b040:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024b044:       bics    xzr, x0, x2
    0.00 :   ffff80001024b048:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b04c:       csdb
         : 249              ioctl_fioasync():
    0.00 :   ffff80001024b050:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024b054:       ldtr    w2, [x1]
         : 578              if (error)
    0.00 :   ffff80001024b058:       cbnz    w20, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 580              flag = on ? FASYNC : 0;
    0.00 :   ffff80001024b05c:       cmp     w2, #0x0
         : 583              if ((flag ^ filp->f_flags) & FASYNC) {
    0.00 :   ffff80001024b060:       ldr     w1, [x21, #64]
         : 580              flag = on ? FASYNC : 0;
    0.00 :   ffff80001024b064:       cset    w0, ne  // ne = any
         : 583              if ((flag ^ filp->f_flags) & FASYNC) {
    0.00 :   ffff80001024b068:       eor     w0, w1, w0, lsl #13
    0.00 :   ffff80001024b06c:       tbz     w0, #13, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 584              if (filp->f_op->fasync)
    0.00 :   ffff80001024b070:       ldr     x0, [x21, #40]
    0.00 :   ffff80001024b074:       mov     w20, #0xffffffe7                // #-25
    0.00 :   ffff80001024b078:       ldr     x3, [x0, #144]
    0.00 :   ffff80001024b07c:       cbz     x3, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 586              error = filp->f_op->fasync(fd, filp, on);
    0.00 :   ffff80001024b080:       mov     x1, x21
    0.00 :   ffff80001024b084:       mov     w0, w4
    0.00 :   ffff80001024b088:       blr     x3
    0.00 :   ffff80001024b08c:       cmp     w0, #0x0
    0.00 :   ffff80001024b090:       csel    w20, w0, wzr, le
    0.00 :   ffff80001024b094:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 593              do_vfs_ioctl():
         : 979              set_close_on_exec(fd, 1);
    0.00 :   ffff80001024b098:       mov     w0, w4
    0.00 :   ffff80001024b09c:       mov     w1, #0x1                        // #1
         : 980              return 0;
    0.00 :   ffff80001024b0a0:       mov     w20, #0x0                       // #0
         : 979              set_close_on_exec(fd, 1);
    0.00 :   ffff80001024b0a4:       bl      ffff80001025a928 <set_close_on_exec>
         : 980              return 0;
    0.00 :   ffff80001024b0a8:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 982              ioctl_fsthaw():
         : 612              struct super_block *sb = file_inode(filp)->i_sb;
    0.00 :   ffff80001024b0ac:       ldr     x20, [x23, #40]
         : 614              if (!ns_capable(sb->s_user_ns, CAP_SYS_ADMIN))
    0.00 :   ffff80001024b0b0:       mov     w1, #0x15                       // #21
    0.00 :   ffff80001024b0b4:       ldr     x0, [x20, #1144]
    0.00 :   ffff80001024b0b8:       bl      ffff80001008d5e0 <ns_capable>
    0.00 :   ffff80001024b0bc:       tst     w0, #0xff
    0.00 :   ffff80001024b0c0:       b.eq    ffff80001024b3c0 <do_vfs_ioctl+0xa68>  // b.none
         : 618              if (sb->s_op->thaw_super)
    0.00 :   ffff80001024b0c4:       ldr     x0, [x20, #48]
    0.00 :   ffff80001024b0c8:       ldr     x1, [x0, #88]
         : 619              return sb->s_op->thaw_super(sb);
    0.00 :   ffff80001024b0cc:       mov     x0, x20
         : 618              if (sb->s_op->thaw_super)
    0.00 :   ffff80001024b0d0:       cbz     x1, ffff80001024b3ac <do_vfs_ioctl+0xa54>
         : 619              return sb->s_op->thaw_super(sb);
    0.00 :   ffff80001024b0d4:       blr     x1
    0.00 :   ffff80001024b0d8:       mov     w20, w0
    0.00 :   ffff80001024b0dc:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 623              get_current():
    0.00 :   ffff80001024b0e0:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b0e4:       ldr     w2, [x0, #36]
         : 49               ioctl_file_dedupe_range():
         : 631              if (get_user(count, &argp->dest_count)) {
    0.00 :   ffff80001024b0e8:       add     x1, x3, #0x10
         : 633              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b0ec:       tbz     w2, #21, ffff80001024b250 <do_vfs_ioctl+0x8f8>
         : 48               sign_extend64():
    0.00 :   ffff80001024b0f0:       sbfx    x0, x1, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b0f4:       and     x0, x1, x0
         : 51               asm volatile(
    0.00 :   ffff80001024b0f8:       mov     x3, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b0fc:       mov     x2, x3
    0.00 :   ffff80001024b100:       adds    x0, x0, #0x2
    0.00 :   ffff80001024b104:       csel    x2, xzr, x2, hi  // hi = pmore
    0.00 :   ffff80001024b108:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b10c:       sbcs    xzr, x0, x2
    0.00 :   ffff80001024b110:       cset    x0, ls  // ls = plast
         : 59               ioctl_file_dedupe_range():
    0.00 :   ffff80001024b114:       cbz     x0, ffff80001024b624 <do_vfs_ioctl+0xccc>
         : 632              sign_extend64():
    0.00 :   ffff80001024b118:       sbfx    x0, x1, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024b11c:       and     x0, x1, x0
         : 239              asm volatile(
    0.00 :   ffff80001024b120:       bics    xzr, x0, x3
    0.00 :   ffff80001024b124:       csel    x2, x1, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b128:       csdb
         : 249              ioctl_file_dedupe_range():
    0.00 :   ffff80001024b12c:       mov     w0, #0x0                        // #0
    0.00 :   ffff80001024b130:       ldtrh   w20, [x2]
    0.00 :   ffff80001024b134:       cbnz    w0, ffff80001024b624 <do_vfs_ioctl+0xccc>
         : 636              size = offsetof(struct file_dedupe_range __user, info[count]);
    0.00 :   ffff80001024b138:       ubfiz   x23, x20, #5, #16
    0.00 :   ffff80001024b13c:       add     x23, x23, #0x18
         : 637              if (size > PAGE_SIZE) {
    0.00 :   ffff80001024b140:       cmp     x23, #0x1, lsl #12
    0.00 :   ffff80001024b144:       b.hi    ffff80001024b618 <do_vfs_ioctl+0xcc0>  // b.pmore
         : 642              same = memdup_user(argp, size);
    0.00 :   ffff80001024b148:       mov     x1, x23
    0.00 :   ffff80001024b14c:       mov     x0, x22
    0.00 :   ffff80001024b150:       bl      ffff8000101a2140 <memdup_user>
    0.00 :   ffff80001024b154:       mov     x24, x0
         : 643              if (IS_ERR(same)) {
    0.00 :   ffff80001024b158:       cmn     x0, #0x1, lsl #12
    0.00 :   ffff80001024b15c:       b.ls    ffff80001024b510 <do_vfs_ioctl+0xbb8>  // b.plast
         : 644              ret = PTR_ERR(same);
    0.00 :   ffff80001024b160:       mov     w20, w0
         : 645              same = NULL;
    0.00 :   ffff80001024b164:       mov     x24, #0x0                       // #0
         : 659              kfree(same);
    0.00 :   ffff80001024b168:       mov     x0, x24
    0.00 :   ffff80001024b16c:       bl      ffff800010206230 <kfree>
         : 662              do_vfs_ioctl():
         : 1025             return ioctl_file_dedupe_range(filp, argp);
    0.00 :   ffff80001024b170:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 1041             return ioctl_fsgetxattr(filp, argp);
    0.00 :   ffff80001024b174:       ldr     x0, [x21, #24]
         : 1043             ioctl_fsgetxattr():
         : 936              struct fileattr fa = { .fsx_valid = true }; /* hint only */
    0.00 :   ffff80001024b178:       str     wzr, [sp, #112]
    0.00 :   ffff80001024b17c:       mov     w1, #0x2                        // #2
    0.00 :   ffff80001024b180:       stp     xzr, xzr, [sp, #88]
    0.00 :   ffff80001024b184:       str     xzr, [sp, #104]
    0.00 :   ffff80001024b188:       strb    w1, [sp, #112]
         : 942              vfs_fileattr_get():
         : 736              if (!inode->i_op->fileattr_get)
    0.00 :   ffff80001024b18c:       ldr     x1, [x0, #48]
    0.00 :   ffff80001024b190:       ldr     x1, [x1, #32]
    0.00 :   ffff80001024b194:       ldr     x2, [x1, #176]
    0.00 :   ffff80001024b198:       cbz     x2, ffff80001024b3b8 <do_vfs_ioctl+0xa60>
         : 739              return inode->i_op->fileattr_get(dentry, fa);
    0.00 :   ffff80001024b19c:       add     x1, sp, #0x58
    0.00 :   ffff80001024b1a0:       blr     x2
    0.00 :   ffff80001024b1a4:       mov     w20, w0
         : 743              ioctl_fsgetxattr():
         : 940              if (!err)
    0.00 :   ffff80001024b1a8:       cbnz    w0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 941              err = copy_fsxattr_to_user(&fa, argp);
    0.00 :   ffff80001024b1ac:       mov     x1, x22
    0.00 :   ffff80001024b1b0:       add     x0, sp, #0x58
    0.00 :   ffff80001024b1b4:       bl      ffff80001024a318 <copy_fsxattr_to_user>
    0.00 :   ffff80001024b1b8:       mov     w20, w0
    0.00 :   ffff80001024b1bc:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 947              do_vfs_ioctl():
         : 993              if (S_ISDIR(inode->i_mode) || S_ISREG(inode->i_mode) ||
    0.00 :   ffff80001024b1c0:       ldrh    w0, [x23]
    0.00 :   ffff80001024b1c4:       mov     w3, #0xffffd000                 // #-12288
    0.00 :   ffff80001024b1c8:       mov     w1, #0x8000                     // #32768
    0.00 :   ffff80001024b1cc:       and     w2, w0, #0xf000
    0.00 :   ffff80001024b1d0:       and     w0, w0, w3
    0.00 :   ffff80001024b1d4:       cmp     w2, #0x4, lsl #12
    0.00 :   ffff80001024b1d8:       ccmp    w0, w1, #0x4, ne  // ne = any
    0.00 :   ffff80001024b1dc:       b.ne    ffff80001024ae60 <do_vfs_ioctl+0x508>  // b.any
         : 995              loff_t res = inode_get_bytes(inode);
    0.00 :   ffff80001024b1e0:       mov     x0, x23
    0.00 :   ffff80001024b1e4:       bl      ffff8000102390a8 <inode_get_bytes>
    0.00 :   ffff80001024b1e8:       str     x0, [sp, #88]
         : 999              get_current():
    0.00 :   ffff80001024b1ec:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b1f0:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b1f4:       tbz     w1, #21, ffff80001024b2f4 <do_vfs_ioctl+0x99c>
         : 48               sign_extend64():
    0.00 :   ffff80001024b1f8:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b1fc:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024b200:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b204:       mov     x1, x2
    0.00 :   ffff80001024b208:       adds    x0, x0, #0x8
    0.00 :   ffff80001024b20c:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024b210:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b214:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024b218:       cset    x0, ls  // ls = plast
         : 59               _copy_to_user():
         : 177              if (access_ok(to, n)) {
    0.00 :   ffff80001024b21c:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 179              sign_extend64():
    0.00 :   ffff80001024b220:       sbfx    x1, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024b224:       and     x1, x1, x22
         : 239              asm volatile(
    0.00 :   ffff80001024b228:       bics    xzr, x1, x2
    0.00 :   ffff80001024b22c:       csel    x0, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b230:       csdb
         : 249              _copy_to_user():
         : 179              instrument_copy_to_user(to, from, n);
         : 180              n = raw_copy_to_user(to, from, n);
    0.00 :   ffff80001024b234:       mov     x2, #0x8                        // #8
    0.00 :   ffff80001024b238:       add     x1, sp, #0x58
         : 183              do_vfs_ioctl():
         : 997              -EFAULT : 0;
    0.00 :   ffff80001024b23c:       mov     w20, #0x0                       // #0
         : 999              _copy_to_user():
    0.00 :   ffff80001024b240:       bl      ffff8000104a5400 <__arch_copy_to_user>
         : 180              do_vfs_ioctl():
    0.00 :   ffff80001024b244:       cbz     x0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 998              ioctl_fionbio():
         : 553              error = get_user(on, argp);
    0.00 :   ffff80001024b248:       mov     w20, #0xfffffff2                // #-14
    0.00 :   ffff80001024b24c:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 556              test_bit():
    0.00 :   ffff80001024b250:       ldr     x2, [x0]
         : 107              __range_ok():
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b254:       mov     x0, x1
    0.00 :   ffff80001024b258:       tst     w2, #0x4000000
    0.00 :   ffff80001024b25c:       b.eq    ffff80001024b0f8 <do_vfs_ioctl+0x7a0>  // b.none
    0.00 :   ffff80001024b260:       b       ffff80001024b0f0 <do_vfs_ioctl+0x798>
         : 51               test_bit():
    0.00 :   ffff80001024b264:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b268:       mov     x0, x3
    0.00 :   ffff80001024b26c:       tst     w1, #0x4000000
    0.00 :   ffff80001024b270:       b.eq    ffff80001024b018 <do_vfs_ioctl+0x6c0>  // b.none
    0.00 :   ffff80001024b274:       b       ffff80001024b010 <do_vfs_ioctl+0x6b8>
         : 50               test_bit():
    0.00 :   ffff80001024b278:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b27c:       mov     x0, x3
    0.00 :   ffff80001024b280:       tst     w1, #0x4000000
    0.00 :   ffff80001024b284:       b.eq    ffff80001024ac44 <do_vfs_ioctl+0x2ec>  // b.none
    0.00 :   ffff80001024b288:       b       ffff80001024ac3c <do_vfs_ioctl+0x2e4>
         : 50               test_bit():
    0.00 :   ffff80001024b28c:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b290:       mov     x0, x3
    0.00 :   ffff80001024b294:       tst     w1, #0x4000000
    0.00 :   ffff80001024b298:       b.eq    ffff80001024ad30 <do_vfs_ioctl+0x3d8>  // b.none
    0.00 :   ffff80001024b29c:       b       ffff80001024ad28 <do_vfs_ioctl+0x3d0>
         : 50               test_bit():
    0.00 :   ffff80001024b2a0:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b2a4:       mov     x0, x3
    0.00 :   ffff80001024b2a8:       tst     w1, #0x4000000
    0.00 :   ffff80001024b2ac:       b.eq    ffff80001024ae7c <do_vfs_ioctl+0x524>  // b.none
    0.00 :   ffff80001024b2b0:       b       ffff80001024ae74 <do_vfs_ioctl+0x51c>
         : 50               test_bit():
    0.00 :   ffff80001024b2b4:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b2b8:       mov     x0, x3
    0.00 :   ffff80001024b2bc:       tst     w1, #0x4000000
    0.00 :   ffff80001024b2c0:       b.eq    ffff80001024af74 <do_vfs_ioctl+0x61c>  // b.none
    0.00 :   ffff80001024b2c4:       b       ffff80001024af6c <do_vfs_ioctl+0x614>
         : 50               get_current():
    0.00 :   ffff80001024b2c8:       mrs     x0, sp_el0
         : 20               test_bit():
    0.00 :   ffff80001024b2cc:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b2d0:       mov     x0, x3
    0.00 :   ffff80001024b2d4:       tst     w1, #0x4000000
    0.00 :   ffff80001024b2d8:       b.eq    ffff80001024ab18 <do_vfs_ioctl+0x1c0>  // b.none
    0.00 :   ffff80001024b2dc:       b       ffff80001024ab10 <do_vfs_ioctl+0x1b8>
         : 50               test_bit():
    0.00 :   ffff80001024b2e0:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b2e4:       mov     x0, x3
    0.00 :   ffff80001024b2e8:       tst     w1, #0x4000000
    0.00 :   ffff80001024b2ec:       b.eq    ffff80001024af08 <do_vfs_ioctl+0x5b0>  // b.none
    0.00 :   ffff80001024b2f0:       b       ffff80001024af00 <do_vfs_ioctl+0x5a8>
         : 50               test_bit():
    0.00 :   ffff80001024b2f4:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b2f8:       mov     x0, x22
    0.00 :   ffff80001024b2fc:       tst     w1, #0x4000000
    0.00 :   ffff80001024b300:       b.eq    ffff80001024b200 <do_vfs_ioctl+0x8a8>  // b.none
    0.00 :   ffff80001024b304:       b       ffff80001024b1f8 <do_vfs_ioctl+0x8a0>
         : 50               get_current():
    0.00 :   ffff80001024b308:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b30c:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b310:       tbnz    w1, #21, ffff80001024b324 <do_vfs_ioctl+0x9cc>
         : 48               test_bit():
    0.00 :   ffff80001024b314:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b318:       mov     x0, x3
    0.00 :   ffff80001024b31c:       tst     w1, #0x4000000
    0.00 :   ffff80001024b320:       b.eq    ffff80001024b32c <do_vfs_ioctl+0x9d4>  // b.none
         : 49               sign_extend64():
    0.00 :   ffff80001024b324:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b328:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024b32c:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b330:       mov     x1, x2
    0.00 :   ffff80001024b334:       adds    x0, x0, #0x4
    0.00 :   ffff80001024b338:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024b33c:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b340:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024b344:       cset    x0, ls  // ls = plast
         : 59               do_vfs_ioctl():
         : 1031             return put_user(i_size_read(inode) - filp->f_pos,
    0.00 :   ffff80001024b348:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 1033             sign_extend64():
    0.00 :   ffff80001024b34c:       sbfx    x0, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024b350:       and     x0, x0, x22
         : 239              asm volatile(
    0.00 :   ffff80001024b354:       bics    xzr, x0, x2
    0.00 :   ffff80001024b358:       csel    x3, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b35c:       csdb
         : 249              do_vfs_ioctl():
    0.00 :   ffff80001024b360:       ldr     x1, [x23, #80]
    0.00 :   ffff80001024b364:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024b368:       ldr     x2, [x21, #104]
    0.00 :   ffff80001024b36c:       sub     w1, w1, w2
    0.00 :   ffff80001024b370:       sttr    w1, [x3]
         : 142              return false;
    0.00 :   ffff80001024b374:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 144              __uaccess_mask_ptr():
         : 239              asm volatile(
    0.00 :   ffff80001024b378:       bics    xzr, x21, x2
    0.00 :   ffff80001024b37c:       csel    x0, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b380:       csdb
         : 249              _copy_to_user():
    0.00 :   ffff80001024b384:       mov     x2, #0x20                       // #32
    0.00 :   ffff80001024b388:       add     x1, sp, #0x78
    0.00 :   ffff80001024b38c:       bl      ffff8000104a5400 <__arch_copy_to_user>
         : 182              ioctl_fiemap():
         : 224              if (copy_to_user(ufiemap, &fiemap, sizeof(fiemap)))
    0.00 :   ffff80001024b390:       cbz     x0, ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 226              ioctl_fionbio():
         : 553              error = get_user(on, argp);
    0.00 :   ffff80001024b394:       mov     w20, #0xfffffff2                // #-14
    0.00 :   ffff80001024b398:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 556              ioctl_fsfreeze():
         : 601              if (sb->s_op->freeze_fs == NULL && sb->s_op->freeze_super == NULL)
    0.00 :   ffff80001024b39c:       ldr     x1, [x0, #72]
    0.00 :   ffff80001024b3a0:       cbnz    x1, ffff80001024ad0c <do_vfs_ioctl+0x3b4>
         : 602              return -EOPNOTSUPP;
    0.00 :   ffff80001024b3a4:       mov     w20, #0xffffffa1                // #-95
    0.00 :   ffff80001024b3a8:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 605              ioctl_fsthaw():
         : 620              return thaw_super(sb);
    0.00 :   ffff80001024b3ac:       bl      ffff8000102367f8 <thaw_super>
    0.00 :   ffff80001024b3b0:       mov     w20, w0
    0.00 :   ffff80001024b3b4:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 624              do_vfs_ioctl():
         : 1052             return -ENOIOCTLCMD;
  100.00 :   ffff80001024b3b8:       mov     w20, #0xfffffdfd                // #-515
    0.00 :   ffff80001024b3bc:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 1055             ioctl_fibmap():
         : 67               return -EPERM;
    0.00 :   ffff80001024b3c0:       mov     w20, #0xffffffff                // #-1
    0.00 :   ffff80001024b3c4:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 70               file_ioctl():
         : 532              switch (cmd) {
    0.00 :   ffff80001024b3c8:       cmp     w5, #0x1
    0.00 :   ffff80001024b3cc:       b.ne    ffff80001024b4e8 <do_vfs_ioctl+0xb90>  // b.any
         : 535              ioctl_fibmap():
         : 66               if (!capable(CAP_SYS_RAWIO))
    0.00 :   ffff80001024b3d0:       mov     w0, #0x11                       // #17
         : 62               struct super_block *sb = inode->i_sb;
    0.00 :   ffff80001024b3d4:       ldr     x24, [x23, #40]
         : 66               if (!capable(CAP_SYS_RAWIO))
    0.00 :   ffff80001024b3d8:       bl      ffff80001008d600 <capable>
    0.00 :   ffff80001024b3dc:       tst     w0, #0xff
    0.00 :   ffff80001024b3e0:       b.eq    ffff80001024b3c0 <do_vfs_ioctl+0xa68>  // b.none
         : 70               get_current():
    0.00 :   ffff80001024b3e4:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b3e8:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b3ec:       tbnz    w1, #21, ffff80001024b400 <do_vfs_ioctl+0xaa8>
         : 48               test_bit():
    0.00 :   ffff80001024b3f0:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b3f4:       mov     x0, x22
    0.00 :   ffff80001024b3f8:       tst     w1, #0x4000000
    0.00 :   ffff80001024b3fc:       b.eq    ffff80001024b408 <do_vfs_ioctl+0xab0>  // b.none
         : 49               sign_extend64():
    0.00 :   ffff80001024b400:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b404:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024b408:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b40c:       mov     x1, x2
    0.00 :   ffff80001024b410:       adds    x0, x0, #0x4
    0.00 :   ffff80001024b414:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024b418:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b41c:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024b420:       cset    x0, ls  // ls = plast
         : 59               ioctl_fibmap():
         : 69               error = get_user(ur_block, p);
    0.00 :   ffff80001024b424:       cbz     x0, ffff80001024abe8 <do_vfs_ioctl+0x290>
         : 71               __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024b428:       str     x25, [sp, #64]
         : 246              sign_extend64():
    0.00 :   ffff80001024b42c:       sbfx    x25, x22, #0, #56
         : 183              __uaccess_mask_ptr():
    0.00 :   ffff80001024b430:       and     x25, x25, x22
         : 239              asm volatile(
    0.00 :   ffff80001024b434:       bics    xzr, x25, x2
    0.00 :   ffff80001024b438:       csel    x1, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b43c:       csdb
         : 249              ioctl_fibmap():
    0.00 :   ffff80001024b440:       mov     w20, #0x0                       // #0
    0.00 :   ffff80001024b444:       ldtr    w0, [x1]
         : 70               if (error)
    0.00 :   ffff80001024b448:       cbnz    w20, ffff80001024b4d4 <do_vfs_ioctl+0xb7c>
         : 73               if (ur_block < 0)
    0.00 :   ffff80001024b44c:       tbnz    w0, #31, ffff80001024b638 <do_vfs_ioctl+0xce0>
         : 76               block = ur_block;
    0.00 :   ffff80001024b450:       sxtw    x2, w0
         : 77               error = bmap(inode, &block);
    0.00 :   ffff80001024b454:       add     x1, sp, #0x58
    0.00 :   ffff80001024b458:       mov     x0, x23
         : 76               block = ur_block;
    0.00 :   ffff80001024b45c:       str     x2, [sp, #88]
         : 77               error = bmap(inode, &block);
    0.00 :   ffff80001024b460:       bl      ffff800010254d68 <bmap>
         : 79               if (block > INT_MAX) {
    0.00 :   ffff80001024b464:       ldr     x1, [sp, #88]
    0.00 :   ffff80001024b468:       mov     x2, #0x7fffffff                 // #2147483647
    0.00 :   ffff80001024b46c:       cmp     x1, x2
    0.00 :   ffff80001024b470:       b.hi    ffff80001024b5d4 <do_vfs_ioctl+0xc7c>  // b.pmore
         : 89               ur_block = block;
    0.00 :   ffff80001024b474:       cmp     w0, #0x0
    0.00 :   ffff80001024b478:       mov     w20, w0
    0.00 :   ffff80001024b47c:       csel    w0, w1, wzr, eq  // eq = none
         : 93               get_current():
    0.00 :   ffff80001024b480:       mrs     x2, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b484:       ldr     w3, [x2, #36]
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b488:       mov     x1, x25
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b48c:       tbnz    w3, #21, ffff80001024b49c <do_vfs_ioctl+0xb44>
         : 48               test_bit():
    0.00 :   ffff80001024b490:       ldr     x1, [x2]
         : 107              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b494:       tst     w1, #0x4000000
    0.00 :   ffff80001024b498:       csel    x1, x25, x22, ne  // ne = any
         : 51               asm volatile(
    0.00 :   ffff80001024b49c:       mov     x3, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b4a0:       mov     x2, x3
    0.00 :   ffff80001024b4a4:       adds    x1, x1, #0x4
    0.00 :   ffff80001024b4a8:       csel    x2, xzr, x2, hi  // hi = pmore
    0.00 :   ffff80001024b4ac:       csinv   x1, x1, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b4b0:       sbcs    xzr, x1, x2
    0.00 :   ffff80001024b4b4:       cset    x1, ls  // ls = plast
         : 59               ioctl_fibmap():
         : 91               if (put_user(ur_block, p))
    0.00 :   ffff80001024b4b8:       cbz     x1, ffff80001024b4dc <do_vfs_ioctl+0xb84>
         : 93               __uaccess_mask_ptr():
         : 239              asm volatile(
    0.00 :   ffff80001024b4bc:       bics    xzr, x25, x3
    0.00 :   ffff80001024b4c0:       csel    x2, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b4c4:       csdb
         : 249              ioctl_fibmap():
    0.00 :   ffff80001024b4c8:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001024b4cc:       sttr    w0, [x2]
    0.00 :   ffff80001024b4d0:       cbnz    w1, ffff80001024b4dc <do_vfs_ioctl+0xb84>
    0.00 :   ffff80001024b4d4:       ldr     x25, [sp, #64]
    0.00 :   ffff80001024b4d8:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 96               ioctl_fionbio():
         : 553              error = get_user(on, argp);
    0.00 :   ffff80001024b4dc:       mov     w20, #0xfffffff2                // #-14
    0.00 :   ffff80001024b4e0:       ldr     x25, [sp, #64]
    0.00 :   ffff80001024b4e4:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 557              file_ioctl():
         : 532              switch (cmd) {
    0.00 :   ffff80001024b4e8:       mov     w0, #0x5828                     // #22568
    0.00 :   ffff80001024b4ec:       movk    w0, #0x4030, lsl #16
    0.00 :   ffff80001024b4f0:       cmp     w5, w0
    0.00 :   ffff80001024b4f4:       b.ne    ffff80001024b3b8 <do_vfs_ioctl+0xa60>  // b.any
         : 537              return ioctl_preallocate(filp, 0, p);
    0.00 :   ffff80001024b4f8:       mov     x2, x22
    0.00 :   ffff80001024b4fc:       mov     x0, x21
    0.00 :   ffff80001024b500:       mov     w1, #0x0                        // #0
    0.00 :   ffff80001024b504:       bl      ffff80001024a3f8 <ioctl_preallocate>
    0.00 :   ffff80001024b508:       mov     w20, w0
    0.00 :   ffff80001024b50c:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 544              ioctl_file_dedupe_range():
         : 631              if (get_user(count, &argp->dest_count)) {
    0.00 :   ffff80001024b510:       strh    w20, [x0, #16]
         : 650              ret = vfs_dedupe_file_range(file, same);
    0.00 :   ffff80001024b514:       mov     x1, x24
    0.00 :   ffff80001024b518:       mov     x0, x21
    0.00 :   ffff80001024b51c:       bl      ffff8000102787f0 <vfs_dedupe_file_range>
    0.00 :   ffff80001024b520:       mov     w20, w0
         : 651              if (ret)
    0.00 :   ffff80001024b524:       cbnz    w0, ffff80001024b168 <do_vfs_ioctl+0x810>
         : 653              get_current():
    0.00 :   ffff80001024b528:       mrs     x0, sp_el0
         : 20               __range_ok():
         : 47               (current->flags & PF_KTHREAD || test_thread_flag(TIF_TAGGED_ADDR)))
    0.00 :   ffff80001024b52c:       ldr     w1, [x0, #36]
         : 46               if (IS_ENABLED(CONFIG_ARM64_TAGGED_ADDR_ABI) &&
    0.00 :   ffff80001024b530:       tbnz    w1, #21, ffff80001024b544 <do_vfs_ioctl+0xbec>
         : 48               test_bit():
    0.00 :   ffff80001024b534:       ldr     x1, [x0]
         : 107              __range_ok():
    0.00 :   ffff80001024b538:       mov     x0, x22
    0.00 :   ffff80001024b53c:       tst     w1, #0x4000000
    0.00 :   ffff80001024b540:       b.eq    ffff80001024b54c <do_vfs_ioctl+0xbf4>  // b.none
         : 49               sign_extend64():
    0.00 :   ffff80001024b544:       sbfx    x0, x22, #0, #56
         : 183              __range_ok():
         : 48               addr = untagged_addr(addr);
    0.00 :   ffff80001024b548:       and     x0, x0, x22
         : 51               asm volatile(
    0.00 :   ffff80001024b54c:       mov     x2, #0xffffffffffff             // #281474976710655
    0.00 :   ffff80001024b550:       mov     x1, x2
    0.00 :   ffff80001024b554:       adds    x0, x0, x23
    0.00 :   ffff80001024b558:       csel    x1, xzr, x1, hi  // hi = pmore
    0.00 :   ffff80001024b55c:       csinv   x0, x0, xzr, cc  // cc = lo, ul, last
    0.00 :   ffff80001024b560:       sbcs    xzr, x0, x1
    0.00 :   ffff80001024b564:       cset    x0, ls  // ls = plast
         : 59               ioctl_file_dedupe_range():
         : 656              ret = -EFAULT;
    0.00 :   ffff80001024b568:       mov     w20, #0xfffffff2                // #-14
         : 658              _copy_to_user():
         : 177              if (access_ok(to, n)) {
    0.00 :   ffff80001024b56c:       cbz     x0, ffff80001024b168 <do_vfs_ioctl+0x810>
         : 179              sign_extend64():
    0.00 :   ffff80001024b570:       sbfx    x1, x22, #0, #56
         : 183              __uaccess_mask_ptr():
         : 244              "r" (untagged_addr(ptr))
    0.00 :   ffff80001024b574:       and     x1, x1, x22
         : 239              asm volatile(
    0.00 :   ffff80001024b578:       bics    xzr, x1, x2
    0.00 :   ffff80001024b57c:       csel    x0, x22, xzr, eq  // eq = none
         : 247              csdb();
    0.00 :   ffff80001024b580:       csdb
         : 249              _copy_to_user():
         : 179              n = raw_copy_to_user(to, from, n);
    0.00 :   ffff80001024b584:       mov     x2, x23
    0.00 :   ffff80001024b588:       mov     x1, x24
    0.00 :   ffff80001024b58c:       bl      ffff8000104a5400 <__arch_copy_to_user>
         : 183              ioctl_file_dedupe_range():
    0.00 :   ffff80001024b590:       cmp     w0, #0x0
    0.00 :   ffff80001024b594:       csel    w20, w0, w20, eq  // eq = none
    0.00 :   ffff80001024b598:       b       ffff80001024b168 <do_vfs_ioctl+0x810>
         : 659              ioctl_fsfreeze():
         : 607              return freeze_super(sb);
    0.00 :   ffff80001024b59c:       mov     x0, x20
    0.00 :   ffff80001024b5a0:       bl      ffff800010236830 <freeze_super>
    0.00 :   ffff80001024b5a4:       mov     w20, w0
    0.00 :   ffff80001024b5a8:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 612              file_ioctl():
         : 540              return ioctl_preallocate(filp, FALLOC_FL_PUNCH_HOLE, p);
    0.00 :   ffff80001024b5ac:       mov     x2, x22
    0.00 :   ffff80001024b5b0:       mov     x0, x21
    0.00 :   ffff80001024b5b4:       mov     w1, #0x2                        // #2
    0.00 :   ffff80001024b5b8:       bl      ffff80001024a3f8 <ioctl_preallocate>
    0.00 :   ffff80001024b5bc:       mov     w20, w0
    0.00 :   ffff80001024b5c0:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 547              ioctl_fionbio():
         : 566              filp->f_flags &= ~flag;
    0.00 :   ffff80001024b5c4:       and     w0, w0, #0xfffff7ff
    0.00 :   ffff80001024b5c8:       b       ffff80001024aed8 <do_vfs_ioctl+0x580>
         : 569              do_vfs_ioctl():
         : 1014             return -EINVAL;
    0.00 :   ffff80001024b5cc:       mov     w20, #0xffffffea                // #-22
    0.00 :   ffff80001024b5d0:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
         : 1017             ioctl_fibmap():
         : 81               pr_warn_ratelimited("[%s/%d] FS: %s File: %pD4 would truncate fibmap result\n",
    0.00 :   ffff80001024b5d4:       adrp    x1, ffff800010e7f000 <memcg1_events>
    0.00 :   ffff80001024b5d8:       adrp    x0, ffff800011cc1000 <hugetlb_cgrp_subsys+0x88>
    0.00 :   ffff80001024b5dc:       add     x1, x1, #0xbb8
    0.00 :   ffff80001024b5e0:       add     x0, x0, #0x408
         : 80               error = -ERANGE;
    0.00 :   ffff80001024b5e4:       mov     w20, #0xffffffde                // #-34
         : 81               pr_warn_ratelimited("[%s/%d] FS: %s File: %pD4 would truncate fibmap result\n",
    0.00 :   ffff80001024b5e8:       bl      ffff8000104b30d8 <___ratelimit>
    0.00 :   ffff80001024b5ec:       cbz     w0, ffff80001024b480 <do_vfs_ioctl+0xb28>
         : 84               get_current():
    0.00 :   ffff80001024b5f0:       mrs     x1, sp_el0
         : 20               ioctl_fibmap():
    0.00 :   ffff80001024b5f4:       ldr     w2, [x1, #1096]
    0.00 :   ffff80001024b5f8:       mov     x4, x21
    0.00 :   ffff80001024b5fc:       add     x3, x24, #0x3a0
    0.00 :   ffff80001024b600:       adrp    x0, ffff80001142c000 <kallsyms_token_index+0x217a0>
    0.00 :   ffff80001024b604:       add     x1, x1, #0x608
    0.00 :   ffff80001024b608:       add     x0, x0, #0xbc8
    0.00 :   ffff80001024b60c:       bl      ffff800010e19544 <printk>
         : 87               ur_block = 0;
    0.00 :   ffff80001024b610:       mov     w0, #0x0                        // #0
    0.00 :   ffff80001024b614:       b       ffff80001024b480 <do_vfs_ioctl+0xb28>
         : 90               ioctl_file_dedupe_range():
         : 638              ret = -ENOMEM;
    0.00 :   ffff80001024b618:       mov     w20, #0xfffffff4                // #-12
         : 626              struct file_dedupe_range *same = NULL;
    0.00 :   ffff80001024b61c:       mov     x24, #0x0                       // #0
    0.00 :   ffff80001024b620:       b       ffff80001024b168 <do_vfs_ioctl+0x810>
         : 632              ret = -EFAULT;
    0.00 :   ffff80001024b624:       mov     w20, #0xfffffff2                // #-14
         : 626              struct file_dedupe_range *same = NULL;
    0.00 :   ffff80001024b628:       mov     x24, #0x0                       // #0
    0.00 :   ffff80001024b62c:       b       ffff80001024b168 <do_vfs_ioctl+0x810>
    0.00 :   ffff80001024b630:       str     x25, [sp, #64]
         : 630              do_vfs_ioctl():
         : 1053             }
    0.00 :   ffff80001024b634:       bl      ffff800010e2b8c8 <__stack_chk_fail>
         : 1055             ioctl_fibmap():
         : 74               return -EINVAL;
    0.00 :   ffff80001024b638:       mov     w20, #0xffffffea                // #-22
    0.00 :   ffff80001024b63c:       ldr     x25, [sp, #64]
    0.00 :   ffff80001024b640:       b       ffff80001024aa00 <do_vfs_ioctl+0xa8>
 Percent |	Source code & Disassembly of perf for cycles (1 samples, percent: local period)
-----------------------------------------------------------------------------------------------
         :
         :
         :
         : 3     Disassembly of section .plt:
         :
         : 5     0000000000070830 <ioctl@plt>:
  100.00 :   70830:  adrp    x16, 34e000 <timerfd_create@GLIBC_2.17>
    0.00 :   70834:  ldr     x17, [x16, #3040]
    0.00 :   70838:  add     x16, x16, #0xbe0
    0.00 :   7083c:  br      x17
 Percent |	Source code & Disassembly of vmlinux for cycles (55 samples, percent: local period)
---------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff80001016ba80 <event_function>:
         : 6                event_function():
         : 214              struct perf_event *event;
         : 215              event_f func;
         : 216              void *data;
         : 217              };
         :
         : 219              static int event_function(void *info)
    0.00 :   ffff80001016ba80:       paciasp
    0.00 :   ffff80001016ba84:       stp     x29, x30, [sp, #-64]!
    0.00 :   ffff80001016ba88:       mov     x29, sp
    0.00 :   ffff80001016ba8c:       stp     x19, x20, [sp, #16]
         : 224              __kern_my_cpu_offset():
         :
         : 40               /*
         : 41               * We want to allow caching the value, so avoid using volatile and
         : 42               * instead use a fake stack read to hazard against barrier().
         : 43               */
         : 44               asm(ALTERNATIVE("mrs %0, tpidr_el1",
    0.00 :   ffff80001016ba90:       mrs     x1, tpidr_el1
         : 46               event_function():
    0.00 :   ffff80001016ba94:       stp     x21, x22, [sp, #32]
    0.00 :   ffff80001016ba98:       mov     x22, x0
    0.00 :   ffff80001016ba9c:       stp     x23, x24, [sp, #48]
         : 216              {
         : 217              struct event_function_struct *efs = info;
    0.00 :   ffff80001016baa0:       ldr     x24, [x0]
         : 217              struct perf_event *event = efs->event;
    0.00 :   ffff80001016baa4:       ldr     x20, [x24, #552]
         : 219              __get_cpu_context():
         : 159              {
    0.00 :   ffff80001016baa8:       ldr     x0, [x20]
    0.00 :   ffff80001016baac:       ldr     x19, [x0, #72]
    0.00 :   ffff80001016bab0:       add     x19, x19, x1
         : 163              perf_ctx_lock():
         : 165              {
    0.00 :   ffff80001016bab4:       add     x23, x19, #0x8
    0.00 :   ffff80001016bab8:       mov     x0, x23
         : 168              event_function():
         : 219              struct perf_event_context *ctx = event->ctx;
         : 220              struct perf_cpu_context *cpuctx = __get_cpu_context(ctx);
    0.00 :   ffff80001016babc:       ldr     x21, [x19, #256]
         : 222              perf_ctx_lock():
         : 165              {
    0.00 :   ffff80001016bac0:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 166              raw_spin_lock(&cpuctx->ctx.lock);
    0.00 :   ffff80001016bac4:       cbz     x21, ffff80001016bad0 <event_function+0x50>
         : 167              if (ctx)
    0.00 :   ffff80001016bac8:       add     x0, x21, #0x8
    0.00 :   ffff80001016bacc:       bl      ffff800010e351f8 <_raw_spin_lock>
         : 170              event_function():
         :
         : 230              perf_ctx_lock(cpuctx, task_ctx);
         : 231              /*
         : 232              * Since we do the IPI call without holding ctx->lock things can have
         : 233              * changed, double check we hit the task we set out to hit.
         : 234              */
    0.00 :   ffff80001016bad0:       ldr     x0, [x20, #176]
    0.00 :   ffff80001016bad4:       cbz     x0, ffff80001016bb3c <event_function+0xbc>
         : 237              get_current():
         : 19               */
         : 20               static __always_inline struct task_struct *get_current(void)
         : 21               {
         : 22               unsigned long sp_el0;
         :
         : 24               asm ("mrs %0, sp_el0" : "=r" (sp_el0));
    0.00 :   ffff80001016bad8:       mrs     x1, sp_el0
         : 26               event_function():
         : 230              if (ctx->task) {
    0.00 :   ffff80001016badc:       cmp     x0, x1
    0.00 :   ffff80001016bae0:       b.ne    ffff80001016bb5c <event_function+0xdc>  // b.any
         : 242              * We only use event_function_call() on established contexts,
         : 243              * and event_function() is only ever called when active (or
         : 244              * rather, we'll have bailed in task_function_call() or the
         : 245              * above ctx->task != current test), therefore we must have
         : 246              * ctx->is_active here.
         : 247              */
    0.00 :   ffff80001016bae4:       ldr     w0, [x20, #152]
    0.00 :   ffff80001016bae8:       cbz     w0, ffff80001016bb4c <event_function+0xcc>
         : 247              WARN_ON_ONCE(!ctx->is_active);
         : 248              /*
         : 249              * And since we have ctx->is_active, cpuctx->task_ctx must
         : 250              * match.
         : 251              */
    0.00 :   ffff80001016baec:       cmp     x20, x21
    0.00 :   ffff80001016baf0:       b.ne    ffff80001016bb54 <event_function+0xd4>  // b.any
         : 252              WARN_ON_ONCE(task_ctx != ctx);
         : 253              } else {
         : 254              WARN_ON_ONCE(&cpuctx->ctx != ctx);
         : 255              }
         :
    0.00 :   ffff80001016baf4:       ldp     x4, x3, [x22, #8]
    0.00 :   ffff80001016baf8:       mov     x1, x19
    0.00 :   ffff80001016bafc:       mov     x2, x20
    0.00 :   ffff80001016bb00:       mov     x0, x24
         : 220              struct perf_event_context *task_ctx = cpuctx->task_ctx;
    0.00 :   ffff80001016bb04:       mov     w19, #0x0                       // #0
         :
    0.00 :   ffff80001016bb08:       blr     x4
         : 254              perf_ctx_unlock():
         : 173              {
    0.00 :   ffff80001016bb0c:       cbz     x21, ffff80001016bb18 <event_function+0x98>
         : 174              if (ctx)
    0.00 :   ffff80001016bb10:       add     x0, x21, #0x8
    0.00 :   ffff80001016bb14:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 175              raw_spin_unlock(&ctx->lock);
    0.00 :   ffff80001016bb18:       mov     x0, x23
    0.00 :   ffff80001016bb1c:       bl      ffff800010e349f0 <_raw_spin_unlock>
         : 178              event_function():
         : 257              efs->func(event, cpuctx, ctx, efs->data);
         : 258              unlock:
         : 259              perf_ctx_unlock(cpuctx, task_ctx);
         :
         : 261              return ret;
    0.00 :   ffff80001016bb20:       mov     w0, w19
   32.17 :   ffff80001016bb24:       ldp     x19, x20, [sp, #16]
   31.93 :   ffff80001016bb28:       ldp     x21, x22, [sp, #32]
    9.55 :   ffff80001016bb2c:       ldp     x23, x24, [sp, #48]
    0.00 :   ffff80001016bb30:       ldp     x29, x30, [sp], #64
    0.00 :   ffff80001016bb34:       autiasp
   26.34 :   ffff80001016bb38:       ret
         : 249              } else {
    0.00 :   ffff80001016bb3c:       cmp     x19, x20
    0.00 :   ffff80001016bb40:       b.eq    ffff80001016baf4 <event_function+0x74>  // b.none
    0.00 :   ffff80001016bb44:       brk     #0x800
    0.00 :   ffff80001016bb48:       b       ffff80001016baf4 <event_function+0x74>
         : 242              */
    0.00 :   ffff80001016bb4c:       brk     #0x800
    0.00 :   ffff80001016bb50:       b       ffff80001016baec <event_function+0x6c>
         : 247              */
    0.00 :   ffff80001016bb54:       brk     #0x800
    0.00 :   ffff80001016bb58:       b       ffff80001016baf4 <event_function+0x74>
         : 231              if (ctx->task != current) {
    0.00 :   ffff80001016bb5c:       mov     w19, #0xfffffffd                // #-3
    0.00 :   ffff80001016bb60:       b       ffff80001016bb0c <event_function+0x8c>
 Percent |	Source code & Disassembly of vmlinux for cycles (1 samples, percent: local period)
--------------------------------------------------------------------------------------------------
         :
         :
         :
         : 3                Disassembly of section .text:
         :
         : 5                ffff8000101693b8 <put_ctx>:
         : 6                put_ctx():
         : 1266             ctx = container_of(head, struct perf_event_context, rcu_head);
         : 1267             free_task_ctx_data(ctx->pmu, ctx->task_ctx_data);
         : 1268             kfree(ctx);
         : 1269             }
         :
         : 1271             static void put_ctx(struct perf_event_context *ctx)
    0.00 :   ffff8000101693b8:       paciasp
    0.00 :   ffff8000101693bc:       stp     x29, x30, [sp, #-32]!
    0.00 :   ffff8000101693c0:       mov     x29, sp
    0.00 :   ffff8000101693c4:       str     x19, [sp, #16]
    0.00 :   ffff8000101693c8:       mov     x19, x0
         : 1267             {
    0.00 :   ffff8000101693cc:       add     x0, x0, #0xac
         : 1269             arch_static_branch_jump():
         : 38               }
         :
         : 40               static __always_inline bool arch_static_branch_jump(struct static_key *key,
         : 41               bool branch)
         : 42               {
         : 43               asm_volatile_goto(
    0.00 :   ffff8000101693d0:       b       ffff80001016942c <put_ctx+0x74>
    0.00 :   ffff8000101693d4:       b       ffff80001016942c <put_ctx+0x74>
         : 46               __lse_atomic_fetch_sub_release():
         : 161              return i;                                                       \
         : 162              }
         :
         : 164              ATOMIC_FETCH_OP_SUB(_relaxed,   )
         : 165              ATOMIC_FETCH_OP_SUB(_acquire,  a, "memory")
         : 166              ATOMIC_FETCH_OP_SUB(_release,  l, "memory")
    0.00 :   ffff8000101693d8:       mov     w1, #0x1                        // #1
    0.00 :   ffff8000101693dc:       neg     w1, w1
    0.00 :   ffff8000101693e0:       ldaddl  w1, w1, [x0]
         : 170              __refcount_sub_and_test():
         : 277              int old = atomic_fetch_sub_release(i, &r->refs);
         :
         : 279              if (oldp)
         : 280              *oldp = old;
         :
         : 282              if (old == i) {
    0.00 :   ffff8000101693e4:       cmp     w1, #0x1
    0.00 :   ffff8000101693e8:       b.ne    ffff800010169440 <put_ctx+0x88>  // b.any
         : 278              smp_acquire__after_ctrl_dep();
    0.00 :   ffff8000101693ec:       dmb     ishld
         : 280              put_ctx():
         : 1268             if (refcount_dec_and_test(&ctx->refcount)) {
    0.00 :   ffff8000101693f0:       ldr     x0, [x19, #200]
    0.00 :   ffff8000101693f4:       cbz     x0, ffff8000101693fc <put_ctx+0x44>
         : 1269             if (ctx->parent_ctx)
    0.00 :   ffff8000101693f8:       bl      ffff8000101693b8 <put_ctx>
         : 1270             put_ctx(ctx->parent_ctx);
    0.00 :   ffff8000101693fc:       ldr     x1, [x19, #176]
    0.00 :   ffff800010169400:       sub     x0, x1, #0x1
    0.00 :   ffff800010169404:       cmn     x0, #0x3
    0.00 :   ffff800010169408:       b.ls    ffff800010169458 <put_ctx+0xa0>  // b.plast
         : 1272             if (ctx->task && ctx->task != TASK_TOMBSTONE)
         : 1273             put_task_struct(ctx->task);
    0.00 :   ffff80001016940c:       add     x0, x19, #0xf0
    0.00 :   ffff800010169410:       adrp    x1, ffff800010164000 <bpf_trampoline_update+0x190>
    0.00 :   ffff800010169414:       add     x1, x1, #0xd30
    0.00 :   ffff800010169418:       bl      ffff800010100c38 <call_rcu>
         : 1274             call_rcu(&ctx->rcu_head, free_ctx);
         : 1275             }
    0.00 :   ffff80001016941c:       ldr     x19, [sp, #16]
    0.00 :   ffff800010169420:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010169424:       autiasp
    0.00 :   ffff800010169428:       ret
         : 1280             __ll_sc_atomic_fetch_sub_release():
         : 112              ATOMIC_FETCH_OP (_relaxed,        ,  ,  ,         , __VA_ARGS__)\
         : 113              ATOMIC_FETCH_OP (_acquire,        , a,  , "memory", __VA_ARGS__)\
         : 114              ATOMIC_FETCH_OP (_release,        ,  , l, "memory", __VA_ARGS__)
         :
         : 116              ATOMIC_OPS(add, add, I)
         : 117              ATOMIC_OPS(sub, sub, J)
    0.00 :   ffff80001016942c:       mov     w2, #0x1                        // #1
    0.00 :   ffff800010169430:       add     x5, x19, #0xac
    0.00 :   ffff800010169434:       b       ffff800010176b30 <perf_event_exit_cpu+0xf0>
         : 121              __refcount_sub_and_test():
         : 277              if (old == i) {
    0.00 :   ffff800010169438:       cmp     w1, #0x1
    0.00 :   ffff80001016943c:       b.eq    ffff8000101693ec <put_ctx+0x34>  // b.none
         : 282              return true;
         : 283              }
         :
         : 285              if (unlikely(old < 0 || old - i < 0))
  100.00 :   ffff800010169440:       cmp     w1, #0x0
    0.00 :   ffff800010169444:       b.le    ffff800010169494 <put_ctx+0xdc>
         : 288              put_ctx():
    0.00 :   ffff800010169448:       ldr     x19, [sp, #16]
    0.00 :   ffff80001016944c:       ldp     x29, x30, [sp], #32
    0.00 :   ffff800010169450:       autiasp
    0.00 :   ffff800010169454:       ret
         : 1278             arch_atomic_fetch_sub_release():
         : 51               ATOMIC_FETCH_OPS(atomic_fetch_andnot)
         : 52               ATOMIC_FETCH_OPS(atomic_fetch_or)
         : 53               ATOMIC_FETCH_OPS(atomic_fetch_xor)
         : 54               ATOMIC_FETCH_OPS(atomic_fetch_add)
         : 55               ATOMIC_FETCH_OPS(atomic_fetch_and)
         : 56               ATOMIC_FETCH_OPS(atomic_fetch_sub)
    0.00 :   ffff800010169458:       bl      ffff8000101648a8 <system_uses_lse_atomics>
         : 58               put_task_struct():
         :
         : 113              extern void __put_task_struct(struct task_struct *t);
         :
         : 115              static inline void put_task_struct(struct task_struct *t)
         : 116              {
         : 117              if (refcount_dec_and_test(&t->usage))
    0.00 :   ffff80001016945c:       add     x3, x1, #0x20
         : 119              arch_atomic_fetch_sub_release():
    0.00 :   ffff800010169460:       tst     w0, #0xff
    0.00 :   ffff800010169464:       b.eq    ffff8000101694ac <put_ctx+0xf4>  // b.none
         : 53               __lse_atomic_fetch_sub_release():
    0.00 :   ffff800010169468:       mov     w0, #0x1                        // #1
    0.00 :   ffff80001016946c:       neg     w0, w0
    0.00 :   ffff800010169470:       ldaddl  w0, w0, [x3]
         : 164              __refcount_sub_and_test():
         : 277              if (old == i) {
    0.00 :   ffff800010169474:       cmp     w0, #0x1
    0.00 :   ffff800010169478:       b.eq    ffff8000101694bc <put_ctx+0x104>  // b.none
         : 282              if (unlikely(old < 0 || old - i < 0))
    0.00 :   ffff80001016947c:       cmp     w0, #0x0
    0.00 :   ffff800010169480:       b.gt    ffff80001016940c <put_ctx+0x54>
         : 283              refcount_warn_saturate(r, REFCOUNT_SUB_UAF);
    0.00 :   ffff800010169484:       mov     x0, x3
    0.00 :   ffff800010169488:       mov     w1, #0x3                        // #3
    0.00 :   ffff80001016948c:       bl      ffff800010470e68 <refcount_warn_saturate>
    0.00 :   ffff800010169490:       b       ffff80001016940c <put_ctx+0x54>
    0.00 :   ffff800010169494:       mov     w1, #0x3                        // #3
    0.00 :   ffff800010169498:       bl      ffff800010470e68 <refcount_warn_saturate>
         : 290              put_ctx():
    0.00 :   ffff80001016949c:       ldr     x19, [sp, #16]
    0.00 :   ffff8000101694a0:       ldp     x29, x30, [sp], #32
    0.00 :   ffff8000101694a4:       autiasp
    0.00 :   ffff8000101694a8:       ret
         : 1278             __ll_sc_atomic_fetch_sub_release():
    0.00 :   ffff8000101694ac:       mov     w2, #0x1                        // #1
    0.00 :   ffff8000101694b0:       add     x6, x1, #0x20
    0.00 :   ffff8000101694b4:       b       ffff800010176b48 <perf_event_exit_cpu+0x108>
    0.00 :   ffff8000101694b8:       b       ffff800010169474 <put_ctx+0xbc>
         : 116              __refcount_sub_and_test():
         : 278              smp_acquire__after_ctrl_dep();
    0.00 :   ffff8000101694bc:       dmb     ishld
         : 280              put_task_struct():
         : 113              __put_task_struct(t);
    0.00 :   ffff8000101694c0:       mov     x0, x1
    0.00 :   ffff8000101694c4:       bl      ffff80001007df38 <__put_task_struct>
    0.00 :   ffff8000101694c8:       b       ffff80001016940c <put_ctx+0x54>
