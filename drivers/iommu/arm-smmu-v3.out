
drivers/iommu/arm-smmu-v3.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <queue_remove_raw>:
	       Q_WRP(q, q->prod) != Q_WRP(q, q->cons);
}

static bool queue_empty(struct arm_smmu_ll_queue *q)
{
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
       0:	b9404002 	ldr	w2, [x0, #64]
       4:	52800023 	mov	w3, #0x1                   	// #1
		*dst++ = le64_to_cpu(*src++);
}

static int queue_remove_raw(struct arm_smmu_queue *q, u64 *ent)
{
	if (queue_empty(&q->llq))
       8:	29401404 	ldp	w4, w5, [x0]
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
       c:	1ac22063 	lsl	w3, w3, w2
      10:	51000462 	sub	w2, w3, #0x1
      14:	2a020063 	orr	w3, w3, w2
      18:	4a0400a4 	eor	w4, w5, w4
      1c:	6a03009f 	tst	w4, w3
      20:	54000460 	b.eq	ac <queue_remove_raw+0xac>  // b.none
		return -EAGAIN;

	queue_read(ent, Q_ENT(q, q->llq.cons), q->ent_dwords);
      24:	f9405006 	ldr	x6, [x0, #160]
      28:	0a0200a4 	and	w4, w5, w2
      2c:	f9404407 	ldr	x7, [x0, #136]
{
      30:	d503233f 	paciasp
	for (i = 0; i < n_dwords; ++i)
      34:	d2800002 	mov	x2, #0x0                   	// #0
	queue_read(ent, Q_ENT(q, q->llq.cons), q->ent_dwords);
      38:	d37df0c8 	lsl	x8, x6, #3
      3c:	9b081c84 	madd	x4, x4, x8, x7
	for (i = 0; i < n_dwords; ++i)
      40:	b40001c6 	cbz	x6, 78 <queue_remove_raw+0x78>
      44:	d503201f 	nop
		*dst++ = le64_to_cpu(*src++);
      48:	f8627885 	ldr	x5, [x4, x2, lsl #3]
	for (i = 0; i < n_dwords; ++i)
      4c:	11000443 	add	w3, w2, #0x1
		*dst++ = le64_to_cpu(*src++);
      50:	f8227825 	str	x5, [x1, x2, lsl #3]
	for (i = 0; i < n_dwords; ++i)
      54:	91000442 	add	x2, x2, #0x1
      58:	eb23c0df 	cmp	x6, w3, sxtw
      5c:	54ffff68 	b.hi	48 <queue_remove_raw+0x48>  // b.pmore
      60:	b9404001 	ldr	w1, [x0, #64]
      64:	52800023 	mov	w3, #0x1                   	// #1
      68:	b9400405 	ldr	w5, [x0, #4]
      6c:	1ac12061 	lsl	w1, w3, w1
      70:	51000423 	sub	w3, w1, #0x1
      74:	2a010063 	orr	w3, w3, w1
	u32 cons = (Q_WRP(q, q->cons) | Q_IDX(q, q->cons)) + 1;
      78:	0a0300a1 	and	w1, w5, w3
	q->cons = Q_OVF(q->cons) | Q_WRP(q, cons) | Q_IDX(q, cons);
      7c:	120100a5 	and	w5, w5, #0x80000000
	u32 cons = (Q_WRP(q, q->cons) | Q_IDX(q, q->cons)) + 1;
      80:	11000421 	add	w1, w1, #0x1
	q->cons = Q_OVF(q->cons) | Q_WRP(q, cons) | Q_IDX(q, cons);
      84:	0a030023 	and	w3, w1, w3
      88:	2a050063 	orr	w3, w3, w5
      8c:	b9000403 	str	w3, [x0, #4]
	mb();
      90:	d5033f9f 	dsb	sy
}

#define __raw_writel __raw_writel
static __always_inline void __raw_writel(u32 val, volatile void __iomem *addr)
{
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
      94:	b9400401 	ldr	w1, [x0, #4]
      98:	f9405800 	ldr	x0, [x0, #176]
      9c:	b9000001 	str	w1, [x0]
	queue_inc_cons(&q->llq);
	queue_sync_cons_out(q);
	return 0;
      a0:	52800000 	mov	w0, #0x0                   	// #0
}
      a4:	d50323bf 	autiasp
      a8:	d65f03c0 	ret
		return -EAGAIN;
      ac:	12800140 	mov	w0, #0xfffffff5            	// #-11
}
      b0:	d65f03c0 	ret
      b4:	d503201f 	nop

00000000000000b8 <arm_smmu_tlb_inv_page_nosync>:
}

static void arm_smmu_tlb_inv_page_nosync(struct iommu_iotlb_gather *gather,
					 unsigned long iova, size_t granule,
					 void *cookie)
{
      b8:	d503233f 	paciasp
      bc:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
      c0:	910003fd 	mov	x29, sp
      c4:	a90153f3 	stp	x19, x20, [sp, #16]
      c8:	aa0003f3 	mov	x19, x0
      cc:	a9025bf5 	stp	x21, x22, [sp, #32]
      d0:	aa0103f5 	mov	x21, x1

static inline void iommu_iotlb_gather_add_page(struct iommu_domain *domain,
					       struct iommu_iotlb_gather *gather,
					       unsigned long iova, size_t size)
{
	unsigned long start = iova, end = start + size;
      d4:	8b020036 	add	x22, x1, x2
      d8:	aa0203f4 	mov	x20, x2
	/*
	 * If the new page is disjoint from the current range or is mapped at
	 * a different granularity, then sync the TLB so that the gather
	 * structure can be rewritten.
	 */
	if (gather->pgsize != size ||
      dc:	f9400801 	ldr	x1, [x0, #16]
      e0:	eb01005f 	cmp	x2, x1
      e4:	54000380 	b.eq	154 <arm_smmu_tlb_inv_page_nosync+0x9c>  // b.none
	    end < gather->start || start > gather->end) {
		if (gather->pgsize)
      e8:	b4000321 	cbz	x1, 14c <arm_smmu_tlb_inv_page_nosync+0x94>
	if (domain->ops->iotlb_sync)
      ec:	91022060 	add	x0, x3, #0x88
      f0:	f9400401 	ldr	x1, [x0, #8]
      f4:	f9402422 	ldr	x2, [x1, #72]
      f8:	b4000062 	cbz	x2, 104 <arm_smmu_tlb_inv_page_nosync+0x4c>
		domain->ops->iotlb_sync(domain, iotlb_gather);
      fc:	aa1303e1 	mov	x1, x19
     100:	d63f0040 	blr	x2
	*gather = (struct iommu_iotlb_gather) {
     104:	92800001 	mov	x1, #0xffffffffffffffff    	// #-1
     108:	a9007e7f 	stp	xzr, xzr, [x19]
     10c:	aa0103e0 	mov	x0, x1
     110:	d2800002 	mov	x2, #0x0                   	// #0
     114:	f9000261 	str	x1, [x19]
     118:	f9000a7f 	str	xzr, [x19, #16]
			iommu_tlb_sync(domain, gather);
		gather->pgsize = size;
     11c:	f9000a74 	str	x20, [x19, #16]
	}

	if (gather->end < end)
     120:	eb0202df 	cmp	x22, x2
     124:	54000049 	b.ls	12c <arm_smmu_tlb_inv_page_nosync+0x74>  // b.plast
		gather->end = end;
     128:	f9000676 	str	x22, [x19, #8]

	if (gather->start > start)
     12c:	eb0002bf 	cmp	x21, x0
     130:	54000042 	b.cs	138 <arm_smmu_tlb_inv_page_nosync+0x80>  // b.hs, b.nlast
		gather->start = start;
     134:	f9000275 	str	x21, [x19]
	struct arm_smmu_domain *smmu_domain = cookie;
	struct iommu_domain *domain = &smmu_domain->domain;

	iommu_iotlb_gather_add_page(domain, gather, iova, granule);
}
     138:	a94153f3 	ldp	x19, x20, [sp, #16]
     13c:	a9425bf5 	ldp	x21, x22, [sp, #32]
     140:	a8c37bfd 	ldp	x29, x30, [sp], #48
     144:	d50323bf 	autiasp
     148:	d65f03c0 	ret
     14c:	a9400a60 	ldp	x0, x2, [x19]
     150:	17fffff3 	b	11c <arm_smmu_tlb_inv_page_nosync+0x64>
	    end < gather->start || start > gather->end) {
     154:	f9400000 	ldr	x0, [x0]
	if (gather->pgsize != size ||
     158:	eb0002df 	cmp	x22, x0
     15c:	54fffc63 	b.cc	e8 <arm_smmu_tlb_inv_page_nosync+0x30>  // b.lo, b.ul, b.last
	    end < gather->start || start > gather->end) {
     160:	f9400662 	ldr	x2, [x19, #8]
     164:	eb0202bf 	cmp	x21, x2
     168:	54fffdc9 	b.ls	120 <arm_smmu_tlb_inv_page_nosync+0x68>  // b.plast
		if (gather->pgsize)
     16c:	b5fffc01 	cbnz	x1, ec <arm_smmu_tlb_inv_page_nosync+0x34>
     170:	17fffff7 	b	14c <arm_smmu_tlb_inv_page_nosync+0x94>
     174:	d503201f 	nop

0000000000000178 <arm_smmu_capable>:
	.tlb_add_page	= arm_smmu_tlb_inv_page_nosync,
};

/* IOMMU API */
static bool arm_smmu_capable(enum iommu_cap cap)
{
     178:	d503233f 	paciasp
	switch (cap) {
     17c:	340000c0 	cbz	w0, 194 <arm_smmu_capable+0x1c>
     180:	7100081f 	cmp	w0, #0x2
     184:	54000080 	b.eq	194 <arm_smmu_capable+0x1c>  // b.none
	case IOMMU_CAP_CACHE_COHERENCY:
		return true;
	case IOMMU_CAP_NOEXEC:
		return true;
	default:
		return false;
     188:	52800000 	mov	w0, #0x0                   	// #0
	}
}
     18c:	d50323bf 	autiasp
     190:	d65f03c0 	ret
		return true;
     194:	52800020 	mov	w0, #0x1                   	// #1
}
     198:	d50323bf 	autiasp
     19c:	d65f03c0 	ret

00000000000001a0 <arm_smmu_map>:
}

static int arm_smmu_map(struct iommu_domain *domain, unsigned long iova,
			phys_addr_t paddr, size_t size, int prot, gfp_t gfp)
{
	struct io_pgtable_ops *ops = to_smmu_domain(domain)->pgtbl_ops;
     1a0:	f85a0000 	ldur	x0, [x0, #-96]

	if (!ops)
     1a4:	b4000120 	cbz	x0, 1c8 <arm_smmu_map+0x28>
{
     1a8:	d503233f 	paciasp
     1ac:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
     1b0:	910003fd 	mov	x29, sp
		return -ENODEV;

	return ops->map(ops, iova, paddr, size, prot);
     1b4:	f9400005 	ldr	x5, [x0]
     1b8:	d63f00a0 	blr	x5
}
     1bc:	a8c17bfd 	ldp	x29, x30, [sp], #16
     1c0:	d50323bf 	autiasp
     1c4:	d65f03c0 	ret
		return -ENODEV;
     1c8:	12800240 	mov	w0, #0xffffffed            	// #-19
}
     1cc:	d65f03c0 	ret

00000000000001d0 <arm_smmu_unmap>:

static size_t arm_smmu_unmap(struct iommu_domain *domain, unsigned long iova,
			     size_t size, struct iommu_iotlb_gather *gather)
{
	struct arm_smmu_domain *smmu_domain = to_smmu_domain(domain);
	struct io_pgtable_ops *ops = smmu_domain->pgtbl_ops;
     1d0:	f85a0000 	ldur	x0, [x0, #-96]

	if (!ops)
     1d4:	b4000120 	cbz	x0, 1f8 <arm_smmu_unmap+0x28>
{
     1d8:	d503233f 	paciasp
     1dc:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
     1e0:	910003fd 	mov	x29, sp
		return 0;

	return ops->unmap(ops, iova, size, gather);
     1e4:	f9400404 	ldr	x4, [x0, #8]
     1e8:	d63f0080 	blr	x4
}
     1ec:	a8c17bfd 	ldp	x29, x30, [sp], #16
     1f0:	d50323bf 	autiasp
     1f4:	d65f03c0 	ret
		return 0;
     1f8:	d2800000 	mov	x0, #0x0                   	// #0
}
     1fc:	d65f03c0 	ret

0000000000000200 <arm_smmu_iova_to_phys>:
static phys_addr_t
arm_smmu_iova_to_phys(struct iommu_domain *domain, dma_addr_t iova)
{
	struct io_pgtable_ops *ops = to_smmu_domain(domain)->pgtbl_ops;

	if (domain->type == IOMMU_DOMAIN_IDENTITY)
     200:	b9400003 	ldr	w3, [x0]
     204:	7100107f 	cmp	w3, #0x4
     208:	54000160 	b.eq	234 <arm_smmu_iova_to_phys+0x34>  // b.none
	struct io_pgtable_ops *ops = to_smmu_domain(domain)->pgtbl_ops;
     20c:	f85a0000 	ldur	x0, [x0, #-96]
		return iova;

	if (!ops)
     210:	b4000160 	cbz	x0, 23c <arm_smmu_iova_to_phys+0x3c>
{
     214:	d503233f 	paciasp
     218:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
     21c:	910003fd 	mov	x29, sp
		return 0;

	return ops->iova_to_phys(ops, iova);
     220:	f9400802 	ldr	x2, [x0, #16]
     224:	d63f0040 	blr	x2
}
     228:	a8c17bfd 	ldp	x29, x30, [sp], #16
     22c:	d50323bf 	autiasp
     230:	d65f03c0 	ret
		return iova;
     234:	aa0103e0 	mov	x0, x1
     238:	d65f03c0 	ret
		return 0;
     23c:	d2800000 	mov	x0, #0x0                   	// #0
}
     240:	d65f03c0 	ret
     244:	d503201f 	nop

0000000000000248 <arm_smmu_write_msi_msg>:
static void arm_smmu_write_msi_msg(struct msi_desc *desc, struct msi_msg *msg)
{
	phys_addr_t doorbell;
	struct device *dev = msi_desc_to_dev(desc);
	struct arm_smmu_device *smmu = dev_get_drvdata(dev);
	phys_addr_t *cfg = arm_smmu_msi_cfg[desc->platform.msi_index];
     248:	7940b002 	ldrh	w2, [x0, #88]
     24c:	52800305 	mov	w5, #0x18                  	// #24
	struct arm_smmu_device *smmu = dev_get_drvdata(dev);
     250:	f9400c00 	ldr	x0, [x0, #24]
	phys_addr_t *cfg = arm_smmu_msi_cfg[desc->platform.msi_index];
     254:	90000003 	adrp	x3, 0 <queue_remove_raw>
     258:	91000063 	add	x3, x3, #0x0

	doorbell = (((u64)msg->address_hi) << 32) | msg->address_lo;
     25c:	f9400024 	ldr	x4, [x1]
{
     260:	d503233f 	paciasp
	phys_addr_t *cfg = arm_smmu_msi_cfg[desc->platform.msi_index];
     264:	9ba57c42 	umull	x2, w2, w5
	doorbell &= MSI_CFG0_ADDR_MASK;

	writeq_relaxed(doorbell, smmu->base + cfg[0]);
     268:	f9403c00 	ldr	x0, [x0, #120]
	doorbell &= MSI_CFG0_ADDR_MASK;
     26c:	927ec484 	and	x4, x4, #0xffffffffffffc
	phys_addr_t *cfg = arm_smmu_msi_cfg[desc->platform.msi_index];
     270:	8b020065 	add	x5, x3, x2
	writeq_relaxed(doorbell, smmu->base + cfg[0]);
     274:	f9400400 	ldr	x0, [x0, #8]
     278:	f8626862 	ldr	x2, [x3, x2]
     27c:	8b020002 	add	x2, x0, x2
}

#define __raw_writeq __raw_writeq
static inline void __raw_writeq(u64 val, volatile void __iomem *addr)
{
	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
     280:	f9000044 	str	x4, [x2]
	writel_relaxed(msg->data, smmu->base + cfg[1]);
     284:	f94004a2 	ldr	x2, [x5, #8]
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
     288:	b9400823 	ldr	w3, [x1, #8]
     28c:	8b020001 	add	x1, x0, x2
     290:	b9000023 	str	w3, [x1]
	writel_relaxed(ARM_SMMU_MEMATTR_DEVICE_nGnRE, smmu->base + cfg[2]);
     294:	f94008a2 	ldr	x2, [x5, #16]
     298:	52800021 	mov	w1, #0x1                   	// #1
     29c:	8b020000 	add	x0, x0, x2
     2a0:	b9000001 	str	w1, [x0]
}
     2a4:	d50323bf 	autiasp
     2a8:	d65f03c0 	ret
     2ac:	d503201f 	nop

00000000000002b0 <arm_smmu_set_bus_ops>:
	else
		return SZ_128K;
}

static int arm_smmu_set_bus_ops(struct iommu_ops *ops)
{
     2b0:	d503233f 	paciasp
     2b4:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
     2b8:	910003fd 	mov	x29, sp
     2bc:	f90013f5 	str	x21, [sp, #32]
	int err;

#ifdef CONFIG_PCI
	if (pci_bus_type.iommu_ops != ops) {
     2c0:	90000015 	adrp	x21, 0 <pci_bus_type>
     2c4:	910002a2 	add	x2, x21, #0x0
{
     2c8:	a90153f3 	stp	x19, x20, [sp, #16]
     2cc:	aa0003f3 	mov	x19, x0
	if (pci_bus_type.iommu_ops != ops) {
     2d0:	f9404c40 	ldr	x0, [x2, #152]
     2d4:	eb13001f 	cmp	x0, x19
     2d8:	540000c0 	b.eq	2f0 <arm_smmu_set_bus_ops+0x40>  // b.none
		err = bus_set_iommu(&pci_bus_type, ops);
     2dc:	aa1303e1 	mov	x1, x19
     2e0:	aa0203e0 	mov	x0, x2
     2e4:	94000000 	bl	0 <bus_set_iommu>
     2e8:	2a0003f4 	mov	w20, w0
		if (err)
     2ec:	350001e0 	cbnz	w0, 328 <arm_smmu_set_bus_ops+0x78>
     2f0:	f90017b6 	str	x22, [x29, #40]
			return err;
	}
#endif
#ifdef CONFIG_ARM_AMBA
	if (amba_bustype.iommu_ops != ops) {
     2f4:	90000016 	adrp	x22, 0 <amba_bustype>
     2f8:	910002c0 	add	x0, x22, #0x0
     2fc:	f9404c01 	ldr	x1, [x0, #152]
     300:	eb13003f 	cmp	x1, x19
     304:	540001e0 	b.eq	340 <arm_smmu_set_bus_ops+0x90>  // b.none
		err = bus_set_iommu(&amba_bustype, ops);
     308:	aa1303e1 	mov	x1, x19
     30c:	94000000 	bl	0 <bus_set_iommu>
     310:	2a0003f4 	mov	w20, w0
		if (err)
     314:	34000160 	cbz	w0, 340 <arm_smmu_set_bus_ops+0x90>
#ifdef CONFIG_ARM_AMBA
	bus_set_iommu(&amba_bustype, NULL);
#endif
err_reset_pci_ops: __maybe_unused;
#ifdef CONFIG_PCI
	bus_set_iommu(&pci_bus_type, NULL);
     318:	d2800001 	mov	x1, #0x0                   	// #0
     31c:	910002a0 	add	x0, x21, #0x0
     320:	94000000 	bl	0 <bus_set_iommu>
     324:	f94017b6 	ldr	x22, [x29, #40]
#endif
	return err;
}
     328:	2a1403e0 	mov	w0, w20
     32c:	f94013f5 	ldr	x21, [sp, #32]
     330:	a94153f3 	ldp	x19, x20, [sp, #16]
     334:	a8c37bfd 	ldp	x29, x30, [sp], #48
     338:	d50323bf 	autiasp
     33c:	d65f03c0 	ret
	if (platform_bus_type.iommu_ops != ops) {
     340:	90000000 	adrp	x0, 0 <platform_bus_type>
     344:	91000000 	add	x0, x0, #0x0
     348:	f9404c01 	ldr	x1, [x0, #152]
     34c:	eb13003f 	cmp	x1, x19
     350:	540000a0 	b.eq	364 <arm_smmu_set_bus_ops+0xb4>  // b.none
		err = bus_set_iommu(&platform_bus_type, ops);
     354:	aa1303e1 	mov	x1, x19
     358:	94000000 	bl	0 <bus_set_iommu>
     35c:	2a0003f4 	mov	w20, w0
		if (err)
     360:	35000120 	cbnz	w0, 384 <arm_smmu_set_bus_ops+0xd4>
	return 0;
     364:	52800014 	mov	w20, #0x0                   	// #0
     368:	f94017b6 	ldr	x22, [x29, #40]
}
     36c:	2a1403e0 	mov	w0, w20
     370:	f94013f5 	ldr	x21, [sp, #32]
     374:	a94153f3 	ldp	x19, x20, [sp, #16]
     378:	a8c37bfd 	ldp	x29, x30, [sp], #48
     37c:	d50323bf 	autiasp
     380:	d65f03c0 	ret
	bus_set_iommu(&amba_bustype, NULL);
     384:	d2800001 	mov	x1, #0x0                   	// #0
     388:	910002c0 	add	x0, x22, #0x0
     38c:	94000000 	bl	0 <bus_set_iommu>
     390:	17ffffe2 	b	318 <arm_smmu_set_bus_ops+0x68>
     394:	d503201f 	nop

0000000000000398 <arm_smmu_of_xlate>:
{
     398:	d503233f 	paciasp
     39c:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	return iommu_fwspec_add_ids(dev, args->args, 1);
     3a0:	52800022 	mov	w2, #0x1                   	// #1
     3a4:	91003021 	add	x1, x1, #0xc
{
     3a8:	910003fd 	mov	x29, sp
	return iommu_fwspec_add_ids(dev, args->args, 1);
     3ac:	94000000 	bl	0 <iommu_fwspec_add_ids>
}
     3b0:	a8c17bfd 	ldp	x29, x30, [sp], #16
     3b4:	d50323bf 	autiasp
     3b8:	d65f03c0 	ret
     3bc:	d503201f 	nop

00000000000003c0 <arm_smmu_get_resv_regions>:
{
     3c0:	d503233f 	paciasp
     3c4:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
	region = iommu_alloc_resv_region(MSI_IOVA_BASE, MSI_IOVA_LENGTH,
     3c8:	52800083 	mov	w3, #0x4                   	// #4
     3cc:	52800342 	mov	w2, #0x1a                  	// #26
{
     3d0:	910003fd 	mov	x29, sp
     3d4:	a90153f3 	stp	x19, x20, [sp, #16]
     3d8:	aa0003f4 	mov	x20, x0
     3dc:	aa0103f3 	mov	x19, x1
	region = iommu_alloc_resv_region(MSI_IOVA_BASE, MSI_IOVA_LENGTH,
     3e0:	d2a10000 	mov	x0, #0x8000000             	// #134217728
     3e4:	d2a00201 	mov	x1, #0x100000              	// #1048576
     3e8:	94000000 	bl	0 <iommu_alloc_resv_region>
	if (!region)
     3ec:	b4000120 	cbz	x0, 410 <arm_smmu_get_resv_regions+0x50>
     3f0:	aa0003e2 	mov	x2, x0
 * Insert a new entry before the specified head.
 * This is useful for implementing queues.
 */
static inline void list_add_tail(struct list_head *new, struct list_head *head)
{
	__list_add(new, head->prev, head);
     3f4:	f9400663 	ldr	x3, [x19, #8]
	next->prev = new;
     3f8:	f9000662 	str	x2, [x19, #8]
	iommu_dma_get_resv_regions(dev, head);
     3fc:	aa1303e1 	mov	x1, x19
     400:	aa1403e0 	mov	x0, x20
	new->prev = prev;
     404:	a9000c53 	stp	x19, x3, [x2]
	WRITE_ONCE(prev->next, new);
     408:	f9000062 	str	x2, [x3]
     40c:	94000000 	bl	0 <iommu_dma_get_resv_regions>
}
     410:	a94153f3 	ldp	x19, x20, [sp, #16]
     414:	a8c27bfd 	ldp	x29, x30, [sp], #32
     418:	d50323bf 	autiasp
     41c:	d65f03c0 	ret

0000000000000420 <arm_smmu_domain_set_attr>:
{
     420:	d503233f 	paciasp
     424:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
     428:	910003fd 	mov	x29, sp
     42c:	a90153f3 	stp	x19, x20, [sp, #16]
     430:	aa0003f3 	mov	x19, x0
	mutex_lock(&smmu_domain->init_mutex);
     434:	d1020014 	sub	x20, x0, #0x80
{
     438:	a9025bf5 	stp	x21, x22, [sp, #32]
	mutex_lock(&smmu_domain->init_mutex);
     43c:	aa1403e0 	mov	x0, x20
{
     440:	2a0103f5 	mov	w21, w1
     444:	aa0203f6 	mov	x22, x2
	mutex_lock(&smmu_domain->init_mutex);
     448:	94000000 	bl	0 <mutex_lock>
	switch (domain->type) {
     44c:	b9400260 	ldr	w0, [x19]
     450:	7100041f 	cmp	w0, #0x1
     454:	54000360 	b.eq	4c0 <arm_smmu_domain_set_attr+0xa0>  // b.none
     458:	71000c1f 	cmp	w0, #0x3
     45c:	54000201 	b.ne	49c <arm_smmu_domain_set_attr+0x7c>  // b.any
		switch(attr) {
     460:	71001ebf 	cmp	w21, #0x7
     464:	54000661 	b.ne	530 <arm_smmu_domain_set_attr+0x110>  // b.any
			smmu_domain->non_strict = *(int *)data;
     468:	b94002c0 	ldr	w0, [x22]
	int ret = 0;
     46c:	52800015 	mov	w21, #0x0                   	// #0
			smmu_domain->non_strict = *(int *)data;
     470:	7100001f 	cmp	w0, #0x0
     474:	1a9f07e0 	cset	w0, ne  // ne = any
     478:	381a8260 	sturb	w0, [x19, #-88]
	mutex_unlock(&smmu_domain->init_mutex);
     47c:	aa1403e0 	mov	x0, x20
     480:	94000000 	bl	0 <mutex_unlock>
}
     484:	2a1503e0 	mov	w0, w21
     488:	a94153f3 	ldp	x19, x20, [sp, #16]
     48c:	a9425bf5 	ldp	x21, x22, [sp, #32]
     490:	a8c37bfd 	ldp	x29, x30, [sp], #48
     494:	d50323bf 	autiasp
     498:	d65f03c0 	ret
		ret = -EINVAL;
     49c:	128002b5 	mov	w21, #0xffffffea            	// #-22
	mutex_unlock(&smmu_domain->init_mutex);
     4a0:	aa1403e0 	mov	x0, x20
     4a4:	94000000 	bl	0 <mutex_unlock>
}
     4a8:	2a1503e0 	mov	w0, w21
     4ac:	a94153f3 	ldp	x19, x20, [sp, #16]
     4b0:	a9425bf5 	ldp	x21, x22, [sp, #32]
     4b4:	a8c37bfd 	ldp	x29, x30, [sp], #48
     4b8:	d50323bf 	autiasp
     4bc:	d65f03c0 	ret
		switch (attr) {
     4c0:	71001abf 	cmp	w21, #0x6
     4c4:	54000361 	b.ne	530 <arm_smmu_domain_set_attr+0x110>  // b.any
			if (smmu_domain->smmu) {
     4c8:	f8578260 	ldur	x0, [x19, #-136]
     4cc:	b50002e0 	cbnz	x0, 528 <arm_smmu_domain_set_attr+0x108>
			if (*(int *)data)
     4d0:	b94002d5 	ldr	w21, [x22]
     4d4:	34000195 	cbz	w21, 504 <arm_smmu_domain_set_attr+0xe4>
				smmu_domain->stage = ARM_SMMU_DOMAIN_NESTED;
     4d8:	52800040 	mov	w0, #0x2                   	// #2
     4dc:	b81b0260 	stur	w0, [x19, #-80]
	int ret = 0;
     4e0:	52800015 	mov	w21, #0x0                   	// #0
	mutex_unlock(&smmu_domain->init_mutex);
     4e4:	aa1403e0 	mov	x0, x20
     4e8:	94000000 	bl	0 <mutex_unlock>
}
     4ec:	2a1503e0 	mov	w0, w21
     4f0:	a94153f3 	ldp	x19, x20, [sp, #16]
     4f4:	a9425bf5 	ldp	x21, x22, [sp, #32]
     4f8:	a8c37bfd 	ldp	x29, x30, [sp], #48
     4fc:	d50323bf 	autiasp
     500:	d65f03c0 	ret
				smmu_domain->stage = ARM_SMMU_DOMAIN_S1;
     504:	b81b027f 	stur	wzr, [x19, #-80]
	mutex_unlock(&smmu_domain->init_mutex);
     508:	aa1403e0 	mov	x0, x20
     50c:	94000000 	bl	0 <mutex_unlock>
}
     510:	2a1503e0 	mov	w0, w21
     514:	a94153f3 	ldp	x19, x20, [sp, #16]
     518:	a9425bf5 	ldp	x21, x22, [sp, #32]
     51c:	a8c37bfd 	ldp	x29, x30, [sp], #48
     520:	d50323bf 	autiasp
     524:	d65f03c0 	ret
				ret = -EPERM;
     528:	12800015 	mov	w21, #0xffffffff            	// #-1
     52c:	17ffffdd 	b	4a0 <arm_smmu_domain_set_attr+0x80>
			ret = -ENODEV;
     530:	12800255 	mov	w21, #0xffffffed            	// #-19
     534:	17ffffdb 	b	4a0 <arm_smmu_domain_set_attr+0x80>

0000000000000538 <arm_smmu_device_group>:
{
     538:	d503233f 	paciasp
     53c:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	if (dev_is_pci(dev))
     540:	90000001 	adrp	x1, 0 <pci_bus_type>
     544:	91000021 	add	x1, x1, #0x0
{
     548:	910003fd 	mov	x29, sp
	if (dev_is_pci(dev))
     54c:	f9403002 	ldr	x2, [x0, #96]
     550:	eb01005f 	cmp	x2, x1
     554:	540000a0 	b.eq	568 <arm_smmu_device_group+0x30>  // b.none
		group = generic_device_group(dev);
     558:	94000000 	bl	0 <generic_device_group>
}
     55c:	a8c17bfd 	ldp	x29, x30, [sp], #16
     560:	d50323bf 	autiasp
     564:	d65f03c0 	ret
		group = pci_device_group(dev);
     568:	94000000 	bl	0 <pci_device_group>
}
     56c:	a8c17bfd 	ldp	x29, x30, [sp], #16
     570:	d50323bf 	autiasp
     574:	d65f03c0 	ret

0000000000000578 <arm_smmu_cmdq_build_cmd>:
	memset(cmd, 0, 1 << CMDQ_ENT_SZ_SHIFT);
     578:	a9007c1f 	stp	xzr, xzr, [x0]
{
     57c:	d503233f 	paciasp
	cmd[0] |= FIELD_PREP(CMDQ_0_OP, ent->opcode);
     580:	f9400003 	ldr	x3, [x0]
     584:	39400022 	ldrb	w2, [x1]
     588:	aa030042 	orr	x2, x2, x3
     58c:	f9000002 	str	x2, [x0]
	switch (ent->opcode) {
     590:	39400023 	ldrb	w3, [x1]
     594:	7100487f 	cmp	w3, #0x12
     598:	54001540 	b.eq	840 <arm_smmu_cmdq_build_cmd+0x2c8>  // b.none
     59c:	54000189 	b.ls	5cc <arm_smmu_cmdq_build_cmd+0x54>  // b.plast
     5a0:	7100c07f 	cmp	w3, #0x30
     5a4:	54001080 	b.eq	7b4 <arm_smmu_cmdq_build_cmd+0x23c>  // b.none
     5a8:	54000a29 	b.ls	6ec <arm_smmu_cmdq_build_cmd+0x174>  // b.plast
     5ac:	7101047f 	cmp	w3, #0x41
     5b0:	54000320 	b.eq	614 <arm_smmu_cmdq_build_cmd+0x9c>  // b.none
     5b4:	7101187f 	cmp	w3, #0x46
     5b8:	54001140 	b.eq	7e0 <arm_smmu_cmdq_build_cmd+0x268>  // b.none
     5bc:	7101007f 	cmp	w3, #0x40
     5c0:	54000620 	b.eq	684 <arm_smmu_cmdq_build_cmd+0x10c>  // b.none
		return -ENOENT;
     5c4:	12800023 	mov	w3, #0xfffffffe            	// #-2
     5c8:	14000010 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
	switch (ent->opcode) {
     5cc:	7100107f 	cmp	w3, #0x4
     5d0:	540012e0 	b.eq	82c <arm_smmu_cmdq_build_cmd+0x2b4>  // b.none
     5d4:	54000ce9 	b.ls	770 <arm_smmu_cmdq_build_cmd+0x1f8>  // b.plast
     5d8:	7100187f 	cmp	w3, #0x6
     5dc:	540004a0 	b.eq	670 <arm_smmu_cmdq_build_cmd+0xf8>  // b.none
     5e0:	540011c3 	b.cc	818 <arm_smmu_cmdq_build_cmd+0x2a0>  // b.lo, b.ul, b.last
     5e4:	7100447f 	cmp	w3, #0x11
     5e8:	54fffee1 	b.ne	5c4 <arm_smmu_cmdq_build_cmd+0x4c>  // b.any
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
     5ec:	79401423 	ldrh	w3, [x1, #10]
     5f0:	aa03c042 	orr	x2, x2, x3, lsl #48
     5f4:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_VMID, ent->tlbi.vmid);
     5f8:	79401821 	ldrh	w1, [x1, #12]
	return 0;
     5fc:	52800003 	mov	w3, #0x0                   	// #0
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_VMID, ent->tlbi.vmid);
     600:	aa018042 	orr	x2, x2, x1, lsl #32
     604:	f9000002 	str	x2, [x0]
}
     608:	2a0303e0 	mov	w0, w3
     60c:	d50323bf 	autiasp
     610:	d65f03c0 	ret
		cmd[0] |= FIELD_PREP(CMDQ_0_SSV, ent->substream_valid);
     614:	39400423 	ldrb	w3, [x1, #1]
		cmd[1] |= FIELD_PREP(CMDQ_PRI_1_GRPID, ent->pri.grpid);
     618:	f9400404 	ldr	x4, [x0, #8]
		cmd[0] |= FIELD_PREP(CMDQ_0_SSV, ent->substream_valid);
     61c:	aa032c43 	orr	x3, x2, x3, lsl #11
     620:	f9000003 	str	x3, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_PRI_0_SSID, ent->pri.ssid);
     624:	b9400c22 	ldr	w2, [x1, #12]
     628:	53144c42 	lsl	w2, w2, #12
     62c:	aa030042 	orr	x2, x2, x3
     630:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_PRI_0_SID, ent->pri.sid);
     634:	b9400823 	ldr	w3, [x1, #8]
     638:	aa038042 	orr	x2, x2, x3, lsl #32
     63c:	f9000002 	str	x2, [x0]
		cmd[1] |= FIELD_PREP(CMDQ_PRI_1_GRPID, ent->pri.grpid);
     640:	79402022 	ldrh	w2, [x1, #16]
     644:	92402042 	and	x2, x2, #0x1ff
     648:	aa040042 	orr	x2, x2, x4
     64c:	f9000402 	str	x2, [x0, #8]
		switch (ent->pri.resp) {
     650:	b9401421 	ldr	w1, [x1, #20]
     654:	7100083f 	cmp	w1, #0x2
     658:	54001348 	b.hi	8c0 <arm_smmu_cmdq_build_cmd+0x348>  // b.pmore
		cmd[1] |= FIELD_PREP(CMDQ_PRI_1_RESP, ent->pri.resp);
     65c:	d3747c21 	ubfiz	x1, x1, #12, #32
	return 0;
     660:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_PRI_1_RESP, ent->pri.resp);
     664:	aa020022 	orr	x2, x1, x2
     668:	f9000402 	str	x2, [x0, #8]
		break;
     66c:	17ffffe7 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
		cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
     670:	b9400821 	ldr	w1, [x1, #8]
	return 0;
     674:	52800003 	mov	w3, #0x0                   	// #0
		cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
     678:	aa018042 	orr	x2, x2, x1, lsl #32
     67c:	f9000002 	str	x2, [x0]
		break;
     680:	17ffffe2 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
		cmd[0] |= FIELD_PREP(CMDQ_0_SSV, ent->substream_valid);
     684:	39400424 	ldrb	w4, [x1, #1]
	return 0;
     688:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_ATC_1_SIZE, ent->atc.size);
     68c:	f9400406 	ldr	x6, [x0, #8]
		cmd[0] |= FIELD_PREP(CMDQ_0_SSV, ent->substream_valid);
     690:	aa042c42 	orr	x2, x2, x4, lsl #11
     694:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_ATC_0_GLOBAL, ent->atc.global);
     698:	39406424 	ldrb	w4, [x1, #25]
     69c:	aa042442 	orr	x2, x2, x4, lsl #9
     6a0:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_ATC_0_SSID, ent->atc.ssid);
     6a4:	b9400c24 	ldr	w4, [x1, #12]
     6a8:	53144c84 	lsl	w4, w4, #12
     6ac:	aa020084 	orr	x4, x4, x2
     6b0:	f9000004 	str	x4, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_ATC_0_SID, ent->atc.sid);
     6b4:	b9400825 	ldr	w5, [x1, #8]
     6b8:	aa058084 	orr	x4, x4, x5, lsl #32
     6bc:	f9000004 	str	x4, [x0]
		cmd[1] |= FIELD_PREP(CMDQ_ATC_1_SIZE, ent->atc.size);
     6c0:	39406022 	ldrb	w2, [x1, #24]
     6c4:	92401442 	and	x2, x2, #0x3f
     6c8:	aa060042 	orr	x2, x2, x6
     6cc:	f9000402 	str	x2, [x0, #8]
}
     6d0:	d50323bf 	autiasp
		cmd[1] |= ent->atc.addr & CMDQ_ATC_1_ADDR_MASK;
     6d4:	f9400821 	ldr	x1, [x1, #16]
     6d8:	9274cc21 	and	x1, x1, #0xfffffffffffff000
     6dc:	aa020022 	orr	x2, x1, x2
     6e0:	f9000402 	str	x2, [x0, #8]
}
     6e4:	2a0303e0 	mov	w0, w3
     6e8:	d65f03c0 	ret
	switch (ent->opcode) {
     6ec:	7100a07f 	cmp	w3, #0x28
     6f0:	54fff840 	b.eq	5f8 <arm_smmu_cmdq_build_cmd+0x80>  // b.none
     6f4:	7100a87f 	cmp	w3, #0x2a
     6f8:	540005a1 	b.ne	7ac <arm_smmu_cmdq_build_cmd+0x234>  // b.any
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_NUM, ent->tlbi.num);
     6fc:	39402024 	ldrb	w4, [x1, #8]
	return 0;
     700:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_LEAF, ent->tlbi.leaf);
     704:	f9400406 	ldr	x6, [x0, #8]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_NUM, ent->tlbi.num);
     708:	d3741084 	ubfiz	x4, x4, #12, #5
     70c:	aa020084 	orr	x4, x4, x2
     710:	f9000004 	str	x4, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_SCALE, ent->tlbi.scale);
     714:	39402422 	ldrb	w2, [x1, #9]
     718:	d36c1042 	ubfiz	x2, x2, #20, #5
     71c:	aa040042 	orr	x2, x2, x4
     720:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_VMID, ent->tlbi.vmid);
     724:	79401825 	ldrh	w5, [x1, #12]
     728:	aa058042 	orr	x2, x2, x5, lsl #32
     72c:	f9000002 	str	x2, [x0]
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_LEAF, ent->tlbi.leaf);
     730:	39403824 	ldrb	w4, [x1, #14]
     734:	aa060084 	orr	x4, x4, x6
     738:	f9000404 	str	x4, [x0, #8]
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_TTL, ent->tlbi.ttl);
     73c:	39403c22 	ldrb	w2, [x1, #15]
     740:	d3780442 	ubfiz	x2, x2, #8, #2
     744:	aa040044 	orr	x4, x2, x4
     748:	f9000404 	str	x4, [x0, #8]
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_TG, ent->tlbi.tg);
     74c:	39404022 	ldrb	w2, [x1, #16]
     750:	d3760442 	ubfiz	x2, x2, #10, #2
     754:	aa040042 	orr	x2, x2, x4
     758:	f9000402 	str	x2, [x0, #8]
		cmd[1] |= ent->tlbi.addr & CMDQ_TLBI_1_IPA_MASK;
     75c:	f9400c21 	ldr	x1, [x1, #24]
     760:	92749c21 	and	x1, x1, #0xffffffffff000
     764:	aa020022 	orr	x2, x1, x2
     768:	f9000402 	str	x2, [x0, #8]
		break;
     76c:	17ffffa7 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
	switch (ent->opcode) {
     770:	7100047f 	cmp	w3, #0x1
     774:	54000240 	b.eq	7bc <arm_smmu_cmdq_build_cmd+0x244>  // b.none
     778:	71000c7f 	cmp	w3, #0x3
     77c:	54fff241 	b.ne	5c4 <arm_smmu_cmdq_build_cmd+0x4c>  // b.any
		cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
     780:	b9400825 	ldr	w5, [x1, #8]
	return 0;
     784:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_CFGI_1_LEAF, ent->cfgi.leaf);
     788:	f9400404 	ldr	x4, [x0, #8]
}
     78c:	d50323bf 	autiasp
		cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SID, ent->cfgi.sid);
     790:	aa058042 	orr	x2, x2, x5, lsl #32
     794:	f9000002 	str	x2, [x0]
		cmd[1] |= FIELD_PREP(CMDQ_CFGI_1_LEAF, ent->cfgi.leaf);
     798:	39404021 	ldrb	w1, [x1, #16]
     79c:	aa010081 	orr	x1, x4, x1
     7a0:	f9000401 	str	x1, [x0, #8]
}
     7a4:	2a0303e0 	mov	w0, w3
     7a8:	d65f03c0 	ret
	switch (ent->opcode) {
     7ac:	7100807f 	cmp	w3, #0x20
     7b0:	54fff0a1 	b.ne	5c4 <arm_smmu_cmdq_build_cmd+0x4c>  // b.any
	return 0;
     7b4:	52800003 	mov	w3, #0x0                   	// #0
     7b8:	17ffff94 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
		cmd[0] |= FIELD_PREP(CMDQ_PREFETCH_0_SID, ent->prefetch.sid);
     7bc:	b9400824 	ldr	w4, [x1, #8]
	return 0;
     7c0:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_PREFETCH_1_SIZE, ent->prefetch.size);
     7c4:	f9400405 	ldr	x5, [x0, #8]
		cmd[0] |= FIELD_PREP(CMDQ_PREFETCH_0_SID, ent->prefetch.sid);
     7c8:	aa048042 	orr	x2, x2, x4, lsl #32
     7cc:	f9000002 	str	x2, [x0]
		cmd[1] |= FIELD_PREP(CMDQ_PREFETCH_1_SIZE, ent->prefetch.size);
     7d0:	39403022 	ldrb	w2, [x1, #12]
     7d4:	92401042 	and	x2, x2, #0x1f
     7d8:	aa050042 	orr	x2, x2, x5
     7dc:	17ffffbc 	b	6cc <arm_smmu_cmdq_build_cmd+0x154>
		if (ent->sync.msiaddr) {
     7e0:	f9400424 	ldr	x4, [x1, #8]
			cmd[0] |= FIELD_PREP(CMDQ_SYNC_0_CS, CMDQ_SYNC_0_CS_SEV);
     7e4:	b2730043 	orr	x3, x2, #0x2000
		if (ent->sync.msiaddr) {
     7e8:	b4000104 	cbz	x4, 808 <arm_smmu_cmdq_build_cmd+0x290>
			cmd[0] |= FIELD_PREP(CMDQ_SYNC_0_CS, CMDQ_SYNC_0_CS_IRQ);
     7ec:	b2740043 	orr	x3, x2, #0x1000
     7f0:	f9000003 	str	x3, [x0]
			cmd[1] |= ent->sync.msiaddr & CMDQ_SYNC_1_MSIADDR_MASK;
     7f4:	f9400402 	ldr	x2, [x0, #8]
     7f8:	f9400421 	ldr	x1, [x1, #8]
     7fc:	927ec421 	and	x1, x1, #0xffffffffffffc
     800:	aa010041 	orr	x1, x2, x1
     804:	f9000401 	str	x1, [x0, #8]
		cmd[0] |= FIELD_PREP(CMDQ_SYNC_0_MSIATTR, ARM_SMMU_MEMATTR_OIWB);
     808:	b26a1461 	orr	x1, x3, #0xfc00000
	return 0;
     80c:	52800003 	mov	w3, #0x0                   	// #0
		cmd[0] |= FIELD_PREP(CMDQ_SYNC_0_MSIATTR, ARM_SMMU_MEMATTR_OIWB);
     810:	f9000001 	str	x1, [x0]
		break;
     814:	17ffff7d 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
		cmd[0] |= FIELD_PREP(CMDQ_CFGI_0_SSID, ent->cfgi.ssid);
     818:	b9400c23 	ldr	w3, [x1, #12]
     81c:	53144c63 	lsl	w3, w3, #12
     820:	aa030042 	orr	x2, x2, x3
     824:	f9000002 	str	x2, [x0]
     828:	17ffffd6 	b	780 <arm_smmu_cmdq_build_cmd+0x208>
		cmd[1] |= FIELD_PREP(CMDQ_CFGI_1_RANGE, 31);
     82c:	f9400401 	ldr	x1, [x0, #8]
	return 0;
     830:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_CFGI_1_RANGE, 31);
     834:	b2401021 	orr	x1, x1, #0x1f
     838:	f9000401 	str	x1, [x0, #8]
		break;
     83c:	17ffff73 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_NUM, ent->tlbi.num);
     840:	39402024 	ldrb	w4, [x1, #8]
	return 0;
     844:	52800003 	mov	w3, #0x0                   	// #0
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_LEAF, ent->tlbi.leaf);
     848:	f9400406 	ldr	x6, [x0, #8]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_NUM, ent->tlbi.num);
     84c:	d3741084 	ubfiz	x4, x4, #12, #5
     850:	aa020084 	orr	x4, x4, x2
     854:	f9000004 	str	x4, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_SCALE, ent->tlbi.scale);
     858:	39402422 	ldrb	w2, [x1, #9]
     85c:	d36c1042 	ubfiz	x2, x2, #20, #5
     860:	aa040042 	orr	x2, x2, x4
     864:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_VMID, ent->tlbi.vmid);
     868:	79401825 	ldrh	w5, [x1, #12]
     86c:	aa058042 	orr	x2, x2, x5, lsl #32
     870:	f9000002 	str	x2, [x0]
		cmd[0] |= FIELD_PREP(CMDQ_TLBI_0_ASID, ent->tlbi.asid);
     874:	79401425 	ldrh	w5, [x1, #10]
     878:	aa05c042 	orr	x2, x2, x5, lsl #48
     87c:	f9000002 	str	x2, [x0]
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_LEAF, ent->tlbi.leaf);
     880:	39403824 	ldrb	w4, [x1, #14]
     884:	aa060084 	orr	x4, x4, x6
     888:	f9000404 	str	x4, [x0, #8]
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_TTL, ent->tlbi.ttl);
     88c:	39403c22 	ldrb	w2, [x1, #15]
     890:	d3780442 	ubfiz	x2, x2, #8, #2
     894:	aa040044 	orr	x4, x2, x4
     898:	f9000404 	str	x4, [x0, #8]
		cmd[1] |= FIELD_PREP(CMDQ_TLBI_1_TG, ent->tlbi.tg);
     89c:	39404022 	ldrb	w2, [x1, #16]
     8a0:	d3760442 	ubfiz	x2, x2, #10, #2
     8a4:	aa040042 	orr	x2, x2, x4
     8a8:	f9000402 	str	x2, [x0, #8]
		cmd[1] |= ent->tlbi.addr & CMDQ_TLBI_1_VA_MASK;
     8ac:	f9400c21 	ldr	x1, [x1, #24]
     8b0:	9274cc21 	and	x1, x1, #0xfffffffffffff000
     8b4:	aa020022 	orr	x2, x1, x2
     8b8:	f9000402 	str	x2, [x0, #8]
		break;
     8bc:	17ffff53 	b	608 <arm_smmu_cmdq_build_cmd+0x90>
			return -EINVAL;
     8c0:	128002a3 	mov	w3, #0xffffffea            	// #-22
     8c4:	17ffff51 	b	608 <arm_smmu_cmdq_build_cmd+0x90>

00000000000008c8 <arm_smmu_free_cd_tables>:
{
     8c8:	d503233f 	paciasp
     8cc:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
     8d0:	910003fd 	mov	x29, sp
     8d4:	a901d7f4 	stp	x20, x21, [sp, #24]
	struct arm_smmu_device *smmu = smmu_domain->smmu;
     8d8:	aa0003f4 	mov	x20, x0
{
     8dc:	f90017f6 	str	x22, [sp, #40]
     8e0:	aa0003f6 	mov	x22, x0
	struct arm_smmu_device *smmu = smmu_domain->smmu;
     8e4:	f8440695 	ldr	x21, [x20], #64
     8e8:	f94002a5 	ldr	x5, [x21]
	if (cdcfg->l1_desc) {
     8ec:	f9400a83 	ldr	x3, [x20, #16]
     8f0:	b9401a80 	ldr	w0, [x20, #24]
     8f4:	531a6401 	lsl	w1, w0, #6
     8f8:	b4000363 	cbz	x3, 964 <arm_smmu_free_cd_tables+0x9c>
		for (i = 0; i < cdcfg->num_l1_ents; i++) {
     8fc:	34000260 	cbz	w0, 948 <arm_smmu_free_cd_tables+0x80>
     900:	f9000bb3 	str	x19, [x29, #16]
     904:	52800013 	mov	w19, #0x0                   	// #0
			if (!cdcfg->l1_desc[i].l2ptr)
     908:	937c7e62 	sbfiz	x2, x19, #4, #32
			dmam_free_coherent(smmu->dev, size,
     90c:	aa0503e0 	mov	x0, x5
			if (!cdcfg->l1_desc[i].l2ptr)
     910:	8b020066 	add	x6, x3, x2
			dmam_free_coherent(smmu->dev, size,
     914:	d2a00021 	mov	x1, #0x10000               	// #65536
			if (!cdcfg->l1_desc[i].l2ptr)
     918:	11000673 	add	w19, w19, #0x1
     91c:	f8626864 	ldr	x4, [x3, x2]
			dmam_free_coherent(smmu->dev, size,
     920:	aa0403e2 	mov	x2, x4
			if (!cdcfg->l1_desc[i].l2ptr)
     924:	b40000a4 	cbz	x4, 938 <arm_smmu_free_cd_tables+0x70>
			dmam_free_coherent(smmu->dev, size,
     928:	f94004c3 	ldr	x3, [x6, #8]
     92c:	94000000 	bl	0 <dmam_free_coherent>
     930:	f9400a83 	ldr	x3, [x20, #16]
     934:	f94002a5 	ldr	x5, [x21]
		for (i = 0; i < cdcfg->num_l1_ents; i++) {
     938:	b9401a80 	ldr	w0, [x20, #24]
     93c:	6b13001f 	cmp	w0, w19
     940:	54fffe48 	b.hi	908 <arm_smmu_free_cd_tables+0x40>  // b.pmore
     944:	f9400bb3 	ldr	x19, [x29, #16]
		devm_kfree(smmu->dev, cdcfg->l1_desc);
     948:	aa0503e0 	mov	x0, x5
     94c:	aa0303e1 	mov	x1, x3
     950:	94000000 	bl	0 <devm_kfree>
		cdcfg->l1_desc = NULL;
     954:	f9000a9f 	str	xzr, [x20, #16]
		l1size = cdcfg->num_l1_ents * (CTXDESC_L1_DESC_DWORDS << 3);
     958:	b9401a81 	ldr	w1, [x20, #24]
     95c:	f94002a5 	ldr	x5, [x21]
     960:	531d7021 	lsl	w1, w1, #3
	dmam_free_coherent(smmu->dev, l1size, cdcfg->cdtab, cdcfg->cdtab_dma);
     964:	f9400683 	ldr	x3, [x20, #8]
     968:	aa0503e0 	mov	x0, x5
     96c:	f94022c2 	ldr	x2, [x22, #64]
     970:	94000000 	bl	0 <dmam_free_coherent>
	cdcfg->cdtab_dma = 0;
     974:	f900069f 	str	xzr, [x20, #8]
	cdcfg->cdtab = NULL;
     978:	f90022df 	str	xzr, [x22, #64]
}
     97c:	a941d7f4 	ldp	x20, x21, [sp, #24]
     980:	f94017f6 	ldr	x22, [sp, #40]
     984:	a8c37bfd 	ldp	x29, x30, [sp], #48
     988:	d50323bf 	autiasp
     98c:	d65f03c0 	ret

0000000000000990 <arm_smmu_domain_alloc>:
{
     990:	d503233f 	paciasp
     994:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
	    type != IOMMU_DOMAIN_DMA &&
     998:	51000c01 	sub	w1, w0, #0x3
{
     99c:	910003fd 	mov	x29, sp
     9a0:	f90013f5 	str	x21, [sp, #32]
	    type != IOMMU_DOMAIN_DMA &&
     9a4:	7100043f 	cmp	w1, #0x1
     9a8:	7a418804 	ccmp	w0, #0x1, #0x4, hi  // hi = pmore
     9ac:	540004a1 	b.ne	a40 <arm_smmu_domain_alloc+0xb0>  // b.any
     9b0:	a90153b3 	stp	x19, x20, [x29, #16]
     9b4:	2a0003f4 	mov	w20, w0
		index = kmalloc_index(size);

		if (!index)
			return ZERO_SIZE_PTR;

		return kmem_cache_alloc_trace(
     9b8:	90000000 	adrp	x0, 0 <kmalloc_caches>
	void *ret = kmem_cache_alloc(s, flags);
     9bc:	5281b801 	mov	w1, #0xdc0                 	// #3520
     9c0:	f9400000 	ldr	x0, [x0]
     9c4:	94000000 	bl	0 <kmem_cache_alloc>
     9c8:	aa0003f3 	mov	x19, x0
	if (!smmu_domain)
     9cc:	b4000380 	cbz	x0, a3c <arm_smmu_domain_alloc+0xac>
     9d0:	91022015 	add	x21, x0, #0x88
	if (type == IOMMU_DOMAIN_DMA &&
     9d4:	71000e9f 	cmp	w20, #0x3
     9d8:	54000220 	b.eq	a1c <arm_smmu_domain_alloc+0x8c>  // b.none
	mutex_init(&smmu_domain->init_mutex);
     9dc:	91002260 	add	x0, x19, #0x8
     9e0:	90000002 	adrp	x2, 0 <queue_remove_raw>
     9e4:	90000001 	adrp	x1, 0 <queue_remove_raw>
     9e8:	91000042 	add	x2, x2, #0x0
     9ec:	91000021 	add	x1, x1, #0x0
     9f0:	94000000 	bl	0 <__mutex_init>
	INIT_LIST_HEAD(&smmu_domain->devices);
     9f4:	91034260 	add	x0, x19, #0xd0
	WRITE_ONCE(list->next, list);
     9f8:	f9006a60 	str	x0, [x19, #208]
	list->prev = list;
     9fc:	f9006e60 	str	x0, [x19, #216]
	spin_lock_init(&smmu_domain->devices_lock);
     a00:	b900e27f 	str	wzr, [x19, #224]
     a04:	a94153b3 	ldp	x19, x20, [x29, #16]
}
     a08:	aa1503e0 	mov	x0, x21
     a0c:	f94013f5 	ldr	x21, [sp, #32]
     a10:	a8c37bfd 	ldp	x29, x30, [sp], #48
     a14:	d50323bf 	autiasp
     a18:	d65f03c0 	ret
	    iommu_get_dma_cookie(&smmu_domain->domain)) {
     a1c:	aa1503e0 	mov	x0, x21
     a20:	94000000 	bl	0 <iommu_get_dma_cookie>
	if (type == IOMMU_DOMAIN_DMA &&
     a24:	34fffdc0 	cbz	w0, 9dc <arm_smmu_domain_alloc+0x4c>
		kfree(smmu_domain);
     a28:	aa1303e0 	mov	x0, x19
		return NULL;
     a2c:	d2800015 	mov	x21, #0x0                   	// #0
		kfree(smmu_domain);
     a30:	94000000 	bl	0 <kfree>
		return NULL;
     a34:	a94153b3 	ldp	x19, x20, [x29, #16]
     a38:	17fffff4 	b	a08 <arm_smmu_domain_alloc+0x78>
     a3c:	a94153b3 	ldp	x19, x20, [x29, #16]
		return NULL;
     a40:	d2800015 	mov	x21, #0x0                   	// #0
}
     a44:	aa1503e0 	mov	x0, x21
     a48:	f94013f5 	ldr	x21, [sp, #32]
     a4c:	a8c37bfd 	ldp	x29, x30, [sp], #48
     a50:	d50323bf 	autiasp
     a54:	d65f03c0 	ret

0000000000000a58 <arm_smmu_cmdq_free_bitmap>:
{
     a58:	d503233f 	paciasp
     a5c:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
     a60:	910003fd 	mov	x29, sp
	bitmap_free(bitmap);
     a64:	94000000 	bl	0 <bitmap_free>
}
     a68:	a8c17bfd 	ldp	x29, x30, [sp], #16
     a6c:	d50323bf 	autiasp
     a70:	d65f03c0 	ret
     a74:	d503201f 	nop

0000000000000a78 <arm_smmu_init_one_queue>:
{
     a78:	d503233f 	paciasp
     a7c:	a9ba7bfd 	stp	x29, x30, [sp, #-96]!
     a80:	910003fd 	mov	x29, sp
     a84:	a90153f3 	stp	x19, x20, [sp, #16]
     a88:	aa0003f4 	mov	x20, x0
     a8c:	a9025bf5 	stp	x21, x22, [sp, #32]
     a90:	aa0403f5 	mov	x21, x4
     a94:	a90363f7 	stp	x23, x24, [sp, #48]
		qsz = ((1 << q->llq.max_n_shift) * dwords) << 3;
     a98:	52800036 	mov	w22, #0x1                   	// #1
{
     a9c:	a9046bf9 	stp	x25, x26, [sp, #64]
     aa0:	aa0203f8 	mov	x24, x2
     aa4:	f9002bfb 	str	x27, [sp, #80]
     aa8:	aa0303f9 	mov	x25, x3
     aac:	aa0503fa 	mov	x26, x5
     ab0:	aa0103fb 	mov	x27, x1
     ab4:	91024037 	add	x23, x1, #0x90
     ab8:	b9404033 	ldr	w19, [x1, #64]
     abc:	14000005 	b	ad0 <arm_smmu_init_one_queue+0x58>
		if (q->base || qsz < PAGE_SIZE)
     ac0:	540007a9 	b.ls	bb4 <arm_smmu_init_one_queue+0x13c>  // b.plast
		q->llq.max_n_shift--;
     ac4:	b9404373 	ldr	w19, [x27, #64]
     ac8:	51000673 	sub	w19, w19, #0x1
     acc:	b9004373 	str	w19, [x27, #64]
		qsz = ((1 << q->llq.max_n_shift) * dwords) << 3;
     ad0:	1ad322d3 	lsl	w19, w22, w19
#endif /* CONFIG_DMA_DECLARE_COHERENT */

static inline void *dmam_alloc_coherent(struct device *dev, size_t size,
		dma_addr_t *dma_handle, gfp_t gfp)
{
	return dmam_alloc_attrs(dev, size, dma_handle, gfp,
     ad4:	f9400280 	ldr	x0, [x20]
     ad8:	93407e73 	sxtw	x19, w19
     adc:	d2800004 	mov	x4, #0x0                   	// #0
     ae0:	52819803 	mov	w3, #0xcc0                 	// #3264
     ae4:	aa1703e2 	mov	x2, x23
     ae8:	9b157e73 	mul	x19, x19, x21
     aec:	d37df273 	lsl	x19, x19, #3
     af0:	aa1303e1 	mov	x1, x19
     af4:	94000000 	bl	0 <dmam_alloc_attrs>
		q->base = dmam_alloc_coherent(smmu->dev, qsz, &q->base_dma,
     af8:	f9004760 	str	x0, [x27, #136]
		if (q->base || qsz < PAGE_SIZE)
     afc:	f13ffe7f 	cmp	x19, #0xfff
     b00:	b4fffe00 	cbz	x0, ac0 <arm_smmu_init_one_queue+0x48>
	if (!WARN_ON(q->base_dma & (qsz - 1))) {
     b04:	f9404b60 	ldr	x0, [x27, #144]
     b08:	d1000673 	sub	x19, x19, #0x1
     b0c:	ea00027f 	tst	x19, x0
     b10:	54000701 	b.ne	bf0 <arm_smmu_init_one_queue+0x178>  // b.any
		dev_info(smmu->dev, "allocated %u entries for %s\n",
     b14:	f9400280 	ldr	x0, [x20]
     b18:	90000001 	adrp	x1, 0 <queue_remove_raw>
     b1c:	b9404362 	ldr	w2, [x27, #64]
     b20:	aa1a03e3 	mov	x3, x26
     b24:	91000021 	add	x1, x1, #0x0
     b28:	1ac222c2 	lsl	w2, w22, w2
     b2c:	94000000 	bl	0 <_dev_info>
	q->prod_reg	= arm_smmu_page1_fixup(prod_off, smmu);
     b30:	f9400680 	ldr	x0, [x20, #8]
	if (offset > SZ_64K)
     b34:	f140431f 	cmp	x24, #0x10, lsl #12
	return smmu->base + offset;
     b38:	8b180000 	add	x0, x0, x24
	if (offset > SZ_64K)
     b3c:	54000089 	b.ls	b4c <arm_smmu_init_one_queue+0xd4>  // b.plast
		return smmu->page1 + offset - SZ_64K;
     b40:	f9400a80 	ldr	x0, [x20, #16]
     b44:	d1404318 	sub	x24, x24, #0x10, lsl #12
     b48:	8b180000 	add	x0, x0, x24
	q->prod_reg	= arm_smmu_page1_fixup(prod_off, smmu);
     b4c:	f9005760 	str	x0, [x27, #168]
	if (offset > SZ_64K)
     b50:	f140433f 	cmp	x25, #0x10, lsl #12
	q->cons_reg	= arm_smmu_page1_fixup(cons_off, smmu);
     b54:	f9400680 	ldr	x0, [x20, #8]
	return smmu->base + offset;
     b58:	8b190000 	add	x0, x0, x25
	if (offset > SZ_64K)
     b5c:	54000089 	b.ls	b6c <arm_smmu_init_one_queue+0xf4>  // b.plast
		return smmu->page1 + offset - SZ_64K;
     b60:	f9400a80 	ldr	x0, [x20, #16]
     b64:	d1404339 	sub	x25, x25, #0x10, lsl #12
     b68:	8b190000 	add	x0, x0, x25
	q->q_base |= q->base_dma & Q_BASE_ADDR_MASK;
     b6c:	f9404b61 	ldr	x1, [x27, #144]
	q->q_base |= FIELD_PREP(Q_BASE_LOG2SIZE, q->llq.max_n_shift);
     b70:	b9404362 	ldr	w2, [x27, #64]
	q->q_base |= q->base_dma & Q_BASE_ADDR_MASK;
     b74:	927bb821 	and	x1, x1, #0xfffffffffffe0
	q->llq.prod = q->llq.cons = 0;
     b78:	f900037f 	str	xzr, [x27]
	q->q_base |= FIELD_PREP(Q_BASE_LOG2SIZE, q->llq.max_n_shift);
     b7c:	92401042 	and	x2, x2, #0x1f
	q->q_base |= q->base_dma & Q_BASE_ADDR_MASK;
     b80:	b2420021 	orr	x1, x1, #0x4000000000000000
	q->cons_reg	= arm_smmu_page1_fixup(cons_off, smmu);
     b84:	f9005b60 	str	x0, [x27, #176]
	q->q_base |= FIELD_PREP(Q_BASE_LOG2SIZE, q->llq.max_n_shift);
     b88:	aa020021 	orr	x1, x1, x2
	q->ent_dwords	= dwords;
     b8c:	a909d761 	stp	x1, x21, [x27, #152]
	return 0;
     b90:	52800000 	mov	w0, #0x0                   	// #0
}
     b94:	a94153f3 	ldp	x19, x20, [sp, #16]
     b98:	a9425bf5 	ldp	x21, x22, [sp, #32]
     b9c:	a94363f7 	ldp	x23, x24, [sp, #48]
     ba0:	a9446bf9 	ldp	x25, x26, [sp, #64]
     ba4:	f9402bfb 	ldr	x27, [sp, #80]
     ba8:	a8c67bfd 	ldp	x29, x30, [sp], #96
     bac:	d50323bf 	autiasp
     bb0:	d65f03c0 	ret
		dev_err(smmu->dev,
     bb4:	f9400280 	ldr	x0, [x20]
     bb8:	aa1a03e3 	mov	x3, x26
     bbc:	aa1303e2 	mov	x2, x19
     bc0:	90000001 	adrp	x1, 0 <queue_remove_raw>
     bc4:	91000021 	add	x1, x1, #0x0
     bc8:	94000000 	bl	0 <_dev_err>
}
     bcc:	f9402bfb 	ldr	x27, [sp, #80]
		return -ENOMEM;
     bd0:	12800160 	mov	w0, #0xfffffff4            	// #-12
}
     bd4:	a94153f3 	ldp	x19, x20, [sp, #16]
     bd8:	a9425bf5 	ldp	x21, x22, [sp, #32]
     bdc:	a94363f7 	ldp	x23, x24, [sp, #48]
     be0:	a9446bf9 	ldp	x25, x26, [sp, #64]
     be4:	a8c67bfd 	ldp	x29, x30, [sp], #96
     be8:	d50323bf 	autiasp
     bec:	d65f03c0 	ret
	if (!WARN_ON(q->base_dma & (qsz - 1))) {
     bf0:	d4210000 	brk	#0x800
     bf4:	17ffffcf 	b	b30 <arm_smmu_init_one_queue+0xb8>

0000000000000bf8 <arm_smmu_free_msis>:
{
     bf8:	d503233f 	paciasp
     bfc:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
     c00:	910003fd 	mov	x29, sp
	platform_msi_domain_free_irqs(dev);
     c04:	94000000 	bl	0 <platform_msi_domain_free_irqs>
}
     c08:	a8c17bfd 	ldp	x29, x30, [sp], #16
     c0c:	d50323bf 	autiasp
     c10:	d65f03c0 	ret
     c14:	d503201f 	nop

0000000000000c18 <queue_sync_prod_in.isra.23>:
static int queue_sync_prod_in(struct arm_smmu_queue *q)
     c18:	d503233f 	paciasp

#define __raw_readl __raw_readl
static __always_inline u32 __raw_readl(const volatile void __iomem *addr)
{
	u32 val;
	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
     c1c:	b9400021 	ldr	w1, [x1]
	if (Q_OVF(prod) != Q_OVF(q->llq.prod))
     c20:	b9400003 	ldr	w3, [x0]
		ret = -EOVERFLOW;
     c24:	12800942 	mov	w2, #0xffffffb5            	// #-75
	q->llq.prod = prod;
     c28:	b9000001 	str	w1, [x0]
}
     c2c:	d50323bf 	autiasp
	if (Q_OVF(prod) != Q_OVF(q->llq.prod))
     c30:	4a030021 	eor	w1, w1, w3
		ret = -EOVERFLOW;
     c34:	7100003f 	cmp	w1, #0x0
}
     c38:	1a9fb040 	csel	w0, w2, wzr, lt  // lt = tstop
     c3c:	d65f03c0 	ret

0000000000000c40 <arm_smmu_evtq_thread>:
{
     c40:	d503233f 	paciasp
     c44:	a9b87bfd 	stp	x29, x30, [sp, #-128]!
     c48:	910003fd 	mov	x29, sp
     c4c:	a90153f3 	stp	x19, x20, [sp, #16]
     c50:	aa0103f3 	mov	x19, x1
     c54:	a9025bf5 	stp	x21, x22, [sp, #32]
     c58:	90000015 	adrp	x21, 0 <__stack_chk_guard>
     c5c:	a90363f7 	stp	x23, x24, [sp, #48]
     c60:	910002a0 	add	x0, x21, #0x0
			dev_err(smmu->dev, "EVTQ overflow detected -- events lost\n");
     c64:	90000018 	adrp	x24, 0 <queue_remove_raw>
			dev_info(smmu->dev, "event 0x%02x received:\n", id);
     c68:	90000017 	adrp	x23, 0 <queue_remove_raw>
{
     c6c:	f9400001 	ldr	x1, [x0]
     c70:	f9003fa1 	str	x1, [x29, #120]
     c74:	d2800001 	mov	x1, #0x0                   	// #0
	struct arm_smmu_queue *q = &smmu->evtq.q;
     c78:	91050274 	add	x20, x19, #0x140
			dev_err(smmu->dev, "EVTQ overflow detected -- events lost\n");
     c7c:	91000318 	add	x24, x24, #0x0
			dev_info(smmu->dev, "event 0x%02x received:\n", id);
     c80:	910002f7 	add	x23, x23, #0x0
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
     c84:	52800036 	mov	w22, #0x1                   	// #1
		while (!queue_remove_raw(q, evt)) {
     c88:	910163a1 	add	x1, x29, #0x58
     c8c:	aa1403e0 	mov	x0, x20
     c90:	97fffcdc 	bl	0 <queue_remove_raw>
     c94:	34000420 	cbz	w0, d18 <arm_smmu_evtq_thread+0xd8>
		if (queue_sync_prod_in(q) == -EOVERFLOW)
     c98:	f940f661 	ldr	x1, [x19, #488]
     c9c:	aa1403e0 	mov	x0, x20
     ca0:	97ffffde 	bl	c18 <queue_sync_prod_in.isra.23>
     ca4:	31012c1f 	cmn	w0, #0x4b
     ca8:	540005c0 	b.eq	d60 <arm_smmu_evtq_thread+0x120>  // b.none
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
     cac:	b9418260 	ldr	w0, [x19, #384]
	} while (!queue_empty(llq));
     cb0:	b9414261 	ldr	w1, [x19, #320]
     cb4:	b9414662 	ldr	w2, [x19, #324]
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
     cb8:	1ac022c0 	lsl	w0, w22, w0
     cbc:	51000403 	sub	w3, w0, #0x1
     cc0:	4a020025 	eor	w5, w1, w2
     cc4:	2a000064 	orr	w4, w3, w0
     cc8:	6a0400bf 	tst	w5, w4
     ccc:	54fffde1 	b.ne	c88 <arm_smmu_evtq_thread+0x48>  // b.any
	llq->cons = Q_OVF(llq->prod) | Q_WRP(llq, llq->cons) |
     cd0:	12010021 	and	w1, w1, #0x80000000
     cd4:	0a000040 	and	w0, w2, w0
     cd8:	2a000020 	orr	w0, w1, w0
		    Q_IDX(llq, llq->cons);
     cdc:	0a030042 	and	w2, w2, w3
	llq->cons = Q_OVF(llq->prod) | Q_WRP(llq, llq->cons) |
     ce0:	2a020000 	orr	w0, w0, w2
     ce4:	b9000680 	str	w0, [x20, #4]
}
     ce8:	910002b5 	add	x21, x21, #0x0
     cec:	52800020 	mov	w0, #0x1                   	// #1
     cf0:	f9403fa2 	ldr	x2, [x29, #120]
     cf4:	f94002a1 	ldr	x1, [x21]
     cf8:	ca010041 	eor	x1, x2, x1
     cfc:	b50003a1 	cbnz	x1, d70 <arm_smmu_evtq_thread+0x130>
     d00:	a94153f3 	ldp	x19, x20, [sp, #16]
     d04:	a9425bf5 	ldp	x21, x22, [sp, #32]
     d08:	a94363f7 	ldp	x23, x24, [sp, #48]
     d0c:	a8c87bfd 	ldp	x29, x30, [sp], #128
     d10:	d50323bf 	autiasp
     d14:	d65f03c0 	ret
     d18:	a9046bb9 	stp	x25, x26, [x29, #64]
			dev_info(smmu->dev, "event 0x%02x received:\n", id);
     d1c:	aa1703e1 	mov	x1, x23
     d20:	394163a2 	ldrb	w2, [x29, #88]
     d24:	9000001a 	adrp	x26, 0 <queue_remove_raw>
     d28:	f9400260 	ldr	x0, [x19]
     d2c:	d2800019 	mov	x25, #0x0                   	// #0
				dev_info(smmu->dev, "\t0x%016llx\n",
     d30:	9100035a 	add	x26, x26, #0x0
			dev_info(smmu->dev, "event 0x%02x received:\n", id);
     d34:	94000000 	bl	0 <_dev_info>
				dev_info(smmu->dev, "\t0x%016llx\n",
     d38:	910163a0 	add	x0, x29, #0x58
     d3c:	aa1a03e1 	mov	x1, x26
     d40:	f8797802 	ldr	x2, [x0, x25, lsl #3]
     d44:	91000739 	add	x25, x25, #0x1
     d48:	f9400260 	ldr	x0, [x19]
     d4c:	94000000 	bl	0 <_dev_info>
			for (i = 0; i < ARRAY_SIZE(evt); ++i)
     d50:	f100133f 	cmp	x25, #0x4
     d54:	54ffff21 	b.ne	d38 <arm_smmu_evtq_thread+0xf8>  // b.any
     d58:	a9446bb9 	ldp	x25, x26, [x29, #64]
     d5c:	17ffffcb 	b	c88 <arm_smmu_evtq_thread+0x48>
			dev_err(smmu->dev, "EVTQ overflow detected -- events lost\n");
     d60:	f9400260 	ldr	x0, [x19]
     d64:	aa1803e1 	mov	x1, x24
     d68:	94000000 	bl	0 <_dev_err>
     d6c:	17ffffd0 	b	cac <arm_smmu_evtq_thread+0x6c>
     d70:	a9046bb9 	stp	x25, x26, [x29, #64]
}
     d74:	94000000 	bl	0 <__stack_chk_fail>

0000000000000d78 <arm_smmu_domain_get_attr>:
	switch (domain->type) {
     d78:	b9400003 	ldr	w3, [x0]
{
     d7c:	d503233f 	paciasp
	switch (domain->type) {
     d80:	7100047f 	cmp	w3, #0x1
     d84:	540001a0 	b.eq	db8 <arm_smmu_domain_get_attr+0x40>  // b.none
     d88:	71000c7f 	cmp	w3, #0x3
     d8c:	54000101 	b.ne	dac <arm_smmu_domain_get_attr+0x34>  // b.any
		switch (attr) {
     d90:	71001c3f 	cmp	w1, #0x7
     d94:	54000241 	b.ne	ddc <arm_smmu_domain_get_attr+0x64>  // b.any
			*(int *)data = smmu_domain->non_strict;
     d98:	385a8001 	ldurb	w1, [x0, #-88]
}
     d9c:	d50323bf 	autiasp
			return 0;
     da0:	52800000 	mov	w0, #0x0                   	// #0
			*(int *)data = smmu_domain->non_strict;
     da4:	b9000041 	str	w1, [x2]
}
     da8:	d65f03c0 	ret
		return -EINVAL;
     dac:	128002a0 	mov	w0, #0xffffffea            	// #-22
}
     db0:	d50323bf 	autiasp
     db4:	d65f03c0 	ret
		switch (attr) {
     db8:	7100183f 	cmp	w1, #0x6
     dbc:	54000101 	b.ne	ddc <arm_smmu_domain_get_attr+0x64>  // b.any
			*(int *)data = (smmu_domain->stage == ARM_SMMU_DOMAIN_NESTED);
     dc0:	b85b0001 	ldur	w1, [x0, #-80]
}
     dc4:	d50323bf 	autiasp
			return 0;
     dc8:	52800000 	mov	w0, #0x0                   	// #0
			*(int *)data = (smmu_domain->stage == ARM_SMMU_DOMAIN_NESTED);
     dcc:	7100083f 	cmp	w1, #0x2
     dd0:	1a9f17e1 	cset	w1, eq  // eq = none
     dd4:	b9000041 	str	w1, [x2]
}
     dd8:	d65f03c0 	ret
			return -ENODEV;
     ddc:	12800240 	mov	w0, #0xffffffed            	// #-19
     de0:	17fffff4 	b	db0 <arm_smmu_domain_get_attr+0x38>
     de4:	d503201f 	nop

0000000000000de8 <arm_smmu_write_reg_sync.isra.32>:
static int arm_smmu_write_reg_sync(struct arm_smmu_device *smmu, u32 val,
     de8:	d503233f 	paciasp
     dec:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
     df0:	910003fd 	mov	x29, sp
     df4:	a90153f3 	stp	x19, x20, [sp, #16]
     df8:	2a0103f4 	mov	w20, w1
     dfc:	a9025bf5 	stp	x21, x22, [sp, #32]
     e00:	aa0003f5 	mov	x21, x0
     e04:	2a0303f3 	mov	w19, w3
	writel_relaxed(val, smmu->base + reg_off);
     e08:	f9400000 	ldr	x0, [x0]
     e0c:	8b224002 	add	x2, x0, w2, uxtw
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
     e10:	b9000041 	str	w1, [x2]
	return ktime_to_ms(ktime_sub(later, earlier));
}

static inline ktime_t ktime_add_us(const ktime_t kt, const u64 usec)
{
	return ktime_add_ns(kt, usec * NSEC_PER_USEC);
     e14:	d2994016 	mov	x22, #0xca00                	// #51712
	return readl_relaxed_poll_timeout(smmu->base + ack_off, reg, reg == val,
     e18:	94000000 	bl	0 <ktime_get>
     e1c:	f2a77356 	movk	x22, #0x3b9a, lsl #16
     e20:	8b160016 	add	x22, x0, x22
     e24:	14000007 	b	e40 <arm_smmu_write_reg_sync.isra.32+0x58>
     e28:	94000000 	bl	0 <ktime_get>
	if (cmp1 > cmp2)
     e2c:	eb0002df 	cmp	x22, x0
     e30:	540001eb 	b.lt	e6c <arm_smmu_write_reg_sync.isra.32+0x84>  // b.tstop
     e34:	d2800021 	mov	x1, #0x1                   	// #1
     e38:	aa0103e0 	mov	x0, x1
     e3c:	94000000 	bl	0 <usleep_range>
     e40:	f94002a0 	ldr	x0, [x21]
     e44:	8b130000 	add	x0, x0, x19
	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
     e48:	b9400000 	ldr	w0, [x0]
     e4c:	6b00029f 	cmp	w20, w0
     e50:	54fffec1 	b.ne	e28 <arm_smmu_write_reg_sync.isra.32+0x40>  // b.any
     e54:	52800000 	mov	w0, #0x0                   	// #0
}
     e58:	a94153f3 	ldp	x19, x20, [sp, #16]
     e5c:	a9425bf5 	ldp	x21, x22, [sp, #32]
     e60:	a8c37bfd 	ldp	x29, x30, [sp], #48
     e64:	d50323bf 	autiasp
     e68:	d65f03c0 	ret
	return readl_relaxed_poll_timeout(smmu->base + ack_off, reg, reg == val,
     e6c:	f94002a0 	ldr	x0, [x21]
     e70:	8b130013 	add	x19, x0, x19
     e74:	b9400273 	ldr	w19, [x19]
     e78:	12800da0 	mov	w0, #0xffffff92            	// #-110
     e7c:	6b13029f 	cmp	w20, w19
     e80:	54fffea0 	b.eq	e54 <arm_smmu_write_reg_sync.isra.32+0x6c>  // b.none
     e84:	17fffff5 	b	e58 <arm_smmu_write_reg_sync.isra.32+0x70>

0000000000000e88 <arm_smmu_device_disable>:
{
     e88:	d503233f 	paciasp
     e8c:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
	ret = arm_smmu_write_reg_sync(smmu, 0, ARM_SMMU_CR0, ARM_SMMU_CR0ACK);
     e90:	52800483 	mov	w3, #0x24                  	// #36
     e94:	52800402 	mov	w2, #0x20                  	// #32
{
     e98:	910003fd 	mov	x29, sp
     e9c:	a90153f3 	stp	x19, x20, [sp, #16]
	ret = arm_smmu_write_reg_sync(smmu, 0, ARM_SMMU_CR0, ARM_SMMU_CR0ACK);
     ea0:	52800001 	mov	w1, #0x0                   	// #0
{
     ea4:	aa0003f4 	mov	x20, x0
	ret = arm_smmu_write_reg_sync(smmu, 0, ARM_SMMU_CR0, ARM_SMMU_CR0ACK);
     ea8:	91002000 	add	x0, x0, #0x8
     eac:	97ffffcf 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
     eb0:	2a0003f3 	mov	w19, w0
	if (ret)
     eb4:	350000c0 	cbnz	w0, ecc <arm_smmu_device_disable+0x44>
}
     eb8:	2a1303e0 	mov	w0, w19
     ebc:	a94153f3 	ldp	x19, x20, [sp, #16]
     ec0:	a8c27bfd 	ldp	x29, x30, [sp], #32
     ec4:	d50323bf 	autiasp
     ec8:	d65f03c0 	ret
		dev_err(smmu->dev, "failed to clear cr0\n");
     ecc:	f9400280 	ldr	x0, [x20]
     ed0:	90000001 	adrp	x1, 0 <queue_remove_raw>
     ed4:	91000021 	add	x1, x1, #0x0
     ed8:	94000000 	bl	0 <_dev_err>
	return ret;
     edc:	17fffff7 	b	eb8 <arm_smmu_device_disable+0x30>

0000000000000ee0 <arm_smmu_device_remove>:

	return arm_smmu_set_bus_ops(&arm_smmu_ops);
}

static int arm_smmu_device_remove(struct platform_device *pdev)
{
     ee0:	d503233f 	paciasp
     ee4:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
     ee8:	910003fd 	mov	x29, sp
     eec:	a90153f3 	stp	x19, x20, [sp, #16]
extern int __platform_driver_probe(struct platform_driver *driver,
		int (*probe)(struct platform_device *), struct module *module);

static inline void *platform_get_drvdata(const struct platform_device *pdev)
{
	return dev_get_drvdata(&pdev->dev);
     ef0:	f9404413 	ldr	x19, [x0, #136]
	struct arm_smmu_device *smmu = platform_get_drvdata(pdev);

	arm_smmu_set_bus_ops(NULL);
     ef4:	d2800000 	mov	x0, #0x0                   	// #0
     ef8:	97fffcee 	bl	2b0 <arm_smmu_set_bus_ops>
	iommu_device_unregister(&smmu->iommu);
     efc:	d2846c00 	mov	x0, #0x2360                	// #9056
     f00:	8b000274 	add	x20, x19, x0
     f04:	aa1403e0 	mov	x0, x20
     f08:	94000000 	bl	0 <iommu_device_unregister>
	iommu_device_sysfs_remove(&smmu->iommu);
     f0c:	aa1403e0 	mov	x0, x20
     f10:	94000000 	bl	0 <iommu_device_sysfs_remove>
	arm_smmu_device_disable(smmu);
     f14:	aa1303e0 	mov	x0, x19
     f18:	97ffffdc 	bl	e88 <arm_smmu_device_disable>

	return 0;
}
     f1c:	52800000 	mov	w0, #0x0                   	// #0
     f20:	a94153f3 	ldp	x19, x20, [sp, #16]
     f24:	a8c27bfd 	ldp	x29, x30, [sp], #32
     f28:	d50323bf 	autiasp
     f2c:	d65f03c0 	ret

0000000000000f30 <arm_smmu_device_shutdown>:

static void arm_smmu_device_shutdown(struct platform_device *pdev)
{
     f30:	d503233f 	paciasp
     f34:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
     f38:	910003fd 	mov	x29, sp
	arm_smmu_device_remove(pdev);
     f3c:	97ffffe9 	bl	ee0 <arm_smmu_device_remove>
}
     f40:	a8c17bfd 	ldp	x29, x30, [sp], #16
     f44:	d50323bf 	autiasp
     f48:	d65f03c0 	ret
     f4c:	d503201f 	nop

0000000000000f50 <arm_smmu_gerror_handler>:
{
     f50:	d503233f 	paciasp
     f54:	a9b77bfd 	stp	x29, x30, [sp, #-144]!
     f58:	910003fd 	mov	x29, sp
     f5c:	a9025bf5 	stp	x21, x22, [sp, #32]
     f60:	aa0103f6 	mov	x22, x1
     f64:	a90153f3 	stp	x19, x20, [sp, #16]
     f68:	90000014 	adrp	x20, 0 <__stack_chk_guard>
     f6c:	91000280 	add	x0, x20, #0x0
     f70:	f9400001 	ldr	x1, [x0]
     f74:	f90047a1 	str	x1, [x29, #136]
     f78:	d2800001 	mov	x1, #0x0                   	// #0
	gerror = readl_relaxed(smmu->base + ARM_SMMU_GERROR);
     f7c:	f94006c0 	ldr	x0, [x22, #8]
     f80:	91018015 	add	x21, x0, #0x60
     f84:	b94002b5 	ldr	w21, [x21]
	gerrorn = readl_relaxed(smmu->base + ARM_SMMU_GERRORN);
     f88:	91019013 	add	x19, x0, #0x64
     f8c:	b9400273 	ldr	w19, [x19]
	active = gerror ^ gerrorn;
     f90:	4a150273 	eor	w19, w19, w21
	if (!(active & GERROR_ERR_MASK))
     f94:	52801fa1 	mov	w1, #0xfd                  	// #253
     f98:	52800000 	mov	w0, #0x0                   	// #0
     f9c:	6a01027f 	tst	w19, w1
     fa0:	54000161 	b.ne	fcc <arm_smmu_gerror_handler+0x7c>  // b.any
}
     fa4:	91000294 	add	x20, x20, #0x0
     fa8:	f94047a2 	ldr	x2, [x29, #136]
     fac:	f9400281 	ldr	x1, [x20]
     fb0:	ca010041 	eor	x1, x2, x1
     fb4:	b5000321 	cbnz	x1, 1018 <arm_smmu_gerror_handler+0xc8>
     fb8:	a94153f3 	ldp	x19, x20, [sp, #16]
     fbc:	a9425bf5 	ldp	x21, x22, [sp, #32]
     fc0:	a8c97bfd 	ldp	x29, x30, [sp], #144
     fc4:	d50323bf 	autiasp
     fc8:	d65f03c0 	ret
	dev_warn(smmu->dev,
     fcc:	f94002c0 	ldr	x0, [x22]
     fd0:	90000001 	adrp	x1, 0 <queue_remove_raw>
     fd4:	2a1303e2 	mov	w2, w19
     fd8:	91000021 	add	x1, x1, #0x0
     fdc:	94000000 	bl	0 <_dev_warn>
	if (active & GERROR_SFM_ERR) {
     fe0:	37400dd3 	tbnz	w19, #8, 1198 <arm_smmu_gerror_handler+0x248>
	if (active & GERROR_MSI_GERROR_ABT_ERR)
     fe4:	37380cf3 	tbnz	w19, #7, 1180 <arm_smmu_gerror_handler+0x230>
	if (active & GERROR_MSI_PRIQ_ABT_ERR)
     fe8:	37300c13 	tbnz	w19, #6, 1168 <arm_smmu_gerror_handler+0x218>
	if (active & GERROR_MSI_EVTQ_ABT_ERR)
     fec:	37280b33 	tbnz	w19, #5, 1150 <arm_smmu_gerror_handler+0x200>
	if (active & GERROR_MSI_CMDQ_ABT_ERR)
     ff0:	37200a53 	tbnz	w19, #4, 1138 <arm_smmu_gerror_handler+0x1e8>
	if (active & GERROR_PRIQ_ABT_ERR)
     ff4:	37180973 	tbnz	w19, #3, 1120 <arm_smmu_gerror_handler+0x1d0>
	if (active & GERROR_EVTQ_ABT_ERR)
     ff8:	371008b3 	tbnz	w19, #2, 110c <arm_smmu_gerror_handler+0x1bc>
	if (active & GERROR_CMDQ_ERR)
     ffc:	37000153 	tbnz	w19, #0, 1024 <arm_smmu_gerror_handler+0xd4>
	writel(gerror, smmu->base + ARM_SMMU_GERRORN);
    1000:	d50332bf 	dmb	oshst
    1004:	f94006c0 	ldr	x0, [x22, #8]
    1008:	91019000 	add	x0, x0, #0x64
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    100c:	b9000015 	str	w21, [x0]
	return IRQ_HANDLED;
    1010:	52800020 	mov	w0, #0x1                   	// #1
    1014:	17ffffe4 	b	fa4 <arm_smmu_gerror_handler+0x54>
    1018:	a90363b7 	stp	x23, x24, [x29, #48]
    101c:	f90023b9 	str	x25, [x29, #64]
}
    1020:	94000000 	bl	0 <__stack_chk_fail>
    1024:	a90363b7 	stp	x23, x24, [x29, #48]
	u32 cons = readl_relaxed(q->cons_reg);
    1028:	910102d7 	add	x23, x22, #0x40
	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    102c:	f9405ae0 	ldr	x0, [x23, #176]
    1030:	b9400013 	ldr	w19, [x0]
	struct arm_smmu_cmdq_ent cmd_sync = {
    1034:	a905ffbf 	stp	xzr, xzr, [x29, #88]
    1038:	528008c0 	mov	w0, #0x46                  	// #70
    103c:	390163a0 	strb	w0, [x29, #88]
	u32 idx = FIELD_GET(CMDQ_CONS_ERR, cons);
    1040:	d3587a78 	ubfx	x24, x19, #24, #7
	struct arm_smmu_cmdq_ent cmd_sync = {
    1044:	a906ffbf 	stp	xzr, xzr, [x29, #104]
	dev_err(smmu->dev, "CMDQ error (cons 0x%08x): %s\n", cons,
    1048:	f1000f1f 	cmp	x24, #0x3
    104c:	f94002c0 	ldr	x0, [x22]
    1050:	54000428 	b.hi	10d4 <arm_smmu_gerror_handler+0x184>  // b.pmore
    1054:	90000003 	adrp	x3, 0 <queue_remove_raw>
    1058:	91000063 	add	x3, x3, #0x0
    105c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1060:	2a1303e2 	mov	w2, w19
    1064:	91000021 	add	x1, x1, #0x0
    1068:	f8787863 	ldr	x3, [x3, x24, lsl #3]
    106c:	94000000 	bl	0 <_dev_err>
	switch (idx) {
    1070:	71000b1f 	cmp	w24, #0x2
    1074:	54000400 	b.eq	10f4 <arm_smmu_gerror_handler+0x1a4>  // b.none
    1078:	71000f1f 	cmp	w24, #0x3
    107c:	54000280 	b.eq	10cc <arm_smmu_gerror_handler+0x17c>  // b.none
    1080:	b4000278 	cbz	x24, 10cc <arm_smmu_gerror_handler+0x17c>
    1084:	f90023b9 	str	x25, [x29, #64]
	queue_read(cmd, Q_ENT(q, cons), q->ent_dwords);
    1088:	b94042e4 	ldr	w4, [x23, #64]
    108c:	52800020 	mov	w0, #0x1                   	// #1
    1090:	f94052e2 	ldr	x2, [x23, #160]
    1094:	9101e3b9 	add	x25, x29, #0x78
    1098:	f94046e3 	ldr	x3, [x23, #136]
    109c:	d2800001 	mov	x1, #0x0                   	// #0
    10a0:	1ac42000 	lsl	w0, w0, w4
    10a4:	51000400 	sub	w0, w0, #0x1
    10a8:	0a130000 	and	w0, w0, w19
    10ac:	d37df044 	lsl	x4, x2, #3
    10b0:	9b040c00 	madd	x0, x0, x4, x3
	for (i = 0; i < n_dwords; ++i)
    10b4:	eb21c05f 	cmp	x2, w1, sxtw
    10b8:	54000809 	b.ls	11b8 <arm_smmu_gerror_handler+0x268>  // b.plast
		*dst++ = le64_to_cpu(*src++);
    10bc:	f8617803 	ldr	x3, [x0, x1, lsl #3]
    10c0:	f8217b23 	str	x3, [x25, x1, lsl #3]
    10c4:	91000421 	add	x1, x1, #0x1
    10c8:	17fffffb 	b	10b4 <arm_smmu_gerror_handler+0x164>
    10cc:	a94363b7 	ldp	x23, x24, [x29, #48]
    10d0:	17ffffcc 	b	1000 <arm_smmu_gerror_handler+0xb0>
	dev_err(smmu->dev, "CMDQ error (cons 0x%08x): %s\n", cons,
    10d4:	90000003 	adrp	x3, 0 <queue_remove_raw>
    10d8:	90000001 	adrp	x1, 0 <queue_remove_raw>
    10dc:	91000063 	add	x3, x3, #0x0
    10e0:	2a1303e2 	mov	w2, w19
    10e4:	91000021 	add	x1, x1, #0x0
    10e8:	f90023b9 	str	x25, [x29, #64]
    10ec:	94000000 	bl	0 <_dev_err>
    10f0:	17ffffe6 	b	1088 <arm_smmu_gerror_handler+0x138>
		dev_err(smmu->dev, "retrying command fetch\n");
    10f4:	f94002c0 	ldr	x0, [x22]
    10f8:	90000001 	adrp	x1, 0 <queue_remove_raw>
    10fc:	91000021 	add	x1, x1, #0x0
    1100:	94000000 	bl	0 <_dev_err>
    1104:	a94363b7 	ldp	x23, x24, [x29, #48]
    1108:	17ffffbe 	b	1000 <arm_smmu_gerror_handler+0xb0>
		dev_err(smmu->dev, "EVTQ write aborted -- events may have been lost\n");
    110c:	f94002c0 	ldr	x0, [x22]
    1110:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1114:	91000021 	add	x1, x1, #0x0
    1118:	94000000 	bl	0 <_dev_err>
    111c:	17ffffb8 	b	ffc <arm_smmu_gerror_handler+0xac>
		dev_err(smmu->dev, "PRIQ write aborted -- events may have been lost\n");
    1120:	f94002c0 	ldr	x0, [x22]
    1124:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1128:	91000021 	add	x1, x1, #0x0
    112c:	94000000 	bl	0 <_dev_err>
	if (active & GERROR_EVTQ_ABT_ERR)
    1130:	3617f673 	tbz	w19, #2, ffc <arm_smmu_gerror_handler+0xac>
    1134:	17fffff6 	b	110c <arm_smmu_gerror_handler+0x1bc>
		dev_warn(smmu->dev, "CMDQ MSI write aborted\n");
    1138:	f94002c0 	ldr	x0, [x22]
    113c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1140:	91000021 	add	x1, x1, #0x0
    1144:	94000000 	bl	0 <_dev_warn>
	if (active & GERROR_PRIQ_ABT_ERR)
    1148:	361ff593 	tbz	w19, #3, ff8 <arm_smmu_gerror_handler+0xa8>
    114c:	17fffff5 	b	1120 <arm_smmu_gerror_handler+0x1d0>
		dev_warn(smmu->dev, "EVTQ MSI write aborted\n");
    1150:	f94002c0 	ldr	x0, [x22]
    1154:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1158:	91000021 	add	x1, x1, #0x0
    115c:	94000000 	bl	0 <_dev_warn>
	if (active & GERROR_MSI_CMDQ_ABT_ERR)
    1160:	3627f4b3 	tbz	w19, #4, ff4 <arm_smmu_gerror_handler+0xa4>
    1164:	17fffff5 	b	1138 <arm_smmu_gerror_handler+0x1e8>
		dev_warn(smmu->dev, "PRIQ MSI write aborted\n");
    1168:	f94002c0 	ldr	x0, [x22]
    116c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1170:	91000021 	add	x1, x1, #0x0
    1174:	94000000 	bl	0 <_dev_warn>
	if (active & GERROR_MSI_EVTQ_ABT_ERR)
    1178:	362ff3d3 	tbz	w19, #5, ff0 <arm_smmu_gerror_handler+0xa0>
    117c:	17fffff5 	b	1150 <arm_smmu_gerror_handler+0x200>
		dev_warn(smmu->dev, "GERROR MSI write aborted\n");
    1180:	f94002c0 	ldr	x0, [x22]
    1184:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1188:	91000021 	add	x1, x1, #0x0
    118c:	94000000 	bl	0 <_dev_warn>
	if (active & GERROR_MSI_PRIQ_ABT_ERR)
    1190:	3637f2f3 	tbz	w19, #6, fec <arm_smmu_gerror_handler+0x9c>
    1194:	17fffff5 	b	1168 <arm_smmu_gerror_handler+0x218>
		dev_err(smmu->dev, "device has entered Service Failure Mode!\n");
    1198:	f94002c0 	ldr	x0, [x22]
    119c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    11a0:	91000021 	add	x1, x1, #0x0
    11a4:	94000000 	bl	0 <_dev_err>
		arm_smmu_device_disable(smmu);
    11a8:	aa1603e0 	mov	x0, x22
    11ac:	97ffff37 	bl	e88 <arm_smmu_device_disable>
	if (active & GERROR_MSI_GERROR_ABT_ERR)
    11b0:	363ff1d3 	tbz	w19, #7, fe8 <arm_smmu_gerror_handler+0x98>
    11b4:	17fffff3 	b	1180 <arm_smmu_gerror_handler+0x230>
	dev_err(smmu->dev, "skipping command in error state:\n");
    11b8:	f94002c0 	ldr	x0, [x22]
    11bc:	90000001 	adrp	x1, 0 <queue_remove_raw>
    11c0:	91000021 	add	x1, x1, #0x0
		dev_err(smmu->dev, "\t0x%016llx\n", (unsigned long long)cmd[i]);
    11c4:	90000018 	adrp	x24, 0 <queue_remove_raw>
    11c8:	91000318 	add	x24, x24, #0x0
	dev_err(smmu->dev, "skipping command in error state:\n");
    11cc:	94000000 	bl	0 <_dev_err>
		dev_err(smmu->dev, "\t0x%016llx\n", (unsigned long long)cmd[i]);
    11d0:	f94002c0 	ldr	x0, [x22]
    11d4:	aa1803e1 	mov	x1, x24
    11d8:	f9403fa2 	ldr	x2, [x29, #120]
    11dc:	94000000 	bl	0 <_dev_err>
    11e0:	f94002c0 	ldr	x0, [x22]
    11e4:	aa1803e1 	mov	x1, x24
    11e8:	f94043a2 	ldr	x2, [x29, #128]
    11ec:	94000000 	bl	0 <_dev_err>
	if (arm_smmu_cmdq_build_cmd(cmd, &cmd_sync)) {
    11f0:	910163a1 	add	x1, x29, #0x58
    11f4:	aa1903e0 	mov	x0, x25
    11f8:	97fffce0 	bl	578 <arm_smmu_cmdq_build_cmd>
    11fc:	35000220 	cbnz	w0, 1240 <arm_smmu_gerror_handler+0x2f0>
	queue_write(Q_ENT(q, cons), cmd, q->ent_dwords);
    1200:	b94042e4 	ldr	w4, [x23, #64]
    1204:	52800020 	mov	w0, #0x1                   	// #1
    1208:	f94052e2 	ldr	x2, [x23, #160]
    120c:	d2800001 	mov	x1, #0x0                   	// #0
    1210:	f94046e3 	ldr	x3, [x23, #136]
    1214:	1ac42000 	lsl	w0, w0, w4
    1218:	51000400 	sub	w0, w0, #0x1
    121c:	0a130000 	and	w0, w0, w19
    1220:	d37df044 	lsl	x4, x2, #3
    1224:	9b040c00 	madd	x0, x0, x4, x3
	for (i = 0; i < n_dwords; ++i)
    1228:	eb21c05f 	cmp	x2, w1, sxtw
    122c:	54000189 	b.ls	125c <arm_smmu_gerror_handler+0x30c>  // b.plast
		*dst++ = cpu_to_le64(*src++);
    1230:	f8617b23 	ldr	x3, [x25, x1, lsl #3]
    1234:	f8217803 	str	x3, [x0, x1, lsl #3]
    1238:	91000421 	add	x1, x1, #0x1
    123c:	17fffffb 	b	1228 <arm_smmu_gerror_handler+0x2d8>
		dev_err(smmu->dev, "failed to convert to CMD_SYNC\n");
    1240:	f94002c0 	ldr	x0, [x22]
    1244:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1248:	91000021 	add	x1, x1, #0x0
    124c:	94000000 	bl	0 <_dev_err>
    1250:	f94023b9 	ldr	x25, [x29, #64]
    1254:	a94363b7 	ldp	x23, x24, [x29, #48]
    1258:	17ffff6a 	b	1000 <arm_smmu_gerror_handler+0xb0>
    125c:	a94363b7 	ldp	x23, x24, [x29, #48]
    1260:	f94023b9 	ldr	x25, [x29, #64]
    1264:	17ffff67 	b	1000 <arm_smmu_gerror_handler+0xb0>

0000000000001268 <arm_smmu_combined_irq_handler>:
{
    1268:	d503233f 	paciasp
    126c:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
    1270:	910003fd 	mov	x29, sp
	arm_smmu_gerror_handler(irq, dev);
    1274:	97ffff37 	bl	f50 <arm_smmu_gerror_handler>
}
    1278:	52800040 	mov	w0, #0x2                   	// #2
    127c:	a8c17bfd 	ldp	x29, x30, [sp], #16
    1280:	d50323bf 	autiasp
    1284:	d65f03c0 	ret

0000000000001288 <arm_smmu_update_gbpa.isra.34>:
static int arm_smmu_update_gbpa(struct arm_smmu_device *smmu, u32 set, u32 clr)
    1288:	d503233f 	paciasp
    128c:	a9bc7bfd 	stp	x29, x30, [sp, #-64]!
    1290:	910003fd 	mov	x29, sp
    1294:	a90153f3 	stp	x19, x20, [sp, #16]
	return ktime_add_ns(kt, usec * NSEC_PER_USEC);
    1298:	d2994014 	mov	x20, #0xca00                	// #51712
    129c:	a9025bf5 	stp	x21, x22, [sp, #32]
	u32 reg, __iomem *gbpa = smmu->base + ARM_SMMU_GBPA;
    12a0:	91011033 	add	x19, x1, #0x44
static int arm_smmu_update_gbpa(struct arm_smmu_device *smmu, u32 set, u32 clr)
    12a4:	f9001bf7 	str	x23, [sp, #48]
    12a8:	aa0003f6 	mov	x22, x0
    12ac:	2a0303f5 	mov	w21, w3
    12b0:	f2a77354 	movk	x20, #0x3b9a, lsl #16
    12b4:	2a0203f7 	mov	w23, w2
	ret = readl_relaxed_poll_timeout(gbpa, reg, !(reg & GBPA_UPDATE),
    12b8:	94000000 	bl	0 <ktime_get>
    12bc:	8b140014 	add	x20, x0, x20
    12c0:	14000007 	b	12dc <arm_smmu_update_gbpa.isra.34+0x54>
    12c4:	94000000 	bl	0 <ktime_get>
	if (cmp1 > cmp2)
    12c8:	eb00029f 	cmp	x20, x0
    12cc:	540003cb 	b.lt	1344 <arm_smmu_update_gbpa.isra.34+0xbc>  // b.tstop
    12d0:	d2800021 	mov	x1, #0x1                   	// #1
    12d4:	aa0103e0 	mov	x0, x1
    12d8:	94000000 	bl	0 <usleep_range>
    12dc:	b9400260 	ldr	w0, [x19]
    12e0:	37ffff20 	tbnz	w0, #31, 12c4 <arm_smmu_update_gbpa.isra.34+0x3c>
	reg &= ~clr;
    12e4:	0a350000 	bic	w0, w0, w21
	writel_relaxed(reg | GBPA_UPDATE, gbpa);
    12e8:	320102f7 	orr	w23, w23, #0x80000000
    12ec:	2a170000 	orr	w0, w0, w23
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    12f0:	b9000260 	str	w0, [x19]
	return ktime_add_ns(kt, usec * NSEC_PER_USEC);
    12f4:	d2994014 	mov	x20, #0xca00                	// #51712
	ret = readl_relaxed_poll_timeout(gbpa, reg, !(reg & GBPA_UPDATE),
    12f8:	94000000 	bl	0 <ktime_get>
    12fc:	f2a77354 	movk	x20, #0x3b9a, lsl #16
    1300:	8b140014 	add	x20, x0, x20
    1304:	14000007 	b	1320 <arm_smmu_update_gbpa.isra.34+0x98>
    1308:	94000000 	bl	0 <ktime_get>
	if (cmp1 > cmp2)
    130c:	eb00029f 	cmp	x20, x0
    1310:	5400022b 	b.lt	1354 <arm_smmu_update_gbpa.isra.34+0xcc>  // b.tstop
    1314:	d2800021 	mov	x1, #0x1                   	// #1
    1318:	aa0103e0 	mov	x0, x1
    131c:	94000000 	bl	0 <usleep_range>
	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    1320:	b9400260 	ldr	w0, [x19]
    1324:	37ffff20 	tbnz	w0, #31, 1308 <arm_smmu_update_gbpa.isra.34+0x80>
    1328:	52800000 	mov	w0, #0x0                   	// #0
}
    132c:	a94153f3 	ldp	x19, x20, [sp, #16]
    1330:	a9425bf5 	ldp	x21, x22, [sp, #32]
    1334:	f9401bf7 	ldr	x23, [sp, #48]
    1338:	a8c47bfd 	ldp	x29, x30, [sp], #64
    133c:	d50323bf 	autiasp
    1340:	d65f03c0 	ret
    1344:	b9400260 	ldr	w0, [x19]
	ret = readl_relaxed_poll_timeout(gbpa, reg, !(reg & GBPA_UPDATE),
    1348:	36fffce0 	tbz	w0, #31, 12e4 <arm_smmu_update_gbpa.isra.34+0x5c>
	ret = readl_relaxed_poll_timeout(gbpa, reg, !(reg & GBPA_UPDATE),
    134c:	12800da0 	mov	w0, #0xffffff92            	// #-110
    1350:	17fffff7 	b	132c <arm_smmu_update_gbpa.isra.34+0xa4>
    1354:	b9400273 	ldr	w19, [x19]
    1358:	36fffe93 	tbz	w19, #31, 1328 <arm_smmu_update_gbpa.isra.34+0xa0>
		dev_err(smmu->dev, "GBPA not responding to update\n");
    135c:	f94002c0 	ldr	x0, [x22]
    1360:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1364:	91000021 	add	x1, x1, #0x0
    1368:	94000000 	bl	0 <_dev_err>
	ret = readl_relaxed_poll_timeout(gbpa, reg, !(reg & GBPA_UPDATE),
    136c:	12800da0 	mov	w0, #0xffffff92            	// #-110
    1370:	17ffffef 	b	132c <arm_smmu_update_gbpa.isra.34+0xa4>
    1374:	d503201f 	nop

0000000000001378 <queue_poll>:
{
    1378:	d503233f 	paciasp
    137c:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
    1380:	910003fd 	mov	x29, sp
    1384:	f9000bf3 	str	x19, [sp, #16]
    1388:	aa0003f3 	mov	x19, x0
	if (ktime_compare(ktime_get(), qp->timeout) > 0)
    138c:	94000000 	bl	0 <ktime_get>
    1390:	f9400261 	ldr	x1, [x19]
    1394:	eb01001f 	cmp	x0, x1
    1398:	540003cc 	b.gt	1410 <queue_poll+0x98>
	if (qp->wfe) {
    139c:	39404260 	ldrb	w0, [x19, #16]
    13a0:	350002c0 	cbnz	w0, 13f8 <queue_poll+0x80>
	} else if (++qp->spin_cnt < ARM_SMMU_POLL_SPIN_COUNT) {
    13a4:	b9400e60 	ldr	w0, [x19, #12]
    13a8:	11000400 	add	w0, w0, #0x1
    13ac:	b9000e60 	str	w0, [x19, #12]
    13b0:	7100241f 	cmp	w0, #0x9
    13b4:	54000169 	b.ls	13e0 <queue_poll+0x68>  // b.plast
		udelay(qp->delay);
    13b8:	b9400a60 	ldr	w0, [x19, #8]
    13bc:	94000000 	bl	0 <__udelay>
		qp->delay *= 2;
    13c0:	b9400a61 	ldr	w1, [x19, #8]
		qp->spin_cnt = 0;
    13c4:	52800000 	mov	w0, #0x0                   	// #0
		qp->delay *= 2;
    13c8:	531f7821 	lsl	w1, w1, #1
		qp->spin_cnt = 0;
    13cc:	29017e61 	stp	w1, wzr, [x19, #8]
}
    13d0:	f9400bf3 	ldr	x19, [sp, #16]
    13d4:	a8c27bfd 	ldp	x29, x30, [sp], #32
    13d8:	d50323bf 	autiasp
    13dc:	d65f03c0 	ret

#ifndef __ASSEMBLY__

static inline void cpu_relax(void)
{
	asm volatile("yield" ::: "memory");
    13e0:	d503203f 	yield
	return 0;
    13e4:	52800000 	mov	w0, #0x0                   	// #0
}
    13e8:	f9400bf3 	ldr	x19, [sp, #16]
    13ec:	a8c27bfd 	ldp	x29, x30, [sp], #32
    13f0:	d50323bf 	autiasp
    13f4:	d65f03c0 	ret
		wfe();
    13f8:	d503205f 	wfe
	return 0;
    13fc:	52800000 	mov	w0, #0x0                   	// #0
}
    1400:	f9400bf3 	ldr	x19, [sp, #16]
    1404:	a8c27bfd 	ldp	x29, x30, [sp], #32
    1408:	d50323bf 	autiasp
    140c:	d65f03c0 	ret
		return -ETIMEDOUT;
    1410:	12800da0 	mov	w0, #0xffffff92            	// #-110
    1414:	17ffffef 	b	13d0 <queue_poll+0x58>

0000000000001418 <arm_smmu_domain_finalise_s2>:
{
    1418:	d503233f 	paciasp
    141c:	a9bc7bfd 	stp	x29, x30, [sp, #-64]!
    1420:	910003fd 	mov	x29, sp
    1424:	a90153f3 	stp	x19, x20, [sp, #16]
	int idx, size = 1 << span;
    1428:	52800034 	mov	w20, #0x1                   	// #1
{
    142c:	a9025bf5 	stp	x21, x22, [sp, #32]
}

static inline int test_and_set_bit(unsigned int nr, volatile unsigned long *p)
{
	long old;
	unsigned long mask = BIT_MASK(nr);
    1430:	d2800036 	mov	x22, #0x1                   	// #1
    1434:	a90363f7 	stp	x23, x24, [sp, #48]
    1438:	aa0003f7 	mov	x23, x0
    143c:	aa0203f8 	mov	x24, x2
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    1440:	f9400000 	ldr	x0, [x0]
	vmid = arm_smmu_bitmap_alloc(smmu->vmid_map, smmu->vmid_bits);
    1444:	910ca013 	add	x19, x0, #0x328
	int idx, size = 1 << span;
    1448:	b9432400 	ldr	w0, [x0, #804]
    144c:	1ac02294 	lsl	w20, w20, w0
    1450:	93407e95 	sxtw	x21, w20
    1454:	d503201f 	nop
		idx = find_first_zero_bit(map, size);
    1458:	d2800002 	mov	x2, #0x0                   	// #0
    145c:	aa1503e1 	mov	x1, x21
    1460:	aa1303e0 	mov	x0, x19
    1464:	94000000 	bl	0 <find_next_zero_bit>
		if (idx == size)
    1468:	6b00029f 	cmp	w20, w0
		idx = find_first_zero_bit(map, size);
    146c:	2a0003e4 	mov	w4, w0

	p += BIT_WORD(nr);
    1470:	53067c03 	lsr	w3, w0, #6
		if (idx == size)
    1474:	54000600 	b.eq	1534 <arm_smmu_domain_finalise_s2+0x11c>  // b.none
    1478:	8b030e62 	add	x2, x19, x3, lsl #3
	if (READ_ONCE(*p) & mask)
    147c:	f8637a63 	ldr	x3, [x19, x3, lsl #3]
	unsigned long mask = BIT_MASK(nr);
    1480:	9ac022c1 	lsl	x1, x22, x0
	if (READ_ONCE(*p) & mask)
    1484:	ea03003f 	tst	x1, x3
    1488:	54fffe81 	b.ne	1458 <arm_smmu_domain_finalise_s2+0x40>  // b.any
}

static __always_inline bool arch_static_branch_jump(struct static_key *key,
						    bool branch)
{
	asm_volatile_goto(
    148c:	14000027 	b	1528 <arm_smmu_domain_finalise_s2+0x110>
    1490:	14000026 	b	1528 <arm_smmu_domain_finalise_s2+0x110>
	ATOMIC64_FETCH_OP(_acquire,  a, op, asm_op, "memory")		\
	ATOMIC64_FETCH_OP(_release,  l, op, asm_op, "memory")		\
	ATOMIC64_FETCH_OP(        , al, op, asm_op, "memory")

ATOMIC64_FETCH_OPS(andnot, ldclr)
ATOMIC64_FETCH_OPS(or, ldset)
    1494:	aa0103e3 	mov	x3, x1
    1498:	f8e33043 	ldsetal	x3, x3, [x2]
    149c:	aa0303e2 	mov	x2, x3
	} while (test_and_set_bit(idx, map));
    14a0:	ea01005f 	tst	x2, x1
    14a4:	54fffda1 	b.ne	1458 <arm_smmu_domain_finalise_s2+0x40>  // b.any
	if (vmid < 0)
    14a8:	37f80484 	tbnz	w4, #31, 1538 <arm_smmu_domain_finalise_s2+0x120>
	cfg->vmid	= (u16)vmid;
    14ac:	790082e0 	strh	w0, [x23, #64]
	return 0;
    14b0:	52800004 	mov	w4, #0x0                   	// #0
	cfg->vttbr	= pgtbl_cfg->arm_lpae_s2_cfg.vttbr;
    14b4:	f9401b00 	ldr	x0, [x24, #48]
    14b8:	f90026e0 	str	x0, [x23, #72]
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SH0, vtcr->sh) |
    14bc:	3940e301 	ldrb	w1, [x24, #56]
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SL0, vtcr->sl) |
    14c0:	3940e700 	ldrb	w0, [x24, #57]
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2OR0, vtcr->orgn) |
    14c4:	79407302 	ldrh	w2, [x24, #56]
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SH0, vtcr->sh) |
    14c8:	d3451826 	ubfx	x6, x1, #5, #2
	cfg->vtcr	= FIELD_PREP(STRTAB_STE_2_VTCR_S2T0SZ, vtcr->tsz) |
    14cc:	b9403b03 	ldr	w3, [x24, #56]
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2IR0, vtcr->irgn) |
    14d0:	d3410807 	ubfx	x7, x0, #1, #2
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SL0, vtcr->sl) |
    14d4:	d3431000 	ubfx	x0, x0, #3, #2
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2OR0, vtcr->orgn) |
    14d8:	d3472042 	ubfx	x2, x2, #7, #2
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2TG, vtcr->tg) |
    14dc:	d3431025 	ubfx	x5, x1, #3, #2
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2IR0, vtcr->irgn) |
    14e0:	d378dce7 	lsl	x7, x7, #8
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SH0, vtcr->sh) |
    14e4:	d374ccc6 	lsl	x6, x6, #12
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2TG, vtcr->tg) |
    14e8:	aa0018e0 	orr	x0, x7, x0, lsl #6
    14ec:	aa0228c2 	orr	x2, x6, x2, lsl #10
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2PS, vtcr->ps);
    14f0:	d3700821 	ubfiz	x1, x1, #16, #3
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2TG, vtcr->tg) |
    14f4:	aa020000 	orr	x0, x0, x2
    14f8:	aa053821 	orr	x1, x1, x5, lsl #14
    14fc:	aa010000 	orr	x0, x0, x1
	cfg->vtcr	= FIELD_PREP(STRTAB_STE_2_VTCR_S2T0SZ, vtcr->tsz) |
    1500:	d34d4861 	ubfx	x1, x3, #13, #6
			  FIELD_PREP(STRTAB_STE_2_VTCR_S2TG, vtcr->tg) |
    1504:	aa010000 	orr	x0, x0, x1
	cfg->vtcr	= FIELD_PREP(STRTAB_STE_2_VTCR_S2T0SZ, vtcr->tsz) |
    1508:	f9002ae0 	str	x0, [x23, #80]
}
    150c:	2a0403e0 	mov	w0, w4
    1510:	a94153f3 	ldp	x19, x20, [sp, #16]
    1514:	a9425bf5 	ldp	x21, x22, [sp, #32]
    1518:	a94363f7 	ldp	x23, x24, [sp, #48]
    151c:	a8c47bfd 	ldp	x29, x30, [sp], #64
    1520:	d50323bf 	autiasp
    1524:	d65f03c0 	ret
	ATOMIC64_FETCH_OP (_relaxed,,  ,  ,         , __VA_ARGS__)	\
	ATOMIC64_FETCH_OP (_acquire,, a,  , "memory", __VA_ARGS__)	\
	ATOMIC64_FETCH_OP (_release,,  , l, "memory", __VA_ARGS__)

ATOMIC64_OPS(and, and, L)
ATOMIC64_OPS(or, orr, L)
    1528:	14000d32 	b	49f0 <arm_smmu_flush_iotlb_all+0x58>
    152c:	aa0303e2 	mov	x2, x3
    1530:	17ffffdc 	b	14a0 <arm_smmu_domain_finalise_s2+0x88>
			return -ENOSPC;
    1534:	12800364 	mov	w4, #0xffffffe4            	// #-28
}
    1538:	2a0403e0 	mov	w0, w4
    153c:	a94153f3 	ldp	x19, x20, [sp, #16]
    1540:	a9425bf5 	ldp	x21, x22, [sp, #32]
    1544:	a94363f7 	ldp	x23, x24, [sp, #48]
    1548:	a8c47bfd 	ldp	x29, x30, [sp], #64
    154c:	d50323bf 	autiasp
    1550:	d65f03c0 	ret
    1554:	d503201f 	nop

0000000000001558 <__arm_smmu_cmdq_poll_set_valid_map.isra.25>:
	ewidx = BIT_WORD(Q_IDX(&llq, eprod));
    1558:	52800025 	mov	w5, #0x1                   	// #1
	while (llq.prod != eprod) {
    155c:	6b02007f 	cmp	w3, w2
	ewidx = BIT_WORD(Q_IDX(&llq, eprod));
    1560:	1ac020a0 	lsl	w0, w5, w0
    1564:	5100040f 	sub	w15, w0, #0x1
    1568:	0a0301eb 	and	w11, w15, w3
	while (llq.prod != eprod) {
    156c:	54000880 	b.eq	167c <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x124>  // b.none
    1570:	53067d70 	lsr	w16, w11, #6
    1574:	1200156b 	and	w11, w11, #0x3f
static void __arm_smmu_cmdq_poll_set_valid_map(struct arm_smmu_cmdq *cmdq,
    1578:	d503233f 	paciasp
    157c:	5280080e 	mov	w14, #0x40                  	// #64
    1580:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
    1584:	4b0b01c5 	sub	w5, w14, w11
    1588:	9280000d 	mov	x13, #0xffffffffffffffff    	// #-1
    158c:	12001c84 	and	w4, w4, #0xff
    1590:	910003fd 	mov	x29, sp
		if ((swidx == ewidx) && (sbidx < ebidx))
    1594:	aa0d03f2 	mov	x18, x13
static void __arm_smmu_cmdq_poll_set_valid_map(struct arm_smmu_cmdq *cmdq,
    1598:	2a0001ec 	orr	w12, w15, w0
    159c:	9ac525ad 	lsr	x13, x13, x5
		mask = GENMASK(limit - 1, sbidx);
    15a0:	d2800031 	mov	x17, #0x1                   	// #1
    15a4:	1400000c 	b	15d4 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x7c>
    15a8:	14000033 	b	1674 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x11c>
    15ac:	14000032 	b	1674 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x11c>
ATOMIC64_OP(xor, steor)
    15b0:	f82720bf 	steor	x7, [x5]
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    15b4:	0a0c0045 	and	w5, w2, w12
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    15b8:	12010046 	and	w6, w2, #0x80000000
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    15bc:	4b0900a2 	sub	w2, w5, w9
    15c0:	0b1e0042 	add	w2, w2, w30
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    15c4:	0a0c0042 	and	w2, w2, w12
    15c8:	2a060042 	orr	w2, w2, w6
	while (llq.prod != eprod) {
    15cc:	6b02007f 	cmp	w3, w2
    15d0:	540004c0 	b.eq	1668 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x110>  // b.none
		swidx = BIT_WORD(Q_IDX(&llq, llq.prod));
    15d4:	0a0201e5 	and	w5, w15, w2
		ptr = &cmdq->valid_map[swidx];
    15d8:	f9400028 	ldr	x8, [x1]
		sbidx = Q_IDX(&llq, llq.prod) % BITS_PER_LONG;
    15dc:	120014a9 	and	w9, w5, #0x3f
		swidx = BIT_WORD(Q_IDX(&llq, llq.prod));
    15e0:	53067ca6 	lsr	w6, w5, #6
		if ((swidx == ewidx) && (sbidx < ebidx))
    15e4:	6b06021f 	cmp	w16, w6
		mask = GENMASK(limit - 1, sbidx);
    15e8:	9ac92227 	lsl	x7, x17, x9
		if ((swidx == ewidx) && (sbidx < ebidx))
    15ec:	7a490160 	ccmp	w11, w9, #0x0, eq  // eq = none
		mask = GENMASK(limit - 1, sbidx);
    15f0:	cb0703e7 	neg	x7, x7
		if ((swidx == ewidx) && (sbidx < ebidx))
    15f4:	9a9281aa 	csel	x10, x13, x18, hi  // hi = pmore
    15f8:	1a8e817e 	csel	w30, w11, w14, hi  // hi = pmore
		mask = GENMASK(limit - 1, sbidx);
    15fc:	8a0a00e7 	and	x7, x7, x10
		ptr = &cmdq->valid_map[swidx];
    1600:	8b060d05 	add	x5, x8, x6, lsl #3
		if (set) {
    1604:	35fffd24 	cbnz	w4, 15a8 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x50>
			atomic_long_cond_read_relaxed(ptr, (VAL & mask) == valid);
    1608:	f8667906 	ldr	x6, [x8, x6, lsl #3]
			valid = (ULONG_MAX + !!Q_WRP(&llq, llq.prod)) & mask;
    160c:	6a00005f 	tst	w2, w0
    1610:	9a9f00ea 	csel	x10, x7, xzr, eq  // eq = none
			atomic_long_cond_read_relaxed(ptr, (VAL & mask) == valid);
    1614:	8a0600e8 	and	x8, x7, x6
    1618:	eb08015f 	cmp	x10, x8
    161c:	54fffcc0 	b.eq	15b4 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x5c>  // b.none
}

__CMPWAIT_CASE(w, b, 8);
__CMPWAIT_CASE(w, h, 16);
__CMPWAIT_CASE(w,  , 32);
__CMPWAIT_CASE( ,  , 64);
    1620:	d50320bf 	sevl
    1624:	d503205f 	wfe
    1628:	c85f7ca8 	ldxr	x8, [x5]
    162c:	ca060108 	eor	x8, x8, x6
    1630:	b5000048 	cbnz	x8, 1638 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0xe0>
    1634:	d503205f 	wfe
    1638:	f94000a6 	ldr	x6, [x5]
    163c:	8a0600e8 	and	x8, x7, x6
    1640:	eb08015f 	cmp	x10, x8
    1644:	54fffee1 	b.ne	1620 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0xc8>  // b.any
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1648:	0a0c0045 	and	w5, w2, w12
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    164c:	12010046 	and	w6, w2, #0x80000000
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1650:	4b0900a2 	sub	w2, w5, w9
    1654:	0b1e0042 	add	w2, w2, w30
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1658:	0a0c0042 	and	w2, w2, w12
    165c:	2a060042 	orr	w2, w2, w6
	while (llq.prod != eprod) {
    1660:	6b02007f 	cmp	w3, w2
    1664:	54fffb81 	b.ne	15d4 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x7c>  // b.any
}
    1668:	a8c17bfd 	ldp	x29, x30, [sp], #16
    166c:	d50323bf 	autiasp
    1670:	d65f03c0 	ret
ATOMIC64_OPS(xor, eor, L)
    1674:	14000ce6 	b	4a0c <arm_smmu_flush_iotlb_all+0x74>
    1678:	17ffffcf 	b	15b4 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x5c>
    167c:	d65f03c0 	ret

0000000000001680 <arm_smmu_domain_free>:
{
    1680:	d503233f 	paciasp
    1684:	a9bd7bfd 	stp	x29, x30, [sp, #-48]!
    1688:	910003fd 	mov	x29, sp
    168c:	a90153f3 	stp	x19, x20, [sp, #16]
    1690:	aa0003f3 	mov	x19, x0
    1694:	f90013f5 	str	x21, [sp, #32]
	return container_of(dom, struct arm_smmu_domain, domain);
    1698:	d1022014 	sub	x20, x0, #0x88
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    169c:	f8578015 	ldur	x21, [x0, #-136]
	iommu_put_dma_cookie(domain);
    16a0:	94000000 	bl	0 <iommu_put_dma_cookie>
	free_io_pgtable_ops(smmu_domain->pgtbl_ops);
    16a4:	f85a0260 	ldur	x0, [x19, #-96]
    16a8:	94000000 	bl	0 <free_io_pgtable_ops>
	if (smmu_domain->stage == ARM_SMMU_DOMAIN_S1) {
    16ac:	b85b0260 	ldur	w0, [x19, #-80]
    16b0:	350001c0 	cbnz	w0, 16e8 <arm_smmu_domain_free+0x68>
		if (cfg->cdcfg.cdtab)
    16b4:	f85b8260 	ldur	x0, [x19, #-72]
    16b8:	b4000060 	cbz	x0, 16c4 <arm_smmu_domain_free+0x44>
			arm_smmu_free_cd_tables(smmu_domain);
    16bc:	aa1403e0 	mov	x0, x20
    16c0:	97fffc82 	bl	8c8 <arm_smmu_free_cd_tables>
		arm_smmu_free_asid(&cfg->cd);
    16c4:	785d8261 	ldurh	w1, [x19, #-40]
	if (!cd->asid)
    16c8:	35000261 	cbnz	w1, 1714 <arm_smmu_domain_free+0x94>
	kfree(smmu_domain);
    16cc:	aa1403e0 	mov	x0, x20
    16d0:	94000000 	bl	0 <kfree>
}
    16d4:	a94153f3 	ldp	x19, x20, [sp, #16]
    16d8:	f94013f5 	ldr	x21, [sp, #32]
    16dc:	a8c37bfd 	ldp	x29, x30, [sp], #48
    16e0:	d50323bf 	autiasp
    16e4:	d65f03c0 	ret
		if (cfg->vmid)
    16e8:	785b8262 	ldurh	w2, [x19, #-72]
    16ec:	34ffff02 	cbz	w2, 16cc <arm_smmu_domain_free+0x4c>
	p += BIT_WORD(nr);
    16f0:	d3463c40 	ubfx	x0, x2, #6, #10
			arm_smmu_bitmap_free(smmu->vmid_map, cfg->vmid);
    16f4:	910ca2b5 	add	x21, x21, #0x328
	atomic_long_andnot(BIT_MASK(nr), (atomic_long_t *)p);
    16f8:	d2800021 	mov	x1, #0x1                   	// #1
	p += BIT_WORD(nr);
    16fc:	8b000ea0 	add	x0, x21, x0, lsl #3
	atomic_long_andnot(BIT_MASK(nr), (atomic_long_t *)p);
    1700:	9ac22021 	lsl	x1, x1, x2
    1704:	14000010 	b	1744 <arm_smmu_domain_free+0xc4>
    1708:	1400000f 	b	1744 <arm_smmu_domain_free+0xc4>
ATOMIC64_OP(andnot, stclr)
    170c:	f821101f 	stclr	x1, [x0]
    1710:	17ffffef 	b	16cc <arm_smmu_domain_free+0x4c>
	xa_erase(&asid_xa, cd->asid);
    1714:	92403c21 	and	x1, x1, #0xffff
    1718:	90000000 	adrp	x0, 0 <queue_remove_raw>
    171c:	91000000 	add	x0, x0, #0x0
    1720:	91044000 	add	x0, x0, #0x110
    1724:	94000000 	bl	0 <xa_erase>
	kfree(smmu_domain);
    1728:	aa1403e0 	mov	x0, x20
    172c:	94000000 	bl	0 <kfree>
}
    1730:	a94153f3 	ldp	x19, x20, [sp, #16]
    1734:	f94013f5 	ldr	x21, [sp, #32]
    1738:	a8c37bfd 	ldp	x29, x30, [sp], #48
    173c:	d50323bf 	autiasp
    1740:	d65f03c0 	ret
/*
 * GAS converts the mysterious and undocumented BIC (immediate) alias to
 * an AND (immediate) instruction with the immediate inverted. We don't
 * have a constraint for this, so fall back to register.
 */
ATOMIC64_OPS(andnot, bic, )
    1744:	14000cb8 	b	4a24 <arm_smmu_flush_iotlb_all+0x8c>
	kfree(smmu_domain);
    1748:	aa1403e0 	mov	x0, x20
    174c:	94000000 	bl	0 <kfree>
}
    1750:	a94153f3 	ldp	x19, x20, [sp, #16]
    1754:	f94013f5 	ldr	x21, [sp, #32]
    1758:	a8c37bfd 	ldp	x29, x30, [sp], #48
    175c:	d50323bf 	autiasp
    1760:	d65f03c0 	ret
    1764:	d503201f 	nop

0000000000001768 <arm_smmu_cmdq_issue_cmdlist>:
{
    1768:	d503233f 	paciasp
    176c:	a9a17bfd 	stp	x29, x30, [sp, #-496]!
    1770:	910003fd 	mov	x29, sp
    1774:	91033fa5 	add	x5, x29, #0xcf
    1778:	a9046bf9 	stp	x25, x26, [sp, #64]
    177c:	927ae4ba 	and	x26, x5, #0xffffffffffffffc0
    1780:	a90363f7 	stp	x23, x24, [sp, #48]
    1784:	a90573fb 	stp	x27, x28, [sp, #80]
	struct arm_smmu_ll_queue llq = {
    1788:	91020357 	add	x23, x26, #0x80
		.max_n_shift = cmdq->q.llq.max_n_shift,
    178c:	9101001b 	add	x27, x0, #0x40
{
    1790:	a90153f3 	stp	x19, x20, [sp, #16]
    1794:	a9025bf5 	stp	x21, x22, [sp, #32]
    1798:	aa0003fc 	mov	x28, x0
	struct arm_smmu_ll_queue llq = {
    179c:	a9017eff 	stp	xzr, xzr, [x23, #16]
{
    17a0:	90000000 	adrp	x0, 0 <__stack_chk_guard>
	struct arm_smmu_ll_queue llq = {
    17a4:	a9027eff 	stp	xzr, xzr, [x23, #32]
{
    17a8:	91000000 	add	x0, x0, #0x0
	struct arm_smmu_ll_queue llq = {
    17ac:	a9037eff 	stp	xzr, xzr, [x23, #48]
    17b0:	a9047eff 	stp	xzr, xzr, [x23, #64]
		.max_n_shift = cmdq->q.llq.max_n_shift,
    17b4:	b9404373 	ldr	w19, [x27, #64]
{
    17b8:	f90033a1 	str	x1, [x29, #96]
    17bc:	12001c61 	and	w1, w3, #0xff
	}, head = llq;
    17c0:	b900c353 	str	w19, [x26, #192]
{
    17c4:	b9006fa1 	str	w1, [x29, #108]
    17c8:	f9400001 	ldr	x1, [x0]
    17cc:	f900f7a1 	str	x1, [x29, #488]
    17d0:	d2800001 	mov	x1, #0x0                   	// #0
    17d4:	b9006ba2 	str	w2, [x29, #104]
	}, head = llq;
    17d8:	aa1703e1 	mov	x1, x23
	struct arm_smmu_ll_queue llq = {
    17dc:	a9087f5f 	stp	xzr, xzr, [x26, #128]
	}, head = llq;
    17e0:	d2801002 	mov	x2, #0x80                  	// #128
	struct arm_smmu_ll_queue llq = {
    17e4:	a9057eff 	stp	xzr, xzr, [x23, #80]
	}, head = llq;
    17e8:	aa1a03e0 	mov	x0, x26
	struct arm_smmu_ll_queue llq = {
    17ec:	a9067eff 	stp	xzr, xzr, [x23, #96]
    17f0:	a9077eff 	stp	xzr, xzr, [x23, #112]
	}, head = llq;
    17f4:	94000000 	bl	0 <memcpy>
 */
static inline unsigned long arch_local_save_flags(void)
{
	unsigned long flags;

	asm volatile(ALTERNATIVE(
    17f8:	d53b4228 	mrs	x8, daif
    17fc:	aa0803f5 	mov	x21, x8

static inline int arch_irqs_disabled_flags(unsigned long flags)
{
	int res;

	asm volatile(ALTERNATIVE(
    1800:	12190100 	and	w0, w8, #0x80

	/*
	 * There are too many states with IRQs disabled, just keep the current
	 * state if interrupts are already disabled/masked.
	 */
	if (!arch_irqs_disabled_flags(flags))
    1804:	35000060 	cbnz	w0, 1810 <arm_smmu_cmdq_issue_cmdlist+0xa8>
	asm volatile(ALTERNATIVE(
    1808:	d2800c00 	mov	x0, #0x60                  	// #96
    180c:	d50342df 	msr	daifset, #0x2
	llq.val = READ_ONCE(cmdq->q.llq.val);
    1810:	f9402380 	ldr	x0, [x28, #64]
	prod = Q_IDX(q, q->prod);
    1814:	52800021 	mov	w1, #0x1                   	// #1
    1818:	b9406ba2 	ldr	w2, [x29, #104]
    181c:	1ad32033 	lsl	w19, w1, w19
	llq.val = READ_ONCE(cmdq->q.llq.val);
    1820:	f9004340 	str	x0, [x26, #128]
				dev_err_ratelimited(smmu->dev, "CMDQ timeout\n");
    1824:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1828:	b9406fa0 	ldr	w0, [x29, #108]
	prod = Q_IDX(q, q->prod);
    182c:	51000676 	sub	w22, w19, #0x1
				dev_err_ratelimited(smmu->dev, "CMDQ timeout\n");
    1830:	91000021 	add	x1, x1, #0x0
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1834:	2a1302d4 	orr	w20, w22, w19
				dev_err_ratelimited(smmu->dev, "CMDQ timeout\n");
    1838:	91008038 	add	x24, x1, #0x20
    183c:	0b020019 	add	w25, w0, w2
		while (!queue_has_space(&llq, n + sync)) {
    1840:	29501341 	ldp	w1, w4, [x26, #128]
	cons = Q_IDX(q, q->cons);
    1844:	0a160080 	and	w0, w4, w22
	prod = Q_IDX(q, q->prod);
    1848:	0a160023 	and	w3, w1, w22
		space = (1 << q->max_n_shift) - (prod - cons);
    184c:	0b130002 	add	w2, w0, w19
	if (Q_WRP(q, q->prod) == Q_WRP(q, q->cons))
    1850:	4a010089 	eor	w9, w4, w1
		space = (1 << q->max_n_shift) - (prod - cons);
    1854:	6a13013f 	tst	w9, w19
    1858:	4b030042 	sub	w2, w2, w3
    185c:	4b030000 	sub	w0, w0, w3
    1860:	1a821000 	csel	w0, w0, w2, ne  // ne = any
		while (!queue_has_space(&llq, n + sync)) {
    1864:	6b19001f 	cmp	w0, w25
    1868:	54000c23 	b.cc	19ec <arm_smmu_cmdq_issue_cmdlist+0x284>  // b.lo, b.ul, b.last
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    186c:	0a140023 	and	w3, w1, w20
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1870:	12010020 	and	w0, w1, #0x80000000
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1874:	0b190063 	add	w3, w3, w25
		old = cmpxchg_relaxed(&cmdq->q.llq.val, llq.val, head.val);
    1878:	f94002e1 	ldr	x1, [x23]
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    187c:	0a140063 	and	w3, w3, w20
    1880:	2a000063 	orr	w3, w3, w0
		head.prod = queue_inc_prod_n(&llq, n + sync) |
    1884:	32010060 	orr	w0, w3, #0x80000000
		head.cons = llq.cons;
    1888:	29001340 	stp	w0, w4, [x26]
		old = cmpxchg_relaxed(&cmdq->q.llq.val, llq.val, head.val);
    188c:	f9400342 	ldr	x2, [x26]
    1890:	1400000b 	b	18bc <arm_smmu_cmdq_issue_cmdlist+0x154>
    1894:	1400000a 	b	18bc <arm_smmu_cmdq_issue_cmdlist+0x154>
}

__CMPXCHG_CASE(w, b,     ,  8,   )
__CMPXCHG_CASE(w, h,     , 16,   )
__CMPXCHG_CASE(w,  ,     , 32,   )
__CMPXCHG_CASE(x,  ,     , 64,   )
    1898:	aa1b03e0 	mov	x0, x27
    189c:	aa0103e4 	mov	x4, x1
    18a0:	c8a47f62 	cas	x4, x2, [x27]
    18a4:	aa0403e0 	mov	x0, x4
		if (old == llq.val)
    18a8:	f94002e1 	ldr	x1, [x23]
    18ac:	eb00003f 	cmp	x1, x0
    18b0:	540000e0 	b.eq	18cc <arm_smmu_cmdq_issue_cmdlist+0x164>  // b.none
		llq.val = old;
    18b4:	f90002e0 	str	x0, [x23]
	do {
    18b8:	17ffffe2 	b	1840 <arm_smmu_cmdq_issue_cmdlist+0xd8>
 * constraint for 32 bit operations.
 */
__CMPXCHG_CASE(w, b,     ,  8,        ,  ,  ,         , K)
__CMPXCHG_CASE(w, h,     , 16,        ,  ,  ,         , K)
__CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
__CMPXCHG_CASE( ,  ,     , 64,        ,  ,  ,         , L)
    18bc:	14000c63 	b	4a48 <arm_smmu_flush_iotlb_all+0xb0>
		if (old == llq.val)
    18c0:	f94002e1 	ldr	x1, [x23]
    18c4:	eb00003f 	cmp	x1, x0
    18c8:	54ffff61 	b.ne	18b4 <arm_smmu_cmdq_issue_cmdlist+0x14c>  // b.any
	owner = !(llq.prod & CMDQ_PROD_OWNED_FLAG);
    18cc:	b94002f9 	ldr	w25, [x23]
	head.prod &= ~CMDQ_PROD_OWNED_FLAG;
    18d0:	12007860 	and	w0, w3, #0x7fffffff
    18d4:	b9000340 	str	w0, [x26]
	llq.prod &= ~CMDQ_PROD_OWNED_FLAG;
    18d8:	12007b2c 	and	w12, w25, #0x7fffffff
	for (i = 0; i < n; ++i) {
    18dc:	b9406ba0 	ldr	w0, [x29, #104]
	llq.prod &= ~CMDQ_PROD_OWNED_FLAG;
    18e0:	b90002ec 	str	w12, [x23]
		.max_n_shift	= cmdq->q.llq.max_n_shift,
    18e4:	b9404362 	ldr	w2, [x27, #64]
	for (i = 0; i < n; ++i) {
    18e8:	7100001f 	cmp	w0, #0x0
    18ec:	5400038d 	b.le	195c <arm_smmu_cmdq_issue_cmdlist+0x1f4>
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    18f0:	5280002d 	mov	w13, #0x1                   	// #1
    18f4:	5100040a 	sub	w10, w0, #0x1
    18f8:	1ac221a0 	lsl	w0, w13, w2
    18fc:	5100040b 	sub	w11, w0, #0x1
    1900:	2a00016b 	orr	w11, w11, w0
    1904:	f94033b8 	ldr	x24, [x29, #96]
    1908:	0a0b0181 	and	w1, w12, w11
    190c:	0b01014a 	add	w10, w10, w1
    1910:	14000003 	b	191c <arm_smmu_cmdq_issue_cmdlist+0x1b4>
    1914:	b9404362 	ldr	w2, [x27, #64]
    1918:	11000421 	add	w1, w1, #0x1
		queue_write(Q_ENT(&cmdq->q, prod), cmd, CMDQ_ENT_DWORDS);
    191c:	f9405363 	ldr	x3, [x27, #160]
    1920:	1ac221a0 	lsl	w0, w13, w2
    1924:	51000400 	sub	w0, w0, #0x1
    1928:	f9404764 	ldr	x4, [x27, #136]
    192c:	0a0b0000 	and	w0, w0, w11
		*dst++ = cpu_to_le64(*src++);
    1930:	f9400309 	ldr	x9, [x24]
		queue_write(Q_ENT(&cmdq->q, prod), cmd, CMDQ_ENT_DWORDS);
    1934:	d37df062 	lsl	x2, x3, #3
    1938:	0a010000 	and	w0, w0, w1
    193c:	91004318 	add	x24, x24, #0x10
	for (i = 0; i < n; ++i) {
    1940:	6b0a003f 	cmp	w1, w10
		queue_write(Q_ENT(&cmdq->q, prod), cmd, CMDQ_ENT_DWORDS);
    1944:	9b027c00 	mul	x0, x0, x2
    1948:	8b000082 	add	x2, x4, x0
		*dst++ = cpu_to_le64(*src++);
    194c:	f8206889 	str	x9, [x4, x0]
    1950:	f85f8300 	ldur	x0, [x24, #-8]
    1954:	f9000440 	str	x0, [x2, #8]
	for (i = 0; i < n; ++i) {
    1958:	54fffde1 	b.ne	1914 <arm_smmu_cmdq_issue_cmdlist+0x1ac>  // b.any
	if (sync) {
    195c:	b9406fa0 	ldr	w0, [x29, #108]
    1960:	35001b40 	cbnz	w0, 1cc8 <arm_smmu_cmdq_issue_cmdlist+0x560>
	dma_wmb();
    1964:	d50332bf 	dmb	oshst
	__arm_smmu_cmdq_poll_set_valid_map(cmdq, sprod, eprod, true);
    1968:	b9400343 	ldr	w3, [x26]
    196c:	91040385 	add	x5, x28, #0x100
    1970:	b9408380 	ldr	w0, [x28, #128]
    1974:	52800024 	mov	w4, #0x1                   	// #1
	arm_smmu_cmdq_set_valid_map(cmdq, llq.prod, head.prod);
    1978:	b9408358 	ldr	w24, [x26, #128]
	__arm_smmu_cmdq_poll_set_valid_map(cmdq, sprod, eprod, true);
    197c:	aa0503e1 	mov	x1, x5
    1980:	f90033a5 	str	x5, [x29, #96]
    1984:	2a1803e2 	mov	w2, w24
    1988:	97fffef4 	bl	1558 <__arm_smmu_cmdq_poll_set_valid_map.isra.25>
	if (owner) {
    198c:	37f80db9 	tbnz	w25, #31, 1b40 <arm_smmu_cmdq_issue_cmdlist+0x3d8>
		atomic_cond_read_relaxed(&cmdq->owner_prod, VAL == llq.prod);
    1990:	b9410b80 	ldr	w0, [x28, #264]
    1994:	91042381 	add	x1, x28, #0x108
    1998:	f94033a5 	ldr	x5, [x29, #96]
    199c:	6b00031f 	cmp	w24, w0
    19a0:	540001a0 	b.eq	19d4 <arm_smmu_cmdq_issue_cmdlist+0x26c>  // b.none
    19a4:	d503201f 	nop
    19a8:	93407c00 	sxtw	x0, w0
__CMPWAIT_CASE(w,  , 32);
    19ac:	d50320bf 	sevl
    19b0:	d503205f 	wfe
    19b4:	885f7c22 	ldxr	w2, [x1]
    19b8:	4a000042 	eor	w2, w2, w0
    19bc:	35000042 	cbnz	w2, 19c4 <arm_smmu_cmdq_issue_cmdlist+0x25c>
    19c0:	d503205f 	wfe
    19c4:	b9410b80 	ldr	w0, [x28, #264]
    19c8:	b94002e2 	ldr	w2, [x23]
    19cc:	6b00005f 	cmp	w2, w0
    19d0:	54fffec1 	b.ne	19a8 <arm_smmu_cmdq_issue_cmdlist+0x240>  // b.any
    19d4:	1400004d 	b	1b08 <arm_smmu_cmdq_issue_cmdlist+0x3a0>
    19d8:	1400004c 	b	1b08 <arm_smmu_cmdq_issue_cmdlist+0x3a0>
ATOMIC_FETCH_OPS(andnot, ldclr)
    19dc:	52b00018 	mov	w24, #0x80000000            	// #-2147483648
    19e0:	91010380 	add	x0, x28, #0x40
    19e4:	b8381018 	ldclr	w24, w24, [x0]
    19e8:	1400004b 	b	1b14 <arm_smmu_cmdq_issue_cmdlist+0x3ac>
/*
 * restore saved IRQ state
 */
static inline void arch_local_irq_restore(unsigned long flags)
{
	asm volatile(ALTERNATIVE(
    19ec:	d51b4235 	msr	daif, x21
	asm volatile(ALTERNATIVE(
    19f0:	d53b4224 	mrs	x4, daif
	asm volatile(ALTERNATIVE(
    19f4:	12190080 	and	w0, w4, #0x80
	if (!arch_irqs_disabled_flags(flags))
    19f8:	35000060 	cbnz	w0, 1a04 <arm_smmu_cmdq_issue_cmdlist+0x29c>
	asm volatile(ALTERNATIVE(
    19fc:	d2800c00 	mov	x0, #0x60                  	// #96
    1a00:	d50342df 	msr	daifset, #0x2
#if defined(arch_atomic_cmpxchg_relaxed)
static __always_inline int
atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
{
	instrument_atomic_write(v, sizeof(*v));
	return arch_atomic_cmpxchg_relaxed(v, old, new);
    1a04:	91043383 	add	x3, x28, #0x10c
    1a08:	14000019 	b	1a6c <arm_smmu_cmdq_issue_cmdlist+0x304>
    1a0c:	14000018 	b	1a6c <arm_smmu_cmdq_issue_cmdlist+0x304>
__CMPXCHG_CASE(w,  ,     , 32,   )
    1a10:	52800001 	mov	w1, #0x0                   	// #0
    1a14:	aa0303e0 	mov	x0, x3
    1a18:	52b00002 	mov	w2, #0x80000000            	// #-2147483648
    1a1c:	2a0103e5 	mov	w5, w1
    1a20:	88a57c62 	cas	w5, w2, [x3]
    1a24:	2a0503e0 	mov	w0, w5
	if (arm_smmu_cmdq_exclusive_trylock_irqsave(cmdq, flags)) {
    1a28:	350002c0 	cbnz	w0, 1a80 <arm_smmu_cmdq_issue_cmdlist+0x318>
    1a2c:	f9405b61 	ldr	x1, [x27, #176]
    1a30:	b9400021 	ldr	w1, [x1]
		WRITE_ONCE(cmdq->q.llq.cons, readl_relaxed(cmdq->q.cons_reg));
    1a34:	b9004781 	str	w1, [x28, #68]

#ifndef arch_atomic_set_release
static __always_inline void
arch_atomic_set_release(atomic_t *v, int i)
{
	smp_store_release(&(v)->counter, i);
    1a38:	91043381 	add	x1, x28, #0x10c
    1a3c:	889ffc20 	stlr	w0, [x1]
	asm volatile(ALTERNATIVE(
    1a40:	d51b4224 	msr	daif, x4
		llq->val = READ_ONCE(cmdq->q.llq.val);
    1a44:	f9400360 	ldr	x0, [x27]
    1a48:	f90002e0 	str	x0, [x23]
    1a4c:	d503201f 	nop
	asm volatile(ALTERNATIVE(
    1a50:	d53b4228 	mrs	x8, daif
    1a54:	aa0803f5 	mov	x21, x8
	asm volatile(ALTERNATIVE(
    1a58:	12190100 	and	w0, w8, #0x80
	if (!arch_irqs_disabled_flags(flags))
    1a5c:	35ffef20 	cbnz	w0, 1840 <arm_smmu_cmdq_issue_cmdlist+0xd8>
	asm volatile(ALTERNATIVE(
    1a60:	d2800c00 	mov	x0, #0x60                  	// #96
    1a64:	d50342df 	msr	daifset, #0x2
    1a68:	17ffff76 	b	1840 <arm_smmu_cmdq_issue_cmdlist+0xd8>
__CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
    1a6c:	d2800001 	mov	x1, #0x0                   	// #0
    1a70:	52b00002 	mov	w2, #0x80000000            	// #-2147483648
    1a74:	91043385 	add	x5, x28, #0x10c
    1a78:	14000c04 	b	4a88 <arm_smmu_flush_iotlb_all+0xf0>
	if (arm_smmu_cmdq_exclusive_trylock_irqsave(cmdq, flags)) {
    1a7c:	34fffd80 	cbz	w0, 1a2c <arm_smmu_cmdq_issue_cmdlist+0x2c4>
	asm volatile(ALTERNATIVE(
    1a80:	d51b4224 	msr	daif, x4
	qp->wfe = !!(smmu->features & ARM_SMMU_FEAT_SEV);
    1a84:	b9401b80 	ldr	w0, [x28, #24]
	qp->delay = 1;
    1a88:	d2800021 	mov	x1, #0x1                   	// #1
    1a8c:	f9003fa1 	str	x1, [x29, #120]
	qp->wfe = !!(smmu->features & ARM_SMMU_FEAT_SEV);
    1a90:	d3461800 	ubfx	x0, x0, #6, #1
    1a94:	390203a0 	strb	w0, [x29, #128]
	qp->timeout = ktime_add_us(ktime_get(), ARM_SMMU_POLL_TIMEOUT_US);
    1a98:	94000000 	bl	0 <ktime_get>
	return ktime_add_ns(kt, usec * NSEC_PER_USEC);
    1a9c:	d2994001 	mov	x1, #0xca00                	// #51712
    1aa0:	f2a77341 	movk	x1, #0x3b9a, lsl #16
    1aa4:	8b010000 	add	x0, x0, x1
    1aa8:	f9003ba0 	str	x0, [x29, #112]
    1aac:	d503201f 	nop
		llq->val = READ_ONCE(smmu->cmdq.q.llq.val);
    1ab0:	f9402380 	ldr	x0, [x28, #64]
    1ab4:	f90002e0 	str	x0, [x23]
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
    1ab8:	d360fc01 	lsr	x1, x0, #32
    1abc:	4a010000 	eor	w0, w0, w1
    1ac0:	6a0002df 	tst	w22, w0
    1ac4:	54fffc61 	b.ne	1a50 <arm_smmu_cmdq_issue_cmdlist+0x2e8>  // b.any
    1ac8:	6a00027f 	tst	w19, w0
    1acc:	54fffc20 	b.eq	1a50 <arm_smmu_cmdq_issue_cmdlist+0x2e8>  // b.none
		ret = queue_poll(&qp);
    1ad0:	9101c3a0 	add	x0, x29, #0x70
    1ad4:	97fffe29 	bl	1378 <queue_poll>
	} while (!ret);
    1ad8:	34fffec0 	cbz	w0, 1ab0 <arm_smmu_cmdq_issue_cmdlist+0x348>
				dev_err_ratelimited(smmu->dev, "CMDQ timeout\n");
    1adc:	90000000 	adrp	x0, 0 <queue_remove_raw>
    1ae0:	91000000 	add	x0, x0, #0x0
    1ae4:	aa1803e1 	mov	x1, x24
    1ae8:	91052000 	add	x0, x0, #0x148
    1aec:	94000000 	bl	0 <___ratelimit>
    1af0:	34fffb00 	cbz	w0, 1a50 <arm_smmu_cmdq_issue_cmdlist+0x2e8>
    1af4:	f9400380 	ldr	x0, [x28]
    1af8:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1afc:	91000021 	add	x1, x1, #0x0
    1b00:	94000000 	bl	0 <_dev_err>
    1b04:	17ffffd3 	b	1a50 <arm_smmu_cmdq_issue_cmdlist+0x2e8>
ATOMIC_OPS(andnot, bic, )
    1b08:	52b00000 	mov	w0, #0x80000000            	// #-2147483648
    1b0c:	91010383 	add	x3, x28, #0x40
    1b10:	14000be6 	b	4aa8 <arm_smmu_flush_iotlb_all+0x110>
	__arm_smmu_cmdq_poll_set_valid_map(cmdq, sprod, eprod, false);
    1b14:	b9408380 	ldr	w0, [x28, #128]
		prod &= ~CMDQ_PROD_OWNED_FLAG;
    1b18:	12007b18 	and	w24, w24, #0x7fffffff
	__arm_smmu_cmdq_poll_set_valid_map(cmdq, sprod, eprod, false);
    1b1c:	b9408342 	ldr	w2, [x26, #128]
    1b20:	52800004 	mov	w4, #0x0                   	// #0
    1b24:	2a1803e3 	mov	w3, w24
    1b28:	aa0503e1 	mov	x1, x5
    1b2c:	97fffe8b 	bl	1558 <__arm_smmu_cmdq_poll_set_valid_map.isra.25>
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    1b30:	f9405760 	ldr	x0, [x27, #168]
    1b34:	b9000018 	str	w24, [x0]
    1b38:	91042380 	add	x0, x28, #0x108
    1b3c:	889ffc18 	stlr	w24, [x0]
	if (sync) {
    1b40:	b9406fa0 	ldr	w0, [x29, #108]
	int ret = 0;
    1b44:	52800018 	mov	w24, #0x0                   	// #0
	if (sync) {
    1b48:	35000220 	cbnz	w0, 1b8c <arm_smmu_cmdq_issue_cmdlist+0x424>
    1b4c:	d51b4235 	msr	daif, x21
}
    1b50:	90000000 	adrp	x0, 0 <__stack_chk_guard>
    1b54:	91000015 	add	x21, x0, #0x0
    1b58:	f940f7a2 	ldr	x2, [x29, #488]
    1b5c:	f94002a1 	ldr	x1, [x21]
    1b60:	ca010041 	eor	x1, x2, x1
    1b64:	2a1803e0 	mov	w0, w24
    1b68:	b5001b61 	cbnz	x1, 1ed4 <arm_smmu_cmdq_issue_cmdlist+0x76c>
    1b6c:	a94153f3 	ldp	x19, x20, [sp, #16]
    1b70:	a9425bf5 	ldp	x21, x22, [sp, #32]
    1b74:	a94363f7 	ldp	x23, x24, [sp, #48]
    1b78:	a9446bf9 	ldp	x25, x26, [sp, #64]
    1b7c:	a94573fb 	ldp	x27, x28, [sp, #80]
    1b80:	a8df7bfd 	ldp	x29, x30, [sp], #496
    1b84:	d50323bf 	autiasp
    1b88:	d65f03c0 	ret
		llq.prod = queue_inc_prod_n(&llq, n);
    1b8c:	b9408342 	ldr	w2, [x26, #128]
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1b90:	b9406ba3 	ldr	w3, [x29, #104]
    1b94:	0a140040 	and	w0, w2, w20
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1b98:	b9401b81 	ldr	w1, [x28, #24]
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1b9c:	0b030003 	add	w3, w0, w3
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1ba0:	12010042 	and	w2, w2, #0x80000000
    1ba4:	0a140063 	and	w3, w3, w20
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1ba8:	12190420 	and	w0, w1, #0x180
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1bac:	2a020079 	orr	w25, w3, w2
		llq.prod = queue_inc_prod_n(&llq, n);
    1bb0:	b9008359 	str	w25, [x26, #128]
    1bb4:	d3461821 	ubfx	x1, x1, #6, #1
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1bb8:	7106001f 	cmp	w0, #0x180
    1bbc:	540011c0 	b.eq	1df4 <arm_smmu_cmdq_issue_cmdlist+0x68c>  // b.none
	qp->delay = 1;
    1bc0:	d2800020 	mov	x0, #0x1                   	// #1
    1bc4:	f9003fa0 	str	x0, [x29, #120]
	qp->wfe = !!(smmu->features & ARM_SMMU_FEAT_SEV);
    1bc8:	390203a1 	strb	w1, [x29, #128]
    1bcc:	0a1902d4 	and	w20, w22, w25
	qp->timeout = ktime_add_us(ktime_get(), ARM_SMMU_POLL_TIMEOUT_US);
    1bd0:	94000000 	bl	0 <ktime_get>
	llq->val = READ_ONCE(smmu->cmdq.q.llq.val);
    1bd4:	f9402381 	ldr	x1, [x28, #64]
    1bd8:	d2994002 	mov	x2, #0xca00                	// #51712
    1bdc:	f9004341 	str	x1, [x26, #128]
    1be0:	f2a77342 	movk	x2, #0x3b9a, lsl #16
    1be4:	8b020000 	add	x0, x0, x2
	qp->timeout = ktime_add_us(ktime_get(), ARM_SMMU_POLL_TIMEOUT_US);
    1be8:	f9003ba0 	str	x0, [x29, #112]
    1bec:	d360fc21 	lsr	x1, x1, #32
	return ((Q_WRP(q, q->cons) == Q_WRP(q, prod)) &&
    1bf0:	4a010320 	eor	w0, w25, w1
    1bf4:	0a0102c1 	and	w1, w22, w1
		(Q_IDX(q, q->cons) > Q_IDX(q, prod))) ||
    1bf8:	6a13001f 	tst	w0, w19
    1bfc:	54000200 	b.eq	1c3c <arm_smmu_cmdq_issue_cmdlist+0x4d4>  // b.none
	       ((Q_WRP(q, q->cons) != Q_WRP(q, prod)) &&
    1c00:	6b14003f 	cmp	w1, w20
    1c04:	54000208 	b.hi	1c44 <arm_smmu_cmdq_issue_cmdlist+0x4dc>  // b.pmore
    1c08:	52800018 	mov	w24, #0x0                   	// #0
	return arch_atomic_read(v);
    1c0c:	b9410f81 	ldr	w1, [x28, #268]
    1c10:	91043380 	add	x0, x28, #0x10c
	if (atomic_read(&cmdq->lock) == 1)
    1c14:	7100043f 	cmp	w1, #0x1
    1c18:	540013a0 	b.eq	1e8c <arm_smmu_cmdq_issue_cmdlist+0x724>  // b.none
    1c1c:	14000027 	b	1cb8 <arm_smmu_cmdq_issue_cmdlist+0x550>
    1c20:	14000026 	b	1cb8 <arm_smmu_cmdq_issue_cmdlist+0x550>
ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
    1c24:	52800021 	mov	w1, #0x1                   	// #1
    1c28:	91043383 	add	x3, x28, #0x10c
    1c2c:	4b0103e1 	neg	w1, w1
    1c30:	b8610062 	ldaddl	w1, w2, [x3]
    1c34:	0b020021 	add	w1, w1, w2
    1c38:	17ffffc5 	b	1b4c <arm_smmu_cmdq_issue_cmdlist+0x3e4>
	return ((Q_WRP(q, q->cons) == Q_WRP(q, prod)) &&
    1c3c:	6b14003f 	cmp	w1, w20
    1c40:	54fffe48 	b.hi	1c08 <arm_smmu_cmdq_issue_cmdlist+0x4a0>  // b.pmore
		ret = queue_poll(&qp);
    1c44:	9101c3a0 	add	x0, x29, #0x70
    1c48:	97fffdcc 	bl	1378 <queue_poll>
	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    1c4c:	f9405b61 	ldr	x1, [x27, #176]
    1c50:	2a0003f8 	mov	w24, w0
    1c54:	b9400021 	ldr	w1, [x1]
		llq->cons = readl(cmdq->q.cons_reg);
    1c58:	d50331bf 	dmb	oshld
    1c5c:	2a0103e0 	mov	w0, w1
    1c60:	ca000000 	eor	x0, x0, x0
    1c64:	b5000000 	cbnz	x0, 1c64 <arm_smmu_cmdq_issue_cmdlist+0x4fc>
    1c68:	b90006e1 	str	w1, [x23, #4]
	} while (!ret);
    1c6c:	34fffc38 	cbz	w24, 1bf0 <arm_smmu_cmdq_issue_cmdlist+0x488>
			dev_err_ratelimited(smmu->dev,
    1c70:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1c74:	90000000 	adrp	x0, 0 <queue_remove_raw>
    1c78:	91000021 	add	x1, x1, #0x0
    1c7c:	91000000 	add	x0, x0, #0x0
    1c80:	91008021 	add	x1, x1, #0x20
    1c84:	91048000 	add	x0, x0, #0x120
    1c88:	94000000 	bl	0 <___ratelimit>
    1c8c:	34fffc00 	cbz	w0, 1c0c <arm_smmu_cmdq_issue_cmdlist+0x4a4>
    1c90:	f9405763 	ldr	x3, [x27, #168]
    1c94:	b9400063 	ldr	w3, [x3]
    1c98:	f9405b64 	ldr	x4, [x27, #176]
    1c9c:	b9400084 	ldr	w4, [x4]
    1ca0:	b9408342 	ldr	w2, [x26, #128]
    1ca4:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1ca8:	f9400380 	ldr	x0, [x28]
    1cac:	91000021 	add	x1, x1, #0x0
    1cb0:	94000000 	bl	0 <_dev_err>
    1cb4:	17ffffd6 	b	1c0c <arm_smmu_cmdq_issue_cmdlist+0x4a4>
ATOMIC_OPS(sub, sub, J)
    1cb8:	52800020 	mov	w0, #0x1                   	// #1
    1cbc:	91043383 	add	x3, x28, #0x10c
    1cc0:	14000b84 	b	4ad0 <arm_smmu_flush_iotlb_all+0x138>
    1cc4:	17ffffa2 	b	1b4c <arm_smmu_cmdq_issue_cmdlist+0x3e4>
	struct arm_smmu_cmdq_ent ent = {
    1cc8:	528008c1 	mov	w1, #0x46                  	// #70
    1ccc:	a9077fbf 	stp	xzr, xzr, [x29, #112]
    1cd0:	3901c3a1 	strb	w1, [x29, #112]
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1cd4:	0a140189 	and	w9, w12, w20
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1cd8:	b9401b80 	ldr	w0, [x28, #24]
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1cdc:	b9406ba1 	ldr	w1, [x29, #104]
	struct arm_smmu_cmdq_ent ent = {
    1ce0:	a9087fbf 	stp	xzr, xzr, [x29, #128]
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1ce4:	12190400 	and	w0, w0, #0x180
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1ce8:	0b010129 	add	w9, w9, w1
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1cec:	7106001f 	cmp	w0, #0x180
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1cf0:	0a140129 	and	w9, w9, w20
	if (smmu->features & ARM_SMMU_FEAT_MSI &&
    1cf4:	54000161 	b.ne	1d20 <arm_smmu_cmdq_issue_cmdlist+0x5b8>  // b.any
		ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    1cf8:	b9404363 	ldr	w3, [x27, #64]
    1cfc:	52800020 	mov	w0, #0x1                   	// #1
				   q->ent_dwords * 8;
    1d00:	f9405361 	ldr	x1, [x27, #160]
		ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    1d04:	f9404b62 	ldr	x2, [x27, #144]
    1d08:	1ac32000 	lsl	w0, w0, w3
    1d0c:	51000400 	sub	w0, w0, #0x1
    1d10:	0a090000 	and	w0, w0, w9
				   q->ent_dwords * 8;
    1d14:	d37df021 	lsl	x1, x1, #3
		ent.sync.msiaddr = q->base_dma + Q_IDX(&q->llq, prod) *
    1d18:	9b010800 	madd	x0, x0, x1, x2
    1d1c:	f9003fa0 	str	x0, [x29, #120]
	arm_smmu_cmdq_build_cmd(cmd, &ent);
    1d20:	9101c3a1 	add	x1, x29, #0x70
    1d24:	910763a0 	add	x0, x29, #0x1d8
    1d28:	97fffa14 	bl	578 <arm_smmu_cmdq_build_cmd>
		queue_write(Q_ENT(&cmdq->q, prod), cmd_sync, CMDQ_ENT_DWORDS);
    1d2c:	b9404364 	ldr	w4, [x27, #64]
    1d30:	52800020 	mov	w0, #0x1                   	// #1
    1d34:	f9405361 	ldr	x1, [x27, #160]
    1d38:	f9404762 	ldr	x2, [x27, #136]
    1d3c:	1ac42000 	lsl	w0, w0, w4
    1d40:	51000400 	sub	w0, w0, #0x1
    1d44:	d37df021 	lsl	x1, x1, #3
    1d48:	0a090000 	and	w0, w0, w9
		*dst++ = cpu_to_le64(*src++);
    1d4c:	f940efa3 	ldr	x3, [x29, #472]
	if (atomic_fetch_inc_relaxed(&cmdq->lock) >= 0)
    1d50:	91043384 	add	x4, x28, #0x10c
		queue_write(Q_ENT(&cmdq->q, prod), cmd_sync, CMDQ_ENT_DWORDS);
    1d54:	9b017c00 	mul	x0, x0, x1
    1d58:	8b000041 	add	x1, x2, x0
		*dst++ = cpu_to_le64(*src++);
    1d5c:	f8206843 	str	x3, [x2, x0]
    1d60:	f940f3a0 	ldr	x0, [x29, #480]
    1d64:	f9000420 	str	x0, [x1, #8]
    1d68:	1400001d 	b	1ddc <arm_smmu_cmdq_issue_cmdlist+0x674>
    1d6c:	1400001c 	b	1ddc <arm_smmu_cmdq_issue_cmdlist+0x674>
ATOMIC_FETCH_OPS(add, ldadd)
    1d70:	52800020 	mov	w0, #0x1                   	// #1
    1d74:	b8200080 	ldadd	w0, w0, [x4]
	if (atomic_fetch_inc_relaxed(&cmdq->lock) >= 0)
    1d78:	36ffdf60 	tbz	w0, #31, 1964 <arm_smmu_cmdq_issue_cmdlist+0x1fc>
		val = atomic_cond_read_relaxed(&cmdq->lock, VAL >= 0);
    1d7c:	b9410f83 	ldr	w3, [x28, #268]
    1d80:	36f80163 	tbz	w3, #31, 1dac <arm_smmu_cmdq_issue_cmdlist+0x644>
    1d84:	d503201f 	nop
    1d88:	93407c63 	sxtw	x3, w3
    1d8c:	d50320bf 	sevl
    1d90:	d503205f 	wfe
    1d94:	885f7c80 	ldxr	w0, [x4]
    1d98:	4a030000 	eor	w0, w0, w3
    1d9c:	35000040 	cbnz	w0, 1da4 <arm_smmu_cmdq_issue_cmdlist+0x63c>
    1da0:	d503205f 	wfe
    1da4:	b9410f83 	ldr	w3, [x28, #268]
    1da8:	37ffff03 	tbnz	w3, #31, 1d88 <arm_smmu_cmdq_issue_cmdlist+0x620>
	return arch_atomic_cmpxchg_relaxed(v, old, new);
    1dac:	93407c61 	sxtw	x1, w3
	} while (atomic_cmpxchg_relaxed(&cmdq->lock, val, val + 1) != val);
    1db0:	11000462 	add	w2, w3, #0x1
    1db4:	1400000e 	b	1dec <arm_smmu_cmdq_issue_cmdlist+0x684>
    1db8:	1400000d 	b	1dec <arm_smmu_cmdq_issue_cmdlist+0x684>
__CMPXCHG_CASE(w,  ,     , 32,   )
    1dbc:	aa0403e0 	mov	x0, x4
    1dc0:	2a0303e1 	mov	w1, w3
    1dc4:	2a0103e5 	mov	w5, w1
    1dc8:	88a57c82 	cas	w5, w2, [x4]
    1dcc:	2a0503e0 	mov	w0, w5
    1dd0:	6b03001f 	cmp	w0, w3
    1dd4:	54fffe81 	b.ne	1da4 <arm_smmu_cmdq_issue_cmdlist+0x63c>  // b.any
    1dd8:	17fffee3 	b	1964 <arm_smmu_cmdq_issue_cmdlist+0x1fc>
ATOMIC_OPS(add, add, I)
    1ddc:	91043383 	add	x3, x28, #0x10c
    1de0:	14000b42 	b	4ae8 <arm_smmu_flush_iotlb_all+0x150>
	if (atomic_fetch_inc_relaxed(&cmdq->lock) >= 0)
    1de4:	36ffdc00 	tbz	w0, #31, 1964 <arm_smmu_cmdq_issue_cmdlist+0x1fc>
    1de8:	17ffffe5 	b	1d7c <arm_smmu_cmdq_issue_cmdlist+0x614>
__CMPXCHG_CASE(w,  ,     , 32,        ,  ,  ,         , K)
    1dec:	14000b45 	b	4b00 <arm_smmu_flush_iotlb_all+0x168>
    1df0:	17fffff8 	b	1dd0 <arm_smmu_cmdq_issue_cmdlist+0x668>
	u32 *cmd = (u32 *)(Q_ENT(&cmdq->q, llq->prod));
    1df4:	b9404362 	ldr	w2, [x27, #64]
    1df8:	52800033 	mov	w19, #0x1                   	// #1
    1dfc:	f9405360 	ldr	x0, [x27, #160]
	qp->delay = 1;
    1e00:	d2800023 	mov	x3, #0x1                   	// #1
	u32 *cmd = (u32 *)(Q_ENT(&cmdq->q, llq->prod));
    1e04:	f9404778 	ldr	x24, [x27, #136]
    1e08:	1ac22273 	lsl	w19, w19, w2
    1e0c:	51000673 	sub	w19, w19, #0x1
    1e10:	d37df000 	lsl	x0, x0, #3
    1e14:	0a190273 	and	w19, w19, w25
	qp->delay = 1;
    1e18:	f9003fa3 	str	x3, [x29, #120]
	qp->wfe = !!(smmu->features & ARM_SMMU_FEAT_SEV);
    1e1c:	390203a1 	strb	w1, [x29, #128]
	u32 *cmd = (u32 *)(Q_ENT(&cmdq->q, llq->prod));
    1e20:	9b007e73 	mul	x19, x19, x0
	qp->timeout = ktime_add_us(ktime_get(), ARM_SMMU_POLL_TIMEOUT_US);
    1e24:	94000000 	bl	0 <ktime_get>
    1e28:	d2994001 	mov	x1, #0xca00                	// #51712
	qp.wfe = false;
    1e2c:	390203bf 	strb	wzr, [x29, #128]
    1e30:	f2a77341 	movk	x1, #0x3b9a, lsl #16
    1e34:	8b010000 	add	x0, x0, x1
	qp->timeout = ktime_add_us(ktime_get(), ARM_SMMU_POLL_TIMEOUT_US);
    1e38:	f9003ba0 	str	x0, [x29, #112]
	u32 *cmd = (u32 *)(Q_ENT(&cmdq->q, llq->prod));
    1e3c:	8b130316 	add	x22, x24, x19
	smp_cond_load_relaxed(cmd, !VAL || (ret = queue_poll(&qp)));
    1e40:	b8736b13 	ldr	w19, [x24, x19]
    1e44:	35000173 	cbnz	w19, 1e70 <arm_smmu_cmdq_issue_cmdlist+0x708>
    1e48:	1400001b 	b	1eb4 <arm_smmu_cmdq_issue_cmdlist+0x74c>
    1e4c:	2a1303f3 	mov	w19, w19
    1e50:	d50320bf 	sevl
    1e54:	d503205f 	wfe
    1e58:	885f7ec0 	ldxr	w0, [x22]
    1e5c:	4a130000 	eor	w0, w0, w19
    1e60:	35000040 	cbnz	w0, 1e68 <arm_smmu_cmdq_issue_cmdlist+0x700>
    1e64:	d503205f 	wfe
    1e68:	b94002d3 	ldr	w19, [x22]
    1e6c:	34000233 	cbz	w19, 1eb0 <arm_smmu_cmdq_issue_cmdlist+0x748>
    1e70:	9101c3a0 	add	x0, x29, #0x70
    1e74:	97fffd41 	bl	1378 <queue_poll>
    1e78:	2a0003f8 	mov	w24, w0
    1e7c:	34fffe80 	cbz	w0, 1e4c <arm_smmu_cmdq_issue_cmdlist+0x6e4>
	llq->cons = ret ? llq->prod : queue_inc_prod_n(llq, 1);
    1e80:	b9408340 	ldr	w0, [x26, #128]
    1e84:	b90006e0 	str	w0, [x23, #4]
    1e88:	17ffff7a 	b	1c70 <arm_smmu_cmdq_issue_cmdlist+0x508>
			WRITE_ONCE(cmdq->q.llq.cons, llq.cons);
    1e8c:	b94006e1 	ldr	w1, [x23, #4]
    1e90:	b9004781 	str	w1, [x28, #68]
    1e94:	17ffff89 	b	1cb8 <arm_smmu_cmdq_issue_cmdlist+0x550>
    1e98:	17ffff88 	b	1cb8 <arm_smmu_cmdq_issue_cmdlist+0x550>
ATOMIC_OP_SUB_RETURN(_release,  l, "memory")
    1e9c:	52800021 	mov	w1, #0x1                   	// #1
    1ea0:	4b0103e1 	neg	w1, w1
    1ea4:	b8610002 	ldaddl	w1, w2, [x0]
    1ea8:	0b020021 	add	w1, w1, w2
    1eac:	17ffff28 	b	1b4c <arm_smmu_cmdq_issue_cmdlist+0x3e4>
    1eb0:	b9408359 	ldr	w25, [x26, #128]
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1eb4:	0a190280 	and	w0, w20, w25
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1eb8:	12010336 	and	w22, w25, #0x80000000
	u32 prod = (Q_WRP(q, q->prod) | Q_IDX(q, q->prod)) + n;
    1ebc:	11000400 	add	w0, w0, #0x1
    1ec0:	52800018 	mov	w24, #0x0                   	// #0
	return Q_OVF(q->prod) | Q_WRP(q, prod) | Q_IDX(q, prod);
    1ec4:	0a140014 	and	w20, w0, w20
    1ec8:	2a160296 	orr	w22, w20, w22
	llq->cons = ret ? llq->prod : queue_inc_prod_n(llq, 1);
    1ecc:	b90006f6 	str	w22, [x23, #4]
    1ed0:	17ffff4f 	b	1c0c <arm_smmu_cmdq_issue_cmdlist+0x4a4>
}
    1ed4:	94000000 	bl	0 <__stack_chk_fail>

0000000000001ed8 <arm_smmu_cmdq_issue_cmd>:
{
    1ed8:	d503233f 	paciasp
    1edc:	a9bc7bfd 	stp	x29, x30, [sp, #-64]!
    1ee0:	aa0003e7 	mov	x7, x0
    1ee4:	aa0103e8 	mov	x8, x1
    1ee8:	910003fd 	mov	x29, sp
    1eec:	f9000bf3 	str	x19, [sp, #16]
    1ef0:	90000013 	adrp	x19, 0 <__stack_chk_guard>
    1ef4:	91000262 	add	x2, x19, #0x0
    1ef8:	f9400040 	ldr	x0, [x2]
    1efc:	f9001fa0 	str	x0, [x29, #56]
    1f00:	d2800000 	mov	x0, #0x0                   	// #0
	if (arm_smmu_cmdq_build_cmd(cmd, ent)) {
    1f04:	9100a3a0 	add	x0, x29, #0x28
    1f08:	97fff99c 	bl	578 <arm_smmu_cmdq_build_cmd>
    1f0c:	350001e0 	cbnz	w0, 1f48 <arm_smmu_cmdq_issue_cmd+0x70>
	return arm_smmu_cmdq_issue_cmdlist(smmu, cmd, 1, false);
    1f10:	52800003 	mov	w3, #0x0                   	// #0
    1f14:	52800022 	mov	w2, #0x1                   	// #1
    1f18:	9100a3a1 	add	x1, x29, #0x28
    1f1c:	aa0703e0 	mov	x0, x7
    1f20:	97fffe12 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
}
    1f24:	91000273 	add	x19, x19, #0x0
    1f28:	f9401fa2 	ldr	x2, [x29, #56]
    1f2c:	f9400261 	ldr	x1, [x19]
    1f30:	ca010041 	eor	x1, x2, x1
    1f34:	b5000181 	cbnz	x1, 1f64 <arm_smmu_cmdq_issue_cmd+0x8c>
    1f38:	f9400bf3 	ldr	x19, [sp, #16]
    1f3c:	a8c47bfd 	ldp	x29, x30, [sp], #64
    1f40:	d50323bf 	autiasp
    1f44:	d65f03c0 	ret
		dev_warn(smmu->dev, "ignoring unknown CMDQ opcode 0x%x\n",
    1f48:	f94000e0 	ldr	x0, [x7]
    1f4c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    1f50:	39400102 	ldrb	w2, [x8]
    1f54:	91000021 	add	x1, x1, #0x0
    1f58:	94000000 	bl	0 <_dev_warn>
    1f5c:	128002a0 	mov	w0, #0xffffffea            	// #-22
    1f60:	17fffff1 	b	1f24 <arm_smmu_cmdq_issue_cmd+0x4c>
}
    1f64:	94000000 	bl	0 <__stack_chk_fail>

0000000000001f68 <arm_smmu_priq_thread>:
{
    1f68:	d503233f 	paciasp
    1f6c:	d10303ff 	sub	sp, sp, #0xc0
    1f70:	a9027bfd 	stp	x29, x30, [sp, #32]
    1f74:	910083fd 	add	x29, sp, #0x20
    1f78:	a90353f3 	stp	x19, x20, [sp, #48]
    1f7c:	aa0103f3 	mov	x19, x1
    1f80:	a9045bf5 	stp	x21, x22, [sp, #64]
    1f84:	90000015 	adrp	x21, 0 <__stack_chk_guard>
    1f88:	a90563f7 	stp	x23, x24, [sp, #80]
    1f8c:	910002a0 	add	x0, x21, #0x0
    1f90:	a9066bf9 	stp	x25, x26, [sp, #96]
			dev_err(smmu->dev, "PRIQ overflow detected -- requests lost\n");
    1f94:	90000017 	adrp	x23, 0 <queue_remove_raw>
{
    1f98:	a90773fb 	stp	x27, x28, [sp, #112]
	dev_info(smmu->dev, "unexpected PRI request received:\n");
    1f9c:	90000016 	adrp	x22, 0 <queue_remove_raw>
	struct arm_smmu_queue *q = &smmu->priq.q;
    1fa0:	91090274 	add	x20, x19, #0x240
			dev_err(smmu->dev, "PRIQ overflow detected -- requests lost\n");
    1fa4:	910002f7 	add	x23, x23, #0x0
{
    1fa8:	f9400001 	ldr	x1, [x0]
    1fac:	f9004fa1 	str	x1, [x29, #152]
    1fb0:	d2800001 	mov	x1, #0x0                   	// #0
	dev_info(smmu->dev, "unexpected PRI request received:\n");
    1fb4:	910002d6 	add	x22, x22, #0x0
		while (!queue_remove_raw(q, evt))
    1fb8:	910223a1 	add	x1, x29, #0x88
    1fbc:	aa1403e0 	mov	x0, x20
    1fc0:	97fff810 	bl	0 <queue_remove_raw>
    1fc4:	34000500 	cbz	w0, 2064 <arm_smmu_priq_thread+0xfc>
		if (queue_sync_prod_in(q) == -EOVERFLOW)
    1fc8:	f9417661 	ldr	x1, [x19, #744]
    1fcc:	aa1403e0 	mov	x0, x20
    1fd0:	97fffb12 	bl	c18 <queue_sync_prod_in.isra.23>
    1fd4:	31012c1f 	cmn	w0, #0x4b
    1fd8:	54000ba0 	b.eq	214c <arm_smmu_priq_thread+0x1e4>  // b.none
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
    1fdc:	b9428261 	ldr	w1, [x19, #640]
    1fe0:	52800020 	mov	w0, #0x1                   	// #1
	} while (!queue_empty(llq));
    1fe4:	b9424262 	ldr	w2, [x19, #576]
    1fe8:	b9424663 	ldr	w3, [x19, #580]
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
    1fec:	1ac12001 	lsl	w1, w0, w1
    1ff0:	51000424 	sub	w4, w1, #0x1
    1ff4:	4a030046 	eor	w6, w2, w3
    1ff8:	2a010085 	orr	w5, w4, w1
    1ffc:	6a0500df 	tst	w6, w5
    2000:	54fffdc1 	b.ne	1fb8 <arm_smmu_priq_thread+0x50>  // b.any
	llq->cons = Q_OVF(llq->prod) | Q_WRP(llq, llq->cons) |
    2004:	12010042 	and	w2, w2, #0x80000000
    2008:	0a010061 	and	w1, w3, w1
    200c:	2a010041 	orr	w1, w2, w1
		      Q_IDX(llq, llq->cons);
    2010:	0a040063 	and	w3, w3, w4
	llq->cons = Q_OVF(llq->prod) | Q_WRP(llq, llq->cons) |
    2014:	2a030021 	orr	w1, w1, w3
    2018:	b9000681 	str	w1, [x20, #4]
	mb();
    201c:	d5033f9f 	dsb	sy
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    2020:	b9424661 	ldr	w1, [x19, #580]
    2024:	f9417a62 	ldr	x2, [x19, #752]
    2028:	b9000041 	str	w1, [x2]
}
    202c:	910002b5 	add	x21, x21, #0x0
    2030:	f9404fa2 	ldr	x2, [x29, #152]
    2034:	f94002a1 	ldr	x1, [x21]
    2038:	ca010041 	eor	x1, x2, x1
    203c:	b5000901 	cbnz	x1, 215c <arm_smmu_priq_thread+0x1f4>
    2040:	a9427bfd 	ldp	x29, x30, [sp, #32]
    2044:	a94353f3 	ldp	x19, x20, [sp, #48]
    2048:	a9445bf5 	ldp	x21, x22, [sp, #64]
    204c:	a94563f7 	ldp	x23, x24, [sp, #80]
    2050:	a9466bf9 	ldp	x25, x26, [sp, #96]
    2054:	a94773fb 	ldp	x27, x28, [sp, #112]
    2058:	910303ff 	add	sp, sp, #0xc0
    205c:	d50323bf 	autiasp
    2060:	d65f03c0 	ret
	grpid = FIELD_GET(PRIQ_1_PRG_IDX, evt[1]);
    2064:	a948e3bb 	ldp	x27, x24, [x29, #136]
	dev_info(smmu->dev, "unexpected PRI request received:\n");
    2068:	aa1603e1 	mov	x1, x22
    206c:	f9400260 	ldr	x0, [x19]
	grpid = FIELD_GET(PRIQ_1_PRG_IDX, evt[1]);
    2070:	92402318 	and	x24, x24, #0x1ff
	ssv = FIELD_GET(PRIQ_0_SSID_V, evt[0]);
    2074:	d37fff7c 	lsr	x28, x27, #63
	ssid = ssv ? FIELD_GET(PRIQ_0_SSID, evt[0]) : 0;
    2078:	d360cf79 	ubfx	x25, x27, #32, #20
    207c:	f100039f 	cmp	x28, #0x0
	last = FIELD_GET(PRIQ_0_PRG_LAST, evt[0]);
    2080:	d37efb7a 	ubfx	x26, x27, #62, #1
	ssid = ssv ? FIELD_GET(PRIQ_0_SSID, evt[0]) : 0;
    2084:	1a9903f9 	csel	w25, wzr, w25, eq  // eq = none
	dev_info(smmu->dev, "unexpected PRI request received:\n");
    2088:	94000000 	bl	0 <_dev_info>
	dev_info(smmu->dev,
    208c:	a94893a0 	ldp	x0, x4, [x29, #136]
    2090:	f100035f 	cmp	x26, #0x0
    2094:	90000001 	adrp	x1, 0 <queue_remove_raw>
    2098:	90000005 	adrp	x5, 0 <queue_remove_raw>
    209c:	91000021 	add	x1, x1, #0x0
    20a0:	910000a5 	add	x5, x5, #0x0
    20a4:	9a8110a5 	csel	x5, x5, x1, ne  // ne = any
    20a8:	90000006 	adrp	x6, 0 <queue_remove_raw>
    20ac:	f246001f 	tst	x0, #0x400000000000000
    20b0:	910000c6 	add	x6, x6, #0x0
    20b4:	9a861026 	csel	x6, x1, x6, ne  // ne = any
    20b8:	90000007 	adrp	x7, 0 <queue_remove_raw>
    20bc:	f244001f 	tst	x0, #0x1000000000000000
    20c0:	910000e7 	add	x7, x7, #0x0
    20c4:	9a8110e7 	csel	x7, x7, x1, ne  // ne = any
    20c8:	90000003 	adrp	x3, 0 <queue_remove_raw>
    20cc:	f243001f 	tst	x0, #0x2000000000000000
    20d0:	91000063 	add	x3, x3, #0x0
    20d4:	9a811063 	csel	x3, x3, x1, ne  // ne = any
    20d8:	f245001f 	tst	x0, #0x800000000000000
    20dc:	f9400260 	ldr	x0, [x19]
    20e0:	90000002 	adrp	x2, 0 <queue_remove_raw>
    20e4:	91000042 	add	x2, x2, #0x0
    20e8:	9a811041 	csel	x1, x2, x1, ne  // ne = any
    20ec:	9274cc82 	and	x2, x4, #0xfffffffffffff000
    20f0:	a90007e3 	stp	x3, x1, [sp]
    20f4:	2a1803e4 	mov	w4, w24
    20f8:	f9000be2 	str	x2, [sp, #16]
    20fc:	90000001 	adrp	x1, 0 <queue_remove_raw>
    2100:	2a1903e3 	mov	w3, w25
    2104:	2a1b03e2 	mov	w2, w27
    2108:	91000021 	add	x1, x1, #0x0
    210c:	94000000 	bl	0 <_dev_info>
	if (last) {
    2110:	b4fff55a 	cbz	x26, 1fb8 <arm_smmu_priq_thread+0x50>
		struct arm_smmu_cmdq_ent cmd = {
    2114:	9101aba0 	add	x0, x29, #0x6a
    2118:	52800821 	mov	w1, #0x41                  	// #65
    211c:	3901a3a1 	strb	w1, [x29, #104]
		arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    2120:	9101a3a1 	add	x1, x29, #0x68
	ssv = FIELD_GET(PRIQ_0_SSID_V, evt[0]);
    2124:	3901a7bc 	strb	w28, [x29, #105]
		struct arm_smmu_cmdq_ent cmd = {
    2128:	a9007c1f 	stp	xzr, xzr, [x0]
		arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    212c:	aa1303e0 	mov	x0, x19
		struct arm_smmu_cmdq_ent cmd = {
    2130:	290e67bb 	stp	w27, w25, [x29, #112]
	grpid = FIELD_GET(PRIQ_1_PRG_IDX, evt[1]);
    2134:	7900f3b8 	strh	w24, [x29, #120]
		struct arm_smmu_cmdq_ent cmd = {
    2138:	f807a3bf 	stur	xzr, [x29, #122]
    213c:	b80823bf 	stur	wzr, [x29, #130]
    2140:	79010fbf 	strh	wzr, [x29, #134]
		arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    2144:	97ffff65 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
    2148:	17ffff9c 	b	1fb8 <arm_smmu_priq_thread+0x50>
			dev_err(smmu->dev, "PRIQ overflow detected -- requests lost\n");
    214c:	f9400260 	ldr	x0, [x19]
    2150:	aa1703e1 	mov	x1, x23
    2154:	94000000 	bl	0 <_dev_err>
    2158:	17ffffa1 	b	1fdc <arm_smmu_priq_thread+0x74>
}
    215c:	94000000 	bl	0 <__stack_chk_fail>

0000000000002160 <arm_smmu_combined_irq_thread>:
{
    2160:	d503233f 	paciasp
    2164:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
    2168:	910003fd 	mov	x29, sp
    216c:	a90153f3 	stp	x19, x20, [sp, #16]
    2170:	aa0103f3 	mov	x19, x1
    2174:	2a0003f4 	mov	w20, w0
	arm_smmu_evtq_thread(irq, dev);
    2178:	97fffab2 	bl	c40 <arm_smmu_evtq_thread>
	if (smmu->features & ARM_SMMU_FEAT_PRI)
    217c:	b9401a60 	ldr	w0, [x19, #24]
    2180:	36200080 	tbz	w0, #4, 2190 <arm_smmu_combined_irq_thread+0x30>
		arm_smmu_priq_thread(irq, dev);
    2184:	aa1303e1 	mov	x1, x19
    2188:	2a1403e0 	mov	w0, w20
    218c:	97ffff77 	bl	1f68 <arm_smmu_priq_thread>
}
    2190:	52800020 	mov	w0, #0x1                   	// #1
    2194:	a94153f3 	ldp	x19, x20, [sp, #16]
    2198:	a8c27bfd 	ldp	x29, x30, [sp], #32
    219c:	d50323bf 	autiasp
    21a0:	d65f03c0 	ret
    21a4:	d503201f 	nop

00000000000021a8 <arm_smmu_sync_ste_for_sid>:
{
    21a8:	d503233f 	paciasp
    21ac:	a9ba7bfd 	stp	x29, x30, [sp, #-96]!
    21b0:	910003fd 	mov	x29, sp
    21b4:	a90153f3 	stp	x19, x20, [sp, #16]
    21b8:	90000013 	adrp	x19, 0 <__stack_chk_guard>
    21bc:	91000273 	add	x19, x19, #0x0
	struct arm_smmu_cmdq_ent cmd = {
    21c0:	52800034 	mov	w20, #0x1                   	// #1
{
    21c4:	f9400262 	ldr	x2, [x19]
    21c8:	f9002fa2 	str	x2, [x29, #88]
    21cc:	d2800002 	mov	x2, #0x0                   	// #0
	struct arm_smmu_cmdq_ent cmd = {
    21d0:	a903ffbf 	stp	xzr, xzr, [x29, #56]
    21d4:	52800062 	mov	w2, #0x3                   	// #3
    21d8:	a904ffbf 	stp	xzr, xzr, [x29, #72]
    21dc:	3900e3a2 	strb	w2, [x29, #56]
    21e0:	b90043a1 	str	w1, [x29, #64]
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    21e4:	9100e3a1 	add	x1, x29, #0x38
{
    21e8:	f90013f5 	str	x21, [sp, #32]
    21ec:	aa0003f5 	mov	x21, x0
	struct arm_smmu_cmdq_ent cmd = {
    21f0:	390123b4 	strb	w20, [x29, #72]
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    21f4:	97ffff39 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
	return arm_smmu_cmdq_issue_cmdlist(smmu, NULL, 0, true);
    21f8:	d2800001 	mov	x1, #0x0                   	// #0
    21fc:	2a1403e3 	mov	w3, w20
    2200:	52800002 	mov	w2, #0x0                   	// #0
    2204:	aa1503e0 	mov	x0, x21
    2208:	97fffd58 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
}
    220c:	f9402fa1 	ldr	x1, [x29, #88]
    2210:	f9400260 	ldr	x0, [x19]
    2214:	ca000020 	eor	x0, x1, x0
    2218:	b50000c0 	cbnz	x0, 2230 <arm_smmu_sync_ste_for_sid+0x88>
    221c:	a94153f3 	ldp	x19, x20, [sp, #16]
    2220:	f94013f5 	ldr	x21, [sp, #32]
    2224:	a8c67bfd 	ldp	x29, x30, [sp], #96
    2228:	d50323bf 	autiasp
    222c:	d65f03c0 	ret
    2230:	94000000 	bl	0 <__stack_chk_fail>
    2234:	d503201f 	nop

0000000000002238 <arm_smmu_write_strtab_ent>:
{
    2238:	d503233f 	paciasp
    223c:	a9b97bfd 	stp	x29, x30, [sp, #-112]!
    2240:	910003fd 	mov	x29, sp
    2244:	a90153f3 	stp	x19, x20, [sp, #16]
    2248:	aa0203f3 	mov	x19, x2
    224c:	a9025bf5 	stp	x21, x22, [sp, #32]
    2250:	90000014 	adrp	x20, 0 <__stack_chk_guard>
    2254:	91000282 	add	x2, x20, #0x0
	struct arm_smmu_cmdq_ent prefetch_cmd = {
    2258:	a904ffbf 	stp	xzr, xzr, [x29, #72]
{
    225c:	f9400043 	ldr	x3, [x2]
    2260:	f90037a3 	str	x3, [x29, #104]
    2264:	d2800003 	mov	x3, #0x0                   	// #0
    2268:	2a0103f6 	mov	w22, w1
	u64 val = le64_to_cpu(dst[0]);
    226c:	f9400262 	ldr	x2, [x19]
	struct arm_smmu_cmdq_ent prefetch_cmd = {
    2270:	52800021 	mov	w1, #0x1                   	// #1
    2274:	390123a1 	strb	w1, [x29, #72]
    2278:	b90053b6 	str	w22, [x29, #80]
    227c:	92400043 	and	x3, x2, #0x1
    2280:	a905ffbf 	stp	xzr, xzr, [x29, #88]
	if (master) {
    2284:	b4000940 	cbz	x0, 23ac <arm_smmu_write_strtab_ent+0x174>
		smmu_domain = master->domain;
    2288:	f9400801 	ldr	x1, [x0, #16]
		smmu = master->smmu;
    228c:	f9400015 	ldr	x21, [x0]
	if (smmu_domain) {
    2290:	b4000901 	cbz	x1, 23b0 <arm_smmu_write_strtab_ent+0x178>
		switch (smmu_domain->stage) {
    2294:	b9403824 	ldr	w4, [x1, #56]
    2298:	34000de4 	cbz	w4, 2454 <arm_smmu_write_strtab_ent+0x21c>
    229c:	7100089f 	cmp	w4, #0x2
    22a0:	54000c89 	b.ls	2430 <arm_smmu_write_strtab_ent+0x1f8>  // b.plast
	if (val & STRTAB_STE_0_V) {
    22a4:	b4000c23 	cbz	x3, 2428 <arm_smmu_write_strtab_ent+0x1f0>
	struct arm_smmu_s2_cfg *s2_cfg = NULL;
    22a8:	d2800004 	mov	x4, #0x0                   	// #0
	struct arm_smmu_s1_cfg *s1_cfg = NULL;
    22ac:	d2800001 	mov	x1, #0x0                   	// #0
		switch (FIELD_GET(STRTAB_STE_0_CFG, val)) {
    22b0:	d3410c42 	ubfx	x2, x2, #1, #3
	bool ste_live = false;
    22b4:	52800003 	mov	w3, #0x0                   	// #0
		switch (FIELD_GET(STRTAB_STE_0_CFG, val)) {
    22b8:	f100105f 	cmp	x2, #0x4
    22bc:	540000e0 	b.eq	22d8 <arm_smmu_write_strtab_ent+0xa0>  // b.none
    22c0:	54000e48 	b.hi	2488 <arm_smmu_write_strtab_ent+0x250>  // b.pmore
    22c4:	b5000ae2 	cbnz	x2, 2420 <arm_smmu_write_strtab_ent+0x1e8>
			BUG_ON(!disable_bypass);
    22c8:	90000002 	adrp	x2, 0 <queue_remove_raw>
    22cc:	39400042 	ldrb	w2, [x2]
    22d0:	34000be2 	cbz	w2, 244c <arm_smmu_write_strtab_ent+0x214>
    22d4:	d503201f 	nop
	if (!smmu_domain || !(s1_cfg || s2_cfg)) {
    22d8:	f100003f 	cmp	x1, #0x0
    22dc:	fa400880 	ccmp	x4, #0x0, #0x0, eq  // eq = none
    22e0:	54000a40 	b.eq	2428 <arm_smmu_write_strtab_ent+0x1f0>  // b.none
    22e4:	f9001bb7 	str	x23, [x29, #48]
	if (s1_cfg) {
    22e8:	b4000c81 	cbz	x1, 2478 <arm_smmu_write_strtab_ent+0x240>
		BUG_ON(ste_live);
    22ec:	35000da3 	cbnz	w3, 24a0 <arm_smmu_write_strtab_ent+0x268>
		dst[1] = cpu_to_le64(
    22f0:	d2801ac2 	mov	x2, #0xd6                  	// #214
    22f4:	f9000662 	str	x2, [x19, #8]
		if (smmu->features & ARM_SMMU_FEAT_STALLS &&
    22f8:	52850007 	mov	w7, #0x2800                	// #10240
			dst[1] |= cpu_to_le64(STRTAB_STE_1_S1STALLD);
    22fc:	d2801ac6 	mov	x6, #0xd6                  	// #214
		if (smmu->features & ARM_SMMU_FEAT_STALLS &&
    2300:	b9401aa3 	ldr	w3, [x21, #24]
			dst[1] |= cpu_to_le64(STRTAB_STE_1_S1STALLD);
    2304:	f2a10006 	movk	x6, #0x800, lsl #16
		val |= (s1_cfg->cdcfg.cdtab_dma & STRTAB_STE_0_S1CTXPTR_MASK) |
    2308:	d2800165 	mov	x5, #0xb                   	// #11
		if (smmu->features & ARM_SMMU_FEAT_STALLS &&
    230c:	0a070063 	and	w3, w3, w7
			dst[1] |= cpu_to_le64(STRTAB_STE_1_S1STALLD);
    2310:	7120007f 	cmp	w3, #0x800
    2314:	9a861042 	csel	x2, x2, x6, ne  // ne = any
    2318:	f9000662 	str	x2, [x19, #8]
			FIELD_PREP(STRTAB_STE_0_S1FMT, s1_cfg->s1fmt);
    231c:	39410022 	ldrb	w2, [x1, #64]
			FIELD_PREP(STRTAB_STE_0_S1CDMAX, s1_cfg->s1cdmax) |
    2320:	39410437 	ldrb	w23, [x1, #65]
		val |= (s1_cfg->cdcfg.cdtab_dma & STRTAB_STE_0_S1CTXPTR_MASK) |
    2324:	f9400421 	ldr	x1, [x1, #8]
			FIELD_PREP(STRTAB_STE_0_S1FMT, s1_cfg->s1fmt);
    2328:	d37c0442 	ubfiz	x2, x2, #4, #2
		val |= (s1_cfg->cdcfg.cdtab_dma & STRTAB_STE_0_S1CTXPTR_MASK) |
    232c:	927ab421 	and	x1, x1, #0xfffffffffffc0
    2330:	aa17ec57 	orr	x23, x2, x23, lsl #59
    2334:	aa050021 	orr	x1, x1, x5
    2338:	aa0102f7 	orr	x23, x23, x1
	if (s2_cfg) {
    233c:	b4000184 	cbz	x4, 236c <arm_smmu_write_strtab_ent+0x134>
    2340:	b27e06f7 	orr	x23, x23, #0xc
		dst[2] = cpu_to_le64(
    2344:	f9400881 	ldr	x1, [x4, #16]
    2348:	d2e08903 	mov	x3, #0x448000000000000     	// #308496574474878976
    234c:	79400082 	ldrh	w2, [x4]
    2350:	d3604821 	ubfiz	x1, x1, #32, #19
    2354:	aa030042 	orr	x2, x2, x3
    2358:	aa020021 	orr	x1, x1, x2
    235c:	f9000a61 	str	x1, [x19, #16]
		dst[3] = cpu_to_le64(s2_cfg->vttbr & STRTAB_STE_3_S2TTB_MASK);
    2360:	f9400481 	ldr	x1, [x4, #8]
    2364:	927cbc21 	and	x1, x1, #0xffffffffffff0
    2368:	f9000e61 	str	x1, [x19, #24]
	if (master->ats_enabled)
    236c:	3940d000 	ldrb	w0, [x0, #52]
    2370:	34000080 	cbz	w0, 2380 <arm_smmu_write_strtab_ent+0x148>
		dst[1] |= cpu_to_le64(FIELD_PREP(STRTAB_STE_1_EATS,
    2374:	f9400660 	ldr	x0, [x19, #8]
    2378:	b2640000 	orr	x0, x0, #0x10000000
    237c:	f9000660 	str	x0, [x19, #8]
	arm_smmu_sync_ste_for_sid(smmu, sid);
    2380:	2a1603e1 	mov	w1, w22
    2384:	aa1503e0 	mov	x0, x21
    2388:	97ffff88 	bl	21a8 <arm_smmu_sync_ste_for_sid>
	WRITE_ONCE(dst[0], cpu_to_le64(val));
    238c:	f9000277 	str	x23, [x19]
	arm_smmu_sync_ste_for_sid(smmu, sid);
    2390:	aa1503e0 	mov	x0, x21
    2394:	2a1603e1 	mov	w1, w22
    2398:	97ffff84 	bl	21a8 <arm_smmu_sync_ste_for_sid>
	if (!(smmu->options & ARM_SMMU_OPT_SKIP_PREFETCH))
    239c:	b9401ea0 	ldr	w0, [x21, #28]
    23a0:	36000620 	tbz	w0, #0, 2464 <arm_smmu_write_strtab_ent+0x22c>
    23a4:	f9401bb7 	ldr	x23, [x29, #48]
    23a8:	1400000f 	b	23e4 <arm_smmu_write_strtab_ent+0x1ac>
	struct arm_smmu_device *smmu = NULL;
    23ac:	d2800015 	mov	x21, #0x0                   	// #0
	if (val & STRTAB_STE_0_V) {
    23b0:	b50002e3 	cbnz	x3, 240c <arm_smmu_write_strtab_ent+0x1d4>
		if (!smmu_domain && disable_bypass)
    23b4:	90000000 	adrp	x0, 0 <queue_remove_raw>
			val |= FIELD_PREP(STRTAB_STE_0_CFG, STRTAB_STE_0_CFG_ABORT);
    23b8:	d2800123 	mov	x3, #0x9                   	// #9
		if (!smmu_domain && disable_bypass)
    23bc:	39400000 	ldrb	w0, [x0]
			val |= FIELD_PREP(STRTAB_STE_0_CFG, STRTAB_STE_0_CFG_ABORT);
    23c0:	7100001f 	cmp	w0, #0x0
    23c4:	9a9f0463 	csinc	x3, x3, xzr, eq  // eq = none
		dst[1] = cpu_to_le64(FIELD_PREP(STRTAB_STE_1_SHCFG,
    23c8:	d2c20000 	mov	x0, #0x100000000000        	// #17592186044416
    23cc:	a9000263 	stp	x3, x0, [x19]
		dst[2] = 0; /* Nuke the VMID */
    23d0:	f9000a7f 	str	xzr, [x19, #16]
		if (smmu)
    23d4:	b4000095 	cbz	x21, 23e4 <arm_smmu_write_strtab_ent+0x1ac>
			arm_smmu_sync_ste_for_sid(smmu, sid);
    23d8:	2a1603e1 	mov	w1, w22
    23dc:	aa1503e0 	mov	x0, x21
    23e0:	97ffff72 	bl	21a8 <arm_smmu_sync_ste_for_sid>
}
    23e4:	91000294 	add	x20, x20, #0x0
    23e8:	f94037a1 	ldr	x1, [x29, #104]
    23ec:	f9400280 	ldr	x0, [x20]
    23f0:	ca000020 	eor	x0, x1, x0
    23f4:	b5000580 	cbnz	x0, 24a4 <arm_smmu_write_strtab_ent+0x26c>
    23f8:	a94153f3 	ldp	x19, x20, [sp, #16]
    23fc:	a9425bf5 	ldp	x21, x22, [sp, #32]
    2400:	a8c77bfd 	ldp	x29, x30, [sp], #112
    2404:	d50323bf 	autiasp
    2408:	d65f03c0 	ret
		switch (FIELD_GET(STRTAB_STE_0_CFG, val)) {
    240c:	d3410c42 	ubfx	x2, x2, #1, #3
    2410:	b4000182 	cbz	x2, 2440 <arm_smmu_write_strtab_ent+0x208>
    2414:	d1001042 	sub	x2, x2, #0x4
    2418:	f100085f 	cmp	x2, #0x2
    241c:	54fffcc9 	b.ls	23b4 <arm_smmu_write_strtab_ent+0x17c>  // b.plast
    2420:	f9001bb7 	str	x23, [x29, #48]
			BUG(); /* STE corruption */
    2424:	d4210000 	brk	#0x800
			val |= FIELD_PREP(STRTAB_STE_0_CFG, STRTAB_STE_0_CFG_BYPASS);
    2428:	d2800123 	mov	x3, #0x9                   	// #9
    242c:	17ffffe7 	b	23c8 <arm_smmu_write_strtab_ent+0x190>
			s2_cfg = &smmu_domain->s2_cfg;
    2430:	91010024 	add	x4, x1, #0x40
	struct arm_smmu_s1_cfg *s1_cfg = NULL;
    2434:	d2800001 	mov	x1, #0x0                   	// #0
	if (val & STRTAB_STE_0_V) {
    2438:	b4fff503 	cbz	x3, 22d8 <arm_smmu_write_strtab_ent+0xa0>
    243c:	17ffff9d 	b	22b0 <arm_smmu_write_strtab_ent+0x78>
			BUG_ON(!disable_bypass);
    2440:	90000000 	adrp	x0, 0 <queue_remove_raw>
    2444:	39400000 	ldrb	w0, [x0]
    2448:	35fffc00 	cbnz	w0, 23c8 <arm_smmu_write_strtab_ent+0x190>
    244c:	f9001bb7 	str	x23, [x29, #48]
    2450:	d4210000 	brk	#0x800
			s1_cfg = &smmu_domain->s1_cfg;
    2454:	91010021 	add	x1, x1, #0x40
	struct arm_smmu_s2_cfg *s2_cfg = NULL;
    2458:	d2800004 	mov	x4, #0x0                   	// #0
	if (val & STRTAB_STE_0_V) {
    245c:	b4fff3e3 	cbz	x3, 22d8 <arm_smmu_write_strtab_ent+0xa0>
    2460:	17ffff94 	b	22b0 <arm_smmu_write_strtab_ent+0x78>
		arm_smmu_cmdq_issue_cmd(smmu, &prefetch_cmd);
    2464:	910123a1 	add	x1, x29, #0x48
    2468:	aa1503e0 	mov	x0, x21
    246c:	97fffe9b 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
    2470:	f9401bb7 	ldr	x23, [x29, #48]
    2474:	17ffffdc 	b	23e4 <arm_smmu_write_strtab_ent+0x1ac>
	if (s2_cfg) {
    2478:	b4000104 	cbz	x4, 2498 <arm_smmu_write_strtab_ent+0x260>
    247c:	d28001b7 	mov	x23, #0xd                   	// #13
		BUG_ON(ste_live);
    2480:	34fff623 	cbz	w3, 2344 <arm_smmu_write_strtab_ent+0x10c>
    2484:	d4210000 	brk	#0x800
		switch (FIELD_GET(STRTAB_STE_0_CFG, val)) {
    2488:	52800023 	mov	w3, #0x1                   	// #1
    248c:	f100185f 	cmp	x2, #0x6
    2490:	54fff249 	b.ls	22d8 <arm_smmu_write_strtab_ent+0xa0>  // b.plast
    2494:	17ffffe3 	b	2420 <arm_smmu_write_strtab_ent+0x1e8>
	val = STRTAB_STE_0_V;
    2498:	d2800037 	mov	x23, #0x1                   	// #1
    249c:	17ffffb4 	b	236c <arm_smmu_write_strtab_ent+0x134>
		BUG_ON(ste_live);
    24a0:	d4210000 	brk	#0x800
    24a4:	f9001bb7 	str	x23, [x29, #48]
}
    24a8:	94000000 	bl	0 <__stack_chk_fail>
    24ac:	d503201f 	nop

00000000000024b0 <arm_smmu_install_ste_for_dev>:
{
    24b0:	d503233f 	paciasp
    24b4:	a9bc7bfd 	stp	x29, x30, [sp, #-64]!
    24b8:	910003fd 	mov	x29, sp
    24bc:	f90017f6 	str	x22, [sp, #40]
	for (i = 0; i < master->num_sids; ++i) {
    24c0:	b9403006 	ldr	w6, [x0, #48]
	struct arm_smmu_device *smmu = master->smmu;
    24c4:	f9400016 	ldr	x22, [x0]
	for (i = 0; i < master->num_sids; ++i) {
    24c8:	34000566 	cbz	w6, 2574 <arm_smmu_install_ste_for_dev+0xc4>
    24cc:	f90013b5 	str	x21, [x29, #32]
    24d0:	aa0003f5 	mov	x21, x0
    24d4:	f9001bb7 	str	x23, [x29, #48]
    24d8:	d2846600 	mov	x0, #0x2330                	// #9008
    24dc:	8b0002d7 	add	x23, x22, x0
    24e0:	a90153b3 	stp	x19, x20, [x29, #16]
    24e4:	52800013 	mov	w19, #0x0                   	// #0
		l1_desc = &cfg->l1_desc[idx];
    24e8:	52800314 	mov	w20, #0x18                  	// #24
    24ec:	d503201f 	nop
	if (smmu->features & ARM_SMMU_FEAT_2_LVL_STRTAB) {
    24f0:	b9401ac0 	ldr	w0, [x22, #24]
		u32 sid = master->sids[i];
    24f4:	f94016a3 	ldr	x3, [x21, #40]
    24f8:	b873d861 	ldr	w1, [x3, w19, sxtw #2]
	if (smmu->features & ARM_SMMU_FEAT_2_LVL_STRTAB) {
    24fc:	36000440 	tbz	w0, #0, 2584 <arm_smmu_install_ste_for_dev+0xd4>
		step = &l1_desc->l2ptr[idx];
    2500:	f9400ae0 	ldr	x0, [x23, #16]
		idx = (sid >> STRTAB_SPLIT) * STRTAB_L1_DESC_DWORDS;
    2504:	53087c24 	lsr	w4, w1, #8
		step = &l1_desc->l2ptr[idx];
    2508:	d37a1c22 	ubfiz	x2, x1, #6, #8
    250c:	9bb40084 	umaddl	x4, w4, w20, x0
    2510:	f9400484 	ldr	x4, [x4, #8]
    2514:	8b020082 	add	x2, x4, x2
		for (j = 0; j < i; j++)
    2518:	7100027f 	cmp	w19, #0x0
    251c:	540001ad 	b.le	2550 <arm_smmu_install_ste_for_dev+0xa0>
			if (master->sids[j] == sid)
    2520:	b9400060 	ldr	w0, [x3]
    2524:	6b00003f 	cmp	w1, w0
    2528:	540001a0 	b.eq	255c <arm_smmu_install_ste_for_dev+0xac>  // b.none
    252c:	51000665 	sub	w5, w19, #0x1
    2530:	91001063 	add	x3, x3, #0x4
    2534:	8b254865 	add	x5, x3, w5, uxtw #2
    2538:	14000004 	b	2548 <arm_smmu_install_ste_for_dev+0x98>
    253c:	b8404464 	ldr	w4, [x3], #4
    2540:	6b01009f 	cmp	w4, w1
    2544:	540000c0 	b.eq	255c <arm_smmu_install_ste_for_dev+0xac>  // b.none
		for (j = 0; j < i; j++)
    2548:	eb05007f 	cmp	x3, x5
    254c:	54ffff81 	b.ne	253c <arm_smmu_install_ste_for_dev+0x8c>  // b.any
		arm_smmu_write_strtab_ent(master, sid, step);
    2550:	aa1503e0 	mov	x0, x21
    2554:	97ffff39 	bl	2238 <arm_smmu_write_strtab_ent>
    2558:	b94032a6 	ldr	w6, [x21, #48]
	for (i = 0; i < master->num_sids; ++i) {
    255c:	11000673 	add	w19, w19, #0x1
    2560:	6b1300df 	cmp	w6, w19
    2564:	54fffc68 	b.hi	24f0 <arm_smmu_install_ste_for_dev+0x40>  // b.pmore
    2568:	a94153b3 	ldp	x19, x20, [x29, #16]
    256c:	f94013b5 	ldr	x21, [x29, #32]
    2570:	f9401bb7 	ldr	x23, [x29, #48]
}
    2574:	f94017f6 	ldr	x22, [sp, #40]
    2578:	a8c47bfd 	ldp	x29, x30, [sp], #64
    257c:	d50323bf 	autiasp
    2580:	d65f03c0 	ret
		step = &cfg->strtab[sid * STRTAB_STE_DWORDS];
    2584:	f94002e2 	ldr	x2, [x23]
    2588:	d37a7020 	ubfiz	x0, x1, #6, #29
    258c:	8b000042 	add	x2, x2, x0
    2590:	17ffffe2 	b	2518 <arm_smmu_install_ste_for_dev+0x68>
    2594:	d503201f 	nop

0000000000002598 <arm_smmu_detach_dev>:
{
    2598:	d503233f 	paciasp
    259c:	a9ba7bfd 	stp	x29, x30, [sp, #-96]!
    25a0:	910003fd 	mov	x29, sp
    25a4:	a90153f3 	stp	x19, x20, [sp, #16]
    25a8:	aa0003f3 	mov	x19, x0
    25ac:	f90013f5 	str	x21, [sp, #32]
    25b0:	90000015 	adrp	x21, 0 <__stack_chk_guard>
    25b4:	910002a0 	add	x0, x21, #0x0
	struct arm_smmu_domain *smmu_domain = master->domain;
    25b8:	f9400a74 	ldr	x20, [x19, #16]
{
    25bc:	f9400001 	ldr	x1, [x0]
    25c0:	f9002fa1 	str	x1, [x29, #88]
    25c4:	d2800001 	mov	x1, #0x0                   	// #0
	if (!smmu_domain)
    25c8:	b40002b4 	cbz	x20, 261c <arm_smmu_detach_dev+0x84>
	if (!master->ats_enabled)
    25cc:	3940d260 	ldrb	w0, [x19, #52]
    25d0:	350003a0 	cbnz	w0, 2644 <arm_smmu_detach_dev+0xac>
 * Map the spin_lock functions to the raw variants for PREEMPT_RT=n
 */

static __always_inline raw_spinlock_t *spinlock_check(spinlock_t *lock)
{
	return &lock->rlock;
    25d4:	91038294 	add	x20, x20, #0xe0
	spin_lock_irqsave(&smmu_domain->devices_lock, flags);
    25d8:	aa1403e0 	mov	x0, x20
    25dc:	94000000 	bl	0 <_raw_spin_lock_irqsave>
static inline void __list_del_entry(struct list_head *entry)
{
	if (!__list_del_entry_valid(entry))
		return;

	__list_del(entry->prev, entry->next);
    25e0:	a9418a63 	ldp	x3, x2, [x19, #24]
	next->prev = prev;
    25e4:	f9000462 	str	x2, [x3, #8]
 * in an undefined state.
 */
static inline void list_del(struct list_head *entry)
{
	__list_del_entry(entry);
	entry->next = LIST_POISON1;
    25e8:	d2802005 	mov	x5, #0x100                 	// #256
	entry->prev = LIST_POISON2;
    25ec:	d2802444 	mov	x4, #0x122                 	// #290
	entry->next = LIST_POISON1;
    25f0:	f2fbd5a5 	movk	x5, #0xdead, lsl #48
	entry->prev = LIST_POISON2;
    25f4:	f2fbd5a4 	movk	x4, #0xdead, lsl #48
	WRITE_ONCE(prev->next, next);
    25f8:	f9000043 	str	x3, [x2]
	raw_spin_unlock_irq(&lock->rlock);
}

static __always_inline void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags)
{
	raw_spin_unlock_irqrestore(&lock->rlock, flags);
    25fc:	aa0003e1 	mov	x1, x0
	entry->prev = LIST_POISON2;
    2600:	a9019265 	stp	x5, x4, [x19, #24]
    2604:	aa1403e0 	mov	x0, x20
    2608:	94000000 	bl	0 <_raw_spin_unlock_irqrestore>
	master->domain = NULL;
    260c:	f9000a7f 	str	xzr, [x19, #16]
	master->ats_enabled = false;
    2610:	3900d27f 	strb	wzr, [x19, #52]
	arm_smmu_install_ste_for_dev(master);
    2614:	aa1303e0 	mov	x0, x19
    2618:	97ffffa6 	bl	24b0 <arm_smmu_install_ste_for_dev>
}
    261c:	910002b5 	add	x21, x21, #0x0
    2620:	f9402fa1 	ldr	x1, [x29, #88]
    2624:	f94002a0 	ldr	x0, [x21]
    2628:	ca000020 	eor	x0, x1, x0
    262c:	b5000600 	cbnz	x0, 26ec <arm_smmu_detach_dev+0x154>
    2630:	a94153f3 	ldp	x19, x20, [sp, #16]
    2634:	f94013f5 	ldr	x21, [sp, #32]
    2638:	a8c67bfd 	ldp	x29, x30, [sp], #96
    263c:	d50323bf 	autiasp
    2640:	d65f03c0 	ret
	pci_disable_ats(to_pci_dev(master->dev));
    2644:	f9400660 	ldr	x0, [x19, #8]
    2648:	d102a000 	sub	x0, x0, #0xa8
    264c:	94000000 	bl	0 <pci_disable_ats>
	wmb();
    2650:	d5033e9f 	dsb	st
	for (i = 0; i < master->num_sids; i++) {
    2654:	b9403260 	ldr	w0, [x19, #48]
	*cmd = (struct arm_smmu_cmdq_ent) {
    2658:	52800802 	mov	w2, #0x40                  	// #64
    265c:	a903ffbf 	stp	xzr, xzr, [x29, #56]
		cmd->atc.size = ATC_INV_SIZE_ALL;
    2660:	52800681 	mov	w1, #0x34                  	// #52
	*cmd = (struct arm_smmu_cmdq_ent) {
    2664:	a904ffbf 	stp	xzr, xzr, [x29, #72]
    2668:	3900e3a2 	strb	w2, [x29, #56]
		cmd->atc.size = ATC_INV_SIZE_ALL;
    266c:	390143a1 	strb	w1, [x29, #80]
	for (i = 0; i < master->num_sids; i++) {
    2670:	340001e0 	cbz	w0, 26ac <arm_smmu_detach_dev+0x114>
    2674:	f90017b6 	str	x22, [x29, #40]
    2678:	52800016 	mov	w22, #0x0                   	// #0
    267c:	d503201f 	nop
		cmd.atc.sid = master->sids[i];
    2680:	f9401662 	ldr	x2, [x19, #40]
		arm_smmu_cmdq_issue_cmd(master->smmu, &cmd);
    2684:	9100e3a1 	add	x1, x29, #0x38
    2688:	f9400260 	ldr	x0, [x19]
		cmd.atc.sid = master->sids[i];
    268c:	b876d842 	ldr	w2, [x2, w22, sxtw #2]
	for (i = 0; i < master->num_sids; i++) {
    2690:	110006d6 	add	w22, w22, #0x1
		cmd.atc.sid = master->sids[i];
    2694:	b90043a2 	str	w2, [x29, #64]
		arm_smmu_cmdq_issue_cmd(master->smmu, &cmd);
    2698:	97fffe10 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
	for (i = 0; i < master->num_sids; i++) {
    269c:	b9403260 	ldr	w0, [x19, #48]
    26a0:	6b16001f 	cmp	w0, w22
    26a4:	54fffee8 	b.hi	2680 <arm_smmu_detach_dev+0xe8>  // b.pmore
    26a8:	f94017b6 	ldr	x22, [x29, #40]
	return arm_smmu_cmdq_issue_cmdlist(smmu, NULL, 0, true);
    26ac:	f9400260 	ldr	x0, [x19]
    26b0:	d2800001 	mov	x1, #0x0                   	// #0
    26b4:	52800023 	mov	w3, #0x1                   	// #1
    26b8:	52800002 	mov	w2, #0x0                   	// #0
    26bc:	97fffc2b 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
	atomic_dec(&smmu_domain->nr_ats_masters);
    26c0:	9100d281 	add	x1, x20, #0x34
    26c4:	14000006 	b	26dc <arm_smmu_detach_dev+0x144>
    26c8:	14000005 	b	26dc <arm_smmu_detach_dev+0x144>
	asm volatile(
    26cc:	52800020 	mov	w0, #0x1                   	// #1
    26d0:	4b0003e0 	neg	w0, w0
    26d4:	b820003f 	stadd	w0, [x1]
    26d8:	17ffffbf 	b	25d4 <arm_smmu_detach_dev+0x3c>
ATOMIC_OPS(sub, sub, J)
    26dc:	52800020 	mov	w0, #0x1                   	// #1
    26e0:	9100d283 	add	x3, x20, #0x34
    26e4:	1400090e 	b	4b1c <arm_smmu_flush_iotlb_all+0x184>
    26e8:	17ffffbb 	b	25d4 <arm_smmu_detach_dev+0x3c>
    26ec:	f90017b6 	str	x22, [x29, #40]
}
    26f0:	94000000 	bl	0 <__stack_chk_fail>
    26f4:	d503201f 	nop

00000000000026f8 <arm_smmu_release_device>:
	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
    26f8:	f9417402 	ldr	x2, [x0, #744]
int iommu_fwspec_add_ids(struct device *dev, u32 *ids, int num_ids);
const struct iommu_ops *iommu_ops_from_fwnode(struct fwnode_handle *fwnode);

static inline struct iommu_fwspec *dev_iommu_fwspec_get(struct device *dev)
{
	if (dev->iommu)
    26fc:	b4000122 	cbz	x2, 2720 <arm_smmu_release_device+0x28>
		return dev->iommu->fwspec;
    2700:	f9401443 	ldr	x3, [x2, #40]
	if (!fwspec || fwspec->ops != &arm_smmu_ops)
    2704:	b40000e3 	cbz	x3, 2720 <arm_smmu_release_device+0x28>
    2708:	90000001 	adrp	x1, 0 <queue_remove_raw>
    270c:	f9400063 	ldr	x3, [x3]
    2710:	91000021 	add	x1, x1, #0x0
    2714:	9105e021 	add	x1, x1, #0x178
    2718:	eb01007f 	cmp	x3, x1
    271c:	54000040 	b.eq	2724 <arm_smmu_release_device+0x2c>  // b.none
    2720:	d65f03c0 	ret
{
    2724:	d503233f 	paciasp
    2728:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
    272c:	910003fd 	mov	x29, sp
    2730:	a90153f3 	stp	x19, x20, [sp, #16]
    2734:	aa0003f3 	mov	x19, x0
	dev->iommu->fwspec = fwspec;
}

static inline void *dev_iommu_priv_get(struct device *dev)
{
	return dev->iommu->priv;
    2738:	f9401c54 	ldr	x20, [x2, #56]
	arm_smmu_detach_dev(master);
    273c:	aa1403e0 	mov	x0, x20
    2740:	97ffff96 	bl	2598 <arm_smmu_detach_dev>
	arm_smmu_disable_pasid(master);
    2744:	f9400681 	ldr	x1, [x20, #8]
	if (!dev_is_pci(master->dev))
    2748:	90000000 	adrp	x0, 0 <pci_bus_type>
    274c:	91000000 	add	x0, x0, #0x0
    2750:	f9403022 	ldr	x2, [x1, #96]
    2754:	eb00005f 	cmp	x2, x0
    2758:	54000120 	b.eq	277c <arm_smmu_release_device+0x84>  // b.none
	kfree(master);
    275c:	aa1403e0 	mov	x0, x20
    2760:	94000000 	bl	0 <kfree>
	iommu_fwspec_free(dev);
    2764:	aa1303e0 	mov	x0, x19
    2768:	94000000 	bl	0 <iommu_fwspec_free>
}
    276c:	a94153f3 	ldp	x19, x20, [sp, #16]
    2770:	a8c27bfd 	ldp	x29, x30, [sp], #32
    2774:	d50323bf 	autiasp
    2778:	d65f03c0 	ret
	if (!pdev->pasid_enabled)
    277c:	d102a020 	sub	x0, x1, #0xa8
    2780:	395fac01 	ldrb	w1, [x0, #2027]
    2784:	3607fec1 	tbz	w1, #0, 275c <arm_smmu_release_device+0x64>
	master->ssid_bits = 0;
    2788:	b9003a9f 	str	wzr, [x20, #56]
	pci_disable_pasid(pdev);
    278c:	94000000 	bl	0 <pci_disable_pasid>
    2790:	17fffff3 	b	275c <arm_smmu_release_device+0x64>
    2794:	d503201f 	nop

0000000000002798 <arm_smmu_probe_device>:
{
    2798:	d503233f 	paciasp
    279c:	a9b97bfd 	stp	x29, x30, [sp, #-112]!
    27a0:	910003fd 	mov	x29, sp
    27a4:	f9000bf3 	str	x19, [sp, #16]
	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
    27a8:	f9417401 	ldr	x1, [x0, #744]
	if (dev->iommu)
    27ac:	b4000161 	cbz	x1, 27d8 <arm_smmu_probe_device+0x40>
    27b0:	f90013b5 	str	x21, [x29, #32]
		return dev->iommu->fwspec;
    27b4:	f9401435 	ldr	x21, [x1, #40]
	if (!fwspec || fwspec->ops != &arm_smmu_ops)
    27b8:	b40000f5 	cbz	x21, 27d4 <arm_smmu_probe_device+0x3c>
    27bc:	90000004 	adrp	x4, 0 <queue_remove_raw>
    27c0:	f94002a3 	ldr	x3, [x21]
    27c4:	91000084 	add	x4, x4, #0x0
    27c8:	9105e082 	add	x2, x4, #0x178
    27cc:	eb02007f 	cmp	x3, x2
    27d0:	54000100 	b.eq	27f0 <arm_smmu_probe_device+0x58>  // b.none
    27d4:	f94013b5 	ldr	x21, [x29, #32]
		return ERR_PTR(-ENODEV);
    27d8:	92800253 	mov	x19, #0xffffffffffffffed    	// #-19
}
    27dc:	aa1303e0 	mov	x0, x19
    27e0:	f9400bf3 	ldr	x19, [sp, #16]
    27e4:	a8c77bfd 	ldp	x29, x30, [sp], #112
    27e8:	d50323bf 	autiasp
    27ec:	d65f03c0 	ret
	if (WARN_ON_ONCE(dev_iommu_priv_get(dev)))
    27f0:	f9401c21 	ldr	x1, [x1, #56]
    27f4:	b50013e1 	cbnz	x1, 2a70 <arm_smmu_probe_device+0x2d8>
    27f8:	f9000fb4 	str	x20, [x29, #24]
 */
static inline struct device *
driver_find_device_by_fwnode(struct device_driver *drv,
			     const struct fwnode_handle *fwnode)
{
	return driver_find_device(drv, NULL, fwnode, device_match_fwnode);
    27fc:	90000003 	adrp	x3, 0 <device_match_fwnode>
    2800:	91000063 	add	x3, x3, #0x0
    2804:	d2800001 	mov	x1, #0x0                   	// #0
    2808:	f94006a2 	ldr	x2, [x21, #8]
    280c:	aa0003f4 	mov	x20, x0
    2810:	9101c080 	add	x0, x4, #0x70
    2814:	94000000 	bl	0 <driver_find_device>
    2818:	aa0003f3 	mov	x19, x0
	put_device(dev);
    281c:	94000000 	bl	0 <put_device>
	return dev ? dev_get_drvdata(dev) : NULL;
    2820:	b4001313 	cbz	x19, 2a80 <arm_smmu_probe_device+0x2e8>
    2824:	f9001bb7 	str	x23, [x29, #48]
    2828:	f9403e77 	ldr	x23, [x19, #120]
	if (!smmu)
    282c:	b40006b7 	cbz	x23, 2900 <arm_smmu_probe_device+0x168>
		return kmem_cache_alloc_trace(
    2830:	90000000 	adrp	x0, 0 <kmalloc_caches>
    2834:	f9001fb8 	str	x24, [x29, #56]
	void *ret = kmem_cache_alloc(s, flags);
    2838:	5281b801 	mov	w1, #0xdc0                 	// #3520
		return ERR_PTR(-ENOMEM);
    283c:	92800173 	mov	x19, #0xfffffffffffffff4    	// #-12
    2840:	f9400000 	ldr	x0, [x0]
    2844:	94000000 	bl	0 <kmem_cache_alloc>
    2848:	aa0003f8 	mov	x24, x0
	if (!master)
    284c:	b40010c0 	cbz	x0, 2a64 <arm_smmu_probe_device+0x2cc>
    2850:	f90017b6 	str	x22, [x29, #40]
	master->sids = fwspec->ids;
    2854:	910072a0 	add	x0, x21, #0x1c
	master->dev = dev;
    2858:	a9005317 	stp	x23, x20, [x24]
	master->sids = fwspec->ids;
    285c:	f9001700 	str	x0, [x24, #40]
	dev_iommu_priv_set(dev, master);
    2860:	f9417680 	ldr	x0, [x20, #744]
	master->num_sids = fwspec->num_ids;
    2864:	b9401aa1 	ldr	w1, [x21, #24]
    2868:	b9003301 	str	w1, [x24, #48]
}

static inline void dev_iommu_priv_set(struct device *dev, void *priv)
{
	dev->iommu->priv = priv;
    286c:	f9001c18 	str	x24, [x0, #56]
	for (i = 0; i < master->num_sids; i++) {
    2870:	b9403303 	ldr	w3, [x24, #48]
    2874:	34000943 	cbz	w3, 299c <arm_smmu_probe_device+0x204>
    2878:	a9046bb9 	stp	x25, x26, [x29, #64]
    287c:	52800016 	mov	w22, #0x0                   	// #0
    2880:	f9002bbb 	str	x27, [x29, #80]
    2884:	1400000d 	b	28b8 <arm_smmu_probe_device+0x120>
		if (!arm_smmu_sid_in_range(smmu, sid)) {
    2888:	eb01201f 	cmp	x0, x1, lsl #8
    288c:	54000262 	b.cs	28d8 <arm_smmu_probe_device+0x140>  // b.hs, b.nlast
	struct arm_smmu_strtab_l1_desc *desc = &cfg->l1_desc[sid >> STRTAB_SPLIT];
    2890:	53087e60 	lsr	w0, w19, #8
    2894:	52800301 	mov	w1, #0x18                  	// #24
    2898:	f951a2fb 	ldr	x27, [x23, #9024]
    289c:	9ba17c1a 	umull	x26, w0, w1
    28a0:	8b1a0379 	add	x25, x27, x26
	if (desc->l2ptr)
    28a4:	f9400721 	ldr	x1, [x25, #8]
    28a8:	b4000321 	cbz	x1, 290c <arm_smmu_probe_device+0x174>
	for (i = 0; i < master->num_sids; i++) {
    28ac:	110006d6 	add	w22, w22, #0x1
    28b0:	6b16007f 	cmp	w3, w22
    28b4:	54000709 	b.ls	2994 <arm_smmu_probe_device+0x1fc>  // b.plast
		u32 sid = master->sids[i];
    28b8:	f9401700 	ldr	x0, [x24, #40]
	if (smmu->features & ARM_SMMU_FEAT_2_LVL_STRTAB)
    28bc:	b9401ae2 	ldr	w2, [x23, #24]
	unsigned long limit = smmu->strtab_cfg.num_l1_ents;
    28c0:	b9634ae1 	ldr	w1, [x23, #9032]
		u32 sid = master->sids[i];
    28c4:	b876d813 	ldr	w19, [x0, w22, sxtw #2]
    28c8:	2a1303e0 	mov	w0, w19
	if (smmu->features & ARM_SMMU_FEAT_2_LVL_STRTAB)
    28cc:	3707fde2 	tbnz	w2, #0, 2888 <arm_smmu_probe_device+0xf0>
		if (!arm_smmu_sid_in_range(smmu, sid)) {
    28d0:	eb00003f 	cmp	x1, x0
    28d4:	54fffec8 	b.hi	28ac <arm_smmu_probe_device+0x114>  // b.pmore
    28d8:	92800433 	mov	x19, #0xffffffffffffffde    	// #-34
	kfree(master);
    28dc:	aa1803e0 	mov	x0, x24
    28e0:	94000000 	bl	0 <kfree>
	dev_iommu_priv_set(dev, NULL);
    28e4:	f9417680 	ldr	x0, [x20, #744]
    28e8:	f9001c1f 	str	xzr, [x0, #56]
	return ERR_PTR(ret);
    28ec:	a941d7b4 	ldp	x20, x21, [x29, #24]
    28f0:	a942dfb6 	ldp	x22, x23, [x29, #40]
    28f4:	a943e7b8 	ldp	x24, x25, [x29, #56]
    28f8:	a944efba 	ldp	x26, x27, [x29, #72]
    28fc:	17ffffb8 	b	27dc <arm_smmu_probe_device+0x44>
    2900:	a941d7b4 	ldp	x20, x21, [x29, #24]
    2904:	f9401bb7 	ldr	x23, [x29, #48]
    2908:	17ffffb4 	b	27d8 <arm_smmu_probe_device+0x40>
    290c:	f9002fbc 	str	x28, [x29, #88]
    2910:	d2800004 	mov	x4, #0x0                   	// #0
	strtab = &cfg->strtab[(sid >> STRTAB_SPLIT) * STRTAB_L1_DESC_DWORDS];
    2914:	f90037a0 	str	x0, [x29, #104]
    2918:	52819803 	mov	w3, #0xcc0                 	// #3264
    291c:	f9519ae1 	ldr	x1, [x23, #9008]
    2920:	91004322 	add	x2, x25, #0x10
    2924:	f90033a1 	str	x1, [x29, #96]
	desc->span = STRTAB_SPLIT + 1;
    2928:	52800121 	mov	w1, #0x9                   	// #9
    292c:	383a6b61 	strb	w1, [x27, x26]
    2930:	d2880001 	mov	x1, #0x4000                	// #16384
    2934:	f94002e0 	ldr	x0, [x23]
    2938:	94000000 	bl	0 <dmam_alloc_attrs>
	desc->l2ptr = dmam_alloc_coherent(smmu->dev, size, &desc->l2ptr_dma,
    293c:	f9000720 	str	x0, [x25, #8]
    2940:	aa0003fc 	mov	x28, x0
	if (!desc->l2ptr) {
    2944:	b4000a20 	cbz	x0, 2a88 <arm_smmu_probe_device+0x2f0>
    2948:	91401013 	add	x19, x0, #0x4, lsl #12
    294c:	d503201f 	nop
		arm_smmu_write_strtab_ent(NULL, -1, strtab);
    2950:	aa1c03e2 	mov	x2, x28
    2954:	12800001 	mov	w1, #0xffffffff            	// #-1
    2958:	d2800000 	mov	x0, #0x0                   	// #0
		strtab += STRTAB_STE_DWORDS;
    295c:	9101039c 	add	x28, x28, #0x40
		arm_smmu_write_strtab_ent(NULL, -1, strtab);
    2960:	97fffe36 	bl	2238 <arm_smmu_write_strtab_ent>
	for (i = 0; i < nent; ++i) {
    2964:	eb13039f 	cmp	x28, x19
    2968:	54ffff41 	b.ne	2950 <arm_smmu_probe_device+0x1b8>  // b.any
	val |= FIELD_PREP(STRTAB_L1_DESC_SPAN, desc->span);
    296c:	387a6b60 	ldrb	w0, [x27, x26]
	val |= desc->l2ptr_dma & STRTAB_L1_DESC_L2PTR_MASK;
    2970:	f9400b21 	ldr	x1, [x25, #16]
	val |= FIELD_PREP(STRTAB_L1_DESC_SPAN, desc->span);
    2974:	92401000 	and	x0, x0, #0x1f
	val |= desc->l2ptr_dma & STRTAB_L1_DESC_L2PTR_MASK;
    2978:	927ab421 	and	x1, x1, #0xfffffffffffc0
    297c:	aa010000 	orr	x0, x0, x1
	WRITE_ONCE(*dst, cpu_to_le64(val));
    2980:	a9460ba1 	ldp	x1, x2, [x29, #96]
    2984:	f8227820 	str	x0, [x1, x2, lsl #3]
    2988:	b9403303 	ldr	w3, [x24, #48]
    298c:	f9402fbc 	ldr	x28, [x29, #88]
    2990:	17ffffc7 	b	28ac <arm_smmu_probe_device+0x114>
    2994:	a9446bb9 	ldp	x25, x26, [x29, #64]
    2998:	f9402bbb 	ldr	x27, [x29, #80]
	master->ssid_bits = min(smmu->ssid_bits, fwspec->num_pasid_bits);
    299c:	b94016a2 	ldr	w2, [x21, #20]
	if (!dev_is_pci(master->dev))
    29a0:	90000001 	adrp	x1, 0 <pci_bus_type>
	master->ssid_bits = min(smmu->ssid_bits, fwspec->num_pasid_bits);
    29a4:	b9632ae0 	ldr	w0, [x23, #9000]
	if (!dev_is_pci(master->dev))
    29a8:	91000021 	add	x1, x1, #0x0
    29ac:	f9400714 	ldr	x20, [x24, #8]
	master->ssid_bits = min(smmu->ssid_bits, fwspec->num_pasid_bits);
    29b0:	6b02001f 	cmp	w0, w2
    29b4:	1a829000 	csel	w0, w0, w2, ls  // ls = plast
    29b8:	b9003b00 	str	w0, [x24, #56]
	if (!dev_is_pci(master->dev))
    29bc:	f9403280 	ldr	x0, [x20, #96]
    29c0:	eb01001f 	cmp	x0, x1
    29c4:	54000321 	b.ne	2a28 <arm_smmu_probe_device+0x290>  // b.any
	pdev = to_pci_dev(master->dev);
    29c8:	d102a295 	sub	x21, x20, #0xa8
	features = pci_pasid_features(pdev);
    29cc:	aa1503e0 	mov	x0, x21
    29d0:	94000000 	bl	0 <pci_pasid_features>
    29d4:	2a0003f6 	mov	w22, w0
	if (features < 0)
    29d8:	37f80280 	tbnz	w0, #31, 2a28 <arm_smmu_probe_device+0x290>
	num_pasids = pci_max_pasids(pdev);
    29dc:	aa1503e0 	mov	x0, x21
    29e0:	94000000 	bl	0 <pci_max_pasids>
    29e4:	2a0003f3 	mov	w19, w0
	if (num_pasids <= 0)
    29e8:	7100001f 	cmp	w0, #0x0
    29ec:	540001ed 	b.le	2a28 <arm_smmu_probe_device+0x290>
	ret = pci_enable_pasid(pdev, features);
    29f0:	2a1603e1 	mov	w1, w22
    29f4:	aa1503e0 	mov	x0, x21
    29f8:	94000000 	bl	0 <pci_enable_pasid>
	if (ret) {
    29fc:	35000560 	cbnz	w0, 2aa8 <arm_smmu_probe_device+0x310>
	master->ssid_bits = min_t(u8, ilog2(num_pasids),
    2a00:	f9400301 	ldr	x1, [x24]
 * This is defined the same way as ffs.
 * Note fls(0) = 0, fls(1) = 1, fls(0x80000000) = 32.
 */
static __always_inline int fls(unsigned int x)
{
	return x ? sizeof(x) * 8 - __builtin_clz(x) : 0;
    2a04:	5ac01260 	clz	w0, w19
    2a08:	2a2003e0 	mvn	w0, w0
 */
#ifndef CONFIG_ARCH_HAS_ILOG2_U32
static inline __attribute__((const))
int __ilog2_u32(u32 n)
{
	return fls(n) - 1;
    2a0c:	11008000 	add	w0, w0, #0x20
    2a10:	b9632821 	ldr	w1, [x1, #9000]
    2a14:	12001c22 	and	w2, w1, #0xff
    2a18:	12001c21 	and	w1, w1, #0xff
    2a1c:	6b20005f 	cmp	w2, w0, uxtb
    2a20:	1a809020 	csel	w0, w1, w0, ls  // ls = plast
    2a24:	b9003b00 	str	w0, [x24, #56]
	if (!(smmu->features & ARM_SMMU_FEAT_2_LVL_CDTAB))
    2a28:	b9401ae0 	ldr	w0, [x23, #24]
    2a2c:	37080100 	tbnz	w0, #1, 2a4c <arm_smmu_probe_device+0x2b4>
		master->ssid_bits = min_t(u8, master->ssid_bits,
    2a30:	b9403b00 	ldr	w0, [x24, #56]
    2a34:	52800141 	mov	w1, #0xa                   	// #10
    2a38:	12001c02 	and	w2, w0, #0xff
    2a3c:	12001c00 	and	w0, w0, #0xff
    2a40:	6b01005f 	cmp	w2, w1
    2a44:	1a813000 	csel	w0, w0, w1, cc  // cc = lo, ul, last
    2a48:	b9003b00 	str	w0, [x24, #56]
	return &smmu->iommu;
    2a4c:	d2846c00 	mov	x0, #0x2360                	// #9056
    2a50:	f9401fb8 	ldr	x24, [x29, #56]
    2a54:	8b0002f3 	add	x19, x23, x0
    2a58:	a941d7b4 	ldp	x20, x21, [x29, #24]
    2a5c:	a942dfb6 	ldp	x22, x23, [x29, #40]
    2a60:	17ffff5f 	b	27dc <arm_smmu_probe_device+0x44>
    2a64:	a941d7b4 	ldp	x20, x21, [x29, #24]
    2a68:	a94363b7 	ldp	x23, x24, [x29, #48]
    2a6c:	17ffff5c 	b	27dc <arm_smmu_probe_device+0x44>
	if (WARN_ON_ONCE(dev_iommu_priv_get(dev)))
    2a70:	d4210000 	brk	#0x800
		return ERR_PTR(-EBUSY);
    2a74:	928001f3 	mov	x19, #0xfffffffffffffff0    	// #-16
    2a78:	f94013b5 	ldr	x21, [x29, #32]
    2a7c:	17ffff58 	b	27dc <arm_smmu_probe_device+0x44>
    2a80:	a941d7b4 	ldp	x20, x21, [x29, #24]
    2a84:	17ffff55 	b	27d8 <arm_smmu_probe_device+0x40>
		dev_err(smmu->dev,
    2a88:	f94002e0 	ldr	x0, [x23]
    2a8c:	2a1303e2 	mov	w2, w19
    2a90:	90000001 	adrp	x1, 0 <queue_remove_raw>
    2a94:	92800173 	mov	x19, #0xfffffffffffffff4    	// #-12
    2a98:	91000021 	add	x1, x1, #0x0
    2a9c:	94000000 	bl	0 <_dev_err>
    2aa0:	f9402fbc 	ldr	x28, [x29, #88]
    2aa4:	17ffff8e 	b	28dc <arm_smmu_probe_device+0x144>
		dev_err(&pdev->dev, "Failed to enable PASID\n");
    2aa8:	90000001 	adrp	x1, 0 <queue_remove_raw>
    2aac:	aa1403e0 	mov	x0, x20
    2ab0:	91000021 	add	x1, x1, #0x0
    2ab4:	94000000 	bl	0 <_dev_err>
    2ab8:	17ffffdc 	b	2a28 <arm_smmu_probe_device+0x290>
    2abc:	d503201f 	nop

0000000000002ac0 <arm_smmu_cmdq_batch_add>:
{
    2ac0:	d503233f 	paciasp
    2ac4:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
    2ac8:	910003fd 	mov	x29, sp
    2acc:	a90153f3 	stp	x19, x20, [sp, #16]
    2ad0:	aa0203f4 	mov	x20, x2
    2ad4:	aa0103f3 	mov	x19, x1
	if (cmds->num == CMDQ_BATCH_ENTRIES) {
    2ad8:	b9440022 	ldr	w2, [x1, #1024]
    2adc:	7101005f 	cmp	w2, #0x40
    2ae0:	54000180 	b.eq	2b10 <arm_smmu_cmdq_batch_add+0x50>  // b.none
    2ae4:	531f7842 	lsl	w2, w2, #1
    2ae8:	8b22cc20 	add	x0, x1, w2, sxtw #3
	arm_smmu_cmdq_build_cmd(&cmds->cmds[cmds->num * CMDQ_ENT_DWORDS], cmd);
    2aec:	aa1403e1 	mov	x1, x20
    2af0:	97fff6a2 	bl	578 <arm_smmu_cmdq_build_cmd>
	cmds->num++;
    2af4:	b9440260 	ldr	w0, [x19, #1024]
    2af8:	11000400 	add	w0, w0, #0x1
    2afc:	b9040260 	str	w0, [x19, #1024]
}
    2b00:	a94153f3 	ldp	x19, x20, [sp, #16]
    2b04:	a8c27bfd 	ldp	x29, x30, [sp], #32
    2b08:	d50323bf 	autiasp
    2b0c:	d65f03c0 	ret
		arm_smmu_cmdq_issue_cmdlist(smmu, cmds->cmds, cmds->num, false);
    2b10:	52800003 	mov	w3, #0x0                   	// #0
    2b14:	97fffb15 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
		cmds->num = 0;
    2b18:	aa1303e0 	mov	x0, x19
    2b1c:	b904027f 	str	wzr, [x19, #1024]
    2b20:	17fffff3 	b	2aec <arm_smmu_cmdq_batch_add+0x2c>
    2b24:	d503201f 	nop

0000000000002b28 <arm_smmu_sync_cd>:
{
    2b28:	d503233f 	paciasp
    2b2c:	d11203ff 	sub	sp, sp, #0x480
    2b30:	a9007bfd 	stp	x29, x30, [sp]
    2b34:	910003fd 	mov	x29, sp
    2b38:	a90153f3 	stp	x19, x20, [sp, #16]
    2b3c:	2a0103f4 	mov	w20, w1
    2b40:	a9025bf5 	stp	x21, x22, [sp, #32]
	list_for_each_entry(master, &smmu_domain->devices, domain_head) {
    2b44:	aa0003f6 	mov	x22, x0
{
    2b48:	a90363f7 	stp	x23, x24, [sp, #48]
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    2b4c:	aa0003f7 	mov	x23, x0
{
    2b50:	f90023f9 	str	x25, [sp, #64]
    2b54:	90000018 	adrp	x24, 0 <__stack_chk_guard>
    2b58:	91000300 	add	x0, x24, #0x0
    2b5c:	12001c53 	and	w19, w2, #0xff
    2b60:	f9400003 	ldr	x3, [x0]
    2b64:	f9023fa3 	str	x3, [x29, #1144]
    2b68:	d2800003 	mov	x3, #0x0                   	// #0
	struct arm_smmu_cmdq_batch cmds = {};
    2b6c:	52800001 	mov	w1, #0x0                   	// #0
    2b70:	d2808102 	mov	x2, #0x408                 	// #1032
    2b74:	9101c3a0 	add	x0, x29, #0x70
    2b78:	94000000 	bl	0 <memset>
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    2b7c:	f84e06f5 	ldr	x21, [x23], #224
	struct arm_smmu_cmdq_ent cmd = {
    2b80:	a9057fbf 	stp	xzr, xzr, [x29, #80]
    2b84:	528000a0 	mov	w0, #0x5                   	// #5
    2b88:	a9067fbf 	stp	xzr, xzr, [x29, #96]
    2b8c:	390143a0 	strb	w0, [x29, #80]
	spin_lock_irqsave(&smmu_domain->devices_lock, flags);
    2b90:	aa1703e0 	mov	x0, x23
	struct arm_smmu_cmdq_ent cmd = {
    2b94:	b9005fb4 	str	w20, [x29, #92]
    2b98:	390183b3 	strb	w19, [x29, #96]
	spin_lock_irqsave(&smmu_domain->devices_lock, flags);
    2b9c:	94000000 	bl	0 <_raw_spin_lock_irqsave>
    2ba0:	aa0003f9 	mov	x25, x0
	list_for_each_entry(master, &smmu_domain->devices, domain_head) {
    2ba4:	f84d0ec0 	ldr	x0, [x22, #208]!
    2ba8:	d1006014 	sub	x20, x0, #0x18
    2bac:	eb0002df 	cmp	x22, x0
    2bb0:	540002a0 	b.eq	2c04 <arm_smmu_sync_cd+0xdc>  // b.none
    2bb4:	d503201f 	nop
		for (i = 0; i < master->num_sids; i++) {
    2bb8:	b9403280 	ldr	w0, [x20, #48]
    2bbc:	d2800013 	mov	x19, #0x0                   	// #0
    2bc0:	340001a0 	cbz	w0, 2bf4 <arm_smmu_sync_cd+0xcc>
    2bc4:	d503201f 	nop
			cmd.cfgi.sid = master->sids[i];
    2bc8:	f9401683 	ldr	x3, [x20, #40]
			arm_smmu_cmdq_batch_add(smmu, &cmds, &cmd);
    2bcc:	9101c3a1 	add	x1, x29, #0x70
    2bd0:	910143a2 	add	x2, x29, #0x50
    2bd4:	aa1503e0 	mov	x0, x21
			cmd.cfgi.sid = master->sids[i];
    2bd8:	b8737863 	ldr	w3, [x3, x19, lsl #2]
		for (i = 0; i < master->num_sids; i++) {
    2bdc:	91000673 	add	x19, x19, #0x1
			cmd.cfgi.sid = master->sids[i];
    2be0:	b9005ba3 	str	w3, [x29, #88]
			arm_smmu_cmdq_batch_add(smmu, &cmds, &cmd);
    2be4:	97ffffb7 	bl	2ac0 <arm_smmu_cmdq_batch_add>
		for (i = 0; i < master->num_sids; i++) {
    2be8:	b9403281 	ldr	w1, [x20, #48]
    2bec:	eb13003f 	cmp	x1, x19
    2bf0:	54fffec8 	b.hi	2bc8 <arm_smmu_sync_cd+0xa0>  // b.pmore
	list_for_each_entry(master, &smmu_domain->devices, domain_head) {
    2bf4:	f9400e80 	ldr	x0, [x20, #24]
    2bf8:	d1006014 	sub	x20, x0, #0x18
    2bfc:	eb0002df 	cmp	x22, x0
    2c00:	54fffdc1 	b.ne	2bb8 <arm_smmu_sync_cd+0x90>  // b.any
    2c04:	aa1903e1 	mov	x1, x25
    2c08:	aa1703e0 	mov	x0, x23
    2c0c:	94000000 	bl	0 <_raw_spin_unlock_irqrestore>
}
    2c10:	91000318 	add	x24, x24, #0x0
	return arm_smmu_cmdq_issue_cmdlist(smmu, cmds->cmds, cmds->num, true);
    2c14:	b94473a2 	ldr	w2, [x29, #1136]
    2c18:	9101c3a1 	add	x1, x29, #0x70
    2c1c:	52800023 	mov	w3, #0x1                   	// #1
    2c20:	aa1503e0 	mov	x0, x21
    2c24:	97fffad1 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
}
    2c28:	f9423fa1 	ldr	x1, [x29, #1144]
    2c2c:	f9400300 	ldr	x0, [x24]
    2c30:	ca000020 	eor	x0, x1, x0
    2c34:	b5000120 	cbnz	x0, 2c58 <arm_smmu_sync_cd+0x130>
    2c38:	a9407bfd 	ldp	x29, x30, [sp]
    2c3c:	a94153f3 	ldp	x19, x20, [sp, #16]
    2c40:	a9425bf5 	ldp	x21, x22, [sp, #32]
    2c44:	a94363f7 	ldp	x23, x24, [sp, #48]
    2c48:	f94023f9 	ldr	x25, [sp, #64]
    2c4c:	911203ff 	add	sp, sp, #0x480
    2c50:	d50323bf 	autiasp
    2c54:	d65f03c0 	ret
    2c58:	94000000 	bl	0 <__stack_chk_fail>
    2c5c:	d503201f 	nop

0000000000002c60 <arm_smmu_domain_finalise_s1>:
{
    2c60:	d503233f 	paciasp
    2c64:	a9b97bfd 	stp	x29, x30, [sp, #-112]!
    2c68:	d2800023 	mov	x3, #0x1                   	// #1
    2c6c:	910003fd 	mov	x29, sp
    2c70:	a90153f3 	stp	x19, x20, [sp, #16]
    2c74:	aa0003f3 	mov	x19, x0
    2c78:	a9025bf5 	stp	x21, x22, [sp, #32]
    2c7c:	90000015 	adrp	x21, 0 <__stack_chk_guard>
    2c80:	a90363f7 	stp	x23, x24, [sp, #48]
	ret = xa_alloc(&asid_xa, &asid, &cfg->cd,
    2c84:	91018018 	add	x24, x0, #0x60
{
    2c88:	f90023f9 	str	x25, [sp, #64]
    2c8c:	aa0103f9 	mov	x25, x1
    2c90:	a90573fb 	stp	x27, x28, [sp, #80]
		       XA_LIMIT(1, (1 << smmu->asid_bits) - 1), GFP_KERNEL);
    2c94:	5280003b 	mov	w27, #0x1                   	// #1
{
    2c98:	910002a4 	add	x4, x21, #0x0
    2c9c:	d2800016 	mov	x22, #0x0                   	// #0
		       XA_LIMIT(1, (1 << smmu->asid_bits) - 1), GFP_KERNEL);
    2ca0:	f9400000 	ldr	x0, [x0]
{
    2ca4:	aa0203fc 	mov	x28, x2
    2ca8:	f9400082 	ldr	x2, [x4]
    2cac:	f90037a2 	str	x2, [x29, #104]
    2cb0:	d2800002 	mov	x2, #0x0                   	// #0
	raw_spin_lock(&lock->rlock);
    2cb4:	90000017 	adrp	x23, 0 <queue_remove_raw>
    2cb8:	910002f4 	add	x20, x23, #0x0
		       XA_LIMIT(1, (1 << smmu->asid_bits) - 1), GFP_KERNEL);
    2cbc:	b9432001 	ldr	w1, [x0, #800]
    2cc0:	91044294 	add	x20, x20, #0x110
    2cc4:	aa1403e0 	mov	x0, x20
    2cc8:	1ac12361 	lsl	w1, w27, w1
    2ccc:	51000421 	sub	w1, w1, #0x1
    2cd0:	b3407c36 	bfxil	x22, x1, #0, #32
    2cd4:	b3607c76 	bfi	x22, x3, #32, #32
    2cd8:	94000000 	bl	0 <_raw_spin_lock>
		void *entry, struct xa_limit limit, gfp_t gfp)
{
	int err;

	xa_lock(xa);
	err = __xa_alloc(xa, id, entry, limit, gfp);
    2cdc:	aa1603e3 	mov	x3, x22
    2ce0:	aa1803e2 	mov	x2, x24
    2ce4:	910193a1 	add	x1, x29, #0x64
    2ce8:	52819804 	mov	w4, #0xcc0                 	// #3264
    2cec:	aa1403e0 	mov	x0, x20
    2cf0:	94000000 	bl	0 <__xa_alloc>
    2cf4:	2a0003f6 	mov	w22, w0
	raw_spin_unlock(&lock->rlock);
    2cf8:	aa1403e0 	mov	x0, x20
    2cfc:	94000000 	bl	0 <_raw_spin_unlock>
	if (ret)
    2d00:	340001f6 	cbz	w22, 2d3c <arm_smmu_domain_finalise_s1+0xdc>
}
    2d04:	910002b5 	add	x21, x21, #0x0
    2d08:	2a1603e0 	mov	w0, w22
    2d0c:	f94037a2 	ldr	x2, [x29, #104]
    2d10:	f94002a1 	ldr	x1, [x21]
    2d14:	ca010041 	eor	x1, x2, x1
    2d18:	b5001461 	cbnz	x1, 2fa4 <arm_smmu_domain_finalise_s1+0x344>
    2d1c:	a94153f3 	ldp	x19, x20, [sp, #16]
    2d20:	a9425bf5 	ldp	x21, x22, [sp, #32]
    2d24:	a94363f7 	ldp	x23, x24, [sp, #48]
    2d28:	f94023f9 	ldr	x25, [sp, #64]
    2d2c:	a94573fb 	ldp	x27, x28, [sp, #80]
    2d30:	a8c77bfd 	ldp	x29, x30, [sp], #112
    2d34:	d50323bf 	autiasp
    2d38:	d65f03c0 	ret
    2d3c:	f90027ba 	str	x26, [x29, #72]
    2d40:	9101027a 	add	x26, x19, #0x40
	cfg->s1cdmax = master->ssid_bits;
    2d44:	b9403b20 	ldr	w0, [x25, #56]
    2d48:	39010740 	strb	w0, [x26, #65]
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    2d4c:	f9400279 	ldr	x25, [x19]
	max_contexts = 1 << cfg->s1cdmax;
    2d50:	1ac0237b 	lsl	w27, w27, w0
    2d54:	93407f61 	sxtw	x1, w27
	if (!(smmu->features & ARM_SMMU_FEAT_2_LVL_CDTAB) ||
    2d58:	f110003f 	cmp	x1, #0x400
    2d5c:	b9401b20 	ldr	w0, [x25, #24]
    2d60:	121f0000 	and	w0, w0, #0x2
    2d64:	7a408804 	ccmp	w0, #0x0, #0x4, hi  // hi = pmore
    2d68:	54000801 	b.ne	2e68 <arm_smmu_domain_finalise_s1+0x208>  // b.any
		l1size = max_contexts * (CTXDESC_CD_DWORDS << 3);
    2d6c:	d37ae421 	lsl	x1, x1, #6
		cdcfg->num_l1_ents = max_contexts;
    2d70:	b9001b5b 	str	w27, [x26, #24]
		cfg->s1fmt = STRTAB_STE_0_S1FMT_LINEAR;
    2d74:	3901035f 	strb	wzr, [x26, #64]
    2d78:	f9400320 	ldr	x0, [x25]
    2d7c:	d2800004 	mov	x4, #0x0                   	// #0
    2d80:	52819803 	mov	w3, #0xcc0                 	// #3264
    2d84:	91012262 	add	x2, x19, #0x48
    2d88:	94000000 	bl	0 <dmam_alloc_attrs>
	cdcfg->cdtab = dmam_alloc_coherent(smmu->dev, l1size, &cdcfg->cdtab_dma,
    2d8c:	f9002260 	str	x0, [x19, #64]
    2d90:	aa0003f4 	mov	x20, x0
	if (!cdcfg->cdtab) {
    2d94:	b40010c0 	cbz	x0, 2fac <arm_smmu_domain_finalise_s1+0x34c>
	cfg->cd.asid	= (u16)asid;
    2d98:	b94067a0 	ldr	w0, [x29, #100]
			  CTXDESC_CD_0_TCR_EPD1 | CTXDESC_CD_0_AA64;
    2d9c:	d2a80007 	mov	x7, #0x40000000            	// #1073741824
	cfg->cd.asid	= (u16)asid;
    2da0:	79004340 	strh	w0, [x26, #32]
			  CTXDESC_CD_0_TCR_EPD1 | CTXDESC_CD_0_AA64;
    2da4:	f2c04007 	movk	x7, #0x200, lsl #32
	if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
    2da8:	52800025 	mov	w5, #0x1                   	// #1
	cfg->cd.ttbr	= pgtbl_cfg->arm_lpae_s1_cfg.ttbr;
    2dac:	f9401b80 	ldr	x0, [x28, #48]
    2db0:	f9001740 	str	x0, [x26, #40]
			  FIELD_PREP(CTXDESC_CD_0_TCR_IRGN0, tcr->irgn) |
    2db4:	3940e780 	ldrb	w0, [x28, #57]
			  FIELD_PREP(CTXDESC_CD_0_TCR_TG0, tcr->tg) |
    2db8:	3940e382 	ldrb	w2, [x28, #56]
			  FIELD_PREP(CTXDESC_CD_0_TCR_ORGN0, tcr->orgn) |
    2dbc:	79407383 	ldrh	w3, [x28, #56]
	cfg->cd.tcr	= FIELD_PREP(CTXDESC_CD_0_TCR_T0SZ, tcr->tsz) |
    2dc0:	b9403b84 	ldr	w4, [x28, #56]
			  FIELD_PREP(CTXDESC_CD_0_TCR_IRGN0, tcr->irgn) |
    2dc4:	d3410800 	ubfx	x0, x0, #1, #2
			  FIELD_PREP(CTXDESC_CD_0_TCR_TG0, tcr->tg) |
    2dc8:	d3431041 	ubfx	x1, x2, #3, #2
			  FIELD_PREP(CTXDESC_CD_0_TCR_SH0, tcr->sh) |
    2dcc:	d3451846 	ubfx	x6, x2, #5, #2
			  FIELD_PREP(CTXDESC_CD_0_TCR_IRGN0, tcr->irgn) |
    2dd0:	d378dc00 	lsl	x0, x0, #8
			  FIELD_PREP(CTXDESC_CD_0_TCR_ORGN0, tcr->orgn) |
    2dd4:	d3472063 	ubfx	x3, x3, #7, #2
	cfg->cd.tcr	= FIELD_PREP(CTXDESC_CD_0_TCR_T0SZ, tcr->tsz) |
    2dd8:	d34b4084 	ubfx	x4, x4, #11, #6
			  CTXDESC_CD_0_TCR_EPD1 | CTXDESC_CD_0_AA64;
    2ddc:	aa011800 	orr	x0, x0, x1, lsl #6
    2de0:	aa070084 	orr	x4, x4, x7
			  FIELD_PREP(CTXDESC_CD_0_TCR_SH0, tcr->sh) |
    2de4:	d374ccc1 	lsl	x1, x6, #12
			  CTXDESC_CD_0_TCR_EPD1 | CTXDESC_CD_0_AA64;
    2de8:	aa032821 	orr	x1, x1, x3, lsl #10
    2dec:	aa040000 	orr	x0, x0, x4
			  FIELD_PREP(CTXDESC_CD_0_TCR_IPS, tcr->ips) |
    2df0:	d3600842 	ubfiz	x2, x2, #32, #3
			  CTXDESC_CD_0_TCR_EPD1 | CTXDESC_CD_0_AA64;
    2df4:	aa010000 	orr	x0, x0, x1
    2df8:	aa020000 	orr	x0, x0, x2
	cfg->cd.tcr	= FIELD_PREP(CTXDESC_CD_0_TCR_T0SZ, tcr->tsz) |
    2dfc:	f9001b40 	str	x0, [x26, #48]
	cfg->cd.mair	= pgtbl_cfg->arm_lpae_s1_cfg.mair;
    2e00:	f9402380 	ldr	x0, [x28, #64]
    2e04:	f9001f40 	str	x0, [x26, #56]
	if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
    2e08:	39420660 	ldrb	w0, [x19, #129]
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    2e0c:	f9400279 	ldr	x25, [x19]
	if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
    2e10:	1ac020a0 	lsl	w0, w5, w0
    2e14:	7100001f 	cmp	w0, #0x0
    2e18:	54000b0d 	b.le	2f78 <arm_smmu_domain_finalise_s1+0x318>
	if (smmu_domain->s1_cfg.s1fmt == STRTAB_STE_0_S1FMT_LINEAR)
    2e1c:	39420260 	ldrb	w0, [x19, #128]
    2e20:	34000080 	cbz	w0, 2e30 <arm_smmu_domain_finalise_s1+0x1d0>
	l1_desc = &cdcfg->l1_desc[idx];
    2e24:	f9400b5a 	ldr	x26, [x26, #16]
	if (!l1_desc->l2ptr) {
    2e28:	f9400354 	ldr	x20, [x26]
    2e2c:	b40003b4 	cbz	x20, 2ea0 <arm_smmu_domain_finalise_s1+0x240>
		val = 0;
    2e30:	d2800000 	mov	x0, #0x0                   	// #0
	if (!cd) { /* (4) */
    2e34:	b40000d8 	cbz	x24, 2e4c <arm_smmu_domain_finalise_s1+0x1ec>
	val = le64_to_cpu(cdptr[0]);
    2e38:	f9400281 	ldr	x1, [x20]
	} else if (cd_live) { /* (3) */
    2e3c:	36f80721 	tbz	w1, #31, 2f20 <arm_smmu_domain_finalise_s1+0x2c0>
		val |= FIELD_PREP(CTXDESC_CD_0_ASID, cd->asid);
    2e40:	7940c260 	ldrh	w0, [x19, #96]
		val &= ~CTXDESC_CD_0_ASID;
    2e44:	9240bc21 	and	x1, x1, #0xffffffffffff
		val |= FIELD_PREP(CTXDESC_CD_0_ASID, cd->asid);
    2e48:	aa00c020 	orr	x0, x1, x0, lsl #48
	WRITE_ONCE(cdptr[0], cpu_to_le64(val));
    2e4c:	f9000280 	str	x0, [x20]
	arm_smmu_sync_cd(smmu_domain, ssid, true);
    2e50:	52800022 	mov	w2, #0x1                   	// #1
    2e54:	52800001 	mov	w1, #0x0                   	// #0
    2e58:	aa1303e0 	mov	x0, x19
    2e5c:	97ffff33 	bl	2b28 <arm_smmu_sync_cd>
    2e60:	f94027ba 	ldr	x26, [x29, #72]
    2e64:	17ffffa8 	b	2d04 <arm_smmu_domain_finalise_s1+0xa4>
		cdcfg->num_l1_ents = DIV_ROUND_UP(max_contexts,
    2e68:	910ffc21 	add	x1, x1, #0x3ff
		cfg->s1fmt = STRTAB_STE_0_S1FMT_64K_L2;
    2e6c:	52800040 	mov	w0, #0x2                   	// #2
    2e70:	39010340 	strb	w0, [x26, #64]
	size_t bytes;

	if (unlikely(check_mul_overflow(n, size, &bytes)))
		return NULL;

	return devm_kmalloc(dev, bytes, flags);
    2e74:	5281b802 	mov	w2, #0xdc0                 	// #3520
		cdcfg->num_l1_ents = DIV_ROUND_UP(max_contexts,
    2e78:	d34afc21 	lsr	x1, x1, #10
    2e7c:	b9001b41 	str	w1, [x26, #24]
    2e80:	f9400320 	ldr	x0, [x25]
    2e84:	d37c7c21 	ubfiz	x1, x1, #4, #32
    2e88:	94000000 	bl	0 <devm_kmalloc>
		cdcfg->l1_desc = devm_kcalloc(smmu->dev, cdcfg->num_l1_ents,
    2e8c:	f9000b40 	str	x0, [x26, #16]
		if (!cdcfg->l1_desc)
    2e90:	b4000860 	cbz	x0, 2f9c <arm_smmu_domain_finalise_s1+0x33c>
		l1size = cdcfg->num_l1_ents * (CTXDESC_L1_DESC_DWORDS << 3);
    2e94:	b9401b41 	ldr	w1, [x26, #24]
    2e98:	531d7021 	lsl	w1, w1, #3
    2e9c:	17ffffb7 	b	2d78 <arm_smmu_domain_finalise_s1+0x118>
    2ea0:	f9400320 	ldr	x0, [x25]
    2ea4:	d2800004 	mov	x4, #0x0                   	// #0
    2ea8:	52819803 	mov	w3, #0xcc0                 	// #3264
    2eac:	91002342 	add	x2, x26, #0x8
    2eb0:	d2a00021 	mov	x1, #0x10000               	// #65536
    2eb4:	94000000 	bl	0 <dmam_alloc_attrs>
	l1_desc->l2ptr = dmam_alloc_coherent(smmu->dev, size,
    2eb8:	f9000340 	str	x0, [x26]
	if (!l1_desc->l2ptr) {
    2ebc:	b4000640 	cbz	x0, 2f84 <arm_smmu_domain_finalise_s1+0x324>
	u64 val = (l1_desc->l2ptr_dma & CTXDESC_L1_DESC_L2PTR_MASK) |
    2ec0:	f9400743 	ldr	x3, [x26, #8]
		arm_smmu_sync_cd(smmu_domain, ssid, false);
    2ec4:	52800002 	mov	w2, #0x0                   	// #0
		l1ptr = cdcfg->cdtab + idx * CTXDESC_L1_DESC_DWORDS;
    2ec8:	f9402264 	ldr	x4, [x19, #64]
		arm_smmu_sync_cd(smmu_domain, ssid, false);
    2ecc:	52800001 	mov	w1, #0x0                   	// #0
	u64 val = (l1_desc->l2ptr_dma & CTXDESC_L1_DESC_L2PTR_MASK) |
    2ed0:	92749c63 	and	x3, x3, #0xffffffffff000
		arm_smmu_sync_cd(smmu_domain, ssid, false);
    2ed4:	aa1303e0 	mov	x0, x19
	u64 val = (l1_desc->l2ptr_dma & CTXDESC_L1_DESC_L2PTR_MASK) |
    2ed8:	b2400063 	orr	x3, x3, #0x1
	WRITE_ONCE(*dst, cpu_to_le64(val));
    2edc:	f9000083 	str	x3, [x4]
		arm_smmu_sync_cd(smmu_domain, ssid, false);
    2ee0:	97ffff12 	bl	2b28 <arm_smmu_sync_cd>
    2ee4:	f9400354 	ldr	x20, [x26]
	if (!cdptr)
    2ee8:	b5fffa54 	cbnz	x20, 2e30 <arm_smmu_domain_finalise_s1+0x1d0>
    2eec:	12800176 	mov	w22, #0xfffffff4            	// #-12
	arm_smmu_free_cd_tables(smmu_domain);
    2ef0:	aa1303e0 	mov	x0, x19
    2ef4:	97fff675 	bl	8c8 <arm_smmu_free_cd_tables>
	arm_smmu_free_asid(&cfg->cd);
    2ef8:	7940c261 	ldrh	w1, [x19, #96]
	if (!cd->asid)
    2efc:	35000061 	cbnz	w1, 2f08 <arm_smmu_domain_finalise_s1+0x2a8>
    2f00:	f94027ba 	ldr	x26, [x29, #72]
    2f04:	17ffff80 	b	2d04 <arm_smmu_domain_finalise_s1+0xa4>
	xa_erase(&asid_xa, cd->asid);
    2f08:	910002e0 	add	x0, x23, #0x0
    2f0c:	92403c21 	and	x1, x1, #0xffff
    2f10:	91044000 	add	x0, x0, #0x110
    2f14:	94000000 	bl	0 <xa_erase>
    2f18:	f94027ba 	ldr	x26, [x29, #72]
    2f1c:	17ffff7a 	b	2d04 <arm_smmu_domain_finalise_s1+0xa4>
		cdptr[1] = cpu_to_le64(cd->ttbr & CTXDESC_CD_1_TTB0_MASK);
    2f20:	f9400700 	ldr	x0, [x24, #8]
		arm_smmu_sync_cd(smmu_domain, ssid, true);
    2f24:	52800022 	mov	w2, #0x1                   	// #1
    2f28:	52800001 	mov	w1, #0x0                   	// #0
		cdptr[1] = cpu_to_le64(cd->ttbr & CTXDESC_CD_1_TTB0_MASK);
    2f2c:	927cbc00 	and	x0, x0, #0xffffffffffff0
		cdptr[2] = 0;
    2f30:	a900fe80 	stp	x0, xzr, [x20, #8]
		arm_smmu_sync_cd(smmu_domain, ssid, true);
    2f34:	aa1303e0 	mov	x0, x19
		cdptr[3] = cpu_to_le64(cd->mair);
    2f38:	f9400f03 	ldr	x3, [x24, #24]
    2f3c:	f9000e83 	str	x3, [x20, #24]
		arm_smmu_sync_cd(smmu_domain, ssid, true);
    2f40:	97fffefa 	bl	2b28 <arm_smmu_sync_cd>
			FIELD_PREP(CTXDESC_CD_0_ASID, cd->asid) |
    2f44:	7940c260 	ldrh	w0, [x19, #96]
		val = cd->tcr |
    2f48:	d2b00001 	mov	x1, #0x80000000            	// #2147483648
			CTXDESC_CD_0_AA64 |
    2f4c:	f9400b04 	ldr	x4, [x24, #16]
		val = cd->tcr |
    2f50:	d2b00002 	mov	x2, #0x80000000            	// #2147483648
		if (smmu->features & ARM_SMMU_FEAT_STALL_FORCE)
    2f54:	b9401b23 	ldr	w3, [x25, #24]
		val = cd->tcr |
    2f58:	f2dc4001 	movk	x1, #0xe200, lsl #32
    2f5c:	f2de4002 	movk	x2, #0xf200, lsl #32
			CTXDESC_CD_0_AA64 |
    2f60:	aa00c080 	orr	x0, x4, x0, lsl #48
		val = cd->tcr |
    2f64:	aa010001 	orr	x1, x0, x1
    2f68:	f273007f 	tst	x3, #0x2000
    2f6c:	aa020000 	orr	x0, x0, x2
    2f70:	9a811000 	csel	x0, x0, x1, ne  // ne = any
    2f74:	17ffffb6 	b	2e4c <arm_smmu_domain_finalise_s1+0x1ec>
	if (WARN_ON(ssid >= (1 << smmu_domain->s1_cfg.s1cdmax)))
    2f78:	d4210000 	brk	#0x800
		return -E2BIG;
    2f7c:	128000d6 	mov	w22, #0xfffffff9            	// #-7
    2f80:	17ffffdc 	b	2ef0 <arm_smmu_domain_finalise_s1+0x290>
		dev_warn(smmu->dev,
    2f84:	f9400320 	ldr	x0, [x25]
    2f88:	90000001 	adrp	x1, 0 <queue_remove_raw>
    2f8c:	12800176 	mov	w22, #0xfffffff4            	// #-12
    2f90:	91000021 	add	x1, x1, #0x0
    2f94:	94000000 	bl	0 <_dev_warn>
    2f98:	17ffffd6 	b	2ef0 <arm_smmu_domain_finalise_s1+0x290>
			return -ENOMEM;
    2f9c:	12800176 	mov	w22, #0xfffffff4            	// #-12
    2fa0:	17ffffd6 	b	2ef8 <arm_smmu_domain_finalise_s1+0x298>
    2fa4:	f90027ba 	str	x26, [x29, #72]
}
    2fa8:	94000000 	bl	0 <__stack_chk_fail>
		dev_warn(smmu->dev, "failed to allocate context descriptor\n");
    2fac:	f9400320 	ldr	x0, [x25]
    2fb0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    2fb4:	91000021 	add	x1, x1, #0x0
    2fb8:	94000000 	bl	0 <_dev_warn>
	if (cdcfg->l1_desc) {
    2fbc:	f9400b41 	ldr	x1, [x26, #16]
    2fc0:	b4fffee1 	cbz	x1, 2f9c <arm_smmu_domain_finalise_s1+0x33c>
		devm_kfree(smmu->dev, cdcfg->l1_desc);
    2fc4:	f9400320 	ldr	x0, [x25]
	return ret;
    2fc8:	12800176 	mov	w22, #0xfffffff4            	// #-12
		devm_kfree(smmu->dev, cdcfg->l1_desc);
    2fcc:	94000000 	bl	0 <devm_kfree>
		cdcfg->l1_desc = NULL;
    2fd0:	f9000b5f 	str	xzr, [x26, #16]
    2fd4:	17ffffc9 	b	2ef8 <arm_smmu_domain_finalise_s1+0x298>

0000000000002fd8 <arm_smmu_device_probe>:
{
    2fd8:	d503233f 	paciasp
    2fdc:	a9b57bfd 	stp	x29, x30, [sp, #-176]!
	return devm_kmalloc(dev, size, gfp | __GFP_ZERO);
    2fe0:	5281b802 	mov	w2, #0xdc0                 	// #3520
    2fe4:	910003fd 	mov	x29, sp
    2fe8:	a901d7f4 	stp	x20, x21, [sp, #24]
	struct device *dev = &pdev->dev;
    2fec:	91004015 	add	x21, x0, #0x10
{
    2ff0:	a902dff6 	stp	x22, x23, [sp, #40]
    2ff4:	aa0003f7 	mov	x23, x0
    2ff8:	90000016 	adrp	x22, 0 <__stack_chk_guard>
    2ffc:	910002c0 	add	x0, x22, #0x0
    3000:	f9400001 	ldr	x1, [x0]
    3004:	f90057a1 	str	x1, [x29, #168]
    3008:	d2800001 	mov	x1, #0x0                   	// #0
    300c:	aa1503e0 	mov	x0, x21
    3010:	d2847801 	mov	x1, #0x23c0                	// #9152
    3014:	94000000 	bl	0 <devm_kmalloc>
	if (!smmu) {
    3018:	b4006de0 	cbz	x0, 3dd4 <arm_smmu_device_probe+0xdfc>
    301c:	f9000bb3 	str	x19, [x29, #16]
    3020:	aa0003f3 	mov	x19, x0
    3024:	f9001fb8 	str	x24, [x29, #56]
	if (dev->of_node) {
    3028:	f9414ea0 	ldr	x0, [x21, #664]
	smmu->dev = dev;
    302c:	f9000275 	str	x21, [x19]
	if (dev->of_node) {
    3030:	b4002480 	cbz	x0, 34c0 <arm_smmu_device_probe+0x4e8>
 */
static inline int of_property_read_u32_array(const struct device_node *np,
					     const char *propname,
					     u32 *out_values, size_t sz)
{
	int ret = of_property_read_variable_u32_array(np, propname, out_values,
    3034:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3038:	d2800004 	mov	x4, #0x0                   	// #0
    303c:	d2800023 	mov	x3, #0x1                   	// #1
    3040:	9101a3a2 	add	x2, x29, #0x68
    3044:	91000021 	add	x1, x1, #0x0
    3048:	94000000 	bl	0 <of_property_read_variable_u32_array>
						      sz, 0);
	if (ret >= 0)
    304c:	37f87180 	tbnz	w0, #31, 3e7c <arm_smmu_device_probe+0xea4>
	else if (cells != 1)
    3050:	b9406ba2 	ldr	w2, [x29, #104]
		ret = 0;
    3054:	52800018 	mov	w24, #0x0                   	// #0
	else if (cells != 1)
    3058:	7100045f 	cmp	w2, #0x1
    305c:	54007041 	b.ne	3e64 <arm_smmu_device_probe+0xe8c>  // b.any
		if (of_property_read_bool(smmu->dev->of_node,
    3060:	f9400260 	ldr	x0, [x19]
 * Returns true if the property exists false otherwise.
 */
static inline bool of_property_read_bool(const struct device_node *np,
					 const char *propname)
{
	struct property *prop = of_find_property(np, propname, NULL);
    3064:	90000014 	adrp	x20, 0 <queue_remove_raw>
    3068:	91000294 	add	x20, x20, #0x0
    306c:	d2800002 	mov	x2, #0x0                   	// #0
    3070:	aa1403e1 	mov	x1, x20
    3074:	f9414c00 	ldr	x0, [x0, #664]
    3078:	94000000 	bl	0 <of_find_property>
    307c:	b50071e0 	cbnz	x0, 3eb8 <arm_smmu_device_probe+0xee0>
    3080:	f9400260 	ldr	x0, [x19]
    3084:	90000014 	adrp	x20, 0 <queue_remove_raw>
    3088:	91000294 	add	x20, x20, #0x0
    308c:	d2800002 	mov	x2, #0x0                   	// #0
    3090:	aa1403e1 	mov	x1, x20
    3094:	f9414c00 	ldr	x0, [x0, #664]
    3098:	94000000 	bl	0 <of_find_property>
    309c:	b5006fc0 	cbnz	x0, 3e94 <arm_smmu_device_probe+0xebc>
	if (of_dma_is_coherent(dev->of_node))
    30a0:	f9414ea0 	ldr	x0, [x21, #664]
    30a4:	94000000 	bl	0 <of_dma_is_coherent>
    30a8:	72001c1f 	tst	w0, #0xff
    30ac:	54000080 	b.eq	30bc <arm_smmu_device_probe+0xe4>  // b.none
		smmu->features |= ARM_SMMU_FEAT_COHERENCY;
    30b0:	b9401a60 	ldr	w0, [x19, #24]
    30b4:	32180000 	orr	w0, w0, #0x100
    30b8:	b9001a60 	str	w0, [x19, #24]
	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
    30bc:	52800002 	mov	w2, #0x0                   	// #0
    30c0:	52804001 	mov	w1, #0x200                 	// #512
    30c4:	aa1703e0 	mov	x0, x23
    30c8:	94000000 	bl	0 <platform_get_resource>
	if (smmu->options & ARM_SMMU_OPT_PAGE0_REGS_ONLY)
    30cc:	b9401e65 	ldr	w5, [x19, #28]
		return SZ_64K;
    30d0:	d2a00044 	mov	x4, #0x20000               	// #131072
int adjust_resource(struct resource *res, resource_size_t start,
		    resource_size_t size);
resource_size_t resource_alignment(struct resource *res);
static inline resource_size_t resource_size(const struct resource *res)
{
	return res->end - res->start + 1;
    30d4:	a9400403 	ldp	x3, x1, [x0]
    30d8:	d2a00022 	mov	x2, #0x10000               	// #65536
    30dc:	f27f00bf 	tst	x5, #0x2
    30e0:	91000421 	add	x1, x1, #0x1
    30e4:	9a820084 	csel	x4, x4, x2, eq  // eq = none
    30e8:	cb030021 	sub	x1, x1, x3
	if (resource_size(res) < arm_smmu_resource_size(smmu)) {
    30ec:	eb01009f 	cmp	x4, x1
    30f0:	540067e8 	b.hi	3dec <arm_smmu_device_probe+0xe14>  // b.pmore
		.end = start + size - 1,
    30f4:	9137fc60 	add	x0, x3, #0xdff
	struct resource res = {
    30f8:	a907ffbf 	stp	xzr, xzr, [x29, #120]
    30fc:	d2804014 	mov	x20, #0x200                 	// #512
	return devm_ioremap_resource(dev, &res);
    3100:	9101a3a1 	add	x1, x29, #0x68
	struct resource res = {
    3104:	a9060fa3 	stp	x3, x3, [x29, #96]
    3108:	f9003ba0 	str	x0, [x29, #112]
	return devm_ioremap_resource(dev, &res);
    310c:	aa1503e0 	mov	x0, x21
	struct resource res = {
    3110:	f90043b4 	str	x20, [x29, #128]
    3114:	a908ffbf 	stp	xzr, xzr, [x29, #136]
    3118:	a909ffbf 	stp	xzr, xzr, [x29, #152]
	return devm_ioremap_resource(dev, &res);
    311c:	94000000 	bl	0 <devm_ioremap_resource>
	smmu->base = arm_smmu_ioremap(dev, ioaddr, ARM_SMMU_REG_SZ);
    3120:	f9000660 	str	x0, [x19, #8]
	if (IS_ERR(smmu->base))
    3124:	b140041f 	cmn	x0, #0x1, lsl #12
    3128:	540026a8 	b.hi	35fc <arm_smmu_device_probe+0x624>  // b.pmore
	if (smmu->options & ARM_SMMU_OPT_PAGE0_REGS_ONLY)
    312c:	b9401e61 	ldr	w1, [x19, #28]
    3130:	36081ee1 	tbz	w1, #1, 350c <arm_smmu_device_probe+0x534>
    3134:	a9046bb9 	stp	x25, x26, [x29, #64]
	irq = platform_get_irq_byname_optional(pdev, "combined");
    3138:	90000001 	adrp	x1, 0 <queue_remove_raw>
		smmu->page1 = smmu->base;
    313c:	f9000a60 	str	x0, [x19, #16]
	irq = platform_get_irq_byname_optional(pdev, "combined");
    3140:	91000021 	add	x1, x1, #0x0
    3144:	aa1703e0 	mov	x0, x23
    3148:	94000000 	bl	0 <platform_get_irq_byname_optional>
	if (irq > 0)
    314c:	7100001f 	cmp	w0, #0x0
    3150:	540020ad 	b.le	3564 <arm_smmu_device_probe+0x58c>
		smmu->combined_irq = irq;
    3154:	b9030660 	str	w0, [x19, #772]
	bool coherent = smmu->features & ARM_SMMU_FEAT_COHERENCY;
    3158:	b9401a60 	ldr	w0, [x19, #24]
	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
    315c:	f9400674 	ldr	x20, [x19, #8]
    3160:	12180003 	and	w3, w0, #0x100
    3164:	d3482001 	ubfx	x1, x0, #8, #1
    3168:	b9400294 	ldr	w20, [x20]
	if (FIELD_GET(IDR0_ST_LVL, reg) == IDR0_ST_LVL_2LVL)
    316c:	2a1403f9 	mov	w25, w20
    3170:	d35b7322 	ubfx	x2, x25, #27, #2
    3174:	f100045f 	cmp	x2, #0x1
    3178:	54001180 	b.eq	33a8 <arm_smmu_device_probe+0x3d0>  // b.none
	if (reg & IDR0_CD2L)
    317c:	36980094 	tbz	w20, #19, 318c <arm_smmu_device_probe+0x1b4>
		smmu->features |= ARM_SMMU_FEAT_2_LVL_CDTAB;
    3180:	b9401a60 	ldr	w0, [x19, #24]
    3184:	321f0000 	orr	w0, w0, #0x2
    3188:	b9001a60 	str	w0, [x19, #24]
	switch (FIELD_GET(IDR0_TTENDIAN, reg)) {
    318c:	d3555b20 	ubfx	x0, x25, #21, #2
    3190:	f940027a 	ldr	x26, [x19]
    3194:	b4001020 	cbz	x0, 3398 <arm_smmu_device_probe+0x3c0>
    3198:	f100081f 	cmp	x0, #0x2
    319c:	54006001 	b.ne	3d9c <arm_smmu_device_probe+0xdc4>  // b.any
		smmu->features |= ARM_SMMU_FEAT_TT_LE;
    31a0:	b9401a60 	ldr	w0, [x19, #24]
    31a4:	321e0000 	orr	w0, w0, #0x4
    31a8:	b9001a60 	str	w0, [x19, #24]
	if (IS_ENABLED(CONFIG_PCI_ATS) && reg & IDR0_ATS)
    31ac:	36500074 	tbz	w20, #10, 31b8 <arm_smmu_device_probe+0x1e0>
		smmu->features |= ARM_SMMU_FEAT_ATS;
    31b0:	321b0000 	orr	w0, w0, #0x20
    31b4:	b9001a60 	str	w0, [x19, #24]
	if (reg & IDR0_SEV)
    31b8:	36700074 	tbz	w20, #14, 31c4 <arm_smmu_device_probe+0x1ec>
		smmu->features |= ARM_SMMU_FEAT_SEV;
    31bc:	321a0000 	orr	w0, w0, #0x40
    31c0:	b9001a60 	str	w0, [x19, #24]
	if (reg & IDR0_MSI)
    31c4:	36680074 	tbz	w20, #13, 31d0 <arm_smmu_device_probe+0x1f8>
		smmu->features |= ARM_SMMU_FEAT_MSI;
    31c8:	32190000 	orr	w0, w0, #0x80
    31cc:	b9001a60 	str	w0, [x19, #24]
	if (reg & IDR0_HYP)
    31d0:	36480074 	tbz	w20, #9, 31dc <arm_smmu_device_probe+0x204>
		smmu->features |= ARM_SMMU_FEAT_HYP;
    31d4:	32140000 	orr	w0, w0, #0x1000
    31d8:	b9001a60 	str	w0, [x19, #24]
	if (!!(reg & IDR0_COHACC) != coherent)
    31dc:	d3441280 	ubfx	x0, x20, #4, #1
    31e0:	6b00003f 	cmp	w1, w0
    31e4:	54006161 	b.ne	3e10 <arm_smmu_device_probe+0xe38>  // b.any
	switch (FIELD_GET(IDR0_STALL_MODEL, reg)) {
    31e8:	d3586720 	ubfx	x0, x25, #24, #2
    31ec:	b4001e80 	cbz	x0, 35bc <arm_smmu_device_probe+0x5e4>
    31f0:	f100081f 	cmp	x0, #0x2
    31f4:	540000a1 	b.ne	3208 <arm_smmu_device_probe+0x230>  // b.any
		smmu->features |= ARM_SMMU_FEAT_STALL_FORCE;
    31f8:	b9401a60 	ldr	w0, [x19, #24]
    31fc:	32130000 	orr	w0, w0, #0x2000
		smmu->features |= ARM_SMMU_FEAT_STALLS;
    3200:	32150000 	orr	w0, w0, #0x800
    3204:	b9001a60 	str	w0, [x19, #24]
	if (reg & IDR0_S1P)
    3208:	36080094 	tbz	w20, #1, 3218 <arm_smmu_device_probe+0x240>
		smmu->features |= ARM_SMMU_FEAT_TRANS_S1;
    320c:	b9401a60 	ldr	w0, [x19, #24]
    3210:	32170000 	orr	w0, w0, #0x200
    3214:	b9001a60 	str	w0, [x19, #24]
	if (reg & IDR0_S2P)
    3218:	36000094 	tbz	w20, #0, 3228 <arm_smmu_device_probe+0x250>
		smmu->features |= ARM_SMMU_FEAT_TRANS_S2;
    321c:	b9401a60 	ldr	w0, [x19, #24]
    3220:	32160000 	orr	w0, w0, #0x400
    3224:	b9001a60 	str	w0, [x19, #24]
	if (!(reg & (IDR0_S1P | IDR0_S2P))) {
    3228:	f240069f 	tst	x20, #0x3
    322c:	54005c40 	b.eq	3db4 <arm_smmu_device_probe+0xddc>  // b.none
	switch (FIELD_GET(IDR0_TTF, reg)) {
    3230:	d3420f39 	ubfx	x25, x25, #2, #2
    3234:	f1000b3f 	cmp	x25, #0x2
    3238:	540000a0 	b.eq	324c <arm_smmu_device_probe+0x274>  // b.none
    323c:	f1000f3f 	cmp	x25, #0x3
    3240:	54005c21 	b.ne	3dc4 <arm_smmu_device_probe+0xdec>  // b.any
		smmu->ias = 40;
    3244:	d2800500 	mov	x0, #0x28                  	// #40
    3248:	f9018660 	str	x0, [x19, #776]
	smmu->asid_bits = reg & IDR0_ASID16 ? 16 : 8;
    324c:	f274029f 	tst	x20, #0x1000
    3250:	52800203 	mov	w3, #0x10                  	// #16
    3254:	52800101 	mov	w1, #0x8                   	// #8
	reg = readl_relaxed(smmu->base + ARM_SMMU_IDR1);
    3258:	f9400660 	ldr	x0, [x19, #8]
	smmu->asid_bits = reg & IDR0_ASID16 ? 16 : 8;
    325c:	1a830022 	csel	w2, w1, w3, eq  // eq = none
	smmu->vmid_bits = reg & IDR0_VMID16 ? 16 : 8;
    3260:	f26e029f 	tst	x20, #0x40000
    3264:	1a830021 	csel	w1, w1, w3, eq  // eq = none
	smmu->asid_bits = reg & IDR0_ASID16 ? 16 : 8;
    3268:	b9032262 	str	w2, [x19, #800]
	smmu->vmid_bits = reg & IDR0_VMID16 ? 16 : 8;
    326c:	b9032661 	str	w1, [x19, #804]
	reg = readl_relaxed(smmu->base + ARM_SMMU_IDR1);
    3270:	91001001 	add	x1, x0, #0x4
    3274:	b9400021 	ldr	w1, [x1]
	if (reg & (IDR1_TABLES_PRESET | IDR1_QUEUES_PRESET | IDR1_REL)) {
    3278:	7204083f 	tst	w1, #0x70000000
    327c:	54005e21 	b.ne	3e40 <arm_smmu_device_probe+0xe68>  // b.any
	smmu->cmdq.q.llq.max_n_shift = min_t(u32, CMDQ_MAX_SZ_SHIFT,
    3280:	2a0103e2 	mov	w2, w1
    3284:	d3556444 	ubfx	x4, x2, #21, #5
    3288:	7100409f 	cmp	w4, #0x10
    328c:	1a839085 	csel	w5, w4, w3, ls  // ls = plast
    3290:	b9008265 	str	w5, [x19, #128]
	if (smmu->cmdq.q.llq.max_n_shift <= ilog2(CMDQ_BATCH_ENTRIES)) {
    3294:	f100189f 	cmp	x4, #0x6
    3298:	540056e9 	b.ls	3d74 <arm_smmu_device_probe+0xd9c>  // b.plast
	smmu->evtq.q.llq.max_n_shift = min_t(u32, EVTQ_MAX_SZ_SHIFT,
    329c:	d3505045 	ubfx	x5, x2, #16, #5
	smmu->priq.q.llq.max_n_shift = min_t(u32, PRIQ_MAX_SZ_SHIFT,
    32a0:	d34b3c44 	ubfx	x4, x2, #11, #5
	smmu->evtq.q.llq.max_n_shift = min_t(u32, EVTQ_MAX_SZ_SHIFT,
    32a4:	71003cbf 	cmp	w5, #0xf
    32a8:	528001e6 	mov	w6, #0xf                   	// #15
    32ac:	1a8690a5 	csel	w5, w5, w6, ls  // ls = plast
	smmu->priq.q.llq.max_n_shift = min_t(u32, PRIQ_MAX_SZ_SHIFT,
    32b0:	7100409f 	cmp	w4, #0x10
    32b4:	1a839083 	csel	w3, w4, w3, ls  // ls = plast
    32b8:	12001421 	and	w1, w1, #0x3f
	smmu->ssid_bits = FIELD_GET(IDR1_SSIDSIZE, reg);
    32bc:	d3462842 	ubfx	x2, x2, #6, #5
	smmu->evtq.q.llq.max_n_shift = min_t(u32, EVTQ_MAX_SZ_SHIFT,
    32c0:	b9018265 	str	w5, [x19, #384]
	smmu->priq.q.llq.max_n_shift = min_t(u32, PRIQ_MAX_SZ_SHIFT,
    32c4:	b9028263 	str	w3, [x19, #640]
	if (smmu->sid_bits <= STRTAB_SPLIT)
    32c8:	7100203f 	cmp	w1, #0x8
	smmu->ssid_bits = FIELD_GET(IDR1_SSIDSIZE, reg);
    32cc:	b9232a62 	str	w2, [x19, #9000]
	smmu->sid_bits = FIELD_GET(IDR1_SIDSIZE, reg);
    32d0:	b9232e61 	str	w1, [x19, #9004]
	if (smmu->sid_bits <= STRTAB_SPLIT)
    32d4:	54000088 	b.hi	32e4 <arm_smmu_device_probe+0x30c>  // b.pmore
		smmu->features &= ~ARM_SMMU_FEAT_2_LVL_STRTAB;
    32d8:	b9401a61 	ldr	w1, [x19, #24]
    32dc:	121f7821 	and	w1, w1, #0xfffffffe
    32e0:	b9001a61 	str	w1, [x19, #24]
	reg = readl_relaxed(smmu->base + ARM_SMMU_IDR3);
    32e4:	91003001 	add	x1, x0, #0xc
    32e8:	b9400021 	ldr	w1, [x1]
	if (FIELD_GET(IDR3_RIL, reg))
    32ec:	36500081 	tbz	w1, #10, 32fc <arm_smmu_device_probe+0x324>
		smmu->features |= ARM_SMMU_FEAT_RANGE_INV;
    32f0:	b9401a61 	ldr	w1, [x19, #24]
    32f4:	32110021 	orr	w1, w1, #0x8000
    32f8:	b9001a61 	str	w1, [x19, #24]
	reg = readl_relaxed(smmu->base + ARM_SMMU_IDR5);
    32fc:	91005000 	add	x0, x0, #0x14
    3300:	b9400000 	ldr	w0, [x0]
	smmu->evtq.max_stalls = FIELD_GET(IDR5_STALL_MAX, reg);
    3304:	53107c01 	lsr	w1, w0, #16
    3308:	b9020261 	str	w1, [x19, #512]
	if (reg & IDR5_GRAN64K)
    330c:	363000a0 	tbz	w0, #6, 3320 <arm_smmu_device_probe+0x348>
		smmu->pgsize_bitmap |= SZ_64K | SZ_512M;
    3310:	f9418e61 	ldr	x1, [x19, #792]
    3314:	d2a40022 	mov	x2, #0x20010000            	// #536936448
    3318:	aa020021 	orr	x1, x1, x2
    331c:	f9018e61 	str	x1, [x19, #792]
	if (reg & IDR5_GRAN16K)
    3320:	362800c0 	tbz	w0, #5, 3338 <arm_smmu_device_probe+0x360>
		smmu->pgsize_bitmap |= SZ_16K | SZ_32M;
    3324:	f9418e61 	ldr	x1, [x19, #792]
    3328:	d2880002 	mov	x2, #0x4000                	// #16384
    332c:	f2a04002 	movk	x2, #0x200, lsl #16
    3330:	aa020021 	orr	x1, x1, x2
    3334:	f9018e61 	str	x1, [x19, #792]
	if (reg & IDR5_GRAN4K)
    3338:	362000c0 	tbz	w0, #4, 3350 <arm_smmu_device_probe+0x378>
		smmu->pgsize_bitmap |= SZ_4K | SZ_2M | SZ_1G;
    333c:	f9418e61 	ldr	x1, [x19, #792]
    3340:	d2820002 	mov	x2, #0x1000                	// #4096
    3344:	f2a80402 	movk	x2, #0x4020, lsl #16
    3348:	aa020021 	orr	x1, x1, x2
    334c:	f9018e61 	str	x1, [x19, #792]
	if (FIELD_GET(IDR5_VAX, reg) == IDR5_VAX_52_BIT)
    3350:	d34a2c01 	ubfx	x1, x0, #10, #2
    3354:	f100043f 	cmp	x1, #0x1
    3358:	54000081 	b.ne	3368 <arm_smmu_device_probe+0x390>  // b.any
		smmu->features |= ARM_SMMU_FEAT_VAX;
    335c:	b9401a61 	ldr	w1, [x19, #24]
    3360:	32120021 	orr	w1, w1, #0x4000
    3364:	b9001a61 	str	w1, [x19, #24]
	switch (FIELD_GET(IDR5_OAS, reg)) {
    3368:	12000800 	and	w0, w0, #0x7
    336c:	71000c1f 	cmp	w0, #0x3
    3370:	540016c0 	b.eq	3648 <arm_smmu_device_probe+0x670>  // b.none
    3374:	54000228 	b.hi	33b8 <arm_smmu_device_probe+0x3e0>  // b.pmore
    3378:	7100041f 	cmp	w0, #0x1
    337c:	540015c0 	b.eq	3634 <arm_smmu_device_probe+0x65c>  // b.none
    3380:	540012c8 	b.hi	35d8 <arm_smmu_device_probe+0x600>  // b.pmore
		smmu->oas = 32;
    3384:	d2800414 	mov	x20, #0x20                  	// #32
    3388:	f9418e62 	ldr	x2, [x19, #792]
    338c:	aa1403e0 	mov	x0, x20
    3390:	f9018a74 	str	x20, [x19, #784]
    3394:	14000015 	b	33e8 <arm_smmu_device_probe+0x410>
		smmu->features |= ARM_SMMU_FEAT_TT_LE | ARM_SMMU_FEAT_TT_BE;
    3398:	b9401a60 	ldr	w0, [x19, #24]
    339c:	321e0400 	orr	w0, w0, #0xc
    33a0:	b9001a60 	str	w0, [x19, #24]
    33a4:	17ffff82 	b	31ac <arm_smmu_device_probe+0x1d4>
		smmu->features |= ARM_SMMU_FEAT_2_LVL_STRTAB;
    33a8:	32000000 	orr	w0, w0, #0x1
    33ac:	b9001a60 	str	w0, [x19, #24]
	if (reg & IDR0_CD2L)
    33b0:	369feef4 	tbz	w20, #19, 318c <arm_smmu_device_probe+0x1b4>
    33b4:	17ffff73 	b	3180 <arm_smmu_device_probe+0x1a8>
	switch (FIELD_GET(IDR5_OAS, reg)) {
    33b8:	7100141f 	cmp	w0, #0x5
    33bc:	54001320 	b.eq	3620 <arm_smmu_device_probe+0x648>  // b.none
    33c0:	54001023 	b.cc	35c4 <arm_smmu_device_probe+0x5ec>  // b.lo, b.ul, b.last
    33c4:	7100181f 	cmp	w0, #0x6
    33c8:	54001221 	b.ne	360c <arm_smmu_device_probe+0x634>  // b.any
		smmu->pgsize_bitmap |= 1ULL << 42; /* 4TB */
    33cc:	f9418e62 	ldr	x2, [x19, #792]
		smmu->oas = 52;
    33d0:	d2800694 	mov	x20, #0x34                  	// #52
		smmu->pgsize_bitmap |= 1ULL << 42; /* 4TB */
    33d4:	aa1403e0 	mov	x0, x20
		smmu->oas = 52;
    33d8:	f9018a74 	str	x20, [x19, #784]
		smmu->pgsize_bitmap |= 1ULL << 42; /* 4TB */
    33dc:	b2560042 	orr	x2, x2, #0x40000000000
    33e0:	f9018e62 	str	x2, [x19, #792]
    33e4:	d503201f 	nop
	if (arm_smmu_ops.pgsize_bitmap == -1UL)
    33e8:	90000019 	adrp	x25, 0 <queue_remove_raw>
    33ec:	91000323 	add	x3, x25, #0x0
	if (dma_set_mask_and_coherent(smmu->dev, DMA_BIT_MASK(smmu->oas)))
    33f0:	d2800034 	mov	x20, #0x1                   	// #1
    33f4:	9ac02294 	lsl	x20, x20, x0
    33f8:	d1000694 	sub	x20, x20, #0x1
	if (arm_smmu_ops.pgsize_bitmap == -1UL)
    33fc:	f9415864 	ldr	x4, [x3, #688]
	int rc = dma_set_mask(dev, mask);
    3400:	aa1403e1 	mov	x1, x20
    3404:	aa1a03e0 	mov	x0, x26
		arm_smmu_ops.pgsize_bitmap = smmu->pgsize_bitmap;
    3408:	b100049f 	cmn	x4, #0x1
    340c:	aa020084 	orr	x4, x4, x2
    3410:	9a840042 	csel	x2, x2, x4, eq  // eq = none
    3414:	f9015862 	str	x2, [x3, #688]
    3418:	94000000 	bl	0 <dma_set_mask>
	if (rc == 0)
    341c:	34000e80 	cbz	w0, 35ec <arm_smmu_device_probe+0x614>
		dev_warn(smmu->dev,
    3420:	f9400260 	ldr	x0, [x19]
    3424:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3428:	91000021 	add	x1, x1, #0x0
    342c:	94000000 	bl	0 <_dev_warn>
	smmu->ias = max(smmu->ias, smmu->oas);
    3430:	f9418662 	ldr	x2, [x19, #776]
	dev_info(smmu->dev, "ias %lu-bit, oas %lu-bit (features 0x%08x)\n",
    3434:	aa1303fa 	mov	x26, x19
	smmu->ias = max(smmu->ias, smmu->oas);
    3438:	f9418a60 	ldr	x0, [x19, #784]
	dev_info(smmu->dev, "ias %lu-bit, oas %lu-bit (features 0x%08x)\n",
    343c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3440:	b9401a64 	ldr	w4, [x19, #24]
    3444:	91000021 	add	x1, x1, #0x0
	smmu->ias = max(smmu->ias, smmu->oas);
    3448:	eb00005f 	cmp	x2, x0
	dev_info(smmu->dev, "ias %lu-bit, oas %lu-bit (features 0x%08x)\n",
    344c:	aa0003e3 	mov	x3, x0
	smmu->ias = max(smmu->ias, smmu->oas);
    3450:	9a802042 	csel	x2, x2, x0, cs  // cs = hs, nlast
    3454:	f9018662 	str	x2, [x19, #776]
	dev_info(smmu->dev, "ias %lu-bit, oas %lu-bit (features 0x%08x)\n",
    3458:	f8440740 	ldr	x0, [x26], #64
    345c:	94000000 	bl	0 <_dev_info>
	ret = arm_smmu_init_one_queue(smmu, &smmu->cmdq.q, ARM_SMMU_CMDQ_PROD,
    3460:	90000005 	adrp	x5, 0 <queue_remove_raw>
    3464:	d2800044 	mov	x4, #0x2                   	// #2
    3468:	910000a5 	add	x5, x5, #0x0
    346c:	d2801383 	mov	x3, #0x9c                  	// #156
    3470:	d2801302 	mov	x2, #0x98                  	// #152
    3474:	aa1a03e1 	mov	x1, x26
    3478:	aa1303e0 	mov	x0, x19
    347c:	97fff57f 	bl	a78 <arm_smmu_init_one_queue>
    3480:	2a0003f4 	mov	w20, w0
	if (ret)
    3484:	34000ec0 	cbz	w0, 365c <arm_smmu_device_probe+0x684>
    3488:	f9400bb3 	ldr	x19, [x29, #16]
    348c:	a943e7b8 	ldp	x24, x25, [x29, #56]
    3490:	f94027ba 	ldr	x26, [x29, #72]
}
    3494:	910002d6 	add	x22, x22, #0x0
    3498:	2a1403e0 	mov	w0, w20
    349c:	f94057a2 	ldr	x2, [x29, #168]
    34a0:	f94002c1 	ldr	x1, [x22]
    34a4:	ca010041 	eor	x1, x2, x1
    34a8:	b5004d41 	cbnz	x1, 3e50 <arm_smmu_device_probe+0xe78>
    34ac:	a941d7f4 	ldp	x20, x21, [sp, #24]
    34b0:	a942dff6 	ldp	x22, x23, [sp, #40]
    34b4:	a8cb7bfd 	ldp	x29, x30, [sp], #176
    34b8:	d50323bf 	autiasp
    34bc:	d65f03c0 	ret
	node = *(struct acpi_iort_node **)dev_get_platdata(dev);
    34c0:	f94042e0 	ldr	x0, [x23, #128]
    34c4:	b9401e62 	ldr	w2, [x19, #28]
    34c8:	f9400014 	ldr	x20, [x0]
	acpi_smmu_get_options(iort_smmu->model, smmu);
    34cc:	91004294 	add	x20, x20, #0x10
	switch (model) {
    34d0:	b9401a80 	ldr	w0, [x20, #24]
    34d4:	7100041f 	cmp	w0, #0x1
    34d8:	540017e0 	b.eq	37d4 <arm_smmu_device_probe+0x7fc>  // b.none
    34dc:	7100081f 	cmp	w0, #0x2
    34e0:	54000061 	b.ne	34ec <arm_smmu_device_probe+0x514>  // b.any
		smmu->options |= ARM_SMMU_OPT_PAGE0_REGS_ONLY;
    34e4:	321f0042 	orr	w2, w2, #0x2
    34e8:	b9001e62 	str	w2, [x19, #28]
	dev_notice(smmu->dev, "option mask 0x%x\n", smmu->options);
    34ec:	aa1503e0 	mov	x0, x21
    34f0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    34f4:	91000021 	add	x1, x1, #0x0
    34f8:	94000000 	bl	0 <_dev_notice>
	if (iort_smmu->flags & ACPI_IORT_SMMU_V3_COHACC_OVERRIDE)
    34fc:	b9400a80 	ldr	w0, [x20, #8]
		ret = arm_smmu_device_acpi_probe(pdev, smmu);
    3500:	52800018 	mov	w24, #0x0                   	// #0
	if (iort_smmu->flags & ACPI_IORT_SMMU_V3_COHACC_OVERRIDE)
    3504:	3707dd60 	tbnz	w0, #0, 30b0 <arm_smmu_device_probe+0xd8>
    3508:	17fffeed 	b	30bc <arm_smmu_device_probe+0xe4>
		smmu->page1 = arm_smmu_ioremap(dev, ioaddr + SZ_64K,
    350c:	f94033a0 	ldr	x0, [x29, #96]
	struct resource res = {
    3510:	a907ffbf 	stp	xzr, xzr, [x29, #120]
		smmu->page1 = arm_smmu_ioremap(dev, ioaddr + SZ_64K,
    3514:	91404001 	add	x1, x0, #0x10, lsl #12
		.end = start + size - 1,
    3518:	91404000 	add	x0, x0, #0x10, lsl #12
    351c:	9137fc00 	add	x0, x0, #0xdff
	struct resource res = {
    3520:	a90683a1 	stp	x1, x0, [x29, #104]
    3524:	f90043b4 	str	x20, [x29, #128]
	return devm_ioremap_resource(dev, &res);
    3528:	9101a3a1 	add	x1, x29, #0x68
	struct resource res = {
    352c:	a908ffbf 	stp	xzr, xzr, [x29, #136]
	return devm_ioremap_resource(dev, &res);
    3530:	aa1503e0 	mov	x0, x21
	struct resource res = {
    3534:	a909ffbf 	stp	xzr, xzr, [x29, #152]
	return devm_ioremap_resource(dev, &res);
    3538:	94000000 	bl	0 <devm_ioremap_resource>
		smmu->page1 = arm_smmu_ioremap(dev, ioaddr + SZ_64K,
    353c:	f9000a60 	str	x0, [x19, #16]
		if (IS_ERR(smmu->page1))
    3540:	b140041f 	cmn	x0, #0x1, lsl #12
    3544:	540005c8 	b.hi	35fc <arm_smmu_device_probe+0x624>  // b.pmore
    3548:	a9046bb9 	stp	x25, x26, [x29, #64]
	irq = platform_get_irq_byname_optional(pdev, "combined");
    354c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3550:	aa1703e0 	mov	x0, x23
    3554:	91000021 	add	x1, x1, #0x0
    3558:	94000000 	bl	0 <platform_get_irq_byname_optional>
	if (irq > 0)
    355c:	7100001f 	cmp	w0, #0x0
    3560:	54ffdfac 	b.gt	3154 <arm_smmu_device_probe+0x17c>
		irq = platform_get_irq_byname_optional(pdev, "eventq");
    3564:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3568:	aa1703e0 	mov	x0, x23
    356c:	91000021 	add	x1, x1, #0x0
    3570:	94000000 	bl	0 <platform_get_irq_byname_optional>
		if (irq > 0)
    3574:	7100001f 	cmp	w0, #0x0
    3578:	5400004d 	b.le	3580 <arm_smmu_device_probe+0x5a8>
			smmu->evtq.q.irq = irq;
    357c:	b901c260 	str	w0, [x19, #448]
		irq = platform_get_irq_byname_optional(pdev, "priq");
    3580:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3584:	aa1703e0 	mov	x0, x23
    3588:	91000021 	add	x1, x1, #0x0
    358c:	94000000 	bl	0 <platform_get_irq_byname_optional>
		if (irq > 0)
    3590:	7100001f 	cmp	w0, #0x0
    3594:	5400004d 	b.le	359c <arm_smmu_device_probe+0x5c4>
			smmu->priq.q.irq = irq;
    3598:	b902c260 	str	w0, [x19, #704]
		irq = platform_get_irq_byname_optional(pdev, "gerror");
    359c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    35a0:	aa1703e0 	mov	x0, x23
    35a4:	91000021 	add	x1, x1, #0x0
    35a8:	94000000 	bl	0 <platform_get_irq_byname_optional>
		if (irq > 0)
    35ac:	7100001f 	cmp	w0, #0x0
    35b0:	54ffdd4d 	b.le	3158 <arm_smmu_device_probe+0x180>
			smmu->gerr_irq = irq;
    35b4:	b9030260 	str	w0, [x19, #768]
    35b8:	17fffee8 	b	3158 <arm_smmu_device_probe+0x180>
    35bc:	b9401a60 	ldr	w0, [x19, #24]
    35c0:	17ffff10 	b	3200 <arm_smmu_device_probe+0x228>
		smmu->oas = 44;
    35c4:	d2800594 	mov	x20, #0x2c                  	// #44
    35c8:	f9418e62 	ldr	x2, [x19, #792]
    35cc:	aa1403e0 	mov	x0, x20
    35d0:	f9018a74 	str	x20, [x19, #784]
    35d4:	17ffff85 	b	33e8 <arm_smmu_device_probe+0x410>
		smmu->oas = 40;
    35d8:	d2800514 	mov	x20, #0x28                  	// #40
    35dc:	f9418e62 	ldr	x2, [x19, #792]
    35e0:	aa1403e0 	mov	x0, x20
    35e4:	f9018a74 	str	x20, [x19, #784]
    35e8:	17ffff80 	b	33e8 <arm_smmu_device_probe+0x410>
		dma_set_coherent_mask(dev, mask);
    35ec:	aa1403e1 	mov	x1, x20
    35f0:	aa1a03e0 	mov	x0, x26
    35f4:	94000000 	bl	0 <dma_set_coherent_mask>
    35f8:	17ffff8e 	b	3430 <arm_smmu_device_probe+0x458>
			return PTR_ERR(smmu->page1);
    35fc:	2a0003f4 	mov	w20, w0
    3600:	f9400bb3 	ldr	x19, [x29, #16]
    3604:	f9401fb8 	ldr	x24, [x29, #56]
    3608:	17ffffa3 	b	3494 <arm_smmu_device_probe+0x4bc>
		dev_info(smmu->dev,
    360c:	aa1a03e0 	mov	x0, x26
    3610:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3614:	91000021 	add	x1, x1, #0x0
    3618:	94000000 	bl	0 <_dev_info>
    361c:	f940027a 	ldr	x26, [x19]
		smmu->oas = 48;
    3620:	d2800601 	mov	x1, #0x30                  	// #48
    3624:	f9418e62 	ldr	x2, [x19, #792]
    3628:	aa0103e0 	mov	x0, x1
    362c:	f9018a61 	str	x1, [x19, #784]
    3630:	17ffff6e 	b	33e8 <arm_smmu_device_probe+0x410>
		smmu->oas = 36;
    3634:	d2800494 	mov	x20, #0x24                  	// #36
    3638:	f9418e62 	ldr	x2, [x19, #792]
    363c:	aa1403e0 	mov	x0, x20
    3640:	f9018a74 	str	x20, [x19, #784]
    3644:	17ffff69 	b	33e8 <arm_smmu_device_probe+0x410>
		smmu->oas = 42;
    3648:	d2800554 	mov	x20, #0x2a                  	// #42
    364c:	f9418e62 	ldr	x2, [x19, #792]
    3650:	aa1403e0 	mov	x0, x20
    3654:	f9018a74 	str	x20, [x19, #784]
    3658:	17ffff64 	b	33e8 <arm_smmu_device_probe+0x410>
	unsigned int nents = 1 << cmdq->q.llq.max_n_shift;
    365c:	b9404340 	ldr	w0, [x26, #64]
    3660:	52800022 	mov	w2, #0x1                   	// #1
	arch_atomic_set(v, i);
    3664:	b9010a7f 	str	wzr, [x19, #264]
	bitmap = (atomic_long_t *)bitmap_zalloc(nents, GFP_KERNEL);
    3668:	52819801 	mov	w1, #0xcc0                 	// #3264
    366c:	b9010e7f 	str	wzr, [x19, #268]
    3670:	1ac02040 	lsl	w0, w2, w0
    3674:	94000000 	bl	0 <bitmap_zalloc>
	if (!bitmap) {
    3678:	b4004ea0 	cbz	x0, 404c <arm_smmu_device_probe+0x1074>
		cmdq->valid_map = bitmap;
    367c:	f9006340 	str	x0, [x26, #192]
		devm_add_action(smmu->dev, arm_smmu_cmdq_free_bitmap, bitmap);
    3680:	aa0003e2 	mov	x2, x0
    3684:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3688:	91000021 	add	x1, x1, #0x0
    368c:	f9400260 	ldr	x0, [x19]
    3690:	94000000 	bl	0 <devm_add_action>
	ret = arm_smmu_init_one_queue(smmu, &smmu->evtq.q, ARM_SMMU_EVTQ_PROD,
    3694:	d2801583 	mov	x3, #0xac                  	// #172
    3698:	d2801502 	mov	x2, #0xa8                  	// #168
    369c:	90000005 	adrp	x5, 0 <queue_remove_raw>
    36a0:	d2800084 	mov	x4, #0x4                   	// #4
    36a4:	910000a5 	add	x5, x5, #0x0
    36a8:	f2a00023 	movk	x3, #0x1, lsl #16
    36ac:	f2a00022 	movk	x2, #0x1, lsl #16
    36b0:	91050261 	add	x1, x19, #0x140
    36b4:	aa1303e0 	mov	x0, x19
    36b8:	97fff4f0 	bl	a78 <arm_smmu_init_one_queue>
    36bc:	2a0003f4 	mov	w20, w0
	if (ret)
    36c0:	35ffee40 	cbnz	w0, 3488 <arm_smmu_device_probe+0x4b0>
    36c4:	a90573bb 	stp	x27, x28, [x29, #80]
	if (!(smmu->features & ARM_SMMU_FEAT_PRI))
    36c8:	b9401a61 	ldr	w1, [x19, #24]
    36cc:	37200f21 	tbnz	w1, #4, 38b0 <arm_smmu_device_probe+0x8d8>
    36d0:	d2846602 	mov	x2, #0x2330                	// #9008
    36d4:	8b02027a 	add	x26, x19, x2
    36d8:	91002354 	add	x20, x26, #0x8
    36dc:	b9632e63 	ldr	w3, [x19, #9004]
    36e0:	f9400260 	ldr	x0, [x19]
	if (smmu->features & ARM_SMMU_FEAT_2_LVL_STRTAB)
    36e4:	360008c1 	tbz	w1, #0, 37fc <arm_smmu_device_probe+0x824>
	size = min(size, smmu->sid_bits - STRTAB_SPLIT);
    36e8:	51002061 	sub	w1, w3, #0x8
    36ec:	52800224 	mov	w4, #0x11                  	// #17
    36f0:	6b04003f 	cmp	w1, w4
	cfg->num_l1_ents = 1 << size;
    36f4:	52800022 	mov	w2, #0x1                   	// #1
	size = min(size, smmu->sid_bits - STRTAB_SPLIT);
    36f8:	1a849021 	csel	w1, w1, w4, ls  // ls = plast
	size += STRTAB_SPLIT;
    36fc:	1100203c 	add	w28, w1, #0x8
	cfg->num_l1_ents = 1 << size;
    3700:	1ac12041 	lsl	w1, w2, w1
    3704:	b9001b41 	str	w1, [x26, #24]
	if (size < smmu->sid_bits)
    3708:	6b1c007f 	cmp	w3, w28
    370c:	54004e08 	b.hi	40cc <arm_smmu_device_probe+0x10f4>  // b.pmore
	return dmam_alloc_attrs(dev, size, dma_handle, gfp,
    3710:	aa1403e2 	mov	x2, x20
    3714:	d2800004 	mov	x4, #0x0                   	// #0
    3718:	52819803 	mov	w3, #0xcc0                 	// #3264
    371c:	531d7021 	lsl	w1, w1, #3
    3720:	94000000 	bl	0 <dmam_alloc_attrs>
    3724:	aa0003f4 	mov	x20, x0
	if (!strtab) {
    3728:	b4004c80 	cbz	x0, 40b8 <arm_smmu_device_probe+0x10e0>
	size_t size = sizeof(*cfg->l1_desc) * cfg->num_l1_ents;
    372c:	b9634a61 	ldr	w1, [x19, #9032]
    3730:	5280031b 	mov	w27, #0x18                  	// #24
    3734:	f9400260 	ldr	x0, [x19]
	cfg->strtab_base_cfg = reg;
    3738:	52804003 	mov	w3, #0x200                 	// #512
    373c:	72a00023 	movk	w3, #0x1, lsl #16
	cfg->strtab = strtab;
    3740:	f9119a74 	str	x20, [x19, #9008]
	cfg->strtab_base_cfg = reg;
    3744:	2a03039c 	orr	w28, w28, w3
    3748:	b9235a7c 	str	w28, [x19, #9048]
    374c:	9bbb7c21 	umull	x1, w1, w27
    3750:	5281b802 	mov	w2, #0xdc0                 	// #3520
    3754:	94000000 	bl	0 <devm_kmalloc>
	cfg->l1_desc = devm_kzalloc(smmu->dev, size, GFP_KERNEL);
    3758:	f911a260 	str	x0, [x19, #9024]
	if (!cfg->l1_desc) {
    375c:	b4003c00 	cbz	x0, 3edc <arm_smmu_device_probe+0xf04>
	for (i = 0; i < cfg->num_l1_ents; ++i) {
    3760:	b9634a62 	ldr	w2, [x19, #9032]
    3764:	52800001 	mov	w1, #0x0                   	// #0
		arm_smmu_write_strtab_l1_desc(strtab, &cfg->l1_desc[i]);
    3768:	2a1b03e4 	mov	w4, w27
	for (i = 0; i < cfg->num_l1_ents; ++i) {
    376c:	350001a2 	cbnz	w2, 37a0 <arm_smmu_device_probe+0x7c8>
	reg  = smmu->strtab_cfg.strtab_dma & STRTAB_BASE_ADDR_MASK;
    3770:	f9519e60 	ldr	x0, [x19, #9016]
	set_bit(0, smmu->vmid_map);
    3774:	910ca261 	add	x1, x19, #0x328
	reg  = smmu->strtab_cfg.strtab_dma & STRTAB_BASE_ADDR_MASK;
    3778:	927ab400 	and	x0, x0, #0xfffffffffffc0
	reg |= STRTAB_BASE_RA;
    377c:	b2420000 	orr	x0, x0, #0x4000000000000000
	smmu->strtab_cfg.strtab_base = reg;
    3780:	f911aa60 	str	x0, [x19, #9040]
    3784:	1400003b 	b	3870 <arm_smmu_device_probe+0x898>
    3788:	1400003a 	b	3870 <arm_smmu_device_probe+0x898>
ATOMIC64_OP(or, stset)
    378c:	d2800020 	mov	x0, #0x1                   	// #1
    3790:	910ca262 	add	x2, x19, #0x328
    3794:	f820305f 	stset	x0, [x2]
    3798:	14000038 	b	3878 <arm_smmu_device_probe+0x8a0>
    379c:	f9400b40 	ldr	x0, [x26, #16]
		arm_smmu_write_strtab_l1_desc(strtab, &cfg->l1_desc[i]);
    37a0:	9ba47c22 	umull	x2, w1, w4
	for (i = 0; i < cfg->num_l1_ents; ++i) {
    37a4:	11000421 	add	w1, w1, #0x1
		arm_smmu_write_strtab_l1_desc(strtab, &cfg->l1_desc[i]);
    37a8:	8b020003 	add	x3, x0, x2
	val |= FIELD_PREP(STRTAB_L1_DESC_SPAN, desc->span);
    37ac:	38626800 	ldrb	w0, [x0, x2]
	val |= desc->l2ptr_dma & STRTAB_L1_DESC_L2PTR_MASK;
    37b0:	f9400862 	ldr	x2, [x3, #16]
	val |= FIELD_PREP(STRTAB_L1_DESC_SPAN, desc->span);
    37b4:	92401000 	and	x0, x0, #0x1f
	val |= desc->l2ptr_dma & STRTAB_L1_DESC_L2PTR_MASK;
    37b8:	927ab442 	and	x2, x2, #0xfffffffffffc0
    37bc:	aa020000 	orr	x0, x0, x2
	WRITE_ONCE(*dst, cpu_to_le64(val));
    37c0:	f8008680 	str	x0, [x20], #8
	for (i = 0; i < cfg->num_l1_ents; ++i) {
    37c4:	b9401b40 	ldr	w0, [x26, #24]
    37c8:	6b00003f 	cmp	w1, w0
    37cc:	54fffe83 	b.cc	379c <arm_smmu_device_probe+0x7c4>  // b.lo, b.ul, b.last
    37d0:	17ffffe8 	b	3770 <arm_smmu_device_probe+0x798>
		smmu->options |= ARM_SMMU_OPT_SKIP_PREFETCH;
    37d4:	32000042 	orr	w2, w2, #0x1
    37d8:	b9001e62 	str	w2, [x19, #28]
	dev_notice(smmu->dev, "option mask 0x%x\n", smmu->options);
    37dc:	aa1503e0 	mov	x0, x21
    37e0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    37e4:	91000021 	add	x1, x1, #0x0
    37e8:	94000000 	bl	0 <_dev_notice>
	if (iort_smmu->flags & ACPI_IORT_SMMU_V3_COHACC_OVERRIDE)
    37ec:	b9400a80 	ldr	w0, [x20, #8]
		ret = arm_smmu_device_acpi_probe(pdev, smmu);
    37f0:	52800018 	mov	w24, #0x0                   	// #0
	if (iort_smmu->flags & ACPI_IORT_SMMU_V3_COHACC_OVERRIDE)
    37f4:	3707c5e0 	tbnz	w0, #0, 30b0 <arm_smmu_device_probe+0xd8>
    37f8:	17fffe31 	b	30bc <arm_smmu_device_probe+0xe4>
	size = (1 << smmu->sid_bits) * (STRTAB_STE_DWORDS << 3);
    37fc:	5280081b 	mov	w27, #0x40                  	// #64
    3800:	aa1403e2 	mov	x2, x20
    3804:	1ac32361 	lsl	w1, w27, w3
    3808:	d2800004 	mov	x4, #0x0                   	// #0
    380c:	aa0103fb 	mov	x27, x1
    3810:	52819803 	mov	w3, #0xcc0                 	// #3264
    3814:	94000000 	bl	0 <dmam_alloc_attrs>
    3818:	aa0003f4 	mov	x20, x0
	if (!strtab) {
    381c:	b4003740 	cbz	x0, 3f04 <arm_smmu_device_probe+0xf2c>
	cfg->num_l1_ents = 1 << smmu->sid_bits;
    3820:	b9632e61 	ldr	w1, [x19, #9004]
    3824:	52800020 	mov	w0, #0x1                   	// #1
	cfg->strtab = strtab;
    3828:	f9119a74 	str	x20, [x19, #9008]
	cfg->strtab_base_cfg = reg;
    382c:	12001422 	and	w2, w1, #0x3f
    3830:	b9002b42 	str	w2, [x26, #40]
	cfg->num_l1_ents = 1 << smmu->sid_bits;
    3834:	1ac12000 	lsl	w0, w0, w1
    3838:	b9001b40 	str	w0, [x26, #24]
	for (i = 0; i < nent; ++i) {
    383c:	34fff9a0 	cbz	w0, 3770 <arm_smmu_device_probe+0x798>
    3840:	5100041a 	sub	w26, w0, #0x1
    3844:	9100075a 	add	x26, x26, #0x1
    3848:	8b1a1a9a 	add	x26, x20, x26, lsl #6
    384c:	d503201f 	nop
		arm_smmu_write_strtab_ent(NULL, -1, strtab);
    3850:	aa1403e2 	mov	x2, x20
    3854:	12800001 	mov	w1, #0xffffffff            	// #-1
    3858:	d2800000 	mov	x0, #0x0                   	// #0
		strtab += STRTAB_STE_DWORDS;
    385c:	91010294 	add	x20, x20, #0x40
		arm_smmu_write_strtab_ent(NULL, -1, strtab);
    3860:	97fffa76 	bl	2238 <arm_smmu_write_strtab_ent>
	for (i = 0; i < nent; ++i) {
    3864:	eb1a029f 	cmp	x20, x26
    3868:	54ffff41 	b.ne	3850 <arm_smmu_device_probe+0x878>  // b.any
    386c:	17ffffc1 	b	3770 <arm_smmu_device_probe+0x798>
ATOMIC64_OPS(or, orr, L)
    3870:	910ca262 	add	x2, x19, #0x328
    3874:	140004b4 	b	4b44 <arm_smmu_flush_iotlb_all+0x1ac>
	reg = readl_relaxed(smmu->base + ARM_SMMU_CR0);
    3878:	f9400660 	ldr	x0, [x19, #8]
	return dev->driver_data;
}

static inline void dev_set_drvdata(struct device *dev, void *data)
{
	dev->driver_data = data;
    387c:	f90046f3 	str	x19, [x23, #136]
    3880:	91008000 	add	x0, x0, #0x20
    3884:	b9400000 	ldr	w0, [x0]
	if (reg & CR0_SMMUEN) {
    3888:	37003f40 	tbnz	w0, #0, 4070 <arm_smmu_device_probe+0x1098>
	ret = arm_smmu_device_disable(smmu);
    388c:	aa1303e0 	mov	x0, x19
    3890:	97fff57e 	bl	e88 <arm_smmu_device_disable>
    3894:	2a0003f4 	mov	w20, w0
	if (ret)
    3898:	34000280 	cbz	w0, 38e8 <arm_smmu_device_probe+0x910>
    389c:	f9400bb3 	ldr	x19, [x29, #16]
    38a0:	a943e7b8 	ldp	x24, x25, [x29, #56]
    38a4:	a944efba 	ldp	x26, x27, [x29, #72]
    38a8:	f9402fbc 	ldr	x28, [x29, #88]
    38ac:	17fffefa 	b	3494 <arm_smmu_device_probe+0x4bc>
	return arm_smmu_init_one_queue(smmu, &smmu->priq.q, ARM_SMMU_PRIQ_PROD,
    38b0:	d2801983 	mov	x3, #0xcc                  	// #204
    38b4:	d2801902 	mov	x2, #0xc8                  	// #200
    38b8:	90000005 	adrp	x5, 0 <queue_remove_raw>
    38bc:	d2800044 	mov	x4, #0x2                   	// #2
    38c0:	910000a5 	add	x5, x5, #0x0
    38c4:	f2a00023 	movk	x3, #0x1, lsl #16
    38c8:	f2a00022 	movk	x2, #0x1, lsl #16
    38cc:	91090261 	add	x1, x19, #0x240
    38d0:	aa1303e0 	mov	x0, x19
    38d4:	97fff469 	bl	a78 <arm_smmu_init_one_queue>
    38d8:	2a0003f4 	mov	w20, w0
	if (ret)
    38dc:	35fffe00 	cbnz	w0, 389c <arm_smmu_device_probe+0x8c4>
    38e0:	b9401a61 	ldr	w1, [x19, #24]
    38e4:	17ffff7b 	b	36d0 <arm_smmu_device_probe+0x6f8>
	writel_relaxed(reg, smmu->base + ARM_SMMU_CR1);
    38e8:	f9400660 	ldr	x0, [x19, #8]
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    38ec:	5281aea1 	mov	w1, #0xd75                 	// #3445
    38f0:	9100a002 	add	x2, x0, #0x28
    38f4:	b9000041 	str	w1, [x2]
    38f8:	528000e1 	mov	w1, #0x7                   	// #7
	writel_relaxed(reg, smmu->base + ARM_SMMU_CR2);
    38fc:	9100b002 	add	x2, x0, #0x2c
    3900:	b9000041 	str	w1, [x2]
	writeq_relaxed(smmu->strtab_cfg.strtab_base,
    3904:	91020002 	add	x2, x0, #0x80
	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
    3908:	f951aa61 	ldr	x1, [x19, #9040]
    390c:	f9000041 	str	x1, [x2]
	writel_relaxed(smmu->strtab_cfg.strtab_base_cfg,
    3910:	91022002 	add	x2, x0, #0x88
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    3914:	b9635a61 	ldr	w1, [x19, #9048]
    3918:	b9000041 	str	w1, [x2]
	writeq_relaxed(smmu->cmdq.q.q_base, smmu->base + ARM_SMMU_CMDQ_BASE);
    391c:	91024002 	add	x2, x0, #0x90
	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
    3920:	f9406e61 	ldr	x1, [x19, #216]
    3924:	f9000041 	str	x1, [x2]
	writel_relaxed(smmu->cmdq.q.llq.prod, smmu->base + ARM_SMMU_CMDQ_PROD);
    3928:	91026002 	add	x2, x0, #0x98
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    392c:	b9404261 	ldr	w1, [x19, #64]
    3930:	b9000041 	str	w1, [x2]
	writel_relaxed(smmu->cmdq.q.llq.cons, smmu->base + ARM_SMMU_CMDQ_CONS);
    3934:	91027000 	add	x0, x0, #0x9c
    3938:	b9404661 	ldr	w1, [x19, #68]
    393c:	b9000001 	str	w1, [x0]
    3940:	9100227a 	add	x26, x19, #0x8
	ret = arm_smmu_write_reg_sync(smmu, enables, ARM_SMMU_CR0,
    3944:	52800483 	mov	w3, #0x24                  	// #36
    3948:	52800402 	mov	w2, #0x20                  	// #32
    394c:	52800101 	mov	w1, #0x8                   	// #8
    3950:	aa1a03e0 	mov	x0, x26
    3954:	97fff525 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
    3958:	2a0003f4 	mov	w20, w0
	if (ret) {
    395c:	35003140 	cbnz	w0, 3f84 <arm_smmu_device_probe+0xfac>
	cmd.opcode = CMDQ_OP_CFGI_ALL;
    3960:	52800082 	mov	w2, #0x4                   	// #4
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    3964:	9101a3a1 	add	x1, x29, #0x68
	cmd.opcode = CMDQ_OP_CFGI_ALL;
    3968:	3901a3a2 	strb	w2, [x29, #104]
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    396c:	aa1303e0 	mov	x0, x19
    3970:	97fff95a 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
	return arm_smmu_cmdq_issue_cmdlist(smmu, NULL, 0, true);
    3974:	52800023 	mov	w3, #0x1                   	// #1
    3978:	52800002 	mov	w2, #0x0                   	// #0
    397c:	d2800001 	mov	x1, #0x0                   	// #0
    3980:	aa1303e0 	mov	x0, x19
    3984:	97fff779 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
	if (smmu->features & ARM_SMMU_FEAT_HYP) {
    3988:	b9401a60 	ldr	w0, [x19, #24]
    398c:	37601da0 	tbnz	w0, #12, 3d40 <arm_smmu_device_probe+0xd68>
	cmd.opcode = CMDQ_OP_TLBI_NSNH_ALL;
    3990:	52800602 	mov	w2, #0x30                  	// #48
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    3994:	9101a3a1 	add	x1, x29, #0x68
	cmd.opcode = CMDQ_OP_TLBI_NSNH_ALL;
    3998:	3901a3a2 	strb	w2, [x29, #104]
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    399c:	aa1303e0 	mov	x0, x19
    39a0:	97fff94e 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
	return arm_smmu_cmdq_issue_cmdlist(smmu, NULL, 0, true);
    39a4:	52800023 	mov	w3, #0x1                   	// #1
    39a8:	52800002 	mov	w2, #0x0                   	// #0
    39ac:	d2800001 	mov	x1, #0x0                   	// #0
    39b0:	aa1303e0 	mov	x0, x19
    39b4:	97fff76d 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
	writeq_relaxed(smmu->evtq.q.q_base, smmu->base + ARM_SMMU_EVTQ_BASE);
    39b8:	f9400660 	ldr	x0, [x19, #8]
	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
    39bc:	f940ee61 	ldr	x1, [x19, #472]
    39c0:	91028000 	add	x0, x0, #0xa0
    39c4:	f9000001 	str	x1, [x0]
		return smmu->page1 + offset - SZ_64K;
    39c8:	f9400a60 	ldr	x0, [x19, #16]
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    39cc:	b9414261 	ldr	w1, [x19, #320]
    39d0:	9102a002 	add	x2, x0, #0xa8
    39d4:	b9000041 	str	w1, [x2]
    39d8:	9102b000 	add	x0, x0, #0xac
    39dc:	b9414661 	ldr	w1, [x19, #324]
    39e0:	b9000001 	str	w1, [x0]
	ret = arm_smmu_write_reg_sync(smmu, enables, ARM_SMMU_CR0,
    39e4:	52800483 	mov	w3, #0x24                  	// #36
    39e8:	52800402 	mov	w2, #0x20                  	// #32
    39ec:	52800181 	mov	w1, #0xc                   	// #12
    39f0:	aa1a03e0 	mov	x0, x26
    39f4:	97fff4fd 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
    39f8:	2a0003f4 	mov	w20, w0
	if (ret) {
    39fc:	35002e20 	cbnz	w0, 3fc0 <arm_smmu_device_probe+0xfe8>
	if (smmu->features & ARM_SMMU_FEAT_PRI) {
    3a00:	b9401a60 	ldr	w0, [x19, #24]
	enables |= CR0_EVTQEN;
    3a04:	52800197 	mov	w23, #0xc                   	// #12
	if (smmu->features & ARM_SMMU_FEAT_PRI) {
    3a08:	37200aa0 	tbnz	w0, #4, 3b5c <arm_smmu_device_probe+0xb84>
	if (smmu->features & ARM_SMMU_FEAT_ATS) {
    3a0c:	36280120 	tbz	w0, #5, 3a30 <arm_smmu_device_probe+0xa58>
		enables |= CR0_ATSCHK;
    3a10:	321c02f7 	orr	w23, w23, #0x10
		ret = arm_smmu_write_reg_sync(smmu, enables, ARM_SMMU_CR0,
    3a14:	52800483 	mov	w3, #0x24                  	// #36
    3a18:	52800402 	mov	w2, #0x20                  	// #32
    3a1c:	2a1703e1 	mov	w1, w23
    3a20:	aa1a03e0 	mov	x0, x26
    3a24:	97fff4f1 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
    3a28:	2a0003f4 	mov	w20, w0
		if (ret) {
    3a2c:	350029c0 	cbnz	w0, 3f64 <arm_smmu_device_probe+0xf8c>
	ret = arm_smmu_write_reg_sync(smmu, 0, ARM_SMMU_IRQ_CTRL,
    3a30:	52800a83 	mov	w3, #0x54                  	// #84
    3a34:	52800a02 	mov	w2, #0x50                  	// #80
    3a38:	52800001 	mov	w1, #0x0                   	// #0
    3a3c:	aa1a03e0 	mov	x0, x26
    3a40:	97fff4ea 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
    3a44:	2a0003f4 	mov	w20, w0
	if (ret) {
    3a48:	350027e0 	cbnz	w0, 3f44 <arm_smmu_device_probe+0xf6c>
	irq = smmu->combined_irq;
    3a4c:	b9430661 	ldr	w1, [x19, #772]
    3a50:	f9400274 	ldr	x20, [x19]
	if (irq) {
    3a54:	34000c21 	cbz	w1, 3bd8 <arm_smmu_device_probe+0xc00>
		ret = devm_request_threaded_irq(smmu->dev, irq,
    3a58:	90000005 	adrp	x5, 0 <queue_remove_raw>
    3a5c:	90000003 	adrp	x3, 0 <queue_remove_raw>
    3a60:	90000002 	adrp	x2, 0 <queue_remove_raw>
    3a64:	aa1303e6 	mov	x6, x19
    3a68:	910000a5 	add	x5, x5, #0x0
    3a6c:	d2840004 	mov	x4, #0x2000                	// #8192
    3a70:	91000063 	add	x3, x3, #0x0
    3a74:	91000042 	add	x2, x2, #0x0
    3a78:	aa1403e0 	mov	x0, x20
    3a7c:	94000000 	bl	0 <devm_request_threaded_irq>
		if (ret < 0)
    3a80:	37f82580 	tbnz	w0, #31, 3f30 <arm_smmu_device_probe+0xf58>
	if (smmu->features & ARM_SMMU_FEAT_PRI)
    3a84:	b9401a60 	ldr	w0, [x19, #24]
		irqen_flags |= IRQ_CTRL_PRIQ_IRQEN;
    3a88:	528000e1 	mov	w1, #0x7                   	// #7
	if (smmu->features & ARM_SMMU_FEAT_PRI)
    3a8c:	36200a20 	tbz	w0, #4, 3bd0 <arm_smmu_device_probe+0xbf8>
	ret = arm_smmu_write_reg_sync(smmu, irqen_flags,
    3a90:	52800a83 	mov	w3, #0x54                  	// #84
    3a94:	52800a02 	mov	w2, #0x50                  	// #80
    3a98:	aa1a03e0 	mov	x0, x26
    3a9c:	97fff4d3 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
	if (ret)
    3aa0:	35002860 	cbnz	w0, 3fac <arm_smmu_device_probe+0xfd4>
 * of previous kernel.
 */

static inline bool is_kdump_kernel(void)
{
	return elfcorehdr_addr != ELFCORE_ADDR_MAX;
    3aa4:	90000001 	adrp	x1, 0 <elfcorehdr_addr>
		enables &= ~(CR0_EVTQEN | CR0_PRIQEN);
    3aa8:	121d76e0 	and	w0, w23, #0xfffffff9
	if (is_kdump_kernel())
    3aac:	f9400021 	ldr	x1, [x1]
		enables &= ~(CR0_EVTQEN | CR0_PRIQEN);
    3ab0:	b100043f 	cmn	x1, #0x1
    3ab4:	1a971017 	csel	w23, w0, w23, ne  // ne = any
	if (!bypass || disable_bypass) {
    3ab8:	34000098 	cbz	w24, 3ac8 <arm_smmu_device_probe+0xaf0>
    3abc:	91000320 	add	x0, x25, #0x0
    3ac0:	3945c000 	ldrb	w0, [x0, #368]
    3ac4:	34000760 	cbz	w0, 3bb0 <arm_smmu_device_probe+0xbd8>
		enables |= CR0_SMMUEN;
    3ac8:	320002f7 	orr	w23, w23, #0x1
	ret = arm_smmu_write_reg_sync(smmu, enables, ARM_SMMU_CR0,
    3acc:	52800483 	mov	w3, #0x24                  	// #36
    3ad0:	52800402 	mov	w2, #0x20                  	// #32
    3ad4:	2a1703e1 	mov	w1, w23
    3ad8:	aa1a03e0 	mov	x0, x26
    3adc:	97fff4c3 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
    3ae0:	2a0003f4 	mov	w20, w0
	if (ret) {
    3ae4:	35002ac0 	cbnz	w0, 403c <arm_smmu_device_probe+0x1064>
	ret = iommu_device_sysfs_add(&smmu->iommu, dev, NULL,
    3ae8:	d2846c00 	mov	x0, #0x2360                	// #9056
    3aec:	8b000277 	add	x23, x19, x0
    3af0:	90000003 	adrp	x3, 0 <queue_remove_raw>
    3af4:	910183a4 	add	x4, x29, #0x60
    3af8:	91000063 	add	x3, x3, #0x0
    3afc:	d2800002 	mov	x2, #0x0                   	// #0
    3b00:	aa1503e1 	mov	x1, x21
    3b04:	aa1703e0 	mov	x0, x23
    3b08:	94000000 	bl	0 <iommu_device_sysfs_add>
    3b0c:	2a0003f4 	mov	w20, w0
	if (ret)
    3b10:	35ffec60 	cbnz	w0, 389c <arm_smmu_device_probe+0x8c4>
	iommu_device_set_ops(&smmu->iommu, &arm_smmu_ops);
    3b14:	91000338 	add	x24, x25, #0x0
	iommu->fwnode = fwnode;
    3b18:	f94152a0 	ldr	x0, [x21, #672]
    3b1c:	9105e318 	add	x24, x24, #0x178
	iommu->ops = ops;
    3b20:	f911ba78 	str	x24, [x19, #9072]
	iommu->fwnode = fwnode;
    3b24:	f911be60 	str	x0, [x19, #9080]
	ret = iommu_device_register(&smmu->iommu);
    3b28:	aa1703e0 	mov	x0, x23
	iommu_device_set_ops(&smmu->iommu, &arm_smmu_ops);
    3b2c:	f900a31f 	str	xzr, [x24, #320]
	ret = iommu_device_register(&smmu->iommu);
    3b30:	94000000 	bl	0 <iommu_device_register>
    3b34:	2a0003f4 	mov	w20, w0
	if (ret) {
    3b38:	350027a0 	cbnz	w0, 402c <arm_smmu_device_probe+0x1054>
	return arm_smmu_set_bus_ops(&arm_smmu_ops);
    3b3c:	aa1803e0 	mov	x0, x24
    3b40:	97fff1dc 	bl	2b0 <arm_smmu_set_bus_ops>
    3b44:	f9400bb3 	ldr	x19, [x29, #16]
    3b48:	2a0003f4 	mov	w20, w0
    3b4c:	a943e7b8 	ldp	x24, x25, [x29, #56]
    3b50:	a944efba 	ldp	x26, x27, [x29, #72]
    3b54:	f9402fbc 	ldr	x28, [x29, #88]
    3b58:	17fffe4f 	b	3494 <arm_smmu_device_probe+0x4bc>
		writeq_relaxed(smmu->priq.q.q_base,
    3b5c:	f9400660 	ldr	x0, [x19, #8]
	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
    3b60:	f9416e61 	ldr	x1, [x19, #728]
    3b64:	91030000 	add	x0, x0, #0xc0
    3b68:	f9000001 	str	x1, [x0]
		return smmu->page1 + offset - SZ_64K;
    3b6c:	f9400a60 	ldr	x0, [x19, #16]
	asm volatile("str %w0, [%1]" : : "rZ" (val), "r" (addr));
    3b70:	b9424261 	ldr	w1, [x19, #576]
    3b74:	91032002 	add	x2, x0, #0xc8
    3b78:	b9000041 	str	w1, [x2]
    3b7c:	91033000 	add	x0, x0, #0xcc
    3b80:	b9424661 	ldr	w1, [x19, #580]
    3b84:	b9000001 	str	w1, [x0]
		ret = arm_smmu_write_reg_sync(smmu, enables, ARM_SMMU_CR0,
    3b88:	52800483 	mov	w3, #0x24                  	// #36
    3b8c:	52800402 	mov	w2, #0x20                  	// #32
    3b90:	528001c1 	mov	w1, #0xe                   	// #14
    3b94:	aa1a03e0 	mov	x0, x26
    3b98:	97fff494 	bl	de8 <arm_smmu_write_reg_sync.isra.32>
    3b9c:	2a0003f4 	mov	w20, w0
		if (ret) {
    3ba0:	35001ea0 	cbnz	w0, 3f74 <arm_smmu_device_probe+0xf9c>
		enables |= CR0_PRIQEN;
    3ba4:	528001d7 	mov	w23, #0xe                   	// #14
    3ba8:	b9401a60 	ldr	w0, [x19, #24]
    3bac:	17ffff98 	b	3a0c <arm_smmu_device_probe+0xa34>
		ret = arm_smmu_update_gbpa(smmu, 0, GBPA_ABORT);
    3bb0:	f9400661 	ldr	x1, [x19, #8]
    3bb4:	52a00203 	mov	w3, #0x100000              	// #1048576
    3bb8:	52800002 	mov	w2, #0x0                   	// #0
    3bbc:	aa1303e0 	mov	x0, x19
    3bc0:	97fff5b2 	bl	1288 <arm_smmu_update_gbpa.isra.34>
    3bc4:	2a0003f4 	mov	w20, w0
		if (ret)
    3bc8:	34fff820 	cbz	w0, 3acc <arm_smmu_device_probe+0xaf4>
    3bcc:	17ffff34 	b	389c <arm_smmu_device_probe+0x8c4>
	u32 irqen_flags = IRQ_CTRL_EVTQ_IRQEN | IRQ_CTRL_GERROR_IRQEN;
    3bd0:	528000a1 	mov	w1, #0x5                   	// #5
    3bd4:	17ffffaf 	b	3a90 <arm_smmu_device_probe+0xab8>
	writeq_relaxed(0, smmu->base + ARM_SMMU_GERROR_IRQ_CFG0);
    3bd8:	f9400660 	ldr	x0, [x19, #8]
    3bdc:	9101a001 	add	x1, x0, #0x68
	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
    3be0:	f900003f 	str	xzr, [x1]
	writeq_relaxed(0, smmu->base + ARM_SMMU_EVTQ_IRQ_CFG0);
    3be4:	9102c001 	add	x1, x0, #0xb0
    3be8:	f900003f 	str	xzr, [x1]
	if (smmu->features & ARM_SMMU_FEAT_PRI)
    3bec:	b9401a62 	ldr	w2, [x19, #24]
		nvec--;
    3bf0:	52800041 	mov	w1, #0x2                   	// #2
	if (smmu->features & ARM_SMMU_FEAT_PRI)
    3bf4:	36200082 	tbz	w2, #4, 3c04 <arm_smmu_device_probe+0xc2c>
		writeq_relaxed(0, smmu->base + ARM_SMMU_PRIQ_IRQ_CFG0);
    3bf8:	91034000 	add	x0, x0, #0xd0
    3bfc:	f900001f 	str	xzr, [x0]
	int ret, nvec = ARM_SMMU_MAX_MSIS;
    3c00:	52800061 	mov	w1, #0x3                   	// #3
	if (!(smmu->features & ARM_SMMU_FEAT_MSI))
    3c04:	36380422 	tbz	w2, #7, 3c88 <arm_smmu_device_probe+0xcb0>
	if (!dev->msi_domain) {
    3c08:	f9411280 	ldr	x0, [x20, #544]
    3c0c:	b4000320 	cbz	x0, 3c70 <arm_smmu_device_probe+0xc98>
	ret = platform_msi_domain_alloc_irqs(dev, nvec, arm_smmu_write_msi_msg);
    3c10:	90000002 	adrp	x2, 0 <queue_remove_raw>
    3c14:	aa1403e0 	mov	x0, x20
    3c18:	91000042 	add	x2, x2, #0x0
    3c1c:	94000000 	bl	0 <platform_msi_domain_alloc_irqs>
	if (ret) {
    3c20:	35001ba0 	cbnz	w0, 3f94 <arm_smmu_device_probe+0xfbc>
	for_each_msi_entry(desc, dev) {
    3c24:	f9411a80 	ldr	x0, [x20, #560]
    3c28:	9108c282 	add	x2, x20, #0x230
    3c2c:	eb00005f 	cmp	x2, x0
    3c30:	54000141 	b.ne	3c58 <arm_smmu_device_probe+0xc80>  // b.any
    3c34:	14000049 	b	3d58 <arm_smmu_device_probe+0xd80>
		switch (desc->platform.msi_index) {
    3c38:	340007e1 	cbz	w1, 3d34 <arm_smmu_device_probe+0xd5c>
    3c3c:	7100083f 	cmp	w1, #0x2
    3c40:	54000061 	b.ne	3c4c <arm_smmu_device_probe+0xc74>  // b.any
			smmu->priq.q.irq = desc->irq;
    3c44:	b9401001 	ldr	w1, [x0, #16]
    3c48:	b902c261 	str	w1, [x19, #704]
	for_each_msi_entry(desc, dev) {
    3c4c:	f9400000 	ldr	x0, [x0]
    3c50:	eb02001f 	cmp	x0, x2
    3c54:	54000820 	b.eq	3d58 <arm_smmu_device_probe+0xd80>  // b.none
		switch (desc->platform.msi_index) {
    3c58:	7940b001 	ldrh	w1, [x0, #88]
    3c5c:	7100043f 	cmp	w1, #0x1
    3c60:	54fffec1 	b.ne	3c38 <arm_smmu_device_probe+0xc60>  // b.any
			smmu->gerr_irq = desc->irq;
    3c64:	b9401001 	ldr	w1, [x0, #16]
    3c68:	b9030261 	str	w1, [x19, #768]
    3c6c:	17fffff8 	b	3c4c <arm_smmu_device_probe+0xc74>
		dev_info(smmu->dev, "msi_domain absent - falling back to wired irqs\n");
    3c70:	aa1403e0 	mov	x0, x20
    3c74:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3c78:	91000021 	add	x1, x1, #0x0
    3c7c:	94000000 	bl	0 <_dev_info>
    3c80:	f9400274 	ldr	x20, [x19]
    3c84:	d503201f 	nop
	irq = smmu->evtq.q.irq;
    3c88:	b941c261 	ldr	w1, [x19, #448]
	if (irq) {
    3c8c:	34001be1 	cbz	w1, 4008 <arm_smmu_device_probe+0x1030>
		ret = devm_request_threaded_irq(smmu->dev, irq, NULL,
    3c90:	90000005 	adrp	x5, 0 <queue_remove_raw>
    3c94:	90000003 	adrp	x3, 0 <queue_remove_raw>
    3c98:	aa1303e6 	mov	x6, x19
    3c9c:	910000a5 	add	x5, x5, #0x0
    3ca0:	d2840004 	mov	x4, #0x2000                	// #8192
    3ca4:	91000063 	add	x3, x3, #0x0
    3ca8:	d2800002 	mov	x2, #0x0                   	// #0
    3cac:	aa1403e0 	mov	x0, x20
    3cb0:	94000000 	bl	0 <devm_request_threaded_irq>
		if (ret < 0)
    3cb4:	37f81a00 	tbnz	w0, #31, 3ff4 <arm_smmu_device_probe+0x101c>
	irq = smmu->gerr_irq;
    3cb8:	b9430261 	ldr	w1, [x19, #768]
    3cbc:	f9400260 	ldr	x0, [x19]
	if (irq) {
    3cc0:	34001921 	cbz	w1, 3fe4 <arm_smmu_device_probe+0x100c>

static inline int __must_check
devm_request_irq(struct device *dev, unsigned int irq, irq_handler_t handler,
		 unsigned long irqflags, const char *devname, void *dev_id)
{
	return devm_request_threaded_irq(dev, irq, handler, NULL, irqflags,
    3cc4:	90000005 	adrp	x5, 0 <queue_remove_raw>
    3cc8:	90000002 	adrp	x2, 0 <queue_remove_raw>
    3ccc:	aa1303e6 	mov	x6, x19
    3cd0:	910000a5 	add	x5, x5, #0x0
    3cd4:	d2800004 	mov	x4, #0x0                   	// #0
    3cd8:	d2800003 	mov	x3, #0x0                   	// #0
    3cdc:	91000042 	add	x2, x2, #0x0
    3ce0:	94000000 	bl	0 <devm_request_threaded_irq>
		if (ret < 0)
    3ce4:	37f81760 	tbnz	w0, #31, 3fd0 <arm_smmu_device_probe+0xff8>
	if (smmu->features & ARM_SMMU_FEAT_PRI) {
    3ce8:	b9401a60 	ldr	w0, [x19, #24]
    3cec:	3627f720 	tbz	w0, #4, 3bd0 <arm_smmu_device_probe+0xbf8>
		irq = smmu->priq.q.irq;
    3cf0:	b942c261 	ldr	w1, [x19, #704]
    3cf4:	f9400260 	ldr	x0, [x19]
		if (irq) {
    3cf8:	34001921 	cbz	w1, 401c <arm_smmu_device_probe+0x1044>
			ret = devm_request_threaded_irq(smmu->dev, irq, NULL,
    3cfc:	90000005 	adrp	x5, 0 <queue_remove_raw>
    3d00:	90000003 	adrp	x3, 0 <queue_remove_raw>
    3d04:	aa1303e6 	mov	x6, x19
    3d08:	910000a5 	add	x5, x5, #0x0
    3d0c:	d2840004 	mov	x4, #0x2000                	// #8192
    3d10:	91000063 	add	x3, x3, #0x0
    3d14:	d2800002 	mov	x2, #0x0                   	// #0
    3d18:	94000000 	bl	0 <devm_request_threaded_irq>
			if (ret < 0)
    3d1c:	36ffeb40 	tbz	w0, #31, 3a84 <arm_smmu_device_probe+0xaac>
				dev_warn(smmu->dev,
    3d20:	f9400260 	ldr	x0, [x19]
    3d24:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3d28:	91000021 	add	x1, x1, #0x0
    3d2c:	94000000 	bl	0 <_dev_warn>
    3d30:	17ffff55 	b	3a84 <arm_smmu_device_probe+0xaac>
			smmu->evtq.q.irq = desc->irq;
    3d34:	b9401001 	ldr	w1, [x0, #16]
    3d38:	b901c261 	str	w1, [x19, #448]
    3d3c:	17ffffc4 	b	3c4c <arm_smmu_device_probe+0xc74>
		cmd.opcode = CMDQ_OP_TLBI_EL2_ALL;
    3d40:	52800400 	mov	w0, #0x20                  	// #32
		arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    3d44:	9101a3a1 	add	x1, x29, #0x68
		cmd.opcode = CMDQ_OP_TLBI_EL2_ALL;
    3d48:	3901a3a0 	strb	w0, [x29, #104]
		arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    3d4c:	aa1303e0 	mov	x0, x19
    3d50:	97fff862 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
    3d54:	17ffff0f 	b	3990 <arm_smmu_device_probe+0x9b8>
	devm_add_action(dev, arm_smmu_free_msis, dev);
    3d58:	aa1403e2 	mov	x2, x20
    3d5c:	aa1403e0 	mov	x0, x20
    3d60:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3d64:	91000021 	add	x1, x1, #0x0
    3d68:	94000000 	bl	0 <devm_add_action>
    3d6c:	f9400274 	ldr	x20, [x19]
    3d70:	17ffffc6 	b	3c88 <arm_smmu_device_probe+0xcb0>
		dev_err(smmu->dev, "command queue size <= %d entries not supported\n",
    3d74:	aa1a03e0 	mov	x0, x26
    3d78:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3d7c:	52800802 	mov	w2, #0x40                  	// #64
    3d80:	91000021 	add	x1, x1, #0x0
		return -ENXIO;
    3d84:	128000b4 	mov	w20, #0xfffffffa            	// #-6
		dev_err(smmu->dev, "command queue size <= %d entries not supported\n",
    3d88:	94000000 	bl	0 <_dev_err>
    3d8c:	f9400bb3 	ldr	x19, [x29, #16]
    3d90:	a943e7b8 	ldp	x24, x25, [x29, #56]
    3d94:	f94027ba 	ldr	x26, [x29, #72]
    3d98:	17fffdbf 	b	3494 <arm_smmu_device_probe+0x4bc>
		dev_err(smmu->dev, "unknown/unsupported TT endianness!\n");
    3d9c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3da0:	aa1a03e0 	mov	x0, x26
    3da4:	91000021 	add	x1, x1, #0x0
		return -ENXIO;
    3da8:	128000b4 	mov	w20, #0xfffffffa            	// #-6
		dev_err(smmu->dev, "no translation support!\n");
    3dac:	94000000 	bl	0 <_dev_err>
    3db0:	17fffdb6 	b	3488 <arm_smmu_device_probe+0x4b0>
    3db4:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3db8:	aa1a03e0 	mov	x0, x26
    3dbc:	91000021 	add	x1, x1, #0x0
    3dc0:	17fffffa 	b	3da8 <arm_smmu_device_probe+0xdd0>
		dev_err(smmu->dev, "AArch64 table format not supported!\n");
    3dc4:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3dc8:	aa1a03e0 	mov	x0, x26
    3dcc:	91000021 	add	x1, x1, #0x0
    3dd0:	17fffff6 	b	3da8 <arm_smmu_device_probe+0xdd0>
		dev_err(dev, "failed to allocate arm_smmu_device\n");
    3dd4:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3dd8:	aa1503e0 	mov	x0, x21
    3ddc:	91000021 	add	x1, x1, #0x0
		return -ENOMEM;
    3de0:	12800174 	mov	w20, #0xfffffff4            	// #-12
		dev_err(dev, "failed to allocate arm_smmu_device\n");
    3de4:	94000000 	bl	0 <_dev_err>
		return -ENOMEM;
    3de8:	17fffdab 	b	3494 <arm_smmu_device_probe+0x4bc>
		dev_err(dev, "MMIO region too small (%pr)\n", res);
    3dec:	aa0003e2 	mov	x2, x0
    3df0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3df4:	aa1503e0 	mov	x0, x21
    3df8:	91000021 	add	x1, x1, #0x0
		return -EINVAL;
    3dfc:	128002b4 	mov	w20, #0xffffffea            	// #-22
		dev_err(dev, "MMIO region too small (%pr)\n", res);
    3e00:	94000000 	bl	0 <_dev_err>
		return -EINVAL;
    3e04:	f9400bb3 	ldr	x19, [x29, #16]
    3e08:	f9401fb8 	ldr	x24, [x29, #56]
    3e0c:	17fffda2 	b	3494 <arm_smmu_device_probe+0x4bc>
		dev_warn(smmu->dev, "IDR0.COHACC overridden by FW configuration (%s)\n",
    3e10:	7100007f 	cmp	w3, #0x0
    3e14:	90000003 	adrp	x3, 0 <queue_remove_raw>
    3e18:	91000063 	add	x3, x3, #0x0
    3e1c:	90000002 	adrp	x2, 0 <queue_remove_raw>
    3e20:	91000042 	add	x2, x2, #0x0
    3e24:	aa1a03e0 	mov	x0, x26
    3e28:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3e2c:	9a820062 	csel	x2, x3, x2, eq  // eq = none
    3e30:	91000021 	add	x1, x1, #0x0
    3e34:	94000000 	bl	0 <_dev_warn>
    3e38:	f940027a 	ldr	x26, [x19]
    3e3c:	17fffceb 	b	31e8 <arm_smmu_device_probe+0x210>
		dev_err(smmu->dev, "embedded implementation not supported\n");
    3e40:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3e44:	aa1a03e0 	mov	x0, x26
    3e48:	91000021 	add	x1, x1, #0x0
    3e4c:	17ffffd7 	b	3da8 <arm_smmu_device_probe+0xdd0>
    3e50:	f9000bb3 	str	x19, [x29, #16]
    3e54:	a903e7b8 	stp	x24, x25, [x29, #56]
    3e58:	a904efba 	stp	x26, x27, [x29, #72]
    3e5c:	f9002fbc 	str	x28, [x29, #88]
}
    3e60:	94000000 	bl	0 <__stack_chk_fail>
	int ret = -EINVAL;
    3e64:	128002b8 	mov	w24, #0xffffffea            	// #-22
		dev_err(dev, "invalid #iommu-cells value (%d)\n", cells);
    3e68:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3e6c:	aa1503e0 	mov	x0, x21
    3e70:	91000021 	add	x1, x1, #0x0
    3e74:	94000000 	bl	0 <_dev_err>
    3e78:	17fffc7a 	b	3060 <arm_smmu_device_probe+0x88>
		dev_err(dev, "missing #iommu-cells property\n");
    3e7c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3e80:	aa1503e0 	mov	x0, x21
    3e84:	91000021 	add	x1, x1, #0x0
	int ret = -EINVAL;
    3e88:	128002b8 	mov	w24, #0xffffffea            	// #-22
		dev_err(dev, "missing #iommu-cells property\n");
    3e8c:	94000000 	bl	0 <_dev_err>
    3e90:	17fffc74 	b	3060 <arm_smmu_device_probe+0x88>
			smmu->options |= arm_smmu_options[i].opt;
    3e94:	b9401e63 	ldr	w3, [x19, #28]
			dev_notice(smmu->dev, "option %s\n",
    3e98:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3e9c:	f9400260 	ldr	x0, [x19]
    3ea0:	aa1403e2 	mov	x2, x20
			smmu->options |= arm_smmu_options[i].opt;
    3ea4:	321f0063 	orr	w3, w3, #0x2
    3ea8:	b9001e63 	str	w3, [x19, #28]
			dev_notice(smmu->dev, "option %s\n",
    3eac:	91000021 	add	x1, x1, #0x0
    3eb0:	94000000 	bl	0 <_dev_notice>
    3eb4:	17fffc7b 	b	30a0 <arm_smmu_device_probe+0xc8>
			smmu->options |= arm_smmu_options[i].opt;
    3eb8:	b9401e63 	ldr	w3, [x19, #28]
			dev_notice(smmu->dev, "option %s\n",
    3ebc:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3ec0:	f9400260 	ldr	x0, [x19]
    3ec4:	aa1403e2 	mov	x2, x20
			smmu->options |= arm_smmu_options[i].opt;
    3ec8:	32000063 	orr	w3, w3, #0x1
    3ecc:	b9001e63 	str	w3, [x19, #28]
			dev_notice(smmu->dev, "option %s\n",
    3ed0:	91000021 	add	x1, x1, #0x0
    3ed4:	94000000 	bl	0 <_dev_notice>
    3ed8:	17fffc6a 	b	3080 <arm_smmu_device_probe+0xa8>
		dev_err(smmu->dev, "failed to allocate l1 stream table desc\n");
    3edc:	f9400260 	ldr	x0, [x19]
    3ee0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3ee4:	91000021 	add	x1, x1, #0x0
		return -ENOMEM;
    3ee8:	12800174 	mov	w20, #0xfffffff4            	// #-12
		dev_err(dev, "Failed to register iommu\n");
    3eec:	94000000 	bl	0 <_dev_err>
		return ret;
    3ef0:	f9400bb3 	ldr	x19, [x29, #16]
    3ef4:	a943e7b8 	ldp	x24, x25, [x29, #56]
    3ef8:	a944efba 	ldp	x26, x27, [x29, #72]
    3efc:	f9402fbc 	ldr	x28, [x29, #88]
    3f00:	17fffd65 	b	3494 <arm_smmu_device_probe+0x4bc>
		dev_err(smmu->dev,
    3f04:	f9400260 	ldr	x0, [x19]
    3f08:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f0c:	2a1b03e2 	mov	w2, w27
    3f10:	91000021 	add	x1, x1, #0x0
    3f14:	94000000 	bl	0 <_dev_err>
		return -ENOMEM;
    3f18:	12800174 	mov	w20, #0xfffffff4            	// #-12
    3f1c:	f9400bb3 	ldr	x19, [x29, #16]
    3f20:	a943e7b8 	ldp	x24, x25, [x29, #56]
    3f24:	a944efba 	ldp	x26, x27, [x29, #72]
    3f28:	f9402fbc 	ldr	x28, [x29, #88]
    3f2c:	17fffd5a 	b	3494 <arm_smmu_device_probe+0x4bc>
			dev_warn(smmu->dev, "failed to enable combined irq\n");
    3f30:	f9400260 	ldr	x0, [x19]
    3f34:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f38:	91000021 	add	x1, x1, #0x0
    3f3c:	94000000 	bl	0 <_dev_warn>
    3f40:	17fffed1 	b	3a84 <arm_smmu_device_probe+0xaac>
		dev_err(smmu->dev, "failed to disable irqs\n");
    3f44:	f9400260 	ldr	x0, [x19]
    3f48:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f4c:	91000021 	add	x1, x1, #0x0
    3f50:	94000000 	bl	0 <_dev_err>
		dev_err(smmu->dev, "failed to setup irqs\n");
    3f54:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f58:	f9400260 	ldr	x0, [x19]
    3f5c:	91000021 	add	x1, x1, #0x0
    3f60:	17ffffe3 	b	3eec <arm_smmu_device_probe+0xf14>
			dev_err(smmu->dev, "failed to enable ATS check\n");
    3f64:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f68:	f9400260 	ldr	x0, [x19]
    3f6c:	91000021 	add	x1, x1, #0x0
    3f70:	17ffffdf 	b	3eec <arm_smmu_device_probe+0xf14>
			dev_err(smmu->dev, "failed to enable PRI queue\n");
    3f74:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f78:	f9400260 	ldr	x0, [x19]
    3f7c:	91000021 	add	x1, x1, #0x0
    3f80:	17ffffdb 	b	3eec <arm_smmu_device_probe+0xf14>
		dev_err(smmu->dev, "failed to enable command queue\n");
    3f84:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f88:	f9400260 	ldr	x0, [x19]
    3f8c:	91000021 	add	x1, x1, #0x0
    3f90:	17ffffd7 	b	3eec <arm_smmu_device_probe+0xf14>
		dev_warn(dev, "failed to allocate MSIs - falling back to wired irqs\n");
    3f94:	aa1403e0 	mov	x0, x20
    3f98:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3f9c:	91000021 	add	x1, x1, #0x0
    3fa0:	94000000 	bl	0 <_dev_warn>
    3fa4:	f9400274 	ldr	x20, [x19]
    3fa8:	17ffff38 	b	3c88 <arm_smmu_device_probe+0xcb0>
		dev_warn(smmu->dev, "failed to enable irqs\n");
    3fac:	f9400260 	ldr	x0, [x19]
    3fb0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3fb4:	91000021 	add	x1, x1, #0x0
    3fb8:	94000000 	bl	0 <_dev_warn>
    3fbc:	17fffeba 	b	3aa4 <arm_smmu_device_probe+0xacc>
		dev_err(smmu->dev, "failed to enable event queue\n");
    3fc0:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3fc4:	f9400260 	ldr	x0, [x19]
    3fc8:	91000021 	add	x1, x1, #0x0
    3fcc:	17ffffc8 	b	3eec <arm_smmu_device_probe+0xf14>
			dev_warn(smmu->dev, "failed to enable gerror irq\n");
    3fd0:	f9400260 	ldr	x0, [x19]
    3fd4:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3fd8:	91000021 	add	x1, x1, #0x0
    3fdc:	94000000 	bl	0 <_dev_warn>
    3fe0:	17ffff42 	b	3ce8 <arm_smmu_device_probe+0xd10>
		dev_warn(smmu->dev, "no gerr irq - errors will not be reported!\n");
    3fe4:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3fe8:	91000021 	add	x1, x1, #0x0
    3fec:	94000000 	bl	0 <_dev_warn>
    3ff0:	17ffff3e 	b	3ce8 <arm_smmu_device_probe+0xd10>
			dev_warn(smmu->dev, "failed to enable evtq irq\n");
    3ff4:	f9400260 	ldr	x0, [x19]
    3ff8:	90000001 	adrp	x1, 0 <queue_remove_raw>
    3ffc:	91000021 	add	x1, x1, #0x0
    4000:	94000000 	bl	0 <_dev_warn>
    4004:	17ffff2d 	b	3cb8 <arm_smmu_device_probe+0xce0>
		dev_warn(smmu->dev, "no evtq irq - events will not be reported!\n");
    4008:	90000001 	adrp	x1, 0 <queue_remove_raw>
    400c:	aa1403e0 	mov	x0, x20
    4010:	91000021 	add	x1, x1, #0x0
    4014:	94000000 	bl	0 <_dev_warn>
    4018:	17ffff28 	b	3cb8 <arm_smmu_device_probe+0xce0>
			dev_warn(smmu->dev, "no priq irq - PRI will be broken\n");
    401c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    4020:	91000021 	add	x1, x1, #0x0
    4024:	94000000 	bl	0 <_dev_warn>
    4028:	17fffe97 	b	3a84 <arm_smmu_device_probe+0xaac>
		dev_err(dev, "Failed to register iommu\n");
    402c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    4030:	aa1503e0 	mov	x0, x21
    4034:	91000021 	add	x1, x1, #0x0
    4038:	17ffffad 	b	3eec <arm_smmu_device_probe+0xf14>
		dev_err(smmu->dev, "failed to enable SMMU interface\n");
    403c:	90000001 	adrp	x1, 0 <queue_remove_raw>
    4040:	f9400260 	ldr	x0, [x19]
    4044:	91000021 	add	x1, x1, #0x0
    4048:	17ffffa9 	b	3eec <arm_smmu_device_probe+0xf14>
		dev_err(smmu->dev, "failed to allocate cmdq bitmap\n");
    404c:	f9400260 	ldr	x0, [x19]
    4050:	90000001 	adrp	x1, 0 <queue_remove_raw>
		ret = -ENOMEM;
    4054:	12800174 	mov	w20, #0xfffffff4            	// #-12
		dev_err(smmu->dev, "failed to allocate cmdq bitmap\n");
    4058:	91000021 	add	x1, x1, #0x0
    405c:	94000000 	bl	0 <_dev_err>
    4060:	f9400bb3 	ldr	x19, [x29, #16]
    4064:	a943e7b8 	ldp	x24, x25, [x29, #56]
    4068:	f94027ba 	ldr	x26, [x29, #72]
    406c:	17fffd0a 	b	3494 <arm_smmu_device_probe+0x4bc>
		dev_warn(smmu->dev, "SMMU currently enabled! Resetting...\n");
    4070:	f9400260 	ldr	x0, [x19]
    4074:	90000001 	adrp	x1, 0 <queue_remove_raw>
    4078:	91000021 	add	x1, x1, #0x0
    407c:	94000000 	bl	0 <_dev_warn>
    4080:	90000000 	adrp	x0, 0 <elfcorehdr_addr>
		WARN_ON(is_kdump_kernel() && !disable_bypass);
    4084:	f9400000 	ldr	x0, [x0]
    4088:	b100041f 	cmn	x0, #0x1
    408c:	540000a0 	b.eq	40a0 <arm_smmu_device_probe+0x10c8>  // b.none
    4090:	91000320 	add	x0, x25, #0x0
    4094:	3945c000 	ldrb	w0, [x0, #368]
    4098:	35000040 	cbnz	w0, 40a0 <arm_smmu_device_probe+0x10c8>
    409c:	d4210000 	brk	#0x800
		arm_smmu_update_gbpa(smmu, GBPA_ABORT, 0);
    40a0:	f9400661 	ldr	x1, [x19, #8]
    40a4:	52800003 	mov	w3, #0x0                   	// #0
    40a8:	52a00202 	mov	w2, #0x100000              	// #1048576
    40ac:	aa1303e0 	mov	x0, x19
    40b0:	97fff476 	bl	1288 <arm_smmu_update_gbpa.isra.34>
    40b4:	17fffdf6 	b	388c <arm_smmu_device_probe+0x8b4>
		dev_err(smmu->dev,
    40b8:	90000001 	adrp	x1, 0 <queue_remove_raw>
    40bc:	2a1c03e2 	mov	w2, w28
    40c0:	91000021 	add	x1, x1, #0x0
    40c4:	f9400260 	ldr	x0, [x19]
    40c8:	17ffff93 	b	3f14 <arm_smmu_device_probe+0xf3c>
		dev_warn(smmu->dev,
    40cc:	90000001 	adrp	x1, 0 <queue_remove_raw>
    40d0:	2a1c03e2 	mov	w2, w28
    40d4:	91000021 	add	x1, x1, #0x0
    40d8:	94000000 	bl	0 <_dev_warn>
    40dc:	b9401b41 	ldr	w1, [x26, #24]
    40e0:	f9400260 	ldr	x0, [x19]
    40e4:	17fffd8b 	b	3710 <arm_smmu_device_probe+0x738>

00000000000040e8 <arm_smmu_atc_inv_domain.constprop.49>:
static int arm_smmu_atc_inv_domain(struct arm_smmu_domain *smmu_domain,
    40e8:	d503233f 	paciasp
    40ec:	d11203ff 	sub	sp, sp, #0x480
    40f0:	a9007bfd 	stp	x29, x30, [sp]
    40f4:	910003fd 	mov	x29, sp
    40f8:	a90153f3 	stp	x19, x20, [sp, #16]
    40fc:	aa0103f3 	mov	x19, x1
    4100:	a9025bf5 	stp	x21, x22, [sp, #32]
    4104:	aa0003f5 	mov	x21, x0
    4108:	90000016 	adrp	x22, 0 <__stack_chk_guard>
    410c:	910002c0 	add	x0, x22, #0x0
    4110:	f9400001 	ldr	x1, [x0]
    4114:	f9023fa1 	str	x1, [x29, #1144]
    4118:	d2800001 	mov	x1, #0x0                   	// #0
    411c:	aa0203f4 	mov	x20, x2
	struct arm_smmu_cmdq_batch cmds = {};
    4120:	9101c3a0 	add	x0, x29, #0x70
    4124:	d2808102 	mov	x2, #0x408                 	// #1032
    4128:	94000000 	bl	0 <memset>
	if (!(smmu_domain->smmu->features & ARM_SMMU_FEAT_ATS))
    412c:	f94002a0 	ldr	x0, [x21]
    4130:	b9401800 	ldr	w0, [x0, #24]
    4134:	36280760 	tbz	w0, #5, 4220 <arm_smmu_atc_inv_domain.constprop.49+0x138>
	smp_mb();
    4138:	d5033bbf 	dmb	ish
	return arch_atomic_read(v);
    413c:	b94036a0 	ldr	w0, [x21, #52]
	if (!atomic_read(&smmu_domain->nr_ats_masters))
    4140:	34000700 	cbz	w0, 4220 <arm_smmu_atc_inv_domain.constprop.49+0x138>
	*cmd = (struct arm_smmu_cmdq_ent) {
    4144:	52800800 	mov	w0, #0x40                  	// #64
    4148:	390143a0 	strb	w0, [x29, #80]
    414c:	91014ba0 	add	x0, x29, #0x52
    4150:	a90363b7 	stp	x23, x24, [x29, #48]
    4154:	f90023b9 	str	x25, [x29, #64]
    4158:	390147bf 	strb	wzr, [x29, #81]
    415c:	a9007c1f 	stp	xzr, xzr, [x0]
    4160:	f80623bf 	stur	xzr, [x29, #98]
    4164:	b806a3bf 	stur	wzr, [x29, #106]
    4168:	7900dfbf 	strh	wzr, [x29, #110]
	if (!size) {
    416c:	b5000734 	cbnz	x20, 4250 <arm_smmu_atc_inv_domain.constprop.49+0x168>
		cmd->atc.size = ATC_INV_SIZE_ALL;
    4170:	52800680 	mov	w0, #0x34                  	// #52
    4174:	3901a3a0 	strb	w0, [x29, #104]
	list_for_each_entry(master, &smmu_domain->devices, domain_head) {
    4178:	aa1503f7 	mov	x23, x21
	return &lock->rlock;
    417c:	910382b8 	add	x24, x21, #0xe0
	spin_lock_irqsave(&smmu_domain->devices_lock, flags);
    4180:	aa1803e0 	mov	x0, x24
    4184:	94000000 	bl	0 <_raw_spin_lock_irqsave>
    4188:	aa0003f9 	mov	x25, x0
	list_for_each_entry(master, &smmu_domain->devices, domain_head) {
    418c:	f84d0ee0 	ldr	x0, [x23, #208]!
    4190:	d1006014 	sub	x20, x0, #0x18
    4194:	eb0002ff 	cmp	x23, x0
    4198:	540002e0 	b.eq	41f4 <arm_smmu_atc_inv_domain.constprop.49+0x10c>  // b.none
    419c:	d503201f 	nop
		if (!master->ats_enabled)
    41a0:	3940d280 	ldrb	w0, [x20, #52]
    41a4:	34000200 	cbz	w0, 41e4 <arm_smmu_atc_inv_domain.constprop.49+0xfc>
		for (i = 0; i < master->num_sids; i++) {
    41a8:	b9403280 	ldr	w0, [x20, #48]
    41ac:	340001c0 	cbz	w0, 41e4 <arm_smmu_atc_inv_domain.constprop.49+0xfc>
    41b0:	52800013 	mov	w19, #0x0                   	// #0
    41b4:	d503201f 	nop
			cmd.atc.sid = master->sids[i];
    41b8:	f9401683 	ldr	x3, [x20, #40]
			arm_smmu_cmdq_batch_add(smmu_domain->smmu, &cmds, &cmd);
    41bc:	910143a2 	add	x2, x29, #0x50
    41c0:	f94002a0 	ldr	x0, [x21]
    41c4:	9101c3a1 	add	x1, x29, #0x70
			cmd.atc.sid = master->sids[i];
    41c8:	b873d863 	ldr	w3, [x3, w19, sxtw #2]
		for (i = 0; i < master->num_sids; i++) {
    41cc:	11000673 	add	w19, w19, #0x1
			cmd.atc.sid = master->sids[i];
    41d0:	b9005ba3 	str	w3, [x29, #88]
			arm_smmu_cmdq_batch_add(smmu_domain->smmu, &cmds, &cmd);
    41d4:	97fffa3b 	bl	2ac0 <arm_smmu_cmdq_batch_add>
		for (i = 0; i < master->num_sids; i++) {
    41d8:	b9403280 	ldr	w0, [x20, #48]
    41dc:	6b13001f 	cmp	w0, w19
    41e0:	54fffec8 	b.hi	41b8 <arm_smmu_atc_inv_domain.constprop.49+0xd0>  // b.pmore
	list_for_each_entry(master, &smmu_domain->devices, domain_head) {
    41e4:	f9400e80 	ldr	x0, [x20, #24]
    41e8:	d1006014 	sub	x20, x0, #0x18
    41ec:	eb0002ff 	cmp	x23, x0
    41f0:	54fffd81 	b.ne	41a0 <arm_smmu_atc_inv_domain.constprop.49+0xb8>  // b.any
	raw_spin_unlock_irqrestore(&lock->rlock, flags);
    41f4:	aa1903e1 	mov	x1, x25
    41f8:	aa1803e0 	mov	x0, x24
    41fc:	94000000 	bl	0 <_raw_spin_unlock_irqrestore>
	return arm_smmu_cmdq_issue_cmdlist(smmu, cmds->cmds, cmds->num, true);
    4200:	b94473a2 	ldr	w2, [x29, #1136]
    4204:	52800023 	mov	w3, #0x1                   	// #1
    4208:	f94002a0 	ldr	x0, [x21]
    420c:	9101c3a1 	add	x1, x29, #0x70
    4210:	97fff556 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
    4214:	f94023b9 	ldr	x25, [x29, #64]
    4218:	a94363b7 	ldp	x23, x24, [x29, #48]
    421c:	14000002 	b	4224 <arm_smmu_atc_inv_domain.constprop.49+0x13c>
		return 0;
    4220:	52800000 	mov	w0, #0x0                   	// #0
}
    4224:	910002d6 	add	x22, x22, #0x0
    4228:	f9423fa2 	ldr	x2, [x29, #1144]
    422c:	f94002c1 	ldr	x1, [x22]
    4230:	ca010041 	eor	x1, x2, x1
    4234:	b5000361 	cbnz	x1, 42a0 <arm_smmu_atc_inv_domain.constprop.49+0x1b8>
    4238:	a9407bfd 	ldp	x29, x30, [sp]
    423c:	a94153f3 	ldp	x19, x20, [sp, #16]
    4240:	a9425bf5 	ldp	x21, x22, [sp, #32]
    4244:	911203ff 	add	sp, sp, #0x480
    4248:	d50323bf 	autiasp
    424c:	d65f03c0 	ret
	page_end	= (iova + size - 1) >> inval_grain_shift;
    4250:	d1000660 	sub	x0, x19, #0x1
	page_start	= iova >> inval_grain_shift;
    4254:	d34cfe73 	lsr	x19, x19, #12
	page_end	= (iova + size - 1) >> inval_grain_shift;
    4258:	8b140000 	add	x0, x0, x20
	return fls(x);
}
#elif BITS_PER_LONG == 64
static __always_inline int fls64(__u64 x)
{
	if (x == 0)
    425c:	52800001 	mov	w1, #0x0                   	// #0
    4260:	d34cfc00 	lsr	x0, x0, #12
    4264:	eb00027f 	cmp	x19, x0
    4268:	54000140 	b.eq	4290 <arm_smmu_atc_inv_domain.constprop.49+0x1a8>  // b.none
	log2_span	= fls_long(page_start ^ page_end);
    426c:	ca000260 	eor	x0, x19, x0
 *
 * Undefined if no set bit exists, so code should check against 0 first.
 */
static __always_inline unsigned long __fls(unsigned long word)
{
	return (sizeof(word) * 8) - 1 - __builtin_clzl(word);
    4270:	d28007e1 	mov	x1, #0x3f                  	// #63
    4274:	dac01000 	clz	x0, x0
    4278:	92800002 	mov	x2, #0xffffffffffffffff    	// #-1
    427c:	cb000020 	sub	x0, x1, x0
		return 0;
	return __fls(x) + 1;
    4280:	11000400 	add	w0, w0, #0x1
    4284:	12001c01 	and	w1, w0, #0xff
    4288:	9ac02040 	lsl	x0, x2, x0
    428c:	8a130000 	and	x0, x0, x19
	cmd->atc.addr	= page_start << inval_grain_shift;
    4290:	d374cc00 	lsl	x0, x0, #12
    4294:	f90033a0 	str	x0, [x29, #96]
	cmd->atc.size	= log2_span;
    4298:	3901a3a1 	strb	w1, [x29, #104]
    429c:	17ffffb7 	b	4178 <arm_smmu_atc_inv_domain.constprop.49+0x90>
    42a0:	a90363b7 	stp	x23, x24, [x29, #48]
    42a4:	f90023b9 	str	x25, [x29, #64]
}
    42a8:	94000000 	bl	0 <__stack_chk_fail>
    42ac:	d503201f 	nop

00000000000042b0 <arm_smmu_attach_dev>:
{
    42b0:	d503233f 	paciasp
    42b4:	a9b67bfd 	stp	x29, x30, [sp, #-160]!
    42b8:	910003fd 	mov	x29, sp
    42bc:	a901d7f4 	stp	x20, x21, [sp, #24]
    42c0:	90000015 	adrp	x21, 0 <__stack_chk_guard>
    42c4:	f90023f9 	str	x25, [sp, #64]
    42c8:	aa0103f9 	mov	x25, x1
    42cc:	910002a1 	add	x1, x21, #0x0
    42d0:	aa0003f4 	mov	x20, x0
    42d4:	f9400020 	ldr	x0, [x1]
    42d8:	f9004fa0 	str	x0, [x29, #152]
    42dc:	d2800000 	mov	x0, #0x0                   	// #0
	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
    42e0:	f9417720 	ldr	x0, [x25, #744]
	if (dev->iommu)
    42e4:	b4001900 	cbz	x0, 4604 <arm_smmu_attach_dev+0x354>
    42e8:	f90017b6 	str	x22, [x29, #40]
	return container_of(dom, struct arm_smmu_domain, domain);
    42ec:	d1022296 	sub	x22, x20, #0x88
	if (!fwspec)
    42f0:	f9401401 	ldr	x1, [x0, #40]
    42f4:	b40017a1 	cbz	x1, 45e8 <arm_smmu_attach_dev+0x338>
    42f8:	f9000bb3 	str	x19, [x29, #16]
    42fc:	a90363b7 	stp	x23, x24, [x29, #48]
	mutex_lock(&smmu_domain->init_mutex);
    4300:	910022d7 	add	x23, x22, #0x8
	return dev->iommu->priv;
    4304:	f9401c13 	ldr	x19, [x0, #56]
	arm_smmu_detach_dev(master);
    4308:	aa1303e0 	mov	x0, x19
	smmu = master->smmu;
    430c:	f9400278 	ldr	x24, [x19]
	arm_smmu_detach_dev(master);
    4310:	97fff8a2 	bl	2598 <arm_smmu_detach_dev>
	mutex_lock(&smmu_domain->init_mutex);
    4314:	aa1703e0 	mov	x0, x23
    4318:	94000000 	bl	0 <mutex_lock>
	if (!smmu_domain->smmu) {
    431c:	f8578280 	ldur	x0, [x20, #-136]
    4320:	b4000b60 	cbz	x0, 448c <arm_smmu_attach_dev+0x1dc>
	} else if (smmu_domain->smmu != smmu) {
    4324:	eb18001f 	cmp	x0, x24
    4328:	540017a1 	b.ne	461c <arm_smmu_attach_dev+0x36c>  // b.any
	} else if (smmu_domain->stage == ARM_SMMU_DOMAIN_S1 &&
    432c:	b85b0280 	ldur	w0, [x20, #-80]
    4330:	350000a0 	cbnz	w0, 4344 <arm_smmu_attach_dev+0x94>
		   master->ssid_bits != smmu_domain->s1_cfg.s1cdmax) {
    4334:	385f9282 	ldurb	w2, [x20, #-7]
    4338:	b9403a63 	ldr	w3, [x19, #56]
	} else if (smmu_domain->stage == ARM_SMMU_DOMAIN_S1 &&
    433c:	6b02007f 	cmp	w3, w2
    4340:	54001481 	b.ne	45d0 <arm_smmu_attach_dev+0x320>  // b.any
	master->domain = smmu_domain;
    4344:	f9000a76 	str	x22, [x19, #16]
	if (smmu_domain->stage != ARM_SMMU_DOMAIN_BYPASS)
    4348:	b85b0280 	ldur	w0, [x20, #-80]
    434c:	71000c1f 	cmp	w0, #0x3
    4350:	54000441 	b.ne	43d8 <arm_smmu_attach_dev+0x128>  // b.any
	arm_smmu_install_ste_for_dev(master);
    4354:	aa1303e0 	mov	x0, x19
	return &lock->rlock;
    4358:	91016296 	add	x22, x20, #0x58
    435c:	97fff855 	bl	24b0 <arm_smmu_install_ste_for_dev>
	spin_lock_irqsave(&smmu_domain->devices_lock, flags);
    4360:	aa1603e0 	mov	x0, x22
    4364:	94000000 	bl	0 <_raw_spin_lock_irqsave>
	__list_add(new, head, head->next);
    4368:	aa1403e3 	mov	x3, x20
	list_add(&master->domain_head, &smmu_domain->devices);
    436c:	91006262 	add	x2, x19, #0x18
	raw_spin_unlock_irqrestore(&lock->rlock, flags);
    4370:	aa0003e1 	mov	x1, x0
    4374:	aa1603e0 	mov	x0, x22
    4378:	f8448c64 	ldr	x4, [x3, #72]!
	next->prev = new;
    437c:	f9000482 	str	x2, [x4, #8]
	new->prev = prev;
    4380:	a9018e64 	stp	x4, x3, [x19, #24]
	WRITE_ONCE(prev->next, new);
    4384:	f9002682 	str	x2, [x20, #72]
    4388:	94000000 	bl	0 <_raw_spin_unlock_irqrestore>
	if (!master->ats_enabled)
    438c:	3940d260 	ldrb	w0, [x19, #52]
    4390:	35000460 	cbnz	w0, 441c <arm_smmu_attach_dev+0x16c>
		dev_err(master->dev, "Failed to enable ATS (STU %zu)\n", stu);
    4394:	52800019 	mov	w25, #0x0                   	// #0
	mutex_unlock(&smmu_domain->init_mutex);
    4398:	aa1703e0 	mov	x0, x23
    439c:	94000000 	bl	0 <mutex_unlock>
	return ret;
    43a0:	f9400bb3 	ldr	x19, [x29, #16]
    43a4:	a942dfb6 	ldp	x22, x23, [x29, #40]
    43a8:	f9401fb8 	ldr	x24, [x29, #56]
}
    43ac:	910002b5 	add	x21, x21, #0x0
    43b0:	2a1903e0 	mov	w0, w25
    43b4:	f9404fa2 	ldr	x2, [x29, #152]
    43b8:	f94002a1 	ldr	x1, [x21]
    43bc:	ca010041 	eor	x1, x2, x1
    43c0:	b5001261 	cbnz	x1, 460c <arm_smmu_attach_dev+0x35c>
    43c4:	a941d7f4 	ldp	x20, x21, [sp, #24]
    43c8:	f94023f9 	ldr	x25, [sp, #64]
    43cc:	a8ca7bfd 	ldp	x29, x30, [sp], #160
    43d0:	d50323bf 	autiasp
    43d4:	d65f03c0 	ret
		master->ats_enabled = arm_smmu_ats_supported(master);
    43d8:	a9400263 	ldp	x3, x0, [x19]
		return NULL;
    43dc:	d2800002 	mov	x2, #0x0                   	// #0
	struct iommu_fwspec *fwspec = dev_iommu_fwspec_get(dev);
    43e0:	f9417401 	ldr	x1, [x0, #744]
	if (dev->iommu)
    43e4:	b4000041 	cbz	x1, 43ec <arm_smmu_attach_dev+0x13c>
		return dev->iommu->fwspec;
    43e8:	f9401422 	ldr	x2, [x1, #40]
	if (!(smmu->features & ARM_SMMU_FEAT_ATS))
    43ec:	b9401863 	ldr	w3, [x3, #24]
		return false;
    43f0:	52800001 	mov	w1, #0x0                   	// #0
	if (!(smmu->features & ARM_SMMU_FEAT_ATS))
    43f4:	36280103 	tbz	w3, #5, 4414 <arm_smmu_attach_dev+0x164>
	if (!(fwspec->flags & IOMMU_FWSPEC_PCI_RC_ATS))
    43f8:	b9401042 	ldr	w2, [x2, #16]
    43fc:	360000c2 	tbz	w2, #0, 4414 <arm_smmu_attach_dev+0x164>
	return dev_is_pci(dev) && pci_ats_supported(to_pci_dev(dev));
    4400:	f9403003 	ldr	x3, [x0, #96]
    4404:	90000002 	adrp	x2, 0 <pci_bus_type>
    4408:	91000042 	add	x2, x2, #0x0
    440c:	eb02007f 	cmp	x3, x2
    4410:	54000d60 	b.eq	45bc <arm_smmu_attach_dev+0x30c>  // b.none
		master->ats_enabled = arm_smmu_ats_supported(master);
    4414:	3900d261 	strb	w1, [x19, #52]
    4418:	17ffffcf 	b	4354 <arm_smmu_attach_dev+0xa4>
	pdev = to_pci_dev(master->dev);
    441c:	a9405a61 	ldp	x1, x22, [x19]
	struct arm_smmu_domain *smmu_domain = master->domain;
    4420:	f9400a60 	ldr	x0, [x19, #16]
	pdev = to_pci_dev(master->dev);
    4424:	d102a2d6 	sub	x22, x22, #0xa8
 *
 * Undefined if no bit exists, so code should check against 0 first.
 */
static __always_inline unsigned long __ffs(unsigned long word)
{
	return __builtin_ctzl(word);
    4428:	f9418c34 	ldr	x20, [x1, #792]
	atomic_inc(&smmu_domain->nr_ats_masters);
    442c:	9100d002 	add	x2, x0, #0x34
    4430:	dac00294 	rbit	x20, x20
    4434:	dac01294 	clz	x20, x20
    4438:	14000005 	b	444c <arm_smmu_attach_dev+0x19c>
    443c:	14000004 	b	444c <arm_smmu_attach_dev+0x19c>
ATOMIC_OP(add, stadd)
    4440:	52800021 	mov	w1, #0x1                   	// #1
    4444:	b821005f 	stadd	w1, [x2]
    4448:	14000003 	b	4454 <arm_smmu_attach_dev+0x1a4>
ATOMIC_OPS(add, add, I)
    444c:	9100d003 	add	x3, x0, #0x34
    4450:	140001c4 	b	4b60 <arm_smmu_flush_iotlb_all+0x1c8>
	arm_smmu_atc_inv_domain(smmu_domain, 0, 0, 0);
    4454:	d2800002 	mov	x2, #0x0                   	// #0
    4458:	d2800001 	mov	x1, #0x0                   	// #0
    445c:	97ffff23 	bl	40e8 <arm_smmu_atc_inv_domain.constprop.49>
	if (pci_enable_ats(pdev, stu))
    4460:	2a1403e1 	mov	w1, w20
    4464:	aa1603e0 	mov	x0, x22
    4468:	94000000 	bl	0 <pci_enable_ats>
    446c:	34fff940 	cbz	w0, 4394 <arm_smmu_attach_dev+0xe4>
		dev_err(master->dev, "Failed to enable ATS (STU %zu)\n", stu);
    4470:	f9400660 	ldr	x0, [x19, #8]
    4474:	52800019 	mov	w25, #0x0                   	// #0
    4478:	90000001 	adrp	x1, 0 <queue_remove_raw>
    447c:	aa1403e2 	mov	x2, x20
    4480:	91000021 	add	x1, x1, #0x0
    4484:	94000000 	bl	0 <_dev_err>
    4488:	17ffffc4 	b	4398 <arm_smmu_attach_dev+0xe8>
	if (domain->type == IOMMU_DOMAIN_IDENTITY) {
    448c:	b9400280 	ldr	w0, [x20]
		smmu_domain->smmu = smmu;
    4490:	f8178298 	stur	x24, [x20, #-136]
	if (domain->type == IOMMU_DOMAIN_IDENTITY) {
    4494:	7100101f 	cmp	w0, #0x4
    4498:	540007a0 	b.eq	458c <arm_smmu_attach_dev+0x2dc>  // b.none
	if (!(smmu->features & ARM_SMMU_FEAT_TRANS_S1))
    449c:	b9401b01 	ldr	w1, [x24, #24]
    44a0:	2a0103e0 	mov	w0, w1
    44a4:	37480641 	tbnz	w1, #9, 456c <arm_smmu_attach_dev+0x2bc>
		smmu_domain->stage = ARM_SMMU_DOMAIN_S2;
    44a8:	52800020 	mov	w0, #0x1                   	// #1
    44ac:	b81b0280 	stur	w0, [x20, #-80]
	if (!(smmu->features & ARM_SMMU_FEAT_TRANS_S2))
    44b0:	b9401b01 	ldr	w1, [x24, #24]
    44b4:	37500781 	tbnz	w1, #10, 45a4 <arm_smmu_attach_dev+0x2f4>
		smmu_domain->stage = ARM_SMMU_DOMAIN_S1;
    44b8:	b81b029f 	stur	wzr, [x20, #-80]
    44bc:	b9401b00 	ldr	w0, [x24, #24]
		oas = smmu->ias;
    44c0:	f9418705 	ldr	x5, [x24, #776]
		finalise_stage_fn = arm_smmu_domain_finalise_s1;
    44c4:	90000019 	adrp	x25, 0 <queue_remove_raw>
    44c8:	91000339 	add	x25, x25, #0x0
    44cc:	2a0003e1 	mov	w1, w0
		oas = smmu->ias;
    44d0:	52800606 	mov	w6, #0x30                  	// #48
		fmt = ARM_64_LPAE_S1;
    44d4:	52800040 	mov	w0, #0x2                   	// #2
	if (smmu_domain->non_strict)
    44d8:	385a8283 	ldurb	w3, [x20, #-88]
	pgtbl_cfg = (struct io_pgtable_cfg) {
    44dc:	90000002 	adrp	x2, 0 <queue_remove_raw>
		.iommu_dev	= smmu->dev,
    44e0:	f9400304 	ldr	x4, [x24]
	pgtbl_cfg = (struct io_pgtable_cfg) {
    44e4:	91000042 	add	x2, x2, #0x0
    44e8:	a9057fbf 	stp	xzr, xzr, [x29, #80]
		.coherent_walk	= smmu->features & ARM_SMMU_FEAT_COHERENCY,
    44ec:	d3482021 	ubfx	x1, x1, #8, #1
	pgtbl_cfg = (struct io_pgtable_cfg) {
    44f0:	a9067fbf 	stp	xzr, xzr, [x29, #96]
    44f4:	91010042 	add	x2, x2, #0x40
		.pgsize_bitmap	= smmu->pgsize_bitmap,
    44f8:	f9418f07 	ldr	x7, [x24, #792]
	pgtbl_cfg = (struct io_pgtable_cfg) {
    44fc:	f9002fa7 	str	x7, [x29, #88]
    4500:	290c17a6 	stp	w6, w5, [x29, #96]
    4504:	3901a3a1 	strb	w1, [x29, #104]
    4508:	a90713a2 	stp	x2, x4, [x29, #112]
    450c:	a9087fbf 	stp	xzr, xzr, [x29, #128]
    4510:	f9004bbf 	str	xzr, [x29, #144]
	if (smmu_domain->non_strict)
    4514:	35000423 	cbnz	w3, 4598 <arm_smmu_attach_dev+0x2e8>
	pgtbl_ops = alloc_io_pgtable_ops(fmt, &pgtbl_cfg, smmu_domain);
    4518:	aa1603e2 	mov	x2, x22
    451c:	910143a1 	add	x1, x29, #0x50
    4520:	94000000 	bl	0 <alloc_io_pgtable_ops>
    4524:	aa0003f8 	mov	x24, x0
	if (!pgtbl_ops)
    4528:	b4000960 	cbz	x0, 4654 <arm_smmu_attach_dev+0x3a4>
	domain->geometry.aperture_end = (1UL << pgtbl_cfg.ias) - 1;
    452c:	b94063a1 	ldr	w1, [x29, #96]
    4530:	d2800020 	mov	x0, #0x1                   	// #1
	domain->pgsize_bitmap = pgtbl_cfg.pgsize_bitmap;
    4534:	f9402fa2 	ldr	x2, [x29, #88]
    4538:	f9000a82 	str	x2, [x20, #16]
	ret = finalise_stage_fn(smmu_domain, master, &pgtbl_cfg);
    453c:	910143a2 	add	x2, x29, #0x50
	domain->geometry.force_aperture = true;
    4540:	3900e280 	strb	w0, [x20, #56]
	domain->geometry.aperture_end = (1UL << pgtbl_cfg.ias) - 1;
    4544:	9ac12000 	lsl	x0, x0, x1
    4548:	d1000400 	sub	x0, x0, #0x1
    454c:	f9001a80 	str	x0, [x20, #48]
	ret = finalise_stage_fn(smmu_domain, master, &pgtbl_cfg);
    4550:	aa1303e1 	mov	x1, x19
    4554:	aa1603e0 	mov	x0, x22
    4558:	d63f0320 	blr	x25
    455c:	2a0003f9 	mov	w25, w0
	if (ret < 0) {
    4560:	37f804a0 	tbnz	w0, #31, 45f4 <arm_smmu_attach_dev+0x344>
	smmu_domain->pgtbl_ops = pgtbl_ops;
    4564:	f81a0298 	stur	x24, [x20, #-96]
    4568:	17ffff77 	b	4344 <arm_smmu_attach_dev+0x94>
	if (!(smmu->features & ARM_SMMU_FEAT_TRANS_S2))
    456c:	3657fa61 	tbz	w1, #10, 44b8 <arm_smmu_attach_dev+0x208>
	switch (smmu_domain->stage) {
    4570:	b85b0282 	ldur	w2, [x20, #-80]
    4574:	34fffa62 	cbz	w2, 44c0 <arm_smmu_attach_dev+0x210>
		return -EINVAL;
    4578:	128002b9 	mov	w25, #0xffffffea            	// #-22
	switch (smmu_domain->stage) {
    457c:	7100085f 	cmp	w2, #0x2
    4580:	54000129 	b.ls	45a4 <arm_smmu_attach_dev+0x2f4>  // b.plast
			smmu_domain->smmu = NULL;
    4584:	f817829f 	stur	xzr, [x20, #-136]
			goto out_unlock;
    4588:	17ffff84 	b	4398 <arm_smmu_attach_dev+0xe8>
		smmu_domain->stage = ARM_SMMU_DOMAIN_BYPASS;
    458c:	52800060 	mov	w0, #0x3                   	// #3
    4590:	b81b0280 	stur	w0, [x20, #-80]
    4594:	17ffff6c 	b	4344 <arm_smmu_attach_dev+0x94>
		pgtbl_cfg.quirks |= IO_PGTABLE_QUIRK_NON_STRICT;
    4598:	d2800201 	mov	x1, #0x10                  	// #16
    459c:	f9002ba1 	str	x1, [x29, #80]
    45a0:	17ffffde 	b	4518 <arm_smmu_attach_dev+0x268>
		finalise_stage_fn = arm_smmu_domain_finalise_s2;
    45a4:	90000019 	adrp	x25, 0 <queue_remove_raw>
		fmt = ARM_64_LPAE_S2;
    45a8:	52800060 	mov	w0, #0x3                   	// #3
		finalise_stage_fn = arm_smmu_domain_finalise_s2;
    45ac:	91000339 	add	x25, x25, #0x0
    45b0:	b9430b06 	ldr	w6, [x24, #776]
		oas = smmu->oas;
    45b4:	f9418b05 	ldr	x5, [x24, #784]
    45b8:	17ffffc8 	b	44d8 <arm_smmu_attach_dev+0x228>
	return dev_is_pci(dev) && pci_ats_supported(to_pci_dev(dev));
    45bc:	d102a000 	sub	x0, x0, #0xa8
    45c0:	94000000 	bl	0 <pci_ats_supported>
    45c4:	12001c01 	and	w1, w0, #0xff
		master->ats_enabled = arm_smmu_ats_supported(master);
    45c8:	3900d261 	strb	w1, [x19, #52]
    45cc:	17ffff62 	b	4354 <arm_smmu_attach_dev+0xa4>
		dev_err(dev,
    45d0:	aa1903e0 	mov	x0, x25
    45d4:	90000001 	adrp	x1, 0 <queue_remove_raw>
		ret = -EINVAL;
    45d8:	128002b9 	mov	w25, #0xffffffea            	// #-22
		dev_err(dev,
    45dc:	91000021 	add	x1, x1, #0x0
    45e0:	94000000 	bl	0 <_dev_err>
		goto out_unlock;
    45e4:	17ffff6d 	b	4398 <arm_smmu_attach_dev+0xe8>
		return -ENOENT;
    45e8:	12800039 	mov	w25, #0xfffffffe            	// #-2
    45ec:	f94017b6 	ldr	x22, [x29, #40]
    45f0:	17ffff6f 	b	43ac <arm_smmu_attach_dev+0xfc>
		free_io_pgtable_ops(pgtbl_ops);
    45f4:	aa1803e0 	mov	x0, x24
    45f8:	94000000 	bl	0 <free_io_pgtable_ops>
			smmu_domain->smmu = NULL;
    45fc:	f817829f 	stur	xzr, [x20, #-136]
    4600:	17ffff66 	b	4398 <arm_smmu_attach_dev+0xe8>
		return -ENOENT;
    4604:	12800039 	mov	w25, #0xfffffffe            	// #-2
    4608:	17ffff69 	b	43ac <arm_smmu_attach_dev+0xfc>
    460c:	f9000bb3 	str	x19, [x29, #16]
    4610:	a902dfb6 	stp	x22, x23, [x29, #40]
    4614:	f9001fb8 	str	x24, [x29, #56]
}
    4618:	94000000 	bl	0 <__stack_chk_fail>
		dev_err(dev,
    461c:	f9400000 	ldr	x0, [x0]
	if (dev->init_name)
    4620:	f9402802 	ldr	x2, [x0, #80]
    4624:	b5000042 	cbnz	x2, 462c <arm_smmu_attach_dev+0x37c>
	return kobject_name(&dev->kobj);
    4628:	f9400002 	ldr	x2, [x0]
    462c:	f9400300 	ldr	x0, [x24]
	if (dev->init_name)
    4630:	f9402803 	ldr	x3, [x0, #80]
    4634:	b5000043 	cbnz	x3, 463c <arm_smmu_attach_dev+0x38c>
	return kobject_name(&dev->kobj);
    4638:	f9400003 	ldr	x3, [x0]
    463c:	aa1903e0 	mov	x0, x25
    4640:	90000001 	adrp	x1, 0 <queue_remove_raw>
		ret = -ENXIO;
    4644:	128000b9 	mov	w25, #0xfffffffa            	// #-6
		dev_err(dev,
    4648:	91000021 	add	x1, x1, #0x0
    464c:	94000000 	bl	0 <_dev_err>
		goto out_unlock;
    4650:	17ffff52 	b	4398 <arm_smmu_attach_dev+0xe8>
		return -ENOMEM;
    4654:	12800179 	mov	w25, #0xfffffff4            	// #-12
			smmu_domain->smmu = NULL;
    4658:	f817829f 	stur	xzr, [x20, #-136]
    465c:	17ffff4f 	b	4398 <arm_smmu_attach_dev+0xe8>

0000000000004660 <arm_smmu_tlb_inv_range>:
{
    4660:	d503233f 	paciasp
    4664:	d11243ff 	sub	sp, sp, #0x490
    4668:	a9007bfd 	stp	x29, x30, [sp]
    466c:	910003fd 	mov	x29, sp
    4670:	a90153f3 	stp	x19, x20, [sp, #16]
    4674:	12001c73 	and	w19, w3, #0xff
    4678:	a9025bf5 	stp	x21, x22, [sp, #32]
    467c:	90000016 	adrp	x22, 0 <__stack_chk_guard>
    4680:	a903e7f8 	stp	x24, x25, [sp, #56]
    4684:	aa0403f8 	mov	x24, x4
    4688:	f90027fa 	str	x26, [sp, #72]
    468c:	910002c4 	add	x4, x22, #0x0
    4690:	aa0003fa 	mov	x26, x0
    4694:	aa0103f9 	mov	x25, x1
    4698:	f9400080 	ldr	x0, [x4]
    469c:	f90247a0 	str	x0, [x29, #1160]
    46a0:	d2800000 	mov	x0, #0x0                   	// #0
    46a4:	aa0203f4 	mov	x20, x2
	struct arm_smmu_cmdq_batch cmds = {};
    46a8:	52800001 	mov	w1, #0x0                   	// #0
    46ac:	d2808102 	mov	x2, #0x408                 	// #1032
    46b0:	910203a0 	add	x0, x29, #0x80
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    46b4:	f9400315 	ldr	x21, [x24]
	struct arm_smmu_cmdq_batch cmds = {};
    46b8:	94000000 	bl	0 <memset>
	struct arm_smmu_cmdq_ent cmd = {
    46bc:	a9067fbf 	stp	xzr, xzr, [x29, #96]
    46c0:	3901bbb3 	strb	w19, [x29, #110]
    46c4:	a9077fbf 	stp	xzr, xzr, [x29, #112]
	if (!size)
    46c8:	b4000699 	cbz	x25, 4798 <arm_smmu_tlb_inv_range+0x138>
    46cc:	f9001bb7 	str	x23, [x29, #48]
    46d0:	a90573bb 	stp	x27, x28, [x29, #80]
	if (smmu_domain->stage == ARM_SMMU_DOMAIN_S1) {
    46d4:	b9403b00 	ldr	w0, [x24, #56]
    46d8:	340007a0 	cbz	w0, 47cc <arm_smmu_tlb_inv_range+0x16c>
		cmd.tlbi.vmid	= smmu_domain->s2_cfg.vmid;
    46dc:	79408300 	ldrh	w0, [x24, #64]
		cmd.opcode	= CMDQ_OP_TLBI_S2_IPA;
    46e0:	52800541 	mov	w1, #0x2a                  	// #42
		cmd.tlbi.vmid	= smmu_domain->s2_cfg.vmid;
    46e4:	7900dba0 	strh	w0, [x29, #108]
	if (smmu->features & ARM_SMMU_FEAT_RANGE_INV) {
    46e8:	b9401aa0 	ldr	w0, [x21, #24]
		cmd.opcode	= CMDQ_OP_TLBI_S2_IPA;
    46ec:	390183a1 	strb	w1, [x29, #96]
	if (smmu->features & ARM_SMMU_FEAT_RANGE_INV) {
    46f0:	12110001 	and	w1, w0, #0x8000
    46f4:	377807a0 	tbnz	w0, #15, 47e8 <arm_smmu_tlb_inv_range+0x188>
	unsigned long start = iova, end = iova + size, num_pages = 0, tg = 0;
    46f8:	d280001b 	mov	x27, #0x0                   	// #0
    46fc:	d280001c 	mov	x28, #0x0                   	// #0
    4700:	8b190357 	add	x23, x26, x25
	while (iova < end) {
    4704:	aa1a03f3 	mov	x19, x26
    4708:	eb17035f 	cmp	x26, x23
    470c:	54000302 	b.cs	476c <arm_smmu_tlb_inv_range+0x10c>  // b.hs, b.nlast
		if (smmu->features & ARM_SMMU_FEAT_RANGE_INV) {
    4710:	34000181 	cbz	w1, 4740 <arm_smmu_tlb_inv_range+0xe0>
    4714:	dac00381 	rbit	x1, x28
    4718:	dac01021 	clz	x1, x1
			cmd.tlbi.scale = scale;
    471c:	3901a7a1 	strb	w1, [x29, #105]
			inv_range = num << (scale + tg);
    4720:	0b010374 	add	w20, w27, w1
			num = (num_pages >> scale) & CMDQ_TLBI_RANGE_NUM_MAX;
    4724:	9ac12780 	lsr	x0, x28, x1
    4728:	92401000 	and	x0, x0, #0x1f
			cmd.tlbi.num = num - 1;
    472c:	51000402 	sub	w2, w0, #0x1
    4730:	3901a3a2 	strb	w2, [x29, #104]
			num_pages -= num << scale;
    4734:	9ac12002 	lsl	x2, x0, x1
    4738:	cb02039c 	sub	x28, x28, x2
			inv_range = num << (scale + tg);
    473c:	9ad42014 	lsl	x20, x0, x20
		cmd.tlbi.addr = iova;
    4740:	f9003fb3 	str	x19, [x29, #120]
		arm_smmu_cmdq_batch_add(smmu, &cmds, &cmd);
    4744:	910183a2 	add	x2, x29, #0x60
    4748:	910203a1 	add	x1, x29, #0x80
    474c:	aa1503e0 	mov	x0, x21
		iova += inv_range;
    4750:	8b140273 	add	x19, x19, x20
		arm_smmu_cmdq_batch_add(smmu, &cmds, &cmd);
    4754:	97fff8db 	bl	2ac0 <arm_smmu_cmdq_batch_add>
	while (iova < end) {
    4758:	eb1302ff 	cmp	x23, x19
    475c:	54000089 	b.ls	476c <arm_smmu_tlb_inv_range+0x10c>  // b.plast
    4760:	b9401aa0 	ldr	w0, [x21, #24]
    4764:	12110001 	and	w1, w0, #0x8000
    4768:	17ffffea 	b	4710 <arm_smmu_tlb_inv_range+0xb0>
	return arm_smmu_cmdq_issue_cmdlist(smmu, cmds->cmds, cmds->num, true);
    476c:	b94483a2 	ldr	w2, [x29, #1152]
    4770:	52800023 	mov	w3, #0x1                   	// #1
    4774:	910203a1 	add	x1, x29, #0x80
    4778:	aa1503e0 	mov	x0, x21
    477c:	97fff3fb 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
	arm_smmu_atc_inv_domain(smmu_domain, 0, start, size);
    4780:	aa1903e2 	mov	x2, x25
    4784:	aa1a03e1 	mov	x1, x26
    4788:	aa1803e0 	mov	x0, x24
    478c:	97fffe57 	bl	40e8 <arm_smmu_atc_inv_domain.constprop.49>
    4790:	f9401bb7 	ldr	x23, [x29, #48]
    4794:	a94573bb 	ldp	x27, x28, [x29, #80]
}
    4798:	910002d6 	add	x22, x22, #0x0
    479c:	f94247a1 	ldr	x1, [x29, #1160]
    47a0:	f94002c0 	ldr	x0, [x22]
    47a4:	ca000020 	eor	x0, x1, x0
    47a8:	b50004c0 	cbnz	x0, 4840 <arm_smmu_tlb_inv_range+0x1e0>
    47ac:	a9407bfd 	ldp	x29, x30, [sp]
    47b0:	a94153f3 	ldp	x19, x20, [sp, #16]
    47b4:	a9425bf5 	ldp	x21, x22, [sp, #32]
    47b8:	a943e7f8 	ldp	x24, x25, [sp, #56]
    47bc:	f94027fa 	ldr	x26, [sp, #72]
    47c0:	911243ff 	add	sp, sp, #0x490
    47c4:	d50323bf 	autiasp
    47c8:	d65f03c0 	ret
		cmd.tlbi.asid	= smmu_domain->s1_cfg.cd.asid;
    47cc:	7940c300 	ldrh	w0, [x24, #96]
		cmd.opcode	= CMDQ_OP_TLBI_NH_VA;
    47d0:	52800241 	mov	w1, #0x12                  	// #18
		cmd.tlbi.asid	= smmu_domain->s1_cfg.cd.asid;
    47d4:	7900d7a0 	strh	w0, [x29, #106]
	if (smmu->features & ARM_SMMU_FEAT_RANGE_INV) {
    47d8:	b9401aa0 	ldr	w0, [x21, #24]
		cmd.opcode	= CMDQ_OP_TLBI_NH_VA;
    47dc:	390183a1 	strb	w1, [x29, #96]
	if (smmu->features & ARM_SMMU_FEAT_RANGE_INV) {
    47e0:	12110001 	and	w1, w0, #0x8000
    47e4:	367ff8a0 	tbz	w0, #15, 46f8 <arm_smmu_tlb_inv_range+0x98>
    47e8:	f9404f1c 	ldr	x28, [x24, #152]
    47ec:	dac01280 	clz	x0, x20
    47f0:	d28007e2 	mov	x2, #0x3f                  	// #63
    47f4:	cb000040 	sub	x0, x2, x0
    47f8:	dac0039c 	rbit	x28, x28
    47fc:	51000c00 	sub	w0, w0, #0x3
    4800:	dac0139c 	clz	x28, x28
    4804:	f100029f 	cmp	x20, #0x0
    4808:	93407c00 	sxtw	x0, w0
    480c:	92800062 	mov	x2, #0xfffffffffffffffc    	// #-4
    4810:	93407f9b 	sxtw	x27, w28
    4814:	9a821000 	csel	x0, x0, x2, ne  // ne = any
		cmd.tlbi.ttl = 4 - ((ilog2(granule) - 3) / (tg - 3));
    4818:	d1000f64 	sub	x4, x27, #0x3
		cmd.tlbi.tg = (tg - 10) / 2;
    481c:	d1002b63 	sub	x3, x27, #0xa
		cmd.tlbi.ttl = 4 - ((ilog2(granule) - 3) / (tg - 3));
    4820:	52800082 	mov	w2, #0x4                   	// #4
		num_pages = size >> tg;
    4824:	9adc273c 	lsr	x28, x25, x28
		cmd.tlbi.tg = (tg - 10) / 2;
    4828:	d341fc63 	lsr	x3, x3, #1
    482c:	3901c3a3 	strb	w3, [x29, #112]
		cmd.tlbi.ttl = 4 - ((ilog2(granule) - 3) / (tg - 3));
    4830:	9ac40800 	udiv	x0, x0, x4
    4834:	4b000040 	sub	w0, w2, w0
    4838:	3901bfa0 	strb	w0, [x29, #111]
    483c:	17ffffb1 	b	4700 <arm_smmu_tlb_inv_range+0xa0>
    4840:	f9001bb7 	str	x23, [x29, #48]
    4844:	a90573bb 	stp	x27, x28, [x29, #80]
}
    4848:	94000000 	bl	0 <__stack_chk_fail>
    484c:	d503201f 	nop

0000000000004850 <arm_smmu_iotlb_sync>:
{
    4850:	d503233f 	paciasp
    4854:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	arm_smmu_tlb_inv_range(gather->start, gather->end - gather->start,
    4858:	d1022004 	sub	x4, x0, #0x88
    485c:	52800023 	mov	w3, #0x1                   	// #1
{
    4860:	910003fd 	mov	x29, sp
	arm_smmu_tlb_inv_range(gather->start, gather->end - gather->start,
    4864:	f9400025 	ldr	x5, [x1]
    4868:	f9400822 	ldr	x2, [x1, #16]
    486c:	f9400421 	ldr	x1, [x1, #8]
    4870:	aa0503e0 	mov	x0, x5
    4874:	cb050021 	sub	x1, x1, x5
    4878:	97ffff7a 	bl	4660 <arm_smmu_tlb_inv_range>
}
    487c:	a8c17bfd 	ldp	x29, x30, [sp], #16
    4880:	d50323bf 	autiasp
    4884:	d65f03c0 	ret

0000000000004888 <arm_smmu_tlb_inv_leaf>:
{
    4888:	d503233f 	paciasp
    488c:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	arm_smmu_tlb_inv_range(iova, size, granule, true, cookie);
    4890:	aa0303e4 	mov	x4, x3
    4894:	52800023 	mov	w3, #0x1                   	// #1
{
    4898:	910003fd 	mov	x29, sp
	arm_smmu_tlb_inv_range(iova, size, granule, true, cookie);
    489c:	97ffff71 	bl	4660 <arm_smmu_tlb_inv_range>
}
    48a0:	a8c17bfd 	ldp	x29, x30, [sp], #16
    48a4:	d50323bf 	autiasp
    48a8:	d65f03c0 	ret
    48ac:	d503201f 	nop

00000000000048b0 <arm_smmu_tlb_inv_walk>:
{
    48b0:	d503233f 	paciasp
    48b4:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	arm_smmu_tlb_inv_range(iova, size, granule, false, cookie);
    48b8:	aa0303e4 	mov	x4, x3
    48bc:	52800003 	mov	w3, #0x0                   	// #0
{
    48c0:	910003fd 	mov	x29, sp
	arm_smmu_tlb_inv_range(iova, size, granule, false, cookie);
    48c4:	97ffff67 	bl	4660 <arm_smmu_tlb_inv_range>
}
    48c8:	a8c17bfd 	ldp	x29, x30, [sp], #16
    48cc:	d50323bf 	autiasp
    48d0:	d65f03c0 	ret
    48d4:	d503201f 	nop

00000000000048d8 <arm_smmu_tlb_inv_context>:
{
    48d8:	d503233f 	paciasp
    48dc:	a9ba7bfd 	stp	x29, x30, [sp, #-96]!
    48e0:	910003fd 	mov	x29, sp
    48e4:	a90153f3 	stp	x19, x20, [sp, #16]
    48e8:	aa0003f4 	mov	x20, x0
    48ec:	f90013f5 	str	x21, [sp, #32]
    48f0:	90000013 	adrp	x19, 0 <__stack_chk_guard>
    48f4:	91000260 	add	x0, x19, #0x0
    48f8:	f9400001 	ldr	x1, [x0]
    48fc:	f9002fa1 	str	x1, [x29, #88]
    4900:	d2800001 	mov	x1, #0x0                   	// #0
	if (smmu_domain->stage == ARM_SMMU_DOMAIN_S1) {
    4904:	b9403a80 	ldr	w0, [x20, #56]
	struct arm_smmu_device *smmu = smmu_domain->smmu;
    4908:	f9400295 	ldr	x21, [x20]
	if (smmu_domain->stage == ARM_SMMU_DOMAIN_S1) {
    490c:	34000360 	cbz	w0, 4978 <arm_smmu_tlb_inv_context+0xa0>
		cmd.tlbi.vmid	= smmu_domain->s2_cfg.vmid;
    4910:	79408280 	ldrh	w0, [x20, #64]
		cmd.opcode	= CMDQ_OP_TLBI_S12_VMALL;
    4914:	52800501 	mov	w1, #0x28                  	// #40
    4918:	3900e3a1 	strb	w1, [x29, #56]
		cmd.tlbi.vmid	= smmu_domain->s2_cfg.vmid;
    491c:	79008ba0 	strh	w0, [x29, #68]
	arm_smmu_cmdq_issue_cmd(smmu, &cmd);
    4920:	9100e3a1 	add	x1, x29, #0x38
    4924:	aa1503e0 	mov	x0, x21
    4928:	97fff56c 	bl	1ed8 <arm_smmu_cmdq_issue_cmd>
}
    492c:	91000273 	add	x19, x19, #0x0
	return arm_smmu_cmdq_issue_cmdlist(smmu, NULL, 0, true);
    4930:	52800023 	mov	w3, #0x1                   	// #1
    4934:	52800002 	mov	w2, #0x0                   	// #0
    4938:	d2800001 	mov	x1, #0x0                   	// #0
    493c:	aa1503e0 	mov	x0, x21
    4940:	97fff38a 	bl	1768 <arm_smmu_cmdq_issue_cmdlist>
	arm_smmu_atc_inv_domain(smmu_domain, 0, 0, 0);
    4944:	d2800001 	mov	x1, #0x0                   	// #0
    4948:	d2800002 	mov	x2, #0x0                   	// #0
    494c:	aa1403e0 	mov	x0, x20
    4950:	97fffde6 	bl	40e8 <arm_smmu_atc_inv_domain.constprop.49>
}
    4954:	f9402fa1 	ldr	x1, [x29, #88]
    4958:	f9400260 	ldr	x0, [x19]
    495c:	ca000020 	eor	x0, x1, x0
    4960:	b5000180 	cbnz	x0, 4990 <arm_smmu_tlb_inv_context+0xb8>
    4964:	a94153f3 	ldp	x19, x20, [sp, #16]
    4968:	f94013f5 	ldr	x21, [sp, #32]
    496c:	a8c67bfd 	ldp	x29, x30, [sp], #96
    4970:	d50323bf 	autiasp
    4974:	d65f03c0 	ret
		cmd.tlbi.asid	= smmu_domain->s1_cfg.cd.asid;
    4978:	7940c280 	ldrh	w0, [x20, #96]
		cmd.opcode	= CMDQ_OP_TLBI_NH_ASID;
    497c:	52800221 	mov	w1, #0x11                  	// #17
    4980:	3900e3a1 	strb	w1, [x29, #56]
		cmd.tlbi.asid	= smmu_domain->s1_cfg.cd.asid;
    4984:	790087a0 	strh	w0, [x29, #66]
		cmd.tlbi.vmid	= 0;
    4988:	79008bbf 	strh	wzr, [x29, #68]
    498c:	17ffffe5 	b	4920 <arm_smmu_tlb_inv_context+0x48>
}
    4990:	94000000 	bl	0 <__stack_chk_fail>
    4994:	d503201f 	nop

0000000000004998 <arm_smmu_flush_iotlb_all>:
	if (smmu_domain->smmu)
    4998:	f8578001 	ldur	x1, [x0, #-136]
    499c:	b4000141 	cbz	x1, 49c4 <arm_smmu_flush_iotlb_all+0x2c>
{
    49a0:	d503233f 	paciasp
    49a4:	d1022002 	sub	x2, x0, #0x88
    49a8:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
		arm_smmu_tlb_inv_context(smmu_domain);
    49ac:	aa0203e0 	mov	x0, x2
{
    49b0:	910003fd 	mov	x29, sp
		arm_smmu_tlb_inv_context(smmu_domain);
    49b4:	97ffffc9 	bl	48d8 <arm_smmu_tlb_inv_context>
}
    49b8:	a8c17bfd 	ldp	x29, x30, [sp], #16
    49bc:	d50323bf 	autiasp
    49c0:	d65f03c0 	ret
    49c4:	d65f03c0 	ret
    49c8:	88dffc21 	ldar	w1, [x1]
    49cc:	88dffc00 	ldar	w0, [x0]
    49d0:	88dffe73 	ldar	w19, [x19]
    49d4:	88dffeb5 	ldar	w21, [x21]
    49d8:	88dffe73 	ldar	w19, [x19]
    49dc:	88dffc13 	ldar	w19, [x0]
    49e0:	88dffe60 	ldar	w0, [x19]
    49e4:	88dffe60 	ldar	w0, [x19]
    49e8:	88dffe60 	ldar	w0, [x19]
    49ec:	88dffe73 	ldar	w19, [x19]
    49f0:	f9800051 	prfm	pstl1strm, [x2]
    49f4:	c85f7c43 	ldxr	x3, [x2]
    49f8:	aa010065 	orr	x5, x3, x1
    49fc:	c806fc45 	stlxr	w6, x5, [x2]
    4a00:	35ffffa6 	cbnz	w6, 49f4 <arm_smmu_flush_iotlb_all+0x5c>
    4a04:	d5033bbf 	dmb	ish
    4a08:	17fff2c9 	b	152c <arm_smmu_domain_finalise_s2+0x114>
    4a0c:	f98000b1 	prfm	pstl1strm, [x5]
    4a10:	c85f7ca6 	ldxr	x6, [x5]
    4a14:	ca0700c6 	eor	x6, x6, x7
    4a18:	c8087ca6 	stxr	w8, x6, [x5]
    4a1c:	35ffffa8 	cbnz	w8, 4a10 <arm_smmu_flush_iotlb_all+0x78>
    4a20:	17fff316 	b	1678 <__arm_smmu_cmdq_poll_set_valid_map.isra.25+0x120>
    4a24:	f9800011 	prfm	pstl1strm, [x0]
    4a28:	c85f7c02 	ldxr	x2, [x0]
    4a2c:	8a210042 	bic	x2, x2, x1
    4a30:	c8037c02 	stxr	w3, x2, [x0]
    4a34:	35ffffa3 	cbnz	w3, 4a28 <arm_smmu_flush_iotlb_all+0x90>
    4a38:	17fff344 	b	1748 <arm_smmu_domain_free+0xc8>
    4a3c:	d5384608 	mrs	x8, s3_0_c4_c6_0
    4a40:	521b0900 	eor	w0, w8, #0xe0
    4a44:	d5184600 	msr	s3_0_c4_c6_0, x0
    4a48:	f9800371 	prfm	pstl1strm, [x27]
    4a4c:	c85f7f60 	ldxr	x0, [x27]
    4a50:	ca010004 	eor	x4, x0, x1
    4a54:	b5000064 	cbnz	x4, 4a60 <arm_smmu_flush_iotlb_all+0xc8>
    4a58:	c8047f62 	stxr	w4, x2, [x27]
    4a5c:	35ffff84 	cbnz	w4, 4a4c <arm_smmu_flush_iotlb_all+0xb4>
    4a60:	17fff398 	b	18c0 <arm_smmu_cmdq_issue_cmdlist+0x158>
    4a64:	d5184615 	msr	s3_0_c4_c6_0, x21
    4a68:	d5384604 	mrs	x4, s3_0_c4_c6_0
    4a6c:	521b0880 	eor	w0, w4, #0xe0
    4a70:	d5184600 	msr	s3_0_c4_c6_0, x0
    4a74:	88dffc21 	ldar	w1, [x1]
    4a78:	d5184604 	msr	s3_0_c4_c6_0, x4
    4a7c:	d5384608 	mrs	x8, s3_0_c4_c6_0
    4a80:	521b0900 	eor	w0, w8, #0xe0
    4a84:	d5184600 	msr	s3_0_c4_c6_0, x0
    4a88:	f98000b1 	prfm	pstl1strm, [x5]
    4a8c:	885f7ca0 	ldxr	w0, [x5]
    4a90:	4a010003 	eor	w3, w0, w1
    4a94:	35000063 	cbnz	w3, 4aa0 <arm_smmu_flush_iotlb_all+0x108>
    4a98:	88037ca2 	stxr	w3, w2, [x5]
    4a9c:	35ffff83 	cbnz	w3, 4a8c <arm_smmu_flush_iotlb_all+0xf4>
    4aa0:	17fff3f7 	b	1a7c <arm_smmu_cmdq_issue_cmdlist+0x314>
    4aa4:	d5184604 	msr	s3_0_c4_c6_0, x4
    4aa8:	f9800071 	prfm	pstl1strm, [x3]
    4aac:	885f7c78 	ldxr	w24, [x3]
    4ab0:	0a200301 	bic	w1, w24, w0
    4ab4:	88027c61 	stxr	w2, w1, [x3]
    4ab8:	35ffffa2 	cbnz	w2, 4aac <arm_smmu_flush_iotlb_all+0x114>
    4abc:	17fff416 	b	1b14 <arm_smmu_cmdq_issue_cmdlist+0x3ac>
    4ac0:	d5184615 	msr	s3_0_c4_c6_0, x21
    4ac4:	88dffc21 	ldar	w1, [x1]
    4ac8:	88dffc63 	ldar	w3, [x3]
    4acc:	88dffc84 	ldar	w4, [x4]
    4ad0:	f9800071 	prfm	pstl1strm, [x3]
    4ad4:	885f7c61 	ldxr	w1, [x3]
    4ad8:	4b000021 	sub	w1, w1, w0
    4adc:	8802fc61 	stlxr	w2, w1, [x3]
    4ae0:	35ffffa2 	cbnz	w2, 4ad4 <arm_smmu_flush_iotlb_all+0x13c>
    4ae4:	17fff478 	b	1cc4 <arm_smmu_cmdq_issue_cmdlist+0x55c>
    4ae8:	f9800071 	prfm	pstl1strm, [x3]
    4aec:	885f7c60 	ldxr	w0, [x3]
    4af0:	11000401 	add	w1, w0, #0x1
    4af4:	88027c61 	stxr	w2, w1, [x3]
    4af8:	35ffffa2 	cbnz	w2, 4aec <arm_smmu_flush_iotlb_all+0x154>
    4afc:	17fff4ba 	b	1de4 <arm_smmu_cmdq_issue_cmdlist+0x67c>
    4b00:	f9800091 	prfm	pstl1strm, [x4]
    4b04:	885f7c80 	ldxr	w0, [x4]
    4b08:	4a010009 	eor	w9, w0, w1
    4b0c:	35000069 	cbnz	w9, 4b18 <arm_smmu_flush_iotlb_all+0x180>
    4b10:	88097c82 	stxr	w9, w2, [x4]
    4b14:	35ffff89 	cbnz	w9, 4b04 <arm_smmu_flush_iotlb_all+0x16c>
    4b18:	17fff4b6 	b	1df0 <arm_smmu_cmdq_issue_cmdlist+0x688>
    4b1c:	f9800071 	prfm	pstl1strm, [x3]
    4b20:	885f7c61 	ldxr	w1, [x3]
    4b24:	4b000021 	sub	w1, w1, w0
    4b28:	88027c61 	stxr	w2, w1, [x3]
    4b2c:	35ffffa2 	cbnz	w2, 4b20 <arm_smmu_flush_iotlb_all+0x188>
    4b30:	17fff6ee 	b	26e8 <arm_smmu_detach_dev+0x150>
    4b34:	88dffe94 	ldar	w20, [x20]
    4b38:	88dffc21 	ldar	w1, [x1]
    4b3c:	88dffc21 	ldar	w1, [x1]
    4b40:	88dffc00 	ldar	w0, [x0]
    4b44:	f9800051 	prfm	pstl1strm, [x2]
    4b48:	c85f7c40 	ldxr	x0, [x2]
    4b4c:	b2400000 	orr	x0, x0, #0x1
    4b50:	c8017c40 	stxr	w1, x0, [x2]
    4b54:	35ffffa1 	cbnz	w1, 4b48 <arm_smmu_flush_iotlb_all+0x1b0>
    4b58:	17fffb48 	b	3878 <arm_smmu_device_probe+0x8a0>
    4b5c:	88dffc00 	ldar	w0, [x0]
    4b60:	f9800071 	prfm	pstl1strm, [x3]
    4b64:	885f7c61 	ldxr	w1, [x3]
    4b68:	11000421 	add	w1, w1, #0x1
    4b6c:	88027c61 	stxr	w2, w1, [x3]
    4b70:	35ffffa2 	cbnz	w2, 4b64 <arm_smmu_flush_iotlb_all+0x1cc>
    4b74:	17fffe38 	b	4454 <arm_smmu_attach_dev+0x1a4>

Disassembly of section .init.text:

0000000000000000 <arm_smmu_driver_init>:
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
   0:	d503233f 	paciasp
   4:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	if (queue_empty(&q->llq))
   8:	90000000 	adrp	x0, 0 <arm_smmu_driver_init>
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
   c:	91000000 	add	x0, x0, #0x0
  10:	910003fd 	mov	x29, sp
  14:	d2800001 	mov	x1, #0x0                   	// #0
  18:	91012000 	add	x0, x0, #0x48
  1c:	94000000 	bl	0 <__platform_driver_register>
  20:	a8c17bfd 	ldp	x29, x30, [sp], #16
	queue_read(ent, Q_ENT(q, q->llq.cons), q->ent_dwords);
  24:	d50323bf 	autiasp
  28:	d65f03c0 	ret

Disassembly of section .exit.text:

0000000000000000 <arm_smmu_driver_exit>:
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
   0:	d503233f 	paciasp
   4:	a9bf7bfd 	stp	x29, x30, [sp, #-16]!
	if (queue_empty(&q->llq))
   8:	90000000 	adrp	x0, 0 <arm_smmu_driver_exit>
	return Q_IDX(q, q->prod) == Q_IDX(q, q->cons) &&
   c:	91000000 	add	x0, x0, #0x0
  10:	910003fd 	mov	x29, sp
  14:	91012000 	add	x0, x0, #0x48
  18:	94000000 	bl	0 <platform_driver_unregister>
  1c:	a8c17bfd 	ldp	x29, x30, [sp], #16
  20:	d50323bf 	autiasp
	queue_read(ent, Q_ENT(q, q->llq.cons), q->ent_dwords);
  24:	d65f03c0 	ret
